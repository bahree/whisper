1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:34,200
I'm your host, Sam Charrington, hey what's up everyone, we've got an amazing Twimble

4
00:00:34,200 --> 00:00:38,600
Con AI platform's event shaping up for you and I wanted to share a bit about it.

5
00:00:38,600 --> 00:00:41,920
The event is going to be anchored by what we're calling keynote interviews.

6
00:00:41,920 --> 00:00:46,800
These are live podcasts recorded right on the main stage and I'll be joined by some incredible

7
00:00:46,800 --> 00:00:52,680
guests, here are three that I'm really excited about.

8
00:00:52,680 --> 00:00:57,880
One, Andrew Eng, I could not be happier to have Andrew kicking off this event with me.

9
00:00:57,880 --> 00:01:02,640
Andrew is one of my AI heroes and no one has done more to bring new practitioners into machine

10
00:01:02,640 --> 00:01:05,240
learning and deep learning than he has.

11
00:01:05,240 --> 00:01:08,480
Andrew is going to be sharing a bit about what he's learned helping many businesses get

12
00:01:08,480 --> 00:01:12,640
productive with machine learning and AI and also speak with us about where he sees the

13
00:01:12,640 --> 00:01:13,960
field going.

14
00:01:13,960 --> 00:01:18,800
Number two, Hussein Mahana, Hussein is the head of AI and ML at Cruz, the self-driving

15
00:01:18,800 --> 00:01:20,160
car company.

16
00:01:20,160 --> 00:01:25,080
Before Cruz, Hussein helped build Google's cloud ML platform and Facebook's internal

17
00:01:25,080 --> 00:01:27,520
FB learner platform before that.

18
00:01:27,520 --> 00:01:31,480
Hussein is going to be sharing some of the lessons he's learned building ML platforms

19
00:01:31,480 --> 00:01:35,440
from scratch at some of the most advanced companies in the space.

20
00:01:35,440 --> 00:01:37,720
And number three, Fran Bell.

21
00:01:37,720 --> 00:01:41,560
Fran leads a team responsible for data science platforms at Uber.

22
00:01:41,560 --> 00:01:46,600
These are use case focused ML platform supporting application areas like forecasting, anomaly

23
00:01:46,600 --> 00:01:51,560
detection, NLP and conversational AI segmentation and more.

24
00:01:51,560 --> 00:01:56,480
Her platform sit on top of Uber's Michelangelo, putting here on a unique position to speak

25
00:01:56,480 --> 00:02:01,840
with us about how low level and higher level platforms come together to support data scientists

26
00:02:01,840 --> 00:02:04,040
and developer productivity.

27
00:02:04,040 --> 00:02:07,760
Beyond keynote interviews like this, we've got a bunch of outstanding speakers lined up

28
00:02:07,760 --> 00:02:12,200
to share their successes and failures, helping their organizations build and production

29
00:02:12,200 --> 00:02:15,120
lies, ML and deep learning models.

30
00:02:15,120 --> 00:02:21,240
If this lineup sounds interesting to you, visit twimmolcon.com today to register.

31
00:02:21,240 --> 00:02:27,320
Use the coupon code GreatContent through July 31st for an additional 10% off of our special

32
00:02:27,320 --> 00:02:28,840
early bird pricing.

33
00:02:28,840 --> 00:02:30,240
Hope to see you at Twimmolcon.

34
00:02:30,240 --> 00:02:36,040
Alright everyone, I am on the line with Theo Cariannis.

35
00:02:36,040 --> 00:02:42,080
Theo is an assistant professor at the Brain Research Institute of the University of Zurich.

36
00:02:42,080 --> 00:02:44,960
Theo, welcome to this Week in Machine Learning and AI.

37
00:02:44,960 --> 00:02:46,960
Thank you very much for having me.

38
00:02:46,960 --> 00:02:47,960
Absolutely, absolutely.

39
00:02:47,960 --> 00:02:52,320
Let's get started by having you share a little bit about your background.

40
00:02:52,320 --> 00:02:58,640
How did you come to work at the intersection of brain science and machine learning?

41
00:02:58,640 --> 00:03:08,600
Yes, so I would say that I haven't had sort of the most direct path in this sort of field.

42
00:03:08,600 --> 00:03:15,280
So I started off actually studying pharmacy of all things.

43
00:03:15,280 --> 00:03:21,640
So I had sort of my bachelor's degree in pharmaceutical sciences and pharmacy and then I was

44
00:03:21,640 --> 00:03:27,760
very, very much interested in sort of my final years in getting into brain science and understanding

45
00:03:27,760 --> 00:03:31,920
actually brain physiology and pathology.

46
00:03:31,920 --> 00:03:38,600
After that, I decided to pursue a career in neuroscience research, so brain science,

47
00:03:38,600 --> 00:03:42,920
through which I've had sort of a decent sort of long trajectory.

48
00:03:42,920 --> 00:03:48,160
And after I would say establishing my lab here at the University of Zurich about three

49
00:03:48,160 --> 00:03:57,080
years ago, so I came to appreciate and came more into sort of contact with the methods

50
00:03:57,080 --> 00:04:05,280
that were actually flooding, in fact, every almost field of science and also neuroscience

51
00:04:05,280 --> 00:04:07,360
that had to do with deep learning.

52
00:04:07,360 --> 00:04:14,560
So that was sort of my first kind of contact with deep learning was after I joined the

53
00:04:14,560 --> 00:04:20,600
brain research institute and I started working on my own kind of research projects after

54
00:04:20,600 --> 00:04:22,600
being a postdoctoral fellow.

55
00:04:22,600 --> 00:04:28,880
So I can elaborate more if you want on this or well, why don't you tell us a little bit

56
00:04:28,880 --> 00:04:31,080
about your research focus?

57
00:04:31,080 --> 00:04:32,080
Yeah.

58
00:04:32,080 --> 00:04:33,080
Okay.

59
00:04:33,080 --> 00:04:41,160
So what I have been working on and actually I'm very much interested in the lab as well.

60
00:04:41,160 --> 00:04:46,800
We're very much focused on understanding how the brain develops.

61
00:04:46,800 --> 00:04:57,600
So our primary focus is utilizing animal models, mammalian animal models, more specifically

62
00:04:57,600 --> 00:05:01,600
genetically tractable animal model, the mouse.

63
00:05:01,600 --> 00:05:07,240
And utilizing that in order to understand how the circuits in the brain get formed during

64
00:05:07,240 --> 00:05:12,720
development, especially postnatal development, so after birth, and how these circuits are

65
00:05:12,720 --> 00:05:21,600
modified by experience to allow us to really process information from our environment and

66
00:05:21,600 --> 00:05:28,000
ever increasing sort of complex and specific manner.

67
00:05:28,000 --> 00:05:35,040
So I would say that this is kind of the umbrella field that we were working towards understanding.

68
00:05:35,040 --> 00:05:44,920
So basically one of the sort of the more specific aspects of our work is aimed at understanding

69
00:05:44,920 --> 00:05:52,120
how the cortex gets built, so which is this outer surface of the brain, which is kind

70
00:05:52,120 --> 00:05:59,960
of supposed to be the most complex and evolutionary newer part of the nervous system.

71
00:05:59,960 --> 00:06:06,560
And to understand that, we focused on specific sort of sensory regions in the cortex of the

72
00:06:06,560 --> 00:06:11,760
mouse in order to understand how they process information as the animal grows.

73
00:06:11,760 --> 00:06:12,760
Okay.

74
00:06:12,760 --> 00:06:20,000
And so does the cortex have how are the different sensory regions in the cortex organized?

75
00:06:20,000 --> 00:06:26,040
So there's some sort of some a topic if you want in a way in the sense that they are

76
00:06:26,040 --> 00:06:28,880
separated in space.

77
00:06:28,880 --> 00:06:34,240
So there's, for example, regions that are devoted to processing visual information, other regions

78
00:06:34,240 --> 00:06:40,640
are devoted to processing so much of sensory information, so touch, events, and others

79
00:06:40,640 --> 00:06:46,920
for other sensory modalities that we have, such as hearing or smelling.

80
00:06:46,920 --> 00:06:52,560
So there's sort of a, of course, this aggregation of these areas, which at some point, of course,

81
00:06:52,560 --> 00:06:59,960
further down the information processing kind of convergent come together into a common

82
00:06:59,960 --> 00:07:05,480
sort of conscious, if you want, event that can lead to behavioral outcomes.

83
00:07:05,480 --> 00:07:12,080
Is your research focused on understanding how the kind of connections and pathways are

84
00:07:12,080 --> 00:07:13,080
made?

85
00:07:13,080 --> 00:07:18,880
Or do you see that the neurons kind of physically differentiate so that there are multiple

86
00:07:18,880 --> 00:07:25,440
types that kind of interact with one another to produce memory and behavior in these things?

87
00:07:25,440 --> 00:07:32,920
We basically focus quite a bit on understanding a population of cells, neurons in the brain,

88
00:07:32,920 --> 00:07:40,720
which are called inhibitory cells, or they have, sort of, used alternative names and maybe

89
00:07:40,720 --> 00:07:47,320
more so correct these gubergic cells that take their name from the molecule they used

90
00:07:47,320 --> 00:07:49,520
to communicate with one another.

91
00:07:49,520 --> 00:07:58,320
So we basically focus a lot on understanding how this second most populous neuronal sort

92
00:07:58,320 --> 00:08:07,320
of group in the cortex gets developed, so develops and integrates into the sort of circuit

93
00:08:07,320 --> 00:08:13,000
to start parsing out the information that the circuit receives.

94
00:08:13,000 --> 00:08:20,880
So I would say that, you know, the lab is sort of focused at multiple levels of analysis.

95
00:08:20,880 --> 00:08:29,560
One of which is now going to this a bit more to this sort of brain-wide level where things

96
00:08:29,560 --> 00:08:38,920
need to sort of be quantified at a sort of more complete if you want sort of level.

97
00:08:38,920 --> 00:08:45,640
So we try to understand a little bit how different areas sort of develop how inhibitory cells

98
00:08:45,640 --> 00:08:53,160
themselves that inhibit signals and regulate how information flows are positioned in different

99
00:08:53,160 --> 00:09:05,040
areas, how they start function during development and what that may do for signal propagation.

100
00:09:05,040 --> 00:09:08,880
So this is kind of something that we've been focused, of course, there's multiple different

101
00:09:08,880 --> 00:09:16,640
types of cells and the jury is still out as to how many, but our work is sort of a bit

102
00:09:16,640 --> 00:09:19,800
focused more on these cells.

103
00:09:19,800 --> 00:09:26,200
And so how is deep learning come into play in your research in this area?

104
00:09:26,200 --> 00:09:34,680
The way we kind of came about or turned our attention to deep learning is through a couple

105
00:09:34,680 --> 00:09:41,120
of projects that we had in mind where we in fact wanted to address what I was saying

106
00:09:41,120 --> 00:09:47,160
earlier, which has to do with a bit more comprehensive understanding of how these populations

107
00:09:47,160 --> 00:09:54,200
are, let's say, generated, how they populate different areas and how they may even sort

108
00:09:54,200 --> 00:10:00,520
of cease to exist by a phenomenon which is called cell death.

109
00:10:00,520 --> 00:10:07,560
And so in order to be able to achieve that, one needs to create or have the tools at hand

110
00:10:07,560 --> 00:10:16,120
that allow them to be able to perform an experiment or have some data at hand which have to

111
00:10:16,120 --> 00:10:23,320
do with actually, let's say, distribution of cells, let's say, based on a specific marker

112
00:10:23,320 --> 00:10:27,280
or something that marks the cells that one is interested in our case, let's say inhibitory

113
00:10:27,280 --> 00:10:31,040
cells in the whole brain, right?

114
00:10:31,040 --> 00:10:36,040
And that way you have sort of, let's say, a section, a tissue that allows you to sort

115
00:10:36,040 --> 00:10:38,800
of look at that and take a picture of it.

116
00:10:38,800 --> 00:10:44,240
Now, the key question here is how do you analyze that data and how do you analyze it across

117
00:10:44,240 --> 00:10:47,000
different developmental stages?

118
00:10:47,000 --> 00:10:54,000
This is actually how we came about wanting to look into these techniques that are very powerful

119
00:10:54,000 --> 00:11:01,760
and are created by multiple labs across the globe that would allow us to basically, first

120
00:11:01,760 --> 00:11:12,680
of all, have an atlas that tells us which region is which when we're looking at our tissue.

121
00:11:12,680 --> 00:11:18,000
And on top of that, try to extract the signal, which is a cellular signal.

122
00:11:18,000 --> 00:11:24,760
So it's a dotted sort of signal from each one of those brain areas.

123
00:11:24,760 --> 00:11:30,160
So this is actually, you know, the reason why we turned our attention to deep learning

124
00:11:30,160 --> 00:11:37,280
and machine learning methods that would allow us to basically segment, classify segment

125
00:11:37,280 --> 00:11:45,200
different regions and also be able to basically pick up detect the cellular signal that is found

126
00:11:45,200 --> 00:11:46,200
within them.

127
00:11:46,200 --> 00:11:47,200
Okay.

128
00:11:47,200 --> 00:11:53,480
And so a little bit more about the images that you're using, are they 3D scans?

129
00:11:53,480 --> 00:11:57,960
Are you looking at slices and you need to relate information between slices?

130
00:11:57,960 --> 00:12:01,080
Can you tell us a little bit more about the images themselves?

131
00:12:01,080 --> 00:12:02,080
Yes.

132
00:12:02,080 --> 00:12:10,320
Actually, we started off by doing sections, so slices, so tissue sections, brain sections.

133
00:12:10,320 --> 00:12:16,320
So where we have the whole brain, in fact, in view, and we just take images that can be

134
00:12:16,320 --> 00:12:17,320
also different modalities.

135
00:12:17,320 --> 00:12:23,440
It can be, for example, some bright field images where you detect some chromophore signal

136
00:12:23,440 --> 00:12:27,920
that has been created by a chemical reaction or by fluorescence.

137
00:12:27,920 --> 00:12:34,560
So by signal, which actually leads to fluorescent sort of protein signal that you can detect

138
00:12:34,560 --> 00:12:42,720
in cells, we have nevertheless also applied these kinds of methods now to different images

139
00:12:42,720 --> 00:12:50,320
from different modalities, imaging modalities, such as those taken by a fairly new method

140
00:12:50,320 --> 00:12:56,440
that is used in the biological field and also in the neurosciences, which is called clarity

141
00:12:56,440 --> 00:12:59,680
or brain clearing.

142
00:12:59,680 --> 00:13:05,680
These types of images are generated by the fact that what is done during the processing

143
00:13:05,680 --> 00:13:11,280
of the brain, which is after the animal has been sacrificed, is to basically get rid

144
00:13:11,280 --> 00:13:16,640
of the lipids and make the brain be transparent, the tissue.

145
00:13:16,640 --> 00:13:21,520
And that way you can actually just shine light through it and detect what is evoked in

146
00:13:21,520 --> 00:13:27,160
terms of light by means of, again, the fluorescence sort of signal.

147
00:13:27,160 --> 00:13:30,200
That way the light is not obstructed to go through, right?

148
00:13:30,200 --> 00:13:37,280
So this is another sort of imaging modality that we have used to apply our techniques on.

149
00:13:37,280 --> 00:13:43,160
In addition, in the paper, actually, that was sort of just published, we also tried to

150
00:13:43,160 --> 00:13:48,560
benchmark our methods, at least one of the methods we've used on some sort of MRI scans

151
00:13:48,560 --> 00:13:54,720
from human patients or rather individuals, I'm sorry, that are found on the web in the

152
00:13:54,720 --> 00:13:55,720
database.

153
00:13:55,720 --> 00:14:02,880
But so, although we apply these techniques mainly in mouse tissue, we hope that this method

154
00:14:02,880 --> 00:14:09,560
would also sort of start being applied in other types of tissues in this case or species

155
00:14:09,560 --> 00:14:11,240
like humans.

156
00:14:11,240 --> 00:14:18,240
And so the segmentation that you're trying to do with your method is, is it fair to say

157
00:14:18,240 --> 00:14:23,600
it's what I would, what one might call like a macro level segmentation like these large

158
00:14:23,600 --> 00:14:30,320
regions of the brain as opposed to clusters of cells within individual brain regions.

159
00:14:30,320 --> 00:14:31,320
Yes.

160
00:14:31,320 --> 00:14:38,280
So the initial part was to basically be able to, you're correct, yes, segment a few different

161
00:14:38,280 --> 00:14:44,640
brain regions such as, for example, the cortex, this outer surface that we care about.

162
00:14:44,640 --> 00:14:50,400
But the next level of analysis that we are actually aiming at and we have already implemented

163
00:14:50,400 --> 00:14:55,720
parts of, have to do with being able to at least use these deep learning methods to

164
00:14:55,720 --> 00:14:59,040
be able to detect all the cells.

165
00:14:59,040 --> 00:15:03,320
So in a way, create a, you know, bounding boxes around them and actually classify them

166
00:15:03,320 --> 00:15:10,640
and say with a specific sort of, you know, score that these are in fact neurons.

167
00:15:10,640 --> 00:15:21,360
And you mentioned something about seeing or segmenting connections or like signals in

168
00:15:21,360 --> 00:15:22,360
these images.

169
00:15:22,360 --> 00:15:24,160
Did I interpret that correctly?

170
00:15:24,160 --> 00:15:32,040
Are you able to through the imaging techniques, look at actual communication of neurons?

171
00:15:32,040 --> 00:15:38,880
And so we have not actually been sort of dealing with connections per se in the sense that,

172
00:15:38,880 --> 00:15:44,560
you know, these are usually smaller elements and quite complex in nature, depending on how

173
00:15:44,560 --> 00:15:50,560
you look at them, that we haven't really kind of dive into it yet.

174
00:15:50,560 --> 00:15:56,400
One of the things we have sort of done a little bit of is look at some really fine grain

175
00:15:56,400 --> 00:16:03,600
structures which are found on cells, which are the sites where connections happen and

176
00:16:03,600 --> 00:16:08,000
try to sort of, in fact, look at maybe how these change a little bit.

177
00:16:08,000 --> 00:16:13,520
These are called spines for excitatory cells for these other population of neurons.

178
00:16:13,520 --> 00:16:20,040
But in terms of actually looking at, you know, the elements of two, let's say, cells or

179
00:16:20,040 --> 00:16:26,840
two neurons connecting, we haven't sort of been looking at that too much.

180
00:16:26,840 --> 00:16:33,880
What we have done is utilize these methods in combination though with other genetic

181
00:16:33,880 --> 00:16:42,240
and viral and anatomically basically methods that allow us to look at which cells connect

182
00:16:42,240 --> 00:16:48,960
to which other cells in the brain, then performing a whole sort of brain mapping of those connections

183
00:16:48,960 --> 00:16:55,360
by doing this clarity method that I mentioned before, and then actually analyzing the signal

184
00:16:55,360 --> 00:16:56,960
using these deep learning methods.

185
00:16:56,960 --> 00:17:04,200
So basically analyzing the regions, maybe types of cells, but also the numbers and density

186
00:17:04,200 --> 00:17:09,040
of cells found in those regions using these deep learning algorithms.

187
00:17:09,040 --> 00:17:10,040
Okay.

188
00:17:10,040 --> 00:17:14,800
That may have been what I heard earlier that I was trying to tease apart.

189
00:17:14,800 --> 00:17:20,920
When you say the cells that are connected to one another, is that basically another way

190
00:17:20,920 --> 00:17:25,920
of saying cells that are in the same region, meaning the assumption is all of the cells

191
00:17:25,920 --> 00:17:30,120
in the cortex are connected or all the cells in the hippocampus are connected, that kind

192
00:17:30,120 --> 00:17:31,120
of thing.

193
00:17:31,120 --> 00:17:32,120
Yeah.

194
00:17:32,120 --> 00:17:38,640
It's actually sort of not the case in the sense that, you know, so the first assumptions

195
00:17:38,640 --> 00:17:45,840
that let's say the neurons in specific are all connected or maybe this is kind of the

196
00:17:45,840 --> 00:17:48,880
current view, which is, which is not the case.

197
00:17:48,880 --> 00:17:54,960
There's a lot of specificity actually in those connections between a variety of different

198
00:17:54,960 --> 00:17:56,800
types of cells.

199
00:17:56,800 --> 00:17:58,400
So that's not what you're saying.

200
00:17:58,400 --> 00:18:05,560
No, what I am actually saying is that through the use of a genetically tractable model,

201
00:18:05,560 --> 00:18:11,320
which is the mouse in this case, we end utilizing some complex methods that we can, in fact,

202
00:18:11,320 --> 00:18:13,320
go more into.

203
00:18:13,320 --> 00:18:20,440
We are able to, let's say, have a type of cell that we care about understanding what

204
00:18:20,440 --> 00:18:26,800
connects to it or revealing, and by tracing those connections in the cells that connect

205
00:18:26,800 --> 00:18:34,120
to that cell, not only in that area, but actually across the brain, that allows us to get a full

206
00:18:34,120 --> 00:18:41,560
sort of brain-wide view if you want of what kinds of areas and also what kinds of potentially

207
00:18:41,560 --> 00:18:49,920
cells actually connect with, let's say, the cells of interest in another given area.

208
00:18:49,920 --> 00:18:51,480
Does that make sense?

209
00:18:51,480 --> 00:18:52,480
It does.

210
00:18:52,480 --> 00:18:55,160
Let's definitely go a little bit deeper into that.

211
00:18:55,160 --> 00:19:02,880
But before we do, you've mentioned a couple of times the genetically tractable mouse.

212
00:19:02,880 --> 00:19:08,280
What's the significance of the genetic tractability to your research and what you're describing?

213
00:19:08,280 --> 00:19:16,200
So, it's, for us, it's actually very important, and it opens up sort of the door to a number

214
00:19:16,200 --> 00:19:23,200
of sort of approaches and questions that are not as easily addressable in different kinds

215
00:19:23,200 --> 00:19:29,680
of species, which you cannot, sort of, let's say, genetically modify or manipulate.

216
00:19:29,680 --> 00:19:42,280
So to give you an example, by modifying the genome of the mouse, you can label specific

217
00:19:42,280 --> 00:19:48,480
populations and even types of cells, maybe in specific areas of the brain.

218
00:19:48,480 --> 00:19:54,280
Of course, it's not always as clear-cut, and we can discuss why that is, but it allows

219
00:19:54,280 --> 00:20:01,600
us to basically be able to label these cells, track them across different ages, for example,

220
00:20:01,600 --> 00:20:04,520
and also manipulate them.

221
00:20:04,520 --> 00:20:12,080
And by manipulation, I mean that you can, for example, remove gene of interest, such as,

222
00:20:12,080 --> 00:20:17,720
let's say, a disease relevant gene that has been implicated in some sort of a neurodevelopmental

223
00:20:17,720 --> 00:20:25,640
disorder, where we know that its expression or its sort of function is reduced.

224
00:20:25,640 --> 00:20:32,880
You can basically remove that gene in specific populations and areas and time to understand

225
00:20:32,880 --> 00:20:37,000
what it does and how it affects specific circuits.

226
00:20:37,000 --> 00:20:44,560
So it is very powerful for us to be able to, sort of, really be able to track and also

227
00:20:44,560 --> 00:20:47,720
manipulate specific populations and cells.

228
00:20:47,720 --> 00:20:53,040
When you say label, you're talking about like inserting protein sequences that you can

229
00:20:53,040 --> 00:20:54,560
easily identify.

230
00:20:54,560 --> 00:20:55,560
Yes, you can.

231
00:20:55,560 --> 00:20:58,160
Kind of thing, or something else.

232
00:20:58,160 --> 00:21:00,800
Yes, you can do that.

233
00:21:00,800 --> 00:21:06,760
You can basically, exactly insert, let's say, something which was not present and is

234
00:21:06,760 --> 00:21:12,360
not present in the mouse, but which has been, in fact, shown after multiple sort of control

235
00:21:12,360 --> 00:21:18,320
experiments that doesn't have any negative effect on the cell.

236
00:21:18,320 --> 00:21:24,560
So this is, like, let's say, a small scissors, if you want, protein that acts as a scissors,

237
00:21:24,560 --> 00:21:29,520
and then you can combine that with, sort of, let's say, a receptive end, right?

238
00:21:29,520 --> 00:21:36,000
So you can, let's say, have the points where the scissors can work.

239
00:21:36,000 --> 00:21:42,520
You can add them in specific sort of genes in the genome and hence sort of cut them out.

240
00:21:42,520 --> 00:21:48,960
Or you can add something on top of it, again, external, which then you can cut out and

241
00:21:48,960 --> 00:21:55,040
actually, you can cut out one part and let it then fluoresce and let it sort of die, you

242
00:21:55,040 --> 00:22:00,200
know, die in a sense of, like, color the cells.

243
00:22:00,200 --> 00:22:06,160
So it's actually sort of, there's so many now, very sort of interesting tools that have

244
00:22:06,160 --> 00:22:12,160
been developed, which, by the way, there's also now, even cooler tools that have been developed,

245
00:22:12,160 --> 00:22:21,760
which allows us to now utilize methods that, in species that were not as easily sort of

246
00:22:21,760 --> 00:22:23,120
accessible before.

247
00:22:23,120 --> 00:22:28,400
One of those is this CRISPR-Cas method that has been very popular in biology.

248
00:22:28,400 --> 00:22:35,320
Okay, so with these tools in place, now can you talk a little bit more about this process

249
00:22:35,320 --> 00:22:42,160
of kind of mapping the connections from one cell around the brain?

250
00:22:42,160 --> 00:22:43,480
Yes.

251
00:22:43,480 --> 00:22:46,880
So let me sort of take a step back.

252
00:22:46,880 --> 00:22:51,240
So one of the things that, sort of, the way we've done it, I will try to explain the

253
00:22:51,240 --> 00:22:54,120
way we've done it.

254
00:22:54,120 --> 00:23:03,120
So we have, let's say, been utilizing some genetically modified animals or mice that,

255
00:23:03,120 --> 00:23:10,600
as I said, express these scissors in specific cell populations that we care to study.

256
00:23:10,600 --> 00:23:17,200
Specific, let's say, type, that a specific internal type or inhibitory type in the brain

257
00:23:17,200 --> 00:23:19,400
and the cortex.

258
00:23:19,400 --> 00:23:28,400
So by having these scissors cut out a stop signal, if you want, they allow something else

259
00:23:28,400 --> 00:23:30,200
to come online.

260
00:23:30,200 --> 00:23:36,160
And that something else that comes online, like a set of proteins, are, in fact, then expressed

261
00:23:36,160 --> 00:23:41,040
or presented in the cell types that we care to study.

262
00:23:41,040 --> 00:23:47,760
One of those things that is expressed is actually a receptor, so something which can go

263
00:23:47,760 --> 00:23:54,000
to the membrane of the cell, the outer sort of part of the cell, and that has specific

264
00:23:54,000 --> 00:23:56,000
things that it binds to.

265
00:23:56,000 --> 00:24:03,960
So this is a protein that is not found in mice, so it's actually found in birds.

266
00:24:03,960 --> 00:24:08,320
And hence, we know that then it should be specific for these cell types.

267
00:24:08,320 --> 00:24:14,120
Now what we do is we, at the same time, utilize genetically modified viruses.

268
00:24:14,120 --> 00:24:21,440
So in the neurosciences, viruses have been used quite some time now, in order to be able

269
00:24:21,440 --> 00:24:27,320
to, for example, express certain things, let's say a colorful thing, that once you put

270
00:24:27,320 --> 00:24:34,920
it in a specific area, then you can actually have these viruses be taken up by the cells,

271
00:24:34,920 --> 00:24:40,080
and then you actually see the cells and all their processes labeled.

272
00:24:40,080 --> 00:24:45,280
Therefore, you can follow them in different areas, in different brain regions.

273
00:24:45,280 --> 00:24:52,760
Now this has actually been even more modified, and even more sort of tools have been created

274
00:24:52,760 --> 00:24:57,880
to now be able to label specific populations of cells, such as the ones I was describing.

275
00:24:57,880 --> 00:25:03,720
So by putting a modified rabies virus in this case, the rabies virus, we can discuss

276
00:25:03,720 --> 00:25:08,960
what it is, but it's a different kind of, it's a specific type of virus, you're able to

277
00:25:08,960 --> 00:25:14,000
infect the cells that you want, and because the virus now is red, right, because you

278
00:25:14,000 --> 00:25:19,880
have expressed a dye in their colorful dye, it can actually label the cells that you care

279
00:25:19,880 --> 00:25:24,280
to label, and it can also label the cells that connect to that cell.

280
00:25:24,280 --> 00:25:33,480
And so I hope sort of I explained it simply enough, but not simplified, not I didn't simplify

281
00:25:33,480 --> 00:25:37,840
sort of too much, or it wasn't sort of too complex, but basically by utilizing different

282
00:25:37,840 --> 00:25:44,560
sets of tools, which have to do with the mouse lines and also the different viruses again,

283
00:25:44,560 --> 00:25:51,320
we're able to, in fact, look at connections on specific cell pipes.

284
00:25:51,320 --> 00:25:53,200
That is super fascinating.

285
00:25:53,200 --> 00:25:59,080
And now I've kind of pushed you down into the biology here, which is very, very interesting.

286
00:25:59,080 --> 00:26:05,080
With this particular problem of the connections, is this a place that you're applying deep learning

287
00:26:05,080 --> 00:26:06,080
as well?

288
00:26:06,080 --> 00:26:09,440
Yeah, so I'm really glad you said yes.

289
00:26:09,440 --> 00:26:18,480
Yes, yes, what we have sort of been applying deep learning methods for in this case is

290
00:26:18,480 --> 00:26:27,680
are to be able to again, to look at, for example, the distribution of the connections, right?

291
00:26:27,680 --> 00:26:37,840
So let's say you want to assess a brain area A, and what connects to cell type A.

292
00:26:37,840 --> 00:26:42,240
And so you utilize the methods I mentioned, and then you want to understand, because you

293
00:26:42,240 --> 00:26:44,120
almost go with an unbiased approach, right?

294
00:26:44,120 --> 00:26:49,360
So you say, okay, where do these cells receive information from, from which areas in which

295
00:26:49,360 --> 00:26:50,360
cell time?

296
00:26:50,360 --> 00:26:55,640
So in order to do that, again, in a brain wide manner, you need to put in place methods

297
00:26:55,640 --> 00:27:03,080
that don't force you to actually do typical stereology, that you start counting and extrapolating,

298
00:27:03,080 --> 00:27:09,320
or in fact, you know, make you count every single cell and try to eyeball the region that

299
00:27:09,320 --> 00:27:11,400
the cells sit in.

300
00:27:11,400 --> 00:27:17,840
So we try to utilize these deep learning methods to, first of all, identify brain regions

301
00:27:17,840 --> 00:27:23,200
in a whole brain sort of imaging set, as I said, with clarity and light sheet microscopy.

302
00:27:23,200 --> 00:27:27,440
And then once we have identified the region and segmented, let's say the region, then

303
00:27:27,440 --> 00:27:34,400
we actually use a different algorithm to actually detect all the cells in that region.

304
00:27:34,400 --> 00:27:39,880
And so can you talk about the specifics of the deep learning that you've used to accomplish

305
00:27:39,880 --> 00:27:41,240
these tasks?

306
00:27:41,240 --> 00:27:42,240
Yes.

307
00:27:42,240 --> 00:27:51,360
So in this case, I would say that we're kind of like the end user here and on the application

308
00:27:51,360 --> 00:27:52,360
side.

309
00:27:52,360 --> 00:27:59,960
So the kinds of networks we're utilizing are actually being currently developed by, so

310
00:27:59,960 --> 00:28:03,720
outside the lab, and they're being published by a number of labs.

311
00:28:03,720 --> 00:28:08,040
And in this case, by, for example, Facebook or Google.

312
00:28:08,040 --> 00:28:15,560
And we basically took inspiration from the excellent results that they have, in fact, seen

313
00:28:15,560 --> 00:28:25,480
in life basically, you know, images of humans or cars or any sort of, basically, external

314
00:28:25,480 --> 00:28:32,640
sort of scene that allows us to basically, again, segment and call an object, an object

315
00:28:32,640 --> 00:28:35,360
of a specific type and also count cells.

316
00:28:35,360 --> 00:28:41,960
So the two methods that we have utilized actually adapted, I would say, for our methods.

317
00:28:41,960 --> 00:28:48,000
Our two networks, which are called FastRcNN and MaskRcNN.

318
00:28:48,000 --> 00:28:53,720
And these sort of were developed by the MaskRcN, specifically, which we utilized in the

319
00:28:53,720 --> 00:28:58,200
published work was basically developed by Facebook AI research.

320
00:28:58,200 --> 00:29:00,240
Got it.

321
00:29:00,240 --> 00:29:10,760
And did you evaluate a broad array of different methods or algorithms or start there and

322
00:29:10,760 --> 00:29:13,520
it seemed to work well, so you moved on?

323
00:29:13,520 --> 00:29:14,520
Yeah.

324
00:29:14,520 --> 00:29:19,040
So our primary purpose, obviously, was not to kind of do like an end-to-end comparison with

325
00:29:19,040 --> 00:29:24,440
all the methods that are out there, because we're also not primarily allowed that develops

326
00:29:24,440 --> 00:29:32,920
these kinds of techniques or puts a significant effort in basically into this field.

327
00:29:32,920 --> 00:29:36,960
So I would say that we basically looked out there to see what's available, what's the

328
00:29:36,960 --> 00:29:43,040
most common sort of way that people do this kind of, in this case, image registration

329
00:29:43,040 --> 00:29:44,920
to Nathlas.

330
00:29:44,920 --> 00:29:50,880
And that we benchmarked our method against, which these are not deep learning algorithms.

331
00:29:50,880 --> 00:29:58,640
But of course, there's other sort of other efforts that have been also done by other labs,

332
00:29:58,640 --> 00:30:04,240
of course, that were sort of generating methods to do these kinds of things.

333
00:30:04,240 --> 00:30:11,040
But I would say these efforts have focused on mainly human brain images.

334
00:30:11,040 --> 00:30:17,960
What did you learn as you were applying these methods like mask our CNN to this problem?

335
00:30:17,960 --> 00:30:25,120
Any particular interesting challenge or observations in terms of applying it to the types of images

336
00:30:25,120 --> 00:30:28,040
and objects that you were looking for?

337
00:30:28,040 --> 00:30:35,040
Yeah, I mean, one of the sort of things that we, I at least came to appreciate is actually,

338
00:30:35,040 --> 00:30:41,320
of course, the power of these methods when you should have at least a large enough sort

339
00:30:41,320 --> 00:30:48,280
of training data set to be able them to look at the, you know, testing data set and actually

340
00:30:48,280 --> 00:30:50,000
perform the job.

341
00:30:50,000 --> 00:30:58,440
But in terms of our sort of method, I would say or our sort of questions, I would say that

342
00:30:58,440 --> 00:31:02,440
first of all, we didn't try to do this for all of the brain regions.

343
00:31:02,440 --> 00:31:08,960
We actually chose a few brain regions to kind of showcase the ability of the method to perform

344
00:31:08,960 --> 00:31:12,400
well and the usability of the method.

345
00:31:12,400 --> 00:31:20,880
But I would say that, of course, structures change in the brain when you move to different

346
00:31:20,880 --> 00:31:23,520
sort of, let's say, parts of the axis, right?

347
00:31:23,520 --> 00:31:29,880
So you may have the same brain region, let's say the cortex or the hippocampus.

348
00:31:29,880 --> 00:31:39,200
But as you go and take images of that region at different, basically, levels, right, closer,

349
00:31:39,200 --> 00:31:45,840
let's say to the middle, midline or farther away from it, then the network is having a

350
00:31:45,840 --> 00:31:52,960
challenge in basically being able to detect, of course, more complex types of imaging

351
00:31:52,960 --> 00:31:54,360
brain regions, right?

352
00:31:54,360 --> 00:31:59,720
And so I would say that the network has performed well enough for us to actually make use

353
00:31:59,720 --> 00:32:01,200
of it.

354
00:32:01,200 --> 00:32:07,840
But there's quite some way that we have to go in order to make sure that it's even

355
00:32:07,840 --> 00:32:14,920
more accurate and that it's actually able to segmental of this harder type of regions,

356
00:32:14,920 --> 00:32:21,120
which are maybe not as sort of easy and also expanded in other brain areas and even more

357
00:32:21,120 --> 00:32:24,400
specific parts of a given brain area.

358
00:32:24,400 --> 00:32:29,320
So I would say we're at the very beginning of this of these efforts.

359
00:32:29,320 --> 00:32:36,080
And what were some of the alternative or traditional techniques that you were benchmarking these

360
00:32:36,080 --> 00:32:37,960
methods against?

361
00:32:37,960 --> 00:32:44,240
So two of the most commonly used methods are elastics and MD-rich.

362
00:32:44,240 --> 00:32:52,960
So these are basically non-deep learning algorithms where they take minimum type of error

363
00:32:52,960 --> 00:33:04,360
approaches and utilize linear or non-linear sort of warping of the atlases onto images

364
00:33:04,360 --> 00:33:06,280
that you have collected.

365
00:33:06,280 --> 00:33:13,520
So these are the two sort of most commonly used and we kind of try to utilize those ones

366
00:33:13,520 --> 00:33:15,040
to just initially at least.

367
00:33:15,040 --> 00:33:20,600
And then we try to take it one step further and utilize or compare against some other

368
00:33:20,600 --> 00:33:31,240
methods, which were basically out there published on some human, in fact, tissue, again, was sort

369
00:33:31,240 --> 00:33:34,080
of the web, wasn't generated by us.

370
00:33:34,080 --> 00:33:41,880
So I would say that this is, you know, it is not, of course, clear whether at the moment

371
00:33:41,880 --> 00:33:47,880
this is the best deep learning algorithm to be able to segment different brain regions

372
00:33:47,880 --> 00:33:56,320
because, of course, this field is moving very fast and, you know, it is not unlikely

373
00:33:56,320 --> 00:34:01,800
that other algorithms are in the making or, in fact, we're just, let's say, published

374
00:34:01,800 --> 00:34:08,680
that could even sort of surpass this algorithm we've used.

375
00:34:08,680 --> 00:34:16,480
Were there any particular challenges that you faced in the kind of the data management

376
00:34:16,480 --> 00:34:21,280
and preparation side of this project?

377
00:34:21,280 --> 00:34:27,400
Yes, I would say that, of course, with any of these methods, again, as a sort of novice

378
00:34:27,400 --> 00:34:32,600
in the field, I've come to appreciate the amount of effort that needs to be put in terms

379
00:34:32,600 --> 00:34:35,680
of generating the ground truth data set.

380
00:34:35,680 --> 00:34:44,000
And so that has been sort of, of course, a bit of a bottleneck for us being able to

381
00:34:44,000 --> 00:34:49,640
really kind of create this data that we use to train the network.

382
00:34:49,640 --> 00:34:55,880
Yeah, I would say this has been sort of the biggest challenge for us if you want in

383
00:34:55,880 --> 00:35:04,760
sort of doing this, because we were, in fact, lucky enough, or maybe sort of inspired

384
00:35:04,760 --> 00:35:12,960
enough, I would say, to also have access or gain access to a big data set, which is

385
00:35:12,960 --> 00:35:19,480
available to us and actually the whole neuroscience or brain science community, provided by the

386
00:35:19,480 --> 00:35:23,520
Alan Institute based in Seattle.

387
00:35:23,520 --> 00:35:31,520
So this has been an institute that has been generating a lot of data at different levels

388
00:35:31,520 --> 00:35:40,920
of analysis, including a lot of sort of images of mouse brain for different types of proteins

389
00:35:40,920 --> 00:35:45,120
and markers and so on, so forth, that mark different areas, different sort of cell types

390
00:35:45,120 --> 00:35:46,800
and so on, so forth.

391
00:35:46,800 --> 00:35:50,240
So this was also sort of a great resource for us to have.

392
00:35:50,240 --> 00:35:57,000
And so we tried to utilize it, you know, abundantly in order to sort of get to our goal.

393
00:35:57,000 --> 00:36:03,440
And so what's next for you and your lab in terms of applications of machine learning and

394
00:36:03,440 --> 00:36:06,200
deep learning?

395
00:36:06,200 --> 00:36:13,280
So what's next for the lab is actually one of the things that we would like to try to

396
00:36:13,280 --> 00:36:23,880
do is to expand on on this approaches to both anatomical type of data, but also potentially

397
00:36:23,880 --> 00:36:33,560
sort of some functional data, meaning some activity type of data that we collect and others

398
00:36:33,560 --> 00:36:41,840
on live animals awake or freely behaving or basically that have undergone some sort

399
00:36:41,840 --> 00:36:45,040
of like external stimulus presentation.

400
00:36:45,040 --> 00:36:53,200
So I would say that for now we're aiming to expand some of these methods to potentially

401
00:36:53,200 --> 00:37:02,840
include other areas, but even more so to include hopefully different sub regions within regions,

402
00:37:02,840 --> 00:37:09,120
right, where we then need to create even sort of different types of ground truth, of course,

403
00:37:09,120 --> 00:37:15,000
that will give us quite a bit more specificity in terms of understanding actually this at

404
00:37:15,000 --> 00:37:18,200
the brain wide level or at least cortical wide level.

405
00:37:18,200 --> 00:37:25,480
So I would say that that would be sort of one direction that we're going towards and

406
00:37:25,480 --> 00:37:31,000
trying to also sort of utilize maybe these methods to look at connectivity that you

407
00:37:31,000 --> 00:37:39,920
asked me before, a bit more directly if possible, as well as try to implement these methods

408
00:37:39,920 --> 00:37:46,120
in functional data, as I said, that are collected by methods that look at activity of neurons

409
00:37:46,120 --> 00:37:47,280
in vivo.

410
00:37:47,280 --> 00:37:49,360
So in the live sort of animal.

411
00:37:49,360 --> 00:37:54,440
Well Theo, thanks so much for taking the time to share a bit of what you're working

412
00:37:54,440 --> 00:37:55,440
on.

413
00:37:55,440 --> 00:37:57,240
It has been a pleasure.

414
00:37:57,240 --> 00:37:58,240
Thank you.

415
00:37:58,240 --> 00:37:59,240
Thank you very much for the opportunity.

416
00:37:59,240 --> 00:38:01,720
Awesome, thank you.

417
00:38:01,720 --> 00:38:07,440
All right, everyone, that's our show for today.

418
00:38:07,440 --> 00:38:13,440
For more information on today's show, visit twomolai.com slash shows.

419
00:38:13,440 --> 00:38:19,280
Make sure you head over to twomolcon.com to learn more about the Twomolcon AI Platforms

420
00:38:19,280 --> 00:38:20,760
Conference.

421
00:38:20,760 --> 00:38:30,760
As always, thanks so much for listening and catch you next time.

