1
00:00:00,000 --> 00:00:13,120
Welcome to the Twimal AI Podcast.

2
00:00:13,120 --> 00:00:17,120
I'm your host Sam Charrington.

3
00:00:17,120 --> 00:00:26,600
Hey, what is up, good Twimal people?

4
00:00:26,600 --> 00:00:32,520
As many, if not most of us past the 100 day mark of shelter in place, work from home

5
00:00:32,520 --> 00:00:37,960
and other quarantine measures, I want to both extend to you my best wishes for your health

6
00:00:37,960 --> 00:00:43,160
and happiness and also to remind you to not let your guard down.

7
00:00:43,160 --> 00:00:49,200
COVID-19 is serious business and you don't want to get it or give it.

8
00:00:49,200 --> 00:00:54,400
Be sure to wear that mask when you'll be around other people, avoid indoor crowds and

9
00:00:54,400 --> 00:00:59,280
limit your exposure by minimizing the time and maximizing the distance when you're

10
00:00:59,280 --> 00:01:03,960
in contact with others.

11
00:01:03,960 --> 00:01:10,120
Before we jump into today's show from our CVPR series, I'd like to share a few quick details

12
00:01:10,120 --> 00:01:16,200
about the next great event in our continuing live discussion series.

13
00:01:16,200 --> 00:01:23,440
Join us on Wednesday, July 1st for the great machine learning language undubate as we explore

14
00:01:23,440 --> 00:01:29,480
the strengths, weaknesses and approaches of both popular and emerging programming languages

15
00:01:29,480 --> 00:01:31,400
for machine learning.

16
00:01:31,400 --> 00:01:38,400
We'll have great speakers representing Python, R, Swift, Closure, Scala, Julia and more.

17
00:01:38,400 --> 00:01:43,800
The session kicks off at 11 a.m. Pacific time on the first and you won't want to miss

18
00:01:43,800 --> 00:01:50,640
it, so head over to twimalai.com slash languages to get registered.

19
00:01:50,640 --> 00:01:56,000
At this point, I'd like to send a huge thank you to our friends at Qualcomm for their support

20
00:01:56,000 --> 00:02:01,400
of this podcast and their sponsorship of our CVPR series.

21
00:02:01,400 --> 00:02:07,760
Qualcomm AI research is dedicated to advancing AI to make its core capabilities, perception,

22
00:02:07,760 --> 00:02:11,920
reasoning and action ubiquitous across devices.

23
00:02:11,920 --> 00:02:16,200
Their work makes it possible for billions of users around the world to have AI enhanced

24
00:02:16,200 --> 00:02:20,600
experiences on Qualcomm technology's powered devices.

25
00:02:20,600 --> 00:02:26,440
To learn more about Qualcomm and what they're up to on the AI research front, visit twimalai.com

26
00:02:26,440 --> 00:02:29,160
slash Qualcomm.

27
00:02:29,160 --> 00:02:31,360
And now onto the show.

28
00:02:31,360 --> 00:02:33,200
All right, everyone.

29
00:02:33,200 --> 00:02:35,240
I am here with Pavan Taraga.

30
00:02:35,240 --> 00:02:41,720
Pavan is jointly appointed in the schools of electrical engineering and arts media and

31
00:02:41,720 --> 00:02:45,000
engineering at Arizona State University.

32
00:02:45,000 --> 00:02:47,520
Pavan, welcome to the Twimal AI podcast.

33
00:02:47,520 --> 00:02:48,520
Thank you, Sam.

34
00:02:48,520 --> 00:02:49,520
It's a pleasure and an honor to be here.

35
00:02:49,520 --> 00:02:50,520
Thank you.

36
00:02:50,520 --> 00:02:52,760
It's my pleasure to host you here.

37
00:02:52,760 --> 00:02:58,800
I'm looking forward to digging into your paper that will be presented at CVPR, revisiting

38
00:02:58,800 --> 00:03:02,040
invariance with geometry and deep learning.

39
00:03:02,040 --> 00:03:05,760
But before we do that, I'd love for you to share a little bit about your background and

40
00:03:05,760 --> 00:03:10,840
how you came to work in computer vision and ML sounds great.

41
00:03:10,840 --> 00:03:18,160
So my beginnings in this area started as, you know, as a senior in my undergraduate years.

42
00:03:18,160 --> 00:03:23,320
I was looking at problems like face recognition, face tracking from video, trying to do a senior

43
00:03:23,320 --> 00:03:25,280
design project really.

44
00:03:25,280 --> 00:03:31,040
And as I started digging more, this was in the early or, yeah, early 2000s.

45
00:03:31,040 --> 00:03:36,440
And it was a very exciting time to be in the field of computer vision, because the problem

46
00:03:36,440 --> 00:03:42,680
statement in those days would be presented as giving a computer the ability to see and

47
00:03:42,680 --> 00:03:46,640
that felt like, wow, that's a frontier topic, right?

48
00:03:46,640 --> 00:03:52,240
But I said, you know, looks like I'm sufficiently invested in this, looks like it intersects with

49
00:03:52,240 --> 00:03:57,040
things like neuroscience, perception that is interesting mathematics, that is interesting

50
00:03:57,040 --> 00:04:00,320
computing happening, very highly interdisciplinary.

51
00:04:00,320 --> 00:04:03,360
And it felt like there was much work to be done.

52
00:04:03,360 --> 00:04:09,640
So I decided to go to school in 2000, I mean, grad school in 2004 to the University of

53
00:04:09,640 --> 00:04:16,080
Maryland, studying with Professor Ramachalappa, who is a pioneer in this field and very well

54
00:04:16,080 --> 00:04:21,080
known for face recognition techniques and a lot of interesting things in vision at the

55
00:04:21,080 --> 00:04:22,080
time.

56
00:04:22,080 --> 00:04:28,000
And as I started my work in the lab, I brought in from just face recognition to other things

57
00:04:28,000 --> 00:04:34,240
like understanding video, understanding time series, understanding the role of light,

58
00:04:34,240 --> 00:04:40,000
you know, geometry, elimination, reflectance, all these physics based concepts and how

59
00:04:40,000 --> 00:04:46,160
the interface with pattern recognition methods or machine learning methods and as I went deeper

60
00:04:46,160 --> 00:04:52,280
and deeper into it, I felt like there was a big disconnect between the methods of physics

61
00:04:52,280 --> 00:04:58,520
of image formation and the methods that are used in machine learning, where it's just

62
00:04:58,520 --> 00:05:03,960
purely a driven and statistical techniques and I was trying to find some middle ground

63
00:05:03,960 --> 00:05:08,360
where I could inject physical knowledge into certain structures that could blend well

64
00:05:08,360 --> 00:05:13,080
with machine learning techniques and one thing led to another, I started getting interested

65
00:05:13,080 --> 00:05:19,520
in this area of mathematics called a Romanian geometry and then topology as a means to express

66
00:05:19,520 --> 00:05:23,440
these intuitions and these constraints from physics and interface them with machine learning

67
00:05:23,440 --> 00:05:25,640
in before deep learning.

68
00:05:25,640 --> 00:05:31,120
So that's the theme of my work over the past decade, which is try to understand basic phenomena

69
00:05:31,120 --> 00:05:38,120
whether it's, you know, images or video or human activity and in recent years, we've also

70
00:05:38,120 --> 00:05:43,160
brought in our investigation beyond computer vision to include things like wearable devices

71
00:05:43,160 --> 00:05:49,200
and physiological monitoring where the phenomenon under study is basic human movement and other

72
00:05:49,200 --> 00:05:56,080
things, try to understand it from first principles and try to express that knowledge in a way

73
00:05:56,080 --> 00:06:01,200
that constrains conditions machine learning, so that's the general intersection of topics

74
00:06:01,200 --> 00:06:02,200
I've been looking at.

75
00:06:02,200 --> 00:06:07,320
Okay, and I mentioned in introducing you that one of your appointments is with a school

76
00:06:07,320 --> 00:06:13,320
that has arts in the title, are you, you know, how does that come up in your work and

77
00:06:13,320 --> 00:06:14,320
research?

78
00:06:14,320 --> 00:06:20,280
So, particularly, you know, connected to that particular piece of that school.

79
00:06:20,280 --> 00:06:25,920
So that's a whole story by itself and I can go very organically about how it all began

80
00:06:25,920 --> 00:06:33,920
or I can go in hindsight, this is how it went organically, this is how it began, you

81
00:06:33,920 --> 00:06:40,160
know, our school was founded in 2009 and, you know, I graduated from grad school in 2009,

82
00:06:40,160 --> 00:06:46,000
but then that was 2009, very similar to 2020, Wall Street collapsing and getting loose.

83
00:06:46,000 --> 00:06:51,640
So I stayed back when I posed out for a couple years and when I went interviewing in 2011,

84
00:06:51,640 --> 00:06:56,840
this position opened up in this school under the title of Assistant Professor in Human

85
00:06:56,840 --> 00:07:03,640
Activity Analysis, it was very intriguing and I have been doing human activity analysis

86
00:07:03,640 --> 00:07:08,200
as far as, you know, understanding video-based gate analysis.

87
00:07:08,200 --> 00:07:13,880
Okay, so I'm like fitness trackers and quantified self and all that kind of stuff.

88
00:07:13,880 --> 00:07:18,160
Right, so this was a little before all that stuff happened in particular.

89
00:07:18,160 --> 00:07:23,000
And I came in and I visited and there was, there was a mind-boggling sense of interdisciplinary

90
00:07:23,000 --> 00:07:28,440
that I saw in the school people in music looking at stuff like that, right, accelerometers,

91
00:07:28,440 --> 00:07:31,560
variables, driving, interactive performance with it.

92
00:07:31,560 --> 00:07:36,440
There was a group doing a stroke rehabilitation where you attract human movement through

93
00:07:36,440 --> 00:07:40,560
motion capture and sonify the qualities of your movement.

94
00:07:40,560 --> 00:07:46,800
So smoothness or jerkiness would be converted to sound and you can hear yourself and that

95
00:07:46,800 --> 00:07:49,960
provided additional feedback for you to correct your movements.

96
00:07:49,960 --> 00:07:50,960
Oh wow.

97
00:07:50,960 --> 00:07:56,800
It was, yeah, it was a very mind-boggling experience and even now people find it very

98
00:07:56,800 --> 00:07:59,360
interviewing when I mentioned these things.

99
00:07:59,360 --> 00:08:05,600
So the human activity analysis component was a way for the school to address, you know,

100
00:08:05,600 --> 00:08:09,800
slightly more formal ways to think about human movement, whether it's sense from a camera,

101
00:08:09,800 --> 00:08:13,760
whether it's sense from a variable device, whether it's motion capture, try to come up

102
00:08:13,760 --> 00:08:19,080
with techniques to represent human movement and then do machine learning on it or feed

103
00:08:19,080 --> 00:08:20,360
into these other applications.

104
00:08:20,360 --> 00:08:25,480
And it seemed like I was the right fit at the time and I got a job and I've been here

105
00:08:25,480 --> 00:08:31,040
for eight years and it has led me into very interesting collaborations with media artists

106
00:08:31,040 --> 00:08:37,080
and health scientists who are interested in the intersection of computing, art and things

107
00:08:37,080 --> 00:08:38,280
like health promotion.

108
00:08:38,280 --> 00:08:41,120
So that's the other side.

109
00:08:41,120 --> 00:08:49,600
You mentioned that one of the big themes of your work is been integrating physical, physics

110
00:08:49,600 --> 00:08:53,400
space principles and computer vision.

111
00:08:53,400 --> 00:09:00,160
Can you maybe talk a little bit about that in the broader context of the computer vision

112
00:09:00,160 --> 00:09:01,160
landscape?

113
00:09:01,160 --> 00:09:05,600
We've talked about this quite a bit on the podcast and I kind of describe it as a pendulum

114
00:09:05,600 --> 00:09:09,760
that's kind of swung from physics-based models to statistical and kind of is settling

115
00:09:09,760 --> 00:09:10,760
somewhere in the middle now.

116
00:09:10,760 --> 00:09:14,680
But it sounds like you've been working at this for a while, I'm curious how you think

117
00:09:14,680 --> 00:09:15,680
of it.

118
00:09:15,680 --> 00:09:16,680
Yes.

119
00:09:16,680 --> 00:09:17,680
I mean, you're absolutely right.

120
00:09:17,680 --> 00:09:21,320
It's been a pendulum that keeps swinging and I don't think it settles anywhere.

121
00:09:21,320 --> 00:09:26,000
I mean, that's the interesting problem about computer vision.

122
00:09:26,000 --> 00:09:30,080
Every time someone thinks it settles, right?

123
00:09:30,080 --> 00:09:33,160
Everybody thinks it's settled now and then soon it ships.

124
00:09:33,160 --> 00:09:37,960
So I mean, yes, it's been going on and off this idea about, I mean, I'd like to think

125
00:09:37,960 --> 00:09:45,120
of it as model-based vision versus purely data-driven methods of thinking of vision.

126
00:09:45,120 --> 00:09:50,520
The way the pendulum swings in my opinion is not that the problems are changing.

127
00:09:50,520 --> 00:09:56,360
It's just the language that goes into talking about it and the tools that go into addressing

128
00:09:56,360 --> 00:09:57,360
it.

129
00:09:57,360 --> 00:10:02,240
Those keep shifting, but the problems have remained mostly the same and the problems

130
00:10:02,240 --> 00:10:05,080
are the following in my opinion.

131
00:10:05,080 --> 00:10:11,040
So vision is a very unique, some people think of it as an application of machine learning,

132
00:10:11,040 --> 00:10:13,920
which is a reductionistic way to think about it.

133
00:10:13,920 --> 00:10:18,040
Sure, everything is data and everything is fed into a model and outcomes of decision.

134
00:10:18,040 --> 00:10:25,120
But vision and any perceptual field of inquiry, that can include vision, sound, haptics,

135
00:10:25,120 --> 00:10:29,760
any of these things which have to do with perception, I feel are fundamentally different

136
00:10:29,760 --> 00:10:33,360
than any other application of data analysis.

137
00:10:33,360 --> 00:10:40,320
The way we perceive the world is not the way, let's say, back transactions are processed

138
00:10:40,320 --> 00:10:43,480
by a machine learning computer, machine learning technique.

139
00:10:43,480 --> 00:10:49,520
There is a huge amount of variability is the way I'd call it, that exhibits in the

140
00:10:49,520 --> 00:10:57,720
natural world, which is somehow either discarded or properly passed out by whatever is happening

141
00:10:57,720 --> 00:11:04,000
in our brains and the sources of variability are physics based to a large extent.

142
00:11:04,000 --> 00:11:07,400
The same picture under a different lighting condition looks different, the same picture

143
00:11:07,400 --> 00:11:11,920
under a different slightly changed viewpoint looks different.

144
00:11:11,920 --> 00:11:17,800
So that looking different part is what gives rise to statistical variability.

145
00:11:17,800 --> 00:11:22,160
The statistical ways of thinking are, well, let's just fill up the observation space

146
00:11:22,160 --> 00:11:26,520
with more data points and we'll figure out what the shape of the distribution is from

147
00:11:26,520 --> 00:11:34,120
data, which is okay in, as intense to infinity, I guess that's fine, but when data augmentation

148
00:11:34,120 --> 00:11:38,240
approaches and domain adaptation and that kind of thing, yeah, yeah.

149
00:11:38,240 --> 00:11:43,680
But under and not tend to infinity, if you only have a few data samples, you are better

150
00:11:43,680 --> 00:11:50,360
off trying to understand how the physics around you affects the observed imagery.

151
00:11:50,360 --> 00:11:53,760
And that's where I think the methods have shifted.

152
00:11:53,760 --> 00:11:58,720
So in the keynote that I have at CBPR, you know, at the workshop called differential geometry

153
00:11:58,720 --> 00:12:02,280
and computer vision, I go through some of these historical trends.

154
00:12:02,280 --> 00:12:06,840
And one of the core themes that brings it all together, the word that I use is called

155
00:12:06,840 --> 00:12:12,400
invariance, which is when you look around and try to classify objects, we are able to

156
00:12:12,400 --> 00:12:16,920
do this in a way that is invariant to a lot of nuisance variables.

157
00:12:16,920 --> 00:12:22,400
That is light, you know, shading viewpoint and all sorts of interesting effects that are

158
00:12:22,400 --> 00:12:23,800
hard to describe.

159
00:12:23,800 --> 00:12:28,040
When you say invariance, there's two ways to think about it.

160
00:12:28,040 --> 00:12:33,160
The physics-based ways to think about it are, let's say I am looking at this scene, I

161
00:12:33,160 --> 00:12:37,720
know everything about this scene, including its 3D geometry, including how the paint reflects

162
00:12:37,720 --> 00:12:41,480
off light, including the wavelengths in the incoming radiation.

163
00:12:41,480 --> 00:12:47,360
If I have full knowledge of all of this, then I can re-render a scene, let's say.

164
00:12:47,360 --> 00:12:53,560
I can, just like how it happens in graphics, I can create so many different versions of

165
00:12:53,560 --> 00:12:54,560
the same picture.

166
00:12:54,560 --> 00:12:58,960
If I had full knowledge of everything, simply through a forward rendering process and

167
00:12:58,960 --> 00:13:04,320
construct variability, the data-driven ways of thinking about it say if you don't have

168
00:13:04,320 --> 00:13:08,760
access to everything that you need to understand the phenomena, what is the minimal set, what

169
00:13:08,760 --> 00:13:13,240
is the minimal piece of information that is needed to get a job done.

170
00:13:13,240 --> 00:13:18,360
And that's the dichotomy in the physics-based ways of thinking and the statistical ways

171
00:13:18,360 --> 00:13:19,600
of thinking.

172
00:13:19,600 --> 00:13:27,520
So when you use this term, invariant is the invariant referring to, say we're talking

173
00:13:27,520 --> 00:13:31,120
about a scene with an object in it that might render differently in different lighting

174
00:13:31,120 --> 00:13:32,120
conditions, etc.

175
00:13:32,120 --> 00:13:38,840
Is the invariant that object that is definitively in the scene and then we've got all these

176
00:13:38,840 --> 00:13:44,400
other effects, or does the invariant refer to something else, maybe something more on

177
00:13:44,400 --> 00:13:47,360
the mathematical from a mathematical perspective?

178
00:13:47,360 --> 00:13:51,400
I mean, the word invariant, of course, will depend upon what the end task is.

179
00:13:51,400 --> 00:13:57,640
If it is object recognition, yes, something intrinsic to the object is the invariant.

180
00:13:57,640 --> 00:14:02,880
It is not always as simple as saying the invariant is the color of the object because that changes.

181
00:14:02,880 --> 00:14:08,200
It is often not same as saying the invariant is the edge map of the object or certain corners

182
00:14:08,200 --> 00:14:11,280
of the object because they go in and out of view.

183
00:14:11,280 --> 00:14:16,200
So there's not easy ways of describing what that invariant actually physically means.

184
00:14:16,200 --> 00:14:18,000
So it becomes mathematical at some level.

185
00:14:18,000 --> 00:14:21,520
There is no linguistic equivalent that I can come up with.

186
00:14:21,520 --> 00:14:26,720
But if you look at this rendering ways of thinking, if you can render this object that you

187
00:14:26,720 --> 00:14:30,960
are interested to recognize, in all possible wing conditions, all possible lighting conditions,

188
00:14:30,960 --> 00:14:36,920
and you have this huge set of pictures, that huge set of pictures could be called, you

189
00:14:36,920 --> 00:14:42,840
know, the word sometimes that gets used is equivalent class or sometimes they call it an

190
00:14:42,840 --> 00:14:43,840
orbit.

191
00:14:43,840 --> 00:14:49,720
So this object that you're trying to recognize manifests itself in all this different ways.

192
00:14:49,720 --> 00:14:52,960
If you have a handle on that set, you are in good shape.

193
00:14:52,960 --> 00:14:56,680
If you have a different object, and you place it in the same scene, and you render it in

194
00:14:56,680 --> 00:15:02,120
all these different variations, and you have its own different set, then the invariant

195
00:15:02,120 --> 00:15:09,840
that separates these two is some measure of difference between these two sets of pictures.

196
00:15:09,840 --> 00:15:14,800
And sometimes that set of pictures can have a nice structure, which can allow you to

197
00:15:14,800 --> 00:15:18,280
compute it in closed form, and sometimes not.

198
00:15:18,280 --> 00:15:24,720
So the way we have been trying to express, you know, sometimes illumination is complicated.

199
00:15:24,720 --> 00:15:31,280
And if in the most general case, we don't know how to describe this full set of pictures.

200
00:15:31,280 --> 00:15:36,880
And some simplifying assumptions, which is rooted in some old work from the 90s, Bell

201
00:15:36,880 --> 00:15:41,240
Humor and Krigman wrote a very famous paper, and they said, what is the set of all faces

202
00:15:41,240 --> 00:15:43,920
under any given illumination condition?

203
00:15:43,920 --> 00:15:46,640
And they made some simplifying assumptions of what a face is.

204
00:15:46,640 --> 00:15:51,160
I mean, if I ask you define a face, it's probably defined a face, right?

205
00:15:51,160 --> 00:15:52,160
So how do you even think?

206
00:15:52,160 --> 00:15:57,160
And this is why we've tended towards, you know, deep learning and statistic methods over

207
00:15:57,160 --> 00:16:00,360
the past few years, because we don't know how to define these things.

208
00:16:00,360 --> 00:16:02,320
So exactly.

209
00:16:02,320 --> 00:16:03,640
But here is what they found.

210
00:16:03,640 --> 00:16:08,760
They said, if you define it in some sub linguistic ways, let's say it's a convex object, and

211
00:16:08,760 --> 00:16:13,960
let's say it's an object which has reflectance defined by some lambershine properties, then

212
00:16:13,960 --> 00:16:16,400
you can actually write down what the set looks like.

213
00:16:16,400 --> 00:16:17,880
Now comes deep learning.

214
00:16:17,880 --> 00:16:20,880
It says, I can't define these things, give me data.

215
00:16:20,880 --> 00:16:23,040
And the more data you have, the better it is.

216
00:16:23,040 --> 00:16:24,920
But no one knows how much data is enough, right?

217
00:16:24,920 --> 00:16:30,000
I mean, the more is better is the answer, but how much is enough is never known.

218
00:16:30,000 --> 00:16:33,280
And we have been positioning ourselves at that intersection, where we still look.

219
00:16:33,280 --> 00:16:38,000
If I know that I'm looking at faces, I'm going to weaken the structure a little bit.

220
00:16:38,000 --> 00:16:43,840
I'm going to say that, yeah, these objects that we're looking at have some characterization

221
00:16:43,840 --> 00:16:48,080
under these assumptions of simplicity, but then comes deep learning, which allows me

222
00:16:48,080 --> 00:16:52,320
to fit those other degrees, which I'm not able to specify analytically.

223
00:16:52,320 --> 00:16:57,000
So we're trying to reduce the need for larger and larger training sets by restricting the

224
00:16:57,000 --> 00:17:01,760
deep net layer somehow that are motivated by the knowledge of that physics of image

225
00:17:01,760 --> 00:17:02,760
formation.

226
00:17:02,760 --> 00:17:10,600
Sure, we don't know how much data we need to get the full specification, but we're saying

227
00:17:10,600 --> 00:17:13,880
this will reduce the need for more and more data.

228
00:17:13,880 --> 00:17:18,640
And all things being the same with the same amount of training sets, the same complexity

229
00:17:18,640 --> 00:17:23,760
of the deep architecture, adding these constraints known from the physics of image formation

230
00:17:23,760 --> 00:17:25,720
improves performance.

231
00:17:25,720 --> 00:17:30,680
And it also stabilizes performance against degradation of inputs.

232
00:17:30,680 --> 00:17:34,600
You know, typically if you blur a picture, if you surrender a picture in slightly different

233
00:17:34,600 --> 00:17:38,760
ways, performance drops pretty dramatically, we are able to avoid that.

234
00:17:38,760 --> 00:17:40,320
It's a middle ground, I'd say.

235
00:17:40,320 --> 00:17:47,160
We are not being super specific about defining objects, nor are we saying more data is good.

236
00:17:47,160 --> 00:17:52,160
We are saying something in the middle that is we are trying to come up with some description

237
00:17:52,160 --> 00:17:57,160
of that equivalence class under simplifying assumptions and then let data fill in the

238
00:17:57,160 --> 00:17:58,160
rest.

239
00:17:58,160 --> 00:18:01,240
So that's the way we're trying to marry the two things.

240
00:18:01,240 --> 00:18:08,000
And is the result a mathematical analysis in closed form, or is it experimental results

241
00:18:08,000 --> 00:18:10,000
on data sets?

242
00:18:10,000 --> 00:18:11,000
It both.

243
00:18:11,000 --> 00:18:12,000
Okay.

244
00:18:12,000 --> 00:18:16,920
So, I mean, most of the things we do is we end up having constraints, which are closed

245
00:18:16,920 --> 00:18:19,320
for mathematical equations.

246
00:18:19,320 --> 00:18:23,720
Maybe one layer in the deep net is expected to be orthonormal because the physics of image

247
00:18:23,720 --> 00:18:28,680
formation says that certain variables under certain lighting conditions will have an

248
00:18:28,680 --> 00:18:29,680
orthonormal structure.

249
00:18:29,680 --> 00:18:33,760
Okay, that's the way we impose the constraint that certain layers might have an orthonormal

250
00:18:33,760 --> 00:18:35,640
constraint put in.

251
00:18:35,640 --> 00:18:40,760
But then the network itself has to be learned end to end with data sets.

252
00:18:40,760 --> 00:18:45,400
And the performance has to be validated empirically on data sets.

253
00:18:45,400 --> 00:18:49,920
One of the interesting things we found is this concept of orthonormality, which seems

254
00:18:49,920 --> 00:18:52,200
to have some very special power.

255
00:18:52,200 --> 00:18:55,560
What we're finding is whether, you know, think of it.

256
00:18:55,560 --> 00:19:02,360
So we played with this idea in a paper for BMVC last year, where we took some classic,

257
00:19:02,360 --> 00:19:06,520
you know, disentangling autoencoder kind of networks.

258
00:19:06,520 --> 00:19:13,760
And we had good reason to impose an orthonormality constraint on the latent blocks of these disentangling

259
00:19:13,760 --> 00:19:15,440
autoencoders.

260
00:19:15,440 --> 00:19:16,440
Why orthonormality?

261
00:19:16,440 --> 00:19:22,600
We had to write up a whole, you know, theory around we expect these factors to represent

262
00:19:22,600 --> 00:19:29,840
either movement or lighting conditions or deformations and under appropriate relaxations.

263
00:19:29,840 --> 00:19:34,840
They all become orthogonal to each other and they all have this spherical structures.

264
00:19:34,840 --> 00:19:40,000
So looking at all of this, it looks like orthonormality is a trade-off, which is coming close

265
00:19:40,000 --> 00:19:45,240
to what the physics is telling us to do and but also being sensitive to the idea that

266
00:19:45,240 --> 00:19:46,960
it has to be implemented easily.

267
00:19:46,960 --> 00:19:52,440
We don't want to over complicate things and we want our constraints to be differentiable.

268
00:19:52,440 --> 00:19:54,440
So it's a design process.

269
00:19:54,440 --> 00:19:58,800
So we threw in these orthonormality constraints on disentangling autoencoders and boom, the

270
00:19:58,800 --> 00:20:03,400
numbers of disentangling quality just went up quite significantly.

271
00:20:03,400 --> 00:20:07,000
And so in the case of an autoencoder or in the layer of a deep network, what does it

272
00:20:07,000 --> 00:20:11,280
mean to impose that kind of constraint?

273
00:20:11,280 --> 00:20:19,680
Is it architectural and does it mean that you're diverging from kind of your CNN, resonant

274
00:20:19,680 --> 00:20:24,800
kind of tried-and-true architectures or is it loss function based or something totally

275
00:20:24,800 --> 00:20:25,800
different?

276
00:20:25,800 --> 00:20:27,560
How do you impose those constraints?

277
00:20:27,560 --> 00:20:30,440
There's two or three ways in which it's happened.

278
00:20:30,440 --> 00:20:34,480
One is we stick with architectures as is, don't mess with architectures, but add-and-loss

279
00:20:34,480 --> 00:20:35,480
functions.

280
00:20:35,480 --> 00:20:41,560
That works when the constraints are actually expressable as a closed form equation like

281
00:20:41,560 --> 00:20:47,600
spherical losses or, you know, orthonormality, those can be written on as a closed form equation.

282
00:20:47,600 --> 00:20:51,640
Sometimes the constraints we arrive at do not have an equation, but they have what is

283
00:20:51,640 --> 00:20:54,040
called a manifold structure.

284
00:20:54,040 --> 00:20:59,000
And why manifolds arise is very closely related to invariance.

285
00:20:59,000 --> 00:21:03,960
Here is an example, you know, if I say, so the idea of invariance is this, right, I mean

286
00:21:03,960 --> 00:21:04,960
you have a feature space.

287
00:21:04,960 --> 00:21:07,040
Let's say the feature space is something.

288
00:21:07,040 --> 00:21:11,960
You have this feature space in Rn and it's more specific than something, so it's easier

289
00:21:11,960 --> 00:21:12,960
to follow.

290
00:21:12,960 --> 00:21:19,560
So, let's say it's the latent space of AlexNet, okay, some features from the latent

291
00:21:19,560 --> 00:21:24,760
space of AlexNet, which is embedded in Rn, right, so it's a vector in Rn.

292
00:21:24,760 --> 00:21:29,600
And then we come in and we say, look, I want to impose a slight equivalence here, which

293
00:21:29,600 --> 00:21:33,800
is if I rotate my picture, looks like the features are also changing somehow.

294
00:21:33,800 --> 00:21:38,200
I mean, the features are not always invariant to physical variables like this, right?

295
00:21:38,200 --> 00:21:42,600
But if you're able to say that this feature, this feature, this feature in Rn actually

296
00:21:42,600 --> 00:21:45,760
represent the same picture, just that they're rotated.

297
00:21:45,760 --> 00:21:52,200
We are trying to basically paste the features and thereby the underlying space into something

298
00:21:52,200 --> 00:21:55,840
else to express that concept of equivalence.

299
00:21:55,840 --> 00:22:01,240
And sometimes when that ways of expressing these equivalences is well defined, what happens

300
00:22:01,240 --> 00:22:06,200
is the space gets crumpled, you hope that the neural net learns to crumple the space

301
00:22:06,200 --> 00:22:07,200
all of its own.

302
00:22:07,200 --> 00:22:12,080
That is one of the overarching hopes in deep learning that as you go through the layers

303
00:22:12,080 --> 00:22:17,320
of deep learning, the deep learning is learning to squish and crumple the original feature space

304
00:22:17,320 --> 00:22:20,840
into interesting ways to get a job done.

305
00:22:20,840 --> 00:22:25,440
But what it's doing is it's not always getting the job done the right way because you never

306
00:22:25,440 --> 00:22:26,440
have enough data.

307
00:22:26,440 --> 00:22:30,800
But if I explicitly tell it that here is how rotation affects the features.

308
00:22:30,800 --> 00:22:34,680
And here is how you paste them together through whatever mathematics that's needed.

309
00:22:34,680 --> 00:22:39,360
Then we get some manifold structures, you know, this crumpling can sometimes be expressed

310
00:22:39,360 --> 00:22:41,120
as a manifold.

311
00:22:41,120 --> 00:22:46,680
If you want to say in the concept of, you know, in the paradigm of loss functions, how

312
00:22:46,680 --> 00:22:49,000
do you express a manifold as a loss function?

313
00:22:49,000 --> 00:22:50,960
Sometimes you cannot.

314
00:22:50,960 --> 00:22:58,480
What you can do instead is, you know, manifolds are basically crumpled spaces and they have

315
00:22:58,480 --> 00:23:04,480
ideas associated with them, which are analogous to how we think of maps.

316
00:23:04,480 --> 00:23:09,480
And you know, the earth itself is composed of the earth is a manifold, but then it's also

317
00:23:09,480 --> 00:23:10,480
a sphere approximately.

318
00:23:10,480 --> 00:23:16,320
So if you forget the idea that it's a sphere, but if it were a general weirdly shaped blob,

319
00:23:16,320 --> 00:23:22,320
you would represent it by a series of charts and you would explain how the charts connect.

320
00:23:22,320 --> 00:23:26,080
And that's the way you specify a manifold through things called charts.

321
00:23:26,080 --> 00:23:31,480
And charts are also sometimes, you know, they have a thing, which is similar, called tangent

322
00:23:31,480 --> 00:23:32,480
spaces.

323
00:23:32,480 --> 00:23:37,680
So you sort of flatten the manifold in local coordinate charts and you can express that

324
00:23:37,680 --> 00:23:40,920
tangent space as a vector space.

325
00:23:40,920 --> 00:23:45,760
So once in a while, we have run into these conditions where we have a constraint, which was

326
00:23:45,760 --> 00:23:50,520
expressed as a manifold, which could not be written down as an equation, but whose tangent

327
00:23:50,520 --> 00:23:52,280
space could be written down.

328
00:23:52,280 --> 00:23:58,360
So we were able to enforce conditions of that tangency and said, I want this layer in

329
00:23:58,360 --> 00:24:03,840
my deep net to represent coordinates of a manifold on a specific tangent space.

330
00:24:03,840 --> 00:24:07,120
And the mapping from that back to the manifold could be written down in closed form.

331
00:24:07,120 --> 00:24:08,120
So it depends.

332
00:24:08,120 --> 00:24:16,200
Let me see if I can upload this anywhere close to what you just said.

333
00:24:16,200 --> 00:24:20,360
The way I'm kind of hearing this is that you've got some problem, you know, say you've

334
00:24:20,360 --> 00:24:27,160
got some object and you apply some simple transformation to that object, maybe you rotate

335
00:24:27,160 --> 00:24:28,160
it.

336
00:24:28,160 --> 00:24:35,280
If you've got a deep neural network that is trying to detect that object, for example,

337
00:24:35,280 --> 00:24:42,160
you know, and you've trained it, there may be some feature space or some representation

338
00:24:42,160 --> 00:24:48,760
of that object in, you know, the different layers of the neural net in a oversimplified

339
00:24:48,760 --> 00:24:49,760
world.

340
00:24:49,760 --> 00:24:54,720
You'd kind of want there to be, you know, a relationship between the rotation of the

341
00:24:54,720 --> 00:24:59,280
object itself and the rotation of the features, like maybe you could apply some simple transformation

342
00:24:59,280 --> 00:25:04,160
of the features, but the world isn't, you know, networks aren't that simple.

343
00:25:04,160 --> 00:25:06,880
But it turns out there is a relationship between the features.

344
00:25:06,880 --> 00:25:11,040
It's just more like this crumbly manifold thing.

345
00:25:11,040 --> 00:25:17,360
And you found a way to, you know, express that using the mathematical language of these

346
00:25:17,360 --> 00:25:23,600
manifolds that allow you to detect the actual invariance of the object.

347
00:25:23,600 --> 00:25:25,600
That is very correct.

348
00:25:25,600 --> 00:25:32,560
Thank you for giving me those lines.

349
00:25:32,560 --> 00:25:39,080
The only disclaimer is we have been able to do this for a few common sources of physical

350
00:25:39,080 --> 00:25:40,080
variability.

351
00:25:40,080 --> 00:25:46,560
And that includes things like rotations of objects and deformations of moving parts in

352
00:25:46,560 --> 00:25:52,120
certain cases, lighting conditions under, you know, just to be very clear.

353
00:25:52,120 --> 00:25:55,560
We haven't been able to do this across the board for every possible thing.

354
00:25:55,560 --> 00:25:56,560
Right.

355
00:25:56,560 --> 00:25:57,560
Right.

356
00:25:57,560 --> 00:26:03,600
So simple, like, you know, maybe not three point studio lighting, but a simple, you know,

357
00:26:03,600 --> 00:26:05,800
radio rotation or something like that.

358
00:26:05,800 --> 00:26:10,040
But, you know, clearly there's lots of things you can do in the physical world that aren't

359
00:26:10,040 --> 00:26:12,840
amenable to that representation.

360
00:26:12,840 --> 00:26:13,840
Absolutely.

361
00:26:13,840 --> 00:26:14,840
Yes.

362
00:26:14,840 --> 00:26:15,840
Okay.

363
00:26:15,840 --> 00:26:22,520
And so one of the things that that comes to mind in thinking about this and in your work,

364
00:26:22,520 --> 00:26:30,520
you kind of fall back on or maybe ground yourself in, you know, what you call pragmatic

365
00:26:30,520 --> 00:26:35,160
choices of deep architectures, meaning kind of the popular stuff, the way we're doing

366
00:26:35,160 --> 00:26:37,120
things today.

367
00:26:37,120 --> 00:26:43,560
I think of like Jeff Hinton's capsule networks is trying to come at some of the same ideas

368
00:26:43,560 --> 00:26:49,360
or same problems, are you familiar with that work and you compare contrast?

369
00:26:49,360 --> 00:26:52,360
I mean, we've tracked that body of work also.

370
00:26:52,360 --> 00:26:58,440
Again, you know, he's with all due respect, ACM Turing about, you know, I can't do that

371
00:26:58,440 --> 00:27:03,040
easily, but it's an over complication.

372
00:27:03,040 --> 00:27:11,080
I mean, it's ignoring, it's ignoring so much, it's ignoring the basic laws of, you know,

373
00:27:11,080 --> 00:27:15,560
rotations are not that hard if you understand how to express rotations and we're taking

374
00:27:15,560 --> 00:27:21,080
out that invariances is doable without that level of combination.

375
00:27:21,080 --> 00:27:25,040
So I'm correct that you're trying to come at some of the same problems at least.

376
00:27:25,040 --> 00:27:26,040
Right.

377
00:27:26,040 --> 00:27:27,040
Okay.

378
00:27:27,040 --> 00:27:32,320
In, it may be the case that if that enterprise succeeds, if that capsule network enterprise

379
00:27:32,320 --> 00:27:41,040
succeeds, it may be a more general solution to everything, maybe, but if you want

380
00:27:41,040 --> 00:27:47,120
to be a bit specific about, you know, understood factors of variation, I feel that's an over complication

381
00:27:47,120 --> 00:27:52,120
and there are nicer ways to do that and I think we're able to do that in a better way.

382
00:27:52,120 --> 00:27:53,120
Yeah.

383
00:27:53,120 --> 00:28:00,720
So you've kind of, you've developed this approach and you mentioned that you've got some experimental

384
00:28:00,720 --> 00:28:01,720
results as well.

385
00:28:01,720 --> 00:28:07,200
Can you talk a little bit about how you frame the question experimentally and what you've

386
00:28:07,200 --> 00:28:08,200
seen?

387
00:28:08,200 --> 00:28:09,200
Sure.

388
00:28:09,200 --> 00:28:16,160
I mean, the way we frame it is we want to keep a few things fixed.

389
00:28:16,160 --> 00:28:20,680
And the way we keep a few things fixed is we say pick an architecture first and that

390
00:28:20,680 --> 00:28:21,680
can be allocated.

391
00:28:21,680 --> 00:28:25,960
It can be, you know, we're looking at things like dense net, point net, all those year

392
00:28:25,960 --> 00:28:30,360
architectures, which are known to work well for certain databases, keep the architecture

393
00:28:30,360 --> 00:28:35,800
more or less fixed, keep the training set more or less fixed.

394
00:28:35,800 --> 00:28:41,080
And the only thing that varies is, you know, don't play too much with new fancier data

395
00:28:41,080 --> 00:28:42,080
augmentation methods.

396
00:28:42,080 --> 00:28:48,240
The only thing we are doing is adding in constraints either in some latent variables or we're adding

397
00:28:48,240 --> 00:28:51,080
in certain augmented loss functions.

398
00:28:51,080 --> 00:28:57,040
So most of the additional thing that we're doing is a mathematical expression of some kind.

399
00:28:57,040 --> 00:28:59,720
And keeping in, otherwise there is, it's hard to compare.

400
00:28:59,720 --> 00:29:05,200
I mean, if you say, let me train it for more iterations, but not add a constraint, can

401
00:29:05,200 --> 00:29:06,480
you compare it?

402
00:29:06,480 --> 00:29:13,120
So keeping mostly the computational resources fixed, we're asking if this additional mathematical

403
00:29:13,120 --> 00:29:15,480
knowledge pushes on the low.

404
00:29:15,480 --> 00:29:16,840
And we've been finding that it does.

405
00:29:16,840 --> 00:29:21,520
We have done that for image classification, we've done that for, you know, disentangling

406
00:29:21,520 --> 00:29:25,000
networks, we've done that for time series problems recently.

407
00:29:25,000 --> 00:29:30,280
And some of our compelling results are indeed from time series modeling, where, you know,

408
00:29:30,280 --> 00:29:36,120
we applied this to human activity like ignition data sets with either stick figures or variable

409
00:29:36,120 --> 00:29:38,040
devices.

410
00:29:38,040 --> 00:29:42,560
And the kind of factor that we are trying to factor out in human movement is not light

411
00:29:42,560 --> 00:29:48,480
and shape and geometry, but it's time series variability issues, which is, you know, the

412
00:29:48,480 --> 00:29:53,520
same action when performed by the same person, but at a slightly different time will give

413
00:29:53,520 --> 00:29:57,240
rise to slightly different traces, because people have intrinsic variability and how

414
00:29:57,240 --> 00:29:58,480
they move.

415
00:29:58,480 --> 00:30:03,920
And oftentimes that variability gets expressed through some time warping kinds of relationships.

416
00:30:03,920 --> 00:30:09,680
What we've done is express the time warping property as a constraint, which can be forced

417
00:30:09,680 --> 00:30:14,240
by the network to be factored out in a latent variable, if we just throw in that constraint

418
00:30:14,240 --> 00:30:15,920
in the loss function.

419
00:30:15,920 --> 00:30:21,320
And we found that it improves numbers significantly, just like that without any additional training,

420
00:30:21,320 --> 00:30:24,640
without any additional, you know, data requirements.

421
00:30:24,640 --> 00:30:34,160
So the pictures, or what I think are the pictures of this, if I'm understanding the problem

422
00:30:34,160 --> 00:30:40,920
is along the lines of, you know, start from your seat in the living room, go to the refrigerator,

423
00:30:40,920 --> 00:30:46,080
grab a drink, you know, take off the cover and drop the cover in the trash can, and you've

424
00:30:46,080 --> 00:30:53,840
got this kind of two dimensional plot of the path that the person might take in doing

425
00:30:53,840 --> 00:30:55,440
all that.

426
00:30:55,440 --> 00:31:02,400
And your argument is that the path is an invariant, because the task is the same.

427
00:31:02,400 --> 00:31:08,520
It's, you know, do X and Y, and what you're trying to do is identify, well, what is the

428
00:31:08,520 --> 00:31:09,520
fundamental?

429
00:31:09,520 --> 00:31:16,640
So you said identifying the path, is it somehow in a data set with lots of these, you

430
00:31:16,640 --> 00:31:22,840
know, traces or paths identify which ones correspond to the same actions or.

431
00:31:22,840 --> 00:31:27,000
It's close, I mean, we haven't looked at paths in that way, but we've looked at traces

432
00:31:27,000 --> 00:31:31,520
of stick figures, you know, so you have like 50 joints being tracked and you have the full

433
00:31:31,520 --> 00:31:36,880
time series of 50 joints evolving in space and in three dimensions that comes from motion

434
00:31:36,880 --> 00:31:37,880
capture say.

435
00:31:37,880 --> 00:31:38,880
Okay.

436
00:31:38,880 --> 00:31:42,360
Yes, there are actions, not really unlike what you're saying, actions in a kitchen, actions

437
00:31:42,360 --> 00:31:46,920
in a room, actions in an office, picking up objects, placing them here and there.

438
00:31:46,920 --> 00:31:51,920
And the feature that is invariant, of course, is hard to linguistically describe, but one

439
00:31:51,920 --> 00:31:57,520
of the variables that gives rise to confusion is that people sometimes take longer to do

440
00:31:57,520 --> 00:31:58,520
the same thing.

441
00:31:58,520 --> 00:32:02,400
People sometimes are fast in certain phases of the movement, slow in certain phases of

442
00:32:02,400 --> 00:32:03,400
the movement.

443
00:32:03,400 --> 00:32:04,400
Right.

444
00:32:04,400 --> 00:32:09,400
Or there is asymmetry in the body, you know, the left, the left arm swings more than the

445
00:32:09,400 --> 00:32:10,400
right arm.

446
00:32:10,400 --> 00:32:14,400
You know, there's all these interesting sources of variability which are hard to and the

447
00:32:14,400 --> 00:32:18,960
only way deep learning will be robust to that is if you augmented with all these variables,

448
00:32:18,960 --> 00:32:21,600
all these sources of variation.

449
00:32:21,600 --> 00:32:26,320
The way we think of it is that the variability here is expressible as a warping of the

450
00:32:26,320 --> 00:32:30,720
time axis, whether it's short versus long or speeding up versus slowing down.

451
00:32:30,720 --> 00:32:36,400
Or if it's one side faster than the other side or the swings are smaller than the other,

452
00:32:36,400 --> 00:32:38,760
it's all a time warp.

453
00:32:38,760 --> 00:32:42,960
Sometimes it can be constant, sometimes it can be non-constant and it can be.

454
00:32:42,960 --> 00:32:45,240
So that brings up an interesting question.

455
00:32:45,240 --> 00:32:55,120
Do you assume in your work throughout a single source of invariance or do you also conceive

456
00:32:55,120 --> 00:32:57,320
of multiple sources of invariance?

457
00:32:57,320 --> 00:33:02,840
Like, you know, there's a time invariance, but there's also the left arm swing invariance

458
00:33:02,840 --> 00:33:03,840
factor.

459
00:33:03,840 --> 00:33:04,840
Yeah.

460
00:33:04,840 --> 00:33:06,840
I mean, that is the, I mean, we are headed in that direction.

461
00:33:06,840 --> 00:33:08,840
I mean, right now our investigations have been-

462
00:33:08,840 --> 00:33:09,840
That would be the answer.

463
00:33:09,840 --> 00:33:15,200
The goal is to be able to have almost like a linear combination of known invariance

464
00:33:15,200 --> 00:33:18,560
is that, you know, you can account for, but-

465
00:33:18,560 --> 00:33:19,560
Right.

466
00:33:19,560 --> 00:33:23,560
I mean, at this time we have been playing it very carefully that let's take this one source

467
00:33:23,560 --> 00:33:24,560
of variable.

468
00:33:24,560 --> 00:33:25,560
Let's see if that can be factored out.

469
00:33:25,560 --> 00:33:27,800
Let's see if we can get invaders to that.

470
00:33:27,800 --> 00:33:31,400
And we have had success in many different applications.

471
00:33:31,400 --> 00:33:36,680
It sounds like you're further saying though that in the case of at least this motion capture

472
00:33:36,680 --> 00:33:46,600
type of a data set that the- that maybe time becomes kind of a meta-invariance that can

473
00:33:46,600 --> 00:33:52,480
account for multiple physical characteristics, am I hearing that correctly in there?

474
00:33:52,480 --> 00:33:53,480
It can.

475
00:33:53,480 --> 00:33:57,360
It's- it's hard to write that out clearly, but it does.

476
00:33:57,360 --> 00:34:03,480
Like for instance, if you had like load bearing, you know, if you were carrying a heavy

477
00:34:03,480 --> 00:34:06,640
bag on your bag, it- it will have an interest

478
00:34:06,640 --> 00:34:12,520
ing effect on the time series of your joins, which is not that easy to explain, but it

479
00:34:12,520 --> 00:34:16,360
will sort of stretch out certain phases of your movement and shrink certain phases of

480
00:34:16,360 --> 00:34:17,360
your movement.

481
00:34:17,360 --> 00:34:18,360
It does.

482
00:34:18,360 --> 00:34:24,320
So, yeah, the stretchings and shrinkings of the time axis are the key to finding what that

483
00:34:24,320 --> 00:34:26,800
invariant is for the lack.

484
00:34:26,800 --> 00:34:32,280
And so are there well established benchmark data sets for these types of tasks?

485
00:34:32,280 --> 00:34:36,600
Are you rolling your own to explore these methods?

486
00:34:36,600 --> 00:34:39,560
You know, for motion capture, there are benchmark data sets.

487
00:34:39,560 --> 00:34:43,400
There are, you know, Microsoft has a- it used to have a RGBD data set.

488
00:34:43,400 --> 00:34:48,520
I mean, they go by the RGBD activity, sort of, you know, keywords.

489
00:34:48,520 --> 00:34:49,520
And there's a few out there.

490
00:34:49,520 --> 00:34:51,240
There's a few benchmark data sets out there.

491
00:34:51,240 --> 00:34:54,280
NTU has one, MSR is one.

492
00:34:54,280 --> 00:35:00,600
And sometimes even, you know, the video data sets like HMDB have stick figures available

493
00:35:00,600 --> 00:35:03,360
through other methods like PostNet, for instance.

494
00:35:03,360 --> 00:35:06,880
So yeah, there are well-established data sets that we experiment with.

495
00:35:06,880 --> 00:35:14,880
And is the task that's posed by these data sets one of predicting the action that the-

496
00:35:14,880 --> 00:35:15,880
Right.

497
00:35:15,880 --> 00:35:16,880
Okay.

498
00:35:16,880 --> 00:35:19,640
It's activity classification prediction by and large, right?

499
00:35:19,640 --> 00:35:20,640
Yeah.

500
00:35:20,640 --> 00:35:21,640
Okay.

501
00:35:21,640 --> 00:35:22,640
Okay.

502
00:35:22,640 --> 00:35:27,920
And so what's the kind of state of the art for that kind of activity detection and how

503
00:35:27,920 --> 00:35:30,040
does your method compare to it?

504
00:35:30,040 --> 00:35:35,400
So most of the time series in the deep learning world, most time series things are either a combination

505
00:35:35,400 --> 00:35:39,320
of 1D CNNs or, you know, LSTM models.

506
00:35:39,320 --> 00:35:44,360
So depending upon the data set, the way our process goes is we say, let's find the latest,

507
00:35:44,360 --> 00:35:49,360
you know, benchmarks and we'll improve on those through these mathematical techniques.

508
00:35:49,360 --> 00:35:56,640
So a recent paper we did in CVPR 2019 used LSTMs as the benchmark data, you know, the technique.

509
00:35:56,640 --> 00:36:02,960
And the data sets were NTU 3D data set and a few others like that motion capture.

510
00:36:02,960 --> 00:36:07,840
The tunable parameter in LSTMs is oftentimes the hidden layers, how many hidden units do

511
00:36:07,840 --> 00:36:08,840
you have?

512
00:36:08,840 --> 00:36:12,880
And of course, if you scroll through it, the numbers keep going better and better.

513
00:36:12,880 --> 00:36:15,440
The way we've done it is we kept things the same.

514
00:36:15,440 --> 00:36:21,000
We say, let's say it's 16 hidden units or 32 hidden units, keep that the same.

515
00:36:21,000 --> 00:36:25,400
The only thing we'll change is add in this additional module that either disentangles the

516
00:36:25,400 --> 00:36:29,800
time work function or adds in as a constraint and numbers always go out.

517
00:36:29,800 --> 00:36:36,160
So in the way we thought about it, if my number, if my memory is right, the NTU RGB data set

518
00:36:36,160 --> 00:36:43,280
had like, you know, 80% roughly accuracy with a very fancy LSTM with 200 hidden units

519
00:36:43,280 --> 00:36:44,920
and stuff like that.

520
00:36:44,920 --> 00:36:48,640
And we were able to improve it by four or five percentage points easy without any changes

521
00:36:48,640 --> 00:36:52,520
to anything, but just this additional constraint added in.

522
00:36:52,520 --> 00:36:57,720
So if you find you need more, sure, there's more things to be squeezed out, but we were

523
00:36:57,720 --> 00:37:01,720
able to consistently improve the performance of LSTMs by easy five percentage points

524
00:37:01,720 --> 00:37:06,840
and times six, eight percentage points with no change, but a simple constraint on time

525
00:37:06,840 --> 00:37:07,840
warping.

526
00:37:07,840 --> 00:37:13,560
Yeah, so those are the kinds of results we've been finding, which is if you rethink what

527
00:37:13,560 --> 00:37:19,200
the constraints should be through understanding the phenomena first, the payoffs are actually

528
00:37:19,200 --> 00:37:24,000
quite significant without any additional requirements on data or network, architecture,

529
00:37:24,000 --> 00:37:28,040
complexity or training strategies, they can all be very basic.

530
00:37:28,040 --> 00:37:32,080
And so now we've talked about a couple of, you know, very different types of problems

531
00:37:32,080 --> 00:37:40,040
one, kind of a, you know, computer, a very visual type of task in one of this more time

532
00:37:40,040 --> 00:37:46,440
series to apply this to different settings, how much hand crafting needs to go into the

533
00:37:46,440 --> 00:37:53,000
loss functions and the, you know, the different constraints that you're applying to the network.

534
00:37:53,000 --> 00:37:55,000
That is where the big work is.

535
00:37:55,000 --> 00:38:02,400
So I think the pendulum is swinging to that level of hand crafting, you know, moving away

536
00:38:02,400 --> 00:38:07,200
from features to architectures and loss functions, right, that's where the pendulum is.

537
00:38:07,200 --> 00:38:14,160
And the amount of work that goes into hand crafting is a lot of, I would say, studying

538
00:38:14,160 --> 00:38:21,640
basically, understanding how these variables actually affect the observed data and try

539
00:38:21,640 --> 00:38:25,760
to express it in a way that is emanabled to fusion with the deep net.

540
00:38:25,760 --> 00:38:30,640
The beauty is physics is not one way, you know, light is, there is no single model for

541
00:38:30,640 --> 00:38:35,440
expressing how light and surfaces interact, there's layers and layers and layers to it.

542
00:38:35,440 --> 00:38:40,640
And you have to know all of that or at least as much as you know, as much as you can learn.

543
00:38:40,640 --> 00:38:46,840
And then the hand crafting is where in this spectrum of sophistication do I stop in a way

544
00:38:46,840 --> 00:38:54,080
that I actually have a pragmatic effect on performance without changing anything else.

545
00:38:54,080 --> 00:38:57,680
And that's where a lot of intuition is, you know, you cannot get away from this intuitive

546
00:38:57,680 --> 00:38:58,680
exercise.

547
00:38:58,680 --> 00:39:04,280
Despite all the progress of machine learning and deep learning, the networks are arguably

548
00:39:04,280 --> 00:39:06,040
both intuitive and highly unintuitive.

549
00:39:06,040 --> 00:39:10,480
I mean, some people have an insight about why a network works, but present it to someone

550
00:39:10,480 --> 00:39:12,400
else, it's mysterious.

551
00:39:12,400 --> 00:39:16,640
And the same thing is true of the last functions business.

552
00:39:16,640 --> 00:39:21,280
Sometimes we can motivate it very easily through simple things like, well, yeah, cross entropy

553
00:39:21,280 --> 00:39:25,080
means where it makes sense.

554
00:39:25,080 --> 00:39:29,520
Physics is where some of the unintuitive stuff lies.

555
00:39:29,520 --> 00:39:34,120
It's, that's where a lot of design thinking exists and we are doing that.

556
00:39:34,120 --> 00:39:40,960
So yes, that's where much of the work is understanding that when you approach the N plus 1th problem

557
00:39:40,960 --> 00:39:46,760
that's different from the ones that you've looked at previously that you're starting

558
00:39:46,760 --> 00:39:53,840
from scratch, or are there some principles that give you a foothold when trying to apply

559
00:39:53,840 --> 00:39:56,120
this method to the new area?

560
00:39:56,120 --> 00:39:58,240
And if so, what are those principles?

561
00:39:58,240 --> 00:40:02,160
The details, of course, have to be looked at from scratch, but the principles that we've

562
00:40:02,160 --> 00:40:08,080
bring to the table are ideas of geometry and, you know, this idea that look, whatever it

563
00:40:08,080 --> 00:40:12,640
is that you're observing, whatever it is, the raw space, that is not the space on which

564
00:40:12,640 --> 00:40:14,800
you want your analysis to occur.

565
00:40:14,800 --> 00:40:19,000
You want the analysis to occur in a space that is crumpled.

566
00:40:19,000 --> 00:40:24,480
And the generalizable knowledge that we bring to the table is how do we represent these

567
00:40:24,480 --> 00:40:26,280
crumpled spaces?

568
00:40:26,280 --> 00:40:30,400
And that's the mathematics of humanian geometry and topology, group theory.

569
00:40:30,400 --> 00:40:32,040
Those are all the new mathematics.

570
00:40:32,040 --> 00:40:33,400
It's not new mathematics at all.

571
00:40:33,400 --> 00:40:38,400
It's mathematics of the past two centuries, but in the realm of machine learning, that

572
00:40:38,400 --> 00:40:43,240
mathematics has not made its way in a systematic way.

573
00:40:43,240 --> 00:40:44,720
So that's the generalizable knowledge.

574
00:40:44,720 --> 00:40:48,000
We bring in group theory, geometry, differential geometry, topology.

575
00:40:48,000 --> 00:40:49,560
That's the way we think about it.

576
00:40:49,560 --> 00:40:55,080
But then the specifics, the problem specifics have to be studied from scratch, but then

577
00:40:55,080 --> 00:41:00,200
that knowledge can often be expressed in the constraints of geometry, anthropology, and

578
00:41:00,200 --> 00:41:01,360
group theory.

579
00:41:01,360 --> 00:41:02,520
And that's where we specialize.

580
00:41:02,520 --> 00:41:07,520
How do we take this domain specific knowledge and look at it through the lens of groups and

581
00:41:07,520 --> 00:41:08,520
invariance?

582
00:41:08,520 --> 00:41:12,000
And that's a different kind of generalizable knowledge.

583
00:41:12,000 --> 00:41:18,880
It's really a way of thinking about phenomena rather than thinking about data.

584
00:41:18,880 --> 00:41:28,760
Going back to your keynote, you kind of take a step back and apply this broadly to computer

585
00:41:28,760 --> 00:41:34,120
vision, machine learning, and do you kind of offer any thoughts for where this is all

586
00:41:34,120 --> 00:41:36,120
going?

587
00:41:36,120 --> 00:41:37,120
Not.

588
00:41:37,120 --> 00:41:38,120
Let's make some up.

589
00:41:38,120 --> 00:41:42,920
This is all going, pop in.

590
00:41:42,920 --> 00:41:47,440
So data constraints and scenarios, that's where this is all going.

591
00:41:47,440 --> 00:41:52,200
Machine learning with unconstrained amounts of training data is what the last 10 years

592
00:41:52,200 --> 00:41:53,400
were about.

593
00:41:53,400 --> 00:42:00,160
And we're finding that it's a nice goal, but there are no guarantees to be ever had, even

594
00:42:00,160 --> 00:42:04,320
if you train it forever with as much amount of data that you've got.

595
00:42:04,320 --> 00:42:09,800
If any mission critical deployment requires a guaranteed robustness of some kind, there

596
00:42:09,800 --> 00:42:14,880
is nothing to be given other than, yeah, this is what my numbers are on some data set.

597
00:42:14,880 --> 00:42:15,880
That's all you have.

598
00:42:15,880 --> 00:42:20,160
And now, if I can just hit pause there, you throughout our conversation, you've talked

599
00:42:20,160 --> 00:42:26,920
about constraints, you've talked about constraints on the network and you've talked about constraints

600
00:42:26,920 --> 00:42:33,000
on loss functions, you've talked about constraints on, you know, architectures and not changing

601
00:42:33,000 --> 00:42:34,000
architectures.

602
00:42:34,000 --> 00:42:38,080
And, you know, those have implications on compute constraints and that you haven't really

603
00:42:38,080 --> 00:42:41,240
explicitly talked about constraints on data.

604
00:42:41,240 --> 00:42:44,520
How does that fit into all these other stuff we've talked about?

605
00:42:44,520 --> 00:42:50,560
So I mean, the way I think about it is, if you don't have access to additional data,

606
00:42:50,560 --> 00:42:55,360
you get more bang for your buck by adding these additional constraints that we were talking

607
00:42:55,360 --> 00:42:56,440
about.

608
00:42:56,440 --> 00:43:00,840
If you have access to more data and you can collect as much as you want, you always should,

609
00:43:00,840 --> 00:43:06,840
I mean, that's, I didn't know about, but it's becoming more and more clear that that's

610
00:43:06,840 --> 00:43:09,880
not where the future is headed.

611
00:43:09,880 --> 00:43:14,280
We are not able to keep training bigger and bigger, you know, it's an unsustainable path.

612
00:43:14,280 --> 00:43:18,440
I mean, there is enough energy going in that direction anyway, whether or not we like

613
00:43:18,440 --> 00:43:19,840
it or I like it.

614
00:43:19,840 --> 00:43:22,160
But it's not a sustainable path of progress.

615
00:43:22,160 --> 00:43:27,280
It's smaller and smaller, you know, diminishing returns, but I have an increasing resources.

616
00:43:27,280 --> 00:43:34,560
So that's clear on the margins, but is part of your work trying to get at one shot, few

617
00:43:34,560 --> 00:43:39,440
shot types of problems or no?

618
00:43:39,440 --> 00:43:42,360
We are, I mean, that would be an extreme case.

619
00:43:42,360 --> 00:43:48,600
But yes, I mean, we are thinking more along the lines of, if I had to collect more data,

620
00:43:48,600 --> 00:43:56,600
can I first pause before collecting any more data and robustify what I've got with domain

621
00:43:56,600 --> 00:43:57,600
knowledge?

622
00:43:57,600 --> 00:44:00,080
That's the way I think about it.

623
00:44:00,080 --> 00:44:02,600
One shot and few shot, it's a whole different ball game.

624
00:44:02,600 --> 00:44:08,040
I mean, it's like the wide west of, you know, machine learning and I wouldn't go that

625
00:44:08,040 --> 00:44:09,040
far yet.

626
00:44:09,040 --> 00:44:14,880
Will it be applicable? I mean, sure, I don't see why not, but I wouldn't make big claims

627
00:44:14,880 --> 00:44:21,200
of getting one shot performance, but it should definitely help if not, you know, make it

628
00:44:21,200 --> 00:44:24,080
more amenable to, you know, less training sets.

629
00:44:24,080 --> 00:44:25,080
Yeah.

630
00:44:25,080 --> 00:44:26,080
Okay.

631
00:44:26,080 --> 00:44:30,520
So I interrupt that you were talking about essentially that the data collection is always

632
00:44:30,520 --> 00:44:36,280
going to be expensive and, you know, thinking about the problem space can provide, provide

633
00:44:36,280 --> 00:44:37,280
these benefits.

634
00:44:37,280 --> 00:44:39,960
I mean, unfortunately, human in the loop can't go away.

635
00:44:39,960 --> 00:44:42,800
I mean, there is neural architecture search.

636
00:44:42,800 --> 00:44:44,960
Yes, I mean, again, will this succeed?

637
00:44:44,960 --> 00:44:49,240
They will succeed at developing some representations that get a job done.

638
00:44:49,240 --> 00:44:53,440
And when you layer in questions of interpretation, explanation, which everybody is talking about,

639
00:44:53,440 --> 00:44:58,720
I have a much simpler take on it, which is if you don't have robustness to even simple

640
00:44:58,720 --> 00:45:01,640
physical variables, how will you even explain it?

641
00:45:01,640 --> 00:45:06,280
I mean, if your classification shifts simply because I rotate a picture and you're asking

642
00:45:06,280 --> 00:45:09,640
me to explain it, I think you're asking the wrong question.

643
00:45:09,640 --> 00:45:16,360
If you're at least asking me, can you be first be robust slash invariant to simple things

644
00:45:16,360 --> 00:45:20,880
and then explain it to me, that's a more well-posed question, but these are premature questions

645
00:45:20,880 --> 00:45:22,200
to ask.

646
00:45:22,200 --> 00:45:27,840
And some colleagues of mine have gone so far to say repeatability if your machine learning

647
00:45:27,840 --> 00:45:29,280
technique is not repeatable.

648
00:45:29,280 --> 00:45:33,280
And by that, things like this, yeah, if I click this picture at a slightly different time

649
00:45:33,280 --> 00:45:38,480
of day, nothing's really changed except the time of day and the decision has flipped, the

650
00:45:38,480 --> 00:45:40,280
process is not even repeatable.

651
00:45:40,280 --> 00:45:46,560
So don't even go to the extent of explaining a non-repeatable process or trying to interpret

652
00:45:46,560 --> 00:45:48,040
a non-repeatable process.

653
00:45:48,040 --> 00:45:50,800
Those are all questions that should come later.

654
00:45:50,800 --> 00:45:56,080
So if you think of repeatability, you do an experiment, you get the same result over

655
00:45:56,080 --> 00:46:02,400
and over again, as far as the big things are controlled, machine learning hasn't yet

656
00:46:02,400 --> 00:46:05,560
delivered that even.

657
00:46:05,560 --> 00:46:12,080
So we're trying to bring in that level of robustness, I call it robustness slash invariance.

658
00:46:12,080 --> 00:46:16,840
Some people have called it repeatability, simple and repeatability sounds shinier and

659
00:46:16,840 --> 00:46:22,000
it sounds like the stakes are much higher, but I'm happy to just call it invariance.

660
00:46:22,000 --> 00:46:27,880
Well, Paven, thanks so much for taking the time to share what you're up to and provide

661
00:46:27,880 --> 00:46:32,520
us some context for your CVPR keynote, very cool stuff.

662
00:46:32,520 --> 00:46:37,880
Thank you so much Sam, this has been a pleasure and you've been great, thank you so much.

663
00:46:37,880 --> 00:46:43,960
All right, everyone, that's our show for today.

664
00:46:43,960 --> 00:46:49,760
For more information on today's show, visit twomolai.com slash shows.

665
00:46:49,760 --> 00:47:06,840
As always, thanks so much for listening and catch you next time.

