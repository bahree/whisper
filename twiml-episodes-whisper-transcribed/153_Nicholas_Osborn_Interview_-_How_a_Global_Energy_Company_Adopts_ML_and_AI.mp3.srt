1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:35,000
I'm your host Sam Charrington. A few weeks ago we celebrated the podcast's second anniversary

4
00:00:35,000 --> 00:00:39,320
and asked listeners to send us some ways that they've applied what they've learned on

5
00:00:39,320 --> 00:00:45,160
the podcast to their work. We've seen some great responses and for those of you that did

6
00:00:45,160 --> 00:00:51,400
take the time to reach out, thanks so much. An example I've heard several times, including

7
00:00:51,400 --> 00:00:57,040
most recently from Kelvin Ross, who presented at the last meetup, is from folks who learned

8
00:00:57,040 --> 00:01:02,480
about and gone on to implement the Lime Model Explanability Technique, which stands for

9
00:01:02,480 --> 00:01:09,560
Local Interpretable Model Ignostic Explanations, from my interview with Carlos Guestrin.

10
00:01:09,560 --> 00:01:14,400
One of our favorite comments on the anniversary page came from listener Yuri Gorin, who mentioned

11
00:01:14,400 --> 00:01:19,920
that something clicked for him after hearing Jeff Dean discuss embedding categorical features

12
00:01:19,920 --> 00:01:24,880
with Word to Vec. After listening to that podcast, he was able to implement that technique

13
00:01:24,880 --> 00:01:30,460
to represent various features in one of his models as dense vectors. Fast AI's Rachel

14
00:01:30,460 --> 00:01:35,320
Thomas also referenced the interview with Jeff in her recent blog post about that technique,

15
00:01:35,320 --> 00:01:41,640
which we'll link to in the show notes. In keeping with the theme of listener sharing,

16
00:01:41,640 --> 00:01:46,760
for today's show, I'm super excited to share this interview with Nick Osborne, a long

17
00:01:46,760 --> 00:01:51,560
time listener of the show, and leader of the global machine learning project management

18
00:01:51,560 --> 00:01:58,640
office at AES Corporation, a Fortune 200 power company. Nick and I met at my AI summit

19
00:01:58,640 --> 00:02:03,720
a few weeks back, and after a brief chat about some of the things he was up to at AES,

20
00:02:03,720 --> 00:02:09,080
I knew that I needed to get him on the show. In this interview, Nick and I explore how

21
00:02:09,080 --> 00:02:14,760
AES is implementing machine learning across multiple domains at the company. We dig into

22
00:02:14,760 --> 00:02:19,840
several examples falling under the natural language, computer vision, and cognitive assets

23
00:02:19,840 --> 00:02:24,800
categories that he's established for his projects. Along the way, we cover some of the key

24
00:02:24,800 --> 00:02:30,160
podcast episodes that help Nick discover potentially applicable ML techniques and how

25
00:02:30,160 --> 00:02:35,720
those are helping his team broaden the use of machine learning at AES. This was a fun

26
00:02:35,720 --> 00:02:42,080
and informative conversation that has a lot to offer. Thanks so much, Nick. Alright, let's

27
00:02:42,080 --> 00:02:43,560
do it.

28
00:02:43,560 --> 00:02:52,000
Alright, everyone, I am on the line with Nick Osborne. Nick is the leader of the global

29
00:02:52,000 --> 00:02:57,960
machine learning project management office with AES. Nick, welcome to this week in machine

30
00:02:57,960 --> 00:03:02,000
learning and AI. Thanks for having me. I'm really excited.

31
00:03:02,000 --> 00:03:07,280
Same here. So you are a long time listener of the podcast, who I finally had an opportunity

32
00:03:07,280 --> 00:03:12,680
to meet at my AI some of the few weeks ago, and we got into a really interesting discussion

33
00:03:12,680 --> 00:03:17,600
about some of the things that you're working on at AES. So I'm really looking forward to

34
00:03:17,600 --> 00:03:22,240
digging into that, but before we do, why don't you give us an overview of how you got

35
00:03:22,240 --> 00:03:25,640
started working in machine learning and AI?

36
00:03:25,640 --> 00:03:33,240
Sure. So my start in machine learning and AI is maybe a little bit different from the

37
00:03:33,240 --> 00:03:40,160
typical interview you have on in that I've come from the business analyst side. So my

38
00:03:40,160 --> 00:03:46,400
background is very much finance and consulting. I worked actually in restructuring, which

39
00:03:46,400 --> 00:03:52,400
is working with distressed businesses. But in that work, one of the things that we always

40
00:03:52,400 --> 00:03:59,520
end up doing is a lot of analysis, a lot of work with big data sets. And so when I think

41
00:03:59,520 --> 00:04:05,600
about my background and data science broadly, I think of it from that perspective and really

42
00:04:05,600 --> 00:04:13,400
understanding the value that this type of analysis can add to a business, the real value

43
00:04:13,400 --> 00:04:18,920
it can add for an organization long term and the real financial and practical business

44
00:04:18,920 --> 00:04:26,920
applications. So from that background and really over the last five years now, I've been

45
00:04:26,920 --> 00:04:35,600
working closely with the CTO of our organization to do various strategy initiatives. And one

46
00:04:35,600 --> 00:04:41,680
of those about two years ago, actually a little more than two years ago now, we got started

47
00:04:41,680 --> 00:04:51,480
in looking at machine learning, AI and advanced analytics. And really that effort has continued

48
00:04:51,480 --> 00:04:56,680
to where we are now. And so it's gone from just trying to understand the space to doing

49
00:04:56,680 --> 00:05:04,760
a series of pilots. We've had some some initial successes with our pilot efforts and practical

50
00:05:04,760 --> 00:05:12,360
applications to now where we're really starting to dig in on the companies, making a more

51
00:05:12,360 --> 00:05:17,960
cognizant and more focused investment in upgrading our digital capabilities.

52
00:05:17,960 --> 00:05:24,320
Fantastic. So I think it will help contextualize the discussion of the things that you're

53
00:05:24,320 --> 00:05:31,560
working on for folks to better understand AES and what the company's focus is.

54
00:05:31,560 --> 00:05:40,480
Sure. So AES is a global power company. That's power generation. So we own power plants

55
00:05:40,480 --> 00:05:46,360
and utilities in 15 countries around the world. That's down. Our footprints shrunk a little

56
00:05:46,360 --> 00:05:52,560
bit over the last several years, but we're now currently operating in 15 countries. We

57
00:05:52,560 --> 00:06:04,760
own generation assets that span the spectrum of from solar wind to natural gas and coal.

58
00:06:04,760 --> 00:06:09,320
We are making a very cognizant effort in the in the business to invest in in greener

59
00:06:09,320 --> 00:06:15,800
technologies and transitioning more of our fleet away from coal to cleaner and and a

60
00:06:15,800 --> 00:06:21,760
big focus on renewable renewable energy. And I think one other thing to add in there is

61
00:06:21,760 --> 00:06:25,520
that we are the world's leader in battery energy storage.

62
00:06:25,520 --> 00:06:32,160
What aspect of battery energy storage? So we focus on primarily utility scale, battery

63
00:06:32,160 --> 00:06:39,520
energy storage. So these are the grid facilities that go in. They're usually tensed to hundreds

64
00:06:39,520 --> 00:06:48,680
of megawatts in scale. And they provide a spectrum of services for the grid from balancing

65
00:06:48,680 --> 00:06:55,000
to frequency regulation. And really what we're starting to see now is that these energy storage

66
00:06:55,000 --> 00:07:03,520
assets can actually replace or take the place of a thermal or a natural gas peaking plant.

67
00:07:03,520 --> 00:07:11,760
So it's really one of the ways we are starting to shift the energy networks away from thermal

68
00:07:11,760 --> 00:07:15,000
to cleaner and more renewable technologies.

69
00:07:15,000 --> 00:07:22,280
When you first started to think about applying machine learning and AI to AES's business,

70
00:07:22,280 --> 00:07:27,480
how did you how did you think about it? Where did you think the opportunities were and

71
00:07:27,480 --> 00:07:29,960
what was the initial driver?

72
00:07:29,960 --> 00:07:37,480
Yeah, so you know I think the at the very beginning you know it was much more of a research

73
00:07:37,480 --> 00:07:44,880
effort. And then we kind of slowly began to add additional things that we saw that could

74
00:07:44,880 --> 00:07:50,960
be applicable across the enterprise. And I think where we've gotten to and where we're

75
00:07:50,960 --> 00:07:57,880
current thinking is is that AI can play a role really across the full spectrum of the

76
00:07:57,880 --> 00:08:05,560
enterprise. So currently we have projects going on in language, we have projects going

77
00:08:05,560 --> 00:08:12,400
on in vision, and then we have projects going on in a theme that we call cognitive assets,

78
00:08:12,400 --> 00:08:18,320
which is where we you know try to bring intelligence to our machines. So our power plants right

79
00:08:18,320 --> 00:08:25,200
and that's where we get into maybe the most the clearest or the first area that maybe

80
00:08:25,200 --> 00:08:30,000
came to mind was how could we make our power plants more efficient? How could we operate

81
00:08:30,000 --> 00:08:35,040
them more effectively over the long term and that's where we get into predictive analytics

82
00:08:35,040 --> 00:08:41,840
type initiatives and projects. But really we're looking across the full breadth of the organization

83
00:08:41,840 --> 00:08:49,680
of from HR to strategy. You know being in generation safety is a you know critical piece of how

84
00:08:49,680 --> 00:08:55,000
we operate. And so we've had a few projects take a look at at safety and how we can improve

85
00:08:55,000 --> 00:09:01,520
safety using AI techniques. Before we go to the your first projects you mentioned that the

86
00:09:01,520 --> 00:09:09,360
initial emphasis was research and really learning how did you go about that that learning phase

87
00:09:09,360 --> 00:09:21,040
of this? Well Sam I would say your podcast was that wasn't a softball. Oh no but seriously this

88
00:09:21,040 --> 00:09:26,880
podcast was was a great way to learn about the industry and you know really going back to your

89
00:09:26,880 --> 00:09:31,680
tagline you know interesting people doing interesting things and machine learning and that's

90
00:09:31,680 --> 00:09:37,200
that's really you know the role played for for me and I know several other people in the company

91
00:09:37,200 --> 00:09:44,080
you know listen to the podcast as well. And it was really a great way to get exposed I mean there's

92
00:09:44,080 --> 00:09:52,320
so much activity in the space right now and the filtering and the interview you do with you

93
00:09:52,320 --> 00:09:58,320
know with kind of key people in each of these businesses. It was a great way for us to get our

94
00:09:58,320 --> 00:10:04,160
our heads around you know the breadth of everything going on and and maybe even give us a little bit

95
00:10:04,160 --> 00:10:10,480
of focus on to on the companies that we're doing you know the actual interesting work or some of

96
00:10:10,480 --> 00:10:18,400
the interesting work. And how about coursework have you had various people in the company taken

97
00:10:19,280 --> 00:10:28,160
or pursued kind of formal coursework in the area or research efforts? So yeah people have been

98
00:10:28,160 --> 00:10:34,880
doing coursework formally and informally. We were lucky to have a few people who actually had

99
00:10:35,520 --> 00:10:42,240
some data science as part of their graduate graduate studies and so that that was very helpful

100
00:10:42,960 --> 00:10:49,200
but people have been working through the you know Andrew Hings Coursera work. I know I've

101
00:10:49,200 --> 00:10:55,520
taken a look at some of the stuff on edX and and whatnot and then we've also been just using

102
00:10:55,520 --> 00:11:04,480
you know using some of the like some of the free tutorials that are available like through Azure

103
00:11:04,480 --> 00:11:09,120
and through some of the other platforms and really trying to focus on getting people's hands dirty

104
00:11:09,120 --> 00:11:14,400
with these tools and that's that's something that we actually have done a number of times now where

105
00:11:14,400 --> 00:11:21,120
we lead what we call cohorts which are about a month long where we focus on getting people hands

106
00:11:21,120 --> 00:11:27,600
on with machine learning tools. So we've used you know things like the Azure platform we've gotten

107
00:11:27,600 --> 00:11:36,400
people into Google and some of their tools and TensorFlow we've done work with a cortical and some

108
00:11:36,400 --> 00:11:43,280
of the free APIs they have and getting people to use them IBM Bluemix we did work with some of

109
00:11:43,280 --> 00:11:49,120
their cognitive tools and just just really trying to get people you know past you know reading about

110
00:11:49,120 --> 00:11:54,160
it and getting people to use some of these tools and see how they work and see how people can

111
00:11:54,160 --> 00:11:59,040
interact with them and that's been something that's been you know very helpful for people in the

112
00:11:59,040 --> 00:12:06,000
company. Awesome awesome so you mentioned cortical and this was a great story that you told me at the

113
00:12:06,000 --> 00:12:12,720
at the air summit and I guess it ties to that language that first of the three main areas that you've

114
00:12:12,720 --> 00:12:22,320
dug into. Yeah can you start by talking a little bit about where you see the use cases for

115
00:12:23,920 --> 00:12:31,600
NLP NLU types of technologies and language and then some of the things that you've done. Sure.

116
00:12:32,800 --> 00:12:38,880
So I think language in particular is one of the ones where we see some broad applications and so

117
00:12:38,880 --> 00:12:45,760
just initially we've done some some piloting and some testing and language is actually one of

118
00:12:45,760 --> 00:12:52,640
the areas where we've done some work around safety and seeing if we can you know improve safety or

119
00:12:52,640 --> 00:12:59,360
find some predictive capabilities through language and so so that's one area and I can go into more

120
00:12:59,360 --> 00:13:04,320
depth if you want on that but you know we're also looking at strategy I think there's a number of

121
00:13:04,320 --> 00:13:11,760
possibilities within HR. I think there's a tremendous opportunity for AI and machine learning to

122
00:13:11,760 --> 00:13:18,480
help with the recruiting and the evaluation of candidates through their the resume submissions

123
00:13:19,200 --> 00:13:25,840
and then a lot of my current thinking is around the strategy effort and how can we you know

124
00:13:25,840 --> 00:13:31,840
understand the the exponential content that is going out there or that is coming in and really

125
00:13:31,840 --> 00:13:39,280
provide a you know I'm meaningful way to to understand that content and to get it in front of

126
00:13:39,280 --> 00:13:46,400
our decision-makers in a timely and relevant fashion. So maybe start with safety and take us a

127
00:13:46,400 --> 00:13:51,600
little deeper into what you're what you've done and what you're hoping to achieve there.

128
00:13:52,560 --> 00:13:58,480
Yeah so so safety actually ended up not being one of our more successful projects okay

129
00:13:58,480 --> 00:14:05,280
but you know what the way we work is are one of the things that we do throughout our company is

130
00:14:05,280 --> 00:14:12,960
our things called safety rocks and we also do a lot of just safety monitoring where people go out

131
00:14:12,960 --> 00:14:18,480
and they they will document any safety findings throughout the company and so one of the things

132
00:14:18,480 --> 00:14:23,920
that we are hoping to do is could we could we look at that data set it's a written data set to

133
00:14:23,920 --> 00:14:31,440
understand if there were any triggers or our identifiers in those data sets that could lead us to

134
00:14:31,440 --> 00:14:37,520
understanding you know either really really good safety environments or versus poor safety

135
00:14:37,520 --> 00:14:43,440
environments and what would be an example of a trigger or identifier that you might expect to

136
00:14:44,720 --> 00:14:50,800
correlate to safety. Yeah and and maybe some of that's why that project wasn't as successful as

137
00:14:50,800 --> 00:14:59,040
you know trying to understand the way people are talking about safety and the words that

138
00:14:59,040 --> 00:15:04,320
they're using are writing about the safety of their of their facilities or plants right so

139
00:15:04,320 --> 00:15:10,960
it was a bit nebulous and we didn't get super far on on that project before it was kind of deemed

140
00:15:10,960 --> 00:15:17,920
not not super feasible however so maybe switching over to areas where we did make a little more

141
00:15:17,920 --> 00:15:25,520
progress was we did and this was one of the projects we did with with cortical are using some

142
00:15:25,520 --> 00:15:31,760
of the tools from cortical but we also do periodic culture surveys throughout the organization

143
00:15:32,400 --> 00:15:40,960
and so you know we're a global company with a lot of people so we received 13,000 surveys

144
00:15:40,960 --> 00:15:48,880
back in our last cultural survey effort most of that is multiple choice but we also had four

145
00:15:48,880 --> 00:15:55,600
open entry text fields that people could respond to four questions we were opposing so which ended

146
00:15:55,600 --> 00:16:03,040
up what that's receiving about 30,000 written written responses right so that's a lot of

147
00:16:04,080 --> 00:16:09,600
just data for anyone to kind of sort through or mine through it's very hard to be consistent in

148
00:16:09,600 --> 00:16:17,440
that evaluation even with even if one person read it all and so what we you know we use the tool

149
00:16:17,440 --> 00:16:24,320
from cortical and what we did a number of different analyses but you know what we were looking to do

150
00:16:24,320 --> 00:16:31,840
is benchmark those statements against 60 other statements that we had and so one of the things that

151
00:16:31,840 --> 00:16:38,800
cortical allows you to do is compared two different text you know text documents or text fields

152
00:16:38,800 --> 00:16:43,520
paragraphs or whatever and compare them on a semantic level right so this is where you get your

153
00:16:43,520 --> 00:16:49,840
your overlap between the two and basically by understanding the overlap we were able to benchmark

154
00:16:49,840 --> 00:16:57,760
the responses that we were getting against a series of 60 criteria which are helping us to evaluate

155
00:16:57,760 --> 00:17:02,880
the culture in each of our facilities and so since each of those responses came back with

156
00:17:02,880 --> 00:17:10,480
with the demographic information not anything identifiable to an individual but with kind of broad

157
00:17:10,480 --> 00:17:16,800
demographics male female kind of rough age ranges and those sort of things we were able to kind

158
00:17:16,800 --> 00:17:22,640
of peel the onion a little bit deeper and try to identify on a comparative basis you know which

159
00:17:22,640 --> 00:17:28,240
locations are you know caring about different parts of our culture right so just an example here is

160
00:17:28,240 --> 00:17:33,760
you know one facility could really care about advancement opportunities other facilities could

161
00:17:33,760 --> 00:17:41,360
care about benefits and this was a way for us to really mine that 30,000 comments or questions

162
00:17:41,360 --> 00:17:48,640
that we received back to to really understand the business on a deeper level and so

163
00:17:49,440 --> 00:17:54,000
so that was one part of the analysis we also pulled in some additional tools we pulled in

164
00:17:54,000 --> 00:18:00,640
and before you before you get too far from this particular piece part of what was exciting

165
00:18:01,280 --> 00:18:10,640
for media here from you was that you initially came across the work that cortical was doing

166
00:18:10,640 --> 00:18:16,560
around their semantic folding and semantic NLP stuff yeah through the podcast actually

167
00:18:16,560 --> 00:18:24,000
twin will talk number 10 with their founder Francisco Weber is that right yeah so that is where we

168
00:18:24,000 --> 00:18:31,280
first we first learned about it and I want to say you also had a talk with Numenta on later which

169
00:18:31,280 --> 00:18:38,160
is kind of the founding company are the research institute but yeah so twin will talk 10 with

170
00:18:38,160 --> 00:18:44,880
Francisco Weber was I found it to be incredibly fascinating one of the other you know people in

171
00:18:44,880 --> 00:18:50,480
our company also listen to that podcast and also found it really interesting and we kind of kept

172
00:18:50,480 --> 00:18:54,880
bringing it up to the CTO of our organization on like this is this is different the way they are

173
00:18:54,880 --> 00:19:00,560
thinking about language is just fundamentally different than a lot of the other language tools

174
00:19:00,560 --> 00:19:06,160
that we had seen and at the time we had also spent a fair amount of effort looking into like the IBM

175
00:19:06,160 --> 00:19:13,040
tools and just saw this as something really different and something that to me just kind of

176
00:19:13,040 --> 00:19:19,840
fundamentally makes more sense in the understanding of language so I found it to be really interesting

177
00:19:19,840 --> 00:19:26,080
and for this particular project it sounds like you had good result in understanding

178
00:19:26,880 --> 00:19:34,320
these survey responses did you come up with a measure of you know the results or how good

179
00:19:34,320 --> 00:19:41,280
the results were and had you tried other approaches previously that you know we're we're

180
00:19:41,280 --> 00:19:50,640
that you also measured and like could compare the success so no so we didn't do a comparative analysis

181
00:19:50,640 --> 00:19:57,200
against a different tool but the speed we were able to work through on the tool was much faster

182
00:19:57,200 --> 00:20:06,400
than what we were seeing with other tools and our ability to use it and we were and we were

183
00:20:06,400 --> 00:20:11,680
primarily using just the free API and doing some coding on our side to to make it all work and

184
00:20:12,480 --> 00:20:18,800
manipulate the data into it but it worked great and the and you know we didn't

185
00:20:19,520 --> 00:20:26,640
there wasn't an easy like precision or yeah precision type measure that we could get but we

186
00:20:26,640 --> 00:20:31,360
we spent a fair amount of time validating it just one on one on one going through the responses

187
00:20:31,360 --> 00:20:36,800
and seeing seeing the comparison that it was providing or the prediction that it was providing

188
00:20:36,800 --> 00:20:41,200
through the tool and making sure that it it lined up with what we were seeing so we did a

189
00:20:41,920 --> 00:20:46,880
you know we did some a fair amount of data testing or testing you know once we had

190
00:20:46,880 --> 00:20:51,840
worked through the tool but we didn't have a defined prediction measure for it.

191
00:20:51,840 --> 00:20:57,920
Awesome and I cut you off you were talking you were about to mention other tools I think you were

192
00:20:57,920 --> 00:21:04,640
saying that you were looking at. Yeah so we used some other tools to bring in sentiment analysis

193
00:21:04,640 --> 00:21:09,360
into it right so running the same question through a tool to get sentiment so positive negative

194
00:21:09,360 --> 00:21:14,640
sentiment and the emotional state that was coming back so that was you know again that's just

195
00:21:14,640 --> 00:21:19,680
providing another layer of information on it so we could you know understand whether or not people

196
00:21:19,680 --> 00:21:24,480
were talking positively or negatively about management versus just saying oh that person's

197
00:21:24,480 --> 00:21:30,880
you know talking about management. Okay and so that was that was a you know a helpful layer to add

198
00:21:30,880 --> 00:21:38,320
in there and then the second big piece of the analysis was trying to pull out what we were calling

199
00:21:38,320 --> 00:21:44,880
the meta nouns and meta adjectives from the sentences which were you know the primary topics

200
00:21:45,600 --> 00:21:52,160
and the primary descriptors of the topics that were being used in those statements and so

201
00:21:52,160 --> 00:21:59,120
if you think about the different ways a person could talk about you know their boss right it could

202
00:21:59,120 --> 00:22:05,840
be their leader it could be management manager it could be you know a lot of different descriptors

203
00:22:06,560 --> 00:22:12,240
and so we were able to pull out what we were returning meta nouns and meta adjectives and combine

204
00:22:12,240 --> 00:22:18,720
them together to what we were what we were terming at the time caveman speak which was you know

205
00:22:18,720 --> 00:22:24,160
stuff like you know management good development bad right or something along those lines right so

206
00:22:24,160 --> 00:22:30,880
really basic understanding of the thematic content of the of their responses and again that

207
00:22:30,880 --> 00:22:35,200
that helped us really narrow down what was what was being said because then we could look at

208
00:22:35,840 --> 00:22:41,120
across the organization or across the sample that we are working with on you know what were the

209
00:22:41,120 --> 00:22:46,720
the key things that people were saying right so trying to replicate how a human would go through

210
00:22:46,720 --> 00:22:52,960
that data set and you know pull out the the major themes and you know and this is exactly what

211
00:22:52,960 --> 00:22:56,720
we saw when we talked to the actual humans were who were going through it as they were going through

212
00:22:56,720 --> 00:23:04,160
and they were you know basically tick marking every time that they came across you know a response

213
00:23:04,160 --> 00:23:10,160
with a particular topic in it and so we we tried to use the the cortical tool to basically do

214
00:23:10,160 --> 00:23:17,120
the same thing for us is provide us an understanding of the topics that were coming back in the in

215
00:23:17,120 --> 00:23:22,800
the responses okay interesting interesting yeah and so you you've mentioned safety you've mentioned

216
00:23:22,800 --> 00:23:29,440
this I kind of assuming that is a HR use case and you mentioned strategy as well which it sounds

217
00:23:29,440 --> 00:23:36,640
like that is related to kind of content management is not the right word but kind of content understanding

218
00:23:36,640 --> 00:23:42,800
I guess talk a little bit about that strategy use case and what you did there yeah so this is one

219
00:23:42,800 --> 00:23:48,640
of the ones where we're still working and we had a fair amount of success at the end of last year

220
00:23:48,640 --> 00:23:55,840
and we're kind of reevaluating next steps on this project but basically what we were able to do

221
00:23:55,840 --> 00:24:02,640
is we were able to we we built a scraper to go scrape and we limited you know where we were scraping

222
00:24:02,640 --> 00:24:08,720
the information from for this pilot but we were able to pull out new new news articles from a

223
00:24:08,720 --> 00:24:14,640
from a data source we're then able to evaluate those news articles against and we're going down to

224
00:24:14,640 --> 00:24:21,840
the I think the paragraph level but we were pulling out the are comparing those new at our articles

225
00:24:21,840 --> 00:24:28,240
against specific strategic scenarios that we were for seeing in the next three to five years

226
00:24:28,240 --> 00:24:34,880
for that space and so you know we had gone through an an effort of you know putting the other

227
00:24:34,880 --> 00:24:41,040
and like a red scenario green scenario blue scenario that we were comparing these news articles

228
00:24:41,040 --> 00:24:46,240
against right so we were able to say you know does this you know news article lineup with

229
00:24:47,200 --> 00:24:52,240
you know our green scenario which maybe our green scenario is you know full transition to

230
00:24:52,240 --> 00:24:58,560
clean energy right and these are just very theoretical examples but and so we were able to kind

231
00:24:58,560 --> 00:25:04,560
of understand you know what the news article was about put a categorize it against us like a

232
00:25:04,560 --> 00:25:10,960
strategic outcome that we saw you know in the next three to five years and then what we also did

233
00:25:10,960 --> 00:25:18,480
is we built we built in the ability to present this to a user so we built a little slack interface

234
00:25:18,480 --> 00:25:25,600
to present the news article and the prediction to a user and whether or not to find out whether

235
00:25:25,600 --> 00:25:31,520
or not they agreed or disagreed with our prediction and then we use that prediction to further

236
00:25:31,520 --> 00:25:39,520
hone our our initial and our initial you know pick our prediction okay we're using any particular

237
00:25:39,520 --> 00:25:47,920
tools as part of that or did you develop the tooling for that internally yeah we're working with

238
00:25:47,920 --> 00:25:54,240
corticals API okay again for that one okay but we built a lot of the a lot of the other tooling

239
00:25:54,240 --> 00:26:02,240
was done in-house I think we were using scraping to do the actual web you know crawl and scrape

240
00:26:02,240 --> 00:26:08,240
function but yeah which I've heard great things about yeah it worked really well it was very

241
00:26:08,240 --> 00:26:15,040
quick for us to get up and running I didn't do the actual work with it but it was fast and easy

242
00:26:15,040 --> 00:26:22,640
so that's a good thing okay cool so that's some of the things that you've done on the language

243
00:26:22,640 --> 00:26:28,080
side of things how about vision yeah so visions really interesting and that's one of the areas

244
00:26:28,080 --> 00:26:37,520
we're currently pretty active on so and actually so maybe one one thing Sam we did really early on

245
00:26:37,520 --> 00:26:43,360
and this was just another example of where your podcast came in but you did an interview with

246
00:26:43,360 --> 00:26:53,280
Clarify with Matt Ziller and so we were able to just using again the free the free tooling from

247
00:26:53,280 --> 00:26:59,120
Clarify we were able to prove out a use case and safety where we could detect hard hats right so

248
00:26:59,120 --> 00:27:04,880
we could detect whether or not people were wearing their their PPE their protective equipment

249
00:27:05,920 --> 00:27:11,360
and I mean it was it's like built in the tool just does it for you automatically and so we

250
00:27:11,360 --> 00:27:16,480
we were able to prove out really quickly that yeah this is something that we could do is you know

251
00:27:16,480 --> 00:27:20,480
basically set up a camera to detect whether or not people are wearing their hard hats or

252
00:27:21,280 --> 00:27:27,760
their work gloves or work boots right but yeah I mean it was again it was a really easy tool just

253
00:27:27,760 --> 00:27:34,240
to get up and running we didn't we haven't like pursued that use case but yeah I mean really

254
00:27:34,240 --> 00:27:39,040
and just another example of kind of one of the ways you know we listen to the podcast learned

255
00:27:39,040 --> 00:27:44,720
about a company and then try to you know check it out and bring it into a business application

256
00:27:44,720 --> 00:27:52,640
awesome awesome and so what else have you done on the vision front so yeah so right now we are

257
00:27:52,640 --> 00:28:01,840
working heavily on a project where we are trying to detect damage and drone drone inspection

258
00:28:01,840 --> 00:28:08,160
footage and so we have we have some good data sets that we're working on and we're currently

259
00:28:08,160 --> 00:28:15,440
primarily working with with Google on this effort but we're looking at some other applications are

260
00:28:15,440 --> 00:28:21,280
you know potential applications but Google has been really helpful and working with us we're hoping

261
00:28:21,280 --> 00:28:26,720
to do a few more projects in the coming weeks but you know where this project started off is we

262
00:28:26,720 --> 00:28:34,240
started off with with TensorFlow and with the inception model there and that's specifically for

263
00:28:34,240 --> 00:28:41,600
our use case which was this damage detection project we were able to you you know prove out

264
00:28:41,600 --> 00:28:48,880
that it worked our initial couple models we're working but we were getting problems with

265
00:28:50,000 --> 00:28:55,520
high false positive rates so that's really where we've we've focused in now we're spending a

266
00:28:55,520 --> 00:29:01,920
lot of time working on our labeling and so the labeling has been a big part of the data cleanup

267
00:29:01,920 --> 00:29:06,800
and I'm sure it's not a surprise for anyone who's worked on data science that getting your data

268
00:29:06,800 --> 00:29:13,600
set correct is incredibly important especially when the data set wasn't necessarily built for

269
00:29:14,480 --> 00:29:20,800
for data science right it was the data set we were starting from was just it was built for for

270
00:29:20,800 --> 00:29:25,440
humans and for human inspectors to understand what was going on with the pictures

271
00:29:25,440 --> 00:29:34,480
and so it was it was I mean it's messy and inconsistent what's an example of the kind of damage

272
00:29:34,480 --> 00:29:39,600
that you were looking to determine and what specifically did that data set look like

273
00:29:40,400 --> 00:29:48,400
sure so so our data set right now is you know we own win facilities across the United States

274
00:29:48,400 --> 00:29:57,760
we have three primary projects and about 500 turbines in the US and so the data set we are

275
00:29:57,760 --> 00:30:05,600
looking at is the inspection footage of those of those blades and just for just for sizing each

276
00:30:05,600 --> 00:30:13,280
of the three facilities when we do an inspection we'll come back between 10 and 20,000 images

277
00:30:13,280 --> 00:30:20,560
of those inspections and the supremacally blade inspections right and so the these are images

278
00:30:20,560 --> 00:30:28,000
taken via drone of the blades while they're stopped you know they take pictures of all aspects

279
00:30:28,000 --> 00:30:33,120
so the four kind of different directions of the blade so you know the high pressure side

280
00:30:33,120 --> 00:30:40,560
low pressure side leading and trailing edges the damage can be surprising you know for you know

281
00:30:40,560 --> 00:30:48,080
for for a for a turbine blade that I mean is kind of just going through air there's there's a lot

282
00:30:48,080 --> 00:30:56,400
of different damage types that we see this can you know be like erosion and so some of our facilities

283
00:30:56,400 --> 00:31:02,080
are in our very area or desert landscapes and there's a fair amount of dust in particular matter

284
00:31:02,080 --> 00:31:09,120
so you can get erosion you can get bird strikes so birds hitting the turbine blades which can

285
00:31:09,120 --> 00:31:15,920
do a fair amount of damage lightning lightning strikes and so you I mean you will see you will

286
00:31:15,920 --> 00:31:22,720
see things from you know small you know divots and dense and coating penetrations to kind of

287
00:31:22,720 --> 00:31:31,200
large scale delamination of sections of the blade and so yeah I mean that's that's the that's the

288
00:31:31,200 --> 00:31:39,280
data set and then you know traditionally so I mean if we go backwards a little bit Sam so before

289
00:31:39,280 --> 00:31:44,320
drones these were all these inspections were done manually so someone would climb up the tower

290
00:31:44,320 --> 00:31:50,640
and go down and you know look for damage that way so dangerous time consuming work

291
00:31:51,840 --> 00:31:56,480
when we switched over to drones that was a tremendous tremendous time saver

292
00:31:56,480 --> 00:32:04,480
but had the had the side effect on while now now someone has to review you know 10 to 20

293
00:32:04,480 --> 00:32:12,880
thousand images right and the drones are capturing still images or video so in this application it's

294
00:32:12,880 --> 00:32:19,840
still but you know we we actually have a drone partner that we work with measure and so they can

295
00:32:19,840 --> 00:32:26,480
do different you know image types they can do video or my understanding is they can do video and

296
00:32:26,480 --> 00:32:33,200
infrared and so infrared you know is infrared's actually really important for solar applications

297
00:32:33,200 --> 00:32:40,560
and it's the infrared's a really great way to spot problems on a solar field and I'm assuming

298
00:32:40,560 --> 00:32:47,200
that they're the drones are manually operated as opposed to you know autonomously kind of going

299
00:32:47,200 --> 00:32:54,000
through a field of of turbines yeah correct yeah this is all they're all manually flown

300
00:32:54,000 --> 00:32:59,040
they fly a defined flight pattern when they when they do the inspections but yes it's all manual

301
00:32:59,840 --> 00:33:07,440
and so the you you started with TensorFlow and there's been some that the main issue you're

302
00:33:07,440 --> 00:33:17,120
focusing on now is addressing some issues with your labeling how was the labeling done previously

303
00:33:17,120 --> 00:33:26,800
are these the either your engineers or the drone providers kind of manually writing up a report of

304
00:33:26,800 --> 00:33:34,480
some sort are they coded or something what were you starting yeah so it's changed and it's changing

305
00:33:34,480 --> 00:33:42,320
so it it started off I mean really pretty rudimentary on just people entering information and an

306
00:33:42,320 --> 00:33:49,200
Excel worksheet as they were going through the images our drone partner that we work with now

307
00:33:49,200 --> 00:33:56,880
has some tools to allow them to be kind of more to be you know bounding boxes and to be systematically

308
00:33:56,880 --> 00:34:03,360
labeled with very defined categories and so that's that's helping us really get get where we need to

309
00:34:03,360 --> 00:34:07,920
get to go on the on the labeling side or we hope we'll get us where we need to go on the labeling

310
00:34:07,920 --> 00:34:16,640
side so yeah we're working on getting consistent labels getting those damage instances bounded

311
00:34:17,120 --> 00:34:25,280
to help which we think will be helpful and I'm curious have you explored any of this use case or

312
00:34:25,280 --> 00:34:34,800
any of the others active learning specifically meaning so you train a model based on some set of

313
00:34:34,800 --> 00:34:43,600
data and then you have incremental you basically have a human kind of correct the models decision

314
00:34:44,240 --> 00:34:50,000
on an incremental basis and feed that back in to the model training have you done anything at all

315
00:34:50,000 --> 00:34:57,040
with that actually who we just we just kind of looked at that maybe starting last week okay so

316
00:34:58,160 --> 00:35:05,360
so we've kind of switched over to using auto m auto ml from with google okay and so that has some

317
00:35:05,360 --> 00:35:10,480
of that functionality built right in and so that's that's that's how we're proceeding on that path

318
00:35:10,480 --> 00:35:15,840
is we I won't say we're we've done much with it yet but that's that's part of the plan at this

319
00:35:15,840 --> 00:35:22,640
point once we kind of got our heads around that like we were really excited yeah yeah yeah I mean

320
00:35:22,640 --> 00:35:28,000
it's potentially interesting and I'm hearing some some interesting stories of folks starting to

321
00:35:28,000 --> 00:35:34,480
see good results with it all right cool are there any other any other vision use cases that you've

322
00:35:34,480 --> 00:35:40,800
looked at not not that we're actively working on but I think the applications for drawing

323
00:35:40,800 --> 00:35:45,040
inspection footage is something that we're kind of looking at broadly yeah and there's there's a

324
00:35:45,040 --> 00:35:49,920
lot of different use use cases within the the power space and utility space in general so I

325
00:35:49,920 --> 00:35:57,600
could imagine yeah so it's it's dangerous work it's high voltages high pressures so any anytime we

326
00:35:57,600 --> 00:36:05,440
can take a human like a remote or take them out of that situation is generally seen as a positive

327
00:36:05,440 --> 00:36:12,480
thing and drones are a big part of that and then the flip side of that is taking advantage of the

328
00:36:12,480 --> 00:36:20,480
onboard sensor data to predict machine failure and that kind of leads us to that third category

329
00:36:20,480 --> 00:36:25,680
of cognitive assets can you talk a little bit about what you're doing there yeah so cognitive

330
00:36:25,680 --> 00:36:31,680
assets is a bit of a broad category for us where we we look at a number of or we look at a

331
00:36:31,680 --> 00:36:37,760
number of prediction type capabilities there and really looking at that you know anomaly detection

332
00:36:37,760 --> 00:36:42,720
in a in a facility predictive maintenance and those sort of things but we've also been able to

333
00:36:42,720 --> 00:36:50,160
do some tuning of our assets and that's really where we've seen the most progress and so this is

334
00:36:50,160 --> 00:36:56,080
one of the ones I think I mentioned to you at the at the interop conference but you know I'm sure

335
00:36:56,080 --> 00:37:03,200
you're familiar with the Google data center use case whether they were able to I believe improve

336
00:37:03,200 --> 00:37:10,960
PUE by 40 percent that's right and PUE is the power or something efficiency correct yeah so

337
00:37:12,160 --> 00:37:17,760
you know it's it's not the exact same application but when you think about our battery energy

338
00:37:17,760 --> 00:37:24,560
storage facilities they are very similar to a data center just without the the compute right they're

339
00:37:24,560 --> 00:37:34,480
just big the racks and racks of batteries and so we we were able to you know use a

340
00:37:34,480 --> 00:37:39,920
developer model that first predicted our power usage and power efficiency and then we were

341
00:37:39,920 --> 00:37:46,080
able to use that model to then improve power efficiency and I believe where last update I had

342
00:37:46,080 --> 00:37:52,400
is we were able to show a 20 percent improvement in in efficiency you know with with an algorithm

343
00:37:52,400 --> 00:37:57,920
that we built largely trying to you know copy Google's work in the area and so

344
00:37:59,280 --> 00:38:04,960
that's something that has now moved on into our energy storage business and our energy

345
00:38:04,960 --> 00:38:10,800
storage business got spun out over this past past year into a new enterprise called

346
00:38:10,800 --> 00:38:15,680
Fluence with partnering with Siemens and so it's on joint joint bench and they've they've taken

347
00:38:15,680 --> 00:38:22,240
that project and they continue to to run with it and run with deeper applications of machine learning

348
00:38:22,960 --> 00:38:28,400
on on their what they call their advanced on software interesting so the can you talk a little bit

349
00:38:28,400 --> 00:38:37,040
about the how that project evolved and the data assessment and collection phase the modeling phase

350
00:38:37,040 --> 00:38:43,840
how did you dig into it and how did you get started with it really so yeah I mean it started off

351
00:38:43,840 --> 00:38:49,040
just you know getting access to the data and so one of the great things about our energy storage

352
00:38:49,040 --> 00:38:55,360
facilities is that they're they're digitally native and so all the control systems have been

353
00:38:55,360 --> 00:39:03,760
digital since the very beginning and so we have literally you know tens of terabytes of of information

354
00:39:03,760 --> 00:39:11,520
just from our energy storage assets and so that's a tremendous data set for people to start working

355
00:39:11,520 --> 00:39:18,880
with one of the things that we were or one of the initial kind of difficulties we came across as

356
00:39:18,880 --> 00:39:29,120
that we had always had like a single set point on our on our basically our HVAC system right so

357
00:39:29,120 --> 00:39:37,360
we didn't have a very we didn't have a very diverse data set on on how to manipulate our HVAC

358
00:39:37,360 --> 00:39:44,000
system right so it always had a fixed set point and so one of the things that we had done is we

359
00:39:44,000 --> 00:39:51,200
we did modify our control software to allow to allow some variability in that HVAC setting and so

360
00:39:51,200 --> 00:39:56,320
that that was kind of one of the initial things that we had to work through on on getting a

361
00:39:57,040 --> 00:40:03,200
more meaningful data set for a modeling effort and really once we got beyond there it kind of

362
00:40:03,200 --> 00:40:08,960
all kind of clicked into space and to place on improving our predictive capability on our model

363
00:40:08,960 --> 00:40:14,080
and then and then being able to use that model to tune the system so was the HVAC

364
00:40:14,880 --> 00:40:21,200
system the primary system that you were controlling to increase power efficiency or was it

365
00:40:21,200 --> 00:40:26,400
something related to the batteries themselves or something else yeah no it was primarily the HVAC

366
00:40:26,400 --> 00:40:32,320
system so we were we were really focused on what we call in the in the power industry our auxiliary

367
00:40:32,320 --> 00:40:39,280
load which is the you know it's basically the power we use to well yeah to make power right

368
00:40:39,280 --> 00:40:44,960
and that's kind of the so yeah that's that's what we were really focusing on and you know any time

369
00:40:44,960 --> 00:40:50,880
we can reduce that ox load means we can put more of that power into the into the marketplace

370
00:40:51,440 --> 00:40:57,440
and it's really an efficiency thing for for power plants and do you have a sense for off the

371
00:40:57,440 --> 00:41:03,600
top of your head what that 20% improvement translates into from a business perspective in terms of

372
00:41:03,600 --> 00:41:11,920
you know dollars per year or x per x yeah I I don't have a good I don't have a good figure for that

373
00:41:11,920 --> 00:41:19,040
but it's got to be it's meaningful yeah I mean that's it's meaningful I don't know what the

374
00:41:19,040 --> 00:41:26,080
dollar impact is though maybe taking a step back from these three use case categories

375
00:41:26,080 --> 00:41:36,480
mm-hmm I'm curious if you can speak to running a ML PMO in an organization that you know has

376
00:41:36,480 --> 00:41:40,560
another business your business isn't you know you're not a software company machine learning

377
00:41:40,560 --> 00:41:46,720
company anything like that like how do you approach portfolio management of all these

378
00:41:46,720 --> 00:41:54,800
individual efforts and and you know how do you see that evolving as you gain maturity sure so

379
00:41:54,800 --> 00:42:01,040
you know really on you know we when I worked with our our CTO and defining the you know the

380
00:42:01,040 --> 00:42:08,160
what the PMO would do and what my role would be the role and was really to be to you know facilitate

381
00:42:08,880 --> 00:42:14,960
coordinate and accelerate these projects and so you know being such a distributed business

382
00:42:14,960 --> 00:42:19,440
it was really important that we helped help the businesses foster their own projects and help

383
00:42:19,440 --> 00:42:26,640
them find resources they need and open their eyes to some of the capabilities but to allow for

384
00:42:26,640 --> 00:42:34,960
some organic growth and or organic direction from from the businesses so that was one area where

385
00:42:34,960 --> 00:42:41,840
we've really tried to I don't want to say be hands off but instead of directing each of our

386
00:42:41,840 --> 00:42:47,680
businesses to do something with with ML we've tried to kind of open their eyes to the technology

387
00:42:47,680 --> 00:42:53,360
and to be available to them to help foster or to help facilitate any of these projects coming forward

388
00:42:54,400 --> 00:42:59,360
that said we've also done kind of taking the lead on several projects right so we couldn't let

389
00:42:59,360 --> 00:43:05,680
everything just be you know wait for wait to come to us so we we kind of took a dual approach where

390
00:43:05,680 --> 00:43:14,720
we've led some projects but then we've also put a fairly cognizant effort into raising awareness

391
00:43:14,720 --> 00:43:23,760
of of ML technologies and tools and the business applications and the potential to our senior leaders

392
00:43:23,760 --> 00:43:30,960
and to really some some broad user groups across the company so trying to trying to raise awareness

393
00:43:31,920 --> 00:43:40,400
while also trying to show some successes with our with our pilots and do you have any advice or

394
00:43:40,400 --> 00:43:46,160
kind of lessons learned you know from that perspective the portfolio perspective or the like

395
00:43:46,160 --> 00:43:54,640
introducing ML and AI to a large organization perspective that you would share with folks that

396
00:43:54,640 --> 00:44:00,960
are maybe similarly situated but earlier on in the process. Sure well I think the the biggest

397
00:44:00,960 --> 00:44:08,560
thing is to talk about it and to you know communicate I'm I think just in general that's that's

398
00:44:08,560 --> 00:44:14,720
the biggest thing I find between you know successful efforts and non successful efforts this goes

399
00:44:14,720 --> 00:44:22,240
well before my time at AAS is the clarity of that communication across the organization is key

400
00:44:23,200 --> 00:44:29,520
we've really tried to get our senior leaders on board and I've seen some really great commitment by

401
00:44:29,520 --> 00:44:37,120
our our COO in particular and even our CEO and talking about the capabilities and the need for

402
00:44:37,120 --> 00:44:45,840
our business to be to move kind of higher up the digital mastery you know curve and with with

403
00:44:45,840 --> 00:44:51,920
machine learning and AI being central to that and so getting that executive buy-in is always critical

404
00:44:52,560 --> 00:44:58,000
but then really starting to talk you know down down in the business where where stuff tends to happen

405
00:44:58,000 --> 00:45:04,000
right so the executive support is really important but there's people who are you know working in

406
00:45:04,000 --> 00:45:10,480
this data on a day-to-day basis who have some incredible you know sector matter expertise and

407
00:45:10,480 --> 00:45:16,880
some incredible fundamental knowledge of how the data works and getting those people engaged has

408
00:45:16,880 --> 00:45:22,720
been really important as well because I mean those are those are the people that usually end up

409
00:45:22,720 --> 00:45:29,440
doing the work and and getting them excited about it has been a great avenue for us. That's fantastic

410
00:45:29,440 --> 00:45:35,600
well congratulations on the success you've seen with these projects it sounds like you're doing

411
00:45:35,600 --> 00:45:41,680
really incredible work is there anything else that you'd want to leave folks with?

412
00:45:41,680 --> 00:45:50,960
maybe just you know I'm really committed to the value of of digital and the incredible power that

413
00:45:50,960 --> 00:45:56,480
you know analytics can add to a business you know I've seen firsthand the value it can drive

414
00:45:56,480 --> 00:46:03,440
you know in a variety industries and businesses and you know I just rude highly recommend to

415
00:46:03,440 --> 00:46:08,960
you know to business to business people out there that you know they spend the time to to

416
00:46:08,960 --> 00:46:14,720
understand the technology to demystify it because I think that's something that you know a lot of

417
00:46:14,720 --> 00:46:20,080
people you know if they're just reading kind of the news headlines are are kind of focused on

418
00:46:20,080 --> 00:46:25,920
the kind of the mystical aspect but at the end of the day this is just another or these are just

419
00:46:25,920 --> 00:46:31,840
more tools that you can have in your in your tool belt and you know really drive a lot of value

420
00:46:31,840 --> 00:46:38,160
in your organization for sure for sure well Nick thank you so much for taking the time and

421
00:46:38,160 --> 00:46:42,960
really for being so open with what you've been able to share with us I'm sure it's going to be

422
00:46:42,960 --> 00:46:49,680
very helpful to folks yeah now I'm really excited to be to be here and talk with people about it

423
00:46:49,680 --> 00:46:57,120
and um you know I hope to be able to share some more stuff in the future awesome thank you

424
00:47:02,720 --> 00:47:08,880
all right everyone that's our show for today for more information on Nick or any of the topics

425
00:47:08,880 --> 00:47:17,600
covered in this episode head on over to twimlai.com slash talk slash 150 as always thanks so much

426
00:47:17,600 --> 00:47:27,600
for listening and catch you next time

