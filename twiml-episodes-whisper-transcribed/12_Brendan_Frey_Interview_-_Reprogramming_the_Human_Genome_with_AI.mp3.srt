1
00:00:00,000 --> 00:00:16,240
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:16,240 --> 00:00:21,280
people doing interesting things in machine learning and artificial intelligence.

3
00:00:21,280 --> 00:00:24,400
I'm your host Sam Charrington.

4
00:00:24,400 --> 00:00:29,040
In earlier episodes of the podcast, we've talked about some of the many implications of machine

5
00:00:29,040 --> 00:00:34,400
learning and AI in health care, but we've not yet had an opportunity to dive deeply into

6
00:00:34,400 --> 00:00:36,160
this application area.

7
00:00:36,160 --> 00:00:41,680
Well, that changes now. I'm excited to share with you a really interesting conversation I had

8
00:00:41,680 --> 00:00:46,720
with Brendan Frye, professor of engineering and medicine at the University of Toronto,

9
00:00:46,720 --> 00:00:50,160
and co-founder and CEO of the startup Deep Genomics.

10
00:00:50,800 --> 00:00:53,040
You're going to love this show and learn a ton.

11
00:00:53,760 --> 00:00:58,880
I met Brendan at the rework Deep Learning Summit in San Francisco a few weeks ago,

12
00:00:58,880 --> 00:01:03,920
and I expect to share with you a few other conversations from that conference over the next few weeks.

13
00:01:05,040 --> 00:01:09,840
One of the questions I'm often asked is which AI events are worth going to?

14
00:01:10,400 --> 00:01:14,960
Well, there are a ton of them nowadays, and it can be difficult to separate the good from the

15
00:01:14,960 --> 00:01:21,040
bad. So what I'll be doing regularly here on the podcast is sharing some of the events on my radar.

16
00:01:21,680 --> 00:01:23,920
I'll be sharing them on the Twimble website as well.

17
00:01:23,920 --> 00:01:28,800
For March, I'm planning to be at a bunch of events in the Bay area.

18
00:01:28,800 --> 00:01:35,280
The week of the 6th, I'll be at AI by the Bay, which looks to be a really interesting technical

19
00:01:35,280 --> 00:01:41,680
conference, and next, the Google Cloud Developer Conference. The following week, I'll be at

20
00:01:41,680 --> 00:01:46,320
Strata Hadoop World, which is a great event for machine learning and analytics discussions,

21
00:01:46,320 --> 00:01:49,520
with a particular emphasis on data engineering and infrastructure.

22
00:01:49,520 --> 00:01:55,200
And then, the week of the 20th, I'm attending another couple of events by rework,

23
00:01:55,200 --> 00:01:58,880
this time their machine intelligence and autonomous vehicle summits.

24
00:01:59,680 --> 00:02:04,880
What I'm most excited about, however, and I'll only share this brief teaser now,

25
00:02:04,880 --> 00:02:10,640
is an event I'm organizing called the Future of Data Summit, which will take place in Las Vegas in

26
00:02:10,640 --> 00:02:15,120
May. Stay tuned. I'll share all the details on a future podcast.

27
00:02:15,120 --> 00:02:20,160
Going back to the Strata Hadoop Conference for a sec, you may remember that we partnered with

28
00:02:20,160 --> 00:02:25,680
O'Reilly last year to offer a free ticket to their AI and Strata conferences to lucky Twimble

29
00:02:25,680 --> 00:02:30,800
and AI listeners. Well, we're at it again. We've partnered with the good folks at O'Reilly

30
00:02:30,800 --> 00:02:36,560
to bring you another opportunity to win a free ticket to Strata Hadoop World in San Jose, California.

31
00:02:37,280 --> 00:02:42,560
Join Twimble and thousands of innovators, leaders, and practitioners at Strata Hadoop World to

32
00:02:42,560 --> 00:02:48,080
develop new skills, share best practices, and discover how tools and technologies are evolving

33
00:02:48,080 --> 00:02:55,040
to meet new challenges. One lucky listener will win a pass, but everyone can save 20% on registration

34
00:02:55,040 --> 00:03:00,640
with discount code PC Twimble. That's PC-TW-I-M-L.

35
00:03:01,680 --> 00:03:08,960
To enter, visit our brand new Facebook page at facebook.com slash Twimble AI, where you'll find

36
00:03:08,960 --> 00:03:14,880
full details. Of course, I'll link to the Facebook page in the show notes, which will be posted at

37
00:03:14,880 --> 00:03:21,120
Twimble AI dot com slash talk slash 12. Since the conference is coming up quickly, you'll only have

38
00:03:21,120 --> 00:03:26,400
until March 3rd to enter. Winners will be notified shortly thereafter and announced on the next

39
00:03:26,400 --> 00:03:31,600
podcast. One more quick note before we jump into the interview. Towards the end of my chat with

40
00:03:31,600 --> 00:03:37,280
Brendan, I mentioned a sci-fi series that I like, but I blank on the title. Well, this series is

41
00:03:37,280 --> 00:03:44,160
called the Xenogenesis Trilogy, and it's by Octavia Butler. It's also been re-released as Lilith's

42
00:03:44,160 --> 00:03:50,080
brood, so you may see that as well. In any case, I'll post a link to the books in the show notes,

43
00:03:50,640 --> 00:03:52,480
and now onto the show.

44
00:03:59,920 --> 00:04:06,560
So hello everyone, I've got Brendan Fry on the line with me. Brendan and I met recently at the

45
00:04:06,560 --> 00:04:12,560
Rework Deep Learning Summit in San Francisco, where he delivered a really, really great presentation

46
00:04:12,560 --> 00:04:19,280
called reprogramming the human genome. Why AI is needed? Brendan was kind enough to agree to

47
00:04:19,280 --> 00:04:24,400
discuss his presentation and work in the field here on the podcast. So welcome, Brendan.

48
00:04:25,040 --> 00:04:30,320
Hi Sam, thanks for having me on the show. I'm really excited about this conversation.

49
00:04:30,320 --> 00:04:37,920
You know, we've talked about deep learning and machine learning AI in general,

50
00:04:38,800 --> 00:04:46,800
and healthcare several times on the show. Not in a lot of detail, but just covering the news,

51
00:04:46,800 --> 00:04:52,960
and there's been a lot of advancement in this area. One of the things that we talked about was

52
00:04:52,960 --> 00:04:59,600
Beth Israel Deaconis did the work with applying deep learning to breast cancer detection.

53
00:05:00,480 --> 00:05:08,480
Google Deep Mind is active in applying deep learning to eye disease. And when I think about

54
00:05:08,480 --> 00:05:16,640
examples like the ones that I've tended to see, they are often, they often fit into the pattern of,

55
00:05:16,640 --> 00:05:21,360
hey, we've got a bunch of image data. We know deep learning is great for helping us

56
00:05:21,360 --> 00:05:27,520
kind of find patterns and image data. Let's apply deep learning algorithms to see if we can,

57
00:05:27,520 --> 00:05:33,520
you know, either augment or replace, you know, the medical technicians that are, you know,

58
00:05:33,520 --> 00:05:40,800
finding tumors and things like that. But when I heard and thought about your presentation and the

59
00:05:40,800 --> 00:05:46,720
way you walk through what you guys are doing, it struck me that, and let me know if this is fair,

60
00:05:46,720 --> 00:05:53,840
but it struck me that you guys are applying or trying to apply deep learning at a much

61
00:05:53,840 --> 00:06:00,160
more fundamental level, like looking at the, you know, interactions between proteins and things

62
00:06:00,160 --> 00:06:05,840
like that that create disease. And that strikes me as just super exciting, and that's why I wanted

63
00:06:05,840 --> 00:06:12,800
to really get, have this conversation. So, you know, maybe to get things started, you didn't start

64
00:06:12,800 --> 00:06:17,680
your research career in genomics, how did you find your way into the field?

65
00:06:18,240 --> 00:06:23,840
Yeah, so in the 1990s, I was a machine learning research, right? I did my PhD with Jeff Hinton,

66
00:06:23,840 --> 00:06:30,240
and we were looking at image data and speech and text as well. We published one of the first papers

67
00:06:30,240 --> 00:06:36,480
on deep learning in 1995, which appeared in science. And so really, those are good days,

68
00:06:36,480 --> 00:06:40,000
just discovering new algorithms and trying them out, but we didn't have big data sets,

69
00:06:40,000 --> 00:06:43,840
and we didn't have fast computers, and so, and so that was really a big bottleneck.

70
00:06:44,640 --> 00:06:51,200
Of course, that's completely changed now, but around 2002, by that time I was a professor,

71
00:06:51,200 --> 00:06:57,600
around 2002, my wife and I at the time discovered that the baby shows caring had a genetic problem.

72
00:06:58,480 --> 00:07:05,120
We went and saw a genetic counselor and had to deal with very difficult news. The feedback

73
00:07:05,120 --> 00:07:11,520
was it could be nothing or it could be a really big problem. So that was a really difficult

74
00:07:11,520 --> 00:07:17,760
experience emotionally to go through that and really changed my focus in terms of what I was

75
00:07:17,760 --> 00:07:24,320
doing as a researcher, and it decided to start working on vision and speech recognition and

76
00:07:24,320 --> 00:07:29,360
text analysis and really focus and said on the human genome and figuring out how to connect

77
00:07:29,360 --> 00:07:35,200
what's going on in people's DNA to to their health and also how to how to figure out how to treat

78
00:07:35,760 --> 00:07:44,400
treat disease. And so was my assessment of what you guys are doing relative to some of the examples.

79
00:07:44,400 --> 00:07:48,880
I provided, is that fair? How do you think about the the approach you're taking? Yeah, yeah,

80
00:07:48,880 --> 00:07:54,000
that's that's accurate. So the a lot of other players in this field are essentially leveraging

81
00:07:54,000 --> 00:07:59,840
their previous experience on on image analysis to to then look at medical images. Our approach is

82
00:07:59,840 --> 00:08:04,480
very, very different. We're starting with the genome as the input and the genome is just a long

83
00:08:04,480 --> 00:08:09,680
string of letters, ACG and T three billion of them from your mom and three billion from your dad.

84
00:08:10,320 --> 00:08:17,040
And the challenge there is really to to figure out what the language is. So so first of all the

85
00:08:17,040 --> 00:08:23,680
the language in the genome is not understood and how how words are put together to lead to to life

86
00:08:23,680 --> 00:08:28,640
essentially is not well understood. And so reverse engineering how the genome works is a big

87
00:08:28,640 --> 00:08:33,600
challenge. And then of course, once that's done figuring out how you can manipulate the genome,

88
00:08:33,600 --> 00:08:39,280
what you can do to to fix diseases is the second challenge. So yeah, I've been working on that for

89
00:08:39,280 --> 00:08:44,320
about 13 years and applying machine learning techniques to to crack that problem. And you're talk

90
00:08:44,320 --> 00:08:52,080
you presented some pretty staggering statistics. I think it was that the lifetime risk for

91
00:08:52,080 --> 00:08:59,920
a genetic related disease is something on the order of 65 percent and 8 million births per year

92
00:08:59,920 --> 00:09:08,080
with serious genetic disorders. Yeah, that's right. It's a big problem. And you know, we've

93
00:09:08,080 --> 00:09:12,480
we've been able to sequence the genome and now we can sequence individual genomes for about

94
00:09:12,480 --> 00:09:17,440
a thousand dollars and in a few years it should cost less than a trip to the grocery store to

95
00:09:17,440 --> 00:09:23,360
have your genome sequenced. And so we can read the text of your genome, but the tragic truth is

96
00:09:23,360 --> 00:09:28,640
that we are not currently able to accurately figure out what's wrong with you if you have a

97
00:09:28,640 --> 00:09:33,360
particular mutation, let alone figure out how to fix it. And so there's really a big gap. I call

98
00:09:33,360 --> 00:09:38,720
that the genotype phenotype gap. There's a big gap between our ability to read the text of the

99
00:09:38,720 --> 00:09:43,600
genome and the and make sense of it and then act on it. And so those statistics you gave like 8

100
00:09:43,600 --> 00:09:50,160
million births per year with a serious genetic disorder. That's it's kind of horrendous when

101
00:09:50,160 --> 00:09:53,920
you think we can sequence their genomes. We can find their mutations, but we don't really have

102
00:09:53,920 --> 00:09:58,480
the ability currently to figure out what's going wrong. And that's what we're working on. So both

103
00:09:58,480 --> 00:10:02,400
in my research lab and now with deep genomics, we're figuring out how to how to understand those

104
00:10:02,400 --> 00:10:09,040
mutations and what their implications are. So you know, I'd like to I'd like to understand all

105
00:10:09,040 --> 00:10:15,120
this better. And I'd like the audience to understand all this better. You know, what's the way?

106
00:10:15,120 --> 00:10:21,600
How can you give us kind of a, you know, push us off the deep end perhaps into biology and genomics?

107
00:10:21,600 --> 00:10:27,040
How, you know, how biology works and what are the various issues and implications so that we can

108
00:10:27,040 --> 00:10:33,440
start to have a conversation about this? Yeah, sure. So a common pattern in the field right now is

109
00:10:33,440 --> 00:10:37,040
people get a lot of data and then they kind of say, well, let's just throw it in a big bucket and

110
00:10:37,040 --> 00:10:42,960
give it to machine learning researchers and they'll solve it all. And I think that's a really

111
00:10:42,960 --> 00:10:50,800
bad approach. So our approach is very much a systems approach and that we try to understand biology.

112
00:10:51,520 --> 00:10:58,640
We bring to bear very carefully all biological knowledge that we can ascertain and then we build

113
00:10:58,640 --> 00:11:04,480
our machine learning systems to mimic that biology. And so for example, DNA is replicated when

114
00:11:04,480 --> 00:11:10,560
a cell divides DNA is replicated. So that's an important process. The way DNA is used within

115
00:11:10,560 --> 00:11:17,760
a cell is DNA is transcribed into RNA molecules. RNA molecules are chopped up and put back together

116
00:11:17,760 --> 00:11:24,720
again in a process called splicing. The splice RNA molecules then they are translated into proteins.

117
00:11:24,720 --> 00:11:28,960
And then the proteins go off and do things in the cell. And one of the things the proteins do is they

118
00:11:28,960 --> 00:11:34,880
bind to DNA. So the proteins interact with DNA and they actually interact with DNA in a way that

119
00:11:34,880 --> 00:11:41,600
controls transcription. The proteins also interact with RNA in a way that controls splicing and

120
00:11:41,600 --> 00:11:47,680
similarly processes of translation. And so you can think of biology as these multiple layers

121
00:11:47,680 --> 00:11:54,400
of processing, complex interactions, highly nonlinear, and really the phenotype that we see whether

122
00:11:54,400 --> 00:12:01,280
it's maybe cancer or neurological disorder is something that's gone wrong within one of these

123
00:12:01,280 --> 00:12:07,680
processes. And so that's just a brief summary of what's actually going on in the biology.

124
00:12:08,720 --> 00:12:14,960
So in between the DNA and your phenotype, multiple layers of complex biological processes that

125
00:12:14,960 --> 00:12:20,240
are nonlinear and combinatorial. And so what we do is we build machine learning models for each

126
00:12:20,240 --> 00:12:26,400
of these processes. So right now in the biology community there's just an explosion of data sets

127
00:12:26,400 --> 00:12:31,840
profiling what's going on within cells, essentially allowing scientists to peer right inside of cells

128
00:12:31,840 --> 00:12:37,440
and measure at the single molecule level what's going on. And so there's this rapid growth of data

129
00:12:37,440 --> 00:12:43,280
sets in the last few years and it's growing exponentially. And what we do is we use those massive

130
00:12:43,280 --> 00:12:51,200
data sets to train models to mimic these cellular processes. And like to give you an idea,

131
00:12:51,200 --> 00:12:55,440
the kinds of data sets we're looking at, we have trillions of data points that we use to train

132
00:12:55,440 --> 00:13:04,080
models. Wow. So for any given one of these interactions, you know, before we even start talking

133
00:13:04,080 --> 00:13:11,040
about the computational side of things, just as a community of biologists, how well do we understand

134
00:13:11,040 --> 00:13:16,800
what's really happening in the processes and when we have a data set that we're looking at?

135
00:13:18,080 --> 00:13:22,480
Yeah. Well, that's one of the things that we spent a lot of time on here at Deep Genomics

136
00:13:23,200 --> 00:13:29,280
is basically taking known biology and then figuring out what kinds of data we have that allow us

137
00:13:29,280 --> 00:13:35,040
to better model that known biology and then also try to account for unknown biology as well,

138
00:13:35,040 --> 00:13:40,080
which is one of the nice things that the machine learning offers. People on the past have tried

139
00:13:40,080 --> 00:13:45,280
literally writing down programs, computer programs to try to simulate what's going on in a cell.

140
00:13:45,280 --> 00:13:50,480
And then you might guess those, yeah, you might guess that kind of approach breaks pretty easily.

141
00:13:51,200 --> 00:13:55,280
First of all, we don't know all the rules. Second of all, quantities in the cell are real value.

142
00:13:55,280 --> 00:14:00,080
They're not binary and logical. And so that approach doesn't really work that well.

143
00:14:00,080 --> 00:14:04,320
People have also tried to write down stochastic differential equations describing the

144
00:14:04,320 --> 00:14:10,480
concentrations of molecules in the cell. And that'll work for small sort of very simple,

145
00:14:10,480 --> 00:14:14,160
contained systems where there aren't many molecules that kind of approach can work,

146
00:14:14,160 --> 00:14:18,400
but it won't work for for living cells. There's just too many different molecules

147
00:14:18,400 --> 00:14:22,960
and the processes are too complex. So the approach that we take is the machine learning approach.

148
00:14:22,960 --> 00:14:27,440
We can measure different data sets for these different molecules and then we train machine learning

149
00:14:27,440 --> 00:14:31,840
techniques to mimic the relationships between those data sets that then emerge due to these

150
00:14:31,840 --> 00:14:38,800
biological processes. Is there some characterization for how many relationships there are?

151
00:14:38,800 --> 00:14:43,280
Well, we have a roadmap. We have a technology roadmap, a deep genomics,

152
00:14:43,280 --> 00:14:47,280
which lists all the different modules that we were trying to account for.

153
00:14:47,280 --> 00:14:53,840
And we have a couple dozen described in our roadmap. But the number is much larger than that

154
00:14:53,840 --> 00:15:01,040
and growing every year as well. But having said that, it's just sort of a notion of diminishing

155
00:15:01,040 --> 00:15:06,080
returns. You can get quite a bit out of just modeling one or two processes. For example,

156
00:15:06,080 --> 00:15:11,200
I mentioned splicing where our name molecule is chopped up and then glued back together again.

157
00:15:12,160 --> 00:15:18,320
And that process depends on words essentially in the RNA molecule sequence. So RNA like DNA

158
00:15:18,960 --> 00:15:24,000
is a sequence of letters. And the machinery inside of the cell recognizes little patterns of

159
00:15:24,000 --> 00:15:28,240
letters or words. And those words tell the machinery how to cut up the RNA.

160
00:15:28,240 --> 00:15:36,160
And those letters represent proteins. So the sequence of words is a sequence of proteins in

161
00:15:36,160 --> 00:15:43,760
the RNA or DNA. Is that right? Oh, there's two kinds of words in there. So one kind of

162
00:15:43,760 --> 00:15:49,920
word in the RNA molecule sequence of letters does encode a protein. So it corresponds to amino acids

163
00:15:49,920 --> 00:15:54,880
that make the protein. But there are other words in the RNA that are more like control commands.

164
00:15:54,880 --> 00:15:59,200
So it's kind of like in a computer, you have print statements and then you have control logic.

165
00:15:59,200 --> 00:16:03,600
Right. Right. And the print statements are like proteins. But what's even more important

166
00:16:03,600 --> 00:16:08,160
than the print statements is the control logic itself. That's what creates the system that's

167
00:16:08,160 --> 00:16:12,080
responsive to its environment and that can do different things. Otherwise, we just keep printing

168
00:16:12,080 --> 00:16:19,440
the same thing over and over. Okay. And so the ability of the system to respond to different

169
00:16:19,440 --> 00:16:25,920
circumstances and be dynamic is really crucial. And that's achieved with these control statements,

170
00:16:25,920 --> 00:16:33,440
if you like, that are also embedded within the RNA sequence. So we have a system that was trained

171
00:16:33,440 --> 00:16:40,160
to mimic this process of splicing. And just to give you an example, one of the leading causes

172
00:16:40,160 --> 00:16:47,120
of infant mortality in North America is spinal muscular atrophy. And there's a mutation in the DNA

173
00:16:47,120 --> 00:16:53,840
that leads to this disease. And that mutation is in the RNA molecule as well. And it causes this

174
00:16:53,840 --> 00:17:00,080
process of splicing to go wrong. It leads to so normally a certain chunk of RNA is included in

175
00:17:00,080 --> 00:17:07,680
in the protein that makes up a certain gene called SMN1 or SMN2. And if there's a mutation,

176
00:17:07,680 --> 00:17:13,600
then that chunk is left out and that leads to the disease. Usually those infants die within

177
00:17:13,600 --> 00:17:22,320
the first year of birth. Recently, a therapy was given FDA approval. And what's interesting

178
00:17:22,320 --> 00:17:27,520
about that therapy is that it doesn't target that particular mutation. It actually modifies

179
00:17:27,520 --> 00:17:32,800
another part of the RNA molecule, which goes to show you the importance of commonatorics.

180
00:17:32,800 --> 00:17:37,280
Right? This is not, the biology is not something where there's a correlative effect or there's

181
00:17:37,280 --> 00:17:41,680
a particular mutation. You just need to fix that one mutation quite often. You need to change

182
00:17:41,680 --> 00:17:45,600
something else in order to fix a problem that's occurring in the genome.

183
00:17:47,280 --> 00:17:54,080
And so how I'm just thinking about the scale of this system and the interactions. You mentioned

184
00:17:55,280 --> 00:18:03,600
on the order of a dozen molecules or sorry modules. For a given disease,

185
00:18:04,400 --> 00:18:11,360
is it typically only one direct cause or they're often combinations of things happening

186
00:18:11,360 --> 00:18:18,160
in these different subsystems that is what causes the disease to spring forth?

187
00:18:18,160 --> 00:18:22,640
Yeah, that's a good question. And one thing I've learned about biology is almost anything goes.

188
00:18:24,400 --> 00:18:29,520
And so there's sort of the what's called the central dogmobology, which is very simple. But then

189
00:18:29,520 --> 00:18:34,800
you realize that a lot more complicated things can happen. So yeah, in the context of diseases,

190
00:18:34,800 --> 00:18:40,880
there are diseases called Mendelian disorders, which you can think of them as just a single mutation

191
00:18:40,880 --> 00:18:48,800
if you like, and one gene and a very simple relatively, relatively simple mechanism.

192
00:18:48,800 --> 00:18:53,520
It's still hard to find those, still hard to figure out how to treat those diseases, but

193
00:18:53,520 --> 00:18:57,840
but relatively simple in the sense it's just one mutation or one gene. But at the other end of

194
00:18:57,840 --> 00:19:04,880
the spectrum is the much more complicated situation where you have many different mechanisms or many

195
00:19:04,880 --> 00:19:12,080
different causes that combine together to result in the disorder or the disease. So a couple of

196
00:19:12,080 --> 00:19:17,440
examples there would be diabetes or autism spectrum disorder. And so if you take autism spectrum

197
00:19:17,440 --> 00:19:23,440
disorder as an example, the phenotype isn't even simply described. It's the whole range of phenotypes

198
00:19:23,440 --> 00:19:31,440
really. And also when you look at the heritability of the disorder, you find out that it can't just be

199
00:19:31,440 --> 00:19:35,920
pinned down to a single gene. It's many different genes. And even within those genes,

200
00:19:35,920 --> 00:19:40,960
it's not just a mutation in a particular location. It's a wide range of different genetic variability,

201
00:19:40,960 --> 00:19:46,640
different mutations at different places within that gene. And so the kinds of systems

202
00:19:46,640 --> 00:19:53,360
are building can be used for both situations. So we can pin down the single mutation that's

203
00:19:53,360 --> 00:19:59,040
causing a disease. And we can also use our systems to understand the complex combination of mutations

204
00:19:59,040 --> 00:20:04,400
that that is involved in a disease. Okay. Let me take a maybe a little bit of a tangent.

205
00:20:05,280 --> 00:20:10,560
There were a couple of technologies that you mentioned in your presentation that I wanted to hear

206
00:20:10,560 --> 00:20:16,400
a little bit about. The first is one that I've heard quite a bit about recently, but haven't really

207
00:20:16,400 --> 00:20:23,520
had a chance to dive into it. And that is CRISPR. It sounds like, well, tell us about CRISPR. What is

208
00:20:23,520 --> 00:20:31,280
that and what are the implications of it? Yeah. So CRISPR, Cas9, it's what's commonly referred to

209
00:20:31,280 --> 00:20:38,960
as a gene editing system. And it's a fairly straightforward idea. You basically program if you

210
00:20:38,960 --> 00:20:44,720
like a template into the into the system. So it's a group of proteins effectively and other

211
00:20:44,720 --> 00:20:49,680
molecules. And you essentially program a template into those. And then in living cells,

212
00:20:49,680 --> 00:20:58,320
you insert these molecules of system. And then the template will find its match within the

213
00:20:58,320 --> 00:21:05,200
within the DNA. And then once it's found a match, the system will then edit the DNA according to

214
00:21:05,200 --> 00:21:10,880
your specification. So there's different ways that can happen. It could be as simple as the template

215
00:21:10,880 --> 00:21:15,760
finds the match. And then it sticks there. Or it could be that the template finds a match. And then

216
00:21:15,760 --> 00:21:22,080
and then the DNA is is actually edited. So it's changed. And that's so that's basically an

217
00:21:22,080 --> 00:21:29,680
example of gene editing, which CRISPR Cas9 is one instance. And so how does that play into the

218
00:21:29,680 --> 00:21:36,080
kinds of work that you're doing in your lab and at the company? Yeah. So so there are a couple

219
00:21:36,080 --> 00:21:42,000
problems with with gene editing systems. And one of them is off target effects. And so and so the

220
00:21:42,000 --> 00:21:48,960
template might not be perfectly specific, which means the the system might bind to the DNA in two

221
00:21:48,960 --> 00:21:54,240
different places and edit the DNA in two different places. And so one of the places the correct one,

222
00:21:54,240 --> 00:21:58,880
maybe there's a mutation you're trying to fix to address some sort of a disease. But what happens

223
00:21:58,880 --> 00:22:03,680
is the system will also bind somewhere else to some other region of the DNA and then edit the DNA

224
00:22:03,680 --> 00:22:07,680
there. And that could actually lead to a problem. And so that and that's called an off target effect.

225
00:22:07,680 --> 00:22:13,840
The other one is that suppose the other problem with these kinds of systems as supposed as a

226
00:22:13,840 --> 00:22:20,720
particular mutation that you're trying to correct trying to fix. It may be that the sequence surrounding

227
00:22:20,720 --> 00:22:27,040
that mutation is just not good in terms of designing a template. So you can't actually design a

228
00:22:27,040 --> 00:22:31,840
template in your CRISPR Cas9 system that will that will work properly in terms of finding that

229
00:22:31,840 --> 00:22:36,480
mutation and then correcting the mutation. And so there's a couple different problems with these

230
00:22:36,480 --> 00:22:41,680
gene editing systems. Another problem is delivery. Just has to do with the fact that the the machinery

231
00:22:41,680 --> 00:22:48,080
you need to get inside of the cell involves several different molecules. And each of those molecules

232
00:22:48,080 --> 00:22:52,160
has different properties in terms of in terms of whether or not it can successfully be

233
00:22:53,600 --> 00:22:58,560
be delivered into the cell. And so there's several different issues with gene editing systems.

234
00:22:59,040 --> 00:23:03,040
And there's a few different ways in which our technology that we develop that deep genome is

235
00:23:03,040 --> 00:23:08,880
can be helpful. So one of them is because we we have these machine learning systems that can mimic

236
00:23:08,880 --> 00:23:15,040
biological processes. One biological process is this template matching. So how well the template

237
00:23:15,040 --> 00:23:20,000
matches the DNA that's actually a biochemical process that occurs within the cell. And so our

238
00:23:20,000 --> 00:23:27,280
systems can identify off target effects and predict predict what might happen. The other example

239
00:23:27,280 --> 00:23:32,960
is when you can't actually edit a particular mutation. So there's a mutation that a patient has

240
00:23:32,960 --> 00:23:38,400
and you'd like to fix it. You can't actually edit that mutation because the you can't design

241
00:23:38,400 --> 00:23:45,520
an appropriate template. So then what do you do? Well one idea is maybe you can edit some other

242
00:23:45,520 --> 00:23:51,280
region of the DNA and somehow there will be some sort of compensatory effect. But in order to do

243
00:23:51,280 --> 00:23:56,480
that you actually need a model. You need a system that can mimic how that DNA is going to be

244
00:23:56,480 --> 00:24:01,840
processed because you can't you can't just fix the mutation. You need to introduce a mutation

245
00:24:01,840 --> 00:24:07,440
somewhere else that is going to correct the problem introduced by the first mutation. So for

246
00:24:07,440 --> 00:24:13,360
example the the first mutation the disease mutation may cause a problem with splicing. And what you'd

247
00:24:13,360 --> 00:24:18,000
like to do is introduce a mutation somewhere else that will reverse that problem with splicing.

248
00:24:18,000 --> 00:24:22,480
Right. And again that up and that again that that requires that you have some sort of a model

249
00:24:22,480 --> 00:24:27,040
for how the cell is going to process that piece of DNA to control splicing and that's the kind

250
00:24:27,040 --> 00:24:34,480
of model we build. Okay so you guys the work that you're doing can improve these genome editing

251
00:24:34,480 --> 00:24:42,640
systems and at the same time the the work that you're doing around diseases the genome editing

252
00:24:42,640 --> 00:24:51,280
system is one way that this work would eventually be deployed if you will put it into practice.

253
00:24:51,280 --> 00:24:56,560
That's right at this point in time in deep genomics we have not developed any products to address

254
00:24:56,560 --> 00:25:01,600
that particular therapeutic approach the gene editing system approach but it is a research

255
00:25:01,600 --> 00:25:08,800
endeavor at this point. And so why have I heard so much about CRISPR you know maybe not this year

256
00:25:08,800 --> 00:25:12,800
but towards the tail end of last year is it just that it was you know new or with their new research

257
00:25:12,800 --> 00:25:19,200
results or is it better faster cheaper like what's the what was the big deal with research? Yeah yeah

258
00:25:19,200 --> 00:25:24,400
it's leading to all sorts of breakthroughs in terms of research so the ability of genome biologists

259
00:25:24,400 --> 00:25:30,640
to conduct different experiments different screens fabulous tool for research and in terms of medicine

260
00:25:30,640 --> 00:25:36,080
there's a lot of promise there are some issues that need to be worked out but those are being

261
00:25:36,080 --> 00:25:41,760
looked at and and I think it's very likely that it'll it'll prove to be a useful therapeutic technique

262
00:25:41,760 --> 00:25:48,400
under some circumstances in any case. And so the other question I had in terms of just the

263
00:25:48,400 --> 00:25:53,920
context in which you're you're doing your work is you mentioned and you mentioned this in early

264
00:25:53,920 --> 00:26:02,720
in our conversation now is the increasing drive towards cheaper and cheaper sequencing and at

265
00:26:02,720 --> 00:26:07,200
the deep learning summit you mentioned some new technology that you were expecting to drive the

266
00:26:07,200 --> 00:26:14,320
cost down to as little as $20 within the next year or so what can you give me a kind of a quick

267
00:26:14,320 --> 00:26:21,120
summary of the activity there? Yeah yeah sure there's just as I mentioned before this rapidly

268
00:26:21,120 --> 00:26:25,920
growing diverse array of different biotechnologies that allow us to measure what's going on inside

269
00:26:25,920 --> 00:26:31,200
of cells and genome sequencing is of course an important one it's the one that kind of gives us

270
00:26:31,200 --> 00:26:35,840
the software if you like for the the basic source code of the of the person or the cells

271
00:26:36,560 --> 00:26:42,880
and yeah there's technologies like the Oxford Nanopore technologies and other companies have

272
00:26:42,880 --> 00:26:48,800
similar technologies which will which will allow cheaper sequence much cheaper sequencing genome

273
00:26:48,800 --> 00:26:53,440
sequencing. But that's not the only technology that's helpful there's there's other kinds of

274
00:26:53,440 --> 00:26:58,080
methods that allow you to for example look inside of DNA and see which genes are being transcribed

275
00:26:58,080 --> 00:27:04,800
and measure how quickly they're being transcribed or the transcription rate of the gene techniques

276
00:27:04,800 --> 00:27:08,800
that allow us to measure quantitatively how much protein is being produced and where the protein

277
00:27:08,800 --> 00:27:14,400
is being located within the cell by the by the molecules that that shuttle proteins around.

278
00:27:14,400 --> 00:27:18,720
So there's a lot of different kinds of biotechnologies being developed that allow us to essentially

279
00:27:18,720 --> 00:27:25,920
look inside of cells and measure what's going on. Okay so lots of stuff going on you know maybe

280
00:27:25,920 --> 00:27:30,560
let's yeah I've kind of been just trying to satisfy some curiosity because I've had about

281
00:27:30,560 --> 00:27:35,760
the biological side of this but maybe let's kind of bring the conversation to machine learning

282
00:27:35,760 --> 00:27:42,800
and deep learning and maybe let's start by talking through you know prior to the work that you

283
00:27:42,800 --> 00:27:50,240
and others are doing to apply deep learning it sounds like machine learning a traditional machine

284
00:27:50,240 --> 00:27:55,760
learning linear regression and things like that were applied to these types of problems well how

285
00:27:55,760 --> 00:28:04,800
was talk about the kind of the standard to date approach. Sure yeah you know and I should emphasize

286
00:28:04,800 --> 00:28:10,960
that deep genomics the word deep is is referring not just to deep learning but also these deep layers

287
00:28:10,960 --> 00:28:16,480
of biological processes that get stacked upon one another that relates DNA to the phenotype

288
00:28:17,120 --> 00:28:21,440
and really that's what's most crucial and as you might guess for each one of these modules the

289
00:28:21,440 --> 00:28:26,320
first thing we do is try linear regression and it's the simplest technique quite often the best

290
00:28:26,320 --> 00:28:31,840
technique but when you have a lot of data it does it does help to to look at more sophisticated

291
00:28:31,840 --> 00:28:37,760
methods and so deep learning is a big part of what we do with deep genomics. Okay yeah so really

292
00:28:39,520 --> 00:28:44,560
in in biology two approaches have been taken on supervised learning and supervised learning

293
00:28:45,440 --> 00:28:52,400
and so way way back in the late 1990s people trained hidden markup models on on DNA sequences

294
00:28:53,440 --> 00:28:58,880
and those hidden markup models were able to learn patterns that indicate the starts of genes

295
00:28:58,880 --> 00:29:04,480
and the ends of genes and the locations of axons within the genes the axons are those parts of

296
00:29:04,480 --> 00:29:08,320
the genes that actually they're like the print statements they're the parts of the genes that tell

297
00:29:08,320 --> 00:29:13,680
you what the protein content is. Okay and so yeah that was back in the late 1990s researchers were

298
00:29:13,680 --> 00:29:20,160
training hidden markup models to to model gene structure. And can you give us a 30,000 foot

299
00:29:20,160 --> 00:29:27,920
view into what a hidden markup model is? Oh yeah sure so a hidden markup model is like a machine and

300
00:29:27,920 --> 00:29:33,680
of course simulated inside of the computer that it has several different states and the the model

301
00:29:33,680 --> 00:29:40,240
can switch back and forth between different states. And so for example it might be in the promoter

302
00:29:40,240 --> 00:29:46,240
so so the structure of a gene is there's a promoter there's an axon and then there's an intron and

303
00:29:46,240 --> 00:29:50,400
there's an axon and there's an intron and that just alternates until the end of the gene. There's

304
00:29:50,400 --> 00:29:55,120
a couple other parts of the gene but for simplicity that's just that's just say those are the components

305
00:29:55,120 --> 00:29:59,680
of the gene. So the hidden markup model would start off in the promoter state and then it was

306
00:29:59,680 --> 00:30:05,840
switched to the axon state and then back to the intron state and then back to the back and forth

307
00:30:05,840 --> 00:30:12,240
right. And so that's so that's the hidden markup model has a finite set of states and then there's

308
00:30:12,240 --> 00:30:17,920
a model for how the or probability distribution that describes how the model switches between states.

309
00:30:18,560 --> 00:30:23,840
So for example if you're in the promoter state then there's a high probability that you'll switch

310
00:30:23,840 --> 00:30:27,600
to the axon state. And if you're in the axon state there's a high probability switch to the

311
00:30:27,600 --> 00:30:32,000
intron state. If you're in the intron state there's a high probability switch to the axon state

312
00:30:32,000 --> 00:30:36,640
and so on. Okay. And so it's a probabilistic model that just allows this machine to switch back

313
00:30:36,640 --> 00:30:41,680
and forth between these different states. And then for each of the states part of the hidden

314
00:30:41,680 --> 00:30:46,880
markup model is also a description of what the data will look like in that state. And so for

315
00:30:46,880 --> 00:30:52,880
example when there's a transition from the axon state to the intron state the hidden markup model

316
00:30:52,880 --> 00:30:59,760
also has a component or a probability distribution over what the DNA symbols will look like at that

317
00:30:59,760 --> 00:31:06,480
transition point. And so if you run the hidden markup model just just simulate it which means

318
00:31:06,480 --> 00:31:10,640
let it flip back and forth between these different states and for each state let it generate some

319
00:31:10,640 --> 00:31:15,360
of the DNA sequence. If you run the hidden markup model you'll end up with a synthetic if you like

320
00:31:15,360 --> 00:31:20,560
a synthetic gene sequence. Okay. And the way the hidden markup model is trained is to make the

321
00:31:20,560 --> 00:31:26,160
synthetic gene sequence the output of the hidden markup model match the real data as best as possible.

322
00:31:26,160 --> 00:31:31,920
And so in the late 1990s researchers trained these hidden markup models using actual examples of

323
00:31:31,920 --> 00:31:37,520
DNA sequences and these models were able to automatically learn what the structure of a DNA

324
00:31:37,520 --> 00:31:42,080
sequence looks like. So they were able to learn that there's a promoter, there's an axon and an

325
00:31:42,080 --> 00:31:48,320
intron and that there's alternation between these axons and introns. So that's one example and

326
00:31:48,320 --> 00:31:53,120
that's unsupervised learning and there are lots of other examples of how unsupervised learning has

327
00:31:53,120 --> 00:32:01,840
been used in genome biology ranging from as I said modeling DNA to to actually just visualizations

328
00:32:01,840 --> 00:32:08,000
of dimensionality reduction taking taking for example expression gene expression measurements

329
00:32:08,000 --> 00:32:13,120
which would be say 22,000 gene expression measurements and compressing them down to a three

330
00:32:13,120 --> 00:32:18,720
dimensional or a two dimensional representation for visualization. So the whole wide range of

331
00:32:18,720 --> 00:32:24,000
different uses of unsupervised learning. And then the other the other process has been taken

332
00:32:24,000 --> 00:32:29,040
to supervised learning where you're actually trying to solve a very specific task and probably the

333
00:32:29,040 --> 00:32:35,840
one of the earliest uses of supervised learning in the context of genetic medicine as what was

334
00:32:35,840 --> 00:32:40,800
called the genome wide association study. And in the genome wide association study what you do is

335
00:32:40,800 --> 00:32:50,160
you measure for each patient a what's called the genotype which is just a measure of a variety of

336
00:32:50,160 --> 00:32:55,680
mutations. So those mutations might be measured using a micro array. People might have heard of

337
00:32:55,680 --> 00:33:02,720
the name SNEP array and so SNEP stands for single nucleotide polymorphism and that's just a

338
00:33:03,280 --> 00:33:09,760
location within your DNA which could have a mutation in it. And so these SNEP arrays would measure

339
00:33:09,760 --> 00:33:15,600
say 500,000 different possible mutations in your in your DNA. Another way you might measure

340
00:33:15,600 --> 00:33:20,480
genotype is whole genome sequencing. So you'd literally read out the three billion letters or if you

341
00:33:20,480 --> 00:33:25,200
have if you can do it for both your paternal and maternal DNA you'd have six six billion letters.

342
00:33:26,560 --> 00:33:31,920
And so whatever you however you go measuring this genotype you can essentially think of it as a

343
00:33:31,920 --> 00:33:41,600
vector. So it's going to be a sequence of of of letters ACG and T. So for 500 nucleotide array you

344
00:33:41,600 --> 00:33:48,800
have 500 letters for a 500,000 nucleotide SNEP array you'd have 500,000 letters and then you can

345
00:33:48,800 --> 00:33:57,600
imagine encoding that vector as a binary vector. So the letters ACG and T you can encode it using

346
00:33:57,600 --> 00:34:04,960
one hot encoding. So A is 1, 0, 0, 0, C would be 0, 1, 0, 0. So there's different ways of doing that

347
00:34:04,960 --> 00:34:10,000
or what's often done is what you do is you compare you compare the person's genetics to the reference

348
00:34:10,000 --> 00:34:16,480
genome and so then you represent whether or not they have a mutation there compared to the

349
00:34:16,480 --> 00:34:21,680
the reference genome something like that. So so basically though you represent the person's

350
00:34:21,680 --> 00:34:28,000
genetics as a big long vector of zeros and ones and then what you do is use linear regression to

351
00:34:28,000 --> 00:34:31,600
try to predict the phenotype. So you've got a whole bunch of patients with cancer and a whole

352
00:34:31,600 --> 00:34:37,760
bunch of patients without cancer and and then you just try to predict the whether or not they have

353
00:34:37,760 --> 00:34:42,720
cancer using linear regression. That's what a genome-wide association study is. So it's probably the

354
00:34:42,720 --> 00:34:48,800
simplest and and one of the original uses of machine learning in in genomic medicine. Okay.

355
00:34:48,800 --> 00:34:54,000
Okay. And what are the challenges associated with that approach?

356
00:34:55,520 --> 00:34:59,360
Well if you think about it, what that approach is essentially assuming is that your phenotype is

357
00:34:59,360 --> 00:35:08,800
a linear function of your genetics. Exactly. You mean it's not. And so you know we already talked

358
00:35:08,800 --> 00:35:13,600
about these complex non-linear biological processes that relate your genetics to your phenotype

359
00:35:13,600 --> 00:35:21,040
and we know from experience that this relationship is not linear. And so it's it's a it's an assumption

360
00:35:21,040 --> 00:35:28,080
that has been used successfully to find mutations that are involved in disease but it doesn't

361
00:35:28,080 --> 00:35:33,200
really accurately mimic the biological process. And so there are a few consequences of that

362
00:35:33,200 --> 00:35:39,200
of that limitation and and one of them is that the is that the genome the genome-wide association

363
00:35:39,200 --> 00:35:44,720
study is not guaranteed to find the causal mutation. Okay. And so it may actually find a mutation

364
00:35:44,720 --> 00:35:50,960
that isn't rich, for example, that is common in patients with with cancer but it's not guaranteed

365
00:35:50,960 --> 00:35:55,760
to be the mutation that actually caused the disease. And that's a big problem if you're trying to find

366
00:35:55,760 --> 00:36:01,360
a drug or a therapy to treat the disease because that mutation will be the wrong one. Now they're

367
00:36:01,360 --> 00:36:07,040
their techniques called fine mapping where you you look for nearby mutations and try to try to

368
00:36:07,040 --> 00:36:11,120
couple up those mutations with the one you found in the genome-wide association study

369
00:36:11,120 --> 00:36:17,280
and that that fine mapping approach has been used to to find the the causal mutation the one

370
00:36:17,280 --> 00:36:22,880
that should be treated with the drug but is still limited and doesn't it doesn't solve all of the

371
00:36:22,880 --> 00:36:30,160
problems. And I guess there are a few different other issues and one of them one of them is the

372
00:36:30,160 --> 00:36:36,240
amount of data that's required. And so because of the way the genome-wide association study works

373
00:36:36,240 --> 00:36:41,520
if you think about it there's three billion letters in the genome, three billion possible places

374
00:36:41,520 --> 00:36:46,880
is the commutation. And for each of those locations you're going to try to use that location to

375
00:36:46,880 --> 00:36:50,400
predict whether or not the person has cancer and then compare it against the experimental data.

376
00:36:51,120 --> 00:36:55,760
And so there's really three billion different places you can look. And the problem is if you don't

377
00:36:55,760 --> 00:37:02,880
have much data just by random chance one of those locations is going to match up with the phenotype

378
00:37:02,880 --> 00:37:06,800
that is just even if the DNA is just noise even if you're just generating a whole bunch of noise

379
00:37:06,800 --> 00:37:11,600
patterns you do that for your cases and your controls just by chance one of the locations one of

380
00:37:11,600 --> 00:37:15,920
the positions in the genome you're going to get a good agreement between that mutation and whether

381
00:37:15,920 --> 00:37:22,800
or not the person has a so-called cancer even though it's just noise it's meaningless. And so

382
00:37:22,800 --> 00:37:29,040
and so so many get a lot of false positives. Yeah that's right a large number of false positives.

383
00:37:29,040 --> 00:37:33,360
Okay. And the only way to get rid of that in a genome-wide association study is collect more

384
00:37:33,360 --> 00:37:38,400
and more data and and that's the way you get rid of those false positives. But the problem there is

385
00:37:38,400 --> 00:37:43,200
meaning you're not addressing you're trying to address it through kind of brute force statistics as

386
00:37:43,200 --> 00:37:49,120
opposed to a better technique. That's right that's right you're just trying to get so much data

387
00:37:49,120 --> 00:37:53,200
the overwhelmed the the fact that you have a model of what's really going on well. So the

388
00:37:53,200 --> 00:37:58,480
approach we take which is this deep learning approach allows us to build models that take us from

389
00:37:58,480 --> 00:38:04,400
the DNA to these intermediate molecular phenotypes or cell variables if you like variables representing

390
00:38:04,400 --> 00:38:10,080
things like transcription and splicing. And those intermediate biological processes are really

391
00:38:10,080 --> 00:38:16,160
what's crucial for disease. And so by modeling those explicitly we can take this big sequence of

392
00:38:16,160 --> 00:38:21,280
three billion letters and user machine learning technique to map it down to a much smaller space

393
00:38:21,280 --> 00:38:26,240
that represents what's really going on inside of the cell. And then we can relate that much smaller

394
00:38:26,240 --> 00:38:30,880
and more compact representation with the phenotype whether the person has cancer or not.

395
00:38:30,880 --> 00:38:38,720
Okay so strikes me then that you know basically what you guys are doing is feature engineering

396
00:38:38,720 --> 00:38:42,720
for this particular type of system. Is that a fair way to think about it?

397
00:38:43,680 --> 00:38:51,520
It's a it to some degree yes it's um I would say instead of feature engineering it's biological

398
00:38:51,520 --> 00:38:56,160
engineering in the sense that we're choosing we're choosing because these features that we're

399
00:38:56,160 --> 00:39:03,600
looking at are fairly complex and high level. Right. And and also it certainly doesn't do what you're

400
00:39:03,600 --> 00:39:09,840
doing justice. But if you think about you've got all this raw data that doesn't really express or

401
00:39:09,840 --> 00:39:16,240
kind of model the underlying phenomena and you guys are creating these meta models if you will

402
00:39:16,240 --> 00:39:23,520
that does based on the raw data. It's kind of feature engineering-ish. Yeah well the thing is we

403
00:39:23,520 --> 00:39:28,720
do have data for these intermediate variables. So for example. Got it. Okay. Yeah so one of the

404
00:39:28,720 --> 00:39:33,360
one of the ways you might think of it as feature engineering is we actually model where a protein

405
00:39:33,360 --> 00:39:39,200
will bind to the DNA right. So so protein binding to DNA is a very important biological process

406
00:39:39,200 --> 00:39:43,040
in understanding how a mutation disrupts that is really important for understanding disease.

407
00:39:43,040 --> 00:39:47,680
So you might sort of say well what we've done is we've designed features that describe how the

408
00:39:47,680 --> 00:39:53,840
protein is binding to the DNA. But the way we actually account for that is we obtain training data

409
00:39:54,560 --> 00:39:59,840
for where the protein bound. So we've got a data set of DNA sequences and whether or not the

410
00:39:59,840 --> 00:40:04,960
protein bound to that DNA sequence and then we train a model for that. So if you like each of these

411
00:40:04,960 --> 00:40:09,360
features is actually a machine learning system. And so that's where that's where it's quite

412
00:40:09,360 --> 00:40:13,200
different from traditional feature engineering where you actually hand code the features. So we don't

413
00:40:13,200 --> 00:40:17,760
we don't really hand code the features. We obtain training sets and then we train the models to

414
00:40:17,760 --> 00:40:23,920
extract the features. Okay. Yeah but it is you know it is it does have that you know that sort of

415
00:40:23,920 --> 00:40:29,200
confidential structure to it and we do there is this notion where each of these features is validated.

416
00:40:29,200 --> 00:40:34,800
We do carefully validate each of these we call them a biomodule. So we validate each

417
00:40:34,800 --> 00:40:39,920
biomodule to make sure that it's really counting for that particular biological mechanism.

418
00:40:40,880 --> 00:40:46,400
The other way you can think about this actually is multi-path multi-task training. Okay so deep

419
00:40:46,400 --> 00:40:52,000
neural networks one of the techniques that works really well is it's called multi-task training.

420
00:40:52,000 --> 00:40:57,040
That's where you you train your system to solve multiple tasks at the same time.

421
00:40:58,400 --> 00:41:04,400
So you might have you might have a very simple example might be the input as an image and your

422
00:41:04,400 --> 00:41:11,200
training it to to classify animals and at the same time you're also training it to classify

423
00:41:12,720 --> 00:41:17,760
some other some other kind of object and the ideas that is that the what it learns about those two

424
00:41:17,760 --> 00:41:21,760
for example faces. So maybe you're trying to classify faces and you're also trying to classify

425
00:41:21,760 --> 00:41:26,720
animals and there's some components to those two different problems that are that are of shared

426
00:41:26,720 --> 00:41:34,240
value. For example the detection of body parts or the detection of eyes something like that and

427
00:41:34,240 --> 00:41:39,200
so by training the system to solve these two different tasks at once it can learn sub components

428
00:41:39,200 --> 00:41:43,360
it can learn intermediate variables if you like that are useful for for the two different tasks.

429
00:41:44,160 --> 00:41:48,080
And so you can also think about what we're doing that way we have this these very deep

430
00:41:48,080 --> 00:41:53,840
multi-layer architectures and they're trained to predict phenotype but they're also trained to

431
00:41:53,840 --> 00:41:57,600
predict protein binding they're also trained to predict splicing they're also trained to predict

432
00:41:57,600 --> 00:42:02,720
transcription and these different processes that are going on within the cell. And by training

433
00:42:02,720 --> 00:42:07,520
them jointly to solve these different tasks they get better at solving any one of them and in

434
00:42:07,520 --> 00:42:12,640
particular they can get better at detecting disease and also predicting the effects of therapies.

435
00:42:13,200 --> 00:42:21,440
Are the different modules? How do I ask this question? If you think about this as a if the model

436
00:42:21,440 --> 00:42:26,960
that we're talking about here is a deep neural network are the different modules expressed

437
00:42:26,960 --> 00:42:36,960
explicitly as layers meaning like the the network architecture or does the training process

438
00:42:36,960 --> 00:42:41,680
kind of cause the modules to be expressed in the layers does that question make sense?

439
00:42:41,680 --> 00:42:45,600
Yeah no it does it's a good question you're sort of asking what's the mapping between the

440
00:42:46,400 --> 00:42:49,760
layers of biology and the layers of our machine learning systems.

441
00:42:49,760 --> 00:42:57,360
Yes yeah so so we have two separate maps if you like two separate networks if you like one network

442
00:42:57,360 --> 00:43:04,320
represents the biological processes and for each if you like for each node and each arrow in

443
00:43:04,320 --> 00:43:10,080
that network we train a deep learning system and so and so if the biological network is 10 layers

444
00:43:10,080 --> 00:43:14,720
deep and each layer is modeled by a deep learning system with 10 layers and there's an overall

445
00:43:14,720 --> 00:43:20,320
depth of 100 so that's the one way you can think about it and so because the system is trained

446
00:43:20,320 --> 00:43:24,720
in a modular fashion we can focus in on each component to the biological network and then train

447
00:43:26,880 --> 00:43:31,920
a deep neural network to model that component and sometimes sometimes use a shell

448
00:43:31,920 --> 00:43:37,600
in that work sometimes linear regression is sufficient so the complexity of each of those biological

449
00:43:37,600 --> 00:43:45,120
modules in terms of machine learning is is carefully selected using the traditional machine learning

450
00:43:45,120 --> 00:43:52,160
types of techniques cross validation and perturbation analysis and methods like that and

451
00:43:52,160 --> 00:44:02,160
does it ever make sense to rather than training these models as a stacked neural network to think

452
00:44:02,160 --> 00:44:06,320
of it more as like an ensemble approach where your modules are more separate and you're training

453
00:44:06,320 --> 00:44:12,800
them independently and then you've got some discriminator network you know it's it's sort of the

454
00:44:12,800 --> 00:44:20,160
overall ideas that each of these modules does have a place within the biological system but

455
00:44:20,160 --> 00:44:25,680
having said that we do we do sometimes run into situations where there are fairly different ways

456
00:44:25,680 --> 00:44:31,200
we can conceive of building each module just like in traditional machine learning you might have

457
00:44:31,200 --> 00:44:37,280
different types of you might use a random forest in one case and a neural network and then

458
00:44:37,280 --> 00:44:41,040
you'd like to combine the outputs and see what happens so that sort of thing happens for for

459
00:44:41,040 --> 00:44:44,800
given biological module and might conceive of different ways we can build the machine learning

460
00:44:44,800 --> 00:44:50,400
system to come up with that process and then combine the outputs the the other the other interesting

461
00:44:50,400 --> 00:44:55,440
aspect of this is the sort of end-to-end training that once we put the the system together

462
00:44:56,480 --> 00:45:00,960
then we can fine tune it to make the overall system perform better so even though we

463
00:45:00,960 --> 00:45:06,240
module is initially built using a machine learning system could be a deep neural network

464
00:45:07,440 --> 00:45:11,760
independently of the other modules once we put them together we can adjust all the modules so

465
00:45:11,760 --> 00:45:18,320
they work better together okay in your presentation you had a slide where you were talking about

466
00:45:19,120 --> 00:45:24,560
kind of applying you know what you were doing and applying AI to these types of problems and you

467
00:45:25,200 --> 00:45:30,720
spent quite a bit of time talking about inductive learning versus transductive learning and

468
00:45:30,720 --> 00:45:38,800
how that seems to be you know something that's overlooked in practice can you recap that for us

469
00:45:38,800 --> 00:45:43,680
yeah there's a big focus right now just on collecting data and I think not enough attention is

470
00:45:43,680 --> 00:45:49,520
being paid to analyzing the data when it comes to genomic medicine and so there are a lot of

471
00:45:49,520 --> 00:45:55,600
private and public efforts to just collect data you know the big genome projects the the 100,000

472
00:45:55,600 --> 00:46:00,720
genome project the way the way success is measured is in the number of genomes as opposed to the

473
00:46:00,720 --> 00:46:07,600
information that's being extracted right and and so I think more attention needs to be paid on

474
00:46:07,600 --> 00:46:12,480
analyzing the data now if you look at the genome wide association study where it's this idea of

475
00:46:12,480 --> 00:46:18,000
correlating mutations with the output that's what I would call is more more of a transductive

476
00:46:18,000 --> 00:46:23,040
reasoning approach or basically you're just comparing you're comparing your mutation to the

477
00:46:23,040 --> 00:46:29,840
training data and then trying to make a sort of a winner take all or or taking a voting approach

478
00:46:29,840 --> 00:46:37,440
trying to make a prediction for that mutation now I that's one type of machine learning a different

479
00:46:37,440 --> 00:46:41,440
kind is inductive learning and inductive learning what you do is you you take your training data

480
00:46:41,440 --> 00:46:46,480
and then you build a machine learning model of what's going on and then you apply that model

481
00:46:46,480 --> 00:46:53,440
to the test cases so you apply the model in the future and the advantage of inductive learning

482
00:46:53,440 --> 00:47:02,560
is is generalization so for inductive learning you can learn if in sort of a in one way to view

483
00:47:02,560 --> 00:47:06,560
it is you're learning the rules of what relates the input to the output you're you're learning more

484
00:47:06,560 --> 00:47:11,840
general patterns and this allows you to to take that learning and apply it to completely new

485
00:47:11,840 --> 00:47:16,800
circumstances and so for example if there's a completely new mutation that's never been seen

486
00:47:16,800 --> 00:47:22,480
before if you've used inductive learning you might hope that your machine learning model can still

487
00:47:22,480 --> 00:47:27,680
figure out what's going to happen with that new mutation in contrast to transductive learning

488
00:47:27,680 --> 00:47:32,400
approach if there's a new mutation that's never been seen before that transductive learning

489
00:47:32,400 --> 00:47:36,960
approach can't do anything and so that's true for genome-wide association studies for example if

490
00:47:36,960 --> 00:47:42,480
there's a mutation in a patient that it doesn't exist in the training set then the genome-wide

491
00:47:42,480 --> 00:47:47,680
association study can say nothing about that mutation whereas with the inductive machine learning

492
00:47:47,680 --> 00:47:52,480
approach you might hope that it could take the system could take a look at that mutation and say

493
00:47:52,480 --> 00:47:58,160
ah this mutation is going to cause something to go wrong with splicing and that's going to lead

494
00:47:58,160 --> 00:48:02,480
to the disease and actually that's what we find with our systems so the systems we trained at

495
00:48:02,480 --> 00:48:06,800
deep genomics were able to analyze mutations that have never been seen before that don't exist in

496
00:48:06,800 --> 00:48:17,200
any database okay okay oh that's huge yeah really fighting actually so maybe let's let's dig

497
00:48:17,200 --> 00:48:26,480
into the the data aspect of this a bit in order to do what you're doing I'm imagining you're

498
00:48:26,480 --> 00:48:33,600
benefited you're benefiting pretty significantly by your new data sets coming online all the time like

499
00:48:33,600 --> 00:48:38,960
how is that landscape change and what are some of the types of data that you're looking at

500
00:48:39,920 --> 00:48:44,880
yeah it's one of the most exciting areas right now is biotechnology just the the number of

501
00:48:44,880 --> 00:48:50,800
different kinds of data sets is growing very rapidly in the sizes of those data sets so 10 years

502
00:48:50,800 --> 00:48:57,440
ago we were looking at small data sets consisting of a few thousand examples and now deep genomics

503
00:48:57,440 --> 00:49:02,640
we look at data sets with billions of examples so we're so the amount of data has just grown

504
00:49:02,640 --> 00:49:09,120
very very rapidly and is going to continue to grow there are publicly available data sets so these

505
00:49:09,120 --> 00:49:16,400
are publicly funded research efforts from university labs and so there's plenty of publicly available

506
00:49:16,400 --> 00:49:21,760
data and then there's also different kinds of proprietary data data coming from patient populations

507
00:49:22,400 --> 00:49:28,640
or data that we generate within deep genomics to to study particular aspects of biochemistry and

508
00:49:28,640 --> 00:49:35,120
sort of fine tuner models if you like and then in terms of the in terms of what the data is telling

509
00:49:35,120 --> 00:49:39,360
us as I mentioned before it's these data sets are measuring all sorts of things that are going

510
00:49:39,360 --> 00:49:45,760
on within cells so it's giving us more and more accurate resolution higher and higher resolution

511
00:49:45,760 --> 00:49:50,880
in terms of pinpointing different processes going on within cells and relationships between

512
00:49:50,880 --> 00:49:56,240
those processes so I really do think that in in five to ten years because of this massive growth

513
00:49:56,240 --> 00:50:02,240
in data if we combine machine learning techniques with all these data sets we're going to be able to

514
00:50:02,240 --> 00:50:06,000
produce models of these cellular processes that are quite accurate and reliable.

515
00:50:08,480 --> 00:50:13,200
I took a look at one of your papers the paper that goes into the work that you're doing

516
00:50:13,200 --> 00:50:19,760
about around deep bind and one of the points that you brought up there was the difficulty of

517
00:50:19,760 --> 00:50:28,000
extending results that are seen with in vitro analyses to in vivo analyses and I'm assuming that

518
00:50:29,360 --> 00:50:35,120
or that's that's tied to this issue of the or to what degree is this tied to this issue of the

519
00:50:35,120 --> 00:50:41,600
data sources that you're getting being primarily in vitro and maybe could talk through some of the

520
00:50:41,600 --> 00:50:49,680
issues there yeah yeah so yeah there's different kinds of data and in vitro is data that is

521
00:50:49,680 --> 00:50:54,480
measured under it's in the test tube and it's so this data that's measured in the lab under very

522
00:50:54,480 --> 00:50:59,680
controlled conditions in vivo with the other end of the spectrum is within the living organism

523
00:51:00,400 --> 00:51:05,040
and so it's the idea is that data would reflect more accurately what's actually going to happen

524
00:51:05,040 --> 00:51:12,320
and say a patient and and historically there's been a big disconnect between these data sets but

525
00:51:12,320 --> 00:51:17,520
as as we sort of fill in if you like if we fill in the map of all the different kinds of things

526
00:51:17,520 --> 00:51:22,720
we can measure within the cell and we also fill in the different kinds of conditions under which

527
00:51:22,720 --> 00:51:29,440
we can measure that data and so in vitro in vivo but also different kinds of organisms different

528
00:51:29,440 --> 00:51:35,280
kinds of cell types different tissue types and as we as we measure more and more data for these

529
00:51:35,280 --> 00:51:40,000
different dimensions if you like of different conditions in which we measure the data we get a

530
00:51:40,000 --> 00:51:43,600
more accurate understanding of how all those different kinds of data relate to one another

531
00:51:44,720 --> 00:51:49,040
and so we're also building better and better models that are accounting for confounding factors

532
00:51:49,040 --> 00:51:58,160
or experimental bias or example of a confounding factor might be what oh yeah so there's a different

533
00:51:58,160 --> 00:52:04,320
a wide range of different kinds of confounding factors they'll lump them all together into one group

534
00:52:04,320 --> 00:52:10,160
so experimental bias is a big one and experimental bias just means how your experiment was conducted

535
00:52:10,160 --> 00:52:15,280
you know what what were the very what were some of the technical details that were used to obtain

536
00:52:15,280 --> 00:52:20,320
the data and those things can have a big impact on the on the data itself actually one of the first

537
00:52:20,320 --> 00:52:26,880
projects I worked on in genobiology we we used a particular kind of unsupervised learning method

538
00:52:26,880 --> 00:52:30,800
to analyze the data and we thought we discovered something really interesting and it turned out what

539
00:52:30,800 --> 00:52:40,800
we discovered is who did the experiment on which day and so that's an experimental type of confounding

540
00:52:40,800 --> 00:52:46,320
factor and then there are confounding factors that are biological and so for example if you're

541
00:52:46,320 --> 00:52:50,880
looking at let's take the genome wide association study approach a very very simple machine learning

542
00:52:50,880 --> 00:52:57,120
technique and so if you're looking at a bunch of patients that have a disease and a bunch of

543
00:52:57,120 --> 00:53:01,680
patients that don't have the disease the the problem is that those patients are not really

544
00:53:01,680 --> 00:53:08,400
independent and identically drawn from some simple distribution they're actually related to one

545
00:53:08,400 --> 00:53:15,040
another in some way and so so maybe half of your cases are derived from a single ancestor that

546
00:53:15,040 --> 00:53:21,360
lived 100,000 years ago or something like that so that kind of structure in the population

547
00:53:21,360 --> 00:53:25,440
is going to lead to dependencies of course between these measurements and those dependencies can

548
00:53:25,440 --> 00:53:30,800
lead you astray it's a little bit like you know suppose you're one problem that all machine

549
00:53:30,800 --> 00:53:35,760
learning researchers are familiar with is suppose you have a training data of a hundred examples

550
00:53:35,760 --> 00:53:40,720
and you take one of your examples and just replicate it a million times right you do not have a

551
00:53:40,720 --> 00:53:45,680
training set a bona fide training set of a million a 99 examples because you've biased your

552
00:53:45,680 --> 00:53:50,800
yeah yeah just copied one of the examples a whole bunch of times so that's an example of a

553
00:53:50,800 --> 00:53:55,680
confounding factor that really does arise in human genetics and is really important to to avoid

554
00:53:56,320 --> 00:54:03,280
and is the idea that your approach or deep learning in general is has a higher level of

555
00:54:04,480 --> 00:54:10,000
is more impervious to these types of confounding factors yes yeah that's that's right and so because

556
00:54:10,000 --> 00:54:14,240
we're building a system to model these different biological components we can factor out certain

557
00:54:14,240 --> 00:54:20,160
confounding factors and so as I mentioned for example our system can detect mutations that have

558
00:54:20,160 --> 00:54:27,200
never been seen before which obviously means that it's not sensitive to the to to the structure of

559
00:54:27,200 --> 00:54:32,960
of the human population in terms of the genetics okay but at the same time I you know I should

560
00:54:32,960 --> 00:54:38,400
add that of course our systems are being trained using data that has biases because basically all

561
00:54:38,400 --> 00:54:43,920
the biology is highly biased so and so it's not like the problem is completely gone but yes they're

562
00:54:43,920 --> 00:54:53,920
more impervious yeah awesome awesome well this is this has been fantastic maybe any closing thoughts

563
00:54:53,920 --> 00:55:00,240
on things that you guys are working on are you know what you're excited about yeah I guess the

564
00:55:01,600 --> 00:55:07,680
the the challenges for us are so we have our systems are working well and we're making

565
00:55:07,680 --> 00:55:13,440
good progress in terms of addressing interesting machine learning problems as well as having an

566
00:55:13,440 --> 00:55:19,840
impact in medicine but I think one one area that's interesting to talk about is is the kinds of

567
00:55:19,840 --> 00:55:24,640
problems that we're facing in terms of our machine learning techniques and how those relate to

568
00:55:25,840 --> 00:55:32,160
what generally the field is looking at and and and being challenged with and one of those is

569
00:55:32,160 --> 00:55:38,400
is building systems that can explain themselves and so this has been a people have been talking

570
00:55:38,400 --> 00:55:43,360
about this quite a bit recently is how do you build or train a neural network say or deep learning

571
00:55:43,360 --> 00:55:48,720
system that in such a way that it can actually explain what's going on so it can explain why it makes

572
00:55:48,720 --> 00:55:56,720
a decision right right and you know so that's that's really important for for earning trust and so

573
00:55:56,720 --> 00:56:02,400
if we have a if we have a machine learning system that predicts that you you know woman should

574
00:56:03,600 --> 00:56:08,000
has a has a disease causing mutation in the context of say breast cancer in the system recommends

575
00:56:08,000 --> 00:56:12,800
a double mastectomy then you really do want the system to be reliable and trustworthy and be able

576
00:56:12,800 --> 00:56:17,840
to explain you know why why it made that decision why it made that provided that advice

577
00:56:19,280 --> 00:56:22,240
and so I think that's a really interesting area for machine learning you know I don't have the

578
00:56:22,240 --> 00:56:26,720
answer to to how we how we do that but people are working on that area and a lot more work needs to

579
00:56:26,720 --> 00:56:34,080
be done well so on that point I did do an interview with Carlos Gastrin not too long ago and

580
00:56:35,040 --> 00:56:39,360
our listeners might remember that one if you're interested in this issue of explainability check

581
00:56:39,360 --> 00:56:46,320
out that interview but traditionally if you can use traditionally when talking about deep neural

582
00:56:46,320 --> 00:56:51,440
networks I guess people you know when we're looking at machine learning models people look to

583
00:56:51,440 --> 00:56:58,240
other types of models and not deep neural networks because of this explainability challenge

584
00:56:58,800 --> 00:57:05,280
that is you know particularly acute with neural networks like do you see where do you see

585
00:57:05,280 --> 00:57:10,640
that going do you see light at the end of the tunnel yeah that's a good point and actually think

586
00:57:10,640 --> 00:57:18,000
that that belief is completely wrong-minded so so here's the traditional argument for why you

587
00:57:18,000 --> 00:57:23,760
should look at simple techniques like linear regression or random forests or something like that

588
00:57:25,200 --> 00:57:31,280
so the the argument goes like this to figure out an explanation for why machine learning system

589
00:57:31,280 --> 00:57:35,600
made its prediction what you do is you should look inside of the machine learning system you should

590
00:57:35,600 --> 00:57:41,200
look at the parameters okay so linear regression is really simple because for each input there's

591
00:57:41,200 --> 00:57:46,000
only one parameter connecting it to the output and so you can just look at that parameter and if it's

592
00:57:46,000 --> 00:57:49,680
positive it means that input has a positive impact on the output and if it's negative it has a

593
00:57:49,680 --> 00:57:55,360
negative impact and so that's that's the justification for looking at simple machine learning systems

594
00:57:55,360 --> 00:58:01,360
right okay now this is why I think that's completely wrong-minded if you if you turn to your

595
00:58:01,360 --> 00:58:07,360
friend and ask them why did you make the decision you just made you don't crack open their skull

596
00:58:07,360 --> 00:58:14,480
and look at their synapses to figure out the explanation that's not what you do and yet that's

597
00:58:14,480 --> 00:58:19,520
what the traditional argument is for why you should use simple machine learning systems you're

598
00:58:19,520 --> 00:58:23,840
going to look at the parameters and so therefore you need a simple system no you don't do that

599
00:58:23,840 --> 00:58:27,760
so what you do is you ask your friend to explain themselves well why did you make the decision

600
00:58:27,760 --> 00:58:33,840
you made so I think the future of machine learning is all about using complex deep neural nets

601
00:58:33,840 --> 00:58:37,760
but training them in such a way that they actually produce an explanation at the output

602
00:58:38,880 --> 00:58:43,680
so we don't crack them open and look at the parameters we we actually train the system so that the

603
00:58:43,680 --> 00:58:48,000
output of the neural network is an explanation as well as a decision does that make sense

604
00:58:48,720 --> 00:58:54,080
it does make sense so I'm thinking of the picture I have in my head is yeah we talked

605
00:58:54,080 --> 00:59:00,800
earlier about neural networks that are trained to produce multiple outputs and so in this case

606
00:59:00,800 --> 00:59:05,680
one of the outputs is the explanation and the other output is the you know the thing we're asking

607
00:59:05,680 --> 00:59:09,520
it to make a decision you got it you got it that's exactly right so you can think of this as a

608
00:59:09,520 --> 00:59:14,560
multitask training problem yeah where one output is the decision the other output is the explanation

609
00:59:14,560 --> 00:59:19,200
and so really I think that's that's the future of machine learning in terms of explanations

610
00:59:19,200 --> 00:59:23,440
and there are obviously some really challenging technical issues for for how we get that to work

611
00:59:23,440 --> 00:59:27,680
and it's not really working well yet but I think that is really where things where things will go

612
00:59:27,680 --> 00:59:34,320
in that regard and the other I guess the other observation I can make is is what's what I find really

613
00:59:34,320 --> 00:59:39,600
exciting about this area that deep genomics is working on is the kind of artificial intelligence we

614
00:59:39,600 --> 00:59:46,880
need and so if you look at some recent big successes like deep mines alphago or Google

615
00:59:47,520 --> 00:59:52,160
Google's results or Facebook so if you look at some of the really exciting results that have come

616
00:59:52,160 --> 00:59:59,040
out of those labs therefore things like games which humans invented or image recognition which

617
00:59:59,040 --> 01:00:04,320
humans have evolved to be good at or speech recognition which humans invented or evolved and

618
01:00:04,320 --> 01:00:08,720
or evolved now these are all tests that humans are good at whereas what I think is really

619
01:00:08,720 --> 01:00:13,840
exciting about genomic medicine is that the AI systems we build need to go beyond what humans

620
01:00:13,840 --> 01:00:19,120
are capable of so no human is it ever going to be capable of understanding genome or how to

621
01:00:19,120 --> 01:00:24,080
cure genetic disease or no group of humans will right it's so complex and so common tutorial

622
01:00:24,080 --> 01:00:32,960
and so really what we need is superhuman AI and so now it's making me think of this is making me

623
01:00:32,960 --> 01:00:37,920
think of a sci-fi book that I like by Octavia Butler I forget the name of the book but basically

624
01:00:37,920 --> 01:00:45,840
there are these race of aliens that come down to a north that's been you know kind of ravaged by

625
01:00:45,840 --> 01:00:54,000
you know disease and this gift that these this alien race has is to effectively repair genetic disorder

626
01:00:54,000 --> 01:01:00,880
what that has to do with AI who knows but you're also I mean there's some interesting things kind

627
01:01:00,880 --> 01:01:05,760
of switching the subject here there's also some interesting things happening up in Toronto right

628
01:01:07,600 --> 01:01:13,920
yeah yeah so you're asking what things happening in Toronto so I can't talk a lot about it right

629
01:01:13,920 --> 01:01:19,600
now but in the next couple weeks there's going to be an announcement for a new type of artificial

630
01:01:19,600 --> 01:01:26,320
intelligence institute in Toronto we have over 170 million dollars of funding for it and the

631
01:01:26,320 --> 01:01:37,920
ideas to build or rebuild the AI research capacity in Toronto and and ensure that we can use that

632
01:01:37,920 --> 01:01:44,640
capacity to to foster innovation in the startup community and another another bigger businesses

633
01:01:44,640 --> 01:01:49,280
in the in the area so yeah that should be announced in a few weeks and it should be really big

634
01:01:49,280 --> 01:01:55,040
big news for Toronto and I think big news for the AI community more broadly that's fantastic

635
01:01:55,040 --> 01:02:00,560
we'll definitely keep our eyes open for that and so before we go where can people learn more about

636
01:02:00,560 --> 01:02:07,600
what you're up to and keep tabs on you yeah so you can go to www.deepgenomics.com also just google

637
01:02:07,600 --> 01:02:13,360
me and we have various papers posted online there where you can for example a tutorial paper that

638
01:02:13,360 --> 01:02:18,000
describes the approach and and how you can use machine learning not just deep learning but just

639
01:02:18,000 --> 01:02:23,360
different kinds of machine learning techniques to to approach problems in genomic medicine also

640
01:02:23,360 --> 01:02:27,920
well Brendan thanks so much this was an amazing conversation I really appreciate you taking the

641
01:02:27,920 --> 01:02:37,840
time out you best sound it was a pleasure all right everyone that's our show for today a huge

642
01:02:37,840 --> 01:02:43,040
thanks to all you listeners out there I appreciate all of the notes and comments that you share be

643
01:02:43,040 --> 01:02:49,440
the mailing list sign up form the show notes pages be a Twitter iTunes and all the other channels

644
01:02:49,440 --> 01:02:55,040
that you use to share your love for the podcast and don't forget to visit our brand new Facebook

645
01:02:55,040 --> 01:03:00,640
page at facebook.com slash swimmol ai and give us a like and register for the strata

646
01:03:00,640 --> 01:03:07,840
Hadoop giveaway while you're there the notes for this show will be up at twimmol ai.com slash talk

647
01:03:07,840 --> 01:03:13,600
slash 12 and there you'll find links to all of the resources mentioned in the show thanks so

648
01:03:13,600 --> 01:03:25,360
much for listening and catch you next time

