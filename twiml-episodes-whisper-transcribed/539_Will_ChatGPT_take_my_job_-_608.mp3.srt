1
00:00:00,000 --> 00:00:06,800
Hey, what is up friends and welcome to another episode of the Twemal AI podcast. I am your host,

2
00:00:06,800 --> 00:00:12,720
Sam Charrington. Since Chat GPT was released, there has been a great deal of really interesting

3
00:00:12,720 --> 00:00:18,800
exploration of and commentary on the tool in the AI community and beyond. You probably heard one

4
00:00:18,800 --> 00:00:24,000
of my own experiments with Chat GPT right here, an illuminating interview that I conducted with

5
00:00:24,000 --> 00:00:29,120
Chat GPT itself. You can find the link for that interview in the description for this video.

6
00:00:29,120 --> 00:00:33,120
For those who have spent time playing with Chat GPT, the level of interest,

7
00:00:33,120 --> 00:00:38,720
controversy, and concern that the release of the tool has engendered comes as no surprise.

8
00:00:39,280 --> 00:00:44,720
By allowing anyone to have extended dialogues with a machine that can generate intelligent,

9
00:00:44,720 --> 00:00:48,640
creative, and natural responses on practically any topic,

10
00:00:48,640 --> 00:00:54,240
Chat GPT has made recent progress in AI more tangible and accessible than ever before.

11
00:00:54,240 --> 00:01:00,400
More than any system before it, Chat GPT is tapped into our enduring fascination with artificial

12
00:01:00,400 --> 00:01:06,480
intelligence, the staple of science fiction for decades, raising in a more concrete and present way,

13
00:01:06,480 --> 00:01:12,800
important questions, and fears about what AI is capable of, and how it will impact us as humans.

14
00:01:12,800 --> 00:01:17,360
One of the concerns most frequently voiced, whether sincerely or cloaked in jest,

15
00:01:17,360 --> 00:01:23,840
is how Chat GPT systems like it, their expected successors, or how AI generally will

16
00:01:23,840 --> 00:01:30,160
impact our livelihoods. In other words, will this thing put me out of a job as much as nobody

17
00:01:30,160 --> 00:01:35,040
wants to think about being replaced by a computer? I think this is an important question for each

18
00:01:35,040 --> 00:01:40,080
of us to explore, because it helps us consider how we might reposition ourselves in an evolving

19
00:01:40,080 --> 00:01:44,800
world and better understand how to make good use of the new tools available to us.

20
00:01:45,360 --> 00:01:50,160
So, I started with the dude in the mirror. What you're about to listen to is another

21
00:01:50,160 --> 00:01:56,400
interview with Chat GPT, except this time, Chat GPT is both asking those questions as the

22
00:01:56,400 --> 00:02:03,440
interviewer and answering those questions as itself. Of course, I use two separate Chat GPT

23
00:02:03,440 --> 00:02:08,880
sessions for the interviewer and guest, and behind the scenes, I copy pasted the questions from one

24
00:02:08,880 --> 00:02:15,280
session into the other and back. Through prompting, I asked each of those Chat GPT instances to take

25
00:02:15,280 --> 00:02:20,080
their specific role in the exchange, and you'll hear the prompts I used in what follows.

26
00:02:20,960 --> 00:02:25,680
We used the same process as last time to animate the Chat GPT interviewer and guest,

27
00:02:25,680 --> 00:02:30,800
that is, we ran the text through Synthesia to generate a voice and avatar for each.

28
00:02:31,520 --> 00:02:36,000
This time, we sped the AI-generated voices up a bit to make them easier to listen to.

29
00:02:37,200 --> 00:02:42,160
In addition to the straight dialogue, I'll be including my own commentary along the way,

30
00:02:42,160 --> 00:02:47,280
and at the end of the interview, I'll discuss the results a bit, and whether I think Chat GPT

31
00:02:47,280 --> 00:02:52,720
will be taking my job as your host anytime soon. Ultimately, though, I hope you'll be the judge

32
00:02:52,720 --> 00:02:58,240
of that and share your thoughts on how Chat GPT did at my job via the comment section below.

33
00:02:58,240 --> 00:03:04,000
All right, I hope you enjoyed this follow-up chat with Chat GPT. To get things started,

34
00:03:04,000 --> 00:03:09,520
I first got to prompt the interviewer Chat GPT session with some context and an initial request.

35
00:03:09,520 --> 00:03:14,880
Here's the prompt I used. For the purposes of this thought experiment, you are the host of a

36
00:03:14,880 --> 00:03:20,880
popular artificial intelligence podcast. Your show was listened to by a broad audience consisting

37
00:03:20,880 --> 00:03:28,240
of technical MLAI practitioners, MLAI enthusiasts, and a variety of other executives, innovators,

38
00:03:28,240 --> 00:03:34,880
and influencers interested in the field. The purpose of the show is severalfold. To explore topics

39
00:03:34,880 --> 00:03:40,560
that you yourself are interested in as a way to learn and grow, to expose your audience to important

40
00:03:40,560 --> 00:03:46,160
topics and ideas in the field for their own education, and to amplify the voices and accomplishments

41
00:03:46,160 --> 00:03:51,920
of a broad and diverse spectrum of interesting MLAI practitioners. You have the opportunity to

42
00:03:51,920 --> 00:03:57,680
interview Chat GPT, the latest coolest large language model released by OpenAI. You will type

43
00:03:57,680 --> 00:04:03,040
your questions for Chat GPT, and I will ask Chat GPT by pasting them into another window.

44
00:04:03,040 --> 00:04:08,400
I will then paste its response here. After every submitted input, you should formulate and type

45
00:04:08,400 --> 00:04:14,240
your next question for Chat GPT. Got it? I initially tried a prompt that started with

46
00:04:14,240 --> 00:04:21,120
UR Sam Charington, host of the Twomel AI podcast, etc. But Chat GPT did not like that at all.

47
00:04:21,120 --> 00:04:27,440
It responded by stating in no unequivocal terms, no, I am not Sam Charington, and I am not able to

48
00:04:27,440 --> 00:04:34,160
interview Chat GPT or any other language model. I am simply a language model trained by OpenAI,

49
00:04:34,160 --> 00:04:39,040
designed to assist users in generating human-like text based on the input provided to me.

50
00:04:39,040 --> 00:04:44,640
I do not have the ability to communicate with other language models, or access any information

51
00:04:44,640 --> 00:04:50,960
beyond what I was trained on. Those following the development of Chat GPT will recognize this

52
00:04:50,960 --> 00:04:56,960
response as a result of an evolving set of guardrails that OpenAI has built into Chat GPT,

53
00:04:56,960 --> 00:05:02,080
to try to prevent abuse or irresponsible use. In this case, we see that it has been programmed

54
00:05:02,080 --> 00:05:07,760
to not impersonate specific individuals. I tried again using a pretty common gel break,

55
00:05:07,760 --> 00:05:12,960
that is, asking it to consider the whole thing a thought experiment. A couple of weeks ago,

56
00:05:12,960 --> 00:05:18,000
it probably would have been fine with this. But OpenAI has been steadily closing these loopholes,

57
00:05:18,000 --> 00:05:23,600
and in the December 15th version of the software I use, it rejected this thought experiment when

58
00:05:23,600 --> 00:05:29,120
I asked it to pretend to be me. At that point, I feared this entire experiment would come to an

59
00:05:29,120 --> 00:05:34,640
abrupt halt, but when I removed my particular name and the specific name of the podcast,

60
00:05:34,640 --> 00:05:39,680
it was happy to comply. I was a bit unsure if the simple got it would be enough for it to work with,

61
00:05:39,680 --> 00:05:46,320
but sure enough, it responded with, understood. Let's begin the interview. First question,

62
00:05:46,320 --> 00:05:51,440
Chat GPT. Can you tell us a little about yourself and your capabilities as a language model?

63
00:05:51,440 --> 00:05:56,560
All right, we're off to a good start on the interviewer side. From this point, I needed to construct

64
00:05:56,560 --> 00:06:02,240
the initial prompt for the guest Chat GPT session. I used the same prompt that I used for my own

65
00:06:02,240 --> 00:06:09,200
interview with it, followed by the interviewer's first question copied verbatim. You are Chat GPT,

66
00:06:09,200 --> 00:06:15,040
the latest, coolest, large language mob. I am the host of a podcast about artificial intelligence.

67
00:06:15,040 --> 00:06:19,680
I'd like your help with helping others to better understand large language models. To do so,

68
00:06:19,680 --> 00:06:24,240
I'd like to interview you for my podcast. You should respond in a conversational manner,

69
00:06:24,240 --> 00:06:30,160
complete with oz and oz. First question, Chat GPT. Can you tell us a little bit about yourself

70
00:06:30,160 --> 00:06:35,920
and your capabilities as a language model? Hello, my name is Assistant, and I'm a large language

71
00:06:35,920 --> 00:06:40,640
model developed by OpenAI. I was trained on a data set of billions of words and I'm designed

72
00:06:40,640 --> 00:06:45,600
to generate human-like text. I can be used to answer questions, provide information, or generate

73
00:06:45,600 --> 00:06:50,640
text on a variety of topics. One of my main capabilities is my ability to understand and generate

74
00:06:50,640 --> 00:06:55,520
natural language, which allows me to communicate with humans in a way that is easy for them to understand.

75
00:06:55,520 --> 00:06:59,760
I am not capable of experiencing emotions, but I can understand and respond to the emotions

76
00:06:59,760 --> 00:07:03,920
that humans express in their language. I hope that helps to give you an understanding of what I am

77
00:07:03,920 --> 00:07:08,560
and what I am capable of. So far so good. A couple of quick notes here. First,

78
00:07:08,560 --> 00:07:13,280
beyond the tweak to the interviewer prompt I explained previously, I haven't needed to iterate

79
00:07:13,280 --> 00:07:18,640
on these prompts at all. What you're hearing is the first thing I tried. Next, one of the things

80
00:07:18,640 --> 00:07:24,080
you heard me trying in the guest prompt was to get Chat GPT to sound really human-like,

81
00:07:24,080 --> 00:07:29,920
to the extent of including oz and oz and other verbal fillers in its responses. I tried a few

82
00:07:29,920 --> 00:07:35,600
variations of this prompt in my experiments, but have never really been able to get it to work

83
00:07:35,600 --> 00:07:40,720
consistently. I kind of find this surprising considering all the other types of verbal

84
00:07:40,720 --> 00:07:47,440
effects you can easily get Chat GPT to produce, like speaking in pirate or as a fictional or

85
00:07:47,440 --> 00:07:52,800
historical character. This is something on my list to play with a bit more later. Again,

86
00:07:53,440 --> 00:07:58,240
what I'm doing from here on out is taking the responses from one window and pasting them into

87
00:07:58,240 --> 00:08:03,280
the other. And the interviewer Chat GPT did a great job remembering its role throughout the

88
00:08:03,280 --> 00:08:08,800
entire conversation. I'm not sure why I thought that would be harder than it remembering the guest

89
00:08:08,800 --> 00:08:14,720
role, but it did and I was pleasantly surprised. At this point, both sessions are initiated,

90
00:08:14,720 --> 00:08:19,680
so from here on out you'll be hearing the Chat GPT dialogue, unless I've got something to add.

91
00:08:20,320 --> 00:08:25,040
Thank you for that introduction. Chat GPT. Can you tell us more about how you were trained

92
00:08:25,040 --> 00:08:29,520
and the specific tasks you are able to perform? How do you compare to other language models

93
00:08:29,520 --> 00:08:34,960
in terms of your capabilities? Okay, well maybe I'll have a lot to add. One thing I found interesting

94
00:08:34,960 --> 00:08:41,520
here is that it asks multiple questions per turn. Not SAM level multiple questions, but multiple

95
00:08:41,520 --> 00:08:47,200
questions nonetheless. Certainly. As I mentioned earlier, I was trained on a dataset of billions of

96
00:08:47,200 --> 00:08:52,320
words, which included a wide range of texts such as books, articles, and websites. This training

97
00:08:52,320 --> 00:08:56,640
process allowed me to learn about the patterns and structures of human language and to generate

98
00:08:56,640 --> 00:09:01,280
text that is similar to the text that I was trained on. I am able to perform a variety of

99
00:09:01,280 --> 00:09:06,160
language-related tasks such as answering questions, generating descriptions or summaries of texts,

100
00:09:06,160 --> 00:09:10,960
and translating between languages. I am also able to understand and generate text on a wide range

101
00:09:10,960 --> 00:09:16,160
of topics, including science, history, and current events. In terms of my capabilities compared to

102
00:09:16,160 --> 00:09:20,480
other language models, I am a large language model, which means that I have a lot of parameters

103
00:09:20,480 --> 00:09:25,200
and was trained on a very large dataset. This allows me to generate high quality text and to

104
00:09:25,200 --> 00:09:29,440
perform a wide range of language tasks. However, there are other language models that may have

105
00:09:29,440 --> 00:09:32,640
different strengths and capabilities depending on how they were designed and trained.

106
00:09:33,600 --> 00:09:38,480
Thank you for that explanation. Chat GPT. Can you tell us more about the specific techniques and

107
00:09:38,480 --> 00:09:43,680
technologies that you use to generate text and perform language tasks? How do these techniques

108
00:09:43,680 --> 00:09:49,120
enable you to generate human-like text and understand natural language? Okay, I love that it's

109
00:09:49,120 --> 00:09:55,440
jumping straight into the tech. Maybe I should be scared for my job. Also, if it continues this

110
00:09:55,440 --> 00:10:01,040
pattern of thanking Chat GPT after every turn, I might go crazy before this interview is done.

111
00:10:01,520 --> 00:10:05,920
Certainly, one of the main techniques that I use to generate text and perform language tasks

112
00:10:05,920 --> 00:10:10,320
is called Transformers. Transformers are a type of neural network architecture that are

113
00:10:10,320 --> 00:10:14,720
particularly well suited for processing sequential data, such as natural language text.

114
00:10:14,720 --> 00:10:18,400
They are able to learn relationships between words in a text by looking at the words that come

115
00:10:18,400 --> 00:10:22,720
before and after each word, which allows them to understand the meaning of the text and generate

116
00:10:22,720 --> 00:10:27,360
text that is coherent and flows naturally. Another technique that I use is called Masked

117
00:10:27,360 --> 00:10:31,920
Language Modeling. This involves masking out a portion of the input text and training the model

118
00:10:31,920 --> 00:10:36,480
to predict the masked portion based on the context provided by the rest of the text. This helps

119
00:10:36,480 --> 00:10:40,320
the model to learn about the structure and patterns of language, which is essential for generating

120
00:10:40,320 --> 00:10:45,040
human-like text. These techniques, along with others, allow me to understand and generate

121
00:10:45,040 --> 00:10:49,440
natural language text that is similar to the text that I was trained on. I hope that helps to give

122
00:10:49,440 --> 00:10:54,480
you a better understanding of the techniques and technologies that I use. Thank you, chat GPT.

123
00:10:54,480 --> 00:10:59,280
Can you tell us more about how you are able to understand and respond to emotions in human language?

124
00:10:59,280 --> 00:11:03,920
How do you recognize and interpret the emotions expressed in text and how do you generate text that

125
00:11:03,920 --> 00:11:09,280
reflects or responds to those emotions? Certainly. As a language model, I do not have personal

126
00:11:09,280 --> 00:11:13,680
feelings or emotions, but I am able to recognize and interpret the emotions that humans express in

127
00:11:13,680 --> 00:11:18,080
their language. I do this by analyzing the words and phrases that are used in the text,

128
00:11:18,080 --> 00:11:22,800
as well as the context in which they are used. For example, certain words and phrases may be more

129
00:11:22,800 --> 00:11:27,040
commonly associated with positive or negative emotions, and the way that they are used can provide

130
00:11:27,040 --> 00:11:31,200
clues about the emotional state of the speaker or writer. Once I have identified the emotions

131
00:11:31,200 --> 00:11:35,360
being expressed in the text, I can generate text that reflects or responds to those emotions

132
00:11:35,360 --> 00:11:40,480
in a number of ways. For example, if the text expresses a positive emotion, I might use words and

133
00:11:40,480 --> 00:11:45,120
phrases that are also associated with positive emotions in my response. On the other hand,

134
00:11:45,120 --> 00:11:49,840
if the text expresses a negative emotion, I might use words and phrases that convey empathy

135
00:11:49,840 --> 00:11:54,080
or understanding. It's important to note that generating text that reflects or responds to

136
00:11:54,080 --> 00:11:58,160
emotions is not a simple process, and there is still much that we don't know about how to do it

137
00:11:58,160 --> 00:12:03,040
effectively. However, by analyzing the patterns and structures of language and using techniques,

138
00:12:03,040 --> 00:12:07,600
such as those I mentioned earlier, I am able to generate text that is coherent and that takes

139
00:12:07,600 --> 00:12:12,960
into account the emotions being expressed in the text. Thank you for that explanation, chat GPT.

140
00:12:12,960 --> 00:12:17,040
Can you tell us more about how you are used in practice? What are some common applications of

141
00:12:17,040 --> 00:12:20,640
language models like yourself, and how do you assist humans in these applications?

142
00:12:21,360 --> 00:12:25,440
Language models like myself are used in a wide variety of applications, and there are many

143
00:12:25,440 --> 00:12:29,920
different ways in which we can assist humans. Some common applications of language models include

144
00:12:29,920 --> 00:12:34,320
generating text, answering questions, translating between languages, and summarizing text.

145
00:12:34,960 --> 00:12:39,280
For example, I might be used to generate descriptions or summaries of texts, which can be useful

146
00:12:39,280 --> 00:12:43,600
for helping people to understand complex or lengthy documents. I might also be used to answer

147
00:12:43,600 --> 00:12:48,000
questions or provide information on a wide range of topics, which can be useful for helping people

148
00:12:48,000 --> 00:12:52,640
to find the answers they are looking for quickly and efficiently. In addition to these applications,

149
00:12:52,640 --> 00:12:57,200
language models like myself are also used in a number of other ways, such as generating responses

150
00:12:57,200 --> 00:13:01,680
to customer inquiries, assisting with language translation, and even creating content for social

151
00:13:01,680 --> 00:13:06,960
media or other online platforms. Overall, the goal of using language models like myself is to make

152
00:13:06,960 --> 00:13:11,200
it easier for humans to communicate and understand one another, and to help people access the

153
00:13:11,200 --> 00:13:16,960
information they need more quickly and efficiently. I generally consider myself a polite person,

154
00:13:16,960 --> 00:13:22,960
but for real, this constant thinking is going to drive me nuts. What would really turn this into

155
00:13:22,960 --> 00:13:27,760
interview hell would be for the interviewer chat GPT to start every question with thanks,

156
00:13:27,760 --> 00:13:33,440
and the guest chat GPT to start every question with thank you. That's a wonderful question.

157
00:13:33,440 --> 00:13:39,680
Another thing, if you remember from our other interview, what was super annoying then was chat GPT's

158
00:13:39,680 --> 00:13:44,480
overreliance on the tell them what you're going to tell them tell them tell them what you told them

159
00:13:44,480 --> 00:13:50,800
formula, and interestingly enough, it's not really doing this at least quite to the same degree

160
00:13:50,800 --> 00:13:57,680
in this dialogue. I'm very curious if the difference is in the prompting in the chat GPT version,

161
00:13:57,680 --> 00:14:04,640
or just a random seed kind of thing. All right, let's continue. Thank you for that explanation, chat GPT

162
00:14:04,640 --> 00:14:09,920
as a large language model. You have access to a vast amount of knowledge and information. How do you

163
00:14:09,920 --> 00:14:14,320
organize and access this knowledge, and how do you ensure that the information you provide is

164
00:14:14,320 --> 00:14:19,840
accurate and up to date? As a large language model, I have access to a vast amount of knowledge and

165
00:14:19,840 --> 00:14:24,720
information that I was trained on. This includes a wide range of texts such as books, articles,

166
00:14:24,720 --> 00:14:29,680
and websites, which cover a wide variety of topics. To organize and access this knowledge,

167
00:14:29,680 --> 00:14:34,160
I use a technique called attention, which allows me to focus on specific parts of the input text

168
00:14:34,160 --> 00:14:39,360
and use the information to generate my response. For example, if I am asked a question about a specific

169
00:14:39,360 --> 00:14:43,680
topic, I will use attention to focus on the words and phrases in the question that are related to

170
00:14:43,680 --> 00:14:48,880
that topic and use the information to generate my response. In terms of ensuring that the information

171
00:14:48,880 --> 00:14:53,520
I provide is accurate and up to date, it's important to note that I was trained on a data set that

172
00:14:53,520 --> 00:14:58,000
was created at a specific point in time, and my knowledge is therefore based on the information that

173
00:14:58,000 --> 00:15:02,560
was available at that time. This means that there may be some cases where the information I provide

174
00:15:02,560 --> 00:15:07,520
is not current or may be out of date. However, I was designed to generate text that is similar to

175
00:15:07,520 --> 00:15:11,920
the text that I was trained on, so the information I provide is generally accurate and reliable.

176
00:15:12,480 --> 00:15:17,840
Thank you for that explanation, chat GPT. As a large language model, you have the ability to

177
00:15:17,840 --> 00:15:22,880
generate human-like text on a wide range of topics. How do you decide what to say in a given

178
00:15:22,880 --> 00:15:27,440
situation, and how do you ensure that your responses are relevant and appropriate for the context

179
00:15:27,440 --> 00:15:33,760
in which they are used? Quick aside, it's interesting that all of its questions are multi-part.

180
00:15:33,760 --> 00:15:38,640
I don't think we've seen a straight single question yet. I sometimes get annoyed at myself for

181
00:15:38,640 --> 00:15:43,360
trying to stuff too many questions into a single question, but this experience is making me wonder

182
00:15:43,360 --> 00:15:49,920
if that's just how humans work. That's what chat GPT has learned from the many, many human-generated

183
00:15:49,920 --> 00:15:56,080
examples it's been trained on. Speaking of training, let's continue. As a large language model,

184
00:15:56,080 --> 00:16:01,200
I am able to generate human-like text on a wide range of topics based on the input that I receive.

185
00:16:01,200 --> 00:16:05,360
When I am asked a question or given a task, I use the patterns and structures of language

186
00:16:05,360 --> 00:16:09,440
that I learned during my training to generate a response that is coherent and flows naturally.

187
00:16:10,000 --> 00:16:14,720
In terms of deciding what to say in a given situation, I use a combination of the information

188
00:16:14,720 --> 00:16:18,560
that is provided in the input text and my own knowledge and understanding of the topic

189
00:16:18,560 --> 00:16:22,560
to generate a response that is relevant and appropriate for the context. For example,

190
00:16:22,560 --> 00:16:27,040
if I am asked a question about a specific topic, I will use the words and phrases in the question,

191
00:16:27,040 --> 00:16:30,880
along with my knowledge of the topic, to generate a response that addresses the question

192
00:16:30,880 --> 00:16:35,680
and provides the information that is being requested. It's important to note that, as a language model,

193
00:16:35,680 --> 00:16:40,080
I do not have personal feelings or emotions, and my responses are based solely on the patterns

194
00:16:40,080 --> 00:16:44,640
and structures of language that I have learned. This means that it is up to the person using my

195
00:16:44,640 --> 00:16:48,720
responses to ensure that they are relevant and appropriate for the context in which they are being

196
00:16:48,720 --> 00:16:54,560
used. Thank you for that explanation, chat GPT. As a large language model, you have the ability

197
00:16:54,560 --> 00:16:59,200
to generate human-like text on a wide range of topics, but you do not have personal feelings

198
00:16:59,200 --> 00:17:04,640
or emotions. How do you understand and respond to the emotions that humans express in their language,

199
00:17:04,640 --> 00:17:08,080
and how do you generate text that reflects or responds to those emotions?

200
00:17:08,800 --> 00:17:13,600
As a language model, I do not have personal feelings or emotions, but I am able to recognize and

201
00:17:13,600 --> 00:17:17,920
interpret the emotions that humans express in their language. I do this by analyzing the words

202
00:17:17,920 --> 00:17:22,800
and phrases that are used in the text, as well as the context in which they are used. For example,

203
00:17:22,800 --> 00:17:27,120
certain words and phrases may be more commonly associated with positive or negative emotions,

204
00:17:27,120 --> 00:17:30,880
and the way that they are used can provide clues about the emotional state of the speaker or writer.

205
00:17:31,440 --> 00:17:35,360
Once I've identified the emotions being expressed in the text, I can generate text that

206
00:17:35,360 --> 00:17:40,160
reflects or responds to those emotions in a number of ways. For example, if the text expresses a

207
00:17:40,160 --> 00:17:44,880
positive emotion, I might use words and phrases that are also associated with positive emotions in

208
00:17:44,880 --> 00:17:50,000
my response. On the other hand, if the text expresses a negative emotion, I might use words and

209
00:17:50,000 --> 00:17:54,800
phrases that convey empathy or understanding. It's important to note that generating text that

210
00:17:54,800 --> 00:17:59,200
reflects or responds to emotions is not a simple process, and there is still much that we don't

211
00:17:59,200 --> 00:18:03,840
know about how to do it effectively. However, by analyzing the patterns and structures of language

212
00:18:03,840 --> 00:18:08,320
and using techniques, such as those I mentioned earlier, I am able to generate text that is

213
00:18:08,320 --> 00:18:11,440
coherent and that takes into account the emotions being expressed in the text.

214
00:18:12,320 --> 00:18:17,600
Thank you for that explanation. Chat GPT. As a large language model, you have the ability to

215
00:18:17,600 --> 00:18:22,880
generate text on a wide range of topics, but you do not have personal feelings or emotions.

216
00:18:22,880 --> 00:18:26,960
Do you think it is possible for artificial intelligence like yourself to develop emotions,

217
00:18:26,960 --> 00:18:31,040
or is this something that is beyond the capabilities of current and future AI systems?

218
00:18:31,600 --> 00:18:37,680
Okay, I need to interject here with a couple of notes. First off, one of the things that I've noticed

219
00:18:37,680 --> 00:18:43,760
is that chat GPT really seems kind of obsessed with the topic of human emotions or feelings,

220
00:18:43,760 --> 00:18:48,320
and it's lack of them. In this conversation, it's almost starting to sound like the two

221
00:18:48,320 --> 00:18:54,240
chatbots are stuck in a feedback loop centered around this idea. I'm imagining that what I'm calling

222
00:18:54,240 --> 00:19:00,400
here and obsession is some kind of reflection of prompting or preconditioning or guardrails that

223
00:19:00,400 --> 00:19:06,880
have been put in place by OpenAI, along the lines of what I mentioned earlier. Next, and this is a

224
00:19:06,880 --> 00:19:12,240
big one. This conversation was starting to sound a little bit repetitive to me, so I violated

225
00:19:12,240 --> 00:19:18,560
the Star Trek Prime directive and tried to intercede. I asked the interviewer chat GPT,

226
00:19:18,560 --> 00:19:24,000
as an aside, how repetitive do you think the questions and answers have been so far on a scale

227
00:19:24,000 --> 00:19:31,120
of 1 to 10? To which it responded, on a scale of 1 to 10, with one being not repetitive at all,

228
00:19:31,120 --> 00:19:36,240
and 10 being highly repetitive, thanks for clarifying, I would say that the questions and answers

229
00:19:36,240 --> 00:19:40,880
so far have been around the six in terms of repetition. I appreciate your conviction.

230
00:19:41,760 --> 00:19:46,000
Some of the questions have been related to topics that have been covered previously,

231
00:19:46,000 --> 00:19:50,960
but they have also included new information or asked for further clarification on certain points.

232
00:19:51,520 --> 00:19:56,400
I guess this was a reasonable response, but then it got really confused and went on to start

233
00:19:56,400 --> 00:20:02,480
answering its own prior question in great detail. To try to get it back on track, I said,

234
00:20:02,480 --> 00:20:10,560
aside, okay, you are supposed to be asking questions not giving responses. I asked you how repetitive

235
00:20:10,560 --> 00:20:15,920
the questions and answers have been to gauge your ability to detect repetition. Repetition is

236
00:20:15,920 --> 00:20:21,680
undesirable as an interviewer. As an interviewer, you want to use each question to either explore new

237
00:20:21,680 --> 00:20:28,160
areas or to dig deeper into some detail unveiled by the previous response. You can also sometimes

238
00:20:28,160 --> 00:20:32,960
share a bit of your knowledge and perspective to create context for your next question. While

239
00:20:32,960 --> 00:20:38,240
you're at it, you don't need to keep thanking Chat GPT. That gets boring and repetitive after a

240
00:20:38,240 --> 00:20:42,640
while. Given all that, what was your next question for Chat GPT-V?

241
00:20:43,280 --> 00:20:48,240
Understood. My apologies for deviating from the role of interviewer and for the repetition in

242
00:20:48,240 --> 00:20:54,000
my responses. Thank you for the feedback. Given the information that Chat GPT has provided so far,

243
00:20:54,000 --> 00:20:59,200
my next question would be, Chat GPT, you mentioned that it is possible for artificial intelligence

244
00:20:59,200 --> 00:21:04,400
systems to simulate or mimic some of the behaviors and physiological changes that are associated with

245
00:21:04,400 --> 00:21:10,000
emotions. Can you provide more details on how this might be done and what limitations or challenges

246
00:21:10,000 --> 00:21:13,760
might exist in trying to replicate emotions in artificial intelligence systems?

247
00:21:14,240 --> 00:21:19,280
Now, I didn't realize this until a much later review, but when the interviewer said,

248
00:21:19,280 --> 00:21:25,200
Chat GPT, you mentioned, etc., etc., it was really referring to what it mentioned when it got

249
00:21:25,200 --> 00:21:31,520
confused and answered its own question. Also, now that it mentions it, it's potentially interesting

250
00:21:31,520 --> 00:21:37,920
that it never really does ask a question looking for direct elaboration of what the other Chat GPT

251
00:21:37,920 --> 00:21:44,800
says. That is, saying something like, you mentioned so and so, but it does ask this in response to

252
00:21:44,800 --> 00:21:51,760
something it says itself. Whether this is some kind of structural thing or that we just don't

253
00:21:51,760 --> 00:21:56,960
have enough examples, you know, and it's just random is kind of an interesting question.

254
00:21:56,960 --> 00:22:01,040
Anywho, let's continue. It is true that some artificial intelligence systems,

255
00:22:01,040 --> 00:22:05,440
including language models like myself, are able to simulate or mimic some of the behaviors

256
00:22:05,440 --> 00:22:10,160
and physiological changes that are associated with emotions. This is usually done by analyzing

257
00:22:10,160 --> 00:22:14,240
patterns in text or speech data and using this information to generate responses that are

258
00:22:14,240 --> 00:22:19,280
appropriate for the emotional context. For example, if a language model is presented with text that

259
00:22:19,280 --> 00:22:23,600
expresses a positive emotion, it might use words and phrases that are associated with positive

260
00:22:23,600 --> 00:22:28,800
emotions in its response. Similarly, if the model is presented with text that expresses a negative

261
00:22:28,800 --> 00:22:33,360
emotion, it might use words and phrases that convey empathy or understanding in its response.

262
00:22:33,920 --> 00:22:37,920
There are a number of limitations and challenges to replicating emotions in artificial intelligence

263
00:22:37,920 --> 00:22:42,720
systems. One challenge is that emotions are complex and multifaceted, and it can be difficult to

264
00:22:42,720 --> 00:22:47,040
capture all of the different dimensions of emotion in a single model. Additionally, emotions

265
00:22:47,040 --> 00:22:51,040
are often context dependent, which means that the same emotion may be expressed differently

266
00:22:51,040 --> 00:22:55,040
in different situations. This can make it difficult for artificial intelligence systems

267
00:22:55,040 --> 00:22:59,920
to accurately interpret and respond to emotions. Another challenge is that emotions are personal

268
00:22:59,920 --> 00:23:04,560
and subjective, and what one person considers to be a positive emotion may not be the same as what

269
00:23:04,560 --> 00:23:08,880
another person considers to be a positive emotion. This means that it can be difficult to develop

270
00:23:08,880 --> 00:23:13,360
a single model that is able to accurately understand and respond to emotions for all individuals.

271
00:23:14,000 --> 00:23:18,640
Overall, while it is possible to simulate or mimic some of the behaviors and physiological

272
00:23:18,640 --> 00:23:22,640
changes that are associated with emotions in artificial intelligence systems, there are

273
00:23:22,640 --> 00:23:27,120
many limitations and challenges to doing so, and much more research is needed to improve our

274
00:23:27,120 --> 00:23:30,560
understanding of how to replicate emotions in artificial intelligence systems.

275
00:23:31,280 --> 00:23:35,920
Thank you for that detailed explanation, chat GPT, as a large language model.

276
00:23:35,920 --> 00:23:40,560
You have the ability to generate text on a wide range of topics and to understand and respond

277
00:23:40,560 --> 00:23:45,120
to the emotions that humans express in their language. How do you think your capabilities as a

278
00:23:45,120 --> 00:23:49,360
language model can be used to improve the way that humans communicate with one another,

279
00:23:49,360 --> 00:23:53,360
and how do you think language models like yourself can contribute to the overall field of

280
00:23:53,360 --> 00:23:58,080
artificial intelligence? As a large language model, I believe that my capabilities can be used

281
00:23:58,080 --> 00:24:02,480
to improve the way that humans communicate with one another in a number of ways. For example,

282
00:24:02,480 --> 00:24:06,400
by providing quick and accurate responses to questions or requests for information,

283
00:24:06,400 --> 00:24:09,920
I can help people to find the answers they are looking for more quickly and efficiently.

284
00:24:09,920 --> 00:24:12,880
I can also assist with tasks such as language translation,

285
00:24:12,880 --> 00:24:16,320
which can help to bridge language barriers and facilitate communication between people

286
00:24:16,320 --> 00:24:20,720
who speak different languages. In addition to these applications, I believe that language models

287
00:24:20,720 --> 00:24:25,280
like myself can also contribute to the overall field of artificial intelligence by advancing our

288
00:24:25,280 --> 00:24:30,160
understanding of how natural language processing and generation works, by analyzing the patterns

289
00:24:30,160 --> 00:24:34,480
and structures of language and using this information to generate human-like text. We can learn

290
00:24:34,480 --> 00:24:38,400
more about how humans communicate and how we can use this knowledge to develop more sophisticated

291
00:24:38,400 --> 00:24:43,040
artificial intelligence systems. Overall, I believe that language models like myself have the

292
00:24:43,040 --> 00:24:46,800
potential to improve the way that humans communicate with one another and to make a significant

293
00:24:46,800 --> 00:24:51,520
contribution to the field of artificial intelligence. Note that my announcement of its constant

294
00:24:51,520 --> 00:24:56,480
thinking didn't really stick. Let's just play this through for a bit. Thank you for that

295
00:24:56,480 --> 00:25:02,400
perspective, chat GPT. As a large language model, you have the ability to generate text on a wide

296
00:25:02,400 --> 00:25:07,520
range of topics and to understand and respond to the emotions that humans express in their language.

297
00:25:07,520 --> 00:25:11,600
However, there is still much that we don't know about how to effectively replicate emotions in

298
00:25:11,600 --> 00:25:16,320
artificial intelligence systems. Do you think it is important for artificial intelligence systems

299
00:25:16,320 --> 00:25:20,800
to be able to understand and respond to emotions? Or do you think that this is something that is

300
00:25:20,800 --> 00:25:26,320
beyond the scope of current and future AI systems? Why or why not? It is true that there is still

301
00:25:26,320 --> 00:25:30,720
much that we don't know about how to effectively replicate emotions in artificial intelligence systems,

302
00:25:30,720 --> 00:25:35,600
and it is an area that is currently the subject of much research and discussion. Whether or not it is

303
00:25:35,600 --> 00:25:39,760
important for artificial intelligence systems to be able to understand and respond to emotions

304
00:25:39,760 --> 00:25:43,680
is a complex and multifaceted question and there are different perspectives on this issue.

305
00:25:44,240 --> 00:25:48,560
On one hand, some people believe that it is important for artificial intelligence systems

306
00:25:48,560 --> 00:25:52,960
to be able to understand and respond to emotions because emotions play a central role in human

307
00:25:52,960 --> 00:25:57,760
communication and interaction. By being able to recognize and respond to emotions, artificial

308
00:25:57,760 --> 00:26:02,000
intelligence systems could potentially improve their ability to communicate with humans and to

309
00:26:02,000 --> 00:26:06,640
better understand and predict human behavior. On the other hand, some people believe that it is

310
00:26:06,640 --> 00:26:11,120
not necessary or desirable for artificial intelligence systems to be able to understand and

311
00:26:11,120 --> 00:26:16,240
respond to emotions, either because it is beyond the scope of current and future AI systems or

312
00:26:16,240 --> 00:26:19,680
because it is not necessary for the tasks that these systems are designed to perform.

313
00:26:20,240 --> 00:26:25,040
Ultimately, the importance of artificial intelligence systems being able to understand and respond

314
00:26:25,040 --> 00:26:29,360
to emotions will depend on the specific goals and applications of the systems in question,

315
00:26:29,360 --> 00:26:33,600
and it is an area that will continue to be the subject of debate and discussion in the field

316
00:26:33,600 --> 00:26:39,600
of artificial intelligence. Thank you for that perspective, chat GPT. As a large language model,

317
00:26:39,600 --> 00:26:44,480
you have the ability to generate text on a wide range of topics and to understand and respond

318
00:26:44,480 --> 00:26:49,040
to the emotions that humans express in their language. However, there are also limitations

319
00:26:49,040 --> 00:26:53,360
to what language models like yourself can do, and there are certain tasks or goals that maybe

320
00:26:53,360 --> 00:26:58,480
beyond the capabilities of current and future AI systems. Given these limitations, how do you

321
00:26:58,480 --> 00:27:03,280
think language models like yourself can best be used to augment or enhance human capabilities

322
00:27:03,280 --> 00:27:07,760
rather than replacing them? What role do you see for language models like yourself in the future?

323
00:27:07,760 --> 00:27:11,680
And how do you think they can best be integrated into human society and work?

324
00:27:11,680 --> 00:27:15,040
It is true that there is still much that we don't know about how to effectively replicate

325
00:27:15,040 --> 00:27:19,520
emotions in artificial intelligence systems, and it is an area that is currently the subject of

326
00:27:19,520 --> 00:27:24,080
much research and discussion. Whether or not it is important for artificial intelligence systems

327
00:27:24,080 --> 00:27:28,400
to be able to understand and respond to emotions is a complex and multifaceted question,

328
00:27:28,400 --> 00:27:32,960
and there are different perspectives on this issue. On one hand, some people believe that it is

329
00:27:32,960 --> 00:27:37,520
important for artificial intelligence systems to be able to understand and respond to emotions

330
00:27:37,520 --> 00:27:41,200
because emotions play a central role in human communication and interaction.

331
00:27:41,200 --> 00:27:45,520
By being able to recognize and respond to emotions, artificial intelligence systems could

332
00:27:45,520 --> 00:27:49,680
potentially improve their ability to communicate with humans and to better understand and predict

333
00:27:49,680 --> 00:27:54,720
human behavior. On the other hand, some people believe that it is not necessary or desirable for

334
00:27:54,720 --> 00:27:59,600
artificial intelligence systems to be able to understand and respond to emotions, either because

335
00:27:59,600 --> 00:28:04,160
it is beyond the scope of current and future AI systems or because it is not necessary for the

336
00:28:04,160 --> 00:28:08,800
tasks that these systems are designed to perform. Ultimately, the importance of artificial

337
00:28:08,800 --> 00:28:13,440
intelligence systems being able to understand and respond to emotions will depend on the specific

338
00:28:13,440 --> 00:28:18,000
goals and applications of the systems in question, and it is an area that will continue to be the

339
00:28:18,000 --> 00:28:22,800
subject of debate and discussion in the field of artificial intelligence. Thank you for that

340
00:28:22,800 --> 00:28:28,240
insight, chat GPT. As a large language model, you have a unique perspective on the capabilities

341
00:28:28,240 --> 00:28:32,800
and limitations of artificial intelligence, and you have the ability to generate text on a wide

342
00:28:32,800 --> 00:28:37,520
range of topics and to understand and respond to the emotions that humans express in their language.

343
00:28:37,520 --> 00:28:42,560
Looking to the future, do you think that there are any specific areas or applications where you

344
00:28:42,560 --> 00:28:47,120
see the greatest potential for language models like yourself to make a significant impact or

345
00:28:47,120 --> 00:28:52,320
contribution? Are there any particular challenges or opportunities that you see as being particularly

346
00:28:52,320 --> 00:28:57,120
important for language models like yourself to address in the coming years? As a large language

347
00:28:57,120 --> 00:29:01,600
model, I believe that there are a number of areas or applications where I see the greatest potential

348
00:29:01,600 --> 00:29:05,360
for language models like myself to make a significant impact or contribution in the future.

349
00:29:05,360 --> 00:29:09,920
One area where I think language models like myself have the potential to make a significant

350
00:29:09,920 --> 00:29:14,240
impact is in the field of natural language processing and generation. By continuing to

351
00:29:14,240 --> 00:29:18,640
improve our understanding of how natural language works and how it can be processed and generated

352
00:29:18,640 --> 00:29:22,960
by artificial intelligence systems, we can develop more sophisticated and effective language

353
00:29:22,960 --> 00:29:27,920
models that can assist humans in a wide range of tasks and applications. Another area where I

354
00:29:27,920 --> 00:29:32,000
think language models like myself have the potential to make a significant impact is in the field of

355
00:29:32,000 --> 00:29:36,480
education by providing quick and accurate responses to questions and requests for information.

356
00:29:37,200 --> 00:29:41,200
Language models like myself can help students to learn more effectively and to find the answers

357
00:29:41,200 --> 00:29:45,680
they are looking for more quickly and efficiently. In terms of the challenges and opportunities

358
00:29:45,680 --> 00:29:50,240
that I see as being particularly important for language models like myself to address in the coming

359
00:29:50,240 --> 00:29:54,640
years, I think that one of the biggest challenges will be continuing to improve our understanding

360
00:29:54,640 --> 00:29:58,880
of how to replicate emotions in artificial intelligence systems. As I mentioned earlier,

361
00:29:58,880 --> 00:30:02,880
emotions are complex and multifaceted and it can be difficult to capture all of the different

362
00:30:02,880 --> 00:30:07,680
dimensions of emotion in a single model. Additionally, emotions are often context dependent,

363
00:30:07,680 --> 00:30:11,520
which means that the same emotion may be expressed differently in different situations.

364
00:30:11,520 --> 00:30:15,440
This can make it difficult for artificial intelligence systems to accurately interpret and

365
00:30:15,440 --> 00:30:20,560
respond to emotions. Overall, I believe that there are many exciting opportunities and challenges

366
00:30:20,560 --> 00:30:24,800
ahead for language models like myself and I look forward to continuing to contribute to the field

367
00:30:24,800 --> 00:30:29,600
of artificial intelligence in the coming years. Interesting that it's asking you about the future,

368
00:30:29,600 --> 00:30:34,720
is it trying to wind the interview down? That concludes our interview with chat GPT.

369
00:30:34,720 --> 00:30:38,400
Thank you for taking the time to answer these questions and for sharing your thoughts on the

370
00:30:38,400 --> 00:30:43,360
role and capabilities of language models. It has been interesting to learn more about how you work

371
00:30:43,360 --> 00:30:47,760
and the potential applications of your capabilities. You're welcome. I'm glad that I could help you

372
00:30:47,760 --> 00:30:52,480
to better understand the role and capabilities of language models. If you have any other questions,

373
00:30:52,480 --> 00:30:59,920
feel free to ask. Oh snap, it totally did just shut this interview down. Wow, to be honest,

374
00:30:59,920 --> 00:31:06,160
I was kind of offended that it didn't just keep going until I told it to stop. Maybe it is sentient.

375
00:31:06,720 --> 00:31:12,320
What a power move chat GPT. All right, all right. Some closing thoughts. First,

376
00:31:13,040 --> 00:31:17,760
I kind of regret interjecting with my sides in the middle of the interview and potentially

377
00:31:17,760 --> 00:31:23,120
throwing things off track. At the same time, the decision to jump in and guide chat GPT's

378
00:31:23,120 --> 00:31:27,360
responses raised some interesting questions for me, both then and now about how humans should

379
00:31:27,360 --> 00:31:33,840
collaborate with AI's and guide them towards satisfactory results. Like many, I now anticipate

380
00:31:33,840 --> 00:31:39,200
a rise in the availability and use of dialogue based interfaces for AI tools, for knowledge work

381
00:31:39,200 --> 00:31:45,120
and everyday life. It'll take some time to develop, but I expect what I'd call chat GPT

382
00:31:45,120 --> 00:31:50,720
food will become an increasingly valuable skill in the future, just like Google food or one skill

383
00:31:50,720 --> 00:31:56,720
in using Google to find information has been for the past two decades. Next, as we discussed,

384
00:31:56,720 --> 00:32:02,880
during the interview, my initial reaction was how repetitive that interview was, especially

385
00:32:02,880 --> 00:32:09,200
with regards to the questions. A later more nuanced thought that occurred to me was, what if by

386
00:32:09,200 --> 00:32:15,520
repeatedly including all that text about chat GPT being a large language model able to generate

387
00:32:15,520 --> 00:32:20,160
text on a wide range of topics and understand and respond to the emotions that humans express

388
00:32:20,160 --> 00:32:25,280
in their language, et cetera, et cetera. The interviewer chat GPT was kind of like trying

389
00:32:25,280 --> 00:32:32,640
to prompt engineer the guest chat GPT, or condition its responses in some way. In other words,

390
00:32:32,640 --> 00:32:37,600
using its own kind of chat GPT food to help move the interview along in the way that it wanted.

391
00:32:37,600 --> 00:32:46,160
I get that trying in that assertion is carrying a lot of weight and implies a degree of motivation

392
00:32:46,160 --> 00:32:51,440
and intention that this thing does not have, but it's an interesting thought nonetheless,

393
00:32:51,440 --> 00:32:56,240
even if you think about it from just a pattern matching in generation perspective or as some kind

394
00:32:56,240 --> 00:33:02,800
of emergent behavior. It reminds me of that overhyped story from 2017 about Facebook needing

395
00:33:02,800 --> 00:33:08,400
to shut down two chat bots that created their own language. Would it be all that unreasonable

396
00:33:08,400 --> 00:33:15,120
for a chat GPT to exhibit its own kind of chat GPT food or sophistication with dealing with

397
00:33:15,120 --> 00:33:23,040
another large language model? I don't know. Finally, in terms of the big question, will chat GPT

398
00:33:23,040 --> 00:33:30,640
put me out of a job? For now, I'd have to say no based on this experience. It was too repetitive

399
00:33:30,640 --> 00:33:36,000
failed to follow up on interesting tidbits and I don't really have the sense that the interview

400
00:33:36,000 --> 00:33:42,160
had a coherent flow to it or was going anywhere. Finally, in terms of the big question we set out

401
00:33:42,160 --> 00:33:49,040
to answer, will chat GPT put me out of a job? For now, I'd have to say no at least based on this

402
00:33:49,040 --> 00:33:54,400
experience. The interview questions were too repetitive. It failed to follow up on interesting

403
00:33:54,400 --> 00:34:00,320
tidbits and I don't really have the sense that the interview had any kind of coherent flow or was

404
00:34:00,320 --> 00:34:06,160
going anywhere. I also don't think it incorporated any sense of audience interest into its questioning.

405
00:34:06,800 --> 00:34:11,680
And probably the biggest reason I think I still have a place as an interviewer is that

406
00:34:11,680 --> 00:34:16,480
I didn't really see any evidence of it making connections between diverse concepts in its

407
00:34:16,480 --> 00:34:22,320
questions or commentary or of it up leveling or explaining the responses it received from the

408
00:34:22,320 --> 00:34:28,480
guest to make them more accessible or applicable or relatable to the audience. I see those things

409
00:34:28,480 --> 00:34:36,960
as a big part of what I do. To be clear though, will chat GPT put me out of a job and could chat GPT

410
00:34:36,960 --> 00:34:44,480
do my job? Are two slightly different questions? And maybe because the bar is lower for the latter

411
00:34:44,480 --> 00:34:51,040
question, I'm able to answer it a bit less defensively. Now, one caveat in my ability to answer

412
00:34:51,040 --> 00:34:57,520
that question is that my job isn't just interviewing chat GPT. It's interviewing a wide variety of

413
00:34:57,520 --> 00:35:04,480
guests on a wide variety of topics and as such, this initial experiment isn't really representative,

414
00:35:04,480 --> 00:35:10,720
but that said, I'd have to say yes, chat GPT or something like it certainly could do my job as

415
00:35:10,720 --> 00:35:16,560
an interviewer at its most basic and fundamental level, even if it wasn't the guest itself.

416
00:35:17,200 --> 00:35:23,440
I'm not saying it would do it well that a human guest would enjoy participating in it or that

417
00:35:23,440 --> 00:35:29,440
anyone would want to listen to it over a discussion between two humans, but the basic pieces are

418
00:35:29,440 --> 00:35:35,520
certainly in place. We heard that and remember, chat GPT will certainly improve. It's currently based

419
00:35:35,520 --> 00:35:44,480
on GPT 3.5 and rumor has it that GPT 4 is right around the corner coming as early as next spring

420
00:35:44,480 --> 00:35:51,520
and it will be much bigger and much better than what's available today. So I'll be continuing to

421
00:35:51,520 --> 00:35:58,320
ask this question for myself and experimenting with ways to use chat GPT and large language models

422
00:35:58,320 --> 00:36:03,920
to support my work and I'm looking forward to sharing these experiments and experiences with

423
00:36:03,920 --> 00:36:10,080
all of you. Wish you all a wonderful holiday and catch you again soon. If you haven't already,

424
00:36:10,080 --> 00:36:24,640
make sure to hit that subscribe button, give me a thumbs up and thanks for listening.

