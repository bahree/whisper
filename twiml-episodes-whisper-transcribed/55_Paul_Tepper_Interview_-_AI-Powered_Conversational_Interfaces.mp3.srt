1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,320
I'm your host Sam Charrington.

4
00:00:23,320 --> 00:00:27,520
This show you are about to hear as part of a series of shows recorded in San Francisco

5
00:00:27,520 --> 00:00:32,040
at the Artificial Intelligence Conference, which was hosted by our friends at O'Reilly

6
00:00:32,040 --> 00:00:33,840
in Intel Nirvana.

7
00:00:33,840 --> 00:00:39,040
In addition to their support for the event itself, Intel Nirvana is also our sponsor for this

8
00:00:39,040 --> 00:00:41,400
series of podcasts from the event.

9
00:00:41,400 --> 00:00:45,640
A huge thanks to them for their continued support of this show.

10
00:00:45,640 --> 00:00:50,680
Make sure you check out my interview with Navine Rao, VP and GM of Intel's AI products

11
00:00:50,680 --> 00:00:56,000
group, and Scott Appland, director of Intel's developer network, which you can find at

12
00:00:56,000 --> 00:01:00,360
Twimbleai.com slash talk slash 51.

13
00:01:00,360 --> 00:01:06,400
At the AI conference, Intel Nirvana announced DevCloud, a cloud hosted hardware and software

14
00:01:06,400 --> 00:01:13,280
platform for learning, sandboxing and accelerating the development of AI solutions.

15
00:01:13,280 --> 00:01:19,520
The DevCloud will be available to 200,000 developers, researchers, academics and startups

16
00:01:19,520 --> 00:01:23,400
via the Intel Nirvana AI Academy this month.

17
00:01:23,400 --> 00:01:30,000
For more information on the DevCloud or the AI Academy, visit intelnervana.com slash

18
00:01:30,000 --> 00:01:31,760
DevCloud.

19
00:01:31,760 --> 00:01:37,800
My guess for this show is Paul Tepper, Worldwide Head of Cognitive Innovation and Product

20
00:01:37,800 --> 00:01:43,120
Manager for Machine Learning and AI at Nuance Communications.

21
00:01:43,120 --> 00:01:48,880
Paul gave a talk at the conference on critical factors in building successful AI-powered conversational

22
00:01:48,880 --> 00:01:50,600
interfaces.

23
00:01:50,600 --> 00:01:57,440
We covered this and a bunch of other topics like voice UI design, behavioral biometrics,

24
00:01:57,440 --> 00:02:01,200
and other interesting things that Nuance has in the works.

25
00:02:01,200 --> 00:02:04,200
And now on to the show.

26
00:02:04,200 --> 00:02:15,920
Alright everyone, I am here at the AI conference in San Francisco and I'm with Paul Tepper,

27
00:02:15,920 --> 00:02:22,680
who is the Worldwide Head of Cognitive Innovation and the Product Manager for AI and Machine

28
00:02:22,680 --> 00:02:28,080
Learning at Nuance Communications, the Enterprise Division of Nuance Communications in particular.

29
00:02:28,080 --> 00:02:32,840
I had the pleasure of meeting Paul at the AI conference in New York just a few months

30
00:02:32,840 --> 00:02:38,760
ago and he was kind enough to volunteer to jump in the hot seat.

31
00:02:38,760 --> 00:02:40,000
So welcome Paul.

32
00:02:40,000 --> 00:02:41,000
Thank you.

33
00:02:41,000 --> 00:02:42,000
Good to be here.

34
00:02:42,000 --> 00:02:43,000
Absolutely.

35
00:02:43,000 --> 00:02:44,000
Absolutely.

36
00:02:44,000 --> 00:02:48,960
So let's start by having you introduce yourself to the audience and talk a little bit about

37
00:02:48,960 --> 00:02:52,840
your background and how you got into Machine Learning and AI.

38
00:02:52,840 --> 00:02:53,840
Sure.

39
00:02:53,840 --> 00:02:58,600
Well for about a year now I've worked at Nuance Communications with our Enterprise Division.

40
00:02:58,600 --> 00:03:01,280
I lead a team that has a few functions.

41
00:03:01,280 --> 00:03:05,640
One of our main functions is identifying high value problems for which the company doesn't

42
00:03:05,640 --> 00:03:11,000
yet have a solution and working with our large corporate research division to see if we

43
00:03:11,000 --> 00:03:16,360
have new forward looking research that could be sort of productized or prototyped to get

44
00:03:16,360 --> 00:03:21,240
in front of customers as a way to kind of move innovation in product, give the product

45
00:03:21,240 --> 00:03:25,920
manager and teams across the company new opportunities and things to look at there.

46
00:03:25,920 --> 00:03:30,000
I did my PhD at Northwestern, my focus was on computational linguistics particularly

47
00:03:30,000 --> 00:03:31,000
in dialogue.

48
00:03:31,000 --> 00:03:35,640
It's had a lot of work on nonverbal behavior, gesture in particular and I also spent

49
00:03:35,640 --> 00:03:39,520
a few years prior to Nuance working on a startup not around anymore, it was called

50
00:03:39,520 --> 00:03:46,920
Citibon and we focused on building cloud-based NLP platform that really focused on human

51
00:03:46,920 --> 00:03:51,600
and loop computing and crowdsourcing as a way to quickly build data sets out to build

52
00:03:51,600 --> 00:03:53,120
custom models for NLP.

53
00:03:53,120 --> 00:03:54,120
Okay.

54
00:03:54,120 --> 00:03:58,960
I don't think I realized the Northwestern connection, I'm a PhD job out at it.

55
00:03:58,960 --> 00:04:00,760
I was really impressed.

56
00:04:00,760 --> 00:04:01,760
Yeah.

57
00:04:01,760 --> 00:04:03,000
Engineering on my side were you engineering or?

58
00:04:03,000 --> 00:04:04,000
Yeah.

59
00:04:04,000 --> 00:04:08,480
I helped to found this program called the Technology and Social Behavior Program that

60
00:04:08,480 --> 00:04:13,920
was a joint degree in computer science and communication studies of all things but that's

61
00:04:13,920 --> 00:04:16,760
where we ended up in communication studies doing a lot of work at that time.

62
00:04:16,760 --> 00:04:17,760
Okay.

63
00:04:17,760 --> 00:04:18,760
That was super interesting.

64
00:04:18,760 --> 00:04:19,760
Super interesting.

65
00:04:19,760 --> 00:04:20,760
Do you miss Evanston?

66
00:04:20,760 --> 00:04:22,760
I'm more of an East Coast guy.

67
00:04:22,760 --> 00:04:26,640
I am an undergrad at Rutgers and I spent a year in Scotland and my master's out there

68
00:04:26,640 --> 00:04:30,400
so I traveled around quite a bit but I'm definitely an East Coast guy.

69
00:04:30,400 --> 00:04:31,400
Nice.

70
00:04:31,400 --> 00:04:32,400
Nice.

71
00:04:32,400 --> 00:04:38,160
I think the folks will get a little bit more about what you're up to now if you maybe

72
00:04:38,160 --> 00:04:41,840
spend a few minutes talking about nuance and what nuance is doing.

73
00:04:41,840 --> 00:04:42,840
Yeah.

74
00:04:42,840 --> 00:04:48,280
So nuance is a fairly large complicated company with about 14,000 employees and several

75
00:04:48,280 --> 00:04:49,280
different divisions.

76
00:04:49,280 --> 00:04:54,280
We have a division that focuses strictly on mobility, mobile products, automotive products.

77
00:04:54,280 --> 00:04:59,680
We have ASR and a lot of cars that people drive due recognition for cars, the in-car systems.

78
00:04:59,680 --> 00:05:05,480
We've got a healthcare division that is some of the top systems for dedication for doctors

79
00:05:05,480 --> 00:05:09,840
to do electronic medical records and imaging division and my division in particular focuses

80
00:05:09,840 --> 00:05:15,360
on enterprise communications and we have two main product areas or areas of focus and

81
00:05:15,360 --> 00:05:19,800
that's one IVR systems or interactive voice response and that was one of the first commercial

82
00:05:19,800 --> 00:05:23,480
applications of speech recognition systems that you can call into and instead of doing

83
00:05:23,480 --> 00:05:27,760
kind of dial tone menus you can just say what you want conversationally and more recently

84
00:05:27,760 --> 00:05:30,440
our focus has been on the digital side.

85
00:05:30,440 --> 00:05:34,000
Now they're called chatbots but we've been calling them virtual systems for a long time

86
00:05:34,000 --> 00:05:37,240
and actually there's a lot of overlap in those two technologies.

87
00:05:37,240 --> 00:05:44,120
So a lot of the technology that has been built out for IVR so to recognize intent, to recognize

88
00:05:44,120 --> 00:05:49,480
concepts and do entity extraction inside sentences and then also the dialogue build out the dialogue

89
00:05:49,480 --> 00:05:52,240
flows with other graphs or trees to build through a dialogue.

90
00:05:52,240 --> 00:05:55,840
A lot of that actually works similarly in the chat world.

91
00:05:55,840 --> 00:05:59,240
However in the IVR world the utterances tend to be a lot shorter.

92
00:05:59,240 --> 00:06:02,520
The chat world will tend to talk a lot longer so different complexities there.

93
00:06:02,520 --> 00:06:06,360
That's an actually an active area of research for us so how do we use user experience?

94
00:06:06,360 --> 00:06:10,960
How do we use UX to get people to talk longer in IVR so we have more because the natural

95
00:06:10,960 --> 00:06:16,320
language understanding or NLU as we call it has really far outpaced what people actually

96
00:06:16,320 --> 00:06:21,480
say today in IVR systems so that's an interesting technical challenge for us.

97
00:06:21,480 --> 00:06:26,400
Yeah I think of when I think of IVR I think of call center and I think of the objective

98
00:06:26,400 --> 00:06:30,480
on both the person that's interacting with the call center and the company that's making

99
00:06:30,480 --> 00:06:34,960
it available is to keep the interaction as short as possible and it sounds like the

100
00:06:34,960 --> 00:06:38,240
technology is allowing us to go the opposite direction.

101
00:06:38,240 --> 00:06:43,200
I think the technical terms in the industry are things like containment so keeping the

102
00:06:43,200 --> 00:06:47,640
user contained to the IVR as opposed to transferring to a live agent or using live agents

103
00:06:47,640 --> 00:06:51,800
are more expensive and not just expense it's actually hard to staff them even if you

104
00:06:51,800 --> 00:06:55,000
have all the resources in the world it's hard to hire up call centers that are big enough

105
00:06:55,000 --> 00:06:59,240
for some companies to even handle attractive if they even wait on limited budget.

106
00:06:59,240 --> 00:07:03,200
So containment's a big one and our one's first contact revolution is a popular KPI in

107
00:07:03,200 --> 00:07:07,240
the industry so that you can have a you don't have to call back you know your resolves

108
00:07:07,240 --> 00:07:13,000
within that first call so it's not always about short but it tends to be about can you

109
00:07:13,000 --> 00:07:18,000
build self-service so being able to let the user call and interact with a system that they

110
00:07:18,000 --> 00:07:21,600
can solve their problem automatically and I'll talk about that in my talk a little bit

111
00:07:21,600 --> 00:07:25,640
about some of the statistics that have come out recently showing that today especially

112
00:07:25,640 --> 00:07:29,560
with like younger generations and consumers people really don't care whether they're

113
00:07:29,560 --> 00:07:34,120
talking to a machine or a human they just want to get their problem solved and in some

114
00:07:34,120 --> 00:07:38,360
cases there's even times prefer it prefer to talk to a human you know sensitive situation

115
00:07:38,360 --> 00:07:42,600
sorry prefer to talk to a bot maybe a sensitive situation you know you have to call in and

116
00:07:42,600 --> 00:07:46,360
talk about you know I need a change of flight because of a death in the family or something

117
00:07:46,360 --> 00:07:50,200
in some cases like that you don't it's sensitive and you don't actually want to talk to

118
00:07:50,200 --> 00:07:54,200
a person even though people have this feeling that emotional intelligence is so important

119
00:07:54,200 --> 00:07:58,280
sometimes it's actually you don't want to get into it you just want to get your transaction

120
00:07:58,280 --> 00:08:04,840
done yeah yeah so you mentioned your talk what's the title of your talk I believe it's a long

121
00:08:04,840 --> 00:08:11,320
title I think it's critical factors in conversational interfaces design and commercial interfaces

122
00:08:11,320 --> 00:08:15,880
they don't know the whole thing memorized so kind of lessons learned in best practices that you've

123
00:08:15,880 --> 00:08:19,720
come across along the way yeah it'll be a mix of lessons learned in best practices as well as

124
00:08:19,720 --> 00:08:23,960
some of the newer things we've discovered and developed new ones okay so walk us through walk us

125
00:08:23,960 --> 00:08:28,120
through those yeah sounds like a fascinating topic put me on the spot I don't think they have

126
00:08:28,120 --> 00:08:34,200
them all memorized at the point I think I practiced your talk I've got about I think 10 at this point

127
00:08:34,200 --> 00:08:37,800
that we're going to talk about yeah I think I had previously done a version this talk where I had

128
00:08:37,800 --> 00:08:42,920
six and this talk that talk was 20 minutes so I thought okay 35 minutes I've got to beef it up a

129
00:08:42,920 --> 00:08:48,040
little bit yeah well just expand upon some of the ones that I briefed three to one through so I

130
00:08:48,040 --> 00:08:53,720
kind of go there's like a high level of things like context and personalization so if you're

131
00:08:53,720 --> 00:08:59,480
on a website and you're browsing let's we deal a lot with like banks and insurance and those kind

132
00:08:59,480 --> 00:09:05,400
of enterprises and you're in the auto insurance part of the website and a chat bot pops up and

133
00:09:05,400 --> 00:09:09,240
says can I help you it actually you know that's the typical thing they're going to say right can I

134
00:09:09,240 --> 00:09:15,240
help you but at this point in the website basic UX you know we'll let you know you should say

135
00:09:15,240 --> 00:09:22,840
hi so and so hi Paul how can I help you with auto insurance those basic principles of UX have not

136
00:09:22,840 --> 00:09:27,480
totally been carried over yet into chatbot world so it's those kind of things like building those

137
00:09:27,480 --> 00:09:31,160
integrations into the systems it's the websites and stuff a lot of times these chat bots are

138
00:09:31,160 --> 00:09:34,920
come from a different platform so you have to actually build those integrations between the

139
00:09:34,920 --> 00:09:39,720
companies website and the chatbot and those kind of things basic UX but they're not totally there

140
00:09:39,720 --> 00:09:46,360
yet in the chatbot world it's funny you you mentioned that I've been kind of on the dl evangelizing

141
00:09:46,360 --> 00:09:52,520
this idea that that a lot of you know what we've learned so much about user experience design

142
00:09:52,520 --> 00:09:59,240
in the web world and in mobile and kind of in these other interface technologies that hasn't really

143
00:09:59,240 --> 00:10:06,280
made it into or we haven't formalized to the degree yet or in and around AI and artificially

144
00:10:06,280 --> 00:10:11,800
intelligent user interfaces and I think the you know so I call it intelligent design but that's

145
00:10:11,800 --> 00:10:19,480
kind of a worldwide term. I haven't come up with the ideal the the ideal replacement for that one

146
00:10:19,480 --> 00:10:27,560
but as certainly you know chatbots are the kind of the tip of the spear so to speak but even devices

147
00:10:27,560 --> 00:10:33,000
like your nest thermostat or something like that there's I think there are like unique things

148
00:10:33,000 --> 00:10:39,000
that you need to take into account to you know make sure that users are comfortable with the

149
00:10:39,000 --> 00:10:44,200
fact that this thing has some intelligence and also kind of signal to them how to interact with

150
00:10:44,200 --> 00:10:50,200
the intelligence. That's interesting now nuance has been doing we call vui design for a long time

151
00:10:50,200 --> 00:10:54,200
or voice user interface design and many of the people who design many of them backgrounds in

152
00:10:54,200 --> 00:10:59,800
linguistics PhDs in linguistics even who design the flow of the conversation and we'll do you know

153
00:10:59,800 --> 00:11:05,480
user testing AB testing etc to figure out what the rest flows are and you'll see these people

154
00:11:05,480 --> 00:11:10,200
who the people with this experience are being scooped up now by google and amazon so you look

155
00:11:10,200 --> 00:11:15,000
at the people now who google has a whole vui design team now for a assistant as is amazon a lot

156
00:11:15,000 --> 00:11:19,880
of former nuance people because we've been doing this for a long time in the ivr world and it turns

157
00:11:19,880 --> 00:11:26,440
out like a lot of those a lot of the basic principles of how a conversation works without a screen

158
00:11:26,440 --> 00:11:32,280
transfer over to these note these kind of like iot devices and it's different when you have a screen

159
00:11:32,280 --> 00:11:37,320
when the screen we actually know a lot about a lot about web design ux and that's another problem

160
00:11:37,320 --> 00:11:41,880
right like there's this area of overlap between a non-like thinking of a venn diagram of like

161
00:11:41,880 --> 00:11:46,680
conversational user interfaces on or voicers in a race to sign web user interface design and that

162
00:11:46,680 --> 00:11:51,560
little spot in the middle of the overlap in the venn diagram where this weird world of okay well

163
00:11:51,560 --> 00:11:55,160
the conversational principles aren't going to cover it completely the web principles are going

164
00:11:55,160 --> 00:11:58,040
to cover completely so you have to kind of merge those two together and figure out things like

165
00:11:58,040 --> 00:12:03,400
okay well on this part of the website the person's browsing you know looking at whatever product

166
00:12:03,400 --> 00:12:07,720
the conversational agent needs to know about that stuff that's one of the things i'll be talking about

167
00:12:07,720 --> 00:12:12,120
another thing is security making it easier for people to either authenticate via traditional

168
00:12:12,120 --> 00:12:17,720
password or SSO as well as new ones as voicebound metric product so you can really transfer you over

169
00:12:17,720 --> 00:12:22,760
to say like my voice is my password use a voice print to identify i don't get the sense that that's

170
00:12:22,760 --> 00:12:29,400
very popular i haven't read it no no no it's it's really new cutting edge and it's it's it's

171
00:12:29,400 --> 00:12:33,640
easier than mobile devices from the mobile devices where we're building virtual distance there

172
00:12:33,640 --> 00:12:37,800
where the whole interface is spoken it's a little bit more you know part of the flow but we are

173
00:12:37,800 --> 00:12:43,320
to vote prototype systems now or you can actually voice print if i or a bank on the web or

174
00:12:43,320 --> 00:12:51,000
oh wow yeah that's a huge it's a huge friction point i think of the the places that that

175
00:12:51,000 --> 00:12:56,120
recognize my number and based on my number you know associate me with a record like the airlines

176
00:12:56,120 --> 00:13:00,200
for example have done a really good job of coming up to the speed on this in the past few years

177
00:13:00,200 --> 00:13:05,000
but then there are other places where they're like okay type or say your password and i'm like well

178
00:13:05,000 --> 00:13:10,680
you know it's like 26 characters and it's in my password safe thing or yeah there's no way

179
00:13:10,680 --> 00:13:14,840
i'm either going to type it or say it yeah so and this is this is another it's a big area of

180
00:13:14,840 --> 00:13:18,760
AI machine learning you know is these systems are all AI machine learning driven these voice

181
00:13:18,760 --> 00:13:23,880
biometric systems are sitting there's also face print identification now we do some work there

182
00:13:23,880 --> 00:13:27,800
and we'll start to see other kinds of biometrics too like behavioral biometrics i've heard of this

183
00:13:27,800 --> 00:13:32,680
where the way a person interacts with a website the way they move their mouths this the cadence

184
00:13:32,680 --> 00:13:37,880
at which they type etc that also creates a unique fingerprint of that person very very hard

185
00:13:37,880 --> 00:13:44,040
to spoof fingerprint i think my first experience with that is with coursera like when you when

186
00:13:44,040 --> 00:13:48,840
you're taking a coursera course like the andering you know deep learning course like you there's

187
00:13:48,840 --> 00:13:54,120
an honor code and you have to type out this honor code thing that says that you know this is you and

188
00:13:54,120 --> 00:13:58,920
when you're taking one of their exams you type this passage out again and it uses that to

189
00:13:58,920 --> 00:14:02,920
verify that you're you i didn't see that i think if you don't if it doesn't think you're you

190
00:14:02,920 --> 00:14:07,560
you have to take a picture with your webcam that's cool how okay that's really cool yeah so that's

191
00:14:07,560 --> 00:14:12,920
that's another gets a reducing that friction point and i'll be spending a while talking about

192
00:14:12,920 --> 00:14:18,520
some new techniques that we're using to try to incorporate unsupervised learning into our pipeline

193
00:14:18,520 --> 00:14:23,560
now this is kind of a frontier area for a right now the majority of it's all supervised at this

194
00:14:23,560 --> 00:14:32,200
point but we're looking at methods where you can take in a set of chat logs or voice conversation

195
00:14:32,200 --> 00:14:39,000
transcripts and the big thing with chatbots and with conversational systems is the first layer is

196
00:14:39,000 --> 00:14:44,200
the nlu the intent classification so what are the what's the intent of the burden of saying such

197
00:14:44,200 --> 00:14:48,360
that then you can then you know respond to that intent whether it's like check my balance or pay

198
00:14:48,360 --> 00:14:54,040
a bill or working on looking at data sets and extracting those intense automatically through unsupervised

199
00:14:54,040 --> 00:14:59,960
learning he kind of double click on that and give a little bit more detail there yeah sure so

200
00:14:59,960 --> 00:15:04,120
unsupervised methods one of the big things they tend to do is group things together automatically

201
00:15:04,120 --> 00:15:10,040
yeah clustering or hierarchical clustering or various kinds of methods that bucket things together

202
00:15:10,040 --> 00:15:15,240
so i can't give out all the secrets off there but that's part of it yeah that's part of it involves

203
00:15:15,240 --> 00:15:19,000
that and part of it involves other steps that can actually identify what the intense are of those

204
00:15:19,000 --> 00:15:25,240
cluster automatically so as a first pass this used to have to all be done manually our our

205
00:15:25,240 --> 00:15:28,600
we call them speech scientists and also our data scientists would have to go through the data

206
00:15:28,600 --> 00:15:33,000
to figure out what the intense were in a large data set as well as interviewing subject matter

207
00:15:33,000 --> 00:15:37,400
experts out of company now is the first pass but today we've managed to cut down a process that

208
00:15:37,400 --> 00:15:41,960
you know used to take hundreds of hours down to a few days months down to a few days by using

209
00:15:41,960 --> 00:15:47,240
this new process that we call intent discovery whereby you can bucket the data and then automatically

210
00:15:47,240 --> 00:15:53,000
identify what the intense are in the data then you can use those data use those that bucketing

211
00:15:53,000 --> 00:15:59,080
to automatically label the data so you get a first pass at like a labeled data set and bootstrap a

212
00:15:59,080 --> 00:16:04,680
model or train a model off of that put a model online now the idea here is that the system won't

213
00:16:04,680 --> 00:16:09,720
necessarily have the same accuracy as it would with a hand tuned system so respecting a hand

214
00:16:09,720 --> 00:16:15,480
to just be 85 90 percent accurate one of these bootstrap systems might be like 65 70 percent

215
00:16:15,480 --> 00:16:21,560
accurate but then what we do is we put that system online and for all the questions that the

216
00:16:21,560 --> 00:16:26,920
VA or the bot the vertus or the bot doesn't know we can pass off for one turn to we call it a hidden

217
00:16:26,920 --> 00:16:32,200
agent a person a human in the loop they can then check what the intent was for that and send it

218
00:16:32,200 --> 00:16:37,240
back to the system so the user ends up with this seamless experience of they're just talking to a

219
00:16:37,240 --> 00:16:41,320
bot would be with like a five second delay when it goes to the person or 10 second delay where it says

220
00:16:41,320 --> 00:16:46,120
hold on I'm checking with you know checking with one of my partners then we can use that data then

221
00:16:46,120 --> 00:16:50,280
train in the future and then we won't have to have that you know that missing data that loop in the

222
00:16:50,280 --> 00:16:55,320
future that makes sense no it makes it makes a ton of sense it I'm wondering does this

223
00:16:55,320 --> 00:17:02,120
create a new business model for nuance where we're in previously I'd imagine you're you selling an

224
00:17:02,120 --> 00:17:08,040
enterprise some set of technology whereas now it's you know the technology but also the service

225
00:17:08,040 --> 00:17:14,040
like are you providing the agents yeah that does this or are the you providing a you know a console

226
00:17:14,040 --> 00:17:19,880
that they can have their own virtual agents doing the checking yeah or both so yeah a few years

227
00:17:19,880 --> 00:17:24,840
ago about here two years ago we acquired a company called touch commerce which is a live chat

228
00:17:24,840 --> 00:17:30,040
platform they provide a whole suite of live chat they also they can provide the agents to you

229
00:17:30,040 --> 00:17:35,000
or they can just provide the interface to you so we have that which is really cool too because now we

230
00:17:35,000 --> 00:17:39,160
can if a VA doesn't know if a virtual system doesn't know the answer or chat button doesn't know

231
00:17:39,160 --> 00:17:43,000
the answer we can we could if a company wants to partner with us transfer that way transferred

232
00:17:43,000 --> 00:17:47,480
directly to our live chat but we also talk work with lots of companies who have their own live chat

233
00:17:47,480 --> 00:17:51,960
platforms a big one in Salesforce they provide live chats with really popular one of these days

234
00:17:51,960 --> 00:17:58,520
transfer to those agents we have a console we can provide to allow companies to have this to use

235
00:17:58,520 --> 00:18:03,800
their own pool of live agents to do this human assisted step or we can provide the software and

236
00:18:03,800 --> 00:18:07,720
the agents we've all different ways of working on it it's very you know we can customize and

237
00:18:07,720 --> 00:18:12,360
all different ways with that not to be too salesy here but you know we have all different ways

238
00:18:12,360 --> 00:18:16,040
of working on it and yeah it is it is a new it is kind of a new line of business the new way of

239
00:18:16,040 --> 00:18:23,320
thinking about it okay all right what else oh targeting that's another big area so when do you

240
00:18:23,320 --> 00:18:28,760
have a chat window actually pop up you know I think based on the way it's implemented now always

241
00:18:28,760 --> 00:18:34,440
always right yeah and it seems like and when I use these systems I it just seems like no rhyme or

242
00:18:34,440 --> 00:18:39,080
reason for I feel like a lot of times these systems it's just a clock or something right and like

243
00:18:39,080 --> 00:18:44,280
if you've been on the page longer than 30 seconds it pops up or if you're visiting the site on your

244
00:18:44,280 --> 00:18:50,280
mobile phone do it you know immediately secure everything else yeah see there's the UX that

245
00:18:50,280 --> 00:18:56,760
she's totally worked out yeah we we have a targeting engine that's constantly undergoing new

246
00:18:56,760 --> 00:19:01,320
prototypes and stuff but that's aimed at like when are you interact with the user how do you

247
00:19:01,320 --> 00:19:05,880
interact with the user in what way what language do you use what even down to like the colors and

248
00:19:05,880 --> 00:19:11,480
stuff on the interface and that targeting engine is based on all kinds of things like how long

249
00:19:11,480 --> 00:19:15,800
has the user been on the page is certainly one of them but what what have they put in their shopping

250
00:19:15,800 --> 00:19:19,000
car like they put something in their shopping cart and walked away so there's all these different

251
00:19:19,560 --> 00:19:25,000
inputs to the system that you can use to then tune when you're going to pop up that you know pop

252
00:19:25,000 --> 00:19:31,000
up that chatbot to ask if they want to talk to an agent or talk to Nina's the name of our

253
00:19:31,000 --> 00:19:37,480
registers talk to Nina talk to a chatbot and assuming it's machine learning driving that ultimate

254
00:19:37,480 --> 00:19:46,200
target decision how transferable are the models from one customer one one one website to another

255
00:19:46,200 --> 00:19:52,200
like are you training these models on a customer by customer basis or is there you know you have

256
00:19:52,200 --> 00:19:59,320
industry models or is there a generic model that outperforms just show the chat bottle yeah so

257
00:19:59,320 --> 00:20:04,920
there we do have generic sit generic setups you know for various verticals but when it comes

258
00:20:04,920 --> 00:20:10,280
down to a lot of this is this is a very difficult subject right now these days for us because a lot

259
00:20:10,280 --> 00:20:13,480
of our customers really feel very shown that they don't want the data share they don't even want

260
00:20:13,480 --> 00:20:20,840
the models shared you know so it's a new it's it's a it's even for when their chatbot pops up on

261
00:20:20,840 --> 00:20:27,160
their website anything it's a it's a it's a very tricky area that I think that our company I think

262
00:20:27,160 --> 00:20:33,720
a lot of companies today are having to deal with which is like how do you both be a competitive AI

263
00:20:33,720 --> 00:20:38,120
machine learning company while at the same time protecting the data of your customers in a way

264
00:20:38,120 --> 00:20:43,080
that they're comfortable and they can that like dealing with all the kind of compliance issues

265
00:20:43,080 --> 00:20:47,480
too because a lot of our customers are banks so it may even be that legally you can you know unless

266
00:20:47,480 --> 00:20:53,320
there's actually a specific consent for example we deal with a government agency in Australia and

267
00:20:53,320 --> 00:20:57,480
they I was reading one of their one of their privacy policy documents on our day and I was

268
00:20:57,480 --> 00:21:01,720
saying like unless you have explicit consent from a user like a pilot says I consent to use this

269
00:21:01,720 --> 00:21:07,080
or you sign some checkbox or something they can't use that data for anything else tuning a model

270
00:21:07,080 --> 00:21:13,320
even you know so this is really I think we talked about all you know all the exciting stuff in AI

271
00:21:13,320 --> 00:21:17,640
today and all the amazing things that are happening when it comes down to for a lot of businesses

272
00:21:18,200 --> 00:21:24,520
these are the real problems today it's not how do I scale a deep learning model or how do I

273
00:21:24,520 --> 00:21:29,640
productionize this system and get it working on you know going from one cluster to a thousand

274
00:21:29,640 --> 00:21:35,320
computers or whatever it's like the legal problems how do you actually deal with the data in a way

275
00:21:35,320 --> 00:21:40,360
that's safe for the company and for the user you know it's really like a huge somewhere you know

276
00:21:41,240 --> 00:21:48,520
right yeah I was just reading I forget what I think it was I think it was a particle in someone

277
00:21:48,520 --> 00:21:54,360
in his newsletter or something like that that was talking about how there's this huge gray area

278
00:21:54,360 --> 00:22:01,400
around copyright and data sets and you know basically everyone who's using for the most part

279
00:22:01,400 --> 00:22:08,520
these public data sets is kind of flying under the radar but there's this you know potential exposure

280
00:22:08,520 --> 00:22:16,600
where there's no established you know precedent around you know the extent to which copyright on

281
00:22:16,600 --> 00:22:21,960
a data set flows into the model for example and so potentially someone using this copyright

282
00:22:21,960 --> 00:22:28,520
data set to train the model could be creating a model that's you know has potentially owned or

283
00:22:28,520 --> 00:22:34,040
has some copyright liability with someone else so that's an example of this kind of meta concern

284
00:22:34,040 --> 00:22:39,880
that that your customers are thinking about do you have any perspectives on the you know the rise

285
00:22:39,880 --> 00:22:47,080
of the consumer voice interface devices the virtual assistance your Alexa's and your Google

286
00:22:47,080 --> 00:22:52,360
assistance and things like that yeah it's interesting I think a lot of that stuff it has to do with

287
00:22:52,360 --> 00:22:57,240
their APIs you know with those kind of systems we right now we have our our chat box integrates

288
00:22:57,240 --> 00:23:02,520
with like Alexa integrates with Google Home but there's certain things we can't do there's certain

289
00:23:02,520 --> 00:23:06,040
things we can't do so one thing we would really like to do a lot of our customers like a center

290
00:23:06,040 --> 00:23:12,440
banks right and with thanks this voice biometrics has become very popular recently but one thing we

291
00:23:12,440 --> 00:23:18,680
can't do right now is voice biometrics over Google and Alexa because they only send you text

292
00:23:19,240 --> 00:23:23,560
so at this point there they don't actually send you the audio signal they do all the ASR for you

293
00:23:23,560 --> 00:23:29,400
speech recognition and the TTS for you the text to speech and they have no way of sending out

294
00:23:29,400 --> 00:23:35,000
those signals so I think this is something that we've had huge strides in terms of the openness

295
00:23:35,000 --> 00:23:39,960
and the compatibility of these platforms with Alexa and now with Google Home but for years this was

296
00:23:39,960 --> 00:23:44,440
a big problem with Siri right with Apple if they had no ability to do 30 third party integration

297
00:23:44,440 --> 00:23:50,200
you couldn't say to Siri like you know play a song on Spotify for me so this is this is definitely

298
00:23:50,200 --> 00:23:56,520
like a big topic for new ones right now this idea of we call it cognitive arbitration where you have

299
00:23:56,520 --> 00:24:02,680
agents that sit like kind of Uber agents that sit in the middle of all these different IOT systems

300
00:24:02,680 --> 00:24:06,600
and coordinate those for you and bring that data together bring the systems together

301
00:24:06,600 --> 00:24:11,000
and those APIs together to talk to these different systems I know this is also a vision of Amazon's

302
00:24:11,000 --> 00:24:15,480
as well with being able to sit and like have their agent that has goes out and there's always

303
00:24:15,480 --> 00:24:20,200
different skills that they come to so this is kind of this is a newer topic for for new ones

304
00:24:20,200 --> 00:24:25,640
that are working on more recently is how you can use intelligence and reasoning and other kinds

305
00:24:25,640 --> 00:24:31,640
of machine learning to build agents that can sit in between all these different IOT devices and talk

306
00:24:31,640 --> 00:24:39,960
each other and do you see is there a role or any emergence of like standards or standardized

307
00:24:39,960 --> 00:24:45,320
approaches like for example you know there's tons of work that's been done around federated

308
00:24:45,320 --> 00:24:50,840
identity in the web and now this is you're introducing a whole other layer around biometrics

309
00:24:50,840 --> 00:24:57,160
does any of that kind of work transfer here do you think or we just like to or no no I think it will

310
00:24:57,160 --> 00:25:01,800
I think that this is word in very early days here so it's basically like I don't think the very

311
00:25:01,800 --> 00:25:05,640
beginning of the internet when these kind of standards were being built out you know like what's

312
00:25:05,640 --> 00:25:10,520
HTML and how does it work that's where we are today with AI so these issues the thing like you

313
00:25:10,520 --> 00:25:14,520
brought up with the data that those kind of issues haven't been solved yet like how do you there's

314
00:25:14,520 --> 00:25:20,360
no you know a patchy license for data at this point you know whereas that stuff you know to season

315
00:25:20,360 --> 00:25:24,600
software engineers and product managers now it's just kind of like second language they know

316
00:25:24,600 --> 00:25:28,440
with the with the licenses mean they know which what they can reuse which code can be leverage

317
00:25:28,440 --> 00:25:32,200
which can't what you had to declare what you don't etc but that stuff doesn't exist for data

318
00:25:32,200 --> 00:25:35,320
but it's an interesting point you know I hadn't thought about it but yeah I think that that'll

319
00:25:35,320 --> 00:25:40,120
come about and similarly with with these standards around interoperability I think that's

320
00:25:40,120 --> 00:25:44,120
something that we have teams at nuance we're working on and trying to kind of reach out to

321
00:25:44,120 --> 00:25:48,120
different partners because this is not a problem that's going to be solved by any particular

322
00:25:48,120 --> 00:25:52,520
company just in the same way that like you know JSON standards can't be solved by Google

323
00:25:52,520 --> 00:25:56,120
you know they can't just make a really great JSON parse on everybody take it and put it in

324
00:25:56,120 --> 00:26:01,000
their browsers or put in their systems it has to be you know standards based and community based

325
00:26:01,000 --> 00:26:05,720
so I think we are we are thinking about these kind of interoperability standards at this point

326
00:26:05,720 --> 00:26:12,440
very early days though right any other things that you covered in your talk that you want to

327
00:26:12,440 --> 00:26:17,880
share with us yeah I covered most of it yeah there's a couple of things like in the front

328
00:26:17,880 --> 00:26:23,800
matter of the cover of the talk that I was talking about which is that in this world of chatbots

329
00:26:23,800 --> 00:26:30,040
and virtual assistants it's surprising about how much of it isn't AI and isn't machine learning

330
00:26:30,040 --> 00:26:34,600
and we really there's a lot of companies will have like you know a dot AI in their name

331
00:26:34,600 --> 00:26:39,320
but everything is still like based on regular expressions and rules and that sort of stuff

332
00:26:39,320 --> 00:26:44,840
so or people or people yeah or people big time that's that's not always necessarily a bad thing

333
00:26:44,840 --> 00:26:48,920
but it's it's often part of the company's strategy in terms of you know having everything

334
00:26:48,920 --> 00:26:54,200
the beginning be run by humans as a way to gather data and then over time learn from it

335
00:26:54,200 --> 00:27:01,080
but that's something we try to help educate our customers about is how much of this actually

336
00:27:01,080 --> 00:27:07,000
is AI and machine learning and how much of it isn't today most of the AI and machine learning

337
00:27:07,000 --> 00:27:13,080
for us happens on the language understanding side of things so when the input comes in

338
00:27:13,080 --> 00:27:18,760
we can be able to categorize it using statistical models and LP models in order to route

339
00:27:18,760 --> 00:27:23,080
to the right response you know to give you the right response to a question we can also do

340
00:27:23,080 --> 00:27:26,680
things like energy extraction extractor concepts of you're saying something like you know I'd

341
00:27:26,680 --> 00:27:32,040
like to order a pizza or I'd like to order a large pizza a large vegetarian pizza with pepper

342
00:27:33,320 --> 00:27:40,200
peppers and onions almost at pepperoni be able to identify both that the intent was to order a

343
00:27:40,200 --> 00:27:45,320
large pizza that the toppings and the size and that sort of stuff a lot those categories that

344
00:27:45,320 --> 00:27:49,400
kind of technology now some of that stuff is standard but there's still quite a few you know

345
00:27:49,400 --> 00:27:53,000
different platforms out there for doing chatbites that don't offer that kind of you know that

346
00:27:53,000 --> 00:27:59,000
level of a machine learning and LP but beyond that played with that stuff in the past like api.ai

347
00:27:59,000 --> 00:28:05,160
it's a very manual and tedious process to build out those those entity trees exactly yeah and so

348
00:28:05,160 --> 00:28:10,280
you're it sounds like what you're describing is a way to learn some of that from the after data

349
00:28:10,280 --> 00:28:15,800
itself yeah exactly so that when it comes to when it comes to our intent discovery and bootstrapping

350
00:28:15,800 --> 00:28:21,240
process we're learning the intense automatically and building out kind of you could call it an

351
00:28:21,240 --> 00:28:25,640
ontology the the group of the intense than the various concepts that are associated with those

352
00:28:25,640 --> 00:28:30,440
intents but yeah we try to just like encourage people to be discerning and try to figure these things

353
00:28:30,440 --> 00:28:35,080
out when you're looking at a platform today I think the next frontier is going to be

354
00:28:35,080 --> 00:28:40,520
on the other side though there really isn't any system on the market today including ours

355
00:28:40,520 --> 00:28:45,080
that can automatically learn how to answer the questions especially if they're complicated

356
00:28:45,080 --> 00:28:50,760
back and forth dialogues so if it requires like a back and forth conversation those tend to be

357
00:28:50,760 --> 00:28:56,680
you know built out manually either as an enterprise in the enterprise you know by talking to

358
00:28:56,680 --> 00:29:01,240
subject matter experts or people are doing it themselves by figuring it out themselves that way

359
00:29:01,240 --> 00:29:06,760
that I think is different is the next frontier for this technology is learning how to answer questions

360
00:29:06,760 --> 00:29:12,360
and dialogue and a lot of now there are tons of people who say they can do that yeah there are a lot

361
00:29:12,360 --> 00:29:16,360
of there's what they tend to do though is you have to feed the system question answer pairs

362
00:29:17,640 --> 00:29:24,440
then it can learn to map new questions to those answers right this question answering

363
00:29:24,440 --> 00:29:32,040
but it's not dialogue that's if something exists sort of an FAQ can you identify if the question

364
00:29:32,040 --> 00:29:36,120
takes a different format though that it actually mapped to this question that's in the FAQ that's

365
00:29:36,120 --> 00:29:39,560
about a format I mean it could not be an FAQ it might be like a list of a thousand questions and

366
00:29:39,560 --> 00:29:42,920
answer pairs or whatever but I mean cutting edge research today I don't know if you remember

367
00:29:42,920 --> 00:29:48,760
with like the Stanford squad data set that Q&A data set where it's trying to answer questions

368
00:29:48,760 --> 00:29:53,240
off Wikipedia articles this is pretty cutting edge research at this point there's research teams

369
00:29:53,240 --> 00:29:59,400
across the world competing in this kind of thing but even that still is focused on you know the answer

370
00:29:59,400 --> 00:30:04,280
is in the article you know we're talking the kind of stuff nuanced is working on today that is

371
00:30:04,280 --> 00:30:07,960
one thing I forgot to mention we've got a product a project we're working on now called mean

372
00:30:07,960 --> 00:30:13,080
and knowledge where you can basically push a button to ingest a website or a set of documents

373
00:30:13,080 --> 00:30:17,560
then start doing question answering on it yeah and it it does leverage from the technology that's

374
00:30:17,560 --> 00:30:22,600
being used to answer like those to work with that squad data set but it also leverages technology

375
00:30:22,600 --> 00:30:27,800
from information retrieval search so it combines a few different areas machine learning as well

376
00:30:27,800 --> 00:30:33,240
as NLP and question answering so that and I like to think of this as low hanging fruit really

377
00:30:33,240 --> 00:30:38,280
because these kinds of questions that you actually have just a one shot answer to those are the

378
00:30:38,280 --> 00:30:43,000
candidates for automation today the things that we still really are still very early days in the

379
00:30:43,000 --> 00:30:49,640
research in is how do you actually learn a back and forth conversation that requires multiple

380
00:30:49,640 --> 00:30:54,520
questions and feedback going through a conversation with somebody from data I think it's the next

381
00:30:54,520 --> 00:31:02,360
frontier in the case of this of Nina knowledge so what degree is it you're doing like transfer

382
00:31:02,360 --> 00:31:09,720
learning off of a model trained on squad and applying that model to the website that's being

383
00:31:09,720 --> 00:31:16,040
ingested or is this process including like training up a new model on that website yeah the

384
00:31:16,040 --> 00:31:21,000
process is yeah certainly we start from scratch you know on each one each time we haven't we

385
00:31:21,000 --> 00:31:24,920
haven't gotten transferred learning like that into production yet today but those are certainly

386
00:31:24,920 --> 00:31:29,640
areas of research are working on is so one area where I don't know if I don't know if you'd

387
00:31:29,640 --> 00:31:34,120
call it transfer learning or not but you can certainly do things like learn word vectors you know

388
00:31:34,120 --> 00:31:37,880
from one data set and apply to another that's that is certainly like a form of transfer learning

389
00:31:37,880 --> 00:31:41,160
most people think about transfer learning I think today they're thinking okay I built this big

390
00:31:41,160 --> 00:31:46,680
multi-layer neural network and I'm extracting a piece of it and then using it on another data set

391
00:31:46,680 --> 00:31:51,000
I think it's still early days for that sort of stuff but certainly when it comes to word vectors

392
00:31:51,000 --> 00:31:56,280
or other kinds of vectors paragraph vectors document vectors etc that stuff can be transferred

393
00:31:56,280 --> 00:32:02,280
and it can be very helpful in improving the quality of a model pretty quickly where are we in terms

394
00:32:02,280 --> 00:32:07,240
of you know we've talked a lot about identifying the intent of you know an utterance or something

395
00:32:07,240 --> 00:32:14,120
that's typed into a chatbot but where are we in terms of you know more you may be more realistic

396
00:32:14,120 --> 00:32:19,800
kind of dialogues that have multiple intents or hidden intents or you know things like that you know

397
00:32:19,800 --> 00:32:24,440
and this is maybe a slightly different direction for the question but you know for a while we've

398
00:32:24,440 --> 00:32:31,400
talked about the IVR systems being able to identify the emotion and you know change or escalate

399
00:32:31,400 --> 00:32:36,440
the way the call is handled based on the emotion you know when I'm frustrated I try to make sure

400
00:32:36,440 --> 00:32:42,760
the IVR knows I'm frustrated and it never makes a difference I really love this question particularly

401
00:32:42,760 --> 00:32:47,960
the emotion part of it I really love that question because we've been working on it a lot lately

402
00:32:47,960 --> 00:32:52,120
yeah of what do you do with taxid sentiment right so that's basically tends to be in the

403
00:32:52,120 --> 00:32:56,520
seminar although there are some models now that classify things into like the five base emotions

404
00:32:56,520 --> 00:33:01,800
like anger happiness frustration says is like these you know old models of this there are some

405
00:33:01,800 --> 00:33:05,160
models that claim to be able to do that I don't know how accurate they are but sentiment that's

406
00:33:05,160 --> 00:33:08,680
at least one that you were pretty accurate we can get pretty accurate on that for the most part at

407
00:33:08,680 --> 00:33:13,480
the global sentiment of a sentence that doesn't always sufficient because there can often be two

408
00:33:13,480 --> 00:33:18,280
sentiments in a sentence you know I love this but I hate this what I do there so I'm getting off

409
00:33:18,280 --> 00:33:23,080
on a tangent but the reason I think this is really fascinating is because the real question is okay

410
00:33:23,080 --> 00:33:27,720
great so what do you do with what do you do when you know someone's pissed off what do you do when

411
00:33:27,720 --> 00:33:33,160
you know someone's frustrated and that's a really hard question because it tends to be what a

412
00:33:33,160 --> 00:33:38,840
company what a customer wants to do is figure out a way it's about containment right so how do we

413
00:33:38,840 --> 00:33:43,560
handle this without escalating to a person because that's going to a person's expensive but

414
00:33:43,560 --> 00:33:46,440
when you have a frustrated person the only thing we know how to do to know with the only thing

415
00:33:46,440 --> 00:33:52,680
we tend to do today is escalate to a person so I think what it's going to come down to is understanding

416
00:33:52,680 --> 00:33:56,840
that they're these aren't black and white things that there's just like we have no confidence

417
00:33:56,840 --> 00:34:03,400
scores and probabilistic models that give you a gradient of how sort of of confidence and say you

418
00:34:03,400 --> 00:34:09,800
know a right answer there's gonna be a gradient in terms of like sentiment so if a person is saying

419
00:34:09,800 --> 00:34:13,800
something like you know I'm having trouble with this then you might be able to say oh okay I'm

420
00:34:13,800 --> 00:34:17,320
sorry you're having trouble with this I really you know wish you were doing a better job there but

421
00:34:17,320 --> 00:34:22,200
you know can I offer you this you know tool this troubleshooting step you know this troubleshooting

422
00:34:22,200 --> 00:34:27,080
dialogue where as a person is really upset then yeah you probably just want to say maybe you want

423
00:34:27,080 --> 00:34:31,240
to offer them at least to say would you like me to have a technical support person contact you

424
00:34:31,240 --> 00:34:36,120
directly you can just like hold on and we'll call you or do you want to proceed with our you know

425
00:34:36,120 --> 00:34:43,320
troubleshooting online yeah so I think although we still aren't there 100% with recognizing these

426
00:34:43,320 --> 00:34:48,120
things the question like what do you do with it once you have recognized it might be even a

427
00:34:48,120 --> 00:34:53,160
harder problem to deal with you know because great we can get like we end up with 100% 99%

428
00:34:53,160 --> 00:34:57,560
accuracy of knowing when some how angry someone is but how do you what how does that help you what

429
00:34:57,560 --> 00:35:02,360
your customer does not want to escalate all of those two you know they're most senior rap or

430
00:35:02,360 --> 00:35:06,760
or exactly right so how do you handle it what do you do with it for an enterprise like how do you

431
00:35:06,760 --> 00:35:10,520
actually use that data in a way that's interesting and again this doesn't actually come down to

432
00:35:10,520 --> 00:35:15,480
an AI problem it comes down to like a user experience problem or design problem yeah I wonder if

433
00:35:15,480 --> 00:35:20,840
there's like you know companies all over of Glondon to net promoter scores a way to measure

434
00:35:20,840 --> 00:35:29,000
customer satisfaction but I wonder if there's like a net IVR anger scores yeah you you guys should

435
00:35:29,000 --> 00:35:36,200
do that yeah yeah this our customers ask about this stuff a lot so it's really it's on the

436
00:35:36,200 --> 00:35:40,200
the front of people's minds but you do to the when you go down that dialogue when you go down

437
00:35:40,200 --> 00:35:47,880
that path it's you know okay so then what yeah awesome football thank you so much for taking the

438
00:35:47,880 --> 00:35:54,920
time to sit down with me I'm looking forward to catching pieces of your talk and how you know

439
00:35:54,920 --> 00:35:59,480
their ways that folks can kind of find out about your research or connect you on Twitter or

440
00:35:59,480 --> 00:36:06,120
anything like that yeah my Twitter handle is my name with the first initials switch so okay

441
00:36:06,120 --> 00:36:11,480
it's all pepper to you well pepper on Twitter that's probably the best way to get at me these days

442
00:36:11,480 --> 00:36:15,640
okay nice nice well good luck with your talk tomorrow thank you thanks

443
00:36:20,280 --> 00:36:26,520
all right everyone that's our show for today thanks so much for listening and of course

444
00:36:26,520 --> 00:36:32,440
for your ongoing feedback and support for more information on Paul and any of the other topics

445
00:36:32,440 --> 00:36:40,760
covered in this episode head on over to twomlai.com slash talk slash 52 for the rest of the series

446
00:36:40,760 --> 00:36:49,400
head over to twomlai.com slash a i s f 2017 and please please please send us any questions or

447
00:36:49,400 --> 00:36:57,480
comments that you may have for us or our guests via Twitter at twomlai or at sam charrington or leave

448
00:36:57,480 --> 00:37:02,840
a comment on the show notes page there are a ton of great conferences coming up through the end

449
00:37:02,840 --> 00:37:08,920
of the year to stay up to date on which events will be attending and hopefully to meet us there

450
00:37:08,920 --> 00:37:19,720
check out our new events page at twomlai.com slash events twimlai.com slash events thanks again for

451
00:37:19,720 --> 00:37:29,720
listening and catch you next time

