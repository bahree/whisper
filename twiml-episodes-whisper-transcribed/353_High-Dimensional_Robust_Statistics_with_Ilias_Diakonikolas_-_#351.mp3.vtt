WEBVTT

00:00.000 --> 00:15.280
Welcome to the Tumel AI Podcast. I'm your host, Sam Charrington.

00:21.440 --> 00:27.760
All right, everyone. I am on the line with Elias Diaco Nicolos. Elias is on the faculty

00:27.760 --> 00:33.680
at the University of Wisconsin-Madison. Elias, welcome to the Tumel AI Podcast.

00:33.680 --> 00:39.680
Great to be here, Sam. I'm really looking forward to diving into our discussion. Before we do,

00:40.400 --> 00:46.320
I'd love to hear a little bit about your background. Your primary research interests are

00:46.320 --> 00:54.160
in algorithms and machine learning. And if the paper that we're going to discuss this time around,

00:54.160 --> 01:00.000
distribution independent pack learning of half spaces with Moss Art Noise, which one

01:00.000 --> 01:05.600
the Outstanding Paper Award at NURBS. If it's any indication, your work is quite theoretical

01:05.600 --> 01:11.440
in nature. Tell us a little about your background and how you came to working on this type of work.

01:11.440 --> 01:18.160
All right, so I grew up in Greece, and this is what I did in my undergrad. I moved to Columbia

01:18.160 --> 01:24.800
University for grad school. My grad school was in a topic called the theoretical computer science,

01:24.800 --> 01:30.400
so I'm an algorithms person. And somehow in the process, I realized that the best way to have

01:30.400 --> 01:37.120
an impact in the world if you're doing theoretical algorithmic research is to actually work on algorithm

01:37.120 --> 01:42.960
questions that come from machine learning and statistics. Why is that? Why is that the best place?

01:43.520 --> 01:46.960
I mean, maybe, yeah, maybe the phrasing is not accurate. I think it's really a good place because

01:46.960 --> 01:52.880
this is a setting where I think our listeners would all agree, but I'm curious your thought.

01:52.880 --> 02:00.000
So I actually started doing this before it was popular, because I could really see that maybe not

02:00.000 --> 02:05.520
all of the theoretical algorithm that one develops, but maybe some of them could be used in practice

02:05.520 --> 02:14.480
and you could see the practical improvements in data analysis tasks. So in particular, I used to

02:14.480 --> 02:20.960
like doing theoretical algorithmic research just for the sake of doing it, but sort of later,

02:20.960 --> 02:27.120
like after my finish at my PhD, I started gravitating towards theoretical questions that if solved,

02:27.120 --> 02:34.880
would actually have a practical impact. Describe for us broadly your research interests and focus,

02:34.880 --> 02:38.960
so that we have a little bit of the context out of which this paper comes.

02:38.960 --> 02:43.840
So I mean, I have broad interests within algorithms and machine learning. So this particular

02:43.840 --> 02:50.720
narrative paper belongs at the high level in an area which is called the high-dimensional robust

02:50.720 --> 02:59.360
learning. The idea here is that historically, every machine learning algorithm needs to make

02:59.360 --> 03:05.360
some assumptions. Assumptions about the model where the data comes from. So in some sense,

03:05.360 --> 03:13.600
very roughly speaking, every algorithm could be viewed as a data fitting method. You're trying

03:13.600 --> 03:20.560
to fit the data to a model. Now, the issue is that this assumption about the data coming from

03:20.560 --> 03:26.960
a model of a given type is very crucial. So and typically, you do not want your algorithm

03:26.960 --> 03:32.320
to overfeed to this assumption. In the sense that if this assumption is not exactly true,

03:32.320 --> 03:37.680
but if it's approximately true, you want your algorithm to still work. And unfortunately,

03:37.680 --> 03:43.280
in high-dimensional settings, we realized about five years ago that this is actually not the case.

03:43.920 --> 03:50.720
Even a very tiny deviation from the assume model could make the machine learning algorithm

03:50.720 --> 03:55.920
very, very fragile. So we started and decided that, okay, we need to rectify this and develop

03:55.920 --> 04:01.120
methodology to have robust learning algorithms for high-dimensional problems. And so when you talk

04:01.120 --> 04:10.640
about high-dimensional problems and perturbations, are you thinking about things like the adversarial

04:10.640 --> 04:15.840
examples, types of problems that we are familiar with, where you've got an image,

04:15.840 --> 04:23.600
high-dimensional, and you apply some noise to it? So that's a great question. I was expecting

04:23.600 --> 04:29.120
this question exactly to draw a difference. So these types of adversarial examples,

04:29.120 --> 04:34.000
they're also some type of robustness, they're quite some type of robustness, but it's somewhat

04:34.000 --> 04:39.680
different than the one I'd like to discuss. In particular, in the sort of adversarial robust

04:39.680 --> 04:44.000
setting, what you have is that you train a bunch, so you train your neural network on some images.

04:45.440 --> 04:50.960
And then you perturb those images in a way that's imperceptible to humans and see how the

04:51.680 --> 04:56.000
how the model you learned performs. We have learned that it's actually non-robust and we need to do

04:56.000 --> 05:02.480
something to make it robust. So the perturbations in the adversarial robust setting take place

05:02.480 --> 05:08.080
at test time. So you train with a bunch of clean data and then you want to test on a set of

05:08.080 --> 05:14.640
corrupted data. So the setting of robustness that I care about, at least with respect to this line

05:14.640 --> 05:20.400
of work, is something that's called test time attacks, where you actually train on corrupted data.

05:20.400 --> 05:27.920
So these two are related, so these two notions of robustness are related, but they're also quite

05:27.920 --> 05:34.400
a bit different. And you said they're called test time attacks, but the data is perturbed in

05:34.400 --> 05:41.920
training. So the side examples are called test time attacks. What I'm going to talk about is

05:41.920 --> 05:48.320
called training time attacks. Got it. Okay. So let me give you an example. Like the most basic

05:48.320 --> 05:53.920
example that I expect anyone could could understand with just a little bit of background. So if I give

05:53.920 --> 06:02.080
you samples like IID samples from a probability distribution, like a Gaussian, and I ask you to find

06:02.080 --> 06:09.760
the expectation, the mean value of the distribution where the samples come from. Let's say in one

06:09.760 --> 06:17.360
dimension, then what would you do? To find the mean value. Yeah. You'd sum them and divide by the

06:17.360 --> 06:23.440
number of samples you have. Yeah, that's fantastic. That's called sort of empirical mean. And we know

06:23.440 --> 06:29.360
that it works, right? Unfortunately, though, if one of the samples that I give you is not drawn

06:29.360 --> 06:34.960
from the distribution that you assumed it was, it's an outlier, then the average doesn't work anymore.

06:35.920 --> 06:39.760
Because the average could be arbitrarily far from the true mean. It's not going to convert

06:39.760 --> 06:44.880
to the true mean. If anything, you take infinitely many samples. So what do we do in this case?

06:44.880 --> 06:49.600
So for the one-dimensional setting, the solution is known for like, I don't know, a centurion

06:49.600 --> 06:54.000
statistics. So instead of taking the average, you're taking something which is called the median.

06:55.200 --> 07:01.040
Okay, so we know that the median is robust to outliers, and it's optimally robust for one-dimensional

07:01.040 --> 07:07.440
problems, right? Now imagine a generalization of this problem to hide dimensions. So now instead of

07:07.440 --> 07:13.680
observing one-dimensional points, you're observing high-dimensional points. Every observation that you

07:13.680 --> 07:18.080
have is a high-dimensional vector, let's say in a million dimensions. And you want to do the same

07:18.080 --> 07:23.280
thing. You want to actually compute the expected value of the corresponding distribution.

07:24.000 --> 07:29.760
Now in the case of clean data, you would do exactly the same thing that you did in the one-dimensional

07:29.760 --> 07:34.960
case. You would sum all the samples and divide by the number of the samples. So this is the empirical

07:34.960 --> 07:40.960
meaning high dimensions. And in the case of clean data, it works. Now the difficulty is actually

07:40.960 --> 07:48.240
generalizing this high-dimensional empirical mean when you actually have, let's say, 10% of your

07:48.240 --> 07:53.280
of your samples being arbitrary outliers. In this case, unfortunately, there's not such an easy

07:53.280 --> 08:00.480
solution as taking the median. Meaning because the median and a high-dimensional scenario isn't well

08:00.480 --> 08:07.040
defined or because of the number of outliers you have. That's, these are great questions. So

08:07.040 --> 08:13.760
there are many ways to define a notion of a median and high dimensions. For example, one thing that

08:13.760 --> 08:20.000
you could do is look at every coordinate individually and calculating the median of every coordinate and

08:20.000 --> 08:25.440
giving that answer. Unfortunately, this is not going to work. The reason is they're going to work

08:25.440 --> 08:30.480
is because you have many dimensions and in some sense the noise can accumulate across the

08:30.480 --> 08:36.240
dimensions. So if you have, let's say, even a 1% of outliers, then the error you're going to get

08:36.240 --> 08:42.240
at the end is going to be very large in the worst case. It would actually depend on, it would actually

08:42.240 --> 08:48.160
scale with the number of dimensions. And this is something that you can avoid. We know that you can

08:48.160 --> 08:53.760
avoid that if you look at like information theoretic bounds, but we didn't know how to avoid it with

08:53.760 --> 08:59.360
a computationally efficient algorithm with a method that you can actually run. So what we did

08:59.360 --> 09:05.200
four years ago with a number of great authors is we developed the first methods that is actually

09:05.200 --> 09:11.200
robust for estimating the mean of a high dimension distribution to a constant number of outliers.

09:11.200 --> 09:16.880
So even if you have, let's say, 20% of outliers and no matter how high the dimension is,

09:16.880 --> 09:22.160
the algorithm runs efficiently and gives you an accurate approximation of the mean.

09:22.720 --> 09:27.920
What's the general flavor or shape of this algorithm? I see. So there are many versions.

09:27.920 --> 09:38.000
Maybe the easiest one is about detecting and removing the consequential outliers.

09:38.880 --> 09:44.720
So we are in a high dimensional setting. So the most sort of naive thing to try to do is detect

09:44.720 --> 09:53.440
the outliers and remove them. And after you do that, then you just output the mean of the rest.

09:53.440 --> 09:58.880
It will be the ideal methodology to solve the problem. The issue is that this is impossible.

09:59.440 --> 10:04.880
We can prove that it is impossible to actually detect the outliers in high dimension setting.

10:05.440 --> 10:11.600
So what do we do? So the next thing to try to is, okay, maybe I cannot detect and remove all the

10:11.600 --> 10:18.640
outliers. Maybe I can detect and remove the ones that if I kept in the data sets, then they

10:18.640 --> 10:23.760
would actually skew the appear can mean by a lot. And it turns out that this is something that you

10:23.760 --> 10:29.200
can do by using spectral memory. So I guess I do not have like a picture to show you, but the idea

10:29.200 --> 10:35.200
is this that let's say you have your data set is some kind of clouds in high dimension. You might

10:35.200 --> 10:40.640
get like a sphere, right? Even outliers very far from that sphere, then you can eyeball it.

10:41.200 --> 10:46.800
You can eyeball it and you can remove it. These are outliers that are very easy to remove.

10:46.800 --> 10:52.720
Unfortunately, in high dimensional settings, these are not the outliers that can kill you.

10:52.720 --> 10:57.280
These are not the only outliers that can kill you. They can be outliers that are within

10:57.280 --> 11:02.480
the initial cloud of points. Each one of them individually looks like a fine point.

11:02.480 --> 11:09.200
You cannot say that this on its own is an outlier, but somehow the outliers have the ability

11:09.200 --> 11:16.320
to collude with each other to skew your estimates. So what you need to do is somehow

11:16.320 --> 11:23.600
detect outliers in a high dimensional setting in a more global scale. So it's like a local versus

11:23.600 --> 11:27.120
global type of phenomenon that appears here. And this is because of the high dimensional setting.

11:28.080 --> 11:35.840
Now does your problem presume single prior distribution? I'm thinking about the one-dimensional

11:35.840 --> 11:44.960
example where as opposed to trying to identify and discard outliers, you might have multiple prior

11:44.960 --> 11:51.760
distributions and you're trying to determine which of your samples belongs to which distribution

11:51.760 --> 11:56.240
as a way to formulate the problem. Right, right. So the formulation that we're using this

11:56.240 --> 12:01.280
setting is a frequentist formulation. It is not the Bayesian formulation. So there is not

12:01.280 --> 12:06.320
something as a prior. So what we really assume is that we have a family of distributions,

12:06.320 --> 12:11.840
let's say a family of models, where we assume the clean data comes from. Let's say for example,

12:11.840 --> 12:17.200
the clean data could come from a mixture of high dimensional gougins. So that's an assumption.

12:18.000 --> 12:22.640
Okay, so you do assume a mixture of gougins as opposed to a single gougin.

12:22.640 --> 12:28.240
Yeah, we can do that. And in fact, there are many different assumptions that we can handle algorithmically.

12:28.240 --> 12:34.560
These are related, I mean, this is a technical problem. So these are related to the rate of increase

12:34.560 --> 12:39.600
of the moments of the distribution of the good error. So if the moments of the good distribution

12:39.600 --> 12:44.960
behave well in the technical, in the technical sense, we can actually solve the problem.

12:45.760 --> 12:50.560
But what I want to emphasize is that some types of assumptions of this form are actually necessary.

12:51.360 --> 12:56.640
In the sense that if you make no assumptions about your good data in this unsupervised learning,

12:56.640 --> 13:01.440
where you have unlabeled data, the problem is not solvable even information theoretically,

13:01.440 --> 13:07.040
even like with infinitely many samples. And the reason is that the outliers, they have the ability

13:07.040 --> 13:11.520
to actually completely mask the information that's contained in the good data.

13:12.320 --> 13:17.200
So some type of assumption like the one that you are literally doing is actually

13:17.200 --> 13:20.320
information theoretically necessary. Got it.

13:20.320 --> 13:24.800
Right, so this is so basically where sort of thing started and this is an unsupervised

13:24.800 --> 13:29.840
setting. Unsupervised machine learning means that the data set that you observe is an unlabeled

13:29.840 --> 13:33.200
data set. You have a bunch of points in high dimension without labels.

13:33.200 --> 13:37.520
So maybe it's time for me to move to the Norrips paper.

13:37.520 --> 13:40.960
Yeah, yes. How does that paper come in?

13:40.960 --> 13:46.560
Right. So this is a supervised learning setting. This is a setting where you observe labeled data.

13:46.560 --> 13:52.080
And what you're trying to do is you're trying to fit a linear model. This is like the most basic

13:52.080 --> 13:59.680
family of concepts that you could try to fit to the data. Like literally a linear separator.

13:59.680 --> 14:06.640
You're trying to find a linear separator that separates the point into two classes,

14:06.640 --> 14:12.800
the positive points and the negative points. This seems like almost like a too simplistic problem.

14:12.800 --> 14:18.880
And indeed, in the case of of clean data, it is. Now the question is what happens

14:19.520 --> 14:24.960
when the labels that you observe are actually not clean. They have, let's say, some kind of random

14:24.960 --> 14:31.040
noise attached to them. Can you still recover the true linear model efficiently in the presence

14:31.040 --> 14:36.240
of these types of corruptions? And what we show in this paper is that, in fact, in a very

14:36.240 --> 14:41.920
reasonable model over random label perturbations, this is something that can be done. It can be done

14:41.920 --> 14:48.080
with a computational efficient algorithm. If I understand what you're saying, it's that the linear

14:48.080 --> 14:57.440
model is insufficient in the case of clean data. But when noise is added, that a linear model,

14:57.440 --> 15:05.760
a simple model becomes sufficient. Let me rephrase. So the reason that we consider

15:05.760 --> 15:11.680
settings where the labels are noisy is because these settings are more realistic in practice.

15:11.680 --> 15:16.480
We cannot really assume that we observe label data and our labels are perfectly clean.

15:16.480 --> 15:23.040
So what I was trying to say is that if you make the unrealistic assumption that the data

15:23.040 --> 15:30.480
is clean, then we knew how to fit linear models since the 60s. What we did is we gave an algorithm

15:31.040 --> 15:36.640
to fit linear models under the more realistic assumption that the labels are actually randomly

15:36.640 --> 15:42.080
perturbed. So this is the contribution of this work compared to prior works. We can actually

15:42.080 --> 15:49.840
learn linear separators efficiently in the presence of noise. And so the paper is called

15:49.840 --> 15:55.040
distribution independent pack learning of half spaces with mass art noise. There's a bunch of

15:55.040 --> 16:01.040
terminology in there. Walk us through that terminology pack learning half spaces mass art noise.

16:01.040 --> 16:05.680
Where do they come into play? Okay, that's great. So pack learning. So pack is an acronym. It means

16:05.680 --> 16:13.520
probably approximately correct is a standard model of binary classification introduced by

16:13.520 --> 16:18.320
Leslie Valiant in the 80s and even before that similar models existed by WAPNIC.

16:19.680 --> 16:26.400
So basically the model is essentially for someone who has seen statistics and machine learning.

16:26.400 --> 16:33.680
The most natural thing you could imagine that you observe a bunch of IID labeled examples

16:33.680 --> 16:39.520
that come from a distribution on points with corresponding labels and then you're trying to find

16:39.520 --> 16:47.120
a classifier that generalizes over unseen data. So that's the definition of the pack model.

16:47.120 --> 16:54.640
Now the term distribution independent which in fact maybe is in some sense unnecessary because

16:54.640 --> 17:00.080
the original definition of the pack model was distribution independent is that I'm going to observe

17:00.080 --> 17:05.760
a bunch of labeled examples x and y. Okay, x is going to be my point in high dimensions and y is

17:05.760 --> 17:12.400
going to be a binary label 0 or 1. So what I do not want to do is I do not want to make any

17:12.400 --> 17:18.640
assumptions about the distribution of the x's. Right? I do not want to assume that the x's are

17:18.640 --> 17:23.200
drawn let's say from a Gaussian distribution. So the only thing I'm going to assume is that the

17:23.200 --> 17:29.120
x's are IID samples from some distribution which is fixed but it's unknown to me and it can be

17:29.120 --> 17:36.240
arbitrary and the motivation for all that is on the real data of this type there are settings

17:36.240 --> 17:42.560
where we don't know anything about the distribution of the data and ideally we would like to be

17:42.560 --> 17:48.160
able to handle noise even in those settings. So this is what distribution independent means.

17:48.800 --> 17:54.720
Now the third and last term of the title is massar noise. So let me explain what this means.

17:54.720 --> 18:02.080
So you observe your labeled examples x, y. If y was sort of in the case of clean data why would

18:02.080 --> 18:08.960
actually be the correct label of x. Right? So now what would be a reasonable model of noise?

18:08.960 --> 18:14.880
A reasonable model of noise would be that's okay. I take every y independently and I perturb it.

18:14.880 --> 18:20.560
I flip it. I make it 0 from 0 to 1 not from 1 to 0 with some small probability. Let's say

18:20.560 --> 18:26.560
1 tenth. So this is what massar noise is but it's a little bit more subtle. What it tells you is

18:26.560 --> 18:33.840
that I take every label and with probability at most 1 tenth I perturb it. But you don't know what

18:33.840 --> 18:38.480
is the probability that I use to perturb it. It's a number that's less than 1 tenth but it could

18:38.480 --> 18:44.000
be anything between 0 and 10. Okay. That's the definition of the massar noise model. It means

18:44.000 --> 18:48.960
that under perturbation and the probability of perturbing every label is going to be bounded

18:48.960 --> 18:53.680
from above by some constant. Certainly the constant should be less than half otherwise I lose

18:53.680 --> 19:00.880
all information. And the feature of the model is that you don't know what the flipping probability is.

19:00.880 --> 19:06.800
It can be different across the examples you observe. Got it. And does that massar noise

19:07.520 --> 19:15.440
particularly model well some natural phenomena that we see? Right. So it's reasonable to assume

19:15.440 --> 19:22.640
that the noise added to the examples is independent or almost independence. But in general we don't

19:22.640 --> 19:28.080
know and certainly we should be assuming some boundedness. Otherwise we get no information.

19:28.080 --> 19:33.040
But what we really don't know is we don't know if the same noise is going to be added to different

19:33.040 --> 19:38.880
examples. So in terms of practical applications there are many the people who define this model

19:38.880 --> 19:44.480
like in the 80s and 90s have set out many settings where this is actually reasonable.

19:44.480 --> 19:49.680
So as a theorist I just took the model and tried to analyze it. Got it. Got it.

19:50.560 --> 19:55.600
So let me tell you one thing that I think is surprising especially if you haven't thought about

19:55.600 --> 20:03.920
this problem. Let's consider the case where you know a priori that every label is going to be

20:03.920 --> 20:10.560
perturbed probability exactly one time. So is this model easier or harder than the one I mentioned

20:10.560 --> 20:15.840
already. So what would you think? I would think easier. I think you would say harder.

20:17.120 --> 20:23.600
Actually it's the opposite. So I would think that you would say that it's harder but in fact it's

20:23.600 --> 20:32.400
easier. Oh I was speaking it's easier from I guess an information theoretic perspective we have

20:32.400 --> 20:36.560
more information about the problem. From an information theoretical perspective when you have more

20:36.560 --> 20:43.520
noise you can predict less accurately. But you are right in the sense that algorithmically

20:43.520 --> 20:51.680
it was known how to solve. Just to see that. So basically when you know exactly what is the

20:51.680 --> 20:56.240
amount of noise you're going to add to every example then in some sense you have the ability to

20:56.240 --> 21:04.640
invert the noise. So in fact go from let's say the any statistic that is defined on the

21:04.640 --> 21:10.480
noisy data there is a mathematical way to transform it efficiently to the same statistic on the

21:10.480 --> 21:16.720
clean data. So this has been studied a lot since the 90s it has a name it's called statistical

21:16.720 --> 21:22.000
query model. There are some genetic transformations that tell you that any algorithm that works in

21:22.000 --> 21:28.000
this statistical query model is actually tolerant to this type of noise. The type of noise where

21:28.000 --> 21:33.680
everything is going to be perturbed with the same probability. But the massar noise model

21:33.680 --> 21:37.920
where you know that the probability of flipping is going to be bounded from above on every example

21:37.920 --> 21:42.960
at most one tenth. But you don't know what it is even though the accuracy you can get is higher

21:42.960 --> 21:48.800
information theoretically the problem is easier algorithmically is much more challenging because now

21:48.800 --> 21:56.640
if you see a given example with its label you have no way of knowing if this label is 100% correct

21:56.640 --> 22:06.080
or 90% correct or anything between 90% and 100%. This makes it really hard to actually to actually

22:06.080 --> 22:12.880
invert. In particular this genetic transformation I mentioned that relates this statistical query

22:12.880 --> 22:19.440
model with tolerance to noise fails to hold in the massar noise model. So we need to do we need

22:19.440 --> 22:25.360
to do something new. One more terminology or one more bit of terminology from the titles half

22:25.360 --> 22:31.520
spaces. Right. Half space is just a linear separator. Oh got it. Just a linear model. You have

22:31.520 --> 22:37.440
a bunch of points. You draw a hyperplane in Euclidean space. What's above the hyperplane is

22:37.440 --> 22:43.840
positive? What's below is negative. All right. So in order to analyze this what kind of

22:43.840 --> 22:51.760
machinery did you call in the play? Right. So what we wanted to do is use SGD. Okay. It makes

22:51.760 --> 22:58.240
sense. SGD is the most natural algorithm to use to solve an ML problem. So you need to formulate

22:58.240 --> 23:04.640
the problem in a mathematical way as an optimization problem and hopefully SGD is going to solve

23:04.640 --> 23:09.600
this optimization problem. What we ended up showing as a first step is that this is impossible.

23:10.400 --> 23:17.040
Okay. Fundamentally SGD can't be applied here in other words. Yes. So this is like 50% of the

23:17.040 --> 23:22.400
truth. So if you try to write some kind of complex relaxation of the problem,

23:22.400 --> 23:27.760
try to solve it by SGD. This is going to be this going to fail completely. We can prove that.

23:27.760 --> 23:33.120
And the proof is not particularly difficult. Right. But during sort of the process of developing

23:33.120 --> 23:38.880
this proof, we actually realized that even though SGD does not suffice to solve the problem of

23:38.880 --> 23:44.000
the entire space, it actually suffices to solve the problem on a non-trivial fraction of the space.

23:44.000 --> 23:50.720
Okay. Okay. So basically, I mean, this is of course, it's a technical thing. But we showed that

23:51.200 --> 23:58.640
there exists a non-trivial fraction of a domain where SGD works. So what we, this is an unknown

23:58.640 --> 24:04.000
subset that there is an efficient algorithm to actually detect. So we can find the subset of the

24:04.000 --> 24:09.280
domain where SGD works. We can solve the problem on that fraction of the domain and then iterate on

24:09.280 --> 24:16.960
the rest. Basically, the algorithm turns out to be an application of many codes to an SGD routine.

24:16.960 --> 24:24.080
Are you able to either determine the importance of the subset of the space that you are able to

24:24.800 --> 24:31.280
apply SGD or are you able to kind of keep track of how much of the space you've covered by iteratively

24:31.280 --> 24:36.240
searching with SGD? Right. So to show that this algorithm is actually efficient,

24:36.240 --> 24:41.680
this process that I describe this iterative process needs to happen a small number of times.

24:41.680 --> 24:46.320
Right. If it happens a exponential number of times, you haven't solved the problem efficiently.

24:46.320 --> 24:51.200
And this is part of the structural understanding that we obtained by solving the problem. But in

24:51.200 --> 24:57.760
every iteration, we actually cover a non-trivial and inverse polynomial fraction of the space.

24:57.760 --> 25:02.400
After at most the polynomial number of iterations, we have covered the entire space.

25:02.400 --> 25:08.240
Right. Okay. Let's say in every iteration, we solve one percent of the problem. So we need

25:08.240 --> 25:16.080
the hundred iterations solve the problem. Maybe this is a sidebar, but are there specific details

25:16.080 --> 25:25.680
of the implementation or the proofs that you or what you covered in a paper that are accessible

25:25.680 --> 25:31.920
without going into, without getting too pulled into the theory? I think the answer to that is

25:31.920 --> 25:40.560
probably no, but I'll be honest here. So it's not a terribly complicated paper. I think it's

25:40.560 --> 25:46.480
actually quite simple from a theory perspective. It has something original that people didn't come

25:46.480 --> 25:54.640
up with before. So what I maybe should say that this, even though it answers an open problem

25:54.640 --> 26:00.160
from a long time ago. So this was posed in the 80s in learning theory. It's not over here.

26:00.160 --> 26:05.520
So this is in some sense the first paper in this sort of line of work of doing distribution

26:05.520 --> 26:10.400
independent learning with noise. And I believe it's going to lead to many developments.

26:11.040 --> 26:18.960
In particular, like something that we have been able to answer very recently with one of the

26:18.960 --> 26:23.920
authors of the same paper, my colleague, Christos Zamos, and two of our PhD students here at

26:23.920 --> 26:31.760
Madison is that in fact, if we make some very weak, but still reasonable assumptions about

26:31.760 --> 26:36.960
the distribution. So if we look at the distribution specific sharing, but still reasonable,

26:36.960 --> 26:42.480
we have a way of showing that SGD actually works as is. So we relax the problem a little bit,

26:43.120 --> 26:47.920
but still in a way that it remains reasonable and we can now solve it by SGD.

26:47.920 --> 26:53.920
And you're a bit cagey about the assumptions that you're making. Are they,

26:54.800 --> 27:01.600
are you fixing to a limited subset of known distributions or is there some other

27:02.960 --> 27:06.800
distributions that's important? Right, right. So the paper is going to be online in a week,

27:06.800 --> 27:14.720
so I'm happy to share this. So I mean, the terms are going to be sort of a little

27:14.720 --> 27:19.840
potentially, potentially a little bit technical, but really what we need is that the distribution

27:19.840 --> 27:26.320
of the inputs is reasonable in the sense that it's not too concentrated or too sort of like,

27:26.320 --> 27:32.800
let's say, not too dense or not too empty and where. Okay. And so there are these technical terms

27:32.800 --> 27:38.080
that are called concentration, anti-cursentration. So as long as we have weak properties of that

27:38.080 --> 27:44.720
for, this probably suffice to solve the problem. Okay. Interesting. Interesting. And so what is it

27:44.720 --> 27:54.400
about this paper that you think kind of caught the interest of the NIPs reviewers and landed it

27:54.400 --> 28:00.080
the outstanding paper award? Right. That's difficult for me to answer. I mean, this is,

28:00.080 --> 28:06.320
I'm not happy that the paper got recognition and I really believed in it before we submitted it.

28:06.320 --> 28:11.440
So I believe it was a significant advance. I think the reason is because it solves,

28:11.440 --> 28:16.240
like, that's my guess, that it solves an old open problem and recognized open problem

28:17.280 --> 28:24.000
in machine learning theory. And really, essentially, no progress had been made on distribution

28:24.000 --> 28:28.560
independent learning in the presence of noise for a long time. And also at the same time,

28:28.560 --> 28:33.520
the solution turns out to be quite clear, at least compared to other theory papers.

28:33.520 --> 28:40.800
And were you surprised by how clean it ended up being? Yes, I was very surprised. In fact,

28:41.840 --> 28:47.440
we solved this problem in a month and then we spent like 10 months to improve it,

28:47.440 --> 28:55.040
and we couldn't. So it somehow gives me the belief that this turns out to be, this is

28:55.040 --> 29:00.320
probably the best possible solution to the problem. But yet, you remain convinced that

29:00.320 --> 29:06.000
there's more to come and you'll be able to build on it or improve on it. Yes, I mean,

29:06.000 --> 29:12.000
there are some other things that we have recently done and I am indeed cage about them because

29:12.000 --> 29:17.360
they're not sort of written yet. But yeah, I believe that this line of work is going to lead to

29:17.360 --> 29:23.040
a lot of progress in the next couple of years. And so for folks that are interested in digging in

29:23.040 --> 29:26.640
a little bit deeper, there's obviously this paper, but you've also recently

29:26.640 --> 29:35.520
co-authored a survey on this broader space. Can you talk a little bit about that in the focus there?

29:35.520 --> 29:41.200
Right, right. So since this initial 2016 paper on robustly learning high-dimensional

29:41.200 --> 29:45.520
distributions, so we're back in the unsupervised setting. So once we wrote this paper,

29:45.520 --> 29:50.800
a number of people found this interesting. And at this point, there is a long literature

29:50.800 --> 29:55.680
on algorithmic high-dimensional robust statistics. So what I did with my long-time

29:55.680 --> 30:00.720
collaborator, Daniel King, we decided, okay, there's so much work in the past four years and it's

30:00.720 --> 30:06.800
unclear if people understand other people's work. So let's try the survey, giving an overview of

30:06.800 --> 30:12.480
all the techniques that people have developed in this space. What are the problems that have been

30:12.480 --> 30:18.880
solved? What are the problems that are open? Somehow giving some kind of, you know, pose, like I

30:18.880 --> 30:24.960
point where, you know, the community needs to say, okay, this is what it has achieved so far.

30:24.960 --> 30:31.200
What are the next directions to look at? So this is available on the archive and it's also going to be

30:31.200 --> 30:36.720
sort of at least a short version of it's going to be part of a book chapter on the young worst

30:36.720 --> 30:41.920
case analysis that's going to be published by Cambridge University Press soon. Okay, and this is

30:41.920 --> 30:47.920
the recent advances in algorithmic high-dimensional robust statistics that was published on archive

30:47.920 --> 30:53.120
back in November of last year. That's right. That's right. And how many papers does it cover?

30:53.120 --> 31:00.400
I mean, in true detail, probably around 15, but we give an overview of about a hundred.

31:00.400 --> 31:06.160
Oh, wow. Wow. There has been a lot of work in this space in the past few years and really

31:06.160 --> 31:15.360
the reason for that are these theoretical questions have the potential of practical impact and

31:16.320 --> 31:20.640
already we have seen some steps in that direction. For example,

31:20.640 --> 31:27.520
one of the prototypical applications of robust statistics is in something that's called data

31:27.520 --> 31:32.320
poisoning. So this is a phenomenon where you have a machine learning system. So the input

31:32.320 --> 31:36.880
coming from the outside let's say you have many users, but then you have a small number of

31:36.880 --> 31:42.400
malicious users that are trying to insert fake data in the system and completely destroy the

31:42.400 --> 31:46.720
behavior of the system. So robust algorithm would actually be able to prevent that.

31:46.720 --> 31:52.560
Okay, so we have had the number of papers and I've got all of the couple where we actually do that.

31:52.560 --> 31:57.760
We actually show that some of these theoretical algorithms developed in these initial works

31:58.240 --> 32:04.080
can give you provable and practically useful defenses against these types of data

32:04.080 --> 32:09.840
poisoning attacks in machine learning systems. Okay. And are you aware of any actual implementations of

32:10.640 --> 32:15.120
the work in the space? Implementation is what sense. I mean, I'm afraid

32:15.120 --> 32:22.880
there. In a sense of a company using it. I see. Okay. So yeah, we're not there yet. So I'm

32:22.880 --> 32:28.880
very eager to sort of, you know, to collaborate with people to do that. At this point,

32:28.880 --> 32:34.560
we're at the stage where we have sort of proof of principle experiments published in like

32:34.560 --> 32:40.480
ICML and Newrips. So we're not yet at the stage where this sort of line of work has reached

32:40.480 --> 32:46.720
the industry. But it's a goal. It's a goal for the immediate future. And do you think that that

32:46.720 --> 32:53.200
is because the, it sounds like folks are aware of the problem are the solutions sufficiently

32:53.200 --> 32:59.840
generalizable at this point that they are easily applied in industry? So I think the reason is

32:59.840 --> 33:06.160
that it hasn't propagated enough. Right. So in some sense, another reason might be that some of

33:06.160 --> 33:12.000
the algorithms are not just creating the sense. Okay. There are a little bit more sophisticated

33:12.000 --> 33:18.080
algorithms using spectral methods. They're not as automatic as machine learning people who'd like

33:18.080 --> 33:23.120
them to be. So basically, a next step, which is currently something I'm currently working on,

33:23.120 --> 33:28.400
is actually completely eliminate the algorithms from these problems. Right. So we formulate them in

33:28.400 --> 33:34.080
a certain way so that we can just use it in solving. And somehow the insights obtained from these

33:34.080 --> 33:41.760
initial papers are useful. Let's see that. So let me point out that these problems are inherently

33:41.760 --> 33:47.600
non-convex. And this is why they're so hard. Okay. But even for non-convex problems,

33:47.600 --> 33:52.960
when they have some additional structure, it is quite possible that if you formulate them the

33:52.960 --> 34:00.000
right way, some version of SGD actually solves them. And this is something that I believe is true

34:00.000 --> 34:05.200
and we're working towards proving it. Well, Alias, thanks so much for taking the time to share what

34:05.200 --> 34:09.520
you're working on. Something you very much for the opportunity that you gave me. Thank you.

34:13.360 --> 34:18.400
All right, everyone. That's our show for today. For more information on today's show,

34:18.400 --> 34:33.200
visit twomolai.com slash shows. As always, thanks so much for listening and catch you next time.

