Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
In today's episode we're joined by Deba Jotire, founder and CEO of Rivet AI, a startup
producing AI-powered tools for storytellers and filmmakers.
Rivet's tools are inspired and part by the founder's collaboration with the team that created
SunSpring, a short AI-written film starring Silicon Valley's Thomas Middleditch, which
you may have seen when it was making the rounds a while back.
Deba and I discussed some of what he's learned in the journey to apply AI to content creation,
including how Rivet approaches the use of machine learning to automate creative processes,
the company's use of hierarchical LSTM models and auto encoders, and the tech stack that
they've put in place to support the business.
Before we dive in, a couple of meetup related updates.
First off, great news for those of you who missed the first round of our fast AI deep learning
for coder's study group.
Sebastian Ween, who participated in the first study group, has stepped up to lead a second
group through the Part 1 course.
Next, if you missed the announcements on email and Twitter, we recently launched a new
online meetup group that's much more conveniently timed for folks in Europe, the Middle East,
and Africa.
This group is being led by Kai Lichtenberg, who delivered a great presentation on capsule
networks earlier this week for that meetups inaugural session.
To learn more or join either of these groups, please sign up for the TwimmelOnline meetup
at twimmelai.com slash meetup.
All right, on to the show.
All right, everyone.
I am on the line with David Jotie Ray.
Dave is founder and CEO of Rivet AI.
Dave, welcome to this week in machine learning and AI.
Thank you very much for having me, Sam.
So Dave, you studied math as an undergrad at the University of Toronto and actually got
a chance to work in Jeff Hinton's lab.
Tell us a little bit about that and how your career evolved from that point.
Yeah, so I was a math major, math specialist at the University of Toronto, and at the same
time, I was really interested in programming and coding.
So I wanted to combine both of my passions.
And University of Toronto, Jeff Hinton was one of the luminaries in the field, so really
what drew me to the University and to math in particular is I wanted to explore the field
of AI.
And in my first year, I actually convinced Jeff Hinton to allow me to sit in one of his
classes.
And then at the end of the summer, I offered to, I offered my programming services as an
undergrad researcher.
And I was really fortunate when they allowed me to do some of the projects.
But I got a taste of machine learning since my undergrad days itself, working with Jeff
Hinton and other researchers in this lab, especially in the field of Bayesian neural networks.
And I had several publications coming out of it during my undergrad.
After that, I wanted to explore the field of computational neuroscience and dive into
neuroscience a little bit more, so I moved to London.
But at that time, there was kind of a boom in the financial sector.
So I made a digression into more hedge funds and quantitative finance.
But in 2008, I also discovered that I wanted to go back to academia and explore my interests
in deep learning and machine learning, again, armed with a new set of applications.
So I went back to grad school, went to Caltech in the Computation and Neural Systems Group.
And there, my focus was more around generative models, because one of the advantages of deep
learning models is it can capture very nuanced statistical behaviors, very complex statistical
behaviors.
So I wanted to see if that could be used to, as a generative model, to study different
types of behaviors, especially behavioral economics.
So that's something that I pursued during my PhD at Caltech.
But more generally looking at generative models for deep learning.
So from there, while you did start a couple of companies between your grad school experience
and starting rivet, there is a connection in that you were working on generative models
there.
And now you're currently working on applying AI to the idea of content creation.
And maybe tell us a little bit about the inspiration for starting rivet, what drove you to look
at that problem.
So from the business point of view, previously, my previous startup was a video amp, which
was in the video advertising space.
It was looking at different behaviors, consumer behavior, and finding the best kind of video
ads to target to people.
But what I saw there is advertising kind of sits on top of content.
If you don't have good content, then you don't get the kinds of engagements.
That's one of the reasons why companies don't get as much ROI out of their video advertising
spent.
And the other thing that I saw is the shift that more and more companies wanted to put their
money instead of putting into video advertising, they wanted to put it into sponsored content.
Because at the end of the day, consumers, humans in general, we resonate much more to stories.
So an ad is basically grabbing attention.
It's 30 seconds to grab somebody's attention and maybe create Pavlovian responses of the
consumer will go and buy something.
But what really resonates with us forms culture, forms behavior is story creation, story-making.
So there are a couple of, in terms of my own interests, I have been very interested in
natural language generation.
So when we look at generative models, especially generative models for language, I wanted to
see how that could be applied to generate language.
We start with a training set, but you also feed a bunch of different parameters.
So can you actually produce narrative structures?
Maybe even stories someday, right, could a model generate a story.
So that was my general kind of research interest.
And also at the same time, noticing this kind of shift in spend by companies from videos
to content, the technology, especially the deep learning technology, was pretty ripe
to be able to analyze content because the tech has matured to the point where you can
analyze videos, you can analyze audios.
These things are not really very possible a few years back, because it's really the perfect
like confluence of tech maturity and the business moving in that direction.
And also it's my personal passion, which is what led me to start Rivet AI.
Maybe as a touchstone for folks, we can reference a project that folks may have come across.
This is SunSpring.
It was a short film that star Thomas Middleditch, who's the star of Silicon Valley.
And it was written by an AI, basically an LSTM.
Tell us about that project and some of the ways you've worked with the team behind that
sense.
Yeah, so the company EndQ produced SunSpring.
And when I was making my transition from video advertising to content, I teamed up with
EndQ because EndQ is a production company that makes feature films, short films, animation
films, and so on.
And really, who creates the best content?
It's Hollywood.
So I wanted to partner up with the folks who really know how to tell good stories, who
know how to create great content.
And EndQ was really the perfect partner because one of the principles of EndQ is a Caltech
trustee, Walter Corkcheck.
And he's also funded projects in AI and at Caltech.
So that's how we had a meeting of minds and wanted to explore the ideas even further.
SunSpring was a project where the tech behind it was essentially a very simple LSTM.
So it's kind of like the same predictive text that you have from your phone.
So imagine you created a story by taking every predictive response from your phone.
So SunSpring was the seed word.
And then you start with SunSpring and imagine putting that into your phone, but something
more complex, obviously.
Imagine your phone's predictive response is now trained on movie scripts and has a little
bit more of a complex LSTM, long short-term memory model.
And you started using very simple, maximum likelihood estimation and picked every word that
came next, every next word that your phone suggested.
So that's how that script was made.
It was very simple, LSTM trained on sci-fi movie scripts and then just maximum likelihood
estimation.
So from there, the real kind of genius in that project was the director Oscar Sharp
was able to take a script like that and turn it into a very interesting watchable movie.
Interesting and watchable, but not necessarily intelligible.
Exactly.
And really kudos to the actors and the director for making something out of it.
But it was a very interesting experiment that very few people would be willing to do.
And so that experiment was like, what if we could actually take some model like that and
turn it into a movie?
What would that look like?
And the response has been very kind of a bi-model in the sense that some people love
it and love the idea of what it represents.
On the other hand, there's hate.
So whenever you get a bi-model response, but lots of responses, that's when you know
you're onto something and that you have to pursue that.
So we made several iterations, especially with RiverDI, we made several iterations on
top of the models before and we came up with the next generation of AI written content
after that.
But also our philosophy changed quite a lot, which was SunSpring where it was completely
unsupervised.
You know, it's completely unsupervised, maximum likelihood estimation, let's create a script.
And there's absolutely no direction involved.
Whereas really, if you're telling a story and the story has to make sense to an audience,
then two ingredients are super important.
One is knowing the preference functions, right, of who your list or who your audiences.
It could be in the form of general audience data or it could be in the form of something
that interacts with the director and tries to learn their preferences.
And the second part is some sort of physical or even a cultural embodiment that AI program
completely lacks, so imagine just an alien showing up or worse and trying to just generate
something with no idea of what the context is at all.
So what we focused on in our next set of models was to really put a sense of context in that
and also learn preference functions, whether it's a human interaction to a human interaction
with the director or writer or audience responses.
And so that kind of evolved into your next set of models.
And our philosophy now is not so much AI-written everything or AI-autonomously generating content
or AI-autonomously writing stories, but AI-augmenting creativity in a couple of different ways.
One is AI-augmenting creativity because a lot of the creative process for those who are
actually engaged in making content, a lot of the process is very tedious.
95% of the time goes into the tedious stuff and only 5% on inspiring creative works.
So our tech is more focused on augmenting the creative aspects and trying to where possible
take away a lot of the or automating a lot of the tedious aspects.
Can you give us some examples of where the TDM comes into play in this particular use case
with this kind of content creation?
Right.
So, you know, for listeners who are not in the content creation process or filmmaking,
what happened?
The typical flow is, you know, you have a story, a script, everything kind of starts there.
And of course, there's a whole lot that goes into making a script.
But let's, as you may start with the script.
Now the first decision is development, like whether you actually decide to work on the
script or not.
So, usually a studio or a production company will get lots and lots of scripts and they
have to evaluate whether they want to produce it or not.
So tip, usually in the industry, it's kind of surprising how, you know, even when you
have these amazingly huge budgets, there's not a whole lot of data that goes into that
decision making.
So, there are different ways you can incorporate data into that decision whether you want
to go with the script or not, whether you want to analyze that script, make some predictions
of how well it would perform and so on.
So let's say you decide to go with the script.
Now the first point is, you know, first step involves a script breakdown.
So a script is essentially just words on a piece of paper, but they need to be depicted
physically or, you know, through an animation.
So it has to go from words to actual physical representation.
So that is a very tedious process.
You know, you have a 200 page script, what happens now is someone goes in with a marker and
starts going through the script word by word, saying, okay, this is, this here is a character,
the character says this, so we do need a person here in a speaking role or it could be,
and they're sitting at a coffee shop talking about this.
So you need to have a set with a coffee shop and the lead actor, he takes a sit from a cup.
So you need to represent that cup as a prop.
So there's so many elements that goes from telling the story to actually putting it in
production.
So that is something that piece itself is hugely time consuming several weeks often, but
that's something that we can solve with natural language understanding because we can,
with a training corpus of previously annotated scripts, we can identify where characters need
to be represented, where props are required, what kind of sets are involved, set dressing.
You know, if you need a vehicle, you need an animal in that screen, an animal handler.
So all of those, like that script breakdown process can be automated, but there needs
to be a better set of training data for that because films always involve analogies,
so you can have a sentence like buzzing like bees, so you don't actually have to have a bee
in the scene, just an analogy.
So those are things that kind of the AI needs to understand.
It sounds like a very specialized, named entity resolution type of problem.
Yes, we've named entity resolution that understands analogies, or where analogies are coming.
So you have to have a context understanding there.
So that's a huge piece that can be automated, like going from like few weeks to just a
few clicks of a button and a few minutes of a script breakdown.
And then from there, you know, the next phase is once you've got, okay, I need for like
over 200 scenes, every scene, I need these, these parts and this actor and this location,
then it's kind of a scheduling problem, a budgeting problem.
So even the first phase, which is a budget approximation, that again is a hugely time consuming
bees, but since we have all these entities extracted and we have training data from budgets
and how these entities map to different budget estimates, we can construct budget estimates
very quickly.
Same thing with schedules, you know, you have so many parameters, you have certain location
where a film needs to be shot and this actor who's extremely, who's time is extremely expensive.
So how do you combine these to get the best schedules in terms of both cost and time effectiveness?
There are billions of parameters to deal with.
That is often done manually in that industry surprisingly.
So just automating a lot of that, just bringing in AI scheduling tools just, you know, gives
you 10-50 percent efficiencies right off the bat, which for these $100 million budget
productions, you know, are substantial savings.
So those are the tedious parts of this content creation where AI can come in and automate
and provide, you know, budget and time savings.
Do you remain involved in the creative content generation side as well or have you mostly,
I think of the various things that you've described as content support, but more on the analysis
side, if you will, do you tend to focus on that as a company now?
Yeah, so we have also been bringing in different kind of tools, but slowly.
So first, it's kind of, whenever we try to talk about AI in the creative industry or content
creation industry, there's a bit of resistance initially.
So it's also a different strategy for kind of entering the market.
So starting with analysis, starting with things that save time and effort, you know, builds
more comfort in allowing people to understand that, yes, AI tools can actually help my work.
You know, the analogy that I draw is AutoCAD, right?
You had architects who, you know, where it was always considered to be a very creative
endeavor.
Nobody touched my clay models.
But then AutoCAD came in and took away a lot of the tedious aspects of architecture.
And now it's hard to imagine, you know, creating these complex architectural models without
using computers and AI tools.
So the same thing, you know, can happen in the field of content creation, but incrementally.
So one of the, you know, features we've added in is things that make the writing better,
but in the sense of, hey, can we make it more readable?
Can we make, you know, improve readability?
Can we improve audience appeals?
So for example, I'm thinking like, I'm thinking like Grammarly for script writers.
Yeah, I mean, Grammarly, you know, improves, it's targeted to a very broad audience.
So imagine for something that where people are creating content where you can take something
that was, let's say, readability levels 11.
And if you turn that into readability level 5 or 6, then you can show that it'll appeal
to a much broader audience while keeping the fundamental idea, the story, everything
the same.
You're just kind of changing some of the words, right?
And simplifying the sentence structures, but all of a sudden you've reached a much wider
audience.
So that's an example of how you can augment the writing, augment the creation.
The other pieces are, you know, with the short films that we have created where the dialogues
are actually generated or some of the AI characters, dialogues are generated with natural
language generation.
So what is different with that from the previous LSTM models is, and I described the script
breakdown.
Now, the next thing you can do is you can also look at character interactions.
So in Scene 1, let's say you have Peter and Amanda interacting and Scene 5, they interact
again.
You can look at the words that they've spoken.
You can look at, you know, the sentiment of their interactions.
You can even look for continuity by analyzing the sentences that they've spoken.
So imagine doing that for a movie or even a TV series.
You can turn a script into a knowledge graph basically, which is characters and their interactions
over a period of time and use that to identify any continuity issues or things that trail
off.
Like it could be just a story sideline that trails off and doesn't really add much to the central
theme.
Now, for writers, for, you know, imagine like Westworld, there's so many little subplots
going on.
And what you're going to a writer's room like that, it was kind of eye opening for me,
going into a writer's room where the wall is literally covered with sticky notes and
strings tying things together.
And the scripts are ginormous.
That's something that's really hard to do where, you know, again, bringing in tools,
like visualization tools and even a step further, like continuity analysis, looking into, you
know, things that trail off or that improves the content generation a lot.
But you can get a step further, which is let's say now I want to make certain changes
to the story itself.
So I have a knowledge graph and I go to a certain node, which is characters interacting.
And I, you know, I want to move around and play with it.
Let's say let's move the story around and let's see what happens.
So there you can actually use a Bayesian inference to figure out what would happen to the rest
of the nodes if you make a particular change in one node.
So those are the different ways that we can give tools in the hands of writers and producers.
So they feel free to change around different parameters of the story.
Now, something we can't do right now, but we're working towards is also mapping that audience
response data.
So perhaps you can make tweaks to a story, you know, in a way that will be more interesting
to the audience, or maybe you want to try something completely new, just to experiment and
see how the audience would react to something.
Can you talk through the knowledge graph and the use of Bayesian inference at the next
level of detail, how do you translate that, for example, translate that, you know, knowledge
graph and Bayesian inference to something that's to an output that a script writer can use.
Right.
So as an analogy, you know, you can use knowledge graphs have been used in a lot of different
domains.
Let's say in the case of, you know, genetics, right, so you look at pairwise interaction
in one place and then you can use Bayesian inference to say, okay, what if I, you know, made
a change here, like the genetic code here, how that's that influence things in other parts,
right, and connected notes in a, in a, in a call in more of a causal model, where you
know the underlying causality, you can make tweaks to one node and you have a causal model
that will tell you what happens as you move one thing and change, and you know, the effects
that it has for their downstream or on the rest of the graph.
So we have certain models of sentiment and models of, you know, emotional interactions
and character interactions.
These are not like models that you can necessarily write down, but more coral, that we've picked
up by breaking down lots and lots of scripts out there.
So there's a universe of like, you know, 50,000 scripts that may have been produced, an
order of magnitude more if you look at scripts that have never been produced.
So you can do this exercise with, you know, produce knowledge graphs for every script
out there and learn some of these interactions.
Now the way we learned our interactions is we had people go and code these interactions
or annotate from one node to another what the sentiment interactions were.
So we were able to use that data to train kind of like a sentiment causality graph.
If you change one, one, the words or the sentiment of one node, how does that impact the
others downstream?
So that's kind of like a high level version of how we can use a knowledge graph to see,
you know, predict what would happen down the road.
How are we representing sentiment?
Is it like trying to apply human emotions to these things, love, hate, whatever?
Now I'm really just trying to wrap my head around maybe a concrete example of how
a script might apply or translate into this model and then how manipulating this model
helps us with the script process.
Yeah.
So, you know, the simplest example is let's say Paul and Andy are in a fight and Paul kills
Andy.
So now all of a sudden that character Andy can no longer exist in the rest of the scenes,
right?
So that's a very simple inference.
That you fly to the rest of the notes.
Let's get more complicated.
Paul and Andy fight, but then they realize they're working towards the same common goal.
So therefore their interactions now are positive.
So now the rest of the nodes, if you have the next node where Paul and Andy interact
were, Nick was a negative interaction.
So for you to change Paul and Andy's interaction to a positive one, you know, that creates
a big difference.
It's basically leave an explanation gap between your node now with Paul and Andy's interaction
and the next one.
So those are basically gaps that you can look at in their interactions, the character's
interactions that are that become fairly easy to identify.
Now you can get a lot more nuanced, but what we see in scripts generally is that's not
necessary.
That's not really necessary.
If you look at successful scripts and look at their knowledge graphs, they tend to cluster
into very fairly predictable storylines.
So if you just map the sentiments, there are certain things like the hero's journey or
the fall from grace.
These are things that even Aristotle wrote about in the poetics identified a certain
set of story archetypes.
And things haven't really changed even after we analyze all these scripts.
These common themes reappear.
It could be because humans tend to respond to those type of storylines.
So at a high level, that's kind of a mapping to understand what is the general storyline
from the knowledge graph.
The second phase after that is, again, in terms of good storytelling, there is always
a tension and resolution.
Happens throughout.
So if you look at good storytelling, it's never a flat affect all the way through because
that doesn't make for an interesting story.
But something always happens, right?
Even if you're writing a story about somebody doing research, it's not like they kept
working night and day and then found a solution.
It's like, no, they worked really hard.
They were close to a breakthrough and something happened and the world came crashing down the
next day like they're, you know, some of the relatives entered into a car crash and they
got depressed.
So there's always has to be something.
You need that volatility in the story just to attract the audience.
So those are things that can be extracted, you know, without necessarily going too deep
into kind of an emotional analysis or sentiment analysis of the script, even like more higher
level things that we can extract, like positive negative interactions, friendly, unfriendly
interactions.
Those are things that we can extract from the script and that can give us a very good
read into how well it would resonate with the audience.
You've helped us understand the problem that you're taking on, providing, since you
create a support for script writers.
In many cases centered around this knowledge graph and you've mentioned, you know, using
techniques like Bayesian inference, but in trying to apply kind of the full breadth of
machine learning, NLP, NLG, NLU, you know, all of this stuff to these types of problems.
I'm curious if you can talk through the, I just, what are, what are some of the
roadblocks that you've run into applying, you know, things that may have been created
in some research lab to, you know, practical tools that you're trying to put in the hands
of script writers and how have you overcome those challenges?
Yeah, I mean, you know, our, we have had to develop a lot of new methods along the way.
So the, one of the big challenges whenever we deal with generative models is a lot of
the research papers. They look really promising because you read it and it looks like this
natural language generation technique really works, but a lot of the times it could just
be really hand-picked answers, hand-picked solutions, and, you know, working with that very
specific kind of data set.
So, you know, LSTM, right, with that was an experiment we did, if we could just generate
a script using LSTM, what it would look like and we ended up with sunscreen.
And in trying to make that useful, we realized a lot of, you know, a lot of gaps, right,
in where academic research is right now versus what we need to create this full solution.
So with LSTMs, we needed to augment that those models in a lot of different ways.
So first, context becomes super important. Also, we modified those models involved active
learning because we wanted to learn preference functions, we wanted the model to kind of
be, wanted to train it more iteratively. Also, we started looking at conditioning on like
the knowledge graph to generate dialogue or generate next responses instead of just
an unsupervised solution, which a lot of these LSTM-like models papers they talk about.
So just from model architecture and coming up with new solutions, we had to take many
steps beyond what was currently shown. And so, a couple of things, one is, you know,
it may not be a great academic paper if you just combine context plus memory models,
plus hierarchical models into one solution and show how great the results are. A lot
of the machine learning papers kind of are publication center around coming up with
a whole new model and showing the mathematics behind it. And that's what ends up, you
know, getting accepted to nips and ICML. So a lot of that research is not necessarily
directly applicable to what we're doing, whereas it's kind of like more on engineering.
So there's a lot of engineering work that goes in, which may not be the most interesting
machine learning advance, like a new model advance, but it's still pushing the results
and the applications a lot along the way. So that's more on the model side. And, you
know, I think something that there's been a lot of work in on the generative side, there's
been a lot of work in in images. So we look at sharp looking images that have been produced
by GANs. And that's why GANs have become such popular models. But that GANs don't work
very effectively when you're looking at natural language generation. There we have found
auto encoder models to be much more effective, partly because the GAN objective function,
it starts pushing it towards defining the posterior distribution very sharply. So that's how
you end up getting very sharp realistic looking images. But when it comes to natural language
generation, it kind of produces the same very predictable sentences over and over. So
that's where something like an auto encoder model works very well. So these are certain
kind of findings that would be interesting for researchers to explore, but that doesn't
really fit into a lot of the current academic models or current models of, you know, what
gets what's a more interesting publication over another.
So you mentioned a few things in there. One is hierarchical LSTMs. What are those and
how do they come into play? So SunSpring, you know, it all came about because we want
to improve models, the model beyond SunSpring. So an LSTM long short to memory model, you
know, it does a better job than an RNN in terms of long term dependencies. So an RNN tends
to kind of forget, you know, what was the word that was like five, six sequences ago,
whereas an LSTM tends to remember. So like within a sentence, you get more coherence,
but there's still limitations. So if you keep producing coherent sentences, that doesn't
make for a story. So let's add more structure to that. So now if you're with a hierarchical
LSTM, you can learn dependencies across sentences, for example. So now your paragraph that you're
produced becomes more coherent, more understandable. Now you can take it a step further. Now you
can define hierarchies, right? It could be paragraphs to sentences to words. It could
be even beyond that. It could be multiple paragraphs to sentences to words. So these hierarchical
LSTMs provide more consistency in the sentences or the words that have been generated.
Are you training them hierarchically as well, meaning independently, or are they, is it
a model that you're training end to end? Yeah, that's a very good question. So when we
tried to train them purely unsupervised, the hierarchical models, you do get consistency
across paragraphs. That's not necessarily the most useful when you're trying to generate
like stories or do something interactive with a story writer or director. So we had to
use a lot of like annotations. So annotations where basically we had human annotators saying
these paragraphs kind of depict the same idea. Or we had encoding saying which we're using
purely hierarchical models, then every paragraph would be sequentially. We'll make the assumption
that every paragraph is sequentially follows a sequential format. That's not necessarily
the case with stories. So we had to tag these stories by paragraph or by even sentences
to say this relates to that paragraph from page 3 section 2. So those are the longer
range dependencies that we could train our model on because we had the annotated data.
It does strike me that a lot of the challenge in what you're doing has to do with how do
you represent these different contexts or these different concepts and contexts for
that matter and the relationships between them and what are the properties of, I guess
you can get arbitrarily detailed with this. Like what are the properties of a given prop
and is there some inconsistency in the way this LSTM is trying to generate someone's
use of a prop or you're probably not trying to go that far. But have you learned any secrets
or tips for you know just dealing with this representation problem generally?
Yeah. So in terms of representation, that's why we found that the knowledge graph is
the more of most efficient structure for learning or encoding these dependencies. It's
the most succinct representation of these dependencies. So now we augmented our model
so that even for the LSTM it's conditioning on all the output is conditioned on the state
within a knowledge graph. So let's say you have dialogues that you're trying to generate
for a character. Now node number 5 is where let's say we need in node in scene 5 is where
we need to generate new dialogue. So we could either go with everything, all the words
that were written before or we represent the state of node 5 and then the LSTM generates
output conditioned of how you've encoded that state in node number 5. So that's a much
much better representation and I think you know the more research needs to be done in looking
at these knowledge graphs and how you can condition on these knowledge graphs to do
a generation. I'm curious if the concept of embeddings comes into play when you're building
these models? Definitely. So you can't just rely on just straight straight up words because
again when we're looking at words embeddings becomes very important. You have analogies,
you have similarities. So we have to learn we base everything on learning a word and embedding
first. And generally I mean that's you know it's the whole natural language generation and
understanding is a very interesting problem in its own right because everything is so context
dependent compared to let's say image recognition. And you know that's why you know you have
a company like Google and Facebook because they have the largest data set of images you
can see the most variation in that data. But that doesn't necessarily work so much when
you're dealing with natural language where you really have to focus on a particular focusing
on a particular vertical gives you much better results on trying to go after a broad problem.
You know there's some of the natural language processing APIs out there cannot even get
anywhere close to what we want to do because they're going after a lot of breath in their
responses. So that's why in terms of like understanding sentences in their context to
given depth is very difficult because context changes kind of so much based on the domain
and the vertical. You also mentioned auto encoders can you share a little bit more about
how you've used those? Yes so auto encoders we've found work very well with natural
language generation. So what an auto encoder does is you know the input layers have some
number of nodes. The hidden layers actually have fewer nodes than or fewer units than the
input layer and the output layer. So what an auto encoder does is it starts with a large
number of input input nodes. So let's say 100 and the output nodes could be another 100.
But the hidden layers would be fewer like 20 nodes. So what that forces the auto encoder
to do because it's using fewer nodes fewer units in the middle. It has to compress the
input and try to generate the output of the same dimensionality. But it has to compress
the data that's coming in. So what that does in terms of language is you know it forces
one way of understanding it. It takes words and forces that into concepts. So let's say
there's you know the input you want to represent the idea that I take walk stale. There are
different ways of saying that like I'm a regular pedestrian. I occasionally walk around
a lot. So the same idea can be expressed in multiple formats. So an auto encoder because
it's compressing the data that's coming in kind of maps things or is forced to map words
into concepts in non supervised way. Are you doing anything where you're taking those
concept vectors from the middle part of the auto encoder and then using those as representations
in your knowledge graph. Is that kind of what you're getting at? Yes. So those kind of
form you know they're basically they can form the states of the knowledge graph. So the
state doesn't necessarily of a knowledge graph doesn't necessarily need to be something
that is human interpretable. It could be you know the middle layers of an auto encoder.
That could inform the state. Oh interesting. It's an interesting case study perhaps on
the you know the practical applications of of AI like all of the different pieces that
you've had to put together to build the solution. Very very interesting. We started off in
something that can be considered fairly niche because these are scripts written for you
know Hollywood. But from business point of view a Hollywood itself is a very big industry.
But even if you look at beyond Hollywood it's the whole content creation industry is massive
in hundreds of billions of dollars. So although it's a very niche problem the economic impact
of it is very substantial you know it's going it's going after one of the biggest markets.
So at this point still there's a lot of you know trying different experiments or taking
different ideas or taking different models and putting these things together. I think
there's fundamentally more work that can be done you know to to build a whole new class
of models that are able to take context you know in different settings able to encode
relationships between entities between people and use that in generation. Now that's that
is a very interesting research problem to go after. And so as a startup trying to bring
an AI product to market do you see part of your contribution is kind of advancing that
research effort or is that outside of scope of what you're trying to do and if someone
does it great you'll use it but you're not in a position to push these research types
of questions. How do you manage or balance that? As a startup we discovered whole new
market instead of applications we started in you know in Hollywood and analyzing scripts
because that data is plentiful like there's a lot of public data available but we found
that a lot of companies fortune 500 fortune 1000 companies have the same need they want
to produce content you know they all are striving to produce better and better content.
So you know you we trained our AI trained our models on the best data out there or we we
cut our teeth on the harder problem which is producing really high quality storytelling
high quality content that's you know what Hollywood is all about and then applying that
to a broader set of content creation that is very specific like a particular company
you know they're they have a certain context in which they want to produce their content.
So that you know our model is basically translate over. So generally I think you know as a startup
we can't go after you know the broad class of problems and spend years dedicated to one
or two core areas. So our goal is to produce products that our end users want at the end
of the day are end users are producers production companies corporations producing content.
So that's who we are catering to but along the way we've discovered a lot of very good
problems and that's one of the reasons we have collaborated with a lot of universities.
So we have strong collaborations going on with with Caltech and you know we've like hired
interns to work on research problems very specifically because you know I think eight like discovering
these solutions kind of help the community overall and I wish more and more people would
look at these problems because you know that's benefiting everybody but also we can kind
of discover or we're always looking at the at the research findings so we'll notice them
before everybody else and we'll you know implement them towards problems where we we have
a path to market. So that's our approach which is you know trying to build the best product
but also keeping a close eye on research out there and also funding and collaborating
with research labs and universities. It's been really interesting kind of chatting about
how your path bringing this to bringing this to market. I think they've been a bunch of
interesting tidbits for me but probably the most so you want is this just all of the different
pieces that you've pulled together to build a solution and when I think about you know what
it means to build kind of a knowledge graph for these scripts it strikes me as a really you
know potentially you know challenging problem like in a lot of ways you know it's not although
the scale is very different in terms of the number of documents that you're trying to incorporate
into this graph the the challenge in a lot of ways doesn't seem all that dissimilar from you
know what a Google's knowledge graph you know in terms of the diversity of concepts that you have
to represent in it and the way you're pulling together all these technologies to support that
is very interesting. Yeah thank you and and you know yes the volume is less but we do have a lot
of complexity in the relationships and the data that we're trying to analyze. So as a result of
that we've had to you know build some really solid proprietary data sets we have to had a we
needed a lot of annotations so fortunately we're you know we offer the product that
products a lot of those annotations and we could train our system so that goes hand in hand
you know landing on you know our products are used by production company and producers that
so we have the best data for this type of problems and then we are looking for different ways to
like use that and enriching the knowledge graph in producing better generative output.
Just out of curiosity what does your technology stack look like?
Most of our models are code and in TensorFlow we use Python there's different for on the product
side you know we use more Node.js and web interfaces and for our knowledge graph and quoting a lot
of that internally I'm a champion of OCaml. A Lisp guy? Well OCaml has related to that right?
Yeah OCaml is a functional programming language like Lisp but OCaml does a few other nice things
like it has formal verification that actually helps I don't think the research community is really
figured out how to make best use of that but if you incorporate formal verification
you can do knowledge graphs pretty well there's just some properties that you can exploit from
formal verification to construct knowledge graphs and also OCaml has object you know you can
encode objects and classes that means you can have a richer you encode richer data sets that
you can't do with you know Haskell and Lisp for sure. So functional programming languages generally
I think are the way to go for programming in AI because you know functions are primitives
and at the end of the day you're you're doing lots and lots of functional operations on pieces
of data. So I think like the whole AI community could do well to switch to you know functional
programming languages from you know Python and all the imperative languages that people use now.
Awesome well Dave thanks so much for taking the time to chat today it's been really interesting.
Thank you very much for having me Sam.
All right everyone that's our show for today for more information on Dave or any of the topics
covered in this episode head over to twimmalai.com slash talk slash 178.
If you're a fan of the podcast we'd like to encourage you to visit your Apple or Google
podcast app and leave us a five star rating and review. Your reviews help inspire us to create
more and better content and they help new listeners find the show. As always thanks so much
for listening and catch you next time.
