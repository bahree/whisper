WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.080
I'm your host Sam Charrington.

00:31.080 --> 00:35.720
Today we're joined by Wendy Chisholm, Lois Brady, and Matthew Gugamas.

00:35.720 --> 00:40.800
Wendy is a principal accessibility architect at Microsoft and one of the chief proponents

00:40.800 --> 00:47.280
of the AI for accessibility program, which extends grants to AI-powered accessibility projects

00:47.280 --> 00:52.640
within the areas of employment, daily life, and communication and connection.

00:52.640 --> 00:58.480
Lois and Matthew are co-founders and CEO and CTO respectively of Itherapy, an AI for

00:58.480 --> 01:04.080
accessibility grantee and creator of the inner voice app, which utilizes visual language

01:04.080 --> 01:08.280
to strengthen communication and children on the autism scale.

01:08.280 --> 01:13.240
In our conversation we discuss the intersection of AI and accessibility, the lasting impact

01:13.240 --> 01:18.080
that innovation in AI can have for people with disabilities and society as a whole, and

01:18.080 --> 01:24.760
the importance of programs like AI for accessibility and bringing projects in this area to fruition.

01:24.760 --> 01:29.800
This episode is part of a series of shows on the topic of AI for the benefit of society

01:29.800 --> 01:33.840
that we're excited to have partnered with Microsoft to produce.

01:33.840 --> 01:37.840
Before we proceed, I'd like to thank Microsoft for their support and their sponsorship

01:37.840 --> 01:40.160
of this series.

01:40.160 --> 01:44.480
Microsoft is committed to ensuring the responsible development and use of AI and is empowering

01:44.480 --> 01:50.640
people around the world with intelligent technology to solve previously intractable societal

01:50.640 --> 01:57.040
challenges, spanning sustainability, accessibility, and humanitarian action.

01:57.040 --> 02:01.200
Learn more about their plan at Microsoft.ai.

02:01.200 --> 02:06.200
Enjoy the show.

02:06.200 --> 02:15.080
All right, everyone, I am here with Wendy Chisholm, Lois Brady, and Matthew Gugamis.

02:15.080 --> 02:23.040
Wendy is a principal accessibility architect at Microsoft, and Lois is co-founder and CEO

02:23.040 --> 02:29.840
of Itherapy, and Matthew is a co-founder and CEO at Itherapy.

02:29.840 --> 02:33.280
Welcome all of you to this week in machine learning and AI.

02:33.280 --> 02:34.280
Thank you.

02:34.280 --> 02:35.280
Yeah.

02:35.280 --> 02:36.280
Fantastic.

02:36.280 --> 02:37.280
Fantastic.

02:37.280 --> 02:42.840
I think five people is the largest interview that I've done, but we had the advantage of

02:42.840 --> 02:45.400
all being in the same room.

02:45.400 --> 02:54.960
In this case, I'm seated with Wendy, actually in a studio in Redmond, and Lois and Matthew

02:54.960 --> 02:57.440
are joining us remotely.

02:57.440 --> 03:01.720
And today we'll be talking about some of the work that Microsoft is doing around AI for

03:01.720 --> 03:02.720
accessibility.

03:02.720 --> 03:08.120
We're really looking forward to digging into that, but before we do, I'd like for our audience

03:08.120 --> 03:12.560
to get to know each of you a little bit better and what you're working on.

03:12.560 --> 03:14.800
So, let's start with you, Wendy.

03:14.800 --> 03:19.640
How did you get involved in working on this intersection of accessibility and artificial

03:19.640 --> 03:20.640
intelligence?

03:20.640 --> 03:23.760
Yeah, it's a fun story.

03:23.760 --> 03:29.920
It starts 25 years ago when I was working on my computer science degree, and I've just

03:29.920 --> 03:35.520
always been very curious about not only technology, but the humans that use them.

03:35.520 --> 03:39.040
And if we're building technology and no one's using it, why are we doing it?

03:39.040 --> 03:44.640
So, I was studying computer science and psychology, and one of my professors asked me to tutor

03:44.640 --> 03:47.160
a student in statistics.

03:47.160 --> 03:52.120
And I said, yes, and I met him, and he was blind.

03:52.120 --> 03:56.440
And I had not ever met anyone who was blind before.

03:56.440 --> 04:02.320
I wasn't really sure what I was doing, but I was very curious to learn about his experience

04:02.320 --> 04:04.560
and what I could do.

04:04.560 --> 04:11.440
So we got very creative and used Legos to teach bar graphs, and I used a pen to poke holes

04:11.440 --> 04:14.800
in a piece of paper to create a scatter plot.

04:14.800 --> 04:19.120
And with the backdrop of my computer science degree, I was like, there's got to be something

04:19.120 --> 04:21.200
that computers can do.

04:21.200 --> 04:24.280
And that really has been my trajectory ever since.

04:24.280 --> 04:27.080
And it's taken me around the world.

04:27.080 --> 04:29.840
I got to work at MIT with Tim Berners-Lee.

04:29.840 --> 04:32.520
I got to write an O'Reilly book and go to Food Camp.

04:32.520 --> 04:35.960
I got to do a lot of really cool things.

04:35.960 --> 04:43.360
And so what that eventually did was by understanding the diversity of human experience worldwide,

04:43.360 --> 04:50.200
and how culture and language can play into that experience, and trying to shift how people

04:50.200 --> 04:56.080
think and understand the experience of the billion people on the planet who have disabilities,

04:56.080 --> 04:58.800
myself included.

04:58.800 --> 05:00.520
It's just been a very interesting thing.

05:00.520 --> 05:07.520
So what I ended up doing was consulting for a while and helping companies try to make

05:07.520 --> 05:09.960
their websites more accessible.

05:09.960 --> 05:14.560
And in realizing that people get very excited about it, they think, yeah, I want to do

05:14.560 --> 05:19.200
us a great idea, but then not a lot would change.

05:19.200 --> 05:25.120
And so I decided to join a large corporation to understand those decisions are made.

05:25.120 --> 05:30.840
And quickly learned that it's the tooling that can really help people make better decisions.

05:30.840 --> 05:36.280
And a lot of times it's not that people are making decisions that make the world less

05:36.280 --> 05:40.440
accessible out of malice, just a lot of folks don't know.

05:40.440 --> 05:47.000
And so the more that we can infuse our engineering systems with the knowledge and information

05:47.000 --> 05:51.120
that's needed to help people make good decisions, then it's more likely that we'll end up with

05:51.120 --> 05:53.040
more accessible outcomes.

05:53.040 --> 05:55.920
So that's kind of what I've been doing the last while.

05:55.920 --> 05:58.240
And that's what led me to AI and machine learning.

05:58.240 --> 06:04.760
Because to me, the real juice in this, again, is how we bring technology together with

06:04.760 --> 06:09.240
humans, and it's about helping people make good decisions.

06:09.240 --> 06:10.880
So that's kind of how I ended up there.

06:10.880 --> 06:18.120
And so maybe to contextualize what I therapy is up to, I'll have you just talk a little

06:18.120 --> 06:25.760
bit about the AI for accessibility project at Microsoft and your role in particular with

06:25.760 --> 06:26.760
that project.

06:26.760 --> 06:27.760
Yeah.

06:27.760 --> 06:34.880
What's super cool about the program is that there's been this long history of innovation

06:34.880 --> 06:39.320
that for people with disabilities that ends up impacting all of us.

06:39.320 --> 06:46.560
And my favorite example of that is that smartphones wouldn't exist if it weren't for people

06:46.560 --> 06:47.880
disabilities.

06:47.880 --> 06:54.120
And the reason is that when you use an on-screen keyboard to text or to type, that keyboard

06:54.120 --> 06:58.840
was actually created a long time ago for people with physical disabilities who couldn't

06:58.840 --> 07:04.720
actually type whether for weakness or loss of a limb or anything.

07:04.720 --> 07:10.320
And now it's being used by all of us because we're not carrying keyboards around with us

07:10.320 --> 07:12.560
so we can type on our phones.

07:12.560 --> 07:16.320
The phones create such a limiting experience for us.

07:16.320 --> 07:21.120
And that's what technology for people with disabilities is about is just really what

07:21.120 --> 07:23.880
abilities do you have and let's amplify those.

07:23.880 --> 07:30.360
So because of that long history of innovation, what we're doing in the AI for accessibility

07:30.360 --> 07:38.160
program is just funding projects that are working on that next wave of innovation.

07:38.160 --> 07:43.720
And so I get to spend my time talking to people who are working on that next wave and then

07:43.720 --> 07:49.560
kind of figuring out who to fund and how to piece that all together into this, what this

07:49.560 --> 07:51.960
future is going to look like for all of us.

07:51.960 --> 07:55.640
Because like I said, when we innovate for people with disabilities, we end up impacting

07:55.640 --> 07:56.880
all of us.

07:56.880 --> 08:01.200
So I get to kind of look into the future and place some bets basically.

08:01.200 --> 08:04.040
That sounds like a ton of fun.

08:04.040 --> 08:05.040
It is.

08:05.040 --> 08:06.040
Yeah.

08:06.040 --> 08:10.760
I get to talk to really smart people like Lois and Matthew and give them money and support

08:10.760 --> 08:12.880
to do cool stuff.

08:12.880 --> 08:17.920
Lois, can you share a bit about your background and I therapy?

08:17.920 --> 08:20.040
Absolutely Sam.

08:20.040 --> 08:26.840
Like Wendy, our journey started about 25 years ago and I became a speech language pathologist.

08:26.840 --> 08:31.840
I'm working with people who had communication challenges in one way or another.

08:31.840 --> 08:40.160
At that time, technology was all about getting the old technology from the general population

08:40.160 --> 08:46.800
and then we had to adapt it to our students who needed communication technology.

08:46.800 --> 08:52.880
When the iPad came out, that kind of flipped the model for us and it was very impressive.

08:52.880 --> 08:59.000
When I noticed how a lot of my students who had significant challenges, complex communication

08:59.000 --> 09:05.680
needs were gravitating towards the iPad and it encouraged me to write a book called Apps

09:05.680 --> 09:06.680
Fraudism.

09:06.680 --> 09:13.160
So as I was writing that book, I noticed that there are certain features that kids would

09:13.160 --> 09:17.840
attend to and use and they'll use it without even us prompting them to use it and there

09:17.840 --> 09:20.600
are certain features that they don't really care about.

09:20.600 --> 09:25.560
So taking all of those things that all my students really loved, we put them into inner

09:25.560 --> 09:30.840
voice to capture their attention and teach them communication and also just to give kids

09:30.840 --> 09:37.080
with complex communication needs or complex sensory needs, the latest, greatest technology

09:37.080 --> 09:42.360
and just let them communicate more or less like everyone else.

09:42.360 --> 09:49.320
So we created the app in our voice and then when we saw the artificial intelligence grant,

09:49.320 --> 09:54.080
we thought it was absolutely perfect to just keep the students, keep our ideas rolling

09:54.080 --> 09:59.880
along, make it easier, faster, more fluent and really put our kids with communication

09:59.880 --> 10:06.560
challenges at the forefront of technology instead of ten years behind everyone else using

10:06.560 --> 10:09.840
all the equipment that everyone else no longer uses.

10:09.840 --> 10:16.400
So this has been wonderful for us because as our kids use this, they really draw in everybody

10:16.400 --> 10:20.280
around them thinking, oh this is so cool, I want to see what you're doing, I want to

10:20.280 --> 10:21.280
come and use it also.

10:21.280 --> 10:24.760
So it's been a big boost for us.

10:24.760 --> 10:31.080
And I understand that you're also trained in animal assistive therapy and you have a

10:31.080 --> 10:34.200
therapy pig named Buttercup.

10:34.200 --> 10:35.880
This is that correct?

10:35.880 --> 10:36.880
Absolutely.

10:36.880 --> 10:41.880
Buttercup is more famous than anything else I've ever done.

10:41.880 --> 10:47.360
He's absolutely wonderful and I chose a pot belly pig because I specifically work and

10:47.360 --> 10:49.600
I specialize in autism.

10:49.600 --> 10:54.240
And a lot of kids with autism definitely have trouble with dogs because they've heard them

10:54.240 --> 11:00.160
bark before or they've been jumped on or some things happen so they have already a preconceived

11:00.160 --> 11:06.560
notion about a dog or a cat, they may have gotten scratched but a pig, they have absolutely

11:06.560 --> 11:13.960
no idea what to do with a pig and it was breaking new ground and it's just a matter of getting

11:13.960 --> 11:19.800
something that captures their attention and using it to create communication opportunities,

11:19.800 --> 11:20.800
much like the iPad.

11:20.800 --> 11:25.840
When the iPad came along it was the exact same thing, we're using this high interest item

11:25.840 --> 11:30.880
whether it's a pig or an iPad to capture their interest and then teach them communication

11:30.880 --> 11:31.880
with it.

11:31.880 --> 11:33.200
But he's great.

11:33.200 --> 11:34.200
He's great.

11:34.200 --> 11:41.600
So I bring that up mostly because I have a daughter who is studying psychology and loves animals

11:41.600 --> 11:49.880
and her goal is to do animal assisted therapy and I can now tell her that I interviewed an

11:49.880 --> 11:53.440
animal assisted therapist and finally get her to listen to one of my podcasts.

11:53.440 --> 11:54.440
Perfect.

11:54.440 --> 11:58.120
We're here to help.

11:58.120 --> 12:05.280
So Matthew, how about you, can you speak a little bit about your background and maybe

12:05.280 --> 12:12.640
go and take us into a little bit more detail into the I therapy app and how it uses AI?

12:12.640 --> 12:14.040
Absolutely.

12:14.040 --> 12:18.760
My background first actually was as a musician.

12:18.760 --> 12:21.400
So I am actually a drummer.

12:21.400 --> 12:25.800
So I really have been interested in just how you learn skills.

12:25.800 --> 12:30.960
Learning takes a long time to learn, takes a lot of study and that's very similar to how

12:30.960 --> 12:32.560
speech and language develops.

12:32.560 --> 12:37.000
I mean, speech and language, those are probably two of the most difficult skills people

12:37.000 --> 12:38.000
can learn.

12:38.000 --> 12:43.240
So I was really fascinated by how do you actually learn to communicate and using words.

12:43.240 --> 12:49.160
And just like Lois, I specialize with people with autism, I'm a certified autism specialist

12:49.160 --> 12:52.000
in addition to being a speech pathologist.

12:52.000 --> 12:56.920
And early on, when I started working with kids with autism, one of the most difficult

12:56.920 --> 13:05.000
things about teaching them skills was to show them things that captured their interests and

13:05.000 --> 13:10.160
interests leads to learning because if you're not interested in something, it's hard to

13:10.160 --> 13:11.160
pay attention.

13:11.160 --> 13:15.640
It's hard to learn things you don't pay attention to.

13:15.640 --> 13:21.560
So when the iPad came out, I noticed, wow, and this, you could really capture people's

13:21.560 --> 13:25.040
interests with the iPad, just like Lois was saying.

13:25.040 --> 13:33.960
And so we started, the first version of inner voice was just using facial recognition technology

13:33.960 --> 13:37.440
to model speech.

13:37.440 --> 13:41.520
And so this is kind of similar, how a musician learns, you go to a drum teacher, he shows

13:41.520 --> 13:44.280
you something, you copy it, and then you practice.

13:44.280 --> 13:52.760
And it was really interesting that you could, I can get tons of kids to imitate what was

13:52.760 --> 13:55.960
on the screen, but not necessarily what I would model for them.

13:55.960 --> 14:03.920
And so how we've kind of woven in the AI component using the Azure vision services, this

14:03.920 --> 14:09.800
is to me really, it's great because we've been testing it with users now.

14:09.800 --> 14:15.320
And it kind of mimics the way people learn language.

14:15.320 --> 14:20.000
So for example, you look at something, let's say you're a child, you look at something,

14:20.000 --> 14:24.880
you point to it, your parents call it, you point to an animal, your parents say that's

14:24.880 --> 14:29.320
a pig, and then the child says, pig, and then they know what a pig is.

14:29.320 --> 14:37.080
So what we've done with the vision services is that now a user, let's say a kid who's

14:37.080 --> 14:43.680
using the, using inner voice, can use the speech we've called visual language.

14:43.680 --> 14:48.600
And here she can take a picture of a pig, for example.

14:48.600 --> 14:53.640
And what will happen is this will, the photo will get sent to a cloud, and then I'll get

14:53.640 --> 14:58.520
paired with text in the text appears back on the screen.

14:58.520 --> 15:04.560
And the avatar, which was from our original version, will read the text so they can see

15:04.560 --> 15:12.560
themselves saying the word, and then pair that word with the image and written text.

15:12.560 --> 15:17.440
And this is something that we've built up, it's called multi-sensory semiotics.

15:17.440 --> 15:20.960
So semiotics is how you assign meaning to a symbol.

15:20.960 --> 15:31.840
So by using this AI technology, we've been able to pair speech and language with photos.

15:31.840 --> 15:33.920
And it can be interest driven.

15:33.920 --> 15:37.840
So let's say a kid wants to know what something is in the room, he can take a picture of it,

15:37.840 --> 15:40.840
and it can be labeled and spoken for him or her.

15:40.840 --> 15:47.600
And then they can imitate it and learn kind of through self-motivation, what things are

15:47.600 --> 15:53.440
called and how to label or describe things in their environment.

15:53.440 --> 15:59.760
Wendy, I'm curious when you think about, again, this intersection of AI and accessibility,

15:59.760 --> 16:10.240
on the one hand, AI presents an opportunity to allow us to connect more directly or to

16:10.240 --> 16:14.280
provide better support for people that need it.

16:14.280 --> 16:21.080
On the other hand, there's also a risk that the people that need support get left behind

16:21.080 --> 16:24.680
or left out of the innovation that's happening with AI.

16:24.680 --> 16:30.120
And I'm curious, how do you think about those who are there other factors that you think

16:30.120 --> 16:36.080
are like, what's the perspective that you bring to supporting organizations that are trying

16:36.080 --> 16:40.600
to do work in kind of the confluence of these fields?

16:40.600 --> 16:43.280
That's a great question.

16:43.280 --> 16:46.360
And there are several different ways that we can go with that.

16:46.360 --> 16:51.920
On the one hand, the people being left behind and not included is near and dear at my

16:51.920 --> 17:03.240
heart, because as low as talked about technology and how people use it, it's just, it's really,

17:03.240 --> 17:09.040
what I guess what I really want to focus on is that it's so important for us to, as we're

17:09.040 --> 17:14.560
building new technology that we're really bringing everyone who's going to be using it

17:14.560 --> 17:18.840
into get them around the table and involved in the process.

17:18.840 --> 17:23.920
And I think that's why when we see these amazing innovations like the on-screen keyboard,

17:23.920 --> 17:30.240
that was because someone, a developer, was working with someone with a disability.

17:30.240 --> 17:35.400
And so I think one of the things I'm excited about that we're doing is we're specifically

17:35.400 --> 17:40.520
looking for projects that are firmly grounded in the community in which they're intending

17:40.520 --> 17:42.600
to benefit.

17:42.600 --> 17:47.320
And ideally, I want to be a shark tank of entrepreneurs with disabilities.

17:47.320 --> 17:52.160
And so part of that is just making sure that folks have the skills to really contribute.

17:52.160 --> 17:57.280
It also means that we're looking at data sets and we're looking at bias in data sets.

17:57.280 --> 18:03.040
And I think one of the things that we're excited about is the photographs that are taken

18:03.040 --> 18:08.600
by people who are blind or have low vision, they're not going to be perfectly framed.

18:08.600 --> 18:13.880
And so how are they going to, how does that affect the models and the training that's

18:13.880 --> 18:15.560
been done before?

18:15.560 --> 18:20.920
So we want to make sure that there's a good diversity there so that folks are included.

18:20.920 --> 18:24.760
And then we get all the good, innovative, juicy stuff too.

18:24.760 --> 18:29.360
And I have so many great stories about that where when you really include people and bring

18:29.360 --> 18:33.800
them around the table that you just, you get to do some really good stuff.

18:33.800 --> 18:36.040
I'd love to hear some of those stories.

18:36.040 --> 18:42.640
Yeah, and I think the other thing about it too is just, so Sikib, who's one of our engineers

18:42.640 --> 18:46.920
that worked on the Seeing AI project is still working on that.

18:46.920 --> 18:49.160
And I'm not sure if you're familiar with Seeing AI.

18:49.160 --> 18:50.360
Tell us about that.

18:50.360 --> 18:51.360
Yeah.

18:51.360 --> 18:53.320
So it's an iPhone app right now.

18:53.320 --> 18:57.760
And there's a really great demo of Sasha and one of my colleagues and Taylor.

18:57.760 --> 19:03.040
And the reason I love this demo is that, so she's blind, she's using Seeing AI.

19:03.040 --> 19:07.640
And he writes on a piece of paper, accessibility is awesome.

19:07.640 --> 19:12.000
And so she's able to feel where the paper is, take a picture of it.

19:12.000 --> 19:16.120
And the text, the handwriting is recognized and read out loud to her.

19:16.120 --> 19:24.840
And for her, that means now that she can read cards or business cards or letters from family

19:24.840 --> 19:25.840
and friends.

19:25.840 --> 19:28.360
And so I think it's really, it's empowering.

19:28.360 --> 19:29.600
And I think that's really cool.

19:29.600 --> 19:35.720
And I think when you start looking at the dream that Sikib has of when he's walking around

19:35.720 --> 19:41.920
with a friend who knows him and his preferences, his friend is able to say,

19:41.920 --> 19:46.560
he's able to recognize what he's interested in and maybe tell him, this is what's changed

19:46.560 --> 19:52.800
since the last time we were here, or give some color about what's happening in the space.

19:52.800 --> 19:57.960
But when you look at that, that's just another eyes free interface.

19:57.960 --> 19:59.920
And it's something that I think we'd all use.

19:59.920 --> 20:06.160
When I'm touristing in a new place, and I don't know the language, or I don't want to

20:06.160 --> 20:09.960
be looking at my phone for directions because I don't want to appear to be a tourist.

20:09.960 --> 20:14.600
And I want some of that feedback in my ear and getting it tailored to me.

20:14.600 --> 20:16.720
That's something we can all use.

20:16.720 --> 20:22.040
So again, that's kind of what I feel the power is for us is, and that goes kind of back

20:22.040 --> 20:23.840
to the decision making as well.

20:23.840 --> 20:27.080
In those instances, we're helping people make better decisions because we're giving them

20:27.080 --> 20:30.560
information that they didn't have before.

20:30.560 --> 20:33.120
So it doesn't really matter if you're disabled or not, right?

20:33.120 --> 20:35.200
You want information so you can make better decisions.

20:35.200 --> 20:37.480
And that's really what this is about, I think.

20:37.480 --> 20:48.440
Yeah, I love this recurring theme of the innovations that we are creating to support

20:48.440 --> 20:54.040
people with disabilities, kind of coming back full circle and impacting the way we use

20:54.040 --> 20:55.040
technology.

20:55.040 --> 20:56.960
The way everyone uses technology.

20:56.960 --> 20:57.960
Exactly.

20:57.960 --> 21:05.880
And I mean, what I really hope the world goes is that by making sure that we're all at

21:05.880 --> 21:11.480
the table and contributing, we're not creating barriers and disability kind of disappears.

21:11.480 --> 21:16.600
Because one of my favorite quotes is, it's the stairs that make the building inaccessible,

21:16.600 --> 21:18.000
not the wheelchair.

21:18.000 --> 21:19.800
And to me, that's the beauty of it, right?

21:19.800 --> 21:25.280
If we can really design the world such that everyone can participate, it's just not really

21:25.280 --> 21:26.280
a thing anymore.

21:26.280 --> 21:32.120
We're all benefiting from these connections with other people.

21:32.120 --> 21:35.040
So again, that's the juicy part with AI.

21:35.040 --> 21:39.400
Because our devices now have so many sensors in them and can give us information that we

21:39.400 --> 21:43.280
may miss, whether we're eyes busy or we're blind.

21:43.280 --> 21:47.560
And that's, there's just so much opportunity there.

21:47.560 --> 21:48.560
Absolutely.

21:48.560 --> 21:56.040
Lois, can you elaborate on the kind of experiences you've seen with the users of the inner voice

21:56.040 --> 22:00.040
app and the kind of impact it's had for them?

22:00.040 --> 22:01.040
Absolutely.

22:01.040 --> 22:06.480
We've been using this in our clinic and in school districts.

22:06.480 --> 22:12.160
And we're even branching out now into hospitals with folks who may have had strokes or head injuries.

22:12.160 --> 22:18.440
But initially, it was made for video self modeling when you take a picture and you see yourself

22:18.440 --> 22:23.880
producing the target language or the target word.

22:23.880 --> 22:28.040
And then we added in the vision where they can take a picture.

22:28.040 --> 22:34.040
Just like Wendy said, it's amazing they can take a picture of words or a thing.

22:34.040 --> 22:37.040
And then the avatar says what that is.

22:37.040 --> 22:43.400
And across the board from the youngest student which we have is probably around two to some

22:43.400 --> 22:46.840
of the oldest which are in their 80s, it's amazement.

22:46.840 --> 22:50.440
They get so that their mouths just drop.

22:50.440 --> 22:56.400
And it becomes then the, I call it like an electric communication environment.

22:56.400 --> 23:00.400
Now everyone's coming over asking about it wanting to use it.

23:00.400 --> 23:05.400
And it just produces this place where now we want to talk and the students want to talk

23:05.400 --> 23:07.400
about what they're doing.

23:07.400 --> 23:11.600
And then our students start adding in characters that they like and they make their characters

23:11.600 --> 23:12.600
talk.

23:12.600 --> 23:17.600
So it's all about just providing these wonderful opportunities for not only the student

23:17.600 --> 23:20.960
to talk but people to come in and say, oh my gosh, show me what you're doing, what's

23:20.960 --> 23:21.960
going on.

23:21.960 --> 23:26.960
So there are kids quite literally never had those opportunities before.

23:26.960 --> 23:29.960
So they're leading the pack in that manner.

23:29.960 --> 23:35.960
So because they do have all this wonderful AI embedded because of the Azure services.

23:35.960 --> 23:38.960
So they're reading the way and nobody's ever seen this.

23:38.960 --> 23:42.960
So they get to be the cool kid.

23:42.960 --> 23:48.960
And I think Wendy hit it a little bit before when she was talking about the universal design.

23:48.960 --> 23:54.960
And I went and used it with a student who was bilingual and didn't have any English at all

23:54.960 --> 24:00.960
and using a translator app, we were able to put in one language and speak a different language.

24:00.960 --> 24:07.360
So the technology is just absolutely amazing and we can almost hit any kind of a challenge

24:07.360 --> 24:09.360
and overcome it right now.

24:09.360 --> 24:12.280
And it's never happened that way for us before.

24:12.280 --> 24:15.960
Technology was something that was cumbersome and hard to use but no more.

24:15.960 --> 24:18.960
Everyone has it in the palm of their hands.

24:18.960 --> 24:22.960
And again, our kids are like leading the way at this point in time.

24:22.960 --> 24:31.560
Matthew, can you share a little bit about your experience in using this using AI as a technologist

24:31.560 --> 24:35.560
building it into the application?

24:35.560 --> 24:42.560
What was your background with regards to AI and how did that inform the way you incorporated

24:42.560 --> 24:43.960
it into the app?

24:43.960 --> 24:46.960
Well, I've always loved technology.

24:46.960 --> 24:52.960
I've always been someone who just loves to read about technology or learn how it works.

24:52.960 --> 24:57.960
My first and foremost background in terms of, I guess, scientific background

24:57.960 --> 24:59.960
and its communication sciences.

24:59.960 --> 25:05.960
And so I looked into how AI could be used for that field.

25:05.960 --> 25:13.960
And probably the one that first caught my eye and then how Lois and I developed our visual language

25:13.960 --> 25:20.960
feature was the character recognition, like describing the feature where I was talking about

25:20.960 --> 25:24.960
before, pairing images to text.

25:24.960 --> 25:29.960
So I thought, wow, that is a fantastic way to help with literacy and help with possibly

25:29.960 --> 25:32.960
help people who maybe just want to learn a different language.

25:32.960 --> 25:36.960
It could be applied, and if you have no disability, oh, it could be applied to that.

25:36.960 --> 25:42.960
The other aspect was I got really fascinated by the smart bot technology that particularly

25:42.960 --> 25:44.960
Microsoft has now.

25:44.960 --> 25:50.960
So they have a number of these services, text, speech, and then the language understanding

25:50.960 --> 25:53.960
and Q&A frameworks.

25:53.960 --> 26:00.960
And it's almost sort of like you can see a lot of this in their Cortana app that they've released.

26:00.960 --> 26:06.960
And that, back to kind of tying back to my background as a musician, you have to practice

26:06.960 --> 26:08.960
things to be good at them.

26:08.960 --> 26:14.960
And I thought, well, what a great way to make practice motivational for kids or anyone

26:14.960 --> 26:17.960
by, you know, you can make a bot that will interact with you.

26:17.960 --> 26:19.960
You can ask questions.

26:19.960 --> 26:21.960
You can find out information.

26:21.960 --> 26:28.960
And one of the trickiest things to teach any person with communication challenges

26:28.960 --> 26:31.960
is to initiate a communication exchange.

26:31.960 --> 26:34.960
But a bot is kind of a friendly place to start.

26:34.960 --> 26:39.960
You can say, what's the weather, what time is it, or what's a platypus, or, you know, what's a pot belly

26:39.960 --> 26:40.960
pig.

26:40.960 --> 26:43.960
And then the bot, or the bot, I had to tie that.

26:43.960 --> 26:46.960
And so the bot can come back with an answer.

26:46.960 --> 26:52.960
And it's motivating because being motivated really is a huge factor in communication.

26:52.960 --> 26:59.960
And AI can, can answer infinite questions about a subject that may be an individual's only interested in.

26:59.960 --> 27:04.960
I mean, so I, I think it's sort of a long answer to your question.

27:04.960 --> 27:10.960
But there's a host of reasons why I got into AI and particularly for communication sciences.

27:10.960 --> 27:16.960
We're going to see how many times we can say pig in this podcast.

27:16.960 --> 27:34.960
Did you specifically work on the integration with the Azure services into the app, or was that work that was done by other folks or via Microsoft?

27:34.960 --> 27:49.960
Oh, so we, our role, specifically, lowest and I do this, we work on the UX UI design first and foremost, and then we work closely with a developer who has helped us from the beginning design interboys.

27:49.960 --> 27:51.960
His name is Junichi Fujita.

27:51.960 --> 27:52.960
He's an amazing guy.

27:52.960 --> 28:11.960
And so we went through some of these tutorials about how to integrate the Azure services into our existing code because basically we're leveraging the cloud-based services into our iOS code because it's currently intervoices in iOS.

28:11.960 --> 28:22.960
And so we contracted with Junichi who did the coding first because I'm actually not a coder. I'm a speech pathologist.

28:22.960 --> 28:28.960
And so we come up with the designs and find the technology to make sure it's feasible for what we want to do.

28:28.960 --> 28:35.960
And then he is barely being able to translate that pretty much exactly to our specifications who work with them for a long time.

28:35.960 --> 28:49.960
Are you aware of any challenges or impediments that you and he ran into in incorporating AI and these cognitive services into the application?

28:49.960 --> 28:52.960
They were actually stunningly easy to integrate.

28:52.960 --> 29:06.960
The biggest problem was the UI UX stuff. So that will be kept going back and forth. Well, how should it look? What's the easiest way for it to be used by users? Because we do a lot of user testing.

29:06.960 --> 29:21.960
We don't just think, hey, I think people will like this. We actually designed something based on observation and interviews with people and we try it with them. And then they either like it or think, oh, this is no good. And then we go back and redesign itself.

29:21.960 --> 29:30.960
Most of the challenges were just in that aspect. But in terms of integrating the the Azure services into our code, it was really easy.

29:30.960 --> 29:40.960
And they've had an easy time, which is great. I think when I look to some of our other grantees, I think they're going to be pushing the limits of the technology.

29:40.960 --> 29:50.960
In particular, when we look at some of the work that Zyrobotics is doing, they're looking at speech recognition for students with non-typical speech patterns.

29:50.960 --> 30:08.960
And so they're really having to train the data and expand what it can recognize. We've got another grantee from the University of Iowa. And she's using a camera to help athletes who are blind and running around jogging tracks.

30:08.960 --> 30:25.960
And so the cool part about that one is with a jogging track, you have clear lines in most tracks, right, kind of indicating where the lanes are. So once they get those recognizes working in real time, they will be able to tell someone they're starting to veer out of their lane.

30:25.960 --> 30:35.960
Now, the problem is getting that working fast enough on the device in real time so that you're not getting it like, oops, a few seconds later and you run into somebody.

30:35.960 --> 30:44.960
And these are athletes who are actively competing. And if we can solve some of those issues, the independence is great.

30:44.960 --> 31:00.960
That's incredible. I happen to live very close to a school for the blind and I see their track all the time and they've got these, I don't know if listeners have ever seen these, but they've basically got these guide wires along the lanes.

31:00.960 --> 31:20.960
And so they can still participate in the activity. But I can envision bringing AI to a device that the athlete can can wear totally eliminates the need for a specialized setup.

31:20.960 --> 31:31.960
They can compete with other athletes and, you know, be on a level playing ground with the help of a model that's running in a phone.

31:31.960 --> 31:44.960
Exactly. Yeah. So there's some going to be some really hard challenges with that one. And I can't talk yet about this next round, but we're in the midst of interviewing our basically what we do, we kind of are operating like a shark tank.

31:44.960 --> 31:53.960
And so after we review a bunch of the applications, we'll invite them in for a pitch meeting, just to kind of meet folks and get a sense of what they're really doing.

31:53.960 --> 32:02.960
And so I'm very excited about some of the ones we're hearing this week. This is pitch week for us. And so we'll be announcing in January, then this kind of next round.

32:02.960 --> 32:08.960
But people, and again, now that there's some maturity to the program.

32:08.960 --> 32:15.960
And, you know, it helps that, you know, Sasha has been out there talking about it too. We're getting some really cool applications.

32:15.960 --> 32:25.960
So I think we were very lucky with a therapy in our first round in Zyrobotics. And now we're just, it's really growing. And so we've got, we've got some fun things in the works.

32:25.960 --> 32:46.960
But yeah, I think too, there's just so many opportunities to use, you know, internet of things and just all these sensors. And, you know, from my own. So I have PTSD. And so I have so many sensors, kind of monitoring different aspects of heart rate and, you know, trying to predict just how I'm feeling.

32:46.960 --> 33:03.960
And I still have not been able to pull together a dashboard that pulls together all my calendar and health data and, you know, mood data and all of this stuff. And I think like, I just, I'm looking forward to some of what we can do.

33:03.960 --> 33:16.960
There's just so much more that we know. And there's so many patterns that we can recognize. And then if we can kind of pull that together, again, it's about the decisions that it allows us to make. And so I'm really excited about that.

33:16.960 --> 33:38.960
It's funny that you mentioned patterns because that's the word that was floating in my mind around this next question. And that's really about the patterns that you see as you work with organizations that are using AI in an accessibility context.

33:38.960 --> 34:00.960
And I think that the broader part of the question is around, you know, as we've started to work with accessibility in the broader computing context, we've developed, you know, specifications and guidelines that at this point are fairly well understood and codified.

34:00.960 --> 34:14.960
And I'm curious, do you, do you see AI for accessibility evolving in a similar way, or is there not a need for that? How do you see that evolving?

34:14.960 --> 34:35.960
That's a really great question. And my work at MIT was on some of those standards. And so that's right in my will house. I'm not sure about that. Honestly, I do think, though, as I'm reviewing, so part of my time too is giving feedback to folks who, well, let me put it this way.

34:35.960 --> 34:50.960
I do a lot of educating about possibilities. And so I do spend time when people are creating plans for how to use AI in their organizations, making sure that they're considering all scenarios and not accidentally creating more barriers.

34:50.960 --> 35:11.960
And so I know there's work going on with other types of guidelines, like there are some, there's some work right now at W3C in terms of cognitive disabilities and some new suggestions on how to make websites more accessible for folks who have learning disabilities or even emotional disabilities.

35:11.960 --> 35:28.960
I am very curious to see where things go in terms of augmented reality in VR. I was looking at a manufacturing, someone talking about manufacturing the other day and how to bring AI into the floor, the manufacturing floor.

35:28.960 --> 35:41.960
And really looking at, there's opportunities here, I think, for people with disabilities to have the employed in some of these new jobs, as long as people really consider how it's being designed.

35:41.960 --> 36:02.960
So for example, in a manufacturing scenario, getting feedback from a bot about how something is working or being notified that, hey, we've noticed, we've detected that this run has some errors and we're seeing some patterns. And just making sure that the information is being presented, if it's audible, well, but it's also going to be intact.

36:02.960 --> 36:12.960
So what's interesting to me is that I think a lot of the potential issues I'm seeing have already been documented and it's kind of just the same things over and over.

36:12.960 --> 36:25.960
And it doesn't surprise me because that's kind of what I've seen in my career, right? I did, I analyzed Java years ago and said, here are the things that we need to do to make sure that if you're using Java, your applications are going to be accessible.

36:25.960 --> 36:35.960
And the concepts haven't really shifted that much, you know, I think if you have visual information, you need to make sure you also have auditory and tactile information.

36:35.960 --> 36:39.960
And just because you never know the scenario, someone's going to be in.

36:39.960 --> 36:45.960
And again, I just, I'm going to tie it back because I really want to drive the point home that any time you do that, huh?

36:45.960 --> 36:55.960
Oh, a pig. Yeah. Oh, my God. How can I integrate pig into that? That's a good challenge.

36:55.960 --> 37:02.960
Because no matter what you're doing, it could be used by a pig. No, I'm kidding.

37:02.960 --> 37:10.960
You never know the scenario that someone's going to be in. And you never know the opposite, the kind of scenario, the environment that someone's in, right?

37:10.960 --> 37:20.960
So for captions, especially on that manufacturing floor, it's got to be really loud. So I was actually really surprised that they were designing something that was audible without being visual because I'm like, isn't it going to be noisy?

37:20.960 --> 37:28.960
I mean, I think everyone is going to be experiencing hearing loss in, you know, on this floor. So, you know, it was just surprising, surprising to me.

37:28.960 --> 37:35.960
So, yeah, I don't know that we'll have new standards, but you never know. It kind of depends on what evolves.

37:35.960 --> 37:46.960
I do actually know I think about it. I think the data sets, I think we are going to have to have some standards that clearly ensure that we have good diversity and all the conversations going on about bias.

37:46.960 --> 37:54.960
I mean, that that's a big part of it right there. It's just making sure that we aren't accidentally continuing to discriminate against people with disabilities.

37:54.960 --> 38:08.960
Because unfortunately, that is quite a reality, especially when you look at, yeah, well, I'll just say that. And that's part of the culture change. I think AI can really help with is ensuring that we're supporting a culture of more diversity.

38:08.960 --> 38:18.960
Yeah, I think one of the things that's most exciting about all the work that's happening in so many places about AI for social good.

38:18.960 --> 38:37.960
And the various aspects of it is just how intersectional it is that, you know, the issues that the folks that are working on AI ethics and AI bias and now the work that we're discussing here around accessibility at ties in so many ways.

38:37.960 --> 38:51.960
And I guess what's kind of bringing that thought to mind is just that I have lots of conversations about bias and bias and data sets, bias and AI systems and you know, think about how important that is in this context.

38:51.960 --> 39:04.960
And then how, you know, as we overcome those issues and create new technologies here, how that feeds into the technologies that we all benefit from.

39:04.960 --> 39:11.960
Yeah, I can't help but think it creates exciting opportunities for folks that want to kind of jump into this field.

39:11.960 --> 39:17.960
Well, that's the thing. And I think that's when I've been talking. So some of our applicants aren't as familiar with disabilities.

39:17.960 --> 39:23.960
And that's great. They're familiar with AI and machine learning and they can see, oh, this is how I can get the data you're looking for.

39:23.960 --> 39:39.960
And that's really a very cool thing is that if we can bring together people who are looking for ways that their work in AI and machine learning can impact humans all over the planet.

39:39.960 --> 39:46.960
I think that that's a very exciting opportunity where we can really start making those partnerships and bringing people together kind of matchmaking.

39:46.960 --> 40:01.960
You know, like, hey, we see over here that this community has this need. Is there anyone out there doing something similar and we can pair you together and then, you know, you can test this out and continue to evolve your work in a way that's really going to be impactful for somebody.

40:01.960 --> 40:08.960
And, you know, one of the things we keep saying is we're funding projects that are developed with or by people with disabilities.

40:08.960 --> 40:19.960
And again, that's because it's when it's grounded in reality, then you know, you get something good. You know, Lois and Matthew talk about how much time is around the UX.

40:19.960 --> 40:33.960
And I think that's so important. You know, that's where the really good stuff comes from is when you're really looking at how people use this and how they are going to integrate it into their daily lives. What it allows people to do.

40:33.960 --> 40:47.960
Lois, when you look forward, what's, you know, what do you see in terms of incorporating AI more deeply in what I therapies doing?

40:47.960 --> 40:54.960
Well, we have we have plans probably up and through the next 10 years.

40:54.960 --> 41:14.960
We continue using this. We have great plans. It's really made, you know, it's made a big difference with a lot of our students. However, one of the main, the main pain points that they have is by the time they come up with something to say are there they can't or join a conversation.

41:14.960 --> 41:30.960
The conversation is done. It's fluency. It's the rate that they speak. And that's across the board and across abilities and ages is that if you're using a device to speak and not using your own voice, it takes a lot longer.

41:30.960 --> 41:47.960
That is probably the gap I would love to bridge is that someone who cannot use their natural voice can jump into a conversation and speak like anyone else. That's going to be difficult and that's absolutely going to be AI.

41:47.960 --> 42:04.960
Currently that it takes so long for for people to either generate a sentence or search for the word they want to say that most folks check out of the conversation and our folks don't really get to have one on one conversations unless they're pre made and scripted.

42:04.960 --> 42:11.960
So that's our I think my ultimate ultimate goal is folks who have challenges speaking can speak like just about anyone else.

42:11.960 --> 42:23.960
Yeah, that's a really beautiful moonshot. There's a lot of these things in AI where we look for that real time with the jogging track that real time feedback and hear real time speech generation.

42:23.960 --> 42:31.960
And we see that in a lot of scenarios. And I think that's yeah, I agree. That's that's the that's the vision. That's a good vision.

42:31.960 --> 42:49.960
Matthew, what's what are you most excited about from an AI perspective? Well, we are looking into coming up with some diagnostic tools, which I think are going to be really cool.

42:49.960 --> 43:12.960
I think they so we're hoping to come up with we're just in the preliminary pieces of this now, but using AI to analyze data through possibly a Q&A framework and to help people create solutions for communication delays or disorders.

43:12.960 --> 43:24.960
So basically one of the ways that we as speech pathologist evaluate people now it's the kind of paper and pencil test and then you have to score it and then it just becomes kind of cumbersome.

43:24.960 --> 43:30.960
And so what we're hoping is we're taking a look at some kind of far out ideas.

43:30.960 --> 43:46.960
In fact, I read this article in wired magazine about a guy named Carl Friston who's into this concept called free energy. And so we're thinking of some ways to take that concept and apply that to diagnosing communication disorder.

43:46.960 --> 43:59.960
So I think that's pretty exciting. So we're that should be in the next few years. So that's that's my I guess goal for the future is to develop that among other things.

43:59.960 --> 44:14.960
Nice. Nice. So one day I gather that by the time folks get an opportunity to listen to this podcast, you'll be just in the midst of finalizing your next round of grantees.

44:14.960 --> 44:29.960
Yeah. Yeah. Before the for folks that hear this and are interested in working with this program, what is the process to look like and you know, when should they start looking for the next round to open up?

44:29.960 --> 44:45.960
Oh, really? Yeah. We're constantly kind of reviewing them. And the link to apply is really easy. It's aka.ms slash grant. Super easy. So aka.ms slash grant.

44:45.960 --> 45:03.960
Yeah. So you pull together an application and we'll review that. We're really looking for projects that are going to elevate the industry. We're not as interested in funding just someone to develop an application.

45:03.960 --> 45:23.960
Not someone who is going to contribute something back because for us, that's really how we're going to raise the water and bring up the boat. You know, and so that's part of what we're looking at is either someone willing to contribute a data set or a model or some other learning, whether research paper or something like that.

45:23.960 --> 45:36.960
And obviously someone who's whether by themselves or through partnership or grounded in community. And that it's something that'll be feasible to accomplish in a year.

45:36.960 --> 45:49.960
So while we in tip, we really are looking for projects that will go beyond a year and there's something that can be built on the grants are your long grants. And so there needs to be some deliverable in that year.

45:49.960 --> 46:00.960
But yeah, and we encourage everyone to apply. I mean, literally anyone from anywhere. So we've done a push in Latin America. We're going to be reaching out to Asia soon.

46:00.960 --> 46:16.960
We do have grantees in different regions. We have a few folks in Europe, one in India. And we're really looking to expand that because especially I'd really encourage folks in Asia and Latin America because

46:16.960 --> 46:28.960
I recently learned and just to spend a moment on Latin America that the unemployment rate in general for people with disabilities is usually twice that of people without.

46:28.960 --> 46:37.960
And the average age is 30 years old in Latin America. And to me, that's like prime employment age. And so we really want to shift those employment numbers to that point.

46:37.960 --> 46:47.960
We really are looking for people for applications and projects that are going to have an impact in our focus areas, which are employment, daily life and communication and connection.

46:47.960 --> 46:58.960
So for example, Lois and Matthew, this is communication and connection, the jogging track that's daily life because that's out and about being independent.

46:58.960 --> 47:13.960
And then employment is another one we've got from Vanderbilt is a good example where they're building a bot that can help someone who has autism and, you know, it's interested in practicing for job interviews and stuff like that.

47:13.960 --> 47:21.960
So it's going to it does some really cool modification of the interview to help someone practice.

47:21.960 --> 47:33.960
So, yeah, I encourage anybody and it NGO nonprofit, individuals, companies, slings, you meet some of those criteria, go for it.

47:33.960 --> 47:36.960
And are they fixed size grants or what's the range?

47:36.960 --> 47:44.960
Yeah, so right now we have a couple categories. We've got one set of grants where we're, it's just called an Azure credits.

47:44.960 --> 47:51.960
And so we're just giving folks credits to just play and learn and see what they come up with, make some progress on their idea.

47:51.960 --> 47:59.960
The other one is kind of an Azure credits plus. And in that one, that's the category that Matthew and Lois are in.

47:59.960 --> 48:16.960
Is we have a community we have a lot of support in terms of education and we've got on staff folks who can help with technical questions integration with Azure. We've got great connections with cognitive services, Microsoft research.

48:16.960 --> 48:29.960
So we can really support folks in their development and give them cash for engineering costs or data acquisition data cleaning data labeling, you know, kind of some of those pieces just needed to build.

48:29.960 --> 48:41.960
And right now we don't we're not really saying much about how much it is we're new we're kind of experimenting with how much we give people and what results we got.

48:41.960 --> 48:46.960
So yeah, we'll see how it goes.

48:46.960 --> 48:52.960
Do you by any chance have a wish list of ideas that you'd love to fund?

48:52.960 --> 49:00.960
I do. Yes, we have several moonshots that I'd love to see. I want to see a self-driving wheelchair.

49:00.960 --> 49:14.960
I want to see a dashboard for people with PTSD like I said that I want that dashboard for myself that pulls together all the data that I have and really learns and can start recommending and predicting.

49:14.960 --> 49:25.960
I want to keep to get his digital assistant so that he can be out and about as he's traveling and get you know information to make decisions.

49:25.960 --> 49:33.960
I love for my friend who is deaf who recently went in for a surgery and her sign language interpreter was late.

49:33.960 --> 49:38.960
So she had to lip read and it was very scary she didn't have all the information.

49:38.960 --> 49:43.960
But if she had had kind of a backup interpreter that could help her in that situation.

49:43.960 --> 49:49.960
And you know the doctor couldn't wait, you know, so those are some of the things that we're looking for.

49:49.960 --> 49:57.960
And then I'm just curious to learn what other ideas people have out there. Like I said, there's some things I heard this week I hadn't even thought were needed.

49:57.960 --> 50:01.960
And now I really want to fund them. So fantastic.

50:01.960 --> 50:11.960
Well, Wendy, Lois and Matthew, thank you so much for taking the time to chat with us about AI for accessibility.

50:11.960 --> 50:12.960
Thank you.

50:12.960 --> 50:21.960
Lois and Matthew, in particular, congratulations for what you're doing. It sounds like a great application with a lot of impact and Wendy great program.

50:21.960 --> 50:22.960
Thank you.

50:22.960 --> 50:23.960
Yeah, thanks.

50:23.960 --> 50:24.960
Thanks so much.

50:24.960 --> 50:25.960
Thank you, Sam.

50:29.960 --> 50:32.960
All right, everyone, that's our show for today.

50:32.960 --> 50:42.960
For more information on Wendy, Lois, Matthew or any of the topics covered in this episode, visit twimlai.com slash talk slash 227.

50:42.960 --> 50:51.960
To follow along with our AI for the benefit of society with Microsoft series, visit twimlai.com slash AI for society.

50:51.960 --> 50:59.960
Thanks once again to Microsoft for sponsoring this show and series. Learn more about their plan for AI at Microsoft.ai.

50:59.960 --> 51:03.960
As always, thanks so much for listening and catch you next time.

