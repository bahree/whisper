All right, everyone. I am here with Artur Yakimovic. Artur is co-founder at Artificial Intelligence
for Life Sciences and a visiting scientist in the lab for molecular cell biology at University
College London. Artur, welcome to the Twimal AI podcast. Hello, Sam. It's a pleasure.
It's great to have you on the show and I'm looking forward to our chat. You know, let's get started
with a little bit about your background. You are very active in trying to bring these two streams
together, AI and life sciences. You know, what's the origin of that interest? That's a great question.
So, I guess, you know, by my background, essentially, highly interdisciplinary. I did my undergrad
in chemistry. Then I decided that I'm very interested to learn where does chemistry stop and biology
starts. So I went on to do a PhD in biology and computational biology. And computers and
computer science was always a great interest for me and I was always thinking about, well, you know,
we could probably do more and better in biology in general and, you know, spearhead the discovery
if we use a little bit more computers there. So after finishing my PhD, I did a short postdoc
at University Hospital in Zurich and I was working on in the Department of Microbiology working on
bacteria and computer vision algorithms. And after that, I moved on to do another longer postdoc
University College London. The postdoc I just recently finalized.
Okay. Cool. And you said something interesting in there. You wanted to see where chemistry stopped
and biology finished and that led you to studying viruses. What's what about viruses kind of
characterizes that that edge unlike any other, you know, number of biological processes that are
also fundamentally chemical? That's a great question, thanks. So in principle, you know, there's
a big philosophical discussion where the viruses are dead or alive. I think personally,
and that's that might start a huge conversation in the in the follow-up of the show, but I think
I think personally that they are undead. So, absolutely, vampires and zombies in the life.
Well, think about that. Viruses technically are alive only once they are inside of a host cell.
So at any time between that, they don't show any signs of being alive. So in that sense,
they can be classified as either alive or dead at any time apart from any specific circumstances.
But they're different from other compounds, and that once they are inside of a host, they start
to do things that we associate with being alive like... Absolutely....and metabolize and all these other
things. Absolutely. So not like some inert catalyst. Exactly. Yeah. And they are very complex systems
that are able to self-replicate and go on with their lives for only that long as the host is alive.
And so after... I mentioned your co-founder of an organization, artificial intelligence for
life sciences, it sounds like it's a consortium is probably not the right word, but it's an organization
along those lines and that you're trying to bring folks together and start conversations.
Tell us a little bit more about what you're up to there and your goals.
Yeah, absolutely. Thanks a lot. So the artificial intelligence for life sciences is essentially just
a platform bringing together people from life sciences, academics, and anyone who is interested in
life sciences in any way, and bringing people... Platform like platform like Facebook or...
We use multiple sort of technology platforms, just an organization or platform.
More like an organizational platform. We simply bring people together and provide
them with means like a simple forum, an exchange of data, a chat where they can exchange
opinions and ask for some technical help or maybe some clarifications and stuff like that.
So our main page if you look at it essentially is a forum where we try to discuss things,
do journal clubs, look at papers, share code, share solutions, and so on.
So the organization itself is aimed as a community interest company, a non-for-profit organization.
And the core idea behind it is essentially to bridge the massive massive divide that exists
between life sciences and computer science or artificial intelligence.
And the divide is constantly growing and as AI progresses, things become more and more
difficult to get into. And we're trying to kind of bring the value that advanced AI can give
to life sciences and to scientific discovery.
Why is it that you think that AI gets more difficult to get into for folks in the life sciences?
It seems like as the field progresses, different approaches become commoditized,
the tools are becoming commoditized and the barriers to entry in a lot of ways are falling.
That certainly is the case. However, let's say many problems that are getting
commoditized are still not the same problems that life sciences is looking on.
So, in life sciences, you quite often try to do things in a little bit more of a broader fashion
where you try to bring in several methods showing the same thing. Whereas in computer science,
you quite often try to look at the same problem over and over and over again using a variation of
as, you know, like you define those canonical problems like facial recognition and
somatic segmentation and so on and so on. Whereas in life sciences, you're trying to bring all
sorts of different kinds of data, DNA sequencing, bi-imaging electron microscopy, this kind of
things in order to kind of show the representative problem from multifaceted view.
So, in this sense, it's a quite a different way of thinking about these problems.
And although certain methodologists get more and more commoditized, as they do, so they certainly
become less difficult to apply to the same problem and more difficult to apply to new problems.
Okay. I've had a number of conversations with folks on the podcast
in the life sciences and a lot of them have, well, they've been fairly varied, but a good number
of them have been focused on microscopy data. And I think that aligns with just the point you
are raising that we've made, made so much progress in computer vision recently. Is that one of the
the fields or problems that you've been working in? Yeah, absolutely. Definitely, thanks a lot
for mentioning it. So the microscopy is and biomedical imaging in general is sort of a
pinnacle of the entire quantitative biology and the way it's moving forward. It is one of the most
sort of digitalized sources of biological data. And obviously working with images is getting
increasingly more and more sort of easier. Like I wouldn't say easier, probably easy is the wrong
word. It's getting, you're getting a bigger tool set to work with images every day. And
thanks for getting. Go on to that distinction. So you've certainly got a lot of tools, but hopefully
the impact of all of these new tools is that they make things easier, but you're not quite ready
to say that yet. Yeah, I think quite often it's a little bit of that's hidden again on the same
point that you raised before, as we progress with things like AutoML and things getting easier and
more commoditized. Suddenly, you don't even know anymore. What is it that you're looking for?
Are you looking for image classifier? Are you looking for a segmentation? And there's awful loads
you need to know about overall image analysis and all this kinds of problem in a history, a problem's
history sort of if you will and computer science background to move it to the from the idea or an
actual biological problem to a computational problem that is then going to be solvable by those
commoditized tools. So we'll come back to kind of some of the broader life sciences,
you know, issues, but let's maybe talk a little bit about your particular research interests.
What did you do for your postdoc and what are some of the things that you do in your current role?
Right, thanks. So in my postdoc, I worked in combining deep learning with
microscopy, quite specifically, super-resolution microscopy of viruses. So virus
particles or like one of the tricky things about viruses altogether is that probably one of the
perhaps one of the only thing that they have in common is that they are cold viruses.
They are quite different entities altogether depending on the kind of virus. They may be
comprised of RNA. They may be comprised of DNA. They may be large. They may be small. The
size can vary between microns and nanometers. So like probably the smallest one is around 20,
30 nanometers. So it's a vast huge field with things being very, very fragmented in multiple subfuelts.
So again, that's coming back to the problem of making things more applicable for computer science
methodology, right? If it's certainly not a great idea to have a lot of small data sets rather than
one huge data set helping to solve one big problem. So in this, in one of the projects,
I worked in several vapors. In one of the projects I've listened to published, we managed to
sort of explore the space of a super-resolved virus particles of so-called
vixenia virus. It's a box virus family. What's the virus name?
Vixenia virus. It's the virus that was used as a life of a vaccine for eradication of small
pox. And in this work, we looked at, we used a set of different relatively advanced,
or let's say, you could say state of the art and neural net architectures for image analysis
and image classification to solve a number of day-to-day problems of ourologist phase
with their data. For example, if you've got a micrograph of a cell infected by a virus,
how do you tell whether the tiny little dots that look like kind of stars are inside of the
cell or outside of the cell? And that's in three dimensional space. So in a biological sense,
what we managed to show is that you can use advanced neural networks to pick
these minute signals, alterations that occur once the virus is crossing the cell or membrane,
so that you could tell that from the virus micrographs by themselves. And one of the interesting
sort of tricks we managed to use in this case, and that's advocating for
using a deep learning for viruses specifically, is that we've been multiplexing the number
of data points through the fact that you would have multiple viruses per one single cell.
And since quite often in microscopy, the fixed magnification is way more suitable for
celler size than the virus, single of our size, you get way more virus particles in your
data set from one single cell. And that allowed us to use more advanced neural nets. And
additionally to that, we developed a trick where we called mimicry embedding, which essentially
repurposed, it's a variation of transfer learning where you simply repurpose things like
amnesty by just feeding all this potentially not useful representations from handwritten digits.
And it turns out that single channel of a viral core looks very similar if you projected
in a certain way, it looks very similar to a handwritten digit. So data sets are very similar
in this case. And that allowed us to sort of avoid the trap of using very high capacity
neural nets on relatively shallow data sets. And just so I'm understanding what you're
saying here, are you saying that this single channel super resolution microscopy imagery,
you're able to do some kind of dimensionality reduction or projected into some embedding space
and to something that's on the order of an amnest digit in terms of the number of features or
there's actually something that is like the digits themselves about this data set that you're
working with. It's more coincidental in this case and it's just the fact that if you work in
fluorescence microscopy, there's a lot of, you know, tricky technical things that are already done
for you as compared to traditional computer vision. So let's say if you have a normal photograph
in computer vision, you would need to mix channels or do some semantic segmentation to avoid
to look at the foreground versus background. And since those were problems in the field of
microscopy for a very long time and a long time ago before we had all these powerful computers and
methods, there was a rather simple physical solution sort of developed for this computer science
problem, if you will, where fluorescence functional microscopy used the system of specific
specific color elimination and filters to just filter out the light that is not necessary. So
you are end up with just looking at the foreground on the black background. And that is quite
an interesting sort of approach and it's very, very commonly used essentially in microscopy
fluorescence microscopy. And that's why, you know, when in computer science people quite often
were, you know, trying to develop a very complex solutions to do the segmentations in biology
people were just like, oh, we're just used, you know, a binning or thresholding as Nikola to just
separate up and down and we're happy we've got our objects here. So that's, it's, there's a
difference in mentality in both fields. And I guess that's what I was alluded to in my previous
points. In past conversations, the issues that I tend to hear about that make traditional approaches
to like segmentation easy to apply to this microscopy data are things like occlusion where you've
got, you know, whatever your target is, say a virus or a cell, depending on your scale, you've got
because you've got these multiple layers, you can have them stacked on each other and things like
that is the nature of the problem that you are looking at such that, you know, because the
virus is the virus are so small relative to the cell that you didn't have that those types of
occlusion issues to deal with or were you, you know, zooming in to able to kind of isolate the,
you know, the individual virus entities or is there, is there something else happening there?
That's a, that's a great question. I'm really glad you asked. So the thing is that in case of
viruses, what we had, what we're dealing with quite often is a very, so we are hitting the
so-called diffraction limit of enlightened microscopy. So obviously that would be definitely
small enough to properly resolve the virus. Absolutely. So, and it depends, obviously it depends
on the virus you're working in, but the virus I was working in and that particular study was
around 450 nanometers in diameter and that's as close as it gets basically to being slightly
above the diffraction limit, which is about 200 nanometers depending on the wavelength. And
basically that allows to exist at this sort of sub-pixel, a little bit of a structure resolution
and you would maybe be able to see, to see if you get a brighter particle in case it's a cluster
of multiple viruses and not, but it's very difficult to get essentially ground truth for that.
And we're just moving towards this direction. We're at the limit of diffraction, if you will,
in virus-like microscopy. And that's where we need techniques like super-resolution microscopy,
which is not to be confused with super-resolution in AI. It's slightly different.
Right. I'm glad you mentioned that because I was wondering about whether there was a relationship
between the two. Super-resolution in AI tends to refer to taking a photo of a given resolution
and making a higher resolution, usually a generative version of that. Super-resolution
microscopy is just talking about using very higher resolution microscopes or is there more to it
than that? So essentially, in a physical scale, there is no a straightforward way to bypass the
or to cross the diffraction limit. And several techniques have been proposed in the past
a few decades that are extremely interesting and extremely successful at the same time. And they
some of them overlap a lot with computational microscopy techniques where you would
essentially try to find sources of information to allow you to cross this limit and compute
beyond the diffraction limit. One of sources of such information could be temporal source where
you could try to unmix individual point sources by making molecules blank rather than shine at
the same time. And another ways to do that would be to temporarily deplete some of the molecules
that are shining and make sure that only if you are shining again. But essentially, the trick
of super-resolution microscopy or difficulty of super-resolution microscopy is that
that there is different fundamental information difference between
pixel resolution and spatial resolution. So with the spatial resolution, you're trying to
understand if you have one pixel, is this one molecule or two molecules. And with pixel resolution,
you can happily create a little bit of structure by doubling the number of pixels and try to do
some prediction there. But essentially, if you don't have enough information on whether it's
single molecule or whether it's two molecules or multiple molecules, then you're a little bit in
trouble, you don't have enough information. And that's why there are all this clever techniques how to
bypass that. Now, I'm trying to resolve all this conversation we're having about the diffraction
limit and things like that with these terribly detailed pictures of the, you know, coronavirus
that we're all intimately familiar with now. Is that just a gigantic, massive virus that is easy
to resolve? Or how do we produce these, you know, those images relative to the types of things
that we're talking about? So one of the classic techniques, so I would say that that light microscopy,
the stuff that I've been talking about, is relatively fresh in virology and sort of a bread and butter
technique in virology would be electron microscopy. So electron microscopy, by using electrons,
rather than photons, you definitely can bypass the diffraction limit. And hence you can get those
very detailed images of viruses. But the trouble with electron microscopy in general is that it
takes a room-sized device and a days of sample preparation to do some work there. So it's also
destructive relative here. Yeah, absolutely. Yeah, so you definitely cannot do this life.
So there is a, there is a field in microscopy or in light microscopy called
a life microscopy or a lifestyle microscopy where you just essentially do a video of what's going
on the cell with a different temporal resolution. Got it. And so this entire project that you
are working on was interesting from a life sciences perspective because it was allowing you to
resolve things at the level of a virus that were kind of at the edge of what you might be able to do
with light microscopes. It's actually not particularly impressive for scanning electron microscopes,
but just that's a lot more expensive. And not only that, I mean in terms of let's say differences
in, there are differences in sample preparations, as you said, right? The sample preparation can be
destructive and the entire sort of process of so-called functional microscopy is not as well
developed in electron microscopy. By functional microscopy, I mean the situation where you can
specifically tag the molecule you're interested in. So in this case, you in fluorescence microscopy,
you're able to know specifically like, oh, I, you know, I placed a GFP, which is a green fluorescent
protein in the capsid of a virus. So I know that if I'm seeing some green spot, that's probably the
capsid of the virus. And that's what I mean by functional microscopy and that's a whole new different
level of techniques. And I think electron microscopy is trying to get to that level, but it's a
way, way trickier. So there's so in addition to to costs and the sample prep, there's also just
stuff that we know how to do with light that we haven't figured out how to do with electrons yet.
Absolutely. Okay. Okay. And so is this work that you're referring to the work that was recently
accepted in the American Society of Microbiology paper or is this is that different? Yeah, yeah,
that's a fresh stuff of the press. Awesome. And so in our, you mentioned that that paper also
looked at the application of caps nets, capsule networks to this problem. And I mentioned when
we were chatting earlier that I think this may be the first time I've heard of caps nets being
applied in the wild. Tell us a little bit about your experience using caps nets. Why, why did you
you know, try that route and what kind of results did you see there relative to, you know, CNNs?
Yeah, thanks. Absolutely. So the caps nets, I have to say, they kind of swayed me with the whole
sort of elegance of the idea. So I decided to try them on and just drop some data on it.
And there's not a skirm that the folks are familiar with that, you know, maybe take a second to
what specifically swayed you about the idea there and what the idea? Yeah, absolutely. So the idea
of having sort of nested representations in capsules and trying to learn the nested representations,
I find this somewhat attractive just because you probably would expect some logical connections
to be retrieved in such a way. So I decided to try to train a capsule network. And so this
turned out to be relatively difficult with absolutely sort of naive architecture without any
pre-trading. However, using this trick that I've been talking about before with embedding some
amnesty data and training it together with, or in a transfer learning sort of setting
with various data, that helped a lot. And we got pretty good results. Resnets still win,
but capsule networks are able to train on even on such wild data, as you mentioned.
Interesting. Yeah, so the way I tend to think about the capsule idea relative to
CNNs, and you tell me if this is a horrible explanation or not, is I think of CNNs as being good at
kind of this two-dimensional, translational, invariance, whereas capsule networks are
designed to represent kind of the structure within the thing, the image in multiple
and higher dimensions, is that the main thing that you find interesting there?
Yeah, absolutely, yeah. And I think that's there is something in this idea because I just
doing some convolutions and then pulling it somehow, although it works remarkably well,
and I don't mean to say anything about very clear and basic convolutional networks.
However, it seems like there should be something more to that, so I choose a belief.
And when it comes to the ultimate results that you saw is the idea and kind of what
is power in your belief in the promise of Capsnets, is it that we with CNNs, and I think you said
you use Resnets, like we know how to scale the compute there, and Capsnets, they're newer,
maybe we don't know how to scale the compute as well and make networks that are as deep, but
fundamentally, if we could do with Capsnets, what we are able to do now with Resnets,
you would expect it to perform better, is it that kind of thing where we're just kind of catching up
in our ability to compute. I'm trying to really get at the thing that you think holds,
you know, holds so much promise given that it isn't working as well.
Yeah, so I hope that exactly, as you suggested, if we able to scale the sort of network capacity
required to address certain problems, we'll get to, we'll get them to work a little bit better
than they do at the moment. And in principle, maybe it's not the capsule networks in general
that will work out in the end. Maybe it is also some other approach that will build upon this
promise that, you know, there's more of a context that we need to try to include in multiple levels
at the same time. Is there, is your work touching on kind of this inherent graph, graphical nature of
the underlying biological systems at all, is that something that you look at?
Not yet. Unfortunately, we didn't have sort of capacity to look at this aspect, but I certainly
think that, you know, there's only that many questions you answer, you can answer with a binary
classification problem, right? So there is definitely an necessity to go deeper into representing the
knowledge that is contained in the massive bodies of biomedical literature, for example,
to try to understand the complexity that we have in the data. I mean, from the point of,
from probably the very first day when I started working with microscopy images, I always perceived
it as a sort of an ultimate roach act test, if you will. You get a spot, like a white spot,
or a grayscale spot in a black background, and you try to understand what is that thing,
and different people would definitely see different things in the same image. One person would be
like, oh, what is that thing? Oh, somebody told me that's a cell nucleus, and another person
would see chromatin there, and a cell is about to divide, and, you know, there's a lot of
information that depends on the contacts, and depends on your prior knowledge there. So,
obviously, as you said, I think incorporating things like knowledge graphs into work like this
would be definitely a way forward, and that's something that I see developing in the coming years
and the field. And so, maybe using that as an opportunity to zoom back out to AI and life sciences
generally, we spend a lot of time talking about microscopy, and that plays a big role in the field.
Are you, has your organization, you know, many new attempts to kind of map out the various ways
that AI, you know, can or should impact life sciences, and how far along we are in those various
areas? That will be a thing to go for that we that we have already discussed with my colleagues.
And unfortunately, we hadn't had that much time to do that just yet, but I think in general,
you know, going beyond just microscopy and images, looking at the, there's a lot of research
going on right now in the field of molecular life sciences in general, looking at the
molecular structures or sequences, protein sequences, DNA sequences, and trying to combine it with,
you know, basic techniques like, same that is used in the in the fields of natural language
processing, for example, right, where you could try to use some generated approaches, for example,
to see, to predict the binding sites and to predict novel confirmations of molecules and so on.
So this is definitely a great direction to start getting into. And I guess the way I see the
mission for the organization is that we should try to bring the conversation forward to
to combining similar to the way that life sciences are structured today. We need to combine
multiple sources of information revolving around a single phenomena in order to sort of
be able to push the discovery because life's discovery in life sciences is never done as a result
of a single sort of method that that shows one thing. You always need to reach out and then try
to prove, prove your concepts using multiple methodologies. And yeah, look at things from
multiple sites. And is that fundamentally because what where the real insights are in life sciences
when we start to understand function and you don't just kind of see that in a one shot thing,
it's based around a developing body of knowledge that comes from looking at things in different angles.
Absolutely. So the thing is that my most discoveries made not because, you know,
you see something unusual and that's a discovery. It's quite in contrary, it's a rigorous process of
just trying to prove that you made a discovery essentially in multiple ways until you run out of
ways to just to prove yourself. So I remember when I stumbled upon a virus inhibitor for which
we were published in 2017, it was using biomedical imaging at the time lapse imaging of
of a so-called virus plaques. Virus plaques are when you start the infection with one single cell
at Chines Green and then you see that the infection spread into neighboring cells and you get an idea
what's going on with those cells. Are they supporting the infections where I do not? And I couldn't
get it to work under certain conditions and it turned out that one of the molecules I was keeping
in my medium was preventing it from spreading and that's how you stumbled upon a discovery.
But essentially to get from that point to the actual published paper, it took collaboration of
multiple people and multiple methodologies to address multiple aspects of what's going on.
So what degree are there hobbyist opportunities in life sciences? Do you have to have the
backing of a huge lab to not necessarily make interesting discoveries but even play with the
data or are there things that folks can do to just start to better understand biology with
the tools that we have in neural networks and the data sets that have been made available.
That's an excellent question, thanks a lot. So actually I believe personally that there are
massive amounts of hobbyist opportunities scattered around the field. There is simply not enough
hands in life sciences to get all this advanced methodologies going and doing what they can do best
like fostering science, improving the accuracy of assays and so on. So I think that
that's one of the main missions of the organization I'm trying to build. It's to bring together
hobbyist researchers from all sorts of fields in order to see, okay, maybe there is an opportunity
to publish paper here and there and maybe there is an opportunity to make advances in biology.
Maybe there is an opportunity to just get some published data and play with it a little bit.
So that's one of the goals of this work. And in principle there is really a lot of data sources
that maybe not many people know about that they can immediately work with as from a public domain.
And there are a lot of open problems, we just need hands.
Awesome, awesome. And so for folks that are interested in taking you up on that, how do they
find you, connect with you, learn more about the opportunities that are out there?
Go to ails.institute and join the forum, start conversation, ask a question.
And the idea is that we will connect you with researchers who are actually working at this.
Awesome. Awesome. Well, Arter, thanks so much for taking the time to share a bit about what you're up to.
Awesome. Thanks a lot. It's a lot of fun. Thank you.
