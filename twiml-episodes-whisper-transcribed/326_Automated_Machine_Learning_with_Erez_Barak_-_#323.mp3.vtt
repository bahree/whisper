WEBVTT

00:00.000 --> 00:13.400
Welcome to the Twimal AI Podcast.

00:13.400 --> 00:15.600
I'm your host, Sam Charrington.

00:15.600 --> 00:23.200
Hey, what's up everyone?

00:23.200 --> 00:24.200
This is Sam.

00:24.200 --> 00:29.040
A quick reminder that we've got a bunch of newly formed or forming study groups, including

00:29.040 --> 00:34.800
groups focused on Kaggle competitions and the fast.aiNLP and deep learning for coders

00:34.800 --> 00:36.760
part one courses.

00:36.760 --> 00:42.960
It's not too late to join us, which you can do by visiting twimalai.com slash community.

00:42.960 --> 00:47.960
Also, this week I'm at ReInvent and next week I'll be at NURRIPS.

00:47.960 --> 00:50.360
If you're at either event, please reach out.

00:50.360 --> 00:52.360
I'd love to connect.

00:52.360 --> 00:57.860
Alright, this week on the podcast, I'm excited to share a series of shows recorded in

00:57.860 --> 01:01.580
Orlando during the Microsoft Ignite conference.

01:01.580 --> 01:05.820
Before we jump in, I'd like to thank Microsoft for their support of the show and their sponsorship

01:05.820 --> 01:07.140
of this series.

01:07.140 --> 01:11.900
Thanks to decades of breakthrough research and technology, Microsoft is making AI real

01:11.900 --> 01:18.660
for businesses with Azure AI, a set of services that span vision, speech, language processing,

01:18.660 --> 01:21.740
custom machine learning, and more.

01:21.740 --> 01:26.180
Millions of developers and data scientists around the world are using Azure AI to build

01:26.180 --> 01:31.260
innovative applications and machine learning models for their organizations, including

01:31.260 --> 01:35.260
85% of the Fortune 100.

01:35.260 --> 01:41.260
Microsoft customers like Spotify, Lexmark, and Airbus choose Azure AI because of its proven

01:41.260 --> 01:47.420
enterprise grade capabilities and innovations, wide range of developer tools and services

01:47.420 --> 01:49.460
and trusted approach.

01:49.460 --> 01:54.500
Stay tuned to learn how Microsoft is enabling developers, data scientists, and MLOPS

01:54.500 --> 02:00.260
and DevOps professionals across all skill levels to increase productivity, operationalize

02:00.260 --> 02:06.660
models at scale, and innovate faster and more responsibly with Azure machine learning.

02:06.660 --> 02:11.540
Learn more at aka.ms slash Azure ML.

02:11.540 --> 02:14.340
Alright, onto the show.

02:14.340 --> 02:22.740
Alright, everyone, I am here in Orlando at Microsoft Ignite and I've got the pleasure of

02:22.740 --> 02:25.660
sitting with Eris Barak.

02:25.660 --> 02:28.580
Eris is group manager for Azure AI.

02:28.580 --> 02:31.340
And it is welcome to the Twoma AI podcast.

02:31.340 --> 02:32.340
Thank you.

02:32.340 --> 02:33.340
Thank you.

02:33.340 --> 02:34.340
Great to be here.

02:34.340 --> 02:35.340
Great to be here with you, Sam.

02:35.340 --> 02:36.340
I'm super excited about this conversation.

02:36.340 --> 02:43.020
We will be diving into a topic that is generating a lot of excitement in the industry and that

02:43.020 --> 02:48.580
is AutoML and the automation of the data science process.

02:48.580 --> 02:55.540
But before we dig into that, I'd love to hear how you got started working in ML and AI.

02:55.540 --> 03:00.380
It's a great question because I've been working with data for quite a while.

03:00.380 --> 03:06.500
And I think roughly about five to ten years ago, it became apparent that the next chapter

03:06.500 --> 03:11.620
for anyone working with data has to weave itself through the AI world.

03:11.620 --> 03:19.540
The world of opportunity with AI is really, really only limited by the amount of data you

03:19.540 --> 03:26.180
have, the uniqueness of the data you have and the access you have to data.

03:26.180 --> 03:33.380
And once you're able to connect those two worlds, a lot of things like predictions, new insights,

03:33.380 --> 03:36.060
new directions, sort of come out of the woodwork.

03:36.060 --> 03:42.620
So seeing that opportunity, imagining that potential has naturally led me to work with AI,

03:42.620 --> 03:45.780
I was lucky enough to join the Azure AI group.

03:45.780 --> 03:49.700
And there's really three focal areas within that group.

03:49.700 --> 03:51.500
One of them is machine learning.

03:51.500 --> 03:58.100
How do we enable data scientists of all skills to operate through the machine learning

03:58.100 --> 04:03.220
lifecycle, starting from the data, to the training, to registering the models, to put

04:03.220 --> 04:07.860
in them in productions and managing them, a process we call ML ops.

04:07.860 --> 04:13.660
So just looking at that end-to-end, then I'm just understanding how we enable others to

04:13.660 --> 04:19.460
really go through that process in a responsible, trusted, and a known way, it's been a super

04:19.460 --> 04:21.460
exciting journey so far.

04:21.460 --> 04:27.380
And so did you come at this primarily from a data science perspective, a research perspective,

04:27.380 --> 04:28.860
an engineering perspective?

04:28.860 --> 04:33.900
Well, I think none of the above or all of the above, I'm actually going to go with all

04:33.900 --> 04:34.900
of that above.

04:34.900 --> 04:39.580
I think it'd be remiss to think that, well, if you're going to hit it from a data science

04:39.580 --> 04:46.620
perspective and you're trying to build a product, really looking to build the right set of products

04:46.620 --> 04:51.620
for people to use as they go through their AI journey, you'd probably miss out on an aspect

04:51.620 --> 04:52.620
of it.

04:52.620 --> 04:55.620
If you're just thinking about the engineering perspective, you'll probably end up with

04:55.620 --> 04:59.380
great info that doesn't align with any of the data science.

04:59.380 --> 05:05.220
So you really got to think between the two worlds and how one empowers the other.

05:05.220 --> 05:12.020
You really got to figure out where most data scientists of all skills need the help.

05:12.020 --> 05:13.020
Want the help?

05:13.020 --> 05:18.340
Are looking for tools and products and services on Azure to help them out?

05:18.340 --> 05:23.180
And I think that's the part I find most compelling, sort of figuring that out and then really

05:23.180 --> 05:28.340
going deep where you landed, right? Because if we end up building a new SDK, we're going

05:28.340 --> 05:34.300
to spend a whole lot of time with our data science customers, our data science internal teams

05:34.300 --> 05:37.620
and figure out, well, how should that SDK look like?

05:37.620 --> 05:41.900
But if you're building something like AutoML that's targeted not only at the deeper data

05:41.900 --> 05:47.380
scientists, but also the deeper rooted data professionals, you're going to spend some

05:47.380 --> 05:51.220
time with them and understand not only what they need, but also how that applies to the

05:51.220 --> 05:52.900
world of data science.

05:52.900 --> 05:56.780
And what were you working on before Azure AI?

05:56.780 --> 06:02.260
So before Azure AI in Microsoft, I worked for a team called ShareData, which really created

06:02.260 --> 06:05.860
a set of data platforms for our internal teams.

06:05.860 --> 06:09.860
And prior to joining Microsoft, I worked in the marketing automation space, completely

06:09.860 --> 06:12.580
called the Optify.

06:12.580 --> 06:17.460
And again, the unique assets we were able to bring to the table as part of Optify and

06:17.460 --> 06:20.100
the world of marketing automations were always database.

06:20.100 --> 06:24.620
We're always sort of looking at the data assets the marketers had and said, what else can

06:24.620 --> 06:26.100
we get out of it?

06:26.100 --> 06:31.100
Machine learning wasn't as prevalent at the time, but you could track back to a lot of

06:31.100 --> 06:35.660
what we did at that time and how machine learning would have helped if it was used on such

06:35.660 --> 06:36.980
a general basis.

06:36.980 --> 06:44.300
Yeah, one of the first machine learning use cases that I worked with were with folks

06:44.300 --> 06:52.380
that were doing trying to do like lead scoring and likelihood to buy propensity to buy types

06:52.380 --> 06:53.380
of use cases.

06:53.380 --> 06:55.900
I mean, that's been going on for a really long time.

06:55.900 --> 06:56.900
So we're on a podcast.

06:56.900 --> 07:03.380
So you can see me smiling, but we did a lot of work around building load, lead scoring.

07:03.380 --> 07:04.380
Okay.

07:04.380 --> 07:07.460
And you're a sticks and manual, you're a sticks and sort of general, you're a sticks and

07:07.460 --> 07:10.060
you're a sticks that the customer could customize.

07:10.060 --> 07:14.660
And today you've seen that to really evolve to a place where there's a lot of machine learning

07:14.660 --> 07:15.660
behind it.

07:15.660 --> 07:16.660
I mean, it's perfect for machine learning, right?

07:16.660 --> 07:18.900
You've got all this data, it's fresh.

07:18.900 --> 07:22.660
It's coming, you know, it does insights that are really hard to find out.

07:22.660 --> 07:27.940
Once you start slicing and dicing it by regions or by size of customers, it gets even more

07:27.940 --> 07:28.940
interesting.

07:28.940 --> 07:32.540
So they're all the makings for having machine learning really make it shine.

07:32.540 --> 07:33.940
Yeah, you are getting pretty excited.

07:33.940 --> 07:35.660
Oh, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,

07:35.660 --> 07:36.660
no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,

07:36.660 --> 07:44.260
no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,nice,

07:44.260 --> 07:45.580
nice, nice.

07:45.580 --> 07:47.580
Who want to dive into talking about auto ML.

07:47.580 --> 07:48.720
I mean, this is.

07:48.720 --> 07:54.880
Yeah, probably for the level of excitement that and demand for auto ML and enthusiasm

07:54.880 --> 08:00.580
that folks have for the topic, not to mention the amount of confusion that there is for

08:00.580 --> 08:01.580
the topic.

08:01.580 --> 08:08.380
covered it nearly enough on the podcast, you know, certainly, you know, when I think of when I

08:08.380 --> 08:17.260
think of AutoML, if there's, you know, a long kind of academic history behind the the technical

08:17.260 --> 08:25.980
approaches that that drive it, but it was really popularized for many, you know, with Google's cloud

08:25.980 --> 08:31.900
AutoML in 2018 and like before that, they had this New York Times, you know, they had this PR win,

08:31.900 --> 08:35.980
it was like a New York Times article talking about how, you know, AI was going to create itself.

08:36.540 --> 08:44.140
And I think that contributed a lot to, for lack of a better term in this space. But then we see it,

08:44.140 --> 08:50.860
you know, all over the place, there are other approaches more focused on kind of citizen data science.

08:50.860 --> 09:00.380
You know, I'd love to, you know, just start with how you define AutoML and, you know, is, is,

09:01.180 --> 09:05.980
you know, what you're taking on it as a space and, you know, it's role and importance, that kind of thing.

09:06.540 --> 09:12.300
You know, I think I can, I really relate to many of the things you touched on. So maybe I'll start,

09:13.260 --> 09:17.900
and this is true for many things you do in Australia, but definitely for AutoML, on your point around

09:17.900 --> 09:25.660
academic roots. Microsoft has this division called MSR, Microsoft Research, and it's really a set

09:25.660 --> 09:32.140
of researchers who look into bleeding edge topics and drive the world of research in different areas.

09:32.780 --> 09:42.540
And that is when we first got, in our team, introduced to AutoML. So they've been doing research,

09:42.540 --> 09:49.580
a subset of that team has been doing research around the AutoML area for quite a few years.

09:49.580 --> 09:54.060
They've been looking at it. They've been thinking, well, you know, it started. Yes, I've heard the

09:54.060 --> 10:00.780
sentence AI making AI. But, you know, when you start reading into it, like, what does it mean? And,

10:02.300 --> 10:07.500
it means, to be honest, it means a lot of things to many people. It's quite overused. I'll be

10:07.500 --> 10:13.500
quite frank. There's no one standard industry standard definition that says, here's what AutoML is.

10:13.500 --> 10:17.660
I can tell you what it is for us. I can tell you what it is for our customers. I can tell you

10:17.660 --> 10:24.780
where we're seeing it make a ton of impact. And it comes to using machine learning capabilities

10:25.580 --> 10:34.220
in order to help you, being the data scientist, create machine capabilities in a more efficient,

10:34.220 --> 10:42.220
in a more accurate, in a more structured fashion. My reaction to that is that it's super high level.

10:42.220 --> 10:48.460
And it, it kind of leaves the door open for all of, you know, this broad spectrum of definitions

10:48.460 --> 10:56.060
that you just talked about. Like, for example, not to kind of over index on what Google's been doing,

10:56.060 --> 11:03.340
but like Cloud AutoML Vision when it first came out was, you know, a way for folks to do a

11:03.340 --> 11:11.820
vision cognitive services, but use some of their own data to tune it, right? Which is a lot different.

11:11.820 --> 11:18.620
In fact, they, they caught a lot of flack from the, the academic AutoML community because

11:19.180 --> 11:25.980
they totally redefined what that community had been working for, you know, for many years. And,

11:27.180 --> 11:32.140
you know, started kind of creating the, the confusion. How do we, maybe the first question is,

11:32.140 --> 11:39.500
do you see it as kind of, you know, being the kind of a broad spectrum of things? Or is it,

11:40.700 --> 11:47.020
you know, how do we even get to a definition that kind of separates the personalized, you know,

11:47.020 --> 11:52.860
cognitive services trained with my own data versus, you know, this other set of things?

11:53.900 --> 11:55.100
I don't know if that's a question.

11:55.100 --> 12:00.540
No, no, no, I think as you see it as more of that general sense. So, yeah, I would say,

12:02.060 --> 12:09.420
probably not. I see it as a much more concrete set of capabilities that adhere to a well-known

12:09.420 --> 12:14.540
process. Okay. That actually is agreed upon across the industry. When you build a model, what do you

12:14.540 --> 12:21.660
do? You get data, you featureize that data. Once the features are in place, you choose a learner,

12:21.660 --> 12:27.820
you choose an algorithm. You train that algorithm with the data, creating a model. At that point,

12:27.820 --> 12:33.580
you want to assess the evaluate the model, make sure it's accurate. And you want to get some

12:33.580 --> 12:39.420
understanding towards what are the underlining features that have most affected the model.

12:39.980 --> 12:45.820
And you want to make sure, in addition to that, that you can explain that model is not biased.

12:45.820 --> 12:52.700
You can explain that model is really fair towards all aspects of what it's looking at. That's a

12:52.700 --> 12:57.100
well-known process. I think there's no argument around that in the sort of the machine learning field,

12:57.100 --> 13:04.460
that's sort of the end to end. AutoML allows automating that process. So, at its purest, you feed

13:04.460 --> 13:11.500
AutoML the data and you get the rest for free, if you may. Okay, that would be sort of where we're

13:11.500 --> 13:17.820
heading, where we want to be. And I think that's at the heart of AutoML. So, where does the confusion

13:17.820 --> 13:27.260
start? I could claim that what we or others do for custom vision follows that path. And it does.

13:27.260 --> 13:32.860
I can also claim that some of what we do for custom vision is automated. And, you know,

13:32.860 --> 13:39.020
then there's a short sort of hop to say, well, therefore it is AutoML. But I think that misses the

13:39.020 --> 13:45.180
general point of what we're trying to do with AutoML. Custom vision is a great example where

13:45.180 --> 13:50.780
AutoML can be leveraged. But AutoML can be leveraged wherever that end-to-end process happens in

13:50.780 --> 13:59.740
machine learning. Nice. I like it. I like it. So, maybe we can kind of walk through that end-to-end

13:59.740 --> 14:08.300
process and talk about some of the key areas where automation is applied to contribute to AutoML.

14:09.580 --> 14:17.100
So, I'd like to start with Featureization. And, you know, at the end of the day, we want an

14:17.100 --> 14:24.220
accurate model. A lot of that accuracy, a lot of the insights we can get, the predictions we can

14:24.220 --> 14:32.220
get, and the output we can get from any model is really hinged on how effective your Featureization

14:32.220 --> 14:38.700
is. So, you know, many times you hear that, well, 80% of the time on data sciences spend on data.

14:39.420 --> 14:43.100
A lot of the time is, can I put it up? Do you know where that number comes from?

14:43.100 --> 14:47.900
Oh, of course. Everyone says it. Everyone repeats it. It's a self-fulfilling prophecy.

14:47.900 --> 14:53.980
You know, I'm going to say 79% of this, just to be sure. But I think it's more of an urban legend

14:53.980 --> 14:59.580
at that point. I don't think there's a, you know, I am seeing customers who do spend that kind of

14:59.580 --> 15:03.900
percentage of time. I am seeing experiments we run that take that amount of time.

15:04.380 --> 15:07.020
Generalizing that number is just, it's too fun not to do.

15:07.020 --> 15:12.300
So, you know, I was wondering if there's, I was thinking about this recently and I'm wondering

15:12.300 --> 15:16.780
if there's some, you know, institute for data science that's been tracking this number over time.

15:16.780 --> 15:20.860
It'd be interesting to see how it changes over time, I think, is the broader curiosity.

15:20.860 --> 15:23.420
If you would, I should go figure that out. I think that's an interesting one.

15:23.420 --> 15:24.860
I've got to be interested in the outside.

15:25.900 --> 15:26.460
So, sorry.

15:28.940 --> 15:35.100
So, but, you know, you can easily and anyone who's built a model can quickly see the effect of

15:35.100 --> 15:44.300
featureization on the output. Now, a lot of what's done when building features can be automated.

15:44.300 --> 15:49.820
I would even venture say that a part of it can be easily automated. But then, naturally,

15:49.820 --> 15:54.620
what are some examples? Some examples are like, I want to take two columns and bring them together

15:54.620 --> 16:00.460
into one. I want to change a date format to better align with the rest of my columns.

16:01.020 --> 16:06.940
You know, not even an easy one. I'd like to enhance my data with some public holiday data

16:06.940 --> 16:11.260
when I do my sales forecasting because that's really going to make it more accurate.

16:11.260 --> 16:16.460
It's more a data enhancement, but you definitely want to build features into your data to do that.

16:16.460 --> 16:24.060
So, getting that right is key. Now, start thinking of data sets that have many rows,

16:25.100 --> 16:30.220
but more importantly, have many columns. Okay, and then the problem gets harder and harder.

16:30.220 --> 16:34.700
You want to try a lot more options. There's a lot more ways of featureizing the data.

16:34.700 --> 16:42.060
Some are more effective than others. Like, you know, we recently in AutoML have incorporated

16:42.700 --> 16:50.140
the birth model into our auto-futurization capability. Now, that allows us to take text data

16:50.140 --> 16:56.220
used for classification and quickly featureize it. It helps us featureize it in a way that

16:56.220 --> 17:01.740
requires less input data to come in for the model to be accurate. I think that's a great example

17:01.740 --> 17:10.380
of how deep and how far that can go. You mentioned that getting that featureization right is key.

17:11.260 --> 17:18.140
To what extent is it an algorithmic methodological challenge versus a computational challenge?

17:18.140 --> 17:25.580
If you can even separate these two, meaning, you know, there's this trade-off between like,

17:25.580 --> 17:32.540
you know, we've got kind of this catalog of, you know, recipes, you know, like combining columns

17:32.540 --> 17:37.820
and, you know, binning things and whatever that we can just throw at a data set that looks like it

17:37.820 --> 17:46.380
might fit, you know, versus more intelligent or selective application of techniques based on,

17:46.380 --> 17:52.220
you know, nuances, you know, whether predefined or learned about the data.

17:52.220 --> 17:59.180
Yeah. So it extends on a few dimensions. Okay. I would say there are techniques. Some require more

17:59.180 --> 18:04.860
compute than others. Some are easier to get done. Some require sort of a deeper integration with

18:04.860 --> 18:10.300
existing miles. Like I mentioned, the bird before to be effective. But that's only one dimension.

18:10.300 --> 18:16.700
The other dimension is the fit of the data into a specific learner. So, you know, we don't call it

18:16.700 --> 18:22.060
experiments and machine learning for nothing. You experiment. Right. You try. Okay. Nobody really

18:22.060 --> 18:27.100
knows exactly which features would affect the model in a proper way would drive accuracy.

18:27.100 --> 18:33.660
So there's a lot of iteration and experimentation being done. Now think of this place where you have

18:33.660 --> 18:38.460
a lot of data, creating a lot of features and you want to try multiple learners, multiple algorithms

18:38.460 --> 18:44.460
if you may. And that becomes quickly quite a mundane process that automating can really,

18:44.460 --> 18:52.060
really help with. And then at the top of that, we're seeing more and more models creating created with

18:52.060 --> 18:59.500
just more and more features. The more features you have, the more nuance you can get about describing

18:59.500 --> 19:04.780
your data, the more nuance the model can get about predicting what's going to happen next. So we're

19:04.780 --> 19:10.140
not seeing models with millions and billions of features coming out. Now, auto mail is not yet

19:10.140 --> 19:15.900
to prepare the prepared to deal with the billion feature model, but we see that dimension extent.

19:15.900 --> 19:23.740
So extend compute one, extend the number of iterations you would have, extend to the number of features

19:23.740 --> 19:30.220
you have. Now you got a problem that's quickly going to be referred to as mundane, hard to do.

19:30.220 --> 19:36.300
Repetitive doesn't really require a lot of imagination. Automation just sounds perfect for that.

19:36.300 --> 19:41.980
So that's why sort of one of the things we went after in the past, I'd say six to twelve

19:41.980 --> 19:46.860
months is how we get featureization to a place where you do a lot of auto featureization.

19:46.860 --> 19:53.100
I'm trying to parse whether the extent to which you got to, you know, whether you agree with this

19:53.100 --> 19:57.980
kind of dichotomy that I presented. Like there's, you've got this, you know, this mundane problem that

19:57.980 --> 20:06.460
if, you know, a human data scientist was doing it would be, you know, just, you know, extremely iterative.

20:06.460 --> 20:13.660
There's certainly one way of automating is just, you know, do that iteration a lot quicker

20:13.660 --> 20:24.780
because a machine can do that. Another way of automating is apply, you know, let's call it, you know,

20:24.780 --> 20:29.980
more intelligent approaches to navigating that feature space or that, you know, iteration space.

20:31.260 --> 20:37.740
And identifying, you know, through algorithmic techniques, you know, what are likely to be the,

20:37.740 --> 20:42.300
the right combinations of features as opposed to just kind of throwing the kitchen sink at it and,

20:42.300 --> 20:47.100
you know, putting that in a bunch of loops. And certainly that's, you know, that's not a dichotomy,

20:47.100 --> 20:53.500
right? You do a bit of both. Can you elaborate on that kind of trade off or the relationship

20:53.500 --> 20:57.020
between those two approaches? Is that even a right way to think about it? Or is that the wrong

20:57.020 --> 21:01.580
way to think about it? I think it's a definitely a way to think about it. Like if you think about it,

21:01.580 --> 21:08.860
it's a, no, I'm just thinking through that lens for a second. So I think you describe sort of the

21:08.860 --> 21:13.820
brute force approach. Yeah. Yeah. On one side. Right. The other side is how nuanced can you get

21:13.820 --> 21:19.740
about it? Yeah. So what we know is you can get quite nuanced. Those things that are known to work,

21:19.740 --> 21:25.500
things that are not known to work, things that work with a certain type of data set that don't work

21:25.500 --> 21:30.300
with another. Right. Things that work with a certain type of data set combined with the learner

21:31.020 --> 21:37.420
that don't work with others. So as we build AutoML, I talked about machine learning used to

21:37.420 --> 21:42.380
help with machine learning. We train a model to say, okay, in this kind of event, you might want to

21:42.380 --> 21:47.260
try this kind of combination first, because if you're, I talked about the number of features,

21:47.260 --> 21:51.980
brute force is not an option. So we got to get a lot more nuanced about it. So what AutoML does

21:51.980 --> 21:59.100
is given those conditions, if you may, or those features for that model, it helps sort of the,

21:59.100 --> 22:05.740
it helps shape the right set of experiments before others. That's allowing you to get a more

22:05.740 --> 22:11.980
accurate model faster. So I think that's one aspect of it. I think another aspect which you may

22:11.980 --> 22:17.420
have touched on. And I think it's really important throughout AutoML. But definitely in featureization is

22:19.340 --> 22:25.020
while people are excited about that, the next thing you're going to hear is, but I want to see what

22:25.020 --> 22:34.460
you did. And you got to show what kind of features you used. Yeah. And quickly follows is, I want to

22:34.460 --> 22:41.180
change feature 950 out of the thousand features you gave me. And I want to add two more features at

22:41.180 --> 22:45.740
the end, because I think they're important. That's where my innovation as a data scientist comes

22:45.740 --> 22:53.900
into play. So you got to, and AutoML allows you to do that, be able to open up that aspect and say,

22:53.900 --> 22:58.140
here's what I've come up with. Would you like to customize? Would you like to add? Would you like

22:58.140 --> 23:03.820
to remove? Because that's where you as a data scientist shine and are able to innovate.

23:03.820 --> 23:11.500
So we started with featureization. Next step is learner slash model selection. I think it's

23:11.500 --> 23:16.860
probably the best next step to talk about. Okay. I think there's a lot of configuration that goes

23:16.860 --> 23:21.980
into this. Like how many iterations do I want to do? Yeah. For instance, how accurate do I want to

23:21.980 --> 23:28.780
get? What defines accuracy? But those are more sort of manual parameters. We ask the user to add

23:28.780 --> 23:36.300
to it. But when automation again comes into play is learner selection. So what happens? You know,

23:36.300 --> 23:41.340
putting AutoML aside, what's going to happen? Build a set of feature, choose a learner. One that I

23:41.340 --> 23:48.060
happen to know is really good for this kind of a problem and try it out. See how accurate I get.

23:48.060 --> 23:52.620
If it doesn't work, but even if it works, you're going to try another. Try another few, try a few

23:52.620 --> 23:58.380
options. AutoML at the heart of it is what it does. Now going back to what we talked about in

23:58.380 --> 24:03.740
featureization, we don't take a brute force approach. We have a model that's been trained over

24:03.740 --> 24:09.180
millions of experiments, sort of knows what would be a good first choice. Given the data,

24:09.180 --> 24:15.020
given the type of features, given the type of outcome you want, what do we try first? Because

24:15.020 --> 24:22.220
people can't just run an endless number of iterations. It takes time, takes cost, and sort of takes

24:22.220 --> 24:29.580
the, frankly, takes a lot of the ROI out of some statistics from AutoML. So you want to get there

24:29.580 --> 24:35.340
as fast as possible based on learnings from the past. So what we've automated is that selection.

24:35.340 --> 24:39.420
Put in the data, set the number of iterations or not set them. We have a default number that

24:39.420 --> 24:44.540
goes in and then start using the learners based on the environment you're seeing out there

24:44.540 --> 24:50.060
and choosing them out of that from that other model we've trained over time. By the way,

24:50.060 --> 24:57.260
that's a place where we really leaned on the outputs and the outputs we got from MSR.

24:57.260 --> 25:02.620
That's a place where they, as they were defining AutoML, as they were researching it,

25:02.620 --> 25:08.300
really went deep into and really sort of created assets were then able to leverage a product

25:08.300 --> 25:13.100
sort of evolves over time and technology evolves over time. But if I have to pick the most

25:13.100 --> 25:19.100
or the deepest rooted area we've looked at from MSR, it's definitely the ability to choose

25:19.100 --> 25:24.380
the right learner for the right job with a minimal amount of compute associated with it if you

25:24.380 --> 25:32.700
may. And what are some of the core contributions of that research if you kind of go to the layer

25:32.700 --> 25:38.780
deeper than that? Are you asking the context of choosing a model or in general?

25:38.780 --> 25:43.500
Yeah, in the context of choosing a model. Like, for example, as you described this,

25:43.500 --> 25:51.580
what is essentially a learner that's learning which model to use that created a bunch of

25:51.580 --> 25:58.220
questions from me around like, okay, how do you represent this whole? What are the features of

25:58.220 --> 26:05.820
that model and what is the structure of that model? I'm curious if that's something that came out

26:05.820 --> 26:12.860
of MSR or that was more the, you know, came from the productization and then, you know, if there are

26:12.860 --> 26:19.100
specific things that came out of that MSR research that come to mind as being, you know, pivotal to the

26:19.100 --> 26:30.860
way you think about that process. So the first version coming out of MSR wasn't really of the

26:30.860 --> 26:39.020
end to end product, but at the heart of it was the model that helps you pick learners as it relates

26:39.020 --> 26:45.180
to the type size of data you have and the type of target you have. This is where a lot of the research

26:45.180 --> 26:51.420
went into. This is where we publish papers around where which features matter when you choose that.

26:52.060 --> 26:57.340
This is where MSR went and collected a lot of historical data around people running experiments

26:57.340 --> 27:04.540
and trained that model. So the basis at the heart of our earliest versions, we really leaned on MSR

27:04.540 --> 27:10.140
to get that model in place. You know, within the workflow to where the auto-futurization I talked

27:10.140 --> 27:14.860
about some other aspects we'll talk about in a minute, but at the heart of it, they did all that

27:14.860 --> 27:19.740
research to understand, well, first trained that model, just, you know, grabbing the data,

27:19.740 --> 27:27.260
getting it right out of experiments. Is that model? Is it, you know, a single model? Is it relatively simple?

27:27.260 --> 27:33.900
Is it fairly complex? Is it some kind of ensemble? Like, oversimplify a little bit, but remember,

27:34.620 --> 27:40.620
it profiles your data. So it takes a profile of your data. It profiles your features. It takes a

27:40.620 --> 27:46.140
profile of your features. It looks at the kind of outcome you want to achieve. Am I doing time

27:46.140 --> 27:50.060
series forecasting here? I'm doing classification. I'm doing regression. That really matters.

27:50.620 --> 27:59.100
And then based on those features, picks the first learner to go after. Then what it does is

27:59.100 --> 28:05.340
uses the result of that first iteration, which included all the features I'm talking about,

28:05.340 --> 28:12.780
but also now includes, hey, I also tried learner X. And I got this result. And that helps it

28:12.780 --> 28:21.180
choose the next one. So what happens is you look at the base data you have, but you constantly

28:21.180 --> 28:27.420
have additional features that show you, well, what have I tried and what were the results? And then

28:27.420 --> 28:32.700
the next learner gets picked based on that. And that gets you in a place where the more you iterate,

28:32.700 --> 28:38.460
the closer you get to that learner that gives you a more accurate, accurate result.

28:38.460 --> 28:45.580
So then is it kind of at its core? Is it a, you know, it's, I'm hearing elements of both,

28:45.580 --> 28:50.700
you know, supervised learning. You have a bunch of experiments and, you know, the models that

28:50.700 --> 28:57.260
were chosen, ultimately, you know, but also elements of something, you know, more like, you know,

28:57.260 --> 29:02.460
simple reinforcement learning, contextual bandics, explore, exploit kind of things as well.

29:02.460 --> 29:09.020
It definitely does both. I would, if I could just sort of touch on one point, reinforcement

29:09.020 --> 29:14.700
learning as it's defined, I wouldn't say we're doing reinforcement learning there. Saying that,

29:14.700 --> 29:20.060
we're definitely sort of every time we have an iteration going or, you know, every X times we have

29:20.060 --> 29:26.060
that, we do fine tune the training of the model to learn as it runs more and more. So I think

29:26.060 --> 29:33.980
reinforcement learning is a lot more sort of a mem reactive. But taking that as an analogy,

29:33.980 --> 29:39.020
we do sort of continuously collect more training data and then retrain the model that helps us choose

29:39.020 --> 29:44.700
better and better over time. Interesting, interesting. So we've talked about a couple of these aspects of

29:44.700 --> 29:51.740
the process, feature engineering model selection. You know, one of the next is once you've identified

29:51.740 --> 29:59.260
the model like tuning hyper parameters and optimization, do you consider that its own step or is that

29:59.260 --> 30:05.020
kind of, you know, a thing that you're doing all along or both? I consider it part of that Uber

30:05.020 --> 30:11.500
process I talked about earlier. You know, we're just delving into starting to use deep learning

30:12.620 --> 30:20.220
learners within AutoML. So that's where we're also going to automate the parameter selection,

30:20.220 --> 30:25.100
hyper parameter selection. A lot of the learners we have today are classic machine learning if you

30:25.100 --> 30:32.940
may. So that's where hyper parameter tuning is not as applicable. But seeing that every time

30:33.500 --> 30:38.300
we see an opportunity like that, I think I mentioned earlier in our forecasting capabilities,

30:38.300 --> 30:43.580
we're now adding them deep learning models. In order to make the forecasting more accurate,

30:43.580 --> 30:47.340
that's where that tuning will also be automated. Then if you think about actually a library,

30:47.340 --> 30:57.020
I think we chatted about that pre-interview. But you mentioned that you're doing some stuff with

30:57.020 --> 31:03.020
TCN and Arima around time series forecasting. Can you elaborate on that? Yeah, so I talked about this

31:03.900 --> 31:12.060
process of choosing a learner. Now, you also have to consider what is your possible set of learners

31:12.060 --> 31:20.700
you can choose from. And what we've added recently are sort of deep learning models or networks that

31:20.700 --> 31:27.740
actually are used within that process. So TCN and Arima are quite useful when doing time series

31:27.740 --> 31:33.500
forecasting really drive the accuracy based on the data you have. So we've now embedded those

31:33.500 --> 31:39.580
capabilities within our forecasting capability. So then when you say within forecasting meaning

31:39.580 --> 31:48.700
a forecasting service that you're offering as opposed to within. Let me clarify. Yeah, there's

31:48.700 --> 31:58.540
three core use cases. We support us part of AutoML. One for classification. The other for regression.

31:59.420 --> 32:05.100
And the third for time series forecasting. So when I refer to that, I was referring more to that

32:05.100 --> 32:11.980
use case within AutoML. Got it. Got it. So in other words, in the context of that forecasting

32:11.980 --> 32:22.140
use case as opposed to building a system that is general and applying it to time series and using

32:22.140 --> 32:29.100
you know more generalized models you're using now TCN and Arima as kind of quarter that which are

32:29.100 --> 32:35.100
you know long proven models for time series forecast. Yeah, I would argue there also be generalized

32:35.100 --> 32:40.700
but in the context of forecast. So but but let me tell you how we're thinking about it. There's

32:40.700 --> 32:45.820
generally applicable models. Yeah. Now we'll see in different use cases like in forecasting,

32:45.820 --> 32:51.020
there are generally applicable models for that area that are really useful in that area. That's

32:51.020 --> 32:56.220
sort of the current state we're in right now. And we want to add a lot more sort of known

32:56.220 --> 33:02.780
and generally applicable models to each area. In addition to that sort of where we're heading and

33:02.780 --> 33:08.140
as I see this moving forward, more and more customers will want to add their own custom model.

33:08.140 --> 33:14.380
Right. We've done forecasting for our manufacturing. We've tuned it to a place where it's just

33:14.380 --> 33:18.860
amazing for what we do because we know a lot more about our business than anyone else.

33:19.580 --> 33:23.980
We'd like to put that in the mix every time your AutoML considers the best option.

33:23.980 --> 33:29.980
So I think we're going to see I'm already seeing a lot of that sort of they bring your own model

33:30.540 --> 33:34.780
which makes sense. Yeah, it's an interesting extension to kind of bring your own data which was

33:34.780 --> 33:39.580
the you know one of the first frontiers here. No, I think it's very like I mean you're coming in

33:40.140 --> 33:44.300
to a world now it's not the hey there's no data science here. There's a lot of data science going

33:44.300 --> 33:50.140
on. So I'm the data scientist. I've worked on this model for the past you name it weeks, months,

33:50.140 --> 33:57.020
years and now this AutoML thing is really going to help me be better. I don't think that's a claim

33:57.020 --> 34:02.540
we even want to make. I don't think that's a claim that fair to make. The whole idea is find

34:02.540 --> 34:07.660
the user where they are. You have a custom model. Sure, let's plug that in. It's going to be

34:07.660 --> 34:14.220
considered with the rest in a fair and visible way. Maybe with the auto-futurization it even

34:14.220 --> 34:19.740
goes and becomes more accurate. Maybe you'll find out something else you want to do in your model.

34:19.740 --> 34:23.180
Maybe you have five of those models and you're not sure which one is best. You plug in all five.

34:23.900 --> 34:28.300
I think that's very much sort of where we're heading. Plugging into an existing process that's

34:28.300 --> 34:35.100
already deep and rich wherever we land. The three areas that we've talked about again,

34:35.100 --> 34:42.060
featureization model selection and parameter or optimization are I think kind of what we

34:42.060 --> 34:52.540
tend to think of as the core of AutoML. Do you also see it playing in the tail end of that

34:52.540 --> 34:59.020
process like the deployment after the models deployed? There are certainly opportunities to

34:59.580 --> 35:07.660
automate there. A lot of that is very much related to DevOps and that kind of thing. Are there

35:07.660 --> 35:17.580
elements of that that are more like what we're talking about here? I think there's two steps before

35:17.580 --> 35:25.180
that. I think there's the evaluation of the model. How accurate is it? But again, you get into

35:25.180 --> 35:30.700
this world of iterations. That's where automation is really helpful. That's one. The other

35:30.700 --> 35:37.180
is the interpretation of the model. That's where automation really helps as well. Now especially when

35:37.180 --> 35:41.980
I did a bunch of automation, I now want to make sure what which features really did affect this

35:41.980 --> 35:49.420
thing. Explain them to me and work that into your automated processes. Did your process provide a

35:49.420 --> 35:57.820
fair set of data for my model to learn from? Does it represent all, all genders probably?

35:57.820 --> 36:02.940
Does all races probably? Does it represent all aspects of my problem? You choose them in a fair

36:02.940 --> 36:11.820
way. Where do you see imbalance? I think automating those pieces are right before we jump into

36:11.820 --> 36:18.140
deployment. I think it's really mandatory when you do AutoML to give that full picture. Otherwise,

36:18.140 --> 36:25.740
you're creating the right set of tools, but I don't feel or I feel without doing that, you're

36:25.740 --> 36:30.460
falling a bit short of providing everyone the right checks and balances to look at the work they're

36:30.460 --> 36:36.780
doing. When I generalize the AutoML process, I definitely include that. Back to your question,

36:36.780 --> 36:44.940
does deployment... Do I see deployment playing there? You know what? To be honest, I'm not sure.

36:44.940 --> 36:52.540
So I think we're definitely the way we evaluate success is we look at the models deployed

36:52.540 --> 36:59.500
with AutoML or via AutoML or that were created via AutoML or not deployed. We looked at their

36:59.500 --> 37:06.700
inferences. We look at their scoring and we provide that view to the customer to assess

37:06.700 --> 37:12.700
the real value of their model. Automation there, I think. You know, if I have to guess,

37:12.700 --> 37:19.500
yes. Automation will stretch there. Do I see it today? Can I call it out today? Not just yet.

37:19.500 --> 37:26.860
Well, I mean, a lot of conversation around this idea of deploying a model out into production

37:26.860 --> 37:37.420
and we've thankfully, I think, convinced people that it's not just like deploy once and you're

37:37.420 --> 37:42.220
not thinking about it anymore. You have to monitor the performance of that model and there's

37:42.220 --> 37:47.740
a limited lifespan for most of the models that we're putting in production. And then kind of the

37:47.740 --> 37:53.180
next thing that folks get excited about as well, I can just see when my model falls out of tolerance

37:53.180 --> 37:58.060
and then like auto retrain. It's one of these. Everyone's talking about it, you know,

37:58.060 --> 38:04.460
few are actually doing it. It sounds like you're kind of in agreement with that. Like we're kind

38:04.460 --> 38:12.300
of not there yet at scale or no. So I think, you know, we often refer to that world as the world

38:12.300 --> 38:22.060
of ML ops, machine learning operations in a more snappy way. I think there is a lot of automation

38:22.060 --> 38:28.780
there. If you look at automation, you do it DevOps for just code. I mean, forget machine learning

38:28.780 --> 38:34.860
code, but code let alone models is very much automation we need. Right. I do think there are like

38:35.820 --> 38:42.940
two separate loops that have clear interface points, like deployed models, like maybe

38:43.660 --> 38:50.220
data about data drift, but they sort of move in different cycles at different speeds. So I'm

38:50.220 --> 38:58.700
maybe, you know, we're learning more about this, but I suspect that iteration of training,

38:58.700 --> 39:03.500
improving accuracy, getting to a model where the data science team says, oh, this one's great,

39:03.500 --> 39:08.380
let's use that. I suspect that's one cycle. And frankly, that's where we've been

39:08.380 --> 39:13.980
hyper focused on automating with auto ML. There's naturally another cycle of that operations that

39:13.980 --> 39:19.020
we're sort of looking at the automation opportunities with ML ops. Do they combine into one automation

39:19.020 --> 39:30.620
cycle? I'm not sure. It does strike me that like when, you know, for example, the decision,

39:30.620 --> 39:37.900
you know, do I kind of retrain from scratch? Do I incrementally retrain? Do I start all the way

39:37.900 --> 39:47.100
over? Maybe that decision could be driven by, you know, some patterns or characteristics in the

39:47.100 --> 39:53.260
nature of the drift and the performance shift that, you know, a model could be applied to. And then

39:53.260 --> 39:57.820
we start to, you know, there are aspects of, you know, what we're thinking about and talking about

39:57.820 --> 40:05.340
as auto ML that are applied to that like DevOps-y part. Who knows? I'd say who knows? And I think, you know,

40:05.340 --> 40:11.580
listening to you, you know, I'm taking note to myself that while we sort of have a bit of a fixed

40:11.580 --> 40:17.020
mindset on the definition, we definitely need to break through some of that and open up and see

40:17.020 --> 40:23.820
well, what is it that we're hearing from the real world that should shape what we automate, how

40:23.820 --> 40:29.980
we automate under which umbrella we put it? I think, and you will notice this moving so fast

40:29.980 --> 40:35.580
and evolving so fast. I think we're just at the, you know, first step of it. Yeah. Yeah. Yeah.

40:36.940 --> 40:44.540
A couple of quick points that I wanted to ask about. Another couple of areas that are generating

40:44.540 --> 40:51.180
excitement under this umbrella are neural architecture search and neural evolution and kind of

40:51.180 --> 40:56.700
techniques like that. Are you doing anything in those domains? Again, we're incorporating some of

40:56.700 --> 41:04.380
those neural architectures into auto ML today. I talked about our deeper roots with MSR and sort of

41:04.380 --> 41:11.420
how they got us that first model. Our MSR team is very much looking deeper into those areas. They're

41:11.420 --> 41:19.580
not things that have formulated just yet, but the feeling is that sort of the same concepts we put

41:19.580 --> 41:27.340
into auto ML or automated machine learning can be used there, can be automated there. I'm being a

41:27.340 --> 41:33.420
little vague because it is a little vague for us, but the feeling is that there is something there.

41:33.420 --> 41:38.220
And, you know, we're lucky enough to have the MSR arm that when there's a feeling there's something

41:38.220 --> 41:43.180
there. Some research starts to pan out and the thinking of different ideas there. But

41:44.540 --> 41:49.100
to be frank, I don't have much to share at that point in terms of more specifics. Yeah. Yeah.

41:49.100 --> 41:57.100
And I guess as, you know, we've been focused on this auto ML is a kind of set of platform

41:57.100 --> 42:03.260
capabilities that helps data scientists be more productive. There's a whole other aspect of,

42:03.260 --> 42:09.100
you know, Microsoft delivering cognitive services for vision and, you know, other things

42:10.140 --> 42:16.860
where they're using auto ML internally and where kind of, you know, it's primarily deep learning

42:16.860 --> 42:22.300
based and I can only imagine that they're throwing things like architecture search and things

42:22.300 --> 42:29.020
like that at the problem. Yeah. Yeah. So they do happen in many cases. I think custom vision is

42:29.020 --> 42:35.180
a good example. We don't see the general patterns just yet. And for the ones we do see sort of the

42:35.180 --> 42:41.500
means of automation haven't been put out that yet. So I think it's like if I look at where we were

42:41.500 --> 42:47.420
with the auto ML thinking probably a few years back is where that is right now, meaning oh,

42:47.420 --> 42:53.100
it's interesting. We know there's something there. The question is how we sort of further evolve

42:53.100 --> 42:58.940
into something more specific. Well, Ed is thanks so much for taking the time to chat with us about

42:58.940 --> 43:04.380
what you're up to. Great conversation and learned a ton. Thank you. Same here. Thanks for your time

43:04.380 --> 43:11.900
and the questions were great. That a great time. All right, everyone. That's our show for today

43:11.900 --> 43:19.340
to learn more about this episode. Visit Twomla.com. As always, thanks so much for listening and catch you

43:19.340 --> 43:29.740
next time.

