1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:33,480
I'm your host, Sam Charrington, you may have seen the news yesterday that MIT researcher

4
00:00:33,480 --> 00:00:37,280
Katie Bowman produced the first image of a black hole.

5
00:00:37,280 --> 00:00:41,240
What's been less reported is that the algorithm she developed to accomplish this is based

6
00:00:41,240 --> 00:00:43,400
on machine learning.

7
00:00:43,400 --> 00:00:47,840
Machine learning is having a huge impact in the fields of astronomy and astrophysics,

8
00:00:47,840 --> 00:00:52,080
and I'm excited to bring you interviews with some of the people innovating in this area.

9
00:00:52,080 --> 00:00:56,840
Today we're joined by Yasha Haseve, assistant professor at the University of Montreal,

10
00:00:56,840 --> 00:01:02,480
and research fellow at the Center for Computational Astrophysics at Flatiron Institute.

11
00:01:02,480 --> 00:01:06,800
Yasha and I caught up to discuss his work on gravitational lensing, which is the bending

12
00:01:06,800 --> 00:01:10,760
of light from distant sources due to the effects of gravity.

13
00:01:10,760 --> 00:01:14,840
In our conversation, Yasha and I discussed how machine learning can be applied to undistort

14
00:01:14,840 --> 00:01:19,800
images, including some of the various techniques used, and how the data is prepared to get the

15
00:01:19,800 --> 00:01:21,440
best results.

16
00:01:21,440 --> 00:01:25,400
We also discussed the intertwined roles of simulation and machine learning in generating

17
00:01:25,400 --> 00:01:31,360
images, incorporating other techniques such as domain transfer or GANS, and how he assesses

18
00:01:31,360 --> 00:01:33,600
the results of this project.

19
00:01:33,600 --> 00:01:38,160
For more of our astronomy and astrophysics coverage, be sure to check out the following

20
00:01:38,160 --> 00:01:39,160
interviews.

21
00:01:39,160 --> 00:02:09,080
I'd like to thank everyone who entered our AI conference and TensorFlow Edge device

22
00:02:09,080 --> 00:02:10,080
giveaways.

23
00:02:10,080 --> 00:02:16,080
Today, I'm excited to announce the winner of our AI conference giveaway, Mark T. from Indiana.

24
00:02:16,080 --> 00:02:19,680
Mark, I'm looking forward to seeing you in New York next week.

25
00:02:19,680 --> 00:02:23,200
Today's show is sponsored by our friends at Pegasystems.

26
00:02:23,200 --> 00:02:27,720
Pegaworld, the company's annual digital transformation conference, will be held at the

27
00:02:27,720 --> 00:02:31,840
MGM Grand in Las Vegas from June 2nd through 5th.

28
00:02:31,840 --> 00:02:36,920
I'll be attending the event as I did last year, and I'm looking forward to presenting again.

29
00:02:36,920 --> 00:02:41,160
In addition to hearing from me, the event is a great opportunity to learn how AI is being

30
00:02:41,160 --> 00:02:46,280
applied to the customer experience and real Pegasystems customers.

31
00:02:46,280 --> 00:02:52,360
As a Twomo listener, you can use the promo code Twomo19 at pegaworld.com for $200 off

32
00:02:52,360 --> 00:02:53,680
of your registration.

33
00:02:53,680 --> 00:02:56,200
Again, that code is Twomo19.

34
00:02:56,200 --> 00:02:57,640
Hope to see you there.

35
00:02:57,640 --> 00:02:58,640
Enjoy.

36
00:02:58,640 --> 00:03:07,400
All right, everyone, I am on the line with Yashar Heiseve. Yashar is an assistant professor

37
00:03:07,400 --> 00:03:13,280
at the University of Montreal and a research fellow at the Center for Computational Astrophysics

38
00:03:13,280 --> 00:03:15,040
at Flatiron Institute.

39
00:03:15,040 --> 00:03:18,760
Yashar, welcome to this week in Machine Learning and AI.

40
00:03:18,760 --> 00:03:19,760
Thanks, Ben.

41
00:03:19,760 --> 00:03:21,840
Thank you very much for inviting me.

42
00:03:21,840 --> 00:03:25,760
Let's start by talking a little bit about your background.

43
00:03:25,760 --> 00:03:31,800
We recently joined University of Montreal as an assistant professor, but tell us a little

44
00:03:31,800 --> 00:03:35,280
bit about the arc of your studies and research.

45
00:03:35,280 --> 00:03:42,040
Yeah, so I'm an astrophysicist, and for most of my research career, I've been primarily

46
00:03:42,040 --> 00:03:44,320
doing research in astrophysics.

47
00:03:44,320 --> 00:03:49,320
I did my undergrad in Physics and Astrophysics at the University of Victoria in Canada,

48
00:03:49,320 --> 00:03:53,280
and my PhD at Meal University in Montreal.

49
00:03:53,280 --> 00:03:59,680
I got my PhD in 2013, and I moved to Stanford as a hubbell fellow until recently.

50
00:03:59,680 --> 00:04:02,880
I just moved from Stanford about three months ago.

51
00:04:02,880 --> 00:04:10,960
And during this whole period of 10 years as a graduate student and a researcher, I've

52
00:04:10,960 --> 00:04:19,400
been working on specifically astrophysical data analysis, and in the past couple of years,

53
00:04:19,400 --> 00:04:24,520
with all the buzz about machine learning, I've kind of started to look into the application

54
00:04:24,520 --> 00:04:28,000
of machine learning methods to astrophysical data analysis.

55
00:04:28,000 --> 00:04:35,840
And so now a good fraction of my research has kind of focused on developing new machine

56
00:04:35,840 --> 00:04:42,680
learning methods for the analysis of astrophysical data, so like telescope data.

57
00:04:42,680 --> 00:04:49,160
And your particular research area is focused on strong gravitational lensing.

58
00:04:49,160 --> 00:04:50,640
That's that.

59
00:04:50,640 --> 00:04:59,080
Strong lensing is the distortion in the images of distant objects, done by the gravity

60
00:04:59,080 --> 00:05:02,320
of intervening object structures.

61
00:05:02,320 --> 00:05:05,920
So just think about it that gravity actually bends light.

62
00:05:05,920 --> 00:05:11,240
So here on the earth, we don't notice it because it's such a tiny effect that you don't

63
00:05:11,240 --> 00:05:12,240
notice it.

64
00:05:12,240 --> 00:05:17,680
But in reality, if you had a flashlight, the light rays instead of going straight, they

65
00:05:17,680 --> 00:05:20,600
would actually blend a little bit because of the gravity of the earth.

66
00:05:20,600 --> 00:05:25,280
It's the same reason that black holes are black because they absorb all this light because

67
00:05:25,280 --> 00:05:28,280
the light falls into the black hole.

68
00:05:28,280 --> 00:05:34,520
So at cosmological distances, you can have two galaxies, one sitting far away, say, five

69
00:05:34,520 --> 00:05:36,120
billion lighters from us.

70
00:05:36,120 --> 00:05:40,880
And second galaxy could be like much farther away, say, 12 billion lighters, but right behind

71
00:05:40,880 --> 00:05:42,760
this middle galaxy.

72
00:05:42,760 --> 00:05:43,760
So we have this scenario.

73
00:05:43,760 --> 00:05:44,760
It's us.

74
00:05:44,760 --> 00:05:49,920
We call it the middle galaxy, we call it like the foreground and the background galaxy.

75
00:05:49,920 --> 00:05:54,240
And so the light rays of that background galaxy as they come and they pass near the foreground

76
00:05:54,240 --> 00:05:58,880
galaxy, they get bent, they get deflected because of its gravity.

77
00:05:58,880 --> 00:06:02,640
And so they come to us from these different angles, different directions because of, you

78
00:06:02,640 --> 00:06:04,440
know, the spending of light.

79
00:06:04,440 --> 00:06:08,880
And as a result, what happens here is that here on the earth, we see these distorted images

80
00:06:08,880 --> 00:06:14,080
of that background galaxy that look like rings and arcs around the middle galaxy.

81
00:06:14,080 --> 00:06:17,960
So you can have, you know, instead of like one galaxy, it can be in front of the other

82
00:06:17,960 --> 00:06:22,440
one, you would see one galaxy and around it, you would see these rings and arcs, which

83
00:06:22,440 --> 00:06:25,960
are actually the images of the distant background galaxy.

84
00:06:25,960 --> 00:06:33,960
And so how does the use of machine learning play into your study of these, these lensing

85
00:06:33,960 --> 00:06:35,360
effects?

86
00:06:35,360 --> 00:06:36,680
So there are two things.

87
00:06:36,680 --> 00:06:41,760
So to give you an analogy about this, you know, I like to make an analogy to lensing

88
00:06:41,760 --> 00:06:44,920
of a candle flame with a wine glass.

89
00:06:44,920 --> 00:06:49,040
So think about it, you know, you have a candle sitting on the table and you have a wine

90
00:06:49,040 --> 00:06:50,040
glass.

91
00:06:50,040 --> 00:06:53,280
If you look at the candle flame through the foot of the wine glass, you can see that

92
00:06:53,280 --> 00:06:56,920
the image of the flame kind of wraps around the foot of the wine glass and it makes like

93
00:06:56,920 --> 00:06:59,000
rings around that thing.

94
00:06:59,000 --> 00:07:03,200
So that's why this is called gravitational lensing because it acts, you know, the middle

95
00:07:03,200 --> 00:07:06,360
galaxy likes acts like a lens.

96
00:07:06,360 --> 00:07:11,880
And so this is kind of the thing that we have and we usually have two questions in each

97
00:07:11,880 --> 00:07:14,800
of these observations.

98
00:07:14,800 --> 00:07:19,960
The first thing that we want to figure out is what is the shape of the foot of the wine

99
00:07:19,960 --> 00:07:20,960
glass?

100
00:07:20,960 --> 00:07:24,280
What is the distortion that this caused the image?

101
00:07:24,280 --> 00:07:28,640
And so this relates to, you know, how much matter there is in the middle galaxy.

102
00:07:28,640 --> 00:07:34,560
So we are trying to use these images, distortions to learn about how matter, you know, to map

103
00:07:34,560 --> 00:07:38,280
the distribution of matter in these lensing galaxies.

104
00:07:38,280 --> 00:07:41,880
And then the second question is that, so I see a distorted image of this background source,

105
00:07:41,880 --> 00:07:43,880
but what does it truly look like?

106
00:07:43,880 --> 00:07:49,880
You know, if I'm looking at this arc that is a stretched out image of the candle flame,

107
00:07:49,880 --> 00:07:53,080
I'm interested, you know, what does the candle flame truly look like?

108
00:07:53,080 --> 00:07:55,760
How could I undistort this image?

109
00:07:55,760 --> 00:08:00,280
And so you can see that all of this kind of relates to image analysis and image processing.

110
00:08:00,280 --> 00:08:08,280
So one thing that, you know, works really well for us is, you know, this development

111
00:08:08,280 --> 00:08:15,160
of convolutional neural networks that are specifically tailored to image analysis problems.

112
00:08:15,160 --> 00:08:19,600
And so we've been kind of like, you know, hijacking them and using them for this application

113
00:08:19,600 --> 00:08:21,760
to answer these two questions, you know.

114
00:08:21,760 --> 00:08:27,920
If I get a distorted image of these background things, can I predict what, you know, the

115
00:08:27,920 --> 00:08:32,880
distortion is that's been caused and can I undistort, can I reconstruct the true image

116
00:08:32,880 --> 00:08:36,280
of this background galaxy?

117
00:08:36,280 --> 00:08:41,760
And so what are some of the techniques that you're using to do this?

118
00:08:41,760 --> 00:08:48,680
So traditionally, this is done by something called, I'll just throw the name and I'll explain

119
00:08:48,680 --> 00:08:53,280
what it is, you know, using like maximum likelihood lens model.

120
00:08:53,280 --> 00:08:57,600
So the way that this works is that you say, well, let's think about this.

121
00:08:57,600 --> 00:09:02,720
I have this, you know, candle in the background, I'm putting a lens in front of it.

122
00:09:02,720 --> 00:09:07,440
So I see this distorted image, you know, magnified image of the candle.

123
00:09:07,440 --> 00:09:11,280
And I have an observation, so I see that image.

124
00:09:11,280 --> 00:09:15,760
But I need to know what that candle truly looks like.

125
00:09:15,760 --> 00:09:19,120
Nor do I know what is the distortion that's been added to its image, right?

126
00:09:19,120 --> 00:09:24,560
So, so I, if I see that the data, I cannot predict these two together, but what I can do

127
00:09:24,560 --> 00:09:27,720
is that I can produce a lot of simulations.

128
00:09:27,720 --> 00:09:32,640
So if you gave me an image of a candle and you gave me a lens, it's easy to simulate

129
00:09:32,640 --> 00:09:35,720
it and say, you know, because you can go from one to the other.

130
00:09:35,720 --> 00:09:41,000
So I can get a lens and predict what is the distortion that it causes to space.

131
00:09:41,000 --> 00:09:44,760
And then I can put the image of the candle and it can make a simulation.

132
00:09:44,760 --> 00:09:49,800
So say, you know, it lends the image, it distorted the image of the candle with look like

133
00:09:49,800 --> 00:09:51,600
that.

134
00:09:51,600 --> 00:09:55,000
It's the problem is that, you know, it's difficult to undo this.

135
00:09:55,000 --> 00:09:58,920
So the way to stop traditionally has been that, you know, I would just produce a lot of

136
00:09:58,920 --> 00:10:05,200
different simulations with like, you know, perhaps random candles and random lenses.

137
00:10:05,200 --> 00:10:09,040
And try to find out which one of them really looks like the data.

138
00:10:09,040 --> 00:10:13,280
And so if I find one simulation that really looks like the data, you know, I can kind of

139
00:10:13,280 --> 00:10:17,640
infer that the parameters that I assume for it, you know, the background source that I

140
00:10:17,640 --> 00:10:22,520
assume for it, the foreground lens that I simply should be kind of a correct description

141
00:10:22,520 --> 00:10:26,040
of their, you know, reality.

142
00:10:26,040 --> 00:10:30,480
And so this kind of like falls into this, you know, general umbrella, like, you know,

143
00:10:30,480 --> 00:10:36,440
inverse problems where it's easy to go from the ingredients of the model.

144
00:10:36,440 --> 00:10:41,120
Like if I knew the truth about the truth about the candle and the lens, I can go forward

145
00:10:41,120 --> 00:10:44,320
and make a simulation, but the inverse problem is difficult.

146
00:10:44,320 --> 00:10:49,320
If I, if you gave me the output, then I cannot figure out, you know, what was the initial

147
00:10:49,320 --> 00:10:52,680
ingredients that it was made from.

148
00:10:52,680 --> 00:10:58,880
So with machine learning, what is exciting about it is that we can construct these inverse,

149
00:10:58,880 --> 00:11:00,280
you know, mappings.

150
00:11:00,280 --> 00:11:07,040
So by using a lot of simulated data or true data, I can learn to just kind of like directly

151
00:11:07,040 --> 00:11:11,760
predict what these background sources or the foreground lenses look like, just directly

152
00:11:11,760 --> 00:11:17,080
looking at the data, we don't need to produce in a lot of simulations for every data analysis.

153
00:11:17,080 --> 00:11:24,720
And describing the simulation based approach, there's something kind of intuitively unsatisfying

154
00:11:24,720 --> 00:11:25,720
about that.

155
00:11:25,720 --> 00:11:30,360
The idea that you're going to just randomly generate a bunch of candles and randomly

156
00:11:30,360 --> 00:11:32,120
generate a bunch of lenses.

157
00:11:32,120 --> 00:11:37,000
And if you get something that kind of looks like, or looks very close to the result that

158
00:11:37,000 --> 00:11:43,640
you've got, you assume that it's that specific lens and candle configuration.

159
00:11:43,640 --> 00:11:50,480
Is it that the chance that you get a good match, you know, without the candle and the lens

160
00:11:50,480 --> 00:11:59,480
being exactly right or close so small that gives you comfort in choosing that particular

161
00:11:59,480 --> 00:12:00,480
configuration?

162
00:12:00,480 --> 00:12:04,840
Or I guess this part of me that says, you know, there could be any number of configurations

163
00:12:04,840 --> 00:12:08,600
of candles and lenses that that's a great question.

164
00:12:08,600 --> 00:12:09,600
That's a great question.

165
00:12:09,600 --> 00:12:16,400
So so in a statistical way, what you really do is that you would say, I'm actually going

166
00:12:16,400 --> 00:12:21,560
to find out every candle and every lens that will kind of produce.

167
00:12:21,560 --> 00:12:25,400
So there might as you said, there might be like multiple answers.

168
00:12:25,400 --> 00:12:30,960
And I'm going to find every one of them that will match the data within my uncertainties.

169
00:12:30,960 --> 00:12:36,160
And so it means that you have to have a statistical description of your data to understand what

170
00:12:36,160 --> 00:12:40,920
are your uncertainties, uncertainties could come from, for example, noise.

171
00:12:40,920 --> 00:12:45,400
And you would write a statistical model to say, well, this particular candle and this particular

172
00:12:45,400 --> 00:12:51,320
glass, it fits my data to some, you know, in a probabilistic way.

173
00:12:51,320 --> 00:12:53,160
And this other one could also match it.

174
00:12:53,160 --> 00:12:56,120
And that's one of the things that makes it even more difficult because the problem is

175
00:12:56,120 --> 00:12:58,000
not only even finding a single answer.

176
00:12:58,000 --> 00:13:02,840
The problem is that now you have to kind of explore all the different answers and kind

177
00:13:02,840 --> 00:13:07,040
of give a range of these answers that are consistent with the data.

178
00:13:07,040 --> 00:13:08,440
So it works well.

179
00:13:08,440 --> 00:13:13,560
It's just that computationally, it's very expensive because now it means that you have to try millions

180
00:13:13,560 --> 00:13:19,080
and millions of these simulations to give an answer for one specific data set.

181
00:13:19,080 --> 00:13:27,960
And what are you assuming as known in the way you've formulated the problem here?

182
00:13:27,960 --> 00:13:33,640
Because you kind of know what a candle looks like and you know what a lens kind of looks

183
00:13:33,640 --> 00:13:34,640
like.

184
00:13:34,640 --> 00:13:40,520
What assumptions are you making about the candle and the lens to you then now?

185
00:13:40,520 --> 00:13:42,400
That's a really good question.

186
00:13:42,400 --> 00:13:48,240
So these assumptions typically in the language of statistical analysis, you would call them

187
00:13:48,240 --> 00:13:49,240
priors.

188
00:13:49,240 --> 00:13:52,960
So these are the prior information, the prior knowledge that we have about these things.

189
00:13:52,960 --> 00:13:57,440
And so the way that these priors are specifically encoded in the analysis could be different

190
00:13:57,440 --> 00:14:00,320
from, you know, mildly different.

191
00:14:00,320 --> 00:14:04,280
But you can imagine that, for example, in the case of strong lensing, you want the background

192
00:14:04,280 --> 00:14:07,880
source to be something looking like a galaxy.

193
00:14:07,880 --> 00:14:12,920
So you would impose some sort of like, you know, prior knowledge, you would say, I have

194
00:14:12,920 --> 00:14:15,720
a prior knowledge of the background source, you know, is a galaxy.

195
00:14:15,720 --> 00:14:20,960
So for example, when I make images of this thing, I will, you know, kind of enforce that,

196
00:14:20,960 --> 00:14:27,800
for example, it is, you know, it's blobby or it's concentrated at the center or that, you

197
00:14:27,800 --> 00:14:31,280
know, it's peaks, you know, it's density at this, you know, it's brightness at the center.

198
00:14:31,280 --> 00:14:35,760
But the way that you define it could be tricky.

199
00:14:35,760 --> 00:14:41,080
And specifically when you were doing these, you know, the kind of like forward modern,

200
00:14:41,080 --> 00:14:47,600
you know, lens modeling procedures, it is difficult to actually specify these priors.

201
00:14:47,600 --> 00:14:50,880
One of the cool things about machine learning is that these prior information, you can

202
00:14:50,880 --> 00:14:54,320
actually learn them from data itself.

203
00:14:54,320 --> 00:15:00,080
And that's one of the really like great advantages of a machine learning approach is that if

204
00:15:00,080 --> 00:15:05,200
I had a large data set of these lenses or galaxies in general, if I think that the background

205
00:15:05,200 --> 00:15:10,680
sources a galaxy, I can get millions of images of other galaxies in the universe from, you

206
00:15:10,680 --> 00:15:12,640
know, all sorts of telescopes.

207
00:15:12,640 --> 00:15:16,400
And I can put it through a machine learning procedure and I can actually learn what are

208
00:15:16,400 --> 00:15:20,800
the kind of structural priors that I need to respect.

209
00:15:20,800 --> 00:15:26,000
And then try to kind of like find out what are the solutions within that kind of like,

210
00:15:26,000 --> 00:15:30,280
you know, range of, you know, possibilities that match this particular data set.

211
00:15:30,280 --> 00:15:37,160
And so maybe share a little bit about the data collection and preparation aspect of these

212
00:15:37,160 --> 00:15:42,400
types of problems, assuming the data that you're working with comes from these, you know,

213
00:15:42,400 --> 00:15:49,400
large radio telescopes and you're able to collect that very fairly readily, but you have

214
00:15:49,400 --> 00:15:51,400
to do a lot of processing to it.

215
00:15:51,400 --> 00:15:52,400
Yeah.

216
00:15:52,400 --> 00:15:58,400
So we work both with radio telescopes and and regular optical telescopes like, you know, Hubble

217
00:15:58,400 --> 00:15:59,400
Space Telescope.

218
00:15:59,400 --> 00:16:04,680
So two of the first like machine learning papers that we wrote were basically just using,

219
00:16:04,680 --> 00:16:07,000
you know, Hubble Space Telescope images.

220
00:16:07,000 --> 00:16:12,800
So these images, usually there's like a few steps of pre-processing that you need to

221
00:16:12,800 --> 00:16:13,800
do with it.

222
00:16:13,800 --> 00:16:18,800
The telescope that comes with, you know, from the image that comes from the telescope might

223
00:16:18,800 --> 00:16:22,160
for example have a lot of cosmic rays.

224
00:16:22,160 --> 00:16:29,720
These are just like particles, you know, around the earth that hit the, you know, the cameras

225
00:16:29,720 --> 00:16:34,680
on the telescope and they just leave these traces very high energy particles.

226
00:16:34,680 --> 00:16:37,920
And so, you know, you might need to remove those.

227
00:16:37,920 --> 00:16:44,680
You might need to, for example, subtract the light from the lensing galaxy itself because

228
00:16:44,680 --> 00:16:49,680
remember what we are interested in is a distortion of this background galaxy and how it's been

229
00:16:49,680 --> 00:16:50,680
distorted.

230
00:16:50,680 --> 00:16:55,040
One of the new sense things here is that the middle galaxy that is distorting also has a lot

231
00:16:55,040 --> 00:16:56,040
of stars.

232
00:16:56,040 --> 00:16:58,400
It has a lot of light that's added to this image.

233
00:16:58,400 --> 00:17:03,360
And so a lot of times you would try to kind of subtract this light first and then kind

234
00:17:03,360 --> 00:17:07,360
of like look at the remaining the arcs that come from the backgrounds or so, how do you

235
00:17:07,360 --> 00:17:09,560
do that?

236
00:17:09,560 --> 00:17:12,480
You know, you might take advantage of the fact that the background galaxy and the foreground

237
00:17:12,480 --> 00:17:17,360
galaxy have different colors and so use the color information from these things.

238
00:17:17,360 --> 00:17:23,160
You might need to estimate what is the blurring of the telescopes.

239
00:17:23,160 --> 00:17:25,160
So the images are never perfectly sharp.

240
00:17:25,160 --> 00:17:27,800
There's some amount of blurring that's your resolution.

241
00:17:27,800 --> 00:17:34,760
So if you have a bigger telescope that are camera on it, you're going to get sharper images.

242
00:17:34,760 --> 00:17:38,880
So that's kind of the blurring of the telescope or the point spread function.

243
00:17:38,880 --> 00:17:43,120
So you might want to estimate that for the analysis and all of these things.

244
00:17:43,120 --> 00:17:48,520
So when you're doing for radio data, it's kind of different things.

245
00:17:48,520 --> 00:17:54,120
But typically there's a lot of these like steps and pre-processing steps that you need

246
00:17:54,120 --> 00:18:01,240
to do before you even move on to that final stage where we're actually doing these simulations

247
00:18:01,240 --> 00:18:02,720
and comparing it into the data.

248
00:18:02,720 --> 00:18:07,080
I got the impression earlier that the simulation was kind of the way you used to do it and

249
00:18:07,080 --> 00:18:11,080
now you're using machine learning as an alternative.

250
00:18:11,080 --> 00:18:13,560
Is that, it sounds like that it's not the case.

251
00:18:13,560 --> 00:18:18,240
You're using the simulations and machine learning to get kind of being conjunction with

252
00:18:18,240 --> 00:18:19,760
one another to solve this problem.

253
00:18:19,760 --> 00:18:20,760
Is that right?

254
00:18:20,760 --> 00:18:26,720
Yeah, so their roles have kind of changed.

255
00:18:26,720 --> 00:18:35,440
So in a what I call maximum lens modeling, just lens modeling in a traditional way.

256
00:18:35,440 --> 00:18:40,720
If you gave me a specific data set, one image of a gravitational lens and I wanted to

257
00:18:40,720 --> 00:18:47,360
analyze it, I need to produce millions of simulations and one by one compared them to the data.

258
00:18:47,360 --> 00:18:51,760
And then based on that comparison, I will pick my next simulation to produce.

259
00:18:51,760 --> 00:18:57,920
So there is a systematic way to kind of like go through these simulations and just say,

260
00:18:57,920 --> 00:19:00,640
well this one is not good in this particular way.

261
00:19:00,640 --> 00:19:05,360
So the next simulation that I need to produce will have to be something that looks like

262
00:19:05,360 --> 00:19:09,760
this, it kind of looks like this or whatever, that's kind of the correct direction for

263
00:19:09,760 --> 00:19:11,760
me to go.

264
00:19:11,760 --> 00:19:15,720
So and then once you're done with that procedure, so let's say you got your answer and

265
00:19:15,720 --> 00:19:19,880
you say, well, these are the ranges of answers from background candles and the foreground

266
00:19:19,880 --> 00:19:23,280
lenses that are consistent with the data.

267
00:19:23,280 --> 00:19:27,520
So you move on the next that you come and you have a new example, a new data set from

268
00:19:27,520 --> 00:19:29,920
a new telescope and you want to get the answer.

269
00:19:29,920 --> 00:19:32,440
So you need to go through the whole thing one more time.

270
00:19:32,440 --> 00:19:38,080
So you need to produce like millions of simulations again for this specific system to analyze it.

271
00:19:38,080 --> 00:19:42,640
With machine learning, what we do is that we produce a lot of these simulations in one

272
00:19:42,640 --> 00:19:47,360
go, we train a machine learning model and then we're done forever.

273
00:19:47,360 --> 00:19:51,640
Because this machine learning model, from all these simulations in one go, it learned

274
00:19:51,640 --> 00:19:56,000
how to do that mapping, how to get, how to predict these parameters that we were interested

275
00:19:56,000 --> 00:19:57,960
in from the data set.

276
00:19:57,960 --> 00:20:01,240
And then so I can apply to this data set and then tomorrow I can apply to another data

277
00:20:01,240 --> 00:20:05,000
set and I never ever have to run another simulation again.

278
00:20:05,000 --> 00:20:09,280
So we're using the same sort of simulations to train the machine learning methods, but

279
00:20:09,280 --> 00:20:11,640
we only need to do it once.

280
00:20:11,640 --> 00:20:17,440
Learning to the machine learning models that you're using to predict the lensing, you

281
00:20:17,440 --> 00:20:23,200
know, one of the things that kind of immediately comes to mind when I think of imaging or processing

282
00:20:23,200 --> 00:20:27,160
images is deep learning and convolutional neural nets.

283
00:20:27,160 --> 00:20:29,400
Is that a part of the solution here?

284
00:20:29,400 --> 00:20:30,400
Yeah, yeah.

285
00:20:30,400 --> 00:20:34,160
So we're using a lot of deep learning and convolution neural nets for the analysis of

286
00:20:34,160 --> 00:20:35,160
these data.

287
00:20:35,160 --> 00:20:36,160
That's right.

288
00:20:36,160 --> 00:20:42,720
What we're doing is allowing you to kind of set up standard supervised learning, training

289
00:20:42,720 --> 00:20:46,880
of CNNs or is there, is that the right way to think of what you're doing?

290
00:20:46,880 --> 00:20:47,880
Yeah.

291
00:20:47,880 --> 00:20:48,880
Yeah, yeah.

292
00:20:48,880 --> 00:20:49,880
Absolutely.

293
00:20:49,880 --> 00:20:53,880
So what we're doing is that we're producing training sets where, so I can, I can, for

294
00:20:53,880 --> 00:20:57,720
example, pick, you know, a particular image of a background galaxy.

295
00:20:57,720 --> 00:21:02,800
And I pick, you know, a galaxy that's doing the lensing, the lensing galaxy with certain

296
00:21:02,800 --> 00:21:08,120
parameters, for example, it's electricity or how massive it is or, you know, where it

297
00:21:08,120 --> 00:21:09,880
is in the sky.

298
00:21:09,880 --> 00:21:13,720
And so I know the truth because this is a simulation, it's a control simulation.

299
00:21:13,720 --> 00:21:15,840
So I know what the truth is.

300
00:21:15,840 --> 00:21:17,960
And I will produce an image.

301
00:21:17,960 --> 00:21:22,840
And so then I will put this image as the inputs of my convolutional neural network and

302
00:21:22,840 --> 00:21:27,880
train me to predict the particular outputs that I have because this is, yeah, supervised

303
00:21:27,880 --> 00:21:31,320
training because I know what the truth is for this particular case.

304
00:21:31,320 --> 00:21:35,400
And so this is, you know, one of the approaches that we've done for this is exactly that,

305
00:21:35,400 --> 00:21:42,720
produce training sets from simulated data and train convolutional neural nets in a supervised

306
00:21:42,720 --> 00:21:45,400
way with these things.

307
00:21:45,400 --> 00:21:50,360
And the reason that we use simulations, by the way, one of the things to say is that there

308
00:21:50,360 --> 00:21:53,280
are two reasons why we use simulations.

309
00:21:53,280 --> 00:21:57,600
One is that we could produce really realistic simulations.

310
00:21:57,600 --> 00:22:05,640
So, and so in a really realistic look in simulation, the good thing is that the labels that we

311
00:22:05,640 --> 00:22:10,080
have, the truth that we have are the absolute truth because these are actually producing

312
00:22:10,080 --> 00:22:11,840
a, you know, control simulation.

313
00:22:11,840 --> 00:22:15,560
So whereas if I actually get a realistic, you know, a real data set from this side that

314
00:22:15,560 --> 00:22:20,600
has been analyzed, the prediction for that itself had some error in it, depending on

315
00:22:20,600 --> 00:22:22,120
various parameters.

316
00:22:22,120 --> 00:22:25,920
And the second thing is that currently we only know of a few hundred gravitational lenses

317
00:22:25,920 --> 00:22:26,920
altogether.

318
00:22:26,920 --> 00:22:35,000
So we probably know of about, like, you know, something out there, like 500 lenses, which

319
00:22:35,000 --> 00:22:40,320
is really, really not enough for training these, like, large deep net worth.

320
00:22:40,320 --> 00:22:45,440
So when we are doing simulations, we would produce like half a million of these things.

321
00:22:45,440 --> 00:22:49,080
And it would only take like, you know, about a day to produce this.

322
00:22:49,080 --> 00:22:54,320
And so that gives us, you know, a lot of data set to avoid, you know, issues like overfitting.

323
00:22:54,320 --> 00:23:01,640
Do you find that the models that you produce as a result of this simulation and training

324
00:23:01,640 --> 00:23:08,920
process apply well to real world images, or do you need to incorporate something like domain

325
00:23:08,920 --> 00:23:11,840
transfer or some of these other techniques?

326
00:23:11,840 --> 00:23:13,800
Yeah, we do.

327
00:23:13,800 --> 00:23:18,640
So this, the lensing simulation aspect of it itself is fine.

328
00:23:18,640 --> 00:23:23,040
It's just that telescopes usually have a lot of funny things happening today.

329
00:23:23,040 --> 00:23:28,920
So there's, you know, various forms of noise, they could be cosmic rays like what I described

330
00:23:28,920 --> 00:23:29,920
earlier.

331
00:23:29,920 --> 00:23:30,920
It could be various.

332
00:23:30,920 --> 00:23:35,520
So, in the first form of noise and, oh, you mentioned the cosmic rays.

333
00:23:35,520 --> 00:23:36,520
Yeah.

334
00:23:36,520 --> 00:23:40,440
So cosmic rays is another kind of like, you know, corruption that happens to the data.

335
00:23:40,440 --> 00:23:44,800
So the first time that we tried this on real data, that's what happened was that we trained

336
00:23:44,800 --> 00:23:50,280
it, you know, as CNN and then we looked at its predictions for real data for the first

337
00:23:50,280 --> 00:23:51,280
time.

338
00:23:51,280 --> 00:23:54,960
And we knew the answer for this real data set because we had modeled it before.

339
00:23:54,960 --> 00:23:58,680
So we had a kind of a rough comparison and we're like, it's, you know, the answer was

340
00:23:58,680 --> 00:24:00,360
to keep garbage.

341
00:24:00,360 --> 00:24:04,600
And so what we did is we took these saliency maps, which means that we took kind of like,

342
00:24:04,600 --> 00:24:08,880
we looked at the gradient of our predictions with respect to the data set.

343
00:24:08,880 --> 00:24:13,920
So anywhere in the data that is, you know, making a huge contribution to our decision for

344
00:24:13,920 --> 00:24:18,320
what the truth, you know, what the, what the prediction is, it would kind of like, you

345
00:24:18,320 --> 00:24:20,000
know, shine bright.

346
00:24:20,000 --> 00:24:23,960
And immediately we noticed that anywhere that there was a hint of kind of like, a low

347
00:24:23,960 --> 00:24:28,480
intensity kind of dotting the image, these are cosmic rays that kind of like, you know,

348
00:24:28,480 --> 00:24:32,960
put kind of like a dot or, you know, imprints in the images, it was shining bright.

349
00:24:32,960 --> 00:24:37,280
And we were like, oh, okay, like, that's kind of a sign that, you know, all these other

350
00:24:37,280 --> 00:24:43,240
corruptions that are in the data do really impact the decisions of the CNN.

351
00:24:43,240 --> 00:24:50,920
So the challenging aspect was exactly that, that domain adaptation to try to, or, you

352
00:24:50,920 --> 00:24:55,040
know, in this case, like really simulate, you know, realistic looking images that bring

353
00:24:55,040 --> 00:25:02,280
every aspect representative of the data that we were going to analyze.

354
00:25:02,280 --> 00:25:07,880
Another technique that comes to mind for this type of a problem, it sounds in many ways

355
00:25:07,880 --> 00:25:15,160
to some of the problems like, you know, correcting missing pixels or distortion and photographic

356
00:25:15,160 --> 00:25:18,360
images is generative models.

357
00:25:18,360 --> 00:25:22,000
Is that something that you've been looking at for this problem?

358
00:25:22,000 --> 00:25:25,120
We have been discussing this, but we haven't, we haven't done anything about it.

359
00:25:25,120 --> 00:25:32,560
So in terms of the generative part of this problem, there's like two parts of it that could

360
00:25:32,560 --> 00:25:34,560
be very interesting.

361
00:25:34,560 --> 00:25:37,200
So the first one is the background sources.

362
00:25:37,200 --> 00:25:42,520
So the background source that's being lensed is the image of an actual real galaxy.

363
00:25:42,520 --> 00:25:46,800
So the thing that we did so far was that we actually got a bunch of a large data set of

364
00:25:46,800 --> 00:25:49,480
real images of galaxies.

365
00:25:49,480 --> 00:25:53,960
And so these are from, you know, these are galaxies that are not strong with lens.

366
00:25:53,960 --> 00:25:57,800
So some of them are galaxies, you know, in the local universe, you know, we have beautiful

367
00:25:57,800 --> 00:26:00,120
images from the Hubble Space Telescopes.

368
00:26:00,120 --> 00:26:03,120
Some of them are more distant galaxies in the universe.

369
00:26:03,120 --> 00:26:06,840
But you know, we got like, you know, 100,000 images of galaxies and then we put those through

370
00:26:06,840 --> 00:26:11,520
simulations and made these arcs and, you know, lensed them.

371
00:26:11,520 --> 00:26:15,120
But you know, we were still limited, you know, by these data sets.

372
00:26:15,120 --> 00:26:19,720
So one thing is that that we've been discussing is using these generative models to produce

373
00:26:19,720 --> 00:26:24,520
an un-lensed image of a galaxy, just produce an image of a galaxy.

374
00:26:24,520 --> 00:26:27,320
And then putting that through a simulation lensed.

375
00:26:27,320 --> 00:26:29,600
So for the lensing aspect of it, you could also do this.

376
00:26:29,600 --> 00:26:34,840
You can imagine, well, I'll just train a generative model that produces a lensed image to begin

377
00:26:34,840 --> 00:26:35,840
with.

378
00:26:35,840 --> 00:26:39,480
Well, the thing about that is that the lensing aspect of things is easy, is relatively

379
00:26:39,480 --> 00:26:40,480
easy.

380
00:26:40,480 --> 00:26:46,320
You know, it just involves running something called a ray tracing simulation, which is not

381
00:26:46,320 --> 00:26:50,640
the most efficient thing in the universe, but it's not too bad.

382
00:26:50,640 --> 00:26:52,680
It's not the bottleneing.

383
00:26:52,680 --> 00:26:57,680
And but then the third aspect of it that could also get interesting with generative models

384
00:26:57,680 --> 00:27:03,200
is exactly the point that you brought up about all the other sorts of corruptions that

385
00:27:03,200 --> 00:27:04,200
goes into data.

386
00:27:04,200 --> 00:27:09,480
You know, can I produce a generative model that actually gets these simple simulations

387
00:27:09,480 --> 00:27:15,560
and adds the various effects of, you know, different instruments and telescopes and gives

388
00:27:15,560 --> 00:27:20,040
me images that are represented to flip off that so that I use it for training off the

389
00:27:20,040 --> 00:27:23,360
other machine learning methods like these humans.

390
00:27:23,360 --> 00:27:29,800
How do you kind of envision the future application of machine learning in the space?

391
00:27:29,800 --> 00:27:34,200
You know, obviously, we just talked about some of the generative models and the applications

392
00:27:34,200 --> 00:27:35,200
of those techniques.

393
00:27:35,200 --> 00:27:40,400
But are there other areas that you see as being interesting ones to explore here?

394
00:27:40,400 --> 00:27:41,400
Oh, yeah.

395
00:27:41,400 --> 00:27:45,800
So this is becoming, you know, kind of a popular topic in astrophysics now.

396
00:27:45,800 --> 00:27:52,920
There are a lot of young people looking into the application of this for different things.

397
00:27:52,920 --> 00:27:59,720
You know, there are so many things in astrophysics that you could kind of like use a neural network

398
00:27:59,720 --> 00:28:06,800
to answer the question, but it's really the question of, you know, is it particularly

399
00:28:06,800 --> 00:28:10,400
useful in this particular, you know, case?

400
00:28:10,400 --> 00:28:16,760
So one thing that really made it worth it for us was that in the next few years, we're

401
00:28:16,760 --> 00:28:21,920
expecting to discover about 200,000 strong rabbit nature lenses.

402
00:28:21,920 --> 00:28:28,320
There are a few new surveys that are planned to be operational.

403
00:28:28,320 --> 00:28:36,200
So like, LSSD is a huge project and Euclid telescope, you know, it's a European satellite.

404
00:28:36,200 --> 00:28:38,920
So these are expected to be surveys.

405
00:28:38,920 --> 00:28:41,800
So they will like map huge chunks of the sky.

406
00:28:41,800 --> 00:28:46,920
LSSD in particular will map the whole sky, the visible part of the sky every three nights.

407
00:28:46,920 --> 00:28:50,640
And it will produce, you know, a ridiculous amount of data.

408
00:28:50,640 --> 00:28:54,840
And we're expecting to discover a forward of like, you know, 200,000 lenses.

409
00:28:54,840 --> 00:29:00,680
Now with my traditional methods, if I wanted to go and fit a lens model to every one of

410
00:29:00,680 --> 00:29:05,920
these, you know, 200,000 lenses, even if it took me like, you know, two, three days to

411
00:29:05,920 --> 00:29:10,200
come up with the answer for one lens, which is optimistic actually.

412
00:29:10,200 --> 00:29:15,840
You know, it would take me like 14, you know, 100 years to do that.

413
00:29:15,840 --> 00:29:20,640
So for strong lensing, it really looks like, you know, it's just like, you know, it's a

414
00:29:20,640 --> 00:29:27,040
matter of speed and the number of lenses that we have to analyze.

415
00:29:27,040 --> 00:29:33,040
So in other fields, like, you know, in imaging of the cosmic microwave background, there

416
00:29:33,040 --> 00:29:38,280
are, you know, papers being written right now, people looking into the application of machine

417
00:29:38,280 --> 00:29:39,280
learning.

418
00:29:39,280 --> 00:29:43,320
But, you know, for example, in that field, the problem is not really speed.

419
00:29:43,320 --> 00:29:50,320
It's sometimes about accuracy and could you train neural networks that can be more accurate

420
00:29:50,320 --> 00:29:54,800
than these maximum likelihood methods, because they can deal with, you know, complex

421
00:29:54,800 --> 00:29:57,760
noise, for example.

422
00:29:57,760 --> 00:30:03,880
So, but my general feeling is that, you know, it's becoming an active field in astrophysics

423
00:30:03,880 --> 00:30:06,600
and more and more people are getting excited about it.

424
00:30:06,600 --> 00:30:10,560
Like, you know, when I started giving talks about this, like, you know, two years ago,

425
00:30:10,560 --> 00:30:17,360
I kind of saw, you know, some level of skepticism, primarily because, you know, people have

426
00:30:17,360 --> 00:30:22,320
this worry that these are black boxes and, you know, you cannot control exactly what

427
00:30:22,320 --> 00:30:23,320
happens.

428
00:30:23,320 --> 00:30:26,840
You don't understand why they're making the decisions that they're making.

429
00:30:26,840 --> 00:30:32,600
But as, you know, people have seen the results of, you know, the excellent performance of

430
00:30:32,600 --> 00:30:33,600
these methods.

431
00:30:33,600 --> 00:30:38,320
I think now more and more people are kind of like warming up to the idea and kind of

432
00:30:38,320 --> 00:30:42,120
a lot of research is going that way.

433
00:30:42,120 --> 00:30:43,120
Awesome.

434
00:30:43,120 --> 00:30:49,000
And, and maybe a quick note before we close out, you mentioned the excellent performance

435
00:30:49,000 --> 00:30:54,080
of these methods in your case where you're looking at gravitational lensing.

436
00:30:54,080 --> 00:30:59,400
How do you characterize that performance and what are the types of results you've seen?

437
00:30:59,400 --> 00:31:07,680
So, for us, there's been kind of like two kind of metrics of performance.

438
00:31:07,680 --> 00:31:10,280
And the most important one has been speed.

439
00:31:10,280 --> 00:31:15,000
And so when we train the neural network, you know, the training itself takes just like

440
00:31:15,000 --> 00:31:16,440
a couple of days.

441
00:31:16,440 --> 00:31:21,320
And after that, you know, for the estimation of its parameters of a single lens, you know,

442
00:31:21,320 --> 00:31:25,000
it would take us a hundredth of a second on a single GPU.

443
00:31:25,000 --> 00:31:29,400
And if you assume that the analysis of, you know, a lens of a typical complexity would

444
00:31:29,400 --> 00:31:34,600
take, you know, a few days, you know, often actually like experts' time that, you know,

445
00:31:34,600 --> 00:31:37,720
would have to sit on this and run, you know, quite a few CPUs.

446
00:31:37,720 --> 00:31:43,640
It's something about, you know, 10 million times improvement in analysis speed.

447
00:31:43,640 --> 00:31:47,840
So you know, the analysis of the LCC dataset that I discussed with you earlier.

448
00:31:47,840 --> 00:31:53,360
So this could be done half an hour on single lap cell, which is completely like orders

449
00:31:53,360 --> 00:31:59,560
of magnitude, you know, faster than whatever you could get from traditional modeling.

450
00:31:59,560 --> 00:32:03,720
And then in terms of the accuracy of the models it themselves, you know, we're showing

451
00:32:03,720 --> 00:32:09,240
that you can get accuracies that are within basically the uncertainties of the parameters.

452
00:32:09,240 --> 00:32:12,360
So we can get excellent accuracies on these predictions.

453
00:32:12,360 --> 00:32:16,480
So remember that we were actually looking at the answers that we were saying, well, I'm

454
00:32:16,480 --> 00:32:20,040
interested about a range of answers that match my thing.

455
00:32:20,040 --> 00:32:26,680
And so the precision of these models are really comfortable to the, you know, kind of the

456
00:32:26,680 --> 00:32:31,360
uncertainties that we get from maximum likelihood modeling anyways.

457
00:32:31,360 --> 00:32:35,080
And the other thing is that in there are certain cases where they can actually outperform

458
00:32:35,080 --> 00:32:36,080
these methods.

459
00:32:36,080 --> 00:32:40,760
So another direction we've gone is recently we're using recurrent neural networks.

460
00:32:40,760 --> 00:32:46,120
So these are networks that are typically used for, you know, speech analysis because

461
00:32:46,120 --> 00:32:49,680
they're good at modeling sequences of data.

462
00:32:49,680 --> 00:32:55,200
What we're teaching them here is actually try to model a sequence of steps in these images.

463
00:32:55,200 --> 00:33:01,640
So imagine, you know, imagine, so we're interested in, for example, predicting the distribution

464
00:33:01,640 --> 00:33:03,800
of matter in the lensing galaxies.

465
00:33:03,800 --> 00:33:09,160
And so we'll start from, you know, an unknown guess, something, you know, a random guess

466
00:33:09,160 --> 00:33:11,960
so we don't know what it is.

467
00:33:11,960 --> 00:33:15,720
And we'll have to take a series of steps to get closer to our answer.

468
00:33:15,720 --> 00:33:21,480
So maybe the first guess is going to be that this galaxy, you know, looks like something,

469
00:33:21,480 --> 00:33:25,680
you know, it has some electricity in some direction and some mass.

470
00:33:25,680 --> 00:33:28,840
And then I will refine my answer as I go.

471
00:33:28,840 --> 00:33:32,480
As we're putting this through a recurrent neural network that, you know, so this is

472
00:33:32,480 --> 00:33:35,880
a particular architecture is called the recurrent inference machine.

473
00:33:35,880 --> 00:33:41,000
And so the recurrent inference machine every time looks at its own prediction and then

474
00:33:41,000 --> 00:33:47,040
and then puts that through our simulation that uses the actually like physical model.

475
00:33:47,040 --> 00:33:48,640
And updates its answer.

476
00:33:48,640 --> 00:33:52,560
And one thing that we've been showing is that this can actually like, you know, predict

477
00:33:52,560 --> 00:33:58,240
background source images with the lens or the undistort the image of the background

478
00:33:58,240 --> 00:34:04,880
sources that are better representation of the data than these maximum likelihood models.

479
00:34:04,880 --> 00:34:08,480
And the reason for that is the same thing that you mentioned at the very beginning of

480
00:34:08,480 --> 00:34:10,160
the talk about priors.

481
00:34:10,160 --> 00:34:13,560
And the reason is that this network can learn the complex prior off of what a background

482
00:34:13,560 --> 00:34:17,600
source, what a galaxy really looks like from the training data set, whereas when you

483
00:34:17,600 --> 00:34:23,400
try to define that in, you know, a statistical way from, you know, just, you know, in a statistical

484
00:34:23,400 --> 00:34:25,120
way, it's just difficult.

485
00:34:25,120 --> 00:34:29,880
It's really difficult to define on a pixel per pixel basis what is a galaxy?

486
00:34:29,880 --> 00:34:31,160
What does a galaxy look like?

487
00:34:31,160 --> 00:34:32,160
Right.

488
00:34:32,160 --> 00:34:36,240
If I show you something that, you know, has a little bit of, you know, more fluctuations

489
00:34:36,240 --> 00:34:42,720
here or a little bit spread out, you know, what kind of scored you give it to say how

490
00:34:42,720 --> 00:34:46,880
galaxy, you know, galaxy looking like this is or this is not.

491
00:34:46,880 --> 00:34:51,240
The neural networks, they can learn that from the training data and perform really, really

492
00:34:51,240 --> 00:34:52,240
well.

493
00:34:52,240 --> 00:34:58,440
Well, Ashley, thanks so much for taking the time to share this with us is really interesting,

494
00:34:58,440 --> 00:34:59,440
really interesting work.

495
00:34:59,440 --> 00:35:03,560
I always love talking to folks that are working on astrophysics and cosmology in general.

496
00:35:03,560 --> 00:35:09,280
The use cases are so, just the scale of them is just enormous.

497
00:35:09,280 --> 00:35:10,280
Yeah.

498
00:35:10,280 --> 00:35:12,080
It's really fun talking to you.

499
00:35:12,080 --> 00:35:15,920
I didn't expect this to become more like kind of a high level.

500
00:35:15,920 --> 00:35:20,240
Yeah, I never thought, you know, about throwing the word CNN or RNN or things like that,

501
00:35:20,240 --> 00:35:23,360
but it was just fun for me to have more technical stuff.

502
00:35:23,360 --> 00:35:24,360
Yeah.

503
00:35:24,360 --> 00:35:25,360
Nice.

504
00:35:25,360 --> 00:35:26,360
Fantastic.

505
00:35:26,360 --> 00:35:27,360
Thanks so much, Ashur.

506
00:35:27,360 --> 00:35:28,360
All right.

507
00:35:28,360 --> 00:35:29,360
Thank you.

508
00:35:29,360 --> 00:35:34,360
All right, everyone, that's our show for today.

509
00:35:34,360 --> 00:35:40,240
For more information on Yashur or any of the topics covered in this show, visit twomolei.com

510
00:35:40,240 --> 00:35:43,440
slash talk slash 250.

511
00:35:43,440 --> 00:35:49,320
Make sure to register for Pegaworld using the code twomole19 for $200 off of registration

512
00:35:49,320 --> 00:35:51,280
at Pegaworld.com.

513
00:35:51,280 --> 00:36:21,240
As always, thanks so much for listening and catch you next time.

