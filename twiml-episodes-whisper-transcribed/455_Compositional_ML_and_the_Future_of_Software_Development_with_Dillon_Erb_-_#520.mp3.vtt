WEBVTT

00:00.000 --> 00:16.240
All right, everyone. I am here with my good friend, Dylan Herb. Dylan is the CEO of PaperSpace.

00:16.240 --> 00:22.720
Dylan, welcome back to the Twimal AI podcast. Thanks for having me. Hey, I am really looking

00:22.720 --> 00:29.040
forward to digging into our conversation. It is just about actually just over a year since

00:29.040 --> 00:35.280
the last time we spoke. We had a really good conversation on machine learning as a software

00:35.280 --> 00:41.440
engineering discipline. And maybe we'll reflect a little bit on that. But before we do,

00:41.440 --> 00:49.040
I'd love to have you kind of reintroduce yourself to our audience and maybe share a bit of an

00:49.040 --> 00:54.800
update on PaperSpace and what you've been up to in the past year. Awesome, thanks Sam. Yeah,

00:54.800 --> 01:01.200
so my name is Dylan Herb. I'm the CEO and co-founder of PaperSpace. We are a cloud computing company

01:02.240 --> 01:07.120
that builds a suite of tools for machine learning developers that simplifies the process

01:07.120 --> 01:13.120
of training and deploying machine learning models. We're based in New York and yeah, I guess it's

01:13.120 --> 01:22.240
been a fun year since we last chat in. Yeah, so I mentioned that conversation and it was one

01:22.240 --> 01:31.280
that we got a lot of great feedback on. We talked about this idea of machine learning. I guess

01:31.280 --> 01:41.280
it was a point in time where it was becoming very clear to folks that there was a shift for many

01:41.280 --> 01:48.240
in thinking about machine learning as this experimental process or an exploratory process to one

01:48.240 --> 01:56.080
that required engineering rigor and discipline. We had a really good conversation about that idea,

01:56.080 --> 02:02.880
but I wonder if you would share maybe your big takeaways or recollections from that conversation.

02:02.880 --> 02:09.680
What were the key points for you? Yeah, definitely. I think that it's probably true in any space that's

02:09.680 --> 02:14.960
moving very quickly where the underlying technology is changing seemingly every week.

02:14.960 --> 02:21.200
But as you know, in the machine learning space in particular, there's been a big conversation

02:21.200 --> 02:28.000
about questions such as does machine learning require its own special set of tools or can we reuse

02:28.000 --> 02:36.080
maybe existing tools from the software engineering world? Are there special considerations for

02:36.080 --> 02:41.840
the users of these applications? Is a data scientist a traditional software engineer or something

02:41.840 --> 02:47.360
different? How do we bridge the gap between the kind of more standard machine learning programming

02:47.360 --> 02:53.760
languages like Python or Julia and the more traditional kind of software web tools and programming

02:53.760 --> 03:00.000
languages like Go and JavaScript? I think it's moved very quickly and I would say even today

03:00.000 --> 03:04.960
it's shifting, but I think it's undeniable that machine learning is very quickly making its way

03:04.960 --> 03:11.200
into the software engineering discipline and we're more importantly into a practice of

03:11.200 --> 03:22.320
like delivering machine learning models. So I saw a tweet this morning actually from SRK

03:23.120 --> 03:31.440
and paraphrasing it a little bit here, but the idea was 2015 to 2016 image and vision.

03:31.440 --> 03:46.880
Someone added 2017-2018 Transformers 2019-2020 NLP 2021-2022 MLOPS and the big question was 2023-2024

03:47.680 --> 03:57.440
question mark and you know they were soliciting thoughts on kind of what's next and idea that

03:57.440 --> 04:05.360
we've been talking about that we'll kind of discuss more here you know could be the thing that

04:05.360 --> 04:11.680
fills in that blank and this idea of compositional machine learning. We picked it around a couple

04:11.680 --> 04:19.520
times in prior conversations and you know maybe this is kind of a good entree to have you share a

04:19.520 --> 04:24.000
little bit about you know when you think of this idea of compositional machine learning you know

04:24.000 --> 04:30.080
what is it where did it come from what were some of the inspirations that you've seen recently

04:30.080 --> 04:39.760
that started you thinking down this line. Yeah I really like that that framing and it's funny how

04:39.760 --> 04:44.000
quickly all of those changes happened you know I think there's there's also this whole question

04:44.000 --> 04:50.000
around foundational machine learning or foundational models you know where are we in sort of the

04:50.000 --> 04:54.800
adoption curve I think you know an idea that we've been kicking around I know that you and I

04:54.800 --> 04:59.680
have talked about in the past is this you know or more recently around compositional AI and so for

04:59.680 --> 05:06.320
us you know we've we are we're really at the I would say the beginning of a lot of folks is

05:06.320 --> 05:13.520
journey into machine learning so gradient our machine learning stack is is used by you know at

05:13.520 --> 05:17.840
this point hundreds of thousands of data scientists and machine learning engineers for primarily a

05:17.840 --> 05:23.840
Jupyter notebook product similar to like a Google collab or you know kind of a web based IDE

05:24.560 --> 05:28.800
and so you know we've been really close to seeing folks you know kind of begin their journey

05:28.800 --> 05:34.320
into machine learning and very rapidly we've started to see some some kind of interesting breakout

05:34.320 --> 05:42.160
cases of of how this of how machine learning has become sort of you know composed or or remix in a

05:42.160 --> 05:46.640
way that I think is just fascinating you know a couple that come to mind that have really kind of

05:46.640 --> 05:52.560
sparked a an internal you know kind of dialogue for for us at paper space have been you know one is

05:52.560 --> 05:58.480
is you know this model a first-order motion model came out of NERIPS in 2019 and then earlier

05:58.480 --> 06:05.040
this year we had someone on our platform build a kind of viral funny lip-syncing app that went

06:05.040 --> 06:10.800
from you know sort of academic paper a couple years ago to you know number one app in the app

06:10.800 --> 06:15.440
store you know in lots of countries worldwide and so you know it's kind of interesting where you

06:15.440 --> 06:19.760
see you know maybe an app developer taking a machine learning model and applying to something

06:19.760 --> 06:25.440
you know odd or interesting the other one that I think has been really inspiring is you know we

06:25.440 --> 06:30.080
talk a lot about you know who who's the audience of this and is it software engineers as a data

06:30.080 --> 06:36.080
scientist as a mathematician statisticians and and I think it's actually you know gone expanded

06:36.080 --> 06:40.240
more quickly than we could have imagined so today you know one of the biggest audiences in the

06:40.240 --> 06:45.600
in the Twitter sphere is you know artists and creators you know folks doing generative art and

06:45.600 --> 06:52.880
that's been precipitated largely by open AI's clip model which is contrastive language image

06:52.880 --> 06:58.240
pre-training which basically was a model that was introduced that when you kind of remix it with a

06:58.240 --> 07:03.360
couple of other generative models gives you the ability to kind of you know use a text-based input

07:03.360 --> 07:09.120
and generate you know really fantastical amazing art projects you know and now this is making its

07:09.120 --> 07:15.920
way into NFTs so so I think what's really interesting today is you know whether whether or not some of

07:15.920 --> 07:22.080
these big models are foundational or or essential or or whatever I think what we're seeing is you

07:22.080 --> 07:26.640
know they're getting composed in interesting ways so the API is not necessarily a cloud-based

07:26.640 --> 07:31.680
API that people are consuming but really like you know taking these building blocks and reapplying

07:32.880 --> 07:36.960
so so I think this idea of compositional AI is something that we're you know it's it's kind

07:36.960 --> 07:42.320
of a framework that we're understanding how machine learning is moving past kind of this academic

07:42.320 --> 07:50.240
phase into you know kind of unexpected and interesting real world applications. Do you draw

07:50.240 --> 07:57.520
inspiration for that from kind of the first wave of APIs around the web but certainly you know

07:57.520 --> 08:02.960
especially when you use the term remix that was the term that we like to throw around I was trying

08:02.960 --> 08:13.440
to kind of mentally pin that in time and I don't really have the I don't you know I have to

08:13.440 --> 08:19.920
research that but like there was this transition from kind of this old school way of thinking about

08:19.920 --> 08:27.840
integrating different applications like you know SOA and web sorry XMO web services that no one

08:27.840 --> 08:37.760
thinks about anymore you know to kind of like web 2.0 and rest APIs when the like the essentially

08:37.760 --> 08:46.160
the bar for integration and remixing different services got dramatically lower to the point that

08:46.880 --> 08:53.840
I think you know it's almost not a specific thing anymore because it's just such an integrated part

08:53.840 --> 08:59.200
of the way we think about building new applications and services especially given the rise of cloud.

09:00.560 --> 09:09.200
You know I'm I wonder you know what that experience in that context tells you about the way

09:09.200 --> 09:16.160
composition will evolve on the machine learning side. Yeah I mean I think it's a it's a big question

09:16.160 --> 09:19.920
I think a lot of like you know a lot of smart folks are thinking about sort of what that looks like

09:19.920 --> 09:24.240
you know one of the you know I think the question for us is kind of what's the form factor there

09:24.960 --> 09:30.800
you know if you think about sort of composable portable and encapsulated building blocks of

09:30.800 --> 09:36.720
any kind of software architecture you know immediately the question becomes sort of how big are they

09:36.720 --> 09:42.480
you know what is the kind of interface between them you know machine learning has rapidly gone

09:42.480 --> 09:49.920
through a number of phases and you know we've been around you know for I guess six six years now

09:49.920 --> 09:54.800
and sort of seen a number of these kind of rise and fall so the first was this kind of idea

09:54.800 --> 09:59.200
everyone's going to consume machine learning models through APIs because you know that's how web

09:59.200 --> 10:04.480
developers are used to consuming things like you know clear bits for or something like that you know

10:04.480 --> 10:09.120
a lot of companies kind of rose rose on that model companies like clarify doing really interesting

10:09.120 --> 10:14.640
vision work and making that available as APIs then the big cloud providers followed with vision

10:14.640 --> 10:21.200
APIs and the idea was that we would just kind of layer these into applications I you know I I kind

10:21.200 --> 10:24.880
of what even when that was really sort of the model that people were pushing it was clear that

10:24.880 --> 10:29.600
wasn't going to be sufficient because you know folks want to build their own you know variant of

10:29.600 --> 10:34.080
these and the API model is kind of fundamentally limited so what we're you know another way of saying

10:34.080 --> 10:39.120
that is that the kind of the granularity had to get kind of smaller you know there's been a lot

10:39.120 --> 10:43.920
of consternation earlier which was like hey these things are enormously computationally intense to

10:43.920 --> 10:48.480
to actually create like very few companies can create models the size of GPT-3

10:49.840 --> 10:54.320
arguably you know a number you can count on your hand and so this whole notion of kind of

10:54.320 --> 10:58.560
pre-training or refitting models was really sort of the I would say for the last five years kind of

10:58.560 --> 11:03.920
the the standard like no one's going to retrain the kind of the first few layers of of the image net

11:03.920 --> 11:09.440
they're going to you know train the last one and now we're seeing you know I think even a like a

11:09.440 --> 11:15.680
step beyond that which is you know in the case of these kind of creative you know this creative

11:15.680 --> 11:21.520
artistic community using Clip what they're doing is they're using Clip which is a you know a model

11:21.520 --> 11:25.600
that opening I released that they open I did not release sort of the generator architecture

11:25.600 --> 11:30.720
on top of it so the community has has kind of taken that and applied another generator called

11:30.720 --> 11:36.880
DQGAM and so it's not even just taking one model and changing the data set you're working on it's

11:36.880 --> 11:43.600
taking two models and then recomposing them in a really interesting way so yeah so I don't think

11:43.600 --> 11:48.480
we know exactly what the form factor is but you know when you know I'm I run a company that that

11:48.480 --> 11:54.000
builds tools for this so we have to look for precedence and so you know in our case one of the

11:54.000 --> 11:59.200
the main precedence that we've looked at is is looking at other kind of composable code

11:59.200 --> 12:05.600
architectures you know for example in GitHub there's there's this kind of very large ecosystem

12:05.600 --> 12:10.000
of actions which are these kind of composable encapsulated building blocks that you can apply

12:10.000 --> 12:15.840
into your code repo that can do things like you know do code coverage or deploy your code or test it

12:16.560 --> 12:22.000
or you know add additional functionality and so as we've begun to develop more of our products

12:22.000 --> 12:25.840
and sort of you know build products that that respond to this compositional AI

12:26.800 --> 12:32.320
reality you know we're we're very heavily inspired by you know things that have worked well and

12:32.320 --> 12:37.520
arguably you know we have pretty good precedent for how how to compose you know code that comes

12:37.520 --> 12:43.840
from all sorts of you know different places in the world and different you know different sort

12:43.840 --> 12:48.160
of foundational I guess I don't want to say foundational models but different kind of foundational

12:48.160 --> 12:56.640
pieces I think that's that is an interesting I don't know if it's a point as much as a discussion

12:56.640 --> 13:04.960
around what is the right granularity for delivering machine learning you know as you alluded to

13:04.960 --> 13:09.680
is something that we've been talking about for a long time you and I in particular and the community

13:09.680 --> 13:18.720
at large you know more broadly you know to what degree will you know models as a service be the

13:18.720 --> 13:28.400
primary delivery mechanism for you know your typical developer versus you know them needing the

13:28.400 --> 13:36.080
control that will require them to have access to you know notebooks and infrastructure and

13:36.080 --> 13:43.120
the entire and an experience so that they can customize what they're doing and I think this

13:43.920 --> 13:54.080
the idea that the future is not just single models but kind of multiple models with you know

13:54.080 --> 14:00.720
that are trained in either some end-to-end way or fine-tuned in end-to-end way or in a tightly

14:00.720 --> 14:09.040
coupled way does you know at some point the the permutations of models you know that people might

14:09.040 --> 14:18.080
want to kind of remix you know breaks the industry's ability to you know create wrapper services

14:18.080 --> 14:24.640
for different combinations and people just to operate at a lower level it sounds like that's the

14:24.640 --> 14:31.360
you know what you what you're seeing or what you're you know the vision that is driving

14:32.480 --> 14:39.280
your interest in this compositional idea yeah absolutely you know I think there's there's

14:39.280 --> 14:43.520
you've heard a million times from you know companies and software developers in the space talking

14:43.520 --> 14:48.320
about you know end-to-end pipelines you know you explore some data you train a model you deploy it

14:48.320 --> 14:54.160
um I think that that that paradigm has stuck around I think it's a it's a it's a good one for how

14:54.160 --> 14:59.040
you know data scientists and and data engineers can you know work on a product pipeline that

14:59.040 --> 15:04.640
eventually ships into something interesting um I think that the idea of end-to-end is maybe a

15:04.640 --> 15:10.320
little bit um uh it oversimplifies it a bit because it kind of it sounds like it's sort of there's

15:10.320 --> 15:14.320
an input and then an output whereas you know what what I think we're really seeing is more

15:14.320 --> 15:18.960
combinatorial you know like there are many inputs and many outputs and it's you a fan in architecture

15:18.960 --> 15:24.560
fan out architecture um and very you know practically this has informed how we're building tools um

15:24.560 --> 15:29.200
you know our our main our most popular product is a Jupyter notebook based product and for folks

15:29.200 --> 15:33.760
that are you know there's obviously a large conversation around what what is the role of Jupyter

15:33.760 --> 15:38.080
inside of the machine learning you know development process but you know one of the very fundamental

15:38.080 --> 15:42.720
limitations um and I think there are a lot of benefits but one of the fundamental limitations is that

15:42.720 --> 15:48.000
it is really a you know a linear pipeline it starts at the top and it works its way through cells

15:48.000 --> 15:55.200
down to the bottom um and so fundamentally it's not really recomposable in a way that um you know

15:55.200 --> 16:00.400
that that facilitates or makes possible these more interesting applications um you know they're they're

16:00.400 --> 16:05.360
not as they're not as composable or portable so they're harder to share you know like they um

16:06.080 --> 16:10.880
they're hard to death you know they're they're large JSON objects I think they're extremely useful

16:10.880 --> 16:14.960
in some ways but um you know we've seen there's a there's a reason that folks have really been

16:15.600 --> 16:20.800
embracing sort of these pipelining tools that let you do kind of arbitrarily complex input outputs

16:21.840 --> 16:26.000
you know uh and so that's where a lot of our thinking is today um is around sort of what is

16:26.000 --> 16:32.640
that form factor how do you go from maybe exploring something model or data or um you know just

16:32.640 --> 16:39.040
code repo in a notebook and sort of an interactive REPL uh and then you know how does it get into a

16:39.040 --> 16:43.200
quote-unquote production or you know not even production how does it get into a more interesting

16:43.200 --> 16:48.000
kind of state after you've modified it um and so that's really I think informed a lot of

16:48.000 --> 16:54.080
our thinking uh because you know there's there's you know data code clearly is the main input on one

16:54.080 --> 16:58.480
side you want to create an app or a web service on the other side but but you know there's a lot of

16:58.480 --> 17:03.360
other pieces you pull in and we've been drawing you know a lot on ideas like continuous integration

17:03.360 --> 17:09.680
continuous deployment um composability uh you know pipelining uh uh dags and you know there's

17:09.680 --> 17:14.000
memes now about dags and yamls because I think what we're what the industry is seeing is that we

17:14.000 --> 17:20.560
have to uh you know embrace kind of a more flexible system for building out these new kind of

17:20.560 --> 17:27.760
composed machine learning applications now your your comments on notebooks is calling the mind

17:27.760 --> 17:35.520
another kind of data science internet I don't know if it's a meme or a feud or a drama or whatever

17:36.880 --> 17:45.840
but you know maybe just put it as like you know there are different opinions on the role of notebooks

17:45.840 --> 17:53.920
or the appropriateness of notebooks uh probably best characterized by uh Joe Bruce on one side

17:53.920 --> 17:59.440
you know and his I don't like notebooks talk and then Jeremy Howard on the other side you know

17:59.440 --> 18:09.440
with his I like notebooks talk uh and I think that um you know that that contrast is is

18:10.800 --> 18:19.200
there are folks that have taken you know those positions and tried to operationalize them in

18:19.200 --> 18:24.960
different ways so like you know typically the I don't like notebooks camp well they just don't

18:24.960 --> 18:31.520
use notebooks and they use traditional code and traditional code artifacts uh you know repos

18:31.520 --> 18:39.040
and containers and you know productionalize their projects just not using notebooks on the other

18:39.040 --> 18:47.040
side you know there's folks uh like you know Jeremy and fast AI uh but also you know Netflix I think

18:47.040 --> 18:53.680
is kind of famous for this and some companies which spun out of Netflix uh for and I believe

18:53.680 --> 18:59.520
Airbnb was trying to do this uh for a while I don't know the the more recent status of this but

19:01.280 --> 19:09.440
trying to take the notebook and turn it into a production artifact um you know either through

19:10.560 --> 19:15.600
you know some kind of decorators or annotators or things like that that allow you to to specify

19:15.600 --> 19:22.400
within the notebook hey this is the code that needs to be exposed uh or other mechanisms um

19:24.640 --> 19:30.000
it sounds like you you you started it what's interesting I think in this conversation is you started

19:30.000 --> 19:36.880
with a notebook service that was popular uh but then took this you know traditional engineering

19:36.880 --> 19:43.840
code artifact route as opposed to leaning into the notebook um you know tell yeah here's the thinking

19:43.840 --> 19:48.720
there yeah also um you know for folks that are listening that aren't familiar with paper space

19:48.720 --> 19:53.680
you know we originally started more as an infrastructure as a service company focused on GPUs

19:54.320 --> 19:59.040
and so we are we're interesting in that you know we kind of in many ways grew up with this machine

19:59.040 --> 20:03.200
learning developer audience and kind of washed what they were doing so you know the first very

20:03.200 --> 20:07.440
first offering we provided with something called machine learning in a box which was you know

20:07.440 --> 20:11.600
uh basically a virtual machine template with all sorts of dependencies kind of pre-installed that

20:11.600 --> 20:16.480
we spent countless hours you know fine-tuning to make it work um this was before really containerization

20:16.480 --> 20:21.200
and taken off uh we worked very you know early on we worked very closely with Jeremy at fast

20:21.200 --> 20:26.880
AI um you know we've been very fortunate to I think um I don't know the you know where where

20:26.880 --> 20:30.720
it falls you know from all the numbers but we we've trained a lot of folks in the in the fast

20:30.720 --> 20:35.520
AI universe um or onboarded them into machine learning and deep learning more broadly uh through

20:35.520 --> 20:40.960
the notebook product but you know notebooks we we kind of formalized because it was a pattern we

20:40.960 --> 20:44.800
saw everyone doing they would create a virtual machine and then they would install Jupiter uh

20:44.800 --> 20:50.640
and then they would you know run a web service and put a public IP on it um so you know we we

20:50.640 --> 20:57.520
kind of formalized that pattern um and that became gradient notebooks um it's so for us we with that

20:57.520 --> 21:02.880
background we've kind of had two you know we have sort of this beginners using notebooks at the same

21:02.880 --> 21:07.680
time we are running um you know large GPU infrastructure large clusters we've worked with

21:07.680 --> 21:13.600
um a handful of much much larger kind of very advanced uh um practitioners on on doing kind of

21:13.600 --> 21:20.000
production deployments really uh and so for us it was really you know I think it's the question

21:20.000 --> 21:25.280
of how do you bridge those two worlds I think notebooks are um you know really wonderful

21:25.280 --> 21:33.600
for onboarding people into complex code and data concepts um you know I don't know if it's a

21:33.600 --> 21:37.760
forever thing you know I think it's you know when we describe gradient notebooks today we talk

21:37.760 --> 21:43.280
about it more as it's a it's a web based Jupiter notebook and IDE um so you know you can bring

21:43.280 --> 21:48.960
in uh Python code and Yamel code and um you know other kind of supporting bits as well so it looks

21:48.960 --> 21:55.520
more like maybe a VS code than then uh sort of a standalone Jupiter interface um but fundamentally

21:55.520 --> 22:00.720
you know we've been very interested in in how do you go from a notebook into uh you know like a

22:00.720 --> 22:04.400
notebook is like you're kind of building your your idea or conviction around something and how

22:04.400 --> 22:09.680
do you take that and make something more out of it um and so you know that's that's I think the

22:09.680 --> 22:13.920
area that a lot of folks are thinking about um it's interesting you'd mentioned kind of decorators

22:13.920 --> 22:19.920
and patterns that have kind of been introduced for turning a notebook into a you know runnable Python

22:19.920 --> 22:27.360
file there was a you know paper mill um is a the Netflix project that is very very popular um you

22:27.360 --> 22:31.760
know there are other interesting ones like streamlit which are kind of um I don't even know how to

22:31.760 --> 22:37.840
describe them sort of a combination of a of an interactive notebook and a deployed uh process um

22:38.800 --> 22:44.560
and yeah I mean I think that um that's sort of like right now the question is how do you take

22:44.560 --> 22:48.160
this audience I mean in our case very practically we have a lot of folks that are sort of maybe

22:48.160 --> 22:53.280
growing out of Jupiter notebooks and how do we give them sort of a more composable uh past or

22:53.280 --> 22:59.120
or you know easier path into promoting what they're building or maybe even thinking of like larger

22:59.120 --> 23:04.720
possibilities because they can bring in you know easier more shareable composable building blocks um

23:05.760 --> 23:11.760
so yeah I mean I think uh I don't think notebooks are going anywhere um and I and I think they're

23:12.480 --> 23:18.560
enormously useful um but you know I don't think they're exclusively the form factor and so

23:18.560 --> 23:23.760
you know that's why we're all kind of working hard to find sort of uh uh you know the next step here

23:24.720 --> 23:33.200
and you're uh the the direction that you're betting on is you know the the mean

23:33.200 --> 23:40.560
dag yes the very mean to dag um I mean yeah the machine learning memes have gotten pretty pretty

23:40.560 --> 23:47.120
good in the last year um so I don't know where that puts us on the the hype cycle um but uh but

23:47.120 --> 23:52.160
yeah so you know we uh the one that I shared yesterday on twitter which I thought was really

23:52.160 --> 24:01.840
funny was like a movie poster it was like from the creators of untitled.ipymb and untitled parentheses

24:01.840 --> 24:13.680
one.ipymb is untitled parentheses too.ipymb yep yep yep spot on um you know it's uh yeah I mean

24:13.680 --> 24:18.320
well that's actually you know practically Jupiter notebooks are really hard diversion we actually

24:18.320 --> 24:22.400
had an internal tool that we're you know hopefully we'll release one day but um that we call

24:22.400 --> 24:26.880
MBDIF which is our Diffing Tool for notebooks just because we had to do it um and we ended up running

24:26.880 --> 24:32.000
into a lot of kind of weird issues because um they're you know they're just they're not they're not

24:32.000 --> 24:38.880
really okay uh the format is odd people can annotate it you know colab can add different metadata

24:38.880 --> 24:44.320
annotations the spec changes a bit um you know we can add annotations and it's just it's it's like

24:44.320 --> 24:48.800
hard to diff and and sort of there's different inputs and outputs there you know Jupiter widgets

24:48.800 --> 24:53.440
which are sort of these uh special collaborations between server and client side they're just they're

24:53.440 --> 24:59.120
really weird um for if you from a traditional code perspective um so you know I think we have to

24:59.120 --> 25:04.480
move towards a direction that looks more like um more you know more like traditional software

25:04.480 --> 25:09.440
engineering and that was my you know big pitch a year ago I yeah stand by it we have you know we

25:09.440 --> 25:15.520
we believe really strongly that um Jupiter has a place uh for sure but but you know to to kind of

25:15.520 --> 25:21.680
move the next step we have to um start thinking of you know drawing from known best practices and in

25:21.680 --> 25:28.240
the uh you know uh kind of software engineering world and and one of those is you know uh I wouldn't

25:28.240 --> 25:34.560
even call them DAGs necessarily I mean they certainly you know uh directed aciculate graphs uh but but um

25:34.560 --> 25:40.400
yeah I mean you need to start you know introducing kind of pipelining uh syntax and semantics and

25:40.400 --> 25:45.600
and kind of those primitives you know for us um where uh we're actually just about to my time

25:45.600 --> 25:51.200
this airs we will have rolled out um workflows which is really like our most ambitious project and

25:51.200 --> 25:56.800
also um kind of our most comprehensive which is uh really an automation um and build system for

25:56.800 --> 26:01.520
machine learning applications that allows you to um you know really tightly couple it to source

26:01.520 --> 26:06.160
control so you know to your point on uh kind of untitled one and two um you know that's not

26:06.160 --> 26:13.680
sustainable um uh but you know sort of add a a few lines of code into a repo um uh and begin to

26:13.680 --> 26:18.240
turn that into a kind of a composable building block that could be consumed by other people um and

26:18.240 --> 26:23.440
you know like I mentioned earlier this is heavily inspired by GitHub actions um and and tools like

26:23.440 --> 26:29.680
that um and sort of blended with uh you know kind of the data pipelining tools such as um you know

26:29.680 --> 26:36.560
airflow or you know we're using Argo uh which is kind of a containerized Kubernetes um uh system

26:36.560 --> 26:40.800
but yeah I mean I think this is where it has to go um so you know I don't think we're leaving

26:40.800 --> 26:45.760
notebooks behind but we you know they're insufficient to take us to I think where we want to go

26:45.760 --> 26:59.360
as an industry um so your your infrastructure um use Kubernetes under the covers uh in a lot of

26:59.360 --> 27:05.840
places correct me if I'm wrong but I believe that yeah we're a big Kubernetes yeah uh and you're

27:05.840 --> 27:16.480
you know you selected Argo as the workflow engine which cube flow does one that just like create

27:16.480 --> 27:22.240
cube flow as a service other folks have have gone that route uh why kind of build it from scratch

27:22.960 --> 27:29.920
yeah that's a great question I mean I think um cube flow uh amazing uh project in lots of ways

27:29.920 --> 27:36.240
I think um it's uh this is my opinion in my opinion alone I think it kind of struggles to

27:36.240 --> 27:43.120
to to uh to match sort of the um the audience where it is today um I think it's it's hard to set up

27:43.120 --> 27:51.360
I think um you know the building out sort of the um the the cube flow actions effectively I think

27:51.360 --> 27:55.680
is um still a bit difficult so it requires just more software engineering work so very large

27:55.680 --> 28:01.120
companies um you know I don't spotify uh can can use um cube flow because they can invest in that

28:01.120 --> 28:08.320
ecosystem I think um you know there it's it's not a pattern that um will be as extensible for

28:08.320 --> 28:13.840
the kind of wide adoption that I foresee um and so you know what we've done with workflows which

28:13.840 --> 28:20.480
is our uh kind of newest addition to gradient um is it's kind of take the best of of cube flow

28:20.480 --> 28:27.520
and Argo which is you know containerization um you know sort of uh the ability to create these

28:27.520 --> 28:32.560
you know complex tags with triggers and and sort of the fundamental pieces but expose it in a way

28:32.560 --> 28:37.840
that is much more uh kind of akin to folks that are building you know for example we took a lot

28:37.840 --> 28:42.480
of inspiration from tools like Netlify and Versal which are these web tools that basically let you

28:42.480 --> 28:47.920
come in attach a repo uh to to their service and then it you know basically creates a build system

28:47.920 --> 28:52.400
and gives you a website at the end um with just clicking a few buttons um and I think that's

28:52.400 --> 28:56.800
the form factor we need um and today you know workflows when you when you onboard you basically

28:56.800 --> 29:02.160
it's it's a very similar process give me a repo or pick one of a sample repo um it's going to

29:02.160 --> 29:07.920
give a little bit of code in in a workflow dot yaml file um although that's kind of abstracted

29:07.920 --> 29:12.800
away um and and I think we're gonna move quickly to a point where the yaml is really an implementation

29:12.800 --> 29:18.320
detail uh and folks will be you know I don't know if it's a full low code no code because I don't

29:18.320 --> 29:23.920
know how quickly we get there um but um you know the composability is where we want to focus our

29:23.920 --> 29:29.600
energy um and so you know I think Duplo it has solved a lot of interesting problems and and you

29:29.600 --> 29:33.040
know they're a handful of other folks in the data kind of the data flow space that have worked on

29:33.040 --> 29:39.840
this as well folks coming from the the Jupiter world so there's like uh these tool like plumber

29:39.840 --> 29:43.120
is a really interesting one that I've been looking at recently there's one called kale for Kubernetes

29:43.120 --> 29:48.160
which lets you sort of build out building blocks um um from a notebook and make them deployable

29:48.160 --> 29:51.680
um but we're coming out of any other direction which is like what are what's the you know

29:51.680 --> 29:55.920
what tools are common in the software engineers tool belt and how do we make this machine learning

29:55.920 --> 30:01.040
thing look a lot more like that so for us the inspiration is um it's not starting at Jupiter notebooks

30:01.040 --> 30:07.520
it's starting at um you know uh Jenkins, CircleCI, Versal, Netlify, GitHub actions things that are

30:07.520 --> 30:13.680
like kind of like known known paradigms and known tool stacks or types of tools in uh you know

30:13.680 --> 30:18.240
for folks that are building production applications. Yeah one of the things that I think is

30:20.000 --> 30:28.080
compelling from a user and a face user experience kind of perspective about um you know paper mill

30:28.080 --> 30:38.000
ask type of types of approaches is the idea that they start with the notebook and you know you

30:38.000 --> 30:45.200
because the notebooks is an interesting and useful place for kind of the throwing stuff against

30:45.200 --> 30:52.320
the wall and seeing what sticks and like starting to you know shape it and um you know just kind of

30:52.320 --> 30:59.840
bootstrapping your thinking about the way to attack a problem uh and then you know the traditional

30:59.840 --> 31:05.840
approaches okay you do that you kind of bang stuff into shape and then you like pull it out into

31:05.840 --> 31:11.920
a python module into a text file um but the you know these other approaches allow you to like

31:13.120 --> 31:17.680
it's it's even easier in a sense and if you've already got that infrastructure in place you just

31:17.680 --> 31:25.680
kind of add your decorator or whatever and you know there's your your artifact um I think the

31:25.680 --> 31:31.200
question I'm trying to get to is like you know do you see a bridge between the worlds and what

31:31.200 --> 31:37.120
you've built with workflows where you know you're starting in this you're you're I don't think

31:37.120 --> 31:45.520
you're suggesting folks to not use notebooks to you know get started or to to experiment because

31:45.520 --> 31:53.520
they're useful for that is there a bridge from that to a dag based you know traditional system

31:53.520 --> 31:58.000
other than okay you know rip your stuff out of the notebook and put it into a code module and

31:58.000 --> 32:06.240
take it in to get up yeah uh that's a good one um I I don't know I mean I think that um that

32:06.240 --> 32:10.880
we're we're internally doing a lot of work on on thinking about that form factor like can you

32:10.880 --> 32:16.720
you know turn a cell into an action in our in our pipeline um can you sort of send one over um

32:18.320 --> 32:22.960
the I think that the form factor that we need to get to more quickly and this is actually where

32:22.960 --> 32:29.520
we sent more of our more more of our energy with workflows is um kind of closer what I would call

32:29.520 --> 32:35.840
maybe build packs or sample apps so for example you know I think what versatile and for folks not

32:35.840 --> 32:43.200
familiar it's a it's a web hosting tool for building or a tool for building web applications

32:43.200 --> 32:50.640
very easily and it relies a lot on you know things like for example create react app which is sort

32:50.640 --> 32:54.480
of a starter template that if you're making a website it's a really good place to kind of fork

32:54.480 --> 32:59.920
that one and start somewhere and so I think that you know the pattern we have for notebooks today is

32:59.920 --> 33:05.760
people fork a notebook and build something out um you know clip and vqgan and then they run through

33:05.760 --> 33:13.120
it and they get some images um I guess you know that form factor is is hard to you know directly turn

33:13.120 --> 33:19.440
into something like a create react app or a um uh you know I don't know a starter template of

33:19.440 --> 33:25.120
sorts but I do think is it the nature of notebooks that makes it hard yeah I mean it's it's largely

33:25.120 --> 33:30.880
because the the you know the the large benefit of a notebook is that you get this interactive

33:30.880 --> 33:35.600
repel environment you know you type code you get a response very quickly um but that same you know

33:35.600 --> 33:40.480
the the the fact that it is sort of embedding its outputs and its inputs um cells are not really

33:40.480 --> 33:46.320
ordered um you know they don't have any reference to the dependencies or the or the metadata um

33:46.320 --> 33:50.960
that's required to run the thing it's hard because it's a notebook it's hard because it's a notebook

33:50.960 --> 33:55.840
and so you know what I think well you know one of the things that we're bringing over more into workflows

33:55.840 --> 34:02.640
is the kind of interactive repel you know idea um like for example in circle CI which is our build

34:02.640 --> 34:08.320
tool that we really like um for our web application um you know you can SSH into an instance which is

34:08.320 --> 34:12.560
the equivalent of kind of creating a repel you kind of go in and you can start interacting with the

34:12.560 --> 34:18.080
real thing um it's just you're doing it at a at a you know a higher like a different level of

34:18.080 --> 34:22.800
granularity um you know a notebook is really like tightly connected to a single kernel and you're

34:22.800 --> 34:28.880
kind of you know going through um I think you know I I don't think they're going anywhere I think

34:28.880 --> 34:35.120
they're extremely important components um I think that their importance will be will know more um

34:35.120 --> 34:38.720
I think in a few you know maybe even in the next year when we start seeing sort of how the

34:38.720 --> 34:43.440
the next set of killer applications um you know come to fruition and my guess is it's going to look

34:43.440 --> 34:48.080
more like starter templates like create react app that you're forking um you know more like build

34:48.080 --> 34:53.040
systems and build packs um where you're kind of focusing your energy on picking different you

34:53.040 --> 34:58.320
know um instead of dolly you're picking vqgant um or instead the first order motion model you're

34:58.320 --> 35:04.400
picking uh you know uh the the new enhanced one that that snapchat just came out with um so

35:04.400 --> 35:09.280
so yeah I think that that's it's a big open question um but the good thing is we don't have to

35:09.280 --> 35:14.560
invent it from scratch we can follow um you know a good precedent and I think we should draw that

35:14.560 --> 35:18.160
and this goes back to the sort of the last conversation I think we should draw primarily from

35:18.160 --> 35:22.720
the software engineering world because a lot of this has been resolved over the last say 25 years

35:22.720 --> 35:29.120
or whatever um on how you how do you build scalable you know large production uh applications

35:30.320 --> 35:34.880
one of the things still in that I've heard you say and in this conversation and we we've talked

35:34.880 --> 35:44.240
previously is that this project is you know one of your or your the paper spaces most ambitious

35:44.240 --> 35:52.720
undertaking and um you know I'm curious what why that is like what makes it ambitious it sounds

35:52.720 --> 35:58.560
like you took Argo and like build a web app around it like you know you can make it you can you

35:58.560 --> 36:05.040
can reduce it or simplify it to sounding very simple you know yep what where's the complexity

36:05.040 --> 36:14.080
and the effort yeah uh great question I mean I um you know what I think for us it's we know that

36:14.080 --> 36:20.480
there are certain really well-known best practices so notebooks today whether we think they're

36:20.480 --> 36:25.360
going to exist for 10 years or not they're they're really practical useful um components in the

36:25.360 --> 36:31.440
machine learning you know developers tool belt um deployments on the other end which we also

36:31.440 --> 36:37.120
a deployment service that were were by time this rolls out there will be sort of our next iteration

36:37.120 --> 36:42.160
of that that has been released um but deployments are also relatively well understood at least from a

36:42.160 --> 36:47.680
web perspective I mean we can go into you know edge deployments and quantizing and pruning models

36:47.680 --> 36:52.400
and sort of the you know the complexity there but I think it's there there are less open questions

36:52.400 --> 37:00.240
um really uh you know it's the question about the glue or the fabric that takes these kind of early

37:00.240 --> 37:08.160
you know exploratory prototyping tools and lets them kind of transition into the you know

37:08.160 --> 37:13.280
the the production world you know think that every software company in the MLO space is talking

37:13.280 --> 37:19.440
about end-to-end you know training to deployment R&D to production um and I think that you know

37:19.440 --> 37:23.920
so that that inner fabric I think is really important um and there's no shortage of

37:23.920 --> 37:31.120
DAG based data flow data um you know data tools um and so for us it was very much pick you know

37:31.120 --> 37:35.280
have some principles on what we're picking as the foundational piece you know containerization

37:35.280 --> 37:39.600
we think is it's you know we're making bets we're making bets on technology stacks you know we

37:40.160 --> 37:45.280
invested very heavily into Kubernetes um and you know Kubernetes is an amazing technology has

37:45.280 --> 37:50.080
actually I think been more complicated than some people thought um but I think is a you know

37:50.080 --> 37:55.680
it's a big it's a big bet for us is that that type of container orchestration layer um is one

37:55.680 --> 38:00.160
that we you know shouldn't try to solve differently for machine learning than we should other other

38:00.160 --> 38:06.400
areas um the form factor though for how you compose them is very different um because the

38:06.400 --> 38:12.160
reality is the audience is different you know the folks that are that are I would say um

38:12.160 --> 38:18.720
um that should be using machine learning in their day-to-day work if all things were created equal

38:18.720 --> 38:24.640
and it were very easy to do is massive it includes uh marketing people and statisticians and

38:24.640 --> 38:30.800
folks in the humanities and artists and um you know in addition to software engineers and

38:30.800 --> 38:36.880
BI people and you know analysts and it really is and medical practice you know uh practitioners

38:36.880 --> 38:41.760
so it's pretty it's pretty expansive and so what that means is there's there I don't think there is a

38:41.760 --> 38:47.680
single form factor for everyone um you know I can see a world where uh there it you know

38:48.720 --> 38:54.960
there are zapier like you know connections for um machine learning models to endpoints and there

38:54.960 --> 39:00.960
are APIs that are consumable um just like there are today for web services but I think the question

39:00.960 --> 39:05.600
that you know when we think about it you know our audience is every software developer in the world

39:05.600 --> 39:11.200
building uh you know software applications and delivering those we believe that they are going to

39:11.200 --> 39:17.280
use machine learning as just a part of their toolbell a part of their stack um so you know we have

39:17.280 --> 39:24.080
some guidance on how to how you know workflow should be designed um but it's it's a uh you know it

39:24.080 --> 39:30.800
is not there there's no very obvious precedent for exactly how this should be done um and I think

39:30.800 --> 39:35.920
that when you take on a very large projects like this um getting the form factor wrong especially

39:35.920 --> 39:43.440
for you know uh a software company um can be can be really dangerous um so you know we can get

39:43.440 --> 39:47.440
into sort of how product and development and management is done but I you know it it really is

39:47.440 --> 39:52.400
always I think even at all good companies um some percentage of like seeing where the world is

39:52.400 --> 39:57.360
today uh what are people building you know what are their problems and challenges uh and then the

39:57.360 --> 40:02.160
other 50% is you know what are going to be the challenges a year from now and given how quickly

40:02.160 --> 40:06.880
the space is moving and how many things that I think are just really amazing and unpredictable um

40:06.880 --> 40:14.480
you know it's uh it's it's I think you know ambitious to to try to give a a version of a future

40:14.480 --> 40:26.560
that is um uh you know so so up in the air right now um yeah I think uh uh you reference this idea form

40:26.560 --> 40:31.920
factor you know multiple times throughout this conversation and and you know what you're saying

40:31.920 --> 40:38.560
clearly is that it's not the it's not necessarily the like the engineering challenge of

40:38.560 --> 40:45.520
hooking up a workflow you know engine to uh deployment system to this it's it's all of that

40:46.160 --> 40:51.120
you know there are there is existing software out there that you're taking advantage of you

40:51.120 --> 40:56.000
know not that that's easy right when you have a large distributed system it's always hard but it's

40:56.640 --> 41:03.360
sounds like what you're saying is that the you know the challenge was more getting the user

41:03.360 --> 41:10.720
experience right uh in all that you know compared to you know your previous undertaking which was

41:11.440 --> 41:16.000
there's this well-known user experience a notebook how do we make it so that you know how do

41:16.000 --> 41:21.440
we make it easier to deploy that yeah there's a lot more risk in trying to figure out you know as you

41:21.440 --> 41:27.200
say kind of look into the future in terms of what people will need to you know more easily kind of

41:27.200 --> 41:36.240
compose machine learning uh an AI systems and then build a system that uses just these infrastructure

41:36.240 --> 41:41.520
primitives to make that easier to do yeah absolutely I think that is the challenge I don't think

41:41.520 --> 41:47.280
it's ours alone but I think you know what we're coming at it with is uh I think a you know a somewhat

41:47.280 --> 41:53.520
unique perspective which is that we you know we have a um more of an infrastructure you know deep GPU

41:53.520 --> 41:58.720
and accelerator focused than probably most companies in this space at the same time you know we have

41:58.720 --> 42:04.240
created tool that is used by uh you know probably more folks in this space than almost any other tool

42:04.240 --> 42:09.120
for kind of learning this for the first time and so we have these you know this kind of split

42:09.120 --> 42:13.920
audience of like beginners and advanced people and and I think that that gives us an interesting

42:13.920 --> 42:19.840
perspective on how to how to bridge those but certainly it's not resolved and you know I can see

42:19.840 --> 42:24.000
a scenario where you come back in a year and we say yeah so you know actually you know we the

42:24.000 --> 42:28.720
YAML stuff was too hard to do and the audience didn't need it we you know we really had to make

42:28.720 --> 42:34.720
this say uh you know a wizzy wig a gooey build or something like that or you know more of a safe

42:34.720 --> 42:41.280
year or you know notebooks actually um you know are no longer as useful when people can can clone

42:41.280 --> 42:46.080
starter apps that do basically what they want to do anyway um including the deployment and the

42:46.080 --> 42:52.880
training and the you know inferencing logic um so yeah I think we'll see I mean I think look uh

42:52.880 --> 42:57.440
we're we're in a really exciting time I mean for software developers in particular uh you know

42:58.080 --> 43:03.680
I just listened to the Greg Brockman version of your podcast which I really liked talking about

43:03.680 --> 43:11.280
codex and copilot you know these tools are being used today um in in the real world by you know

43:11.280 --> 43:16.640
like machine learning and assisted technologies are real and they're being used by programmers by

43:16.640 --> 43:22.960
physicians by um you know a lot of folks and so you know it's some level I think it's inevitable

43:22.960 --> 43:28.560
that this technology breaks out of the lab or whatever the analogy is um but um you know I think

43:28.560 --> 43:32.080
there's a race to figure out the form factor and I think the opportunity is massive because I think

43:32.080 --> 43:37.680
we're gonna see you know just like today totally unexpected applications um that are really

43:37.680 --> 43:42.160
inspiring you know I think it's it's amazing that we've been in the space you know uh for it's

43:42.160 --> 43:48.560
relatively um short life life cycle um and just I continue to be amazed at what is being created

43:48.560 --> 43:54.560
and um you know what's possible um and you know we could we could have a whole other our conversation

43:54.560 --> 43:59.600
about you know transformers and uh you know sort of what what what that what that has done for the

43:59.600 --> 44:07.360
space but um and we probably should but uh you you brought up the the interview with Greg and and

44:07.360 --> 44:14.080
codex and um you you talked abstractly about that stuff being used but from our conversations

44:14.080 --> 44:18.560
I know it's not necessarily just abstract for you you actually used it and there's some

44:18.560 --> 44:25.040
codex generated code in in paper base yeah yeah we'll have to uh I mean it's uh still you know

44:25.040 --> 44:29.920
we we were when it first came out we were kind of playing around and you know giving some comments

44:29.920 --> 44:35.360
like generate a function that uh you know does this simple task uh creates an array of of interesting

44:35.360 --> 44:42.320
names or whatever uh for sample projects um and we actually do have a piece today which is um

44:42.320 --> 44:48.080
totally AI generated that is in our production application um it's small it's you know

44:48.080 --> 44:55.680
founded but it opens up the question you know if one whatever 0.001% of our code base is AI generated

44:55.680 --> 45:01.440
generated today um you know I'm curious what percentage that is a year from now or the next time

45:01.440 --> 45:08.720
we talk my guess is it's going to be more um and so uh you know that's an exciting future for sure

45:08.720 --> 45:13.280
like this this stuff is not we're not talking abstractly about the power of machine learning to

45:13.280 --> 45:18.800
change your day-to-day it's actually doing it um you know that's this is also a very complicated

45:18.800 --> 45:23.280
topic I don't think engineer you know software engineers are going to be out of jobs but um you

45:23.280 --> 45:28.880
know I think this this kind of radical AI assisted future uh is really exciting whether you're an

45:28.880 --> 45:34.800
artist a programmer um you know a media producer uh whatever it is like I think that um that's why

45:34.800 --> 45:39.680
this space is so exciting and that's why I think you know um we we care so much about trying to

45:39.680 --> 45:46.160
find the right form factor UX sort of the the the way that we can assist in um you know helping

45:46.160 --> 45:50.560
build more amazing applications like you know kind of breaking out of the the kind of meme culture

45:50.560 --> 45:54.320
and getting into like what what what are you know what are builders building kind of thing

45:55.760 --> 46:03.200
awesome awesome well Dylan always a pleasure to catch up with you thanks so much for the update

46:03.200 --> 46:11.920
and uh looking forward to next time awesome thanks soon take care thank you

