1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,480
I'm your host Sam Charrington.

4
00:00:31,480 --> 00:00:38,400
In this episode, I speak with Cassinia Konyashkova, a PhD student in a CV lab at Acole Polytechnic

5
00:00:38,400 --> 00:00:41,960
Ferrahal de Lozan in Switzerland.

6
00:00:41,960 --> 00:00:47,080
Cassinia and I connected at Nips back in December to discuss her very interesting research into

7
00:00:47,080 --> 00:00:51,880
some ways we might apply machine learning to ease the challenge of creating label data sets

8
00:00:51,880 --> 00:00:54,320
for machine learning.

9
00:00:54,320 --> 00:00:59,320
The first paper we discuss is learning active learning from data, which suggests a data-driven

10
00:00:59,320 --> 00:01:04,640
approach to active learning that trains a secondary model to identify unlabeled data points

11
00:01:04,640 --> 00:01:11,360
which, when labeled, would likely have the greatest impact on our primary model's performance.

12
00:01:11,360 --> 00:01:17,000
We also discuss our paper, Learning Intelligent Dialogues for Bounding Box Annotation, in

13
00:01:17,000 --> 00:01:22,800
which she trains an agent to guide the actions of a human annotator to more quickly produce

14
00:01:22,800 --> 00:01:27,360
bounding boxes.

15
00:01:27,360 --> 00:01:31,920
Last week, I attended an investor conference in San Francisco.

16
00:01:31,920 --> 00:01:35,760
Having spent a couple of packed days being peppered with questions about the state of the

17
00:01:35,760 --> 00:01:40,360
AI market and its various players, I wrote about some of the key themes that emerged

18
00:01:40,360 --> 00:01:43,280
for the latest issue of my newsletter.

19
00:01:43,280 --> 00:01:47,440
If you're interested in the commercial side of the AI industry, you'll definitely want

20
00:01:47,440 --> 00:01:49,080
to check it out.

21
00:01:49,080 --> 00:01:55,040
If you don't already subscribed to my newsletter, visit twimmolai.com slash newsletter or just

22
00:01:55,040 --> 00:01:59,280
email info at twimmolai.com asking to be added.

23
00:01:59,280 --> 00:02:02,920
You'll automatically get the latest issue when you sign up.

24
00:02:02,920 --> 00:02:06,760
Quickly, a bit about the next Twimmol online meetup.

25
00:02:06,760 --> 00:02:12,600
On Tuesday, March 13th, Sean Devlin will be doing an in-depth review of reinforcement

26
00:02:12,600 --> 00:02:18,120
learning and presenting the Google Deep Mind paper, playing Atari with deep reinforcement

27
00:02:18,120 --> 00:02:19,520
learning.

28
00:02:19,520 --> 00:02:24,360
Head over to twimmolai.com slash meetup to learn more or register.

29
00:02:24,360 --> 00:02:28,760
All right, let's roll.

30
00:02:28,760 --> 00:02:37,080
All right, everyone, we are here at NIPS and I am with Cassinia Konošková.

31
00:02:37,080 --> 00:02:44,080
Cassinia is a PhD student in the computer vision lab at EPFL in Lozan, Switzerland.

32
00:02:44,080 --> 00:02:46,280
Cassinia, welcome to the podcast.

33
00:02:46,280 --> 00:02:47,280
Thank you.

34
00:02:47,280 --> 00:02:48,280
Nice to meet you today.

35
00:02:48,280 --> 00:02:49,280
Absolutely.

36
00:02:49,280 --> 00:02:51,240
Great to meet you as well.

37
00:02:51,240 --> 00:02:55,040
So why don't we get started by having you tell us a little bit about your background and

38
00:02:55,040 --> 00:02:59,840
how you got involved in computer vision and machine learning, artificial intelligence?

39
00:02:59,840 --> 00:03:05,320
Okay, so it probably all started with my master degree when I just heard this cool name,

40
00:03:05,320 --> 00:03:06,320
machine learning.

41
00:03:06,320 --> 00:03:07,320
Okay.

42
00:03:07,320 --> 00:03:11,680
I had a very little idea of what it is all about, but it sounded exciting, and then I learned

43
00:03:11,680 --> 00:03:16,440
that you can actually recognize Cassinia in the pictures if you use machine learning and

44
00:03:16,440 --> 00:03:19,400
then I thought, great, that's the thing for me.

45
00:03:19,400 --> 00:03:20,400
No, I'm kidding.

46
00:03:20,400 --> 00:03:25,000
No, it wasn't the real motivation, but yeah, it just sounds fun.

47
00:03:25,000 --> 00:03:31,280
But yeah, it sounded like a fun field to be, and it was probably a little bit before,

48
00:03:31,280 --> 00:03:37,640
it became so popular and so famous, but I was likely to be there at the beginning.

49
00:03:37,640 --> 00:03:44,480
So I joined the program in machine learning and algorithms in the University of Helsinki.

50
00:03:44,480 --> 00:03:51,280
And after that, I went from my PhD program in Switzerland at a quality technique for the

51
00:03:51,280 --> 00:03:56,520
Grand de la Sant, and I joined the computer vision lab with Pascal Four, who is famous in

52
00:03:56,520 --> 00:04:00,880
the computer vision community, but as you know, today computer vision very much depends

53
00:04:00,880 --> 00:04:06,560
on machine learning, so it was a great match to combine this two fields that interest

54
00:04:06,560 --> 00:04:07,560
me.

55
00:04:07,560 --> 00:04:08,560
Okay, awesome.

56
00:04:08,560 --> 00:04:09,560
Awesome.

57
00:04:09,560 --> 00:04:14,480
And you're here at NIPS, sharing some of the work you're doing, some of your research.

58
00:04:14,480 --> 00:04:16,560
Can you tell me a little bit about that?

59
00:04:16,560 --> 00:04:17,560
Mm-hmm.

60
00:04:17,560 --> 00:04:18,560
Yes, sure.

61
00:04:18,560 --> 00:04:20,680
So I'm working in the field that is called active learning.

62
00:04:20,680 --> 00:04:21,680
Okay.

63
00:04:21,680 --> 00:04:25,400
So the basic idea is that normally in the traditional machine learning, we have a lot of training

64
00:04:25,400 --> 00:04:31,280
data, which we collect from human experts, and then they provide us with the labels for

65
00:04:31,280 --> 00:04:36,000
this data when we're doing the supervised machine learning, and having this huge annotated

66
00:04:36,000 --> 00:04:41,160
corpus of data, we can train a model, which will help us to predict for the new coming

67
00:04:41,160 --> 00:04:45,920
data what labels were assigned, either it's a classification or a regression task.

68
00:04:45,920 --> 00:04:50,480
The problem that we're dealing with is that we don't have this training data available,

69
00:04:50,480 --> 00:04:56,080
and we're trying to select the data in the optimal way, so that if we annotate it, we can

70
00:04:56,080 --> 00:04:59,760
learn the machine learning model as quickly as possible.

71
00:04:59,760 --> 00:05:05,760
So the idea is to reduce human annotation efforts, and at the same time achieve similar

72
00:05:05,760 --> 00:05:10,080
quality of performance of the machine learning algorithms.

73
00:05:10,080 --> 00:05:15,560
And what I'm doing, I'm presenting the work that is called learning active learning from

74
00:05:15,560 --> 00:05:16,560
data.

75
00:05:16,560 --> 00:05:17,560
Okay.

76
00:05:17,560 --> 00:05:22,520
So we're going even one step further, and instead of trying to construct some specific

77
00:05:22,520 --> 00:05:28,160
algorithm that would select data for us, we're trying to learn an algorithm from the

78
00:05:28,160 --> 00:05:33,160
previous examples of active learning algorithms runs.

79
00:05:33,160 --> 00:05:34,160
Okay.

80
00:05:34,160 --> 00:05:41,720
So for example, the very popular active learning algorithm is called uncertainty sampling.

81
00:05:41,720 --> 00:05:45,920
In this case, we have, for example, suppose we have 10 data points that are labeled for

82
00:05:45,920 --> 00:05:51,000
us, it's very little and we probably cannot predict much based on them, but we can still

83
00:05:51,000 --> 00:05:56,280
have a very rough idea of how the model should be, and then we can construct, for example,

84
00:05:56,280 --> 00:06:01,600
the decision hyperplane, and then we will select points that lie closest to the decision

85
00:06:01,600 --> 00:06:06,720
boundary, and we would think that as the model is the most uncertain right now about this

86
00:06:06,720 --> 00:06:11,680
points, if we annotate these kind of points, they would help to train a better model in

87
00:06:11,680 --> 00:06:13,080
the future.

88
00:06:13,080 --> 00:06:19,360
So instead of labeling the data just uniformly a trend from the very big corpus, we select

89
00:06:19,360 --> 00:06:23,200
the data that would help the model the most.

90
00:06:23,200 --> 00:06:27,680
And this kind of algorithms, like I mentioned, uncertainty sampling, and there are many

91
00:06:27,680 --> 00:06:31,480
other ones that were introduced in the literature.

92
00:06:31,480 --> 00:06:36,920
The problem is that on different applications, they're all competing, some of them are doing

93
00:06:36,920 --> 00:06:40,480
better in this scenario, some are doing better in that scenario.

94
00:06:40,480 --> 00:06:45,520
And for example, in my previous work, I worked on specific algorithm to work with images,

95
00:06:45,520 --> 00:06:51,000
so to take the advantage of the structure and some smoothness assumptions of the images

96
00:06:51,000 --> 00:06:52,720
to annotate data.

97
00:06:52,720 --> 00:06:58,040
But then there is nothing principle there, and we don't know which of the algorithm would

98
00:06:58,040 --> 00:07:03,840
actually perform the best at priority, so we have to test them, and this is all human

99
00:07:03,840 --> 00:07:05,320
annotation costs.

100
00:07:05,320 --> 00:07:11,800
So my idea is that we have some annotated data sets already, and then if we simulate

101
00:07:11,800 --> 00:07:17,680
the runs of this data collection process, we can actually see what kind of points led

102
00:07:17,680 --> 00:07:24,040
to a good behavior of active learning algorithm, and which points didn't improve the quality

103
00:07:24,040 --> 00:07:25,200
much.

104
00:07:25,200 --> 00:07:29,240
And then we can try to predict in the future what kind of points should be selected.

105
00:07:29,240 --> 00:07:35,600
So in particular, I'm dealing with station where I just generate a lot of data myself,

106
00:07:35,600 --> 00:07:40,440
just like some synthetic data sets of very simple shapes, but they still have a lot

107
00:07:40,440 --> 00:07:46,200
of variability of them, some in some cases, if I deal with binary classification, sometimes

108
00:07:46,200 --> 00:07:51,200
the classes overlap a lot, sometimes they're easily separable, two-dimensional shapes

109
00:07:51,200 --> 00:07:52,200
or...

110
00:07:52,200 --> 00:07:56,360
Yes, right now it's just very simple, we can do it with a very kind of cheap procedure

111
00:07:56,360 --> 00:08:02,320
with just two-dimensional data, and then we run active learning on them, just kind of

112
00:08:02,320 --> 00:08:08,000
this data collection, and then we look at the state of the classifier, how the classifier

113
00:08:08,000 --> 00:08:13,680
was trained, and the data points, and we look how much adding each kind of data point

114
00:08:13,680 --> 00:08:16,920
reduced the classification error for us.

115
00:08:16,920 --> 00:08:21,840
So for example, we label two data points, we train a model, we look at what kind of

116
00:08:21,840 --> 00:08:26,760
error this model resulted in, as we know all the ground rules, as this is the simulated

117
00:08:26,760 --> 00:08:27,760
data.

118
00:08:27,760 --> 00:08:32,400
Then we try to select one more data point, and we get three points.

119
00:08:32,400 --> 00:08:37,560
Now in these three points, we can learn a new model, and it results in a new error.

120
00:08:37,560 --> 00:08:41,840
And now we can look at the difference between the error of the model with two points and

121
00:08:41,840 --> 00:08:46,880
the error of the model with three points, and the difference would show us how much adding

122
00:08:46,880 --> 00:08:50,000
this third data point helped the model.

123
00:08:50,000 --> 00:08:57,360
And so now as we go on in training, we memorize the states of the classifier, for example

124
00:08:57,360 --> 00:09:01,920
I'm dealing with something very simple, like random forest classification, I can look

125
00:09:01,920 --> 00:09:07,560
at what was the depth of the tree, what was the variance of the forest, what was the cross

126
00:09:07,560 --> 00:09:12,520
for the data accuracy, and then we look at the data points, for example what was the probability

127
00:09:12,520 --> 00:09:18,000
to belong to a certain class for a certain point, and we have how much in this situation,

128
00:09:18,000 --> 00:09:20,760
this particular data point reduced the error.

129
00:09:20,760 --> 00:09:26,560
So based on this data, after we collected for all synthetic data sets, we can train a regressor

130
00:09:26,560 --> 00:09:31,600
that will predict in the future, based on the state of the classifier, and given data

131
00:09:31,600 --> 00:09:37,040
points from the pool of unlabeled data, which of them would result in the highest reduction

132
00:09:37,040 --> 00:09:41,840
in error, and this is the sample that we select to be annotated.

133
00:09:41,840 --> 00:09:48,280
And we all started with this very simple two-dimensional data, and of course the easiest is to train

134
00:09:48,280 --> 00:09:53,520
it on the similar kind of data, and this is our simplest scenario, then we try to complicate

135
00:09:53,520 --> 00:10:00,600
it more and more, for example we deal with the soil-like problems when we have a classification

136
00:10:00,600 --> 00:10:05,520
where the data is in the form of checkerboard, and imagine so we have like positive class,

137
00:10:05,520 --> 00:10:10,360
negative class, positive class, negative class, or they're kind of repeating in the checkerboard

138
00:10:10,360 --> 00:10:11,680
style.

139
00:10:11,680 --> 00:10:16,840
And this kind of data sets are more tricky for machine learning, usually and active learning

140
00:10:16,840 --> 00:10:18,480
is not an exception.

141
00:10:18,480 --> 00:10:24,240
And if we apply the very famous and very popular uncertainty something algorithm, that

142
00:10:24,240 --> 00:10:30,760
is often difficult to outperform in normal situations, in this case it would perform even

143
00:10:30,760 --> 00:10:36,360
worse than random, because it is confused by this checkerboard structure.

144
00:10:36,360 --> 00:10:42,360
And is the difficulty with this structure because the regions are non-contiguous or is

145
00:10:42,360 --> 00:10:43,360
it something else?

146
00:10:43,360 --> 00:10:48,840
The thing is that for example if we imagine the checkerboard is 2x2, so we have, suppose

147
00:10:48,840 --> 00:10:54,400
we have rent class on the top left, then blue class on the top right, and then blue

148
00:10:54,400 --> 00:11:01,960
class again on the bottom left, 10 red class on the bottom right, suppose that we selected

149
00:11:01,960 --> 00:11:07,920
one sample from the upper red class, and one sample from the upper blue class as our

150
00:11:07,920 --> 00:11:12,880
initial examples, then we construct some kind of decision boundary, and what and so does

151
00:11:12,880 --> 00:11:17,960
something we do, we would try to refine this boundary and it would take a very long time

152
00:11:17,960 --> 00:11:23,200
to discover that there are two other regions of these classes that are in completely different

153
00:11:23,200 --> 00:11:24,200
order.

154
00:11:24,200 --> 00:11:29,240
So what uncertainty something is good at is it's refining boundary when we already have

155
00:11:29,240 --> 00:11:33,160
some reasonable approximation of this boundary.

156
00:11:33,160 --> 00:11:38,960
And this can be a problem in many real data sets when one class can be represented by

157
00:11:38,960 --> 00:11:42,960
some several modalities of examples.

158
00:11:42,960 --> 00:11:46,920
And so in this case we show that then this very popular algorithm performs worse than

159
00:11:46,920 --> 00:11:51,440
just random something, by random something I mean that we would just select data, random,

160
00:11:51,440 --> 00:11:53,440
and then we label everything.

161
00:11:53,440 --> 00:12:00,160
So it's definitely not a very efficient strategy, but in this case it does better than uncertainty

162
00:12:00,160 --> 00:12:01,160
something.

163
00:12:01,160 --> 00:12:05,800
However, if we learn this strategy from the previous examples of this active learning

164
00:12:05,800 --> 00:12:11,920
runs, it figures out that it shouldn't follow the strategy of refining the boundary.

165
00:12:11,920 --> 00:12:15,720
And for example, in this case what it seems that it learns is that when the classifier

166
00:12:15,720 --> 00:12:22,560
is uncertain, it's better not to trust it at all, not to follow any of the predictions

167
00:12:22,560 --> 00:12:27,360
of the classifier, but instead just do some random exploration in the beginning until

168
00:12:27,360 --> 00:12:33,880
we collect enough data on which we can train a better classifier.

169
00:12:33,880 --> 00:12:38,360
And then we would be able to refine the boundary that would be more efficient.

170
00:12:38,360 --> 00:12:44,880
And so this method doesn't involve trying to identify data points that are close to your

171
00:12:44,880 --> 00:12:46,360
decision boundary.

172
00:12:46,360 --> 00:12:48,200
No, not anymore.

173
00:12:48,200 --> 00:12:49,200
Okay.

174
00:12:49,200 --> 00:12:56,160
So as a feature, as we have the regressor, it has some features as an input.

175
00:12:56,160 --> 00:13:01,160
And some of them are features of the classifier that just characterize how certain our classifier

176
00:13:01,160 --> 00:13:06,680
is, how good is cross-validated accuracy, for example.

177
00:13:06,680 --> 00:13:09,480
And then some features they characterize the data points.

178
00:13:09,480 --> 00:13:13,680
And one of the features could be the distance to the boundary, but it can also include some

179
00:13:13,680 --> 00:13:14,680
other features.

180
00:13:14,680 --> 00:13:19,720
For example, we can look at the distance to the other labeled points or distance to the

181
00:13:19,720 --> 00:13:21,120
unlabeled points.

182
00:13:21,120 --> 00:13:26,120
For example, it can characterize for us if the point is an outlier or if it lies in the

183
00:13:26,120 --> 00:13:28,920
dense region of the feature space.

184
00:13:28,920 --> 00:13:34,720
So it includes many more features and including the distance to the boundary.

185
00:13:34,720 --> 00:13:42,600
But then if I study how much each of these features influences the decision of the regressor,

186
00:13:42,600 --> 00:13:47,080
the decision of which point to select by the active learning strategy, the distance to

187
00:13:47,080 --> 00:13:51,240
the boundary is not the first and most important criteria.

188
00:13:51,240 --> 00:13:56,720
It comes maybe like the fourth and the first one was actually the certainty, the confidence

189
00:13:56,720 --> 00:13:58,320
of the classifier.

190
00:13:58,320 --> 00:14:03,960
So the strategy is adaptive as the active learning progresses and we collect more and

191
00:14:03,960 --> 00:14:04,960
more data.

192
00:14:04,960 --> 00:14:10,400
The classifier becomes more and more confident and the strategy adapts accordingly.

193
00:14:10,400 --> 00:14:16,240
And next we try to test this kind of algorithm that was learned from the data on the real

194
00:14:16,240 --> 00:14:20,920
data sets that are very different from these synthetic examples.

195
00:14:20,920 --> 00:14:28,320
In the synthetic examples we just had this two-dimensional features for the data points, but you

196
00:14:28,320 --> 00:14:32,720
cannot go very far with it and it doesn't sound like a very exciting problem in the

197
00:14:32,720 --> 00:14:33,720
learning.

198
00:14:33,720 --> 00:14:38,480
It definitely won't help us to classify cats.

199
00:14:38,480 --> 00:14:46,680
So next we move to the real data sets and I'm a part of human brain project that is

200
00:14:46,680 --> 00:14:53,360
a very big European project with a huge funding trying to address the problem of understanding

201
00:14:53,360 --> 00:14:59,000
how human brain functions and there are many many researchers who work on it from very

202
00:14:59,000 --> 00:15:05,320
different perspectives, biologists, neuroscientists, physicists and all kind of people.

203
00:15:05,320 --> 00:15:10,080
And so I'm also part of this project is trying to understand brain imaging.

204
00:15:10,080 --> 00:15:16,720
For example we're dealing with the electron microscopy scans of red tissue, of red brain

205
00:15:16,720 --> 00:15:21,520
tissue and we're trying to segment some cellular structures in it.

206
00:15:21,520 --> 00:15:27,480
For example we're on the cellular resolution and we can see the mitochondria, the synopsis

207
00:15:27,480 --> 00:15:32,960
between neurons, we can identify membranes or other kinds of things.

208
00:15:32,960 --> 00:15:37,560
So the other application which I'm interested is having MRI scans of the brain and try

209
00:15:37,560 --> 00:15:43,240
to segment brain tumor of different types.

210
00:15:43,240 --> 00:15:49,680
And then I apply the same kind of strategy that I learned on the synthetic data to this

211
00:15:49,680 --> 00:15:55,720
real data sets of much higher dimensionality, much higher complexity.

212
00:15:55,720 --> 00:16:02,160
And also I have a very different data set for example for detecting credit card fraud transactions.

213
00:16:02,160 --> 00:16:08,760
So I have transactions from the bank for which we know that 99% of them are normal transactions

214
00:16:08,760 --> 00:16:13,480
and then we have around 1% or even less of fraud transactions.

215
00:16:13,480 --> 00:16:18,600
And it's also very laborious task to annotate this kind of data because you need to annotate

216
00:16:18,600 --> 00:16:25,320
like thousands of data points before you start having only a dozen of examples of fraud.

217
00:16:25,320 --> 00:16:27,400
And this is only humans they can do it.

218
00:16:27,400 --> 00:16:33,480
And the same goes of course for this biomedical imaging like as a person who's not into biology

219
00:16:33,480 --> 00:16:38,800
or neuroscience it is a very hard task to understand what is going on.

220
00:16:38,800 --> 00:16:44,400
And the time of these people is quite expensive and we would better want them spend it on something

221
00:16:44,400 --> 00:16:48,680
more intelligent rather than annotating data for algorithms.

222
00:16:48,680 --> 00:16:54,120
So these are the applications where active learning is the most interesting in cases when

223
00:16:54,120 --> 00:17:00,360
only very specialized and educated humans can annotate data for us.

224
00:17:00,360 --> 00:17:04,160
And in this case we also apply the same kind of strategy that we learned from synthetic

225
00:17:04,160 --> 00:17:05,160
data.

226
00:17:05,160 --> 00:17:11,000
And surprisingly it works even in this cases it can generalize to very different data sets

227
00:17:11,000 --> 00:17:18,160
and how we understand it is that it learns a very general knowledge about active learning.

228
00:17:18,160 --> 00:17:24,320
For example the rule such as when the classifier is uncertain do random exploration and when

229
00:17:24,320 --> 00:17:27,880
classifier is rather certain refine the boundary.

230
00:17:27,880 --> 00:17:32,760
This should hold no matter how the data set looks like and it would hold in the case of

231
00:17:32,760 --> 00:17:38,480
this simple to dimensional data and the case of very complex electron microscopy imaging

232
00:17:38,480 --> 00:17:39,840
data.

233
00:17:39,840 --> 00:17:43,960
And so is the idea you know when you take a step back and think about this in the context

234
00:17:43,960 --> 00:17:52,360
of a system like the imaging data is the idea that you yeah how does this unfold in practice

235
00:17:52,360 --> 00:17:58,280
like you have some minimal set of training data and then you're envisioning that you

236
00:17:58,280 --> 00:18:06,600
would generate some other set of data and kind of send it out for annotation or okay I see

237
00:18:06,600 --> 00:18:12,680
so okay now example for example let's talk about this electron microscopy segmenting

238
00:18:12,680 --> 00:18:19,080
cellular structures how we imagine it is that the user has a stack of tissues so it's actually

239
00:18:19,080 --> 00:18:25,960
not a real image it's a three-dimensional image so it's kind of a cube and in whatever direction

240
00:18:25,960 --> 00:18:30,760
we look at it we can count it in all directions and we'll get to the images of how the tissue

241
00:18:30,760 --> 00:18:32,280
looked like that.

242
00:18:32,280 --> 00:18:38,240
And so what we ask at the beginning as the user to kind of take a brush and some program

243
00:18:38,240 --> 00:18:45,120
and indicate here is like some part of mitochondria and here is a part of background and then based

244
00:18:45,120 --> 00:18:50,960
on this our model would train some initial classify a very very very rough one that would

245
00:18:50,960 --> 00:18:55,680
just like say okay mitochondria is for example they're darker than background on average so

246
00:18:55,680 --> 00:19:00,800
let's just use this as discriminative feature it would train such a model and then there will

247
00:19:00,800 --> 00:19:05,280
be some kind of grayish part in the tissue and it would think that classify I would think

248
00:19:05,280 --> 00:19:10,400
I'm not sure what it belongs to does it belong to mitochondria or does it belong to the

249
00:19:10,400 --> 00:19:17,360
background and then the active learning would select this as the some special part in the tissue

250
00:19:17,360 --> 00:19:22,240
which we want to be annotated and then it brings the user to this part of the tissue and kind of

251
00:19:22,240 --> 00:19:27,440
highlights this error in which we would like to get more labels and ask the user please get

252
00:19:27,440 --> 00:19:33,360
take a brush again and indicate whether this particular error is background or if this particular

253
00:19:33,360 --> 00:19:38,960
error is mitochondria and then the user annotates it's again and then the procedure iterates

254
00:19:39,680 --> 00:19:45,920
until we're satisfied with results or until some budget of time is reached or something of the type

255
00:19:46,560 --> 00:19:51,840
and do you have that whole system running at this point end to end or you more modeling it from

256
00:19:51,840 --> 00:19:58,080
the data itself so right now I was mostly working just with from the data okay so we already have

257
00:19:58,080 --> 00:20:04,000
the labeled data and we simulate this active learning procedure because in this case we can of

258
00:20:04,000 --> 00:20:10,320
course test many strategies we can study how different parameters influence our algorithms we

259
00:20:10,320 --> 00:20:15,840
can compare to many strategies but we actually have students and master's student who is working

260
00:20:15,840 --> 00:20:24,320
on putting it into a plugin that the neuroscientist would use and I actually know some people who work

261
00:20:24,320 --> 00:20:31,360
in neuroscience and I know one girl whose PhD topic is mostly at identifying mitochondria

262
00:20:31,360 --> 00:20:37,920
and trying to understand how they influence the neural diseases and the human brain and what she

263
00:20:37,920 --> 00:20:45,680
does is a big part of her PhD work she's just she has to annotate this data manually and I believe

264
00:20:45,680 --> 00:20:51,520
that she's very knowledgeable and she can do something more useful at that time if we can provide

265
00:20:51,520 --> 00:20:58,160
her with this plugin that only with you know 100 samples can provide the same quality of

266
00:20:58,160 --> 00:21:04,560
classification as with 10,000 samples for example so in some cases we can reduce the annotation

267
00:21:04,560 --> 00:21:13,200
effort like very significantly so is that you know going from 10,000 required samples to 100 is

268
00:21:13,200 --> 00:21:19,760
that representative of the kind of results you've seen for different scenarios you mean across

269
00:21:19,760 --> 00:21:24,640
different applications right okay it depends on the application how much active learning can

270
00:21:24,640 --> 00:21:31,040
actually improve our results okay yeah so in some cases we can get a very dramatic decrease

271
00:21:31,680 --> 00:21:39,280
in the annotation time in some cases it's not that much but in any case we're reaching the same

272
00:21:39,280 --> 00:21:45,200
quality faster and we can stop the procedure at any time when we reach the budget of time and

273
00:21:45,200 --> 00:21:50,400
the classifier that we constructed at that point of time would be better than what we would construct

274
00:21:50,400 --> 00:21:58,160
if we just sample points at random then the thing that we can look at is how human friendly this

275
00:21:58,160 --> 00:22:05,840
kind of annotation environment is for example in my previous work I worked particularly for images

276
00:22:05,840 --> 00:22:13,520
and I tried to design a particular strategy for the 3D imaging stacks and in this case what we

277
00:22:13,520 --> 00:22:19,520
were saying is that it is very cumbersome if we have to annotate the stack just kind of pixel by

278
00:22:19,520 --> 00:22:24,080
pixel suppose that you are brought like in some part of the stack and ask to annotate what is

279
00:22:24,080 --> 00:22:29,040
here then you brought to some other place you ask to annotate something then some islands and other

280
00:22:29,040 --> 00:22:33,840
and it can actually take quite a lot of time just because of this context switches and you have to

281
00:22:33,840 --> 00:22:40,560
understand what is going on and like it's also trivial to understand how this neurons connect

282
00:22:40,560 --> 00:22:45,120
with each other for example so one thing that we're looking at we're trying to find some

283
00:22:45,120 --> 00:22:51,600
optimal cuts in this 3D plane so we're just cutting them in various directions and we're projecting

284
00:22:51,600 --> 00:22:57,360
data on this direction on these planes on these cuts and we're trying to annotate some batches

285
00:22:57,360 --> 00:23:03,760
of samples instead of asking to annotate one by one whatever samples are you can try to think of

286
00:23:03,760 --> 00:23:09,360
it kind of like maximum uncertainty cuts or something yeah so we had some some uncertainty measure

287
00:23:09,360 --> 00:23:15,760
that wasn't like maybe not a standard one but something special for the images but then here we're

288
00:23:15,760 --> 00:23:22,960
trying to find a cut with a maximum uncertainty and then there are other ways to work on this

289
00:23:22,960 --> 00:23:29,360
direction so in as I see it in active learning there are two components one of them is we want to

290
00:23:29,360 --> 00:23:34,160
design an algorithm that would select the best possible sample but on the other hand we should

291
00:23:34,160 --> 00:23:39,840
still remember that there will be humans annotate data for us so we should make it as convenient and

292
00:23:39,840 --> 00:23:47,520
as easy for humans to label the data and yeah another thing that I've been working on also in

293
00:23:47,520 --> 00:23:54,960
this direction is getting label data for object detection so the problem is very different we just

294
00:23:54,960 --> 00:24:00,400
like want to localize objects in images like I don't know the bottle the TV screen a human

295
00:24:00,400 --> 00:24:06,160
and these kind of things and there are various and for this we need bounding box annotations so we

296
00:24:06,160 --> 00:24:12,640
need someone to draw a bounding box around every object and from this with chain and there are

297
00:24:12,640 --> 00:24:17,840
various ways how we can collect it we can ask the humans to draw it manually this kind of this is

298
00:24:17,840 --> 00:24:22,880
the normal way of doing it but on that the hand we already have some kind of detectors that maybe

299
00:24:22,880 --> 00:24:28,000
not as strong as we would like them to be but we can already try to use the output of these

300
00:24:28,000 --> 00:24:34,000
detectors and show them show it to the users and as the users to correct for the mistakes and

301
00:24:34,000 --> 00:24:39,520
this is what we're talking about mistakes in terms of identifying the bounding boxes or labeling

302
00:24:39,520 --> 00:24:45,040
what's in the bounding boxes or both okay so now I'm talking about identifying the location of

303
00:24:45,040 --> 00:24:50,320
the bounding box because in this scenario we simplify the problem and we say that we already have

304
00:24:50,320 --> 00:24:56,480
image level annotations so we already know that there is a bottle in this image there is a door

305
00:24:56,480 --> 00:25:01,840
in this image and now we want to know where this door is okay so we split the problem in two

306
00:25:01,840 --> 00:25:06,880
separate ones and we deal with the second one where we want to get the coordinates of this

307
00:25:06,880 --> 00:25:13,200
bounding boxes okay and in this case on the one hand if we ask humans to draw an object it is

308
00:25:13,200 --> 00:25:20,640
very fast it is not very fast it takes in the very in kind of in the standard protocols it might

309
00:25:20,640 --> 00:25:28,080
take up to 35 seconds to get a one bounding box per image and we need thousands of them for

310
00:25:28,080 --> 00:25:35,840
every class which results like in years and years of human work and on the other hand if we ask

311
00:25:35,840 --> 00:25:41,680
the users to verify the prediction of the classify it can be very fast it takes around two seconds

312
00:25:41,680 --> 00:25:48,400
for example just to say yes or no if it is a correct identification of the object but it is not

313
00:25:48,400 --> 00:25:54,640
guaranteed to provide a bounding box that we would like to get so if the user answers no we have

314
00:25:54,640 --> 00:26:00,160
to repeat the procedure again and we have to ask the user again where the box was so what we are

315
00:26:00,160 --> 00:26:05,120
trying to do in this work we are trying to balance between these two modalities of data

316
00:26:05,120 --> 00:26:12,240
annotation and trying to decide in what situations it's better to ask to draw a bounding box that is

317
00:26:12,240 --> 00:26:18,400
expensive but guaranteed to produce a label and with which situations it's easier to verify

318
00:26:19,280 --> 00:26:26,560
the detection detected proposals and to result in a positively verified box quicker

319
00:26:27,360 --> 00:26:32,640
and is the methodology the same for this project as the one you previously described?

320
00:26:32,640 --> 00:26:38,960
no it's not exactly the same but what unifies them is that we're still dealing with the problem

321
00:26:38,960 --> 00:26:44,720
of reducing human efforts just approaching it from the other direction so one direction is

322
00:26:44,720 --> 00:26:51,040
select what to annotate and the other direction select how to annotate so what I believe is that

323
00:26:51,040 --> 00:26:57,280
both of them would be important and if we just deal with one of them we can get some good results

324
00:26:57,280 --> 00:27:03,040
on paper and some simulations but in practice both of these directions would be important

325
00:27:03,040 --> 00:27:11,680
interesting I'm curious about how the system would go about directing the annotator to a

326
00:27:11,680 --> 00:27:20,320
specific area meaning you have these you have these data points that are annotated what is it

327
00:27:20,320 --> 00:27:25,360
asking for is it asking for like some coordinate does it know like coordinates of uncertainty or

328
00:27:25,360 --> 00:27:31,600
does it know something else okay so I didn't go into details of the protocol but actually how

329
00:27:31,600 --> 00:27:38,240
we start the task is to segment something to segment mitochondria's and we started from

330
00:27:38,240 --> 00:27:44,880
over-sigmenting images so we use something that is called sleek super pixels or sleek super voxels

331
00:27:44,880 --> 00:27:51,680
so the idea is that it is unsupervised method that can provide segmentation of the image of the

332
00:27:51,680 --> 00:28:00,000
very fine fine grain that is not reflecting actually the boundaries of the object but the uniform

333
00:28:00,000 --> 00:28:06,480
more or less so we get like very small segments in the images that are all more or less uniform

334
00:28:06,480 --> 00:28:13,280
in their appearance and every object would compile would consist for example of 100 of such objects

335
00:28:13,280 --> 00:28:20,880
of this super voxels or super pixels and then what the algorithm the active learning algorithm

336
00:28:20,880 --> 00:28:27,040
identifies it selects which super voxel is the most uncertain and are the super voxels they're

337
00:28:27,040 --> 00:28:32,960
all uniform in shape and size yes this is the property of this sleek super voxels is that a

338
00:28:32,960 --> 00:28:40,160
more or less uniform and of a shape that is close to spherical or circular depending if it's 3D

339
00:28:40,160 --> 00:28:47,520
or 2D stacks and so you can have multiple adjacent super voxels that are the same value essentially

340
00:28:47,520 --> 00:28:54,720
the same color or yes yes so it's still even if there is a very uniform part of the image it would

341
00:28:54,720 --> 00:29:00,240
still try to divide it in some way so that they're still kept of more or less the same size

342
00:29:00,240 --> 00:29:06,240
okay the same shape it depends on the parameters how you specify it's it's unsupervised algorithm

343
00:29:06,240 --> 00:29:11,760
but you need to identify how compact you want them to be how smooth you want them to be this kind

344
00:29:11,760 --> 00:29:17,120
of things but what we're trying to do is like to have them roughly circular small objects

345
00:29:17,120 --> 00:29:22,960
okay and the overlapping no they're not overlapping so it's just kind of assignment of every pixel

346
00:29:22,960 --> 00:29:29,120
of the object to a super pixel okay so we call they're called super pixels because they consist

347
00:29:29,120 --> 00:29:35,680
of multiple pixels or super voxels the same for voxels okay and then what active learning does

348
00:29:35,680 --> 00:29:42,240
it select super voxel or super pixel that needs to be annotated in this case or in case of

349
00:29:42,960 --> 00:29:50,560
this identifying the planes it just identifies the error with several super voxels that are uncertain

350
00:29:50,560 --> 00:29:56,320
so in this case it would be just as if we have an image and then we highlight some kind of round

351
00:29:56,320 --> 00:30:02,800
errors and that we're interested in annotations there okay yeah and there were also suggesting that

352
00:30:02,800 --> 00:30:08,960
if the objects are big enough like mitochondria are rather big and the selected error that we want

353
00:30:08,960 --> 00:30:14,560
to use it to annotate is small we can approximate it that just with two clicks of the mouse just

354
00:30:14,560 --> 00:30:21,040
identifying the boundary of mitochondria if it is in the image so it makes it even faster like this

355
00:30:21,040 --> 00:30:26,080
okay so this is another example of working on this other direction of how convenient it is for

356
00:30:26,080 --> 00:30:32,240
user to annotate the data combines together with the algorithm that selects what to annotate

357
00:30:32,240 --> 00:30:39,280
okay and so if the presumably if you're if the user task is to then identify whether the

358
00:30:39,280 --> 00:30:46,560
boundary is in the image or in the the voxel super voxel then you can kind of go from there to

359
00:30:46,560 --> 00:30:52,240
multiple super voxels with boundaries and determine which is where the mitochondria is is that

360
00:30:52,240 --> 00:30:59,840
what you're saying so how it looks like is that suppose we have a circle that overlaps the mitochondria

361
00:30:59,840 --> 00:31:05,040
bit but because mitochondria is rather big compared to the size of the circle right the boundary

362
00:31:05,040 --> 00:31:10,960
of mitochondria is more or less just a line yeah and we can ask the user to draw this line with two

363
00:31:10,960 --> 00:31:19,360
clicks and to identify on which side the the mitochondria is right and then it would we are able

364
00:31:19,360 --> 00:31:25,040
from this line we're able to go towards the assignment of super voxels to particular classes

365
00:31:25,040 --> 00:31:29,840
so when we have just that one assignment in this one super voxel can tell you

366
00:31:29,840 --> 00:31:37,520
a whole about the whole area exactly yeah okay interesting interesting um well this is

367
00:31:37,520 --> 00:31:42,720
really fascinating work I appreciate you taking the time to to share it with us work and folks

368
00:31:42,720 --> 00:31:50,080
learn more about your research do you have a website up on uh yes I have a website that is

369
00:31:50,080 --> 00:31:57,680
xenia.conishcaller.com and I try to keep it more or less updated about the recent research that

370
00:31:57,680 --> 00:32:03,040
I'm doing for example what I mentioned today the work about bounding boxes I just finished

371
00:32:03,600 --> 00:32:08,800
an internship last Friday at Google Research in Zurich okay and this is a project that we're

372
00:32:08,800 --> 00:32:17,040
working on okay and it's soon to be there and okay before it is going to appear anywhere else

373
00:32:17,040 --> 00:32:20,720
awesome awesome well thank you once again yeah thank you

374
00:32:20,720 --> 00:32:30,080
oh all right everyone that's our show for today for more information on cousinia or any of the

375
00:32:30,080 --> 00:32:37,760
topics covered in this episode head on over to twimlai.com slash talk slash 116 if you haven't

376
00:32:37,760 --> 00:32:43,120
already done so make sure you head on over to iTunes as well to leave us your most gracious

377
00:32:43,120 --> 00:32:49,280
rating and review it helps new listeners finds us which helps us grow and of course

378
00:32:49,280 --> 00:32:55,040
thanks so much for listening and catch you next time

