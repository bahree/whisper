1
00:00:00,000 --> 00:00:22,360
All right, everyone, I am here with Abhishek Thakur. Abhishek is a machine learning engineer at Huggingface and the world's first quadruple Kaggle Grandmaster. Abhishek, welcome to the Twoma AI podcast.

2
00:00:22,360 --> 00:00:31,360
Thank you very much, Sam, for inviting me here. I'm really excited to be here. I'm super excited to jump into our conversation as well.

3
00:00:31,360 --> 00:00:40,360
Let's start as we often do here on the podcast with having you share a little bit about your background. How did you come to work in machine learning?

4
00:00:40,360 --> 00:01:08,360
Sure, that's a long story where do I start from? So I think it all started from my internship that I was doing during my bachelor's and I was studying electronics engineering and I got an internship at University of Warwick where I was supposed to be working on pathological images.

5
00:01:08,360 --> 00:01:25,360
And that's where I came to know about random forest. I didn't know what it is, but I just heard the name. And then I was in the image processing part of the image analysis.

6
00:01:25,360 --> 00:01:42,360
So I wasn't doing a lot of machine learning. When I came back, I went to a university upon where I was doing my master's in computer science because I always wanted to study computer science. And they're also my favorite subjects were image processing and computer vision, not machine learning or deep learning.

7
00:01:42,360 --> 00:02:01,360
So I was working at front of her and a lot of friends of mine were talking about machine learning. They were working machine learning and because of that, that I got interested in machine learning and deep learning and data science and then I found Kaggle and I started doing some completions learning yet on my own.

8
00:02:01,360 --> 00:02:15,360
So that's where it started like back in 2010, 11. That's awesome. That's awesome. I'd love to hear you share a little bit about your journey with Kaggle. What was your first competition and how did you approach it?

9
00:02:15,360 --> 00:02:34,360
Okay, my first competition is it's I think it was facial expression recognition or emotion recognition something something like that. So you were given a lot of facial images and you had to predict what kind of emotion it is. I think it was that.

10
00:02:34,360 --> 00:02:52,360
I'm not so sure anymore. What I did was I was using MATLAB because at that time I didn't know Python and I was using my old school image processing skills to figure out the emotions of these pictures.

11
00:02:52,360 --> 00:03:06,360
There were not so many computers in that competition because it required a lot of hardware, I guess, and at that time GPUs were very expensive deep learning was new and this was back in, I think, 2013.

12
00:03:06,360 --> 00:03:18,360
So long time ago and deep learning was new. I think at that time, a lot of people were just using random forest for everything.

13
00:03:18,360 --> 00:03:30,360
So I did some basic stuff in that competition ended up being at the middle of the leaderboard and that was like there were only 50 60 people in that competition.

14
00:03:30,360 --> 00:03:32,360
So it was very interesting.

15
00:03:32,360 --> 00:03:39,360
The guys who won the competition use deep learning. So there I got to know what neural networks are.

16
00:03:39,360 --> 00:03:54,360
So it was it was a good beginning for me and I saw that it's much easier if you use Python. So I started learning Python and nobody, nobody used MATLAB in that competition.

17
00:03:54,360 --> 00:04:03,360
And MATLAB is also not free. So you have to buy the license and Python is free. And Python is always active.

18
00:04:03,360 --> 00:04:21,360
So when I started with the Android and lecture, he was using Octave for everything. But Python is also very similar. So some people think it's going to take them a lot of time to switch from MATLAB or Octave to Python, but it's not like that. It's quite similar.

19
00:04:21,360 --> 00:04:24,360
The syntax and all.

20
00:04:24,360 --> 00:04:39,360
So how many competitions have you done so far? Oh my god, difficult question. I haven't kept track. So I tried to I just tried to jump in a competition. I don't do all competition seriously.

21
00:04:39,360 --> 00:04:54,360
So I don't invest much time as normal competitors in a given competition. So I just pick up a competition. I do some of my own stuff. I submit the result even if I rank 1000. It's OK.

22
00:04:54,360 --> 00:05:09,360
Because I haven't shown any effort there. Right. So I think right now I participate in more than 200 competitions, including, including Kaggle and everything else like driven data.

23
00:05:09,360 --> 00:05:11,360
So these are things.

24
00:05:11,360 --> 00:05:18,360
That's great. And are you still actively participating in those or you focus on other things nowadays?

25
00:05:18,360 --> 00:05:33,360
I used to have a lot of time to participate in competitions. Actually Kaggle was one of the websites I found very early. And that's how I began my journey into data science. And at that time, data science was also very new.

26
00:05:33,360 --> 00:05:44,360
But there were not a lot of people in data science and machine learning. So you really had to build a strong profile to get a job in data science as a fresher.

27
00:05:44,360 --> 00:05:59,360
So that's where Kaggle helped me a lot. I used to invest a lot of time. I used to probably spend few nights, pull all nighters several times a week. But nowadays I cannot do that because I have a day job.

28
00:05:59,360 --> 00:06:20,360
I have to be focused there. And I also I'm also doing a lot of different other things like making YouTube videos or sharing stuff on social media. So I really don't have much time for Kaggle. But I tried to participate in a competition seriously, like once a year or two or three times a year.

29
00:06:20,360 --> 00:06:33,360
Not so much. Now people on the commercial side will often kind of turn their noses up and Kaggle and say, Hey, there's a real world problem. It's not a Kaggle competition as if Kaggle competitions are bad.

30
00:06:33,360 --> 00:06:44,360
But you've invested a lot of time in them, participated in a lot of that presumably you've learned a ton with Kaggle competitions. How do you react when people respond that way?

31
00:06:44,360 --> 00:06:55,360
They are not wrong. But they are also not entirely correct. When you're working on a Kaggle competition, you get data which is clean.

32
00:06:55,360 --> 00:07:03,360
But if you go to the competition forums, people still complain that the data is not clean. So people are always going to complain.

33
00:07:03,360 --> 00:07:17,360
And getting the data is the hardest part when when you're working in industry, when you're working in some companies, you will see you spend more time getting the data and gathering everything from all all the infrastructure that you have.

34
00:07:17,360 --> 00:07:30,360
And then modeling is a very small part of your job and you're still a machine learning engineer or a data scientist. You're doing analysis, but you spending 78% of your time just collecting the data or cleaning the data.

35
00:07:30,360 --> 00:07:43,360
So in this regard, Kaggle is very different from the industries, but when we talk about what you learn from doing Kaggle competitions, can you apply them to industries? Of course you can.

36
00:07:43,360 --> 00:07:53,360
So even if even if you're doing competitions in different domains, you can just use the knowledge that you have gained doing those competitions and apply to real world scenarios.

37
00:07:53,360 --> 00:08:06,360
And I have done that in the past. I still do that. And I think that's one of the best way to learn and people say like when you go to industry, when you're working in a company, you learn the most, right.

38
00:08:06,360 --> 00:08:18,360
And this is also very similar when you're practicing the problems and you're trying to compete with others, you see what others are doing and you're trying to build something better on top of what others have built.

39
00:08:18,360 --> 00:08:30,360
So this is also a good way to learn and you do the same in industries and companies, you work in teams, here also you work in teams. So these kind of things.

40
00:08:30,360 --> 00:08:41,360
What are the biggest things that you've learned in participating in Kaggle competitions, if you had to name a few top takeaways.

41
00:08:41,360 --> 00:08:56,360
So one of the most, one of the most important things that I learned was how to handle categorical variables. So there was a competition several years ago called Amazon Employee Access Challenge.

42
00:08:56,360 --> 00:09:12,360
And in that challenge, it was all about categorical variables and people presented there like we didn't have Kaggle Kernel. So people would write code in discussion forums or just upload their Python scripts there and there was just so much to learn in that combination.

43
00:09:12,360 --> 00:09:25,360
So I still consider it as a very good example, if you want to learn about categorical variables and how to handle categorical variables in many different ways, you should go and take a look at Amazon Employee Access Challenge.

44
00:09:25,360 --> 00:09:52,360
So there's that and then when Kaggle introduced these code competitions, one of the things that you learn is how to run your code given a time limit. So which is also very important in the industry, if you're building models which you want to put in production, they should be reliable enough and they should also have a very low latency.

45
00:09:52,360 --> 00:10:09,360
So it should be able to do a lot of jobs in less amount of time. And I think that's also a good thing to learn. Then I learned how to approach different kinds of problems like images, time series problems, text data, what kind of different.

46
00:10:09,360 --> 00:10:25,360
For text data, there haven't been a lot of competition for, but for images, there's so many competitions going on on Kaggle all the time. And for different kinds of image problems like object detection, segmentation, classification.

47
00:10:25,360 --> 00:10:35,360
So there's a lot to learn from from these competitions and it also helps you like building your portfolio approach.

48
00:10:35,360 --> 00:10:50,360
So I started out with a focus on computer vision and now you're spending much of your time on the natural language processing. How did you end up at hugging face.

49
00:10:50,360 --> 00:11:07,360
So I've always been interested in natural language processing and the companies that have worked before in past few years, they have always been focused on natural language processing problems.

50
00:11:07,360 --> 00:11:25,360
So hugging face is for hugging face, I was talking to Thomas who is one of the founders of hugging face that I have an idea and let's try to build something. And he was, he was also very interested in implementing that idea and that was about alternative.

51
00:11:25,360 --> 00:11:30,360
So that's how I started working with hugging face.

52
00:11:30,360 --> 00:11:42,360
And so there, so I didn't realize that you were the originator of the auto and LP idea there. Maybe tell us a little bit about the idea and where it came about.

53
00:11:42,360 --> 00:11:49,360
I won't say if I was the originator because even I don't know that, but I did start the project.

54
00:11:49,360 --> 00:12:09,360
So I've always been interested in automatic machine learning when I was doing my PhD, my one of the major things that I was focusing on was recommendation systems and at the same time, machine learning was very popular.

55
00:12:09,360 --> 00:12:23,360
So there was a competition called the auto ml challenge and it used to there are auto ml workshops in ICML and they used to organize this auto ml challenge.

56
00:12:23,360 --> 00:12:37,360
So I took part in those challenges and I won some, I got my first GPU because of the auto ml challenge and it was very interesting for me to see like, okay.

57
00:12:37,360 --> 00:12:50,360
You don't need a lot of complicated things to build the automatic machine learning system. It's all about, it's all about what to use when the data is blah blah blah.

58
00:12:50,360 --> 00:13:01,360
So something like this, and if you know that like for me, if I have taken part in now 200 completions, I don't spend much time doing exploratory analysis, I should do that.

59
00:13:01,360 --> 00:13:11,360
Before that, but even before that, I tried to build a model and I tried to see, okay, now I have a baseline, now I will go and do the EDA part.

60
00:13:11,360 --> 00:13:29,360
So, after, after the, had you built up in the course of building out, in the course of competing in so many competitions, have you had you build out like your own frameworks that you use for lots of different competitions.

61
00:13:29,360 --> 00:13:40,360
During the time of my PhD, we did build a framework, but we never got to publish it because I quit my PhD after one year and then I went back to the industries.

62
00:13:40,360 --> 00:13:48,360
So this idea was always there, I always wanted to do something with auto automatic machine learning and then I thought, why not NLP?

63
00:13:48,360 --> 00:14:05,360
Because no one is doing crazy things like with NLP, when it comes to automated machine learning or and when we look at hugging face, they have all these state of the art models.

64
00:14:05,360 --> 00:14:23,360
So it just makes sense that they should do automatic and actual language processing auto NLP and that's why I thought, okay, it's best to work with hugging face and build this system that people can use.

65
00:14:23,360 --> 00:14:31,360
And so, what were the initial goals of auto NLP? How did you kind of scope the effort?

66
00:14:31,360 --> 00:14:42,360
Initially, when we started, it's quite simple, let's say you have a CSV file and you have text and you have some class associated with that text.

67
00:14:42,360 --> 00:14:56,360
So all you need to do is just upload this file somewhere and it will run a bunch of models, state of the art models like bird, rubber, these kind of models, it's going to do all the hyper parameter tuning for you.

68
00:14:56,360 --> 00:15:15,360
You don't need to worry about anything, you don't need to select batch size, you don't need to select the learning rate or the line length, the number of tokens, you don't need to worry about tokenization, which tokenizer to use for what kind of model, you don't need to worry about anything and you just all you need to do is upload the data and then you get the model.

69
00:15:15,360 --> 00:15:32,360
And hugging face has built such a good infrastructure already that every model that we train using auto NLP is automatically eligible for, let's say eligible for production.

70
00:15:32,360 --> 00:15:46,360
You can you can deploy it in production in one click and that's what people want because people don't want to spend time deploying a model, which is like bird or robot or even larger models.

71
00:15:46,360 --> 00:16:00,360
So the problem domain is a primarily focused on fine tuning a language model or are there other problems that it'll work on like any hour or.

72
00:16:00,360 --> 00:16:20,360
Yeah, you definitely so we currently we have implemented a few different tasks, so we have binary classification, multi class classification, we have regression, we have named entity recognition, we have summarization, we are also expanding to question and answering and translation very soon.

73
00:16:20,360 --> 00:16:39,360
So we have different kinds of tasks, so we currently have not thought much about if you can train your or if you can pre train a language model from scratch, but that should also be possible without NLP, but it does require a lot of infrastructure.

74
00:16:39,360 --> 00:16:50,360
And so where were you finding the most use thus far, the project is relatively young, is that right.

75
00:16:50,360 --> 00:17:02,360
It is, it is indeed quite young, it's we started, I think it was mid or end of December and we released it to public one month ago.

76
00:17:02,360 --> 00:17:10,360
So it's very young, so people are still trying it, we haven't publicized that much.

77
00:17:10,360 --> 00:17:28,360
And we are still thinking about a lot of different things in the project because it's it's it's it's it's like currently it's in it's in baby stages, but it's growing quite fast, so we are adding new models and new tasks every week.

78
00:17:28,360 --> 00:17:33,360
So it's growing quite fast or any of those tasks.

79
00:17:33,360 --> 00:17:40,360
Kind of driving the majority of the interest or is our folks using it for everything.

80
00:17:40,360 --> 00:17:55,360
Folks are using it for mostly people are interested in classification problems and that's one one of the reasons we started with binary classification because everyone has data for binary classification problems and every industry.

81
00:17:55,360 --> 00:18:04,360
Or every person wants to try these models on different types of classification problem and very simple thing would be like sentiment detection.

82
00:18:04,360 --> 00:18:09,360
Everybody wants to build model around sentiment in fiction. I don't know why, but yeah, that's how it is.

83
00:18:09,360 --> 00:18:18,360
And so majority of the focus I would say is around classification, which is quite strong at the moment.

84
00:18:18,360 --> 00:18:28,360
But when we come to when we talk about development, we are working with summarization, so sequence sequence models now.

85
00:18:28,360 --> 00:18:32,360
What is the team look like around auto and LP?

86
00:18:32,360 --> 00:18:37,360
It's not much it's just me and one more person named Simon.

87
00:18:37,360 --> 00:18:48,360
We are two people, but we also have Anthony who is in the infra part, we have Thomas who is leading everything.

88
00:18:48,360 --> 00:18:56,360
So we also have many front-end people like we are also coming up with some kind of graphical user interface.

89
00:18:56,360 --> 00:19:06,360
Currently, everything is based on CLI. So we have people here and there, but only to our working full time on this project.

90
00:19:06,360 --> 00:19:13,360
Would you have imagined that you kind of get so much done in such a short period of time with such a small team?

91
00:19:13,360 --> 00:19:20,360
It's very difficult to accomplish to implement so many different kinds of tasks.

92
00:19:20,360 --> 00:19:24,360
So we deployed the whole infrastructure on humanities.

93
00:19:24,360 --> 00:19:33,360
So that's also like it's a pain to deploy stuff and everything should work and to end all the time.

94
00:19:33,360 --> 00:19:44,360
So yeah, it has been quite a journey, but as I said, it's just the beginning and after a few months, I think things will come down or maybe they never will.

95
00:19:44,360 --> 00:19:48,360
It has never come down for me at least.

96
00:19:48,360 --> 00:19:58,360
But yeah, it's quite fun because when you're working on a fun project like this, you don't really care about time.

97
00:19:58,360 --> 00:20:11,360
So like the project drives you. So there's so much to so much to implement so many things to fix so many ways of doing hyper parameter optimization, different kinds of architecture selection.

98
00:20:11,360 --> 00:20:14,360
So it's quite nice, quite interesting.

99
00:20:14,360 --> 00:20:18,360
You mentioned that you're running everything on Kubernetes.

100
00:20:18,360 --> 00:20:24,360
Is that something that you had experienced with before and how has that experience gone?

101
00:20:24,360 --> 00:20:36,360
So I didn't have much experience with Kubernetes. So I as a data scientist as a machine learning engineer, I could I could deploy a demo project on Kubernetes.

102
00:20:36,360 --> 00:20:41,360
But most of the time it was the operations team that takes care of that.

103
00:20:41,360 --> 00:20:48,360
And here also when when it comes to auto LP, most of the work has been done by the infer team.

104
00:20:48,360 --> 00:20:56,360
Deploying to Kubernetes is something that they have taken care of.

105
00:20:56,360 --> 00:21:01,360
We talked a little bit about kind of your broad lessons learned with Kaggle.

106
00:21:01,360 --> 00:21:14,360
I'm curious if you have a similar set of kind of core lessons from the more recent NLP experience and auto NLP in particular.

107
00:21:14,360 --> 00:21:20,360
So much. I mean, it's it's NLP is going quite fast. So you do need to keep yourself updated.

108
00:21:20,360 --> 00:21:23,360
So that's one one of the things that I've learned.

109
00:21:23,360 --> 00:21:30,360
And whenever whenever a new state of the art model comes, do read the paper, go through go through the paper.

110
00:21:30,360 --> 00:21:33,360
Don't worry about.

111
00:21:33,360 --> 00:21:41,360
So a lot of people I've seen a lot of people they have like couple hundred samples of data and they start with a very large huge model.

112
00:21:41,360 --> 00:21:46,360
Probably only that you can you can get away with smaller models.

113
00:21:46,360 --> 00:21:53,360
So it's it's going to be all about transformers in near future.

114
00:21:53,360 --> 00:21:59,360
So get yourself updated and yeah, not much.

115
00:21:59,360 --> 00:22:08,360
Can you maybe talk a little bit about the about how auto NLP approaches a task like binary classification.

116
00:22:08,360 --> 00:22:14,360
Is there a methodology that you've built into it that you could describe?

117
00:22:14,360 --> 00:22:20,360
So I can probably describe like give you a small overview.

118
00:22:20,360 --> 00:22:24,360
So we do have we do have different models for different languages.

119
00:22:24,360 --> 00:22:32,360
So when you're doing sentiment classification, you can choose a language in which you want the models to be from.

120
00:22:32,360 --> 00:22:38,360
And then we choose models from from that given language. So if you're doing sentiment classification for Japanese.

121
00:22:38,360 --> 00:22:43,360
We choose models which have been trained on Japanese and then we try to hyper hyper parameter tune.

122
00:22:43,360 --> 00:22:46,360
Sorry, tune their hyper parameters.

123
00:22:46,360 --> 00:22:57,360
And in the end, we present to you a kind of a leaderboard where you can see how the model performs against different metrics.

124
00:22:57,360 --> 00:23:04,360
So for binary classification, it's it's metrics like F1 precision recall a UC accuracy.

125
00:23:04,360 --> 00:23:07,360
So log loss these kind of things.

126
00:23:07,360 --> 00:23:14,360
And then you can choose the model based on the accuracy and the latency.

127
00:23:14,360 --> 00:23:26,360
So you probably don't want to choose a large model, which gives you and a lift of 0.001% in a UC.

128
00:23:26,360 --> 00:23:34,360
Compared to a small model, because it's also going to take a lot of time for it to predict when it's live.

129
00:23:34,360 --> 00:23:41,360
So the whole back end of auto and LP is closed source.

130
00:23:41,360 --> 00:23:46,360
Only the front end part where you upload the models where you see the data where you choose the different languages.

131
00:23:46,360 --> 00:23:55,360
This is open to the world and auto and LP is built on top of transformers or existing resources from hugging phase.

132
00:23:55,360 --> 00:24:02,360
Like the data sets library, the transformers library.

133
00:24:02,360 --> 00:24:10,360
So when you're when you're building something with auto and LP, do you?

134
00:24:10,360 --> 00:24:24,360
Well, maybe asking a different way like, well, how do you, how does auto and LP the result of auto and LP compare to a model that you've hand crafted and and built?

135
00:24:24,360 --> 00:24:29,360
Yeah, I mean, it's it might not be good.

136
00:24:29,360 --> 00:24:35,360
So auto and LP is all about so.

137
00:24:35,360 --> 00:24:39,360
And let's say you, you, you got the data set.

138
00:24:39,360 --> 00:24:42,360
So the most difficult part is still yours.

139
00:24:42,360 --> 00:24:46,360
You have to get the data set. You have to do some cleaning if you want.

140
00:24:46,360 --> 00:24:52,360
We do take part of some cleaning, but if you want, you can do some cleaning.

141
00:24:52,360 --> 00:24:57,360
And then upload this data now.

142
00:24:57,360 --> 00:25:00,360
During this time, you can build one model, right?

143
00:25:00,360 --> 00:25:05,360
Maybe train one model auto and LP you will train you like 15 20 models.

144
00:25:05,360 --> 00:25:10,360
So this is a difference and then you get a leaderboard where you can check.

145
00:25:10,360 --> 00:25:18,360
Okay, so so if you have if you have one GPU or two two GPUs that at your work, you can probably train two models in parallel.

146
00:25:18,360 --> 00:25:23,360
But given this infrastructure that we have, we can train multiple models in parallel.

147
00:25:23,360 --> 00:25:28,360
And we can do hyper parameter tuning on all these models simultaneously.

148
00:25:28,360 --> 00:25:32,360
And in the end present you the results from all these different kinds of models.

149
00:25:32,360 --> 00:25:35,360
And you just have to choose a single model.

150
00:25:35,360 --> 00:25:38,360
But auto and LP can also be used in a very different in a different way.

151
00:25:38,360 --> 00:25:46,360
So a lot of auto ml vendors, they don't give you the model weights.

152
00:25:46,360 --> 00:25:49,360
They just give you an endpoint and you can use that endpoint.

153
00:25:49,360 --> 00:25:54,360
But yeah, auto LP from hugging face does give you the model weight does give you the tokenizer.

154
00:25:54,360 --> 00:25:57,360
So you have everything that you need.

155
00:25:57,360 --> 00:26:04,360
So you train the model using auto LP choose the best one and try to improve on this result manually.

156
00:26:04,360 --> 00:26:06,360
So you can fine tune the fine tune model.

157
00:26:06,360 --> 00:26:10,360
So this is also one of the use cases people can try.

158
00:26:10,360 --> 00:26:21,360
Nice. What's the approach to hyper parameter optimization? Is it, you know, simple grid based approaches?

159
00:26:21,360 --> 00:26:26,360
Or is it kind of exotic Bayesian stuff? How do you or is it?

160
00:26:26,360 --> 00:26:31,360
Is it task specific based on research papers?

161
00:26:31,360 --> 00:26:40,360
I won't, I'm going to details of this, but it's a, it's a combination of both grid and Bayesian approaches.

162
00:26:40,360 --> 00:26:42,360
Okay.

163
00:26:42,360 --> 00:26:47,360
So sounds like an area that you've invested some kind of creating some IP into.

164
00:26:47,360 --> 00:26:49,360
We are trying to, yeah.

165
00:26:49,360 --> 00:26:50,360
All right.

166
00:26:50,360 --> 00:26:55,360
So, as I mentioned previously.

167
00:26:55,360 --> 00:27:00,360
Automatic machine learning or any kind of auto ml model.

168
00:27:00,360 --> 00:27:04,360
You probably don't need to tune all parameters all the time.

169
00:27:04,360 --> 00:27:09,360
You just need to know which parameter to tune and what should the range of this parameter be.

170
00:27:09,360 --> 00:27:16,360
So if you talk about a model like XG boost, it, and you compare it with light GBM.

171
00:27:16,360 --> 00:27:19,360
Light GBM has so many parameters, right?

172
00:27:19,360 --> 00:27:27,360
And it's so, it becomes so difficult to tune it, but you can, what you can do is you can use XG boost.

173
00:27:27,360 --> 00:27:32,360
Trune some parameters and then transfer it to light GBM and tune further.

174
00:27:32,360 --> 00:27:37,360
So these kind of tricks you can do, you just need to know what, what should I do?

175
00:27:37,360 --> 00:27:45,360
Like if I, if I increase the depth, I should decrease the learning rate.

176
00:27:45,360 --> 00:27:49,360
So these kind of tricks you should know.

177
00:27:49,360 --> 00:27:54,360
And then you will be able to build your own auto ml solution.

178
00:27:54,360 --> 00:28:01,360
And are the, these kinds of tricks things that you have gotten from just trying a lot of different things.

179
00:28:01,360 --> 00:28:07,360
Or do you find that you're learning a lot of these tricks from papers?

180
00:28:07,360 --> 00:28:09,360
Yeah, I'm from both.

181
00:28:09,360 --> 00:28:16,360
So I have, I've gained some knowledge from trying out different competitions, trying out different kinds of datasets.

182
00:28:16,360 --> 00:28:17,360
Yes.

183
00:28:17,360 --> 00:28:25,360
And also learning from different papers, like, like if you're doing biogen search, you have to define the search space, right?

184
00:28:25,360 --> 00:28:27,360
So this is something that you have to do manually.

185
00:28:27,360 --> 00:28:30,360
They won't come up with some kind of search space for you.

186
00:28:30,360 --> 00:28:31,360
Maybe they do.

187
00:28:31,360 --> 00:28:46,360
So this space, if you define it properly, you are, it's more probable that you will get a good model quickly.

188
00:28:46,360 --> 00:28:51,360
Now, what have you learned about working with the transformer models?

189
00:28:51,360 --> 00:28:56,360
I've learned that they are the state with the art right now.

190
00:28:56,360 --> 00:29:01,360
So, yeah, I've learned quite a lot about transformer models.

191
00:29:01,360 --> 00:29:09,360
And I've learned learned a lot from the team, which is working with, with transformers, the library.

192
00:29:09,360 --> 00:29:15,360
So I've, there were many tasks that I didn't try before.

193
00:29:15,360 --> 00:29:19,360
And now I'm, I'm, I'm getting my hands dirty with.

194
00:29:19,360 --> 00:29:23,360
So like the task, like summarization or translation.

195
00:29:23,360 --> 00:29:26,360
So these kind of tasks are quite new for me.

196
00:29:26,360 --> 00:29:32,360
So I'm still in process of learning about these using transformers.

197
00:29:32,360 --> 00:29:35,360
Yeah, I think I was mostly curious.

198
00:29:35,360 --> 00:29:46,360
Like in the hyperparameter tuning and some of the other areas we discussed, there are tricks that you eventually figure out.

199
00:29:46,360 --> 00:29:58,360
If you read enough papers or beat your head against the wall, that you could share that would help folks shortcut that learning, you know, that learning loop.

200
00:29:58,360 --> 00:30:07,360
So yeah, most of the papers come with implementation. And I usually try to start from the implementation and keep the paper on the side.

201
00:30:07,360 --> 00:30:16,360
So you have, you know how this thing is implemented when the author talks about something specific.

202
00:30:16,360 --> 00:30:19,360
So I think that helps a lot.

203
00:30:19,360 --> 00:30:25,360
And like, if you, if you look at the paper.

204
00:30:25,360 --> 00:30:37,360
The intention is all you need. And then you have this web page from Howard NLP annotated transformer.

205
00:30:37,360 --> 00:30:38,360
Okay.

206
00:30:38,360 --> 00:30:45,360
In which they do, they have the whole paper and they have shown how each and everything is implemented.

207
00:30:45,360 --> 00:30:57,360
So that gives you a much clearer picture. So, and then there are many YouTubers who are making videos on when a paper was announced.

208
00:30:57,360 --> 00:30:59,360
And next day they have a video around it.

209
00:30:59,360 --> 00:31:06,360
So try to take a look at those videos and different kinds of tutorials about about the papers.

210
00:31:06,360 --> 00:31:10,360
If you are not so much into reading papers.

211
00:31:10,360 --> 00:31:19,360
Yeah. Speaking of YouTube, you're working on YouTube among other things, you know, when you're not working on auto NLP.

212
00:31:19,360 --> 00:31:24,360
Tell us a little bit about the various things that you have been up to recently.

213
00:31:24,360 --> 00:31:29,360
Yeah, YouTube, YouTube is like it's a fun thing that I do.

214
00:31:29,360 --> 00:31:36,360
And I started it because I face a lot of problems learning things which are not usually taught.

215
00:31:36,360 --> 00:31:47,360
So you can do lectures, but no one is going to tell you how you can write this in a proper manner that you can reuse it again and again and again.

216
00:31:47,360 --> 00:31:52,360
So my YouTube channel focuses a lot of writing clean code.

217
00:31:52,360 --> 00:31:58,360
It's very much applied. So you can learn the theory, but a lot of people face this problem.

218
00:31:58,360 --> 00:32:06,360
Like if they're given a data set, they are not able to apply the theory and they know everything. They know about by torch.

219
00:32:06,360 --> 00:32:14,360
They know how things work and they know deep learning. So they know everything, but they are not able to apply this for some reason.

220
00:32:14,360 --> 00:32:24,360
And that's why I created this YouTube channel where I focus on the applied aspect of machine learning and deep learning.

221
00:32:24,360 --> 00:32:28,360
And what's the, what's the YouTube channel where can folks find it?

222
00:32:28,360 --> 00:32:32,360
Oh, if this search, my name, they will find it.

223
00:32:32,360 --> 00:32:36,360
Well, it's just my name.

224
00:32:36,360 --> 00:32:39,360
And you also published a book recently.

225
00:32:39,360 --> 00:32:44,360
I did publish a book. So that's also very applied.

226
00:32:44,360 --> 00:32:51,360
And it's more of a code book. It's called approaching almost any machine learning problem. It has less text more code.

227
00:32:51,360 --> 00:32:55,360
A lot of people also said that you could have just released it on GitHub.

228
00:32:55,360 --> 00:33:02,360
As it's grid me. So I said, no, then you have all the code and you can copy paste.

229
00:33:02,360 --> 00:33:06,360
So it's better to release it as a book.

230
00:33:06,360 --> 00:33:16,360
So yeah, the book start from some basics of machine learning goes a little bit into deep learning some NLP problem, some image problem.

231
00:33:16,360 --> 00:33:26,360
I'm touching the surface of image and NLP and then showing you how you can use docker docker to deploy your machine learning models.

232
00:33:26,360 --> 00:33:33,360
So yeah, it's like 300 pages, a small book, but a lot of code.

233
00:33:33,360 --> 00:33:43,360
And now I always I have written this in the beginning of the book that if you didn't code you didn't learn so you do need to code to get something out of this book.

234
00:33:43,360 --> 00:33:47,360
So if you're looking for something that.

235
00:33:47,360 --> 00:33:53,360
If this if you think like this book is going to make you a Kaggle grandmaster or you're going to call my data or anything.

236
00:33:53,360 --> 00:33:55,360
This book is not for you.

237
00:33:55,360 --> 00:33:58,360
It can just give you ideas on how to.

238
00:33:58,360 --> 00:34:00,360
Who is it for? Who is it for then?

239
00:34:00,360 --> 00:34:03,360
What is the specific problem that it's all?

240
00:34:03,360 --> 00:34:07,360
Yeah, it's like it can give you ideas on how to approach different kinds of problems.

241
00:34:07,360 --> 00:34:11,360
So when you're starting with machine learning or if you have done some theory on machine learning.

242
00:34:11,360 --> 00:34:15,360
Then you can use this book and implement some examples from the book.

243
00:34:15,360 --> 00:34:20,360
And you can understand more like like categorical variables is my favorite chapter.

244
00:34:20,360 --> 00:34:23,360
So I spent quite a lot of time there.

245
00:34:23,360 --> 00:34:28,360
And there's there's a lot of things there that you don't learn in theory.

246
00:34:28,360 --> 00:34:31,360
So you will only learn it then.

247
00:34:31,360 --> 00:34:36,360
When you when you're solving some problems like entity embeddings.

248
00:34:36,360 --> 00:34:43,360
And nobody is going to teach you how to convert categorical variables into embeddings.

249
00:34:43,360 --> 00:34:45,360
And how to use a neural network there.

250
00:34:45,360 --> 00:34:51,360
So these kind of things you you probably won't learn in theory easily.

251
00:34:51,360 --> 00:34:54,360
And yeah.

252
00:34:54,360 --> 00:34:57,360
Yeah, that's it.

253
00:34:57,360 --> 00:35:12,360
Besides from Kaggle, what resources, you know, courses, books, even papers, most influenced you and your your career.

254
00:35:12,360 --> 00:35:15,360
Everyone's lectures were quite nice.

255
00:35:15,360 --> 00:35:21,360
I was not I was not very good in attending the lectures at my own university.

256
00:35:21,360 --> 00:35:25,360
So I learned everything on my own.

257
00:35:25,360 --> 00:35:31,360
So whenever I saw something, it was like a entity recognition model in head.

258
00:35:31,360 --> 00:35:34,360
If you don't understand something, Google it.

259
00:35:34,360 --> 00:35:38,360
So I used to Google and I used to find different kinds of paper.

260
00:35:38,360 --> 00:35:44,360
There long ago, there was a paper called a natural language processing almost from scratch.

261
00:35:44,360 --> 00:35:46,360
I like that paper a lot.

262
00:35:46,360 --> 00:35:50,360
And it has all these different kinds of problems related to an LP.

263
00:35:50,360 --> 00:35:52,360
It's a big paper.

264
00:35:52,360 --> 00:35:55,360
It's a very easy read.

265
00:35:55,360 --> 00:35:59,360
And but nowadays, everyone is using transformers for everything anyways.

266
00:35:59,360 --> 00:36:02,360
So it's a different story.

267
00:36:02,360 --> 00:36:15,360
But yeah, what helped was lectures from Andrew, a lot of different kinds of YouTube videos, tutorials, and also quite a lot of googling, reading a lot of research papers.

268
00:36:15,360 --> 00:36:20,360
I used to implement research papers at some point, but now I don't have the time.

269
00:36:20,360 --> 00:36:26,360
So I've lost my touch.

270
00:36:26,360 --> 00:36:30,360
What are you, what are you most excited about?

271
00:36:30,360 --> 00:36:39,360
Kind of beyond your work and as you look out onto the horizon of machine learning and deep learning, anything.

272
00:36:39,360 --> 00:36:47,360
You know that you're kind of playing around with or keeping an eye on because you think it could be pretty interesting.

273
00:36:47,360 --> 00:36:50,360
I'm playing around with a lot of things actually.

274
00:36:50,360 --> 00:36:53,360
I'm juggling so many things right now.

275
00:36:53,360 --> 00:36:58,360
I lose track, but I think.

276
00:36:58,360 --> 00:37:10,360
Machine learning and data science in general is reaching such a stage where probably you won't go a lot going forward.

277
00:37:10,360 --> 00:37:23,360
So if you have to train a model and if there's tools available that can train models for you, do all kinds of a parameter tuning in like few commands.

278
00:37:23,360 --> 00:37:30,360
Why would why would industries want to spend time hiring so many data scientists?

279
00:37:30,360 --> 00:37:39,360
So I would suggest like people should try to focus on building these kind of tools.

280
00:37:39,360 --> 00:37:45,360
They think the future is in is an auto, auto X.

281
00:37:45,360 --> 00:37:47,360
It is going there, right?

282
00:37:47,360 --> 00:37:48,360
So everything is getting automated.

283
00:37:48,360 --> 00:37:59,360
Now now you have like you have pre-trained models for doing almost everything and you just fine tune them on very small set of your data and it just works.

284
00:37:59,360 --> 00:38:01,360
It works out of the box.

285
00:38:01,360 --> 00:38:07,360
So you don't even need to invest so much time thinking about how would you approach these kind of problems.

286
00:38:07,360 --> 00:38:10,360
So I'm talking totally from the applied perspective.

287
00:38:10,360 --> 00:38:15,360
There's a lot going on in research and we are using that research.

288
00:38:15,360 --> 00:38:16,360
Yeah.

289
00:38:16,360 --> 00:38:33,360
Yeah, so I do think like if I have to train a model for classification right now or for entertainment or for different tasks of natural language processing, I would probably just throw it inside

290
00:38:33,360 --> 00:38:43,360
Auto and P and C what performs the best so that would be my first step and then extract the model and then do some build something else on top of it.

291
00:38:43,360 --> 00:38:51,360
Like even on Kaggle when you're when you're working with different models, you just take an average of all of them and it becomes an ensemble.

292
00:38:51,360 --> 00:39:00,360
So things like that and yeah, infrastructure is getting cheaper and cheaper day by day.

293
00:39:00,360 --> 00:39:15,360
Would you worry that that approach like a given model that auto auto and LP chooses as the best is like a local optima and some other model that auto and LP didn't do as well on could have been manually optimized.

294
00:39:15,360 --> 00:39:21,360
Yes, yes, sure computers are wrong a lot of time right.

295
00:39:21,360 --> 00:39:32,360
Yeah, it is indeed possible so there are many things that you can do in simple ways.

296
00:39:32,360 --> 00:39:41,360
So as a human and like as a data scientist as a data scientist from this generation.

297
00:39:41,360 --> 00:39:59,360
If they're presented with 304 samples of text what they are going to do is to start using transformers on on it and apply a fancy bird model right nobody's even going to try TF IDF and large degradation maybe that performs well.

298
00:39:59,360 --> 00:40:10,360
So you you never know so there can be situations in which yeah, probably auto and LP didn't choose or any kind of auto ML solution didn't choose the best model.

299
00:40:10,360 --> 00:40:17,360
But you're trying more than you might have otherwise is the yeah, yeah, awesome awesome.

300
00:40:17,360 --> 00:40:28,360
Well, I was like thanks so much for taking the time to chat about what you're up to has been great getting to learn a bit about auto and LP and yeah, a little bit of your story.

301
00:40:28,360 --> 00:40:32,360
Thank you very much for the invitation and it was great talking to you Sam.

302
00:40:32,360 --> 00:40:39,360
Thank you.

