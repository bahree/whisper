WEBVTT

00:00.000 --> 00:16.000
Hello everyone and welcome to another episode of Twimble Talk, the podcast where I interview

00:16.000 --> 00:21.440
interesting people, doing interesting things in machine learning and artificial intelligence.

00:21.440 --> 00:24.360
I'm your host Sam Charrington.

00:24.360 --> 00:29.200
So I'm recording this intro in New York City where I've been attending the O'Reilly

00:29.200 --> 00:31.680
AI and Stratocomferences.

00:31.680 --> 00:36.400
I did a ton of great interviews here at the events and I'm really looking forward to getting

00:36.400 --> 00:38.640
these posted over the next few weeks.

00:38.640 --> 00:43.640
Today though, I've got to show that I know you're going to really enjoy.

00:43.640 --> 00:49.160
My guess this time is Angie Hugeback, who is Principal Data Scientist at Spare 5.

00:49.160 --> 00:53.960
A company focused on helping its customers generate the high quality training datasets that

00:53.960 --> 00:58.880
are so so crucial to developing accurate machine learning models.

00:58.880 --> 01:03.920
In this show, Angie and I cover a bunch of the real world practicalities of generating

01:03.920 --> 01:05.840
training datasets.

01:05.840 --> 01:09.720
We talk through the challenges faced by folks that need to label training data and how

01:09.720 --> 01:14.400
to develop a cohesive system for performing the various labeling tasks that you're likely

01:14.400 --> 01:15.800
to encounter.

01:15.800 --> 01:20.520
We discuss some of the ways that bias can creep into your training data and how to avoid it.

01:20.520 --> 01:24.400
And we explore some of the popular third-party options that companies look at for scaling

01:24.400 --> 01:28.200
training data production and how they differ.

01:28.200 --> 01:32.000
Before we dive into the interview though, I really want to take a moment to acknowledge

01:32.000 --> 01:36.240
Spare 5, who stepped up to sponsor this episode of the show.

01:36.240 --> 01:40.440
Now, I'm not going to spend time talking about their service here because Angie and I do

01:40.440 --> 01:45.240
cover that in the course of the interview, but I will say these three things.

01:45.240 --> 01:48.160
First, what Spare 5 is doing is really cool.

01:48.160 --> 01:52.480
And if you have a training data problem and you know who you are if you do, you should

01:52.480 --> 01:57.040
definitely take a look at what they've got to offer as you explore your options.

01:57.040 --> 02:02.200
Second, they've put together a great offer for 25 lucky twimble talk listeners, which

02:02.200 --> 02:05.640
you'll hear towards the end of the interview.

02:05.640 --> 02:10.160
And third, I'm just very grateful to Spare 5 for helping to make this podcast possible

02:10.160 --> 02:11.720
for all of you.

02:11.720 --> 02:15.600
And I want to really encourage you all to show them some love.

02:15.600 --> 02:18.160
So please, hit them up on Twitter.

02:18.160 --> 02:22.560
They're at Spare 5, S-P-A-R-E, the number 5.

02:22.560 --> 02:27.080
And just thank them, visit their website, sign up for a demo, all of these things let

02:27.080 --> 02:31.760
them know how much you appreciate this podcast and their support for it.

02:31.760 --> 02:36.760
As always, I'll be linking to Angie and the various things we mentioned on the show in

02:36.760 --> 02:45.360
the show notes, which you'll be able to find at twimbleai.com slash talk slash six.

02:45.360 --> 02:54.840
And now onto the interview.

02:54.840 --> 02:58.680
So hey everybody, welcome to another episode of twimble talk.

02:58.680 --> 03:04.720
I've got Angie Hugeback, the principal data scientist at Spare 5 on the line Angie, why

03:04.720 --> 03:05.800
don't you say hi?

03:05.800 --> 03:08.040
Hi everyone, hi Sam.

03:08.040 --> 03:11.840
Hey, so happy to have you on here today.

03:11.840 --> 03:13.320
Yeah, excited to be here.

03:13.320 --> 03:16.520
All right, yeah, I'm really looking forward to digging into some good stuff.

03:16.520 --> 03:17.520
Awesome, awesome.

03:17.520 --> 03:21.960
So why don't we get started by having you give us a little bit about your background

03:21.960 --> 03:24.440
and how you got started in machine learning?

03:24.440 --> 03:26.960
Yeah, sure.

03:26.960 --> 03:31.840
So I started out as a math major in college and I took a stats class.

03:31.840 --> 03:36.160
I was at the University of Minnesota Duluth and I really fell in love with the idea that

03:36.160 --> 03:41.600
you know, it was math, but it was applied and you could learn about the world around you

03:41.600 --> 03:43.600
through math.

03:43.600 --> 03:44.600
So I got really interested in statistics.

03:44.600 --> 03:48.240
I ended up getting my masters in PhD in statistics.

03:48.240 --> 03:54.240
I got my PhD at the University of Chicago and when I came out of school, so I had worked

03:54.240 --> 04:01.480
with my PhD advisor was really big on teaching me how to creatively solve a problem, do creative

04:01.480 --> 04:04.320
algorithm development, just start from the basics.

04:04.320 --> 04:06.840
What are you trying to do and construct from there?

04:06.840 --> 04:12.160
When I was really interested in doing that, I had a strong interest in machine learning

04:12.160 --> 04:13.560
types of topics.

04:13.560 --> 04:17.040
So when I came out of school, I had this idea that I want to work in machine learning,

04:17.040 --> 04:21.320
but I want to do creative algorithm development and trying to find that.

04:21.320 --> 04:26.520
And at the time, you know, the term data scientist didn't exist yet, but that's essentially

04:26.520 --> 04:29.040
what I was interested in doing.

04:29.040 --> 04:34.040
So it just took me some time from there to kind of blend between the traditional definition

04:34.040 --> 04:39.440
of statistician and sort of the engineering end of machine learning and find a good balance

04:39.440 --> 04:41.480
and this is where I landed.

04:41.480 --> 04:42.480
Awesome.

04:42.480 --> 04:48.600
Now, what were some other kinds of problems that you were interested in in grad school as

04:48.600 --> 04:52.520
a statistician, statistician looking into machine learning?

04:52.520 --> 04:53.520
Yeah, sure.

04:53.520 --> 04:57.200
There was, when I was doing my master's degree at a master's thesis problem that was really

04:57.200 --> 04:58.200
fun.

04:58.200 --> 05:01.760
I was, you know, there's the game mastermind where you have the little colored pegs

05:01.760 --> 05:07.320
and someone has a code, which is an ordering of colored pegs and you're trying to guess

05:07.320 --> 05:11.200
through making proposals of, you know, what you think the code might be and getting

05:11.200 --> 05:12.200
some feedback.

05:12.200 --> 05:13.200
Right.

05:13.200 --> 05:14.880
And so I had a lot of fun playing around with.

05:14.880 --> 05:22.280
I ended up building like a metropolis hastings, important sampling style algorithm to solve

05:22.280 --> 05:26.320
the game mastermind in a very limited number of steps.

05:26.320 --> 05:30.680
And, you know, the game is, you know, fairly straightforward when you're dealing with

05:30.680 --> 05:32.520
six pegs in the traditional sense.

05:32.520 --> 05:37.240
But then I was taking it up, you know, well, what if it's 14 pegs or 50 pegs and the space

05:37.240 --> 05:40.000
of the problem becomes incredibly complex?

05:40.000 --> 05:44.040
And I was really interested in, you know, the metropolis hastings algorithm is kind of

05:44.040 --> 05:49.360
like a simulated annealing algorithm where you're able to explore a really high dimensional

05:49.360 --> 05:54.080
space very quickly and kind of rapidly move around in this space and figure out where

05:54.080 --> 05:56.480
you're making progress and work toward an optimal point.

05:56.480 --> 05:58.640
So that was fun.

05:58.640 --> 06:02.280
I also worked on a lot of problems in astronomy.

06:02.280 --> 06:05.880
So astronomy was something I'd always been interested in but never had a chance to learn

06:05.880 --> 06:07.640
in school.

06:07.640 --> 06:10.960
So my advisor was awesome, Mark Clorum.

06:10.960 --> 06:16.880
He invited me to, you know, come on over into the astronomy department at the University

06:16.880 --> 06:19.720
of Chicago and talk to the professors there and figure out what kinds of problems they

06:19.720 --> 06:22.480
were working on where I might be able to help out.

06:22.480 --> 06:25.200
So I did some work with quasars.

06:25.200 --> 06:30.960
I got to do some work on some solar science research, got to do so.

06:30.960 --> 06:36.880
I had an internship at NASA working on some solar research to continue to do some consulting

06:36.880 --> 06:38.680
with them for a while.

06:38.680 --> 06:42.680
And then the last project that always sticks out out in my mind wasn't really part of

06:42.680 --> 06:50.040
my thesis work but when I was in my PhD program, Netflix announced their Netflix prize competition

06:50.040 --> 06:57.320
which was, it was a competition on predictive modeling to do movie ratings, right?

06:57.320 --> 07:02.880
So they released this publicly available data set and it was all these pairs of movie

07:02.880 --> 07:06.400
ID and a user ID and then a rating.

07:06.400 --> 07:11.240
And then you were supposed to be able to predict how certain users would write certain

07:11.240 --> 07:12.240
movies.

07:12.240 --> 07:14.560
And I played around with that problem for about six months.

07:14.560 --> 07:22.920
It came up with a great solution that was competitive in the contest.

07:22.920 --> 07:29.400
But then through that, I actually came to a different understanding of what worked better

07:29.400 --> 07:31.840
in terms of actually making recommendations.

07:31.840 --> 07:36.640
So I built a movie recommender out of that and headed up on the web actually up until

07:36.640 --> 07:37.960
about six months ago.

07:37.960 --> 07:42.080
I was still using it to recommend movies for myself and some of my friends are still

07:42.080 --> 07:43.480
using it.

07:43.480 --> 07:47.720
And so those kinds of problems were the things that I was generally interested in.

07:47.720 --> 07:48.720
Wow.

07:48.720 --> 07:50.920
I was going through school.

07:50.920 --> 07:55.080
So does that mean it takes you less time to pick a movie to watch than it takes the rest

07:55.080 --> 07:56.080
of us?

07:56.080 --> 07:58.760
Yeah, typically it actually works pretty well.

07:58.760 --> 08:00.440
I got to get it up and running good.

08:00.440 --> 08:04.000
Yeah, the best feature was being able to combine two movies.

08:04.000 --> 08:08.920
So you say, I want to see something that's like, I want to watch a movie that's like

08:08.920 --> 08:15.280
Flut loose meets fatal attraction or something like that, and then it would come up with some

08:15.280 --> 08:17.680
great recommendations crossing between those two.

08:17.680 --> 08:18.680
That was really fun.

08:18.680 --> 08:19.680
Oh nice.

08:19.680 --> 08:23.760
You mentioned a whole bunch of really interesting stuff in there.

08:23.760 --> 08:28.400
I want to mention since you mentioned astronomy, I don't know if you've had a chance to hear

08:28.400 --> 08:37.320
the last tumultalk episode that I just posted is with Joshua, Joshua Bloom, who's an astronomy

08:37.320 --> 08:42.600
professor at Berkeley and also the CTO of a company that uses machine learning.

08:42.600 --> 08:44.040
I think you'll find it super interesting.

08:44.040 --> 08:45.040
Oh, yeah.

08:45.040 --> 08:46.040
Thanks.

08:46.040 --> 08:47.040
I'll check it out.

08:47.040 --> 08:48.040
Oh, absolutely.

08:48.040 --> 08:49.040
Thanks.

08:49.040 --> 08:52.280
I mean, you've given us an entree to go deep kind of quickly here.

08:52.280 --> 08:54.280
Metropolis hastings and portance.

08:54.280 --> 08:55.280
Yeah.

08:55.280 --> 08:56.280
What is that all about?

08:56.280 --> 09:00.440
Is that an L or stats or a good question?

09:00.440 --> 09:04.960
I think it's, you know, it was sort of sitting in between the two fields and probably a little

09:04.960 --> 09:05.960
bit more in ML.

09:05.960 --> 09:06.960
Yeah.

09:06.960 --> 09:10.280
So metropolis hastings is one thing important sampling is another.

09:10.280 --> 09:11.280
Okay.

09:11.280 --> 09:12.280
Yeah.

09:12.280 --> 09:13.280
And so, yeah.

09:13.280 --> 09:17.520
So metropolis hastings, it's really just an optimization technique, you know, for, you

09:17.520 --> 09:24.280
know, maximizing a function in a high dimensional space where rather than say, you know, following

09:24.280 --> 09:30.200
the derivative or doing something more mathematical in that sense, you use a random component.

09:30.200 --> 09:34.400
So you say, you start with a space in the high dimensional field, you say, okay, this

09:34.400 --> 09:36.120
is my initial starting point.

09:36.120 --> 09:41.920
And then you propose a point around there that you may go to next.

09:41.920 --> 09:44.800
And so you, you come up with a proposal function.

09:44.800 --> 09:52.120
So you say, okay, maybe my proposal is I pick one of my dimensions at random.

09:52.120 --> 09:59.400
And then I perturb that, that value a little bit with some random, you know, in some random

09:59.400 --> 10:02.120
distance and in some directions, something like that.

10:02.120 --> 10:04.120
And you say, okay, that's my proposed point.

10:04.120 --> 10:09.440
And then you compare your function on that proposed point to the function on the initial

10:09.440 --> 10:10.440
value.

10:10.440 --> 10:13.960
And if you're in a better place and you say, oh, yeah, this is a better place to go to,

10:13.960 --> 10:16.240
you know, you'll always move there.

10:16.240 --> 10:19.360
But if you're, if it looks a little bit worse than your initial position, you'll still

10:19.360 --> 10:21.920
move there with some small probability.

10:21.920 --> 10:27.280
And so what that allows you to do is it allows you to move away from, you know, local minima

10:27.280 --> 10:29.640
and things like that that you might get stuck in.

10:29.640 --> 10:30.640
Yeah.

10:30.640 --> 10:37.280
And it just, yeah, in many, many problems, it provides a kind of a rapid way to search

10:37.280 --> 10:40.200
through a very high dimensional space.

10:40.200 --> 10:47.800
Would it be fair to say that if your proposal function was, was your slope in the end-dimensional

10:47.800 --> 10:53.280
space that it metropolis Hastings, we've kind of approximate gradient descent?

10:53.280 --> 11:00.040
Um, not exactly, no, the proposal is always another, it's, it's basically a sampling.

11:00.040 --> 11:04.840
You're going to sample from the collection of all possible points that you might evaluate.

11:04.840 --> 11:05.840
Okay.

11:05.840 --> 11:10.200
So, um, I mean, I suppose, I suppose you could create a proposal function that says I

11:10.200 --> 11:14.800
always select a point that follows, you know, the slope, but, you know, that's the

11:14.800 --> 11:16.120
thing I suppose you come up with that.

11:16.120 --> 11:19.960
But typically, you, yeah, your proposal is supposed to have a random component and then

11:19.960 --> 11:23.400
there's the additional random component that you may choose it, even if it moves in the

11:23.400 --> 11:24.400
wrong direction.

11:24.400 --> 11:25.400
Okay.

11:25.400 --> 11:34.000
Oh, nice. Uh, so, uh, that, that raises a question for me coming from, uh, strong stats

11:34.000 --> 11:40.440
background, you know, what, how does, how do you feel like this, uh, guide your perspective

11:40.440 --> 11:42.120
as a data scientist?

11:42.120 --> 11:45.120
Data science has come to me in a whole ton of things.

11:45.120 --> 11:51.360
Uh, for many, it's, you know, heavy programming for others, it's heavy data engineering.

11:51.360 --> 11:59.000
You obviously, it's heavy stats, um, heavy, do you have kind of a philosophy on data science

11:59.000 --> 12:00.640
and kind of what that all means to you?

12:00.640 --> 12:01.640
Yeah.

12:01.640 --> 12:05.160
I mean, yeah, definitely, definitely data science is a, is a big umbrella covering a lot

12:05.160 --> 12:06.160
of different things.

12:06.160 --> 12:09.600
And, you know, I think the field, the whole field is, is evolving, right?

12:09.600 --> 12:13.000
And, you know, and there's, there's more and more applications in this area, many more

12:13.000 --> 12:14.280
people going into this field.

12:14.280 --> 12:15.280
Yeah.

12:15.280 --> 12:20.160
So, um, I'd say now there are a lot more people coming out of a computer science background

12:20.160 --> 12:25.400
going into this type of work, um, you know, whereas back, you know, when I was coming out

12:25.400 --> 12:28.600
of school, I, you know, it was almost 50, 50, it was like machine learning was really

12:28.600 --> 12:32.280
sitting in between, um, statistics and computer science, at least that's the way that it

12:32.280 --> 12:34.120
was at, at University of Chicago.

12:34.120 --> 12:35.120
Okay.

12:35.120 --> 12:41.000
Um, yeah, and I do feel like I think I have, um, I, I tend to approach problems more from

12:41.000 --> 12:44.720
the predictive modeling, uh, viewpoint.

12:44.720 --> 12:51.240
I, um, I do a lot with just, um, constructing probabilities, um, likelihood estimation, things

12:51.240 --> 12:56.400
like that that maybe wouldn't be as commonly used coming straight from a, more computer

12:56.400 --> 13:00.840
science engineering machine learning perspective where, where it may be more about, um, deep

13:00.840 --> 13:05.200
learning and, you know, specific types of, of algorithms.

13:05.200 --> 13:10.240
Um, so, so I guess I see a little bit of a difference there, um, but I, you know, and

13:10.240 --> 13:15.960
I have background in more traditional statistics, you know, with just doing, you know, I don't

13:15.960 --> 13:22.840
also, you know, experimental design and, um, doing, um, I, you know, more, more just classic

13:22.840 --> 13:26.360
kinds of testing issues and, um, distribution comparisons and things like that.

13:26.360 --> 13:29.480
But I would say that's a small part of my daily work.

13:29.480 --> 13:33.120
It's one of those, you know, yeah, we do IB testing, we do things like that and I'll participate

13:33.120 --> 13:39.000
in assisting with those kinds of, um, experimental analysis, um, but typically I'm doing more, um,

13:39.000 --> 13:44.640
um, yeah, just constructing from probabilities, from likelihoods, um, you know, uh, working

13:44.640 --> 13:48.920
with predictive modeling, things like that to, you know, to solve our product goals.

13:48.920 --> 13:49.920
That's it.

13:49.920 --> 13:50.920
That.

13:50.920 --> 13:56.760
Are there things that you see commonly in the industry that you think, uh, would be

13:56.760 --> 14:02.120
different, uh, or approaches that folks take that, uh, they might take differently if more

14:02.120 --> 14:05.320
people had, uh, uh, a stats background?

14:05.320 --> 14:13.160
Yeah, I mean, well, I'm, I'm biased, but yeah, I mean, I tend to think, uh, yeah, I don't

14:13.160 --> 14:16.760
know, I, I see them, I see them blending and I see, you know, in people today that are

14:16.760 --> 14:21.000
coming out of, you know, strong computer science programs with machine learning background,

14:21.000 --> 14:24.920
really, there, there's quite a bit of overlap in terms of, you know, the materials that's

14:24.920 --> 14:29.600
been taught and the skills that are there, so, um, yeah, so I'm not sure, not sure.

14:29.600 --> 14:30.600
Okay.

14:30.600 --> 14:31.600
Okay.

14:31.600 --> 14:33.040
Uh, and so what are you up to now?

14:33.040 --> 14:40.680
Yeah, so right, so now I'm here at spare five, um, yeah, and, uh, yeah, so what we do here

14:40.680 --> 14:46.600
at spare five, we do, um, we collect training data for computer vision and natural language

14:46.600 --> 14:47.600
models.

14:47.600 --> 14:51.160
So other companies that are building out AI, building out their own machine learning

14:51.160 --> 14:57.240
models and computer vision and natural language, um, types of problems need really good labeled

14:57.240 --> 15:01.400
training data in order to power, you know, the algorithms that they're trying to build.

15:01.400 --> 15:02.640
And so that's what we do.

15:02.640 --> 15:10.040
So, um, I got really interested in this space because at my, at my prior company, we started,

15:10.040 --> 15:14.320
um, we were building out to natural language models there and, um, we had some really

15:14.320 --> 15:15.320
good stuff.

15:15.320 --> 15:18.760
It was working really well, but we wanted to push it to the next level and the thing that

15:18.760 --> 15:22.520
was preventing us was just getting that really good labeled data.

15:22.520 --> 15:26.160
Um, and so I was thinking a lot about that problem.

15:26.160 --> 15:31.200
And then I heard that, um, Darren, who's our CTO here, I heard that he was at spare five

15:31.200 --> 15:33.280
when I heard about what they were doing.

15:33.280 --> 15:39.240
And I just saw a huge opportunity in terms of, I was like, you know, AI is getting really

15:39.240 --> 15:41.320
big, machine learning is getting really big.

15:41.320 --> 15:45.640
You know, it's no longer kind of a fringe thing that a few companies are trying out.

15:45.640 --> 15:49.400
It's, you know, it's like to be in the, in the space, you know, to be competitive companies

15:49.400 --> 15:52.160
need to be building, building these things out.

15:52.160 --> 15:56.240
And as far as I can see, the real bottleneck is in the training data.

15:56.240 --> 16:03.560
So, you know, that was where I was excited to jump in and be a part of that, be a part

16:03.560 --> 16:04.560
of that business.

16:04.560 --> 16:05.560
Nice.

16:05.560 --> 16:11.840
I think there's growing recognition that the availability of training data is one of

16:11.840 --> 16:19.120
the biggest issues that new entrants to, you know, folks that are trying to apply machine

16:19.120 --> 16:21.640
learning to various problems take on.

16:21.640 --> 16:26.200
And, you know, for a lot of people, they look at it and say, and I've heard this, you know,

16:26.200 --> 16:29.360
I've heard this coming from several different angles, but, you know, something along the

16:29.360 --> 16:37.600
lines of, you know, soon, if not now, it'll be very difficult for a startup, for example,

16:37.600 --> 16:43.240
to, you know, compete with Facebook or Google or, you know, large company and industry,

16:43.240 --> 16:46.160
you know, X because they'll have all the data.

16:46.160 --> 16:52.120
And then the startup will, you know, will not be able to gather it and label it and all

16:52.120 --> 16:53.120
that.

16:53.120 --> 16:54.120
Do you agree with that in general?

16:54.120 --> 16:55.120
Oh, yeah.

16:55.120 --> 16:56.120
Oh, yeah, absolutely.

16:56.120 --> 16:57.120
Absolutely.

16:57.120 --> 17:02.720
I mean, the way that I see, you know, for, I think for quite a while, the focus was on

17:02.720 --> 17:06.720
the algorithms themselves and, you know, how do we get better algorithms, better algorithms?

17:06.720 --> 17:11.280
But at this point, you know, we have so many sophisticated algorithms, very flexible

17:11.280 --> 17:15.680
algorithms, right, for solving so many different types of problems that, that really the defining

17:15.680 --> 17:19.800
factor becomes the training data that you have underneath it to power it in terms of what

17:19.800 --> 17:20.800
you can actually do.

17:20.800 --> 17:23.520
So, yeah, I think that's a really valid concern.

17:23.520 --> 17:28.960
Although, you know, I would say, you know, I mean, it definitely depends on what, you know,

17:28.960 --> 17:31.480
what industry you're trying to jump into if you have a startup and they're trying to

17:31.480 --> 17:32.480
do something new.

17:32.480 --> 17:37.160
I think, yeah, I definitely think, you know, if they have a specific problem that they're

17:37.160 --> 17:42.720
trying to tackle, that, you know, requires a very specific type of data.

17:42.720 --> 17:47.040
I think there are so a lot of opportunities to get into that space if you have access

17:47.040 --> 17:51.680
to, right, the ability to get that, get that label data that you need, right, which is,

17:51.680 --> 17:52.880
which is where we come in.

17:52.880 --> 17:59.760
Okay, so, walk us through specifically what you guys are doing to help, help companies.

17:59.760 --> 18:00.760
Sure.

18:00.760 --> 18:01.760
Absolutely.

18:01.760 --> 18:07.280
So, I guess, yeah, so I would start by saying, you know, when, so when customers come to

18:07.280 --> 18:13.200
us, you know, typically, the number one thing that they're looking for, they're looking

18:13.200 --> 18:19.280
for high quality data, right, and they need that data at scale.

18:19.280 --> 18:26.760
And so, and I would say, you know, traditionally companies may, you know, initially they may

18:26.760 --> 18:31.920
start trying to label that data in-house, right, and they may say, you know, everybody

18:31.920 --> 18:35.600
take a few hours and, you know, look through this data, add some labels, that sort of thing,

18:35.600 --> 18:38.280
and then quickly find out, like, okay, this is going to take forever, and we don't only

18:38.280 --> 18:43.800
have the resources, and then a next step that companies sometimes would go to is trying

18:43.800 --> 18:51.200
to use these, you know, publicly available crowd sourcing, things like mechanical Turk,

18:51.200 --> 18:53.240
where, you know, yeah, there's a crowd out there.

18:53.240 --> 18:57.200
Maybe you can, you know, put your data out to them and they can label it, but that can

18:57.200 --> 19:01.480
be just incredibly painful in terms of, you know, you never know the quality of the

19:01.480 --> 19:02.720
work that you're getting back.

19:02.720 --> 19:07.240
It's like you, you end up having to design an entire workflow around just trying to

19:07.240 --> 19:09.280
QA the data that's coming back to you.

19:09.280 --> 19:13.360
You end up having to send the data out many, many times over again to multiple different

19:13.360 --> 19:16.640
people and try to assemble and make some sense out of the results that you're getting back.

19:16.640 --> 19:17.640
Okay.

19:17.640 --> 19:18.800
So that can be a real headache.

19:18.800 --> 19:26.280
So by the time customers get to us, so what we're doing instead is we handle all of

19:26.280 --> 19:27.720
that headache for you.

19:27.720 --> 19:32.400
So basically the customer comes to us, what all they need to communicate to us is exactly

19:32.400 --> 19:37.480
what correctly labeled data constitutes to them, right?

19:37.480 --> 19:43.280
So they, usually the customer will present us with some examples, you know, these are

19:43.280 --> 19:44.280
some images.

19:44.280 --> 19:45.880
Here's some example annotations.

19:45.880 --> 19:50.200
That would be the correct annotations for these images, that sort of thing.

19:50.200 --> 19:58.320
And from there, we do all the heavy lifting in terms of, we can, we will take on the task,

19:58.320 --> 20:04.360
we will create and generate that label data using our own community, which is like a thoroughly

20:04.360 --> 20:05.960
vetted community.

20:05.960 --> 20:11.000
We do all of the QA work and we guarantee the level of quality coming back to you and your

20:11.000 --> 20:12.000
data, right?

20:12.000 --> 20:18.560
So if you say, these are the specs, this is exactly what correctly labeled data means to us.

20:18.560 --> 20:24.280
We want 95% of the data coming back to us to be correctly labeled to spec, right?

20:24.280 --> 20:27.800
Then that's what, that's what we can guarantee and that's what we can provide.

20:27.800 --> 20:32.480
And so, yeah, so definitely it's, it's quality is the major challenge that we're providing

20:32.480 --> 20:34.600
just speed and scale.

20:34.600 --> 20:41.120
And then one other important piece is that we, we provide, we can provide diversity among

20:41.120 --> 20:42.840
the annotators.

20:42.840 --> 20:47.520
And so in particular, if there's a specific audience that the customer is interested

20:47.520 --> 20:54.120
in to say they're building an AI model and this AI model is going to be used by, you

20:54.120 --> 21:01.040
know, women age, you know, 20 to 30, typically, right, in the US, we can target annotators from

21:01.040 --> 21:05.560
that audience so that, you know, the keywords or, you know, whatever the labels that they're

21:05.560 --> 21:11.520
providing are relevant and the types of things that that audience would typically use, which

21:11.520 --> 21:16.040
is really going to improve the performance for the models themselves, you know, in those

21:16.040 --> 21:17.040
types of settings.

21:17.040 --> 21:22.040
So I would say, you know, those are kind of the three, three kind of pillars of problems

21:22.040 --> 21:25.320
the customers have that, that we were able to solve for them.

21:25.320 --> 21:26.320
Okay.

21:26.320 --> 21:30.680
Let's come back to the diversity angle because that's super interesting.

21:30.680 --> 21:37.640
But even before you get there, if I'm a company and I want to solve a given problem

21:37.640 --> 21:44.280
in my industry, do you, are you able to help me find the right data or augment the data

21:44.280 --> 21:48.840
that I do have with other data that might help me drive better predictability?

21:48.840 --> 21:49.840
Yeah.

21:49.840 --> 21:55.520
So we don't, we don't go out and find, like, publicly available data sets for you.

21:55.520 --> 21:59.800
You know, we are in the business of generating the data, but we definitely do augment data.

21:59.800 --> 22:03.960
So we've done data verification, sometimes, you know, validation, sometimes companies

22:03.960 --> 22:07.480
have already gone through, you know, some steps of a process to assemble data on their

22:07.480 --> 22:10.240
own, but they're hitting the point where they're realizing, like, the quality is just

22:10.240 --> 22:11.240
not there.

22:11.240 --> 22:14.920
And what they need, you know, what they need our community to help with is just going

22:14.920 --> 22:18.200
through and validating, which ones are correct, which ones are incorrect, so that they

22:18.200 --> 22:20.480
can increase the quality there.

22:20.480 --> 22:26.320
We also, we can definitely augment data, you know, maybe they have images that have certain

22:26.320 --> 22:27.320
annotations.

22:27.320 --> 22:33.320
Maybe the images have tags for objects that appear in the image, but the customer now wants

22:33.320 --> 22:36.080
to identify where in the image does that tag appear.

22:36.080 --> 22:41.360
So the tag might be dog, and they need to know exactly where in the image the dog is.

22:41.360 --> 22:47.320
And, you know, we can have our community either do pixel level, polygon annotation around

22:47.320 --> 22:53.800
the dog in the image, do a bounding box annotation around the dog image, those types of things.

22:53.800 --> 22:58.960
So yeah, there's there's a really wide variety of things that we can do in that sense.

22:58.960 --> 22:59.960
Okay.

22:59.960 --> 23:07.160
How much of this is best thought of as a services or consulting engagement versus some

23:07.160 --> 23:13.240
platform that you guys have built up that that automates a ton of the, you know, this

23:13.240 --> 23:14.240
back end work.

23:14.240 --> 23:19.880
I mean, it's really both, and I guess it depends on, I mean, the platform, I think, is really

23:19.880 --> 23:24.200
core and central to what we're doing and what we are able to do here.

23:24.200 --> 23:28.800
But I would say the consulting aspect on the front end of, you know, making sure we design

23:28.800 --> 23:33.800
the task precisely to, you know, making sure the customer is going to be very happy with

23:33.800 --> 23:37.880
the data that they receive and that is going to do what they needed to do for their models

23:37.880 --> 23:40.360
is also absolutely essential.

23:40.360 --> 23:45.880
So I would say, you know, we do have some customers that come to us that have, you know, teams

23:45.880 --> 23:50.040
that have been working on these, these problems for a long time and they know exactly what

23:50.040 --> 23:54.320
they want and they've already got an idea of, you know, exactly how to kind of organize

23:54.320 --> 23:58.440
the logic of, you know, what, what a correct annotation looks like.

23:58.440 --> 24:02.000
And in those cases, it can be relatively straightforward for us to move that right into

24:02.000 --> 24:03.160
our platform.

24:03.160 --> 24:09.040
In other cases, you know, we've got customers that, you know, they know the types of models

24:09.040 --> 24:13.360
they want to build, they've been struggling and they may even want, you know, some initial

24:13.360 --> 24:17.760
consulting on, you know, what types of data are available to us?

24:17.760 --> 24:25.480
You know, what can we do to improve, you know, improve the quality of their own models

24:25.480 --> 24:27.920
and we can do some initial consulting there as well.

24:27.920 --> 24:30.480
So it really just depends on the customer.

24:30.480 --> 24:35.720
But basically, you know, that yeah, the consulting aspect is setting up all the work, making

24:35.720 --> 24:41.600
sure we design the task correctly, going through an iterative, you know, process in the

24:41.600 --> 24:45.720
beginning with the customer where, you know, we say, okay, we think we understand your

24:45.720 --> 24:48.520
specs, you know, we've designed the task the way we think will work.

24:48.520 --> 24:52.960
We run, you know, maybe we do a thousand annotations for the customer, return that back

24:52.960 --> 24:56.840
to them and they verify, yes, this is what we're looking for, you know, yeah, you're,

24:56.840 --> 25:01.520
you know, yeah, the annotators are understanding the task and this looks good before we go

25:01.520 --> 25:02.520
to scale.

25:02.520 --> 25:09.960
Okay, and so you mentioned a bunch of things that customers have typically tried before

25:09.960 --> 25:11.560
they come to you.

25:11.560 --> 25:16.440
Are you doing all those things as well, plus some other things like, for example, you

25:16.440 --> 25:22.400
know, farming the labeling out to multiple people and doing some kind of quorum or voting

25:22.400 --> 25:24.000
or something like that.

25:24.000 --> 25:25.000
Right.

25:25.000 --> 25:26.000
So, so no.

25:26.000 --> 25:27.000
Okay.

25:27.000 --> 25:29.640
So, yeah, the simple answer is no.

25:29.640 --> 25:34.680
So, yeah, so we are not doing crowd sourcing.

25:34.680 --> 25:39.680
So first of all, we don't use mechanical turf, we don't use any external community, we

25:39.680 --> 25:45.480
use our own community through our spare five app and through the web that are, you know,

25:45.480 --> 25:49.960
everyone is fully vetted, we have great detailed information on our users, we get Facebook

25:49.960 --> 25:54.960
and LinkedIn data from our users, we do lots of survey and skill assessments, we're continuously

25:54.960 --> 26:01.440
monitoring their, their tasking behaviors in real time, monitoring the quality of, you

26:01.440 --> 26:03.760
know, of the tasks that are being submitted.

26:03.760 --> 26:06.520
And so, but we are not crowd sourcing.

26:06.520 --> 26:12.160
So on the flip side, what we do is we get really, really good at understanding the quality

26:12.160 --> 26:18.840
of the work that the, that the community members are able to provide so that we are targeting,

26:18.840 --> 26:22.920
we're targeting the right users from the beginning, right?

26:22.920 --> 26:27.040
And then, so we've got predictive models in place to identify, when a new task comes

26:27.040 --> 26:33.680
in, we can identify who are the users that we believe are most likely to do well on

26:33.680 --> 26:34.680
that task.

26:34.680 --> 26:40.280
And so, we can initially target the right subset of our community, then we turn the

26:40.280 --> 26:47.200
task on and we have a real time monitoring system, so we, we turn on that process and

26:47.200 --> 26:52.800
then as soon as the task is live, all of that real time monitoring is feeding back into

26:52.800 --> 26:59.320
our predictive models for quality assessment on the user, and so we're making real time

26:59.320 --> 27:06.360
decisions about when to potentially remove access to a particular, for a particular

27:06.360 --> 27:10.680
user because we're not seeing the level of quality that we need.

27:10.680 --> 27:16.320
And so we have a kind of that user quality model running in real time, and then we also

27:16.320 --> 27:20.040
have an additional layer, which is an answer quality model.

27:20.040 --> 27:27.640
So depending on the task, for some, for some task types, there are other types of data

27:27.640 --> 27:31.480
and information available just based on the answer itself that's provided, and so we

27:31.480 --> 27:35.160
have that additional layer just to make sure that the answer itself is, is meeting our

27:35.160 --> 27:36.160
quality bar.

27:36.160 --> 27:37.160
Okay.

27:37.160 --> 27:38.160
Great.

27:38.160 --> 27:39.160
That's interesting.

27:39.160 --> 27:44.760
My initial reaction was, it sounds like crowdsourcing, but, you know, semantics here,

27:44.760 --> 27:49.280
but it sounds like the key distinction that you guys would make is that, you know, with

27:49.280 --> 27:53.920
crowdsourcing, you kind of put the task out there, and anyone can kind of take it, and

27:53.920 --> 28:00.600
what you guys are doing is, you know, targeting it to specific people who developed a relationship

28:00.600 --> 28:01.600
with over time.

28:01.600 --> 28:03.120
Is that the right way to think about it?

28:03.120 --> 28:04.120
That's true.

28:04.120 --> 28:07.240
And I think, you know, it is a little bit semantics and just culturally help help people

28:07.240 --> 28:13.880
use the terms, but I think that crowdsourcing often connotates that you're going to send

28:13.880 --> 28:21.200
a question to multiple users and then assemble a correct answer from those multiple users.

28:21.200 --> 28:22.200
Okay.

28:22.200 --> 28:24.640
And so that's kind of the main distinction that I make.

28:24.640 --> 28:27.880
So a lot, you know, oftentimes if we're talking to customers, especially if they've already

28:27.880 --> 28:31.880
got a lot of experience themselves working with Mechanical Turk, they're really interested

28:31.880 --> 28:34.960
in, you know, well, what are the metrics you're using to decide whether you have enough

28:34.960 --> 28:40.320
consensus on a specific answer to move forward and how many users do you need to ask each

28:40.320 --> 28:44.280
question and that sort of thing, and in our, in our setting, it's actually irrelevant.

28:44.280 --> 28:48.080
That's not, that's not the approach we use, that's not the perspective that we follow.

28:48.080 --> 28:49.080
Okay.

28:49.080 --> 28:57.360
So is it fair then to think about this space as like Mechanical Turk is an API on top

28:57.360 --> 29:00.080
of the people, but you have to build everything.

29:00.080 --> 29:04.080
You're figuring out, figuring out how to get them your tasks, you're figuring out how

29:04.080 --> 29:07.560
to do all this voting stuff so that you can get decent quality data, whatever.

29:07.560 --> 29:08.560
Yeah.

29:08.560 --> 29:13.520
Yeah, you're writing the instructions, you're doing, yeah, you're filtering, you know,

29:13.520 --> 29:17.320
which users are you going to use, trying, trying to track their quality, all of those things

29:17.320 --> 29:18.320
yourself.

29:18.320 --> 29:19.320
Right.

29:19.320 --> 29:25.320
And then crowd flower, who I think a few months ago announced some specific, some specific

29:25.320 --> 29:31.600
offerings around labeling that I covered on the podcast, like they're kind of taking,

29:31.600 --> 29:34.600
they actually originally were on Mechanical Turk, but I think that's right.

29:34.600 --> 29:35.600
That's right.

29:35.600 --> 29:40.720
And they're kind of a slightly higher level of abstraction that's doing a little bit

29:40.720 --> 29:45.880
more of the stuff, but still fundamentally this, we're going to take the task and push

29:45.880 --> 29:49.880
it to a bunch of people and choose the results.

29:49.880 --> 29:54.960
And you guys are, you know, we're going to look at your problem and design a solution

29:54.960 --> 29:55.960
to get you quality data.

29:55.960 --> 29:57.960
That's exactly right.

29:57.960 --> 29:59.400
That's exactly right.

29:59.400 --> 30:01.400
Okay.

30:01.400 --> 30:06.200
And can you talk a little bit about, you know, as a statistician, like what are some

30:06.200 --> 30:12.320
of the interesting problems that you've, you've come up against and helping to build this

30:12.320 --> 30:13.840
for, for spare five?

30:13.840 --> 30:14.840
Yeah.

30:14.840 --> 30:22.280
I think, I mean, the, the most interesting and challenging problem for me was just how,

30:22.280 --> 30:28.160
how do we design a system and a platform that can work in a general sense at scale?

30:28.160 --> 30:34.920
So, you know, when I, when not, when I started out, you know, we were still doing, there

30:34.920 --> 30:40.200
was still a component of manual review internally just to, to make sure the various processes

30:40.200 --> 30:43.040
that we had in place were working as expected.

30:43.040 --> 30:47.040
And we had a lot of tailored, you know, for this task type, we managed it in this way,

30:47.040 --> 30:49.000
for this task type, we managed it in this way.

30:49.000 --> 30:56.000
And so when I came in, that was one of my initial goals was, how do I, how do I come to understand

30:56.000 --> 31:00.680
this entire system with all the complexity for so many different types of tasks and we

31:00.680 --> 31:04.880
have objective tasks, we have subjective tasks, we're looking at images, we're looking

31:04.880 --> 31:08.520
at text, we're doing all of these different types of problems.

31:08.520 --> 31:15.920
How do we, how do we develop a cohesive system to attack and address all of these different

31:15.920 --> 31:18.920
tasks types and ensure the right level of quality?

31:18.920 --> 31:24.600
So that was, that was really exciting for me and the, you know, and that's been the

31:24.600 --> 31:28.840
focus, you know, over the last several months and, and now we're there.

31:28.840 --> 31:33.240
And, and so that to me has just been a really exciting accomplishment.

31:33.240 --> 31:38.560
That sounds pretty huge, can you talk, or can you talk to whatever level of detail you

31:38.560 --> 31:39.560
can?

31:39.560 --> 31:40.560
Yeah, I know.

31:40.560 --> 31:41.560
Pipelines, slash.

31:41.560 --> 31:42.560
Sure.

31:42.560 --> 31:43.560
Oh, yeah, yeah.

31:43.560 --> 31:46.960
Oh, sorry, can you, could you clarify the last part?

31:46.960 --> 31:52.160
Oh, you're, you're, you're data science pipeline slash technology stack slash, you know,

31:52.160 --> 31:59.680
kind of anything that can help folks get a sense for, you know, as they're building labeling

31:59.680 --> 32:04.720
platforms, what are some of the, yeah, things that they need to consider?

32:04.720 --> 32:05.720
Sure.

32:05.720 --> 32:09.280
Well, so I can tell you just for the tech stack that we have here.

32:09.280 --> 32:16.480
So on the backend, we're using Ruby, we use our Postgres, and then we have a lot of

32:16.480 --> 32:21.840
different AWS services, and then on the front end, we have a web client, as well as

32:21.840 --> 32:25.800
a native iOS application.

32:25.800 --> 32:34.680
And yeah, and so let's see, yeah, so I think that there's a little bit, sorry, maybe you

32:34.680 --> 32:37.280
can give me a little more guidance on exactly what direction you want to.

32:37.280 --> 32:38.280
Oh, yeah.

32:38.280 --> 32:44.720
So, so that, that is very helpful on understanding the, the tech platform, it sounds like you

32:44.720 --> 32:50.000
guys are taking advantage of the cloud and AWS in particular.

32:50.000 --> 32:55.040
As you, you know, when you thought about this challenge of, okay, we've got all these

32:55.040 --> 33:02.560
different types of data, how do we unify this into a single platform that eliminates

33:02.560 --> 33:07.040
like the, a lot of the manual steps that you described?

33:07.040 --> 33:14.000
Are there any lessons that you've learned about building data science pipelines that helped

33:14.000 --> 33:18.240
you achieve that goal that you think would be transferable to other people?

33:18.240 --> 33:22.760
Yeah, and I, I don't know that this is specific to data labeling.

33:22.760 --> 33:28.160
I would say, I would say one thing that I've learned that, that's worked really well, both

33:28.160 --> 33:33.000
here and in previous companies that I've been in, in terms of integrating data science

33:33.000 --> 33:39.200
with the existing tech and existing product is, I think what's, what's really essential

33:39.200 --> 33:46.560
is you want, you want your data scientists to be focused on prototyping, like rapid prototyping.

33:46.560 --> 33:51.000
You want, you want them to be really nimble in terms of, you know, hey, if, if something

33:51.000 --> 33:54.960
about the product changes next week, we want to be able to like dig into the guts of

33:54.960 --> 33:59.440
our models, make our changes really quickly and be able to push that back out into production

33:59.440 --> 34:01.240
in a seamless way.

34:01.240 --> 34:07.640
And, and you don't want your data scientists to have to be spending the majority of their

34:07.640 --> 34:12.920
time, you know, maintaining and these larger systems and, and really having to, having

34:12.920 --> 34:17.520
to be so focused on the engineering side in terms of, you know, let's make sure everything

34:17.520 --> 34:20.320
staying up and stable and doing what it needs to be doing.

34:20.320 --> 34:25.760
So, so one solution in the team that I led previously at my previous company, one solution

34:25.760 --> 34:30.880
that we came to, which worked really well was, we developed, so we still wanted our data

34:30.880 --> 34:36.760
scientists to be able to, to prototype as quickly as possible.

34:36.760 --> 34:40.320
So I would say, you know, R is fantastic in terms of prototyping.

34:40.320 --> 34:45.000
You have your, you know, the graphics and visualization component is, you know, on,

34:45.000 --> 34:49.960
you know, is unsurpassed by, by any other software, you know, you have Python, has lots

34:49.960 --> 34:54.440
of packages that are fantastic and you can definitely do some good data visualization

34:54.440 --> 34:55.440
there.

34:55.440 --> 35:01.200
But our team was focused on R and so we wanted our, our teams to be able to, to do their

35:01.200 --> 35:04.840
modeling and we had a lot of predictive modeling kinds of work going on there.

35:04.840 --> 35:09.640
We wanted our data scientists to be able to do the predictive modeling in R and hand

35:09.640 --> 35:17.800
off the actual model component to the larger system in such a way that, you know, it was

35:17.800 --> 35:21.240
sort of, you know, plug it in so that you have, you know, these are the inputs coming

35:21.240 --> 35:25.920
into the model, these are the outputs coming out of R and we want that, we want to be

35:25.920 --> 35:31.520
able to just take that, that chunk of code that is the model, pass that over into production

35:31.520 --> 35:37.880
and, and get that plugged in and going at scale and, and that, you know, what, what worked

35:37.880 --> 35:43.200
really well, what we've done in both situations is we've used, actually used our serve.

35:43.200 --> 35:48.680
It doesn't have a, a fabulous amount of documentation out there, but it, it works really well and

35:48.680 --> 35:55.840
there's a, yeah, so anyway, so, so building out a system with our serve, building out some

35:55.840 --> 36:02.000
software around that to allow kind of, just the kind of input output portion to be handed

36:02.000 --> 36:06.960
over so that, so that you can have, you know, other standard systems, you know, picking

36:06.960 --> 36:10.800
it up and hitting your models and, you know, moving that all into the cloud so that you

36:10.800 --> 36:13.960
can, you know, if you, if you start getting a lot more volume hitting your model than

36:13.960 --> 36:17.720
you had originally anticipated, right, you just spin up some additional clusters and, and

36:17.720 --> 36:19.520
manage that traffic.

36:19.520 --> 36:22.920
Is our serve open source?

36:22.920 --> 36:23.920
Yes.

36:23.920 --> 36:24.920
Okay.

36:24.920 --> 36:32.520
And so what I, I think what I'm hearing is that you've got the, the exploration and the

36:32.520 --> 36:38.480
model development, that's all happening in R and then, you're able to take those models

36:38.480 --> 36:44.480
and essentially deploy them into our serve and use that for prediction as opposed to

36:44.480 --> 36:48.960
having to throw that over to an engineering group to, exactly, using something else.

36:48.960 --> 36:52.840
Yeah, exactly, exactly, and what I would say too is, I mean, it really depends on the

36:52.840 --> 36:53.880
algorithm that you come up with.

36:53.880 --> 36:56.880
If you're prototyping in the end, you end up using something that's mathematically

36:56.880 --> 37:02.400
very simple, then, you know, then maybe you just pass along, you know, your pseudocode,

37:02.400 --> 37:03.400
you know what I mean?

37:03.400 --> 37:05.000
I'm like, okay, these are the kinds of things that I've done.

37:05.000 --> 37:08.360
These are the steps and you have that re-implemented in a faster language.

37:08.360 --> 37:15.120
But, but if you're using, you know, there are many, many fantastic predictive modeling packages

37:15.120 --> 37:21.160
available directly in R and if you, if you get your system set up correctly, you know,

37:21.160 --> 37:29.480
we were using, you know, we had predictive models with, you know, 1,000 features in real

37:29.480 --> 37:34.280
time returning results in about 100 milliseconds, right, coming straight out of R. If all you're

37:34.280 --> 37:38.400
hitting R for is the actual modeling component, right, once it's already constructed.

37:38.400 --> 37:44.160
So, you know, and I think, and I think keeping the model code in R in that sense just makes

37:44.160 --> 37:48.440
it all that much easier for, you know, any modifications down the line that need to be

37:48.440 --> 37:53.840
made and, you know, and, and I think another layer that you can add on top of that, you

37:53.840 --> 37:59.240
know, which can work really well is, is if you can start to integrate some automated model

37:59.240 --> 38:03.640
rebuilding mechanisms, right, so you've got, got one system going on that's pulling in

38:03.640 --> 38:07.880
new data, continuously updating your models and then you've got another system that's just

38:07.880 --> 38:12.080
plugging into the existing most current model to actually get the results that can work

38:12.080 --> 38:13.080
really well.

38:13.080 --> 38:21.320
It's interesting, I'm glad you raised that I was thinking about that as well and if you,

38:21.320 --> 38:25.680
what you've done to address like model drift over time and if you've been able to build

38:25.680 --> 38:29.200
in like 360 degree feedback loops, that kind of thing.

38:29.200 --> 38:34.880
Yeah, so just somewhat, I haven't gone too deep on those sorts of things, so what, what,

38:34.880 --> 38:42.360
I have some tricks that I like to use in terms of, kind of monitor, model monitoring, when

38:42.360 --> 38:45.640
you are doing automatic updates and things and so there's various kinds of sanity checks.

38:45.640 --> 38:50.720
There's a, there's a paper out of Microsoft that was just fantastic in terms of like these

38:50.720 --> 38:55.120
are all the things that can go wrong when you put your model on autopilot and right and

38:55.120 --> 39:00.560
these are the things that you need to be monitoring and so with just, they're like seven step-by-step

39:00.560 --> 39:04.800
suggestions in terms of things that you might want to get implemented and that's fantastic.

39:04.800 --> 39:08.320
I can, I can try and pull up that paper for you.

39:08.320 --> 39:13.040
Oh, that would be amazing. That sounds like a great resource.

39:13.040 --> 39:15.040
Yes.

39:15.040 --> 39:17.040
Is it relatively recent?

39:17.040 --> 39:19.320
I believe it was in the last couple of years.

39:19.320 --> 39:22.440
Yeah, I've got to look it up.

39:22.440 --> 39:27.840
Just making it in okay.

39:27.840 --> 39:29.160
Yep.

39:29.160 --> 39:34.800
And now you guys are focused on computer vision and natural language.

39:34.800 --> 39:35.800
Is that right?

39:35.800 --> 39:36.800
Yeah, that's right.

39:36.800 --> 39:37.800
That's our focus right now.

39:37.800 --> 39:42.400
And how do those domains influence the approach you've taken?

39:42.400 --> 39:45.720
Yeah, that's an interesting question.

39:45.720 --> 39:51.800
So clearly with computer vision, we're dealing with image data, right?

39:51.800 --> 39:56.680
So I think it's had a huge influence in terms of the types of tooling that we're building

39:56.680 --> 40:02.520
out to allow our users to correctly annotate the data.

40:02.520 --> 40:10.120
Our end resulting data is only as good as the tooling allows for user accuracy, right?

40:10.120 --> 40:14.880
So it's definitely had a major influence in the types of tasks, the types of tooling,

40:14.880 --> 40:17.120
things like that that we've been designing.

40:17.120 --> 40:28.040
But I would say at this point, in the general system for QA that we've constructed, that

40:28.040 --> 40:31.200
is general, it's not specific in those areas.

40:31.200 --> 40:39.480
But what we would like to do, continue, I guess, delving into, is internally, what can

40:39.480 --> 40:44.360
we do in terms of natural language and computer vision modeling ourselves internally to improve

40:44.360 --> 40:46.480
the quality of the results itself?

40:46.480 --> 40:50.840
And that's something that we're just now starting to dive into.

40:50.840 --> 40:51.840
Okay.

40:51.840 --> 40:59.760
So in providing the services that you guys provide, are you needing to get into things

40:59.760 --> 41:05.080
like deep learning and other things, or are these more the things that the customers

41:05.080 --> 41:11.840
would use to train with the data that you're providing?

41:11.840 --> 41:13.880
Yeah, that's right.

41:13.880 --> 41:18.320
So we purely handle delivery of the training data.

41:18.320 --> 41:23.600
So we can do some consulting in terms of, yeah, if you use data like this, this is

41:23.600 --> 41:27.240
how that may affect the models, but it's really just more of a consulting aspect.

41:27.240 --> 41:30.920
We're not doing any of the model training ourselves, we're not hosting any models, nothing

41:30.920 --> 41:31.920
like that.

41:31.920 --> 41:32.920
Okay.

41:32.920 --> 41:33.920
Okay.

41:33.920 --> 41:34.920
Interesting.

41:34.920 --> 41:41.080
Do you have a set of, you know, they're like a top three list of things that you would

41:41.080 --> 41:45.280
want everyone to know about training data?

41:45.280 --> 41:46.280
Oh.

41:46.280 --> 41:50.120
That's a good question.

41:50.120 --> 41:51.520
Let's see.

41:51.520 --> 41:56.840
Yeah, I think, yeah, I mean, I think anyone who's got, you know, any experience in the

41:56.840 --> 42:00.600
field knows that, you know, your model is only as good as your training data.

42:00.600 --> 42:05.640
If you're, if you're training data really only represents, you know, a subset, a specific

42:05.640 --> 42:13.480
subset of the space in which you expect your model to function, then, you know, you're

42:13.480 --> 42:18.360
going to have, you're definitely going to have low accuracy in, in areas where you haven't

42:18.360 --> 42:20.880
provided as much training data.

42:20.880 --> 42:25.760
So definitely you need good, good coverage in terms of, you know, whatever, whatever the

42:25.760 --> 42:30.440
inputs that you're going to be anticipating, that will be coming into this final model

42:30.440 --> 42:33.920
that you build, you want to make sure that your training data represents those inputs

42:33.920 --> 42:37.920
as closely as possible in order to get the best results.

42:37.920 --> 42:38.920
Okay.

42:38.920 --> 42:39.920
One more?

42:39.920 --> 42:40.920
One more.

42:40.920 --> 42:54.600
Well, and I think, I guess one interesting thing to think about is it, you know, it depends,

42:54.600 --> 42:58.360
I think in the computer vision and natural language applications that we're focused

42:58.360 --> 43:08.200
on, the quality of the data is really essential, but in other areas, there are situations

43:08.200 --> 43:13.800
where you can get away with, you know, less, with lower quality training data, and the

43:13.800 --> 43:18.000
model is, you know, as long as the, as long as the patterns are there, the patterns are

43:18.000 --> 43:22.600
present, you know, your model, model may still be able to pick up those patterns, right?

43:22.600 --> 43:29.280
And so, I guess just keeping in mind what level of quality is important or essential for

43:29.280 --> 43:33.720
the type of model that you're building and the type of methods that you're using, you

43:33.720 --> 43:35.880
know, there can be some variation there.

43:35.880 --> 43:36.880
Okay.

43:36.880 --> 43:41.400
How would you characterize the scenarios in which you can get away with the lower quality

43:41.400 --> 43:42.880
training data?

43:42.880 --> 43:50.200
I would say definitely when you're, when your model is more about summarizing and generalizing

43:50.200 --> 43:56.160
the data, then, you know, having a few odd observations in there isn't going to dramatically

43:56.160 --> 43:59.200
affect, you know, affect that, that summary.

43:59.200 --> 44:04.240
Are there any examples that come to mind of customer space X?

44:04.240 --> 44:05.240
Oh.

44:05.240 --> 44:07.240
Let's see.

44:07.240 --> 44:13.080
Well, I don't know, there's some, well, so here's an interesting example, it's a little

44:13.080 --> 44:15.000
bit on the edge of what you're talking about here.

44:15.000 --> 44:22.800
So, so Sentient is a customer of ours that is, they're a provider of AI.

44:22.800 --> 44:28.400
We have a task that we've been running for them for quite some time now.

44:28.400 --> 44:35.560
What they're interested in understanding is user perception of similarities between

44:35.560 --> 44:37.160
shoots.

44:37.160 --> 44:42.200
So they're building out, you know, they have models that they're building out that

44:42.200 --> 44:49.440
are trying to decide what shoes belong together, not from some specific taxonomy or, you know,

44:49.440 --> 44:51.880
hierarchy that some human person wrote down.

44:51.880 --> 44:55.560
But, you know, like, oh, first you go by color and then by size, nothing like that.

44:55.560 --> 45:00.560
What they want to understand is what a human person looking at a collection of shoes, you

45:00.560 --> 45:05.000
know, if you say here's one pair of shoes, now look at these other 10 pair of shoes,

45:05.000 --> 45:06.520
which one is most similar?

45:06.520 --> 45:11.280
And they're really trying to understand the human's perspective of, you know, which of these

45:11.280 --> 45:12.680
10 shoes do you think is similar?

45:12.680 --> 45:14.360
So, it's a very ambiguous task.

45:14.360 --> 45:19.640
It doesn't actually have a right or a wrong answer, but, but when we throw this task out

45:19.640 --> 45:25.560
to our users and we return the data back to Sentient, they are able, they've had very good

45:25.560 --> 45:29.840
success in terms of improving their models, which, you know, in terms of what types of

45:29.840 --> 45:35.840
results they're able to surface at, you know, as a result of getting a very deep understanding

45:35.840 --> 45:38.880
of what similarity means at a human level.

45:38.880 --> 45:45.200
So, you know, there are many, many varying degrees of, you know, of going, you know, the ambiguity

45:45.200 --> 45:51.480
versus, you know, essentially a very precise, you know, correct answer and it just absolutely

45:51.480 --> 45:54.960
depends on the model that you're trying to build exactly what you need.

45:54.960 --> 45:55.960
Okay.

45:55.960 --> 45:59.600
And that example are they ultimately trying to make recommendations or do something?

45:59.600 --> 46:00.600
I believe so.

46:00.600 --> 46:01.600
I believe so.

46:01.600 --> 46:02.600
Okay.

46:02.600 --> 46:05.600
Man, I feel like I should have asked you about customer examples.

46:05.600 --> 46:06.600
Yeah.

46:06.600 --> 46:09.360
That was awesome.

46:09.360 --> 46:15.600
Other interesting kind of use cases that you guys have taken on that we can talk about?

46:15.600 --> 46:16.600
Sure.

46:16.600 --> 46:17.600
Yeah.

46:17.600 --> 46:18.600
Well, so here's one we did recently.

46:18.600 --> 46:20.680
This was kind of different for us and it was a lot of fun.

46:20.680 --> 46:28.320
So there's a company called Init.ai and they're building AI chatbot technology.

46:28.320 --> 46:35.160
And so they, they're interested in building these chatbots in specific contexts.

46:35.160 --> 46:43.000
And so they really, they need conversation data, like they need, you know, a text of conversations

46:43.000 --> 46:47.840
in these contexts and they're having a difficult time going out and, you know, finding that

46:47.840 --> 46:49.720
data publicly available, things like that.

46:49.720 --> 46:55.200
And so, so we were talking with them, you know, and, you know, we've already typically

46:55.200 --> 47:00.120
done lots of categorization of text, we'll do what's called like aspect opinion linking

47:00.120 --> 47:06.000
of text, you know, various kinds of NL tasks, but what, what we ended up doing for Init

47:06.000 --> 47:14.560
was we actually helped them produce the conversations and then took those conversations and labeled

47:14.560 --> 47:16.720
the data, the text of those conversations.

47:16.720 --> 47:21.360
So we actually ended up designing a task that we put out to our community, which was,

47:21.360 --> 47:26.520
you know, pretend you're selling flowers and, you know, and now you'd be the, be the

47:26.520 --> 47:29.400
person selling flowers and then to another user we're saying, you know, pretend you're

47:29.400 --> 47:30.400
buying flowers.

47:30.400 --> 47:34.240
And maybe we, you know, give some guidance, things that the customer is interested in learning

47:34.240 --> 47:35.240
more about.

47:35.240 --> 47:40.000
And we actually send, send the task back and forth to collect a complete conversation.

47:40.000 --> 47:45.160
So, yes, I think we assembled something, I forget on the, I think it was something like

47:45.160 --> 47:47.360
10,000 conversations that we assembled.

47:47.360 --> 47:51.360
And then for each of those conversations, we went back and we did the labeling that they

47:51.360 --> 47:57.080
needed in order to understand the content of what's going on, you know, in those conversations

47:57.080 --> 47:59.600
to help train the AI models that they're building.

47:59.600 --> 48:00.920
So that was, that was fun.

48:00.920 --> 48:04.800
That was fun for us in terms of just designing it out, but it was also fun for the community.

48:04.800 --> 48:07.880
We got so much feedback from people saying, like, I love this.

48:07.880 --> 48:13.040
I could do this all day, you know, because you're just, and the conversations were fantastic.

48:13.040 --> 48:16.400
So I mean, it was, it was really, it was a lot of fun.

48:16.400 --> 48:17.400
That's awesome.

48:17.400 --> 48:18.400
That's awesome.

48:18.400 --> 48:25.120
That reminds me of someone had a month ago or so set up basically these three kind of

48:25.120 --> 48:30.240
conversational chatbots in a, in a chat room and they were just talking, talking to each

48:30.240 --> 48:31.240
other.

48:31.240 --> 48:34.840
And you sit there and monitor and when they got stuck, he just threw out some random thing

48:34.840 --> 48:35.840
to get them.

48:35.840 --> 48:37.600
Oh, that's fabulous.

48:37.600 --> 48:39.960
Oh, I gotta look that up.

48:39.960 --> 48:41.440
That's fantastic.

48:41.440 --> 48:44.560
Oh, that's all.

48:44.560 --> 48:49.400
So I don't know that I'll be able to find that, but if I can, I'll stick it in the

48:49.400 --> 48:50.400
show.

48:50.400 --> 48:51.400
Okay, that'd be great.

48:51.400 --> 48:52.400
That'd be fantastic.

48:52.400 --> 48:59.680
So one of your top, one of your top three things was subsetting the space, which reminded

48:59.680 --> 49:02.920
me that we needed to talk about this diversity point.

49:02.920 --> 49:03.920
Oh, right.

49:03.920 --> 49:07.440
I want you to kind of start us off in this discussion with, you know, the examples that

49:07.440 --> 49:10.960
come to mind for you of like where it's been done really poorly.

49:10.960 --> 49:13.760
Well, well, actually, I have an example.

49:13.760 --> 49:18.800
This is something we actually had an article in TechCrunch about this recently.

49:18.800 --> 49:22.600
So we've been thinking about this a lot just since, you know, it's obviously a benefit

49:22.600 --> 49:26.120
that we can provide to our customers to actually get the diversity and the, you know, the community

49:26.120 --> 49:27.440
that they need.

49:27.440 --> 49:31.840
But so we did a little experiment in how, so we started thinking about the question

49:31.840 --> 49:34.520
of, you know, how different are the results?

49:34.520 --> 49:38.560
Like how different does the training data look if you're sampling, you know, various types

49:38.560 --> 49:40.240
of populations?

49:40.240 --> 49:44.160
And so, you know, and it turns out we really didn't have to dig very deep.

49:44.160 --> 49:50.000
So one of the first data sets that I went to analyze, we had a task that we had put

49:50.000 --> 49:56.040
out to our users just as sort of a fun mental break once in a while, which was called rate

49:56.040 --> 49:57.040
the puppies.

49:57.040 --> 50:02.720
And so we just show you pictures of puppies and then you rate them from one to five stars,

50:02.720 --> 50:06.120
you know, cute or okay, maybe not so cute.

50:06.120 --> 50:10.400
And so we've collected, we've been collecting that data actually over quite a long period

50:10.400 --> 50:14.640
of time, just, you know, a few puppies to rate, you know, here and there for our users.

50:14.640 --> 50:18.920
And so the first thing I thought was, okay, let me just take a look at the data and see

50:18.920 --> 50:20.640
how the ratings differ by gender.

50:20.640 --> 50:26.240
And so I split the data by gender and it was just dramatic and obvious.

50:26.240 --> 50:31.720
Difference that the women were rating the puppies as cuter consistently across the board,

50:31.720 --> 50:33.480
across all puppies.

50:33.480 --> 50:39.640
And with, and there was a wider gap on the cuter end of the spectrum and the gap was more

50:39.640 --> 50:44.680
narrow on the not so cute end of the spectrum, but it was, but it was still there.

50:44.680 --> 50:46.720
And yeah, it was just striking, right?

50:46.720 --> 50:50.800
And it's, you know, it's a simple example and, you know, okay, well, how, how, doesn't

50:50.800 --> 50:54.680
matter, you know, how cute the women of the matter rating the puppy is, okay, probably

50:54.680 --> 51:01.200
not, but it's such a, it's such a clear example of the difference, differences that you can

51:01.200 --> 51:06.800
get in the training data itself, right, just by sampling a different population.

51:06.800 --> 51:11.320
And of course, the training data is what's guiding your model in terms of the output that's

51:11.320 --> 51:12.320
coming up together.

51:12.320 --> 51:13.320
Mm-hmm.

51:13.320 --> 51:14.320
Yeah.

51:14.320 --> 51:18.920
But yeah, so that's an article in TechCrunch, we can put a link to that article as well.

51:18.920 --> 51:19.920
Okay, nice, nice.

51:19.920 --> 51:32.040
And so the, do you run into any challenges in identifying diverse communities to target?

51:32.040 --> 51:35.520
What are the challenges generally that come, come up for you guys and trying to solve

51:35.520 --> 51:37.200
this problem for people?

51:37.200 --> 51:38.200
Sure.

51:38.200 --> 51:42.120
So each of our customers is going to have, you know, their own, their own demographic

51:42.120 --> 51:44.680
that they're, that they are targeting, right?

51:44.680 --> 51:49.040
And so at this point, we have a broad international community.

51:49.040 --> 51:50.640
We have many, many users in the US.

51:50.640 --> 51:55.480
We also have many, we have a good presence across just internationally.

51:55.480 --> 52:02.240
And we have good data in terms of who our users are because we, we put out surveys to collect

52:02.240 --> 52:06.440
demographic information, we, we put out, you know, many different surveys to our users,

52:06.440 --> 52:09.480
you know, that they're compensated for, for completing these surveys to be able to

52:09.480 --> 52:10.480
collect that information.

52:10.480 --> 52:15.240
So we have a good understanding of our, our current user base, which is, you know, which

52:15.240 --> 52:16.240
is very diverse.

52:16.240 --> 52:20.760
But we, we occasionally still have a customer come in and ask for something very specific

52:20.760 --> 52:22.640
that we haven't targeted before.

52:22.640 --> 52:28.720
So they potentially could say, you know, we have this task and we need, who knows, we

52:28.720 --> 52:34.440
need experts in bird identification to label these images of birds, you know, and tell us

52:34.440 --> 52:38.000
precisely what species of bird, you know, this is, you know, something, something like

52:38.000 --> 52:39.000
that, right?

52:39.000 --> 52:42.240
And so when that comes up, you know, we can, first of all, we can go out and survey our

52:42.240 --> 52:46.000
community and find out, you know, in our, in our broad community, do we have people who

52:46.000 --> 52:51.040
are able, able to do this type of classification already, we can identify them.

52:51.040 --> 52:55.240
But and if we find that we don't have enough members in the community yet to meet the

52:55.240 --> 53:00.080
velocity needs or, you know, the volume needs for the customer, then we can go out and

53:00.080 --> 53:05.160
do specific targeting to bring, like, you know, online marketing to bring those individuals

53:05.160 --> 53:06.160
into our community.

53:06.160 --> 53:08.000
And we've had good success with that.

53:08.000 --> 53:09.000
Okay.

53:09.000 --> 53:13.640
So we've talked about demographic targeting primarily thus far.

53:13.640 --> 53:20.280
Have you ever done anything with, uh, psychographic targeting like, right, I don't know for whatever

53:20.280 --> 53:26.120
reason I'm thinking, hey, we want this to be answered by my Briggs ENTJs or absolutely.

53:26.120 --> 53:29.440
You know, we've definitely talked about it.

53:29.440 --> 53:33.200
There's, yeah, there's, you know, there are all sorts of interesting personality profiles

53:33.200 --> 53:34.200
out there.

53:34.200 --> 53:39.280
And that's what's kind of lovely is because we do have this stable community that's working

53:39.280 --> 53:44.560
with us is if we put a survey out to the community, right, you know, and we compensate them

53:44.560 --> 53:49.360
for their time in completing that survey, we can get any, any data that we need.

53:49.360 --> 53:53.880
So it's actually, it's actually very easy for us to target the user that the customer

53:53.880 --> 53:54.880
is interested in.

53:54.880 --> 53:55.880
Okay.

53:55.880 --> 53:56.880
Okay.

53:56.880 --> 54:01.360
And this is a little bit of an aside, but I often think that in the example of like Uber

54:01.360 --> 54:06.600
ratings, you know, I think that there's probably, well, not probably there's, you know, there

54:06.600 --> 54:11.640
are, you know, four average radars and there are three average radars like, you know, hard

54:11.640 --> 54:14.160
graders and easy graders.

54:14.160 --> 54:19.360
I don't have the impression that, you know, an Uber, for example, would normalize, you know,

54:19.360 --> 54:22.160
a person's rating against their average rating.

54:22.160 --> 54:23.160
Right.

54:23.160 --> 54:26.160
It has a strict interpretation, right?

54:26.160 --> 54:27.160
Three stars.

54:27.160 --> 54:28.160
Three stars.

54:28.160 --> 54:29.160
That's what the user said.

54:29.160 --> 54:30.160
Yeah.

54:30.160 --> 54:36.360
Does anyone do something like that or, you know, to what degree to, to what degree to your

54:36.360 --> 54:37.360
knowledge?

54:37.360 --> 54:42.360
Do folks think about that in, you know, thinking about like rating schemes?

54:42.360 --> 54:46.520
And what's the current kind of thinking in the industry around that kind of stuff?

54:46.520 --> 54:47.520
Yeah.

54:47.520 --> 54:50.360
So, yeah, this is a little outside of my, my area.

54:50.360 --> 54:51.360
It's totally right.

54:51.360 --> 54:52.360
Don't I?

54:52.360 --> 54:53.360
Yeah.

54:53.360 --> 54:54.360
Yeah.

54:54.360 --> 54:55.360
That's okay.

54:55.360 --> 54:56.360
Yeah.

54:56.360 --> 54:57.360
I mean, I actually thought about this quite a bit when I was working on the Netflix prize

54:57.360 --> 55:01.360
competition because in that case, we have the one to five stars rating system.

55:01.360 --> 55:02.360
Right.

55:02.360 --> 55:05.800
And so, you know, so I went really deep in, it's just an understanding, like, you know, what

55:05.800 --> 55:09.520
are, what are these different user profiles or, you know, what types of users are out there

55:09.520 --> 55:11.760
and, you know, one of these distributions generally look like.

55:11.760 --> 55:12.760
Yeah.

55:12.760 --> 55:16.040
It's like on one to five star rating system, you basically get one's four's and five's

55:16.040 --> 55:19.240
and occasionally a three, you almost never get a two.

55:19.240 --> 55:24.280
And, you know, so, I don't know, so I have some interesting tidbits and thoughts about

55:24.280 --> 55:25.280
that in general.

55:25.280 --> 55:32.000
But, you know, it currently at spare five from our perspective, you know, we occasionally

55:32.000 --> 55:33.000
do ratings task.

55:33.000 --> 55:37.520
It's not one of the, it's not one of the common customer requirements.

55:37.520 --> 55:41.080
And we'll talk with the customer about whether, you know, is a, is a binary answer.

55:41.080 --> 55:44.160
You're going to be more informative for them or a three level answer versus a five star

55:44.160 --> 55:45.160
answer.

55:45.160 --> 55:50.480
And so we do have some experience in background in thinking about what type of data is going

55:50.480 --> 55:52.720
to come out of those different kinds of rating systems.

55:52.720 --> 55:56.800
And, you know, and beside just the rating system itself, you know, the wording of the question

55:56.800 --> 56:00.920
is so important in terms of, you know, you know, the words that you use, if you, if you

56:00.920 --> 56:07.000
have a three layer system, do you say, you know, perfect, okay, terrible, you know, or

56:07.000 --> 56:09.960
do you make it more, you know, more nuanced it, right?

56:09.960 --> 56:13.640
And you're going to get, you're going to get different data based on different wording

56:13.640 --> 56:14.640
that you use.

56:14.640 --> 56:15.640
Which thing?

56:15.640 --> 56:16.640
Yeah.

56:16.640 --> 56:21.720
Which actually that, just to say going into, you know, another, like a whole, whole

56:21.720 --> 56:26.360
other area of things that we are thinking about constantly here at spare five is just,

56:26.360 --> 56:32.960
just in the, the wording and the framing of, of the question is just such an essential

56:32.960 --> 56:36.400
piece of what we do here, whether, you know, even if it's not a rating question, even

56:36.400 --> 56:42.520
if it's a totally open ended, you know, writing, writing captions for an image or free text

56:42.520 --> 56:49.600
keywords versus, you know, very objective taxonomy categorization, things like that.

56:49.600 --> 56:53.880
The wording of the question makes all the difference, right?

56:53.880 --> 56:59.920
And so in our case, you know, we actually take our users through, or there's a, there's

56:59.920 --> 57:00.920
a complete process.

57:00.920 --> 57:04.320
So when, when a new task comes in, right, where we're iterating with the customer, trying

57:04.320 --> 57:10.360
to design the task, when we start preparing our users to complete that task, we, we will

57:10.360 --> 57:13.840
typically put up a tutorial, we'll start with a tutorial, so the user's just working

57:13.840 --> 57:16.560
through the tutorial, they can work through it as many times as they want, and it's giving

57:16.560 --> 57:19.960
them direct feedback on whether they're, you know, doing what's appropriate for the

57:19.960 --> 57:21.160
task.

57:21.160 --> 57:24.040
The next stage is a qualifier, which is more like a quiz.

57:24.040 --> 57:26.080
You don't get the feedback as you're doing it.

57:26.080 --> 57:30.840
At the end, you find out if you pass or not, and typically we won't allow users to continue

57:30.840 --> 57:34.640
into the task without completing the qualifier, right?

57:34.640 --> 57:39.080
And so, so we have instructions for the task that we're writing, we have the tutorial

57:39.080 --> 57:42.080
that we're writing, we have the qualifier that we're writing, and then we have the task

57:42.080 --> 57:47.240
itself and the questions that we're designing inside the task, right?

57:47.240 --> 57:53.400
And all of the wording, logic, the orientation and design of that information on the page,

57:53.400 --> 57:59.960
it is all part of the, you know, the whole formula of how do you get the right data coming

57:59.960 --> 58:00.960
out at the end?

58:00.960 --> 58:06.520
So, so that's a really important piece that I think people that are new to this field

58:06.520 --> 58:11.280
are just finding out about it for the first time don't realize what an intense amount

58:11.280 --> 58:16.600
of work and thought and effort goes into getting that right.

58:16.600 --> 58:17.720
That's really interesting.

58:17.720 --> 58:24.320
To what degree are you relying on, or do you have the benefit of relying on other folks

58:24.320 --> 58:30.240
research to figure some of the stuff out, or is it all empirical analysis on your part?

58:30.240 --> 58:31.240
Right.

58:31.240 --> 58:36.840
So there is definitely a lot of great learning already out there, you know, that's been

58:36.840 --> 58:37.840
published.

58:37.840 --> 58:45.560
So we have Dan Weld, is a computer science professor at UW, and he consults with us regularly.

58:45.560 --> 58:46.560
He's been fantastic.

58:46.560 --> 58:52.560
He's a crowdsourcing expert, and he's been fantastic about pointing us to, you know, all

58:52.560 --> 58:56.520
the good research out there about different things that have been tried in terms of, yeah,

58:56.520 --> 59:00.200
in terms of instructions and tutorials and designing tasks and all those kinds of things.

59:00.200 --> 59:07.040
So there's definitely a lot of learning there, but I would say, you know, given, given

59:07.040 --> 59:13.520
that, you know, we are working in a somewhat different space in that we are not doing

59:13.520 --> 59:17.640
traditional crowdsourcing, we are not, you know, farming answers, questions out to multiple

59:17.640 --> 59:18.640
users at a time.

59:18.640 --> 59:23.040
And so there has been a lot of just individualized learning on our part in terms of how do we

59:23.040 --> 59:28.600
work with our users and what level are our, our users at, you know, how do we, how do

59:28.600 --> 59:32.720
we bring them through the training process to get them to the level that we need.

59:32.720 --> 59:36.600
So there's definitely a lot of internal learning, and I would say, you know, each time we do

59:36.600 --> 59:40.800
another task, you know, each, you know, we have certain task types that we've done again

59:40.800 --> 59:44.160
and again and again at this point, and we're learning each time we do them along the way,

59:44.160 --> 59:48.440
how to make refinements, how to optimize that process, you know, how to make it even more

59:48.440 --> 59:49.440
clear.

59:49.440 --> 59:53.960
Anything that we can do to make, to make the instructions more clear, it just saves in

59:53.960 --> 59:56.960
terms of efficiency because we have that many more answers coming through that are actually

59:56.960 --> 01:00:01.120
accepted and allowed into the deliverable for the customer.

01:00:01.120 --> 01:00:02.120
Nice.

01:00:02.120 --> 01:00:03.120
Nice.

01:00:03.120 --> 01:00:07.920
I think we're coming up on an hour, anything else that you'd like to share with the audience?

01:00:07.920 --> 01:00:08.920
Yes.

01:00:08.920 --> 01:00:09.920
Absolutely.

01:00:09.920 --> 01:00:16.960
Well, I would say, yeah, if anyone is interested in getting in touch with us, you know,

01:00:16.960 --> 01:00:21.320
a couple of ways to get in touch, you can always head over to spare5.com.

01:00:21.320 --> 01:00:23.200
You can also email me directly.

01:00:23.200 --> 01:00:27.120
I'm Angie at spare5.com.

01:00:27.120 --> 01:00:30.600
And I guess one other thing that we wanted to let the listeners know about, so we have

01:00:30.600 --> 01:00:33.480
a blog series that we started a couple of months ago.

01:00:33.480 --> 01:00:38.400
It's called Conversations in Machine Learning, and it's just all about any interesting

01:00:38.400 --> 01:00:43.760
new applications in AI and ML things, you know, that are popping up all over at various

01:00:43.760 --> 01:00:48.960
companies that we're watching in this space, and for your listeners, we're offering a

01:00:48.960 --> 01:00:54.840
fantastically fabulous spare5 t-shirt to the first 25 people who subscribe to the blog

01:00:54.840 --> 01:00:56.160
series.

01:00:56.160 --> 01:01:01.680
And if anyone's interested, they can sign up at it's a spare5.com slash podcast.

01:01:01.680 --> 01:01:02.680
Well, that's awesome.

01:01:02.680 --> 01:01:03.680
That's awesome.

01:01:03.680 --> 01:01:07.320
And I'll include a link to that, of course, in the show notes.

01:01:07.320 --> 01:01:08.320
Okay.

01:01:08.320 --> 01:01:09.320
Wonderful.

01:01:09.320 --> 01:01:10.320
Thank you.

01:01:10.320 --> 01:01:11.320
Awesome.

01:01:11.320 --> 01:01:12.320
Well, thanks so much, Angie.

01:01:12.320 --> 01:01:13.320
This has been a great conversation, and I really enjoyed it.

01:01:13.320 --> 01:01:14.320
Thank you.

01:01:14.320 --> 01:01:15.320
Thank you.

01:01:15.320 --> 01:01:16.320
Catch you next time.

01:01:16.320 --> 01:01:17.320
Thank you.

01:01:17.320 --> 01:01:18.320
Absolutely.

01:01:18.320 --> 01:01:19.320
Thanks, Sam.

01:01:19.320 --> 01:01:20.320
All right.

01:01:20.320 --> 01:01:21.320
Thanks, bye-bye.

01:01:21.320 --> 01:01:22.320
Thank you.

01:01:22.320 --> 01:01:23.320
All right.

01:01:23.320 --> 01:01:28.320
Everyone, that's it for today's show.

01:01:28.320 --> 01:01:34.920
Thanks so much for listening, and thanks once again to spare5 for sponsoring the show.

01:01:34.920 --> 01:01:41.720
Please don't forget to sign up for their t-shirt offer at spare5.com slash podcast.

01:01:41.720 --> 01:01:44.680
And of course, we both want to hear your feedback.

01:01:44.680 --> 01:01:52.360
On Twitter, I'm at Twimmel AI, T-W-I-M-L-A-I, and spare5 is simply at spare5.

01:01:52.360 --> 01:01:55.560
Reach out to us and let us know what you thought about the conversation.

01:01:55.560 --> 01:02:24.080
Thanks so much for your continued support, and catch you next time.

01:02:25.560 --> 01:02:26.560
Bye-bye.

