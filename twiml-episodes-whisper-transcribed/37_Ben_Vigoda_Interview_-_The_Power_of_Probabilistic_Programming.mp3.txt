Hello and welcome to another episode of Twimultoth, the podcast why I interview interesting people
doing interesting things in machine learning and artificial intelligence. I'm your host,
Sam Charington. The show you're about to hear is part three of our five part O'Reilly AI New York
series sponsored by Intel Nirvana. I'm very grateful to them for helping make this series possible
and I'm excited about the cool stuff they launched at the O'Reilly AI conference including
version 2.0 of their neon framework and their new Nirvana graph project. Be sure to check them out
at intelnervana.com. And if you haven't already listened to the first show in this series where I
interview Navine Rao who leads Intel's newly formed AI products group and Hanlon Tang and algorithms
engineer on that team, it's Twimultoth number 31 and you definitely want to start there.
My guess for this episode is Ben Vigota. Ben is the founder and CEO of Gamalon, a DARPA funded
startup working on Bayesian program synthesis. We dive into what exactly this means and how it enables
what Ben calls idea learning in this show. Note that Ben and I go pretty deep in this discussion,
so I'm issuing the Nerd Alert. All right everyone onto the show.
Hey everyone, I am here with Ben Vigota of Gamalon and I've been meaning to catch up with Ben
for a long time and I was just telling him before we got started about how we do these Nerd Alerts
now and he's like, oh, I'm going full Nerd Alert on this show. So if you like the Nerd Alert,
you're probably going to enjoy this show. So Ben, why don't we start by talking a little bit about
your background and what you're doing, the company, all that stuff. My background, well that
that requires a full Nerd Alert, a super full Nerd Alert. Well, I was at MIT PhD and I was actually
in a physics group second today. Oh, okay. Yeah, so physics is a good background, especially
statistical physics and a lot actually at Gamalon, a lot of our, a lot of folks there are
from physics background as well. I was kind of obsessed actually with machine learning and
AI stuff back in high school and middle school and it was lucky enough to
you get a few audiences with a few of my heroes and some of them recommended that I went
going to physics. That's what I did. It's kind of, it's like if you want to learn how to play
rock guitar where you go study jazz or classical, so you have good chops or something. So you know,
that kind of thing. Yeah, so that's my background, did a postdoc and it was a visiting scientist at
MIT for a little while and then I founded my, my first company was, we called them probability
processors. So they're microchips. Okay. And it was really the first microchip architecture,
first processor for machine learning, you know, before kind of GPUs and before the Google
Tensor processor unit, we created a sparse dense tensor processing processor. Oh, wow.
About five years actually before the TPU CPU. So that's in a bunch of stuff that's in like
every cell phone call you place probably goes through one of those because it's in most like
cell phone towers. Okay. Or a lot of them. And it's in cars and, oh, wow, might be going into
the Amazon echo. So it's in a bunch of places. And is that company still going or was it like
outside or acquired? Yeah. So that's kind of the basis of, you know, it's a big part of analog
devices now, just the company that acquired us. Big Boston, Boston, based semiconductor, yeah,
one of the best semiconductor companies and definitely the best one in Boston.
Right. So, you know, but through that experience, you know, we always thought, you know,
if we're going to have these processors, we got to make them easy to program.
Right. And so we came up with what we call probabilistic programming.
Okay. And, you know, back then you could kind of count on two hands, the other people who thought
they were working on probabilistic programming. We were a small cult. We all knew each other.
Yeah. Now it's just exploded. But, you know, we built one of the first industrial scale,
probabilistic programming systems and compiler systems. Back around the same time,
Microsoft was building in fur.net, okay, which they used. I don't know that one.
Oh, you don't know that one? Yeah. So, you know, it was used to prototype some cool stuff for gamers.
It matches like Xbox people, like if you're an Xbox player, and they used in fur.net to build
a machine learning model that'll find you really good people to play against. Oh, wow.
Okay. Kind of well matched your skill level. Yeah. And it's called true skill. And they also
did some stuff for Bing that I heard about that. Okay. Obviously not an expert on all the things
they didn't tell me. But yeah. So that's kind of where I came from in my background.
And were you in the keynote this morning here at O'Reilly?
I didn't get chance to catch it. It was, uh, I forget the name Jonathan, I think, from MIT.
Professor there at CSAIL was talking about some of the work that they were doing was
that involved probably ballistic programming. Oh, maybe Professor Josh Tannenbaum.
Josh Tannenbaum, yeah. Yeah. Okay. Yeah. He came to my talk and then we were hoping to get to work
together somewhere. Oh nice. Like we have great reverence for for what those folks do in their
lab at MIT. And there's a lot of cross fertilization there. Also one of his former postdocs,
Noah Goodman, who's not Professor at Stanford. Okay. He's a real leader in this field. There's
a few others. David Blight at Columbia here in New York. Okay. So probabilistic programming seems
like a good thing to dig into, but I don't think we got to what Gamalon is up to.
Well, Gamalon started as the largest investment by DARPA in probabilistic programming.
Okay. Over the last few years. And thus you can't really talk about any of the things you're doing.
No, of course you can. Of course you can. What they call a six-to-one technology readiness level one,
which is the academic and commercial research. Okay. You know, so we basically set out to make it
really easy for data scientists or human statisticians or modelers to create large-scale complex
Bayesian models and solve them with data. And then I had this breakthrough where we realized
with the tools we had built, we could actually get a computer to write its own probabilistic
programs. That's a new thing. That's not really an academia. That's just a Gamalon thing.
We call the underlying technology Bayesian programs synthesis, but we branded it idea learning.
Okay. Kind of compete with deep learning a little bit, like good branding, so we needed a good
term. So idea learning. There's some wind behind these sales now, the deep learning. Yeah.
It's interesting to see. So you have kind of a standard way. You walk folks through kind of
Gaussian stuff, probabilistic programming, kind of how that all fits together. Yeah, I do.
You know, you can also check out Gamalon.com. You can follow along on some of the examples that
we have on the technology tab. Like one good example would be say I wanted to make a little drawing
app, right? So we actually did this in one of our hackathons at Gamalon. It's pretty fun.
The idea is basically like Microsoft Surface or a tablet, you know, you would want to
with your finger or stylus, you know, straw triangle or square or whatever.
If you're like me, you're not I'm not I'm a terrible artist. So my squares and rectangles
and triangles come out super lumpy and messed up. But the system should still be able to recognize
them. And then it replaces what you drew with what you meant to draw. Okay. So I've seen there,
there are apps to do this and for that. Absolutely. They kind of I think ours is the coolest.
Cause I mean, I was totally just a toy. Like it's not a product. It's just to kind of play with
the technology. But one of the things that's really satisfying about it is most of those apps,
you sort of draw a triangle and it's like, Oh, that's a triangle. Yeah. But then the triangle it
puts there isn't the triangle you meant to draw. It just puts down like a 60, 60, 60, 60,
60s on the bottom, you know, standard size. So it's not really your triangle. It's their triangle.
Right. The thing, you know, so our app puts it's that map our experiment prototype hackathon thing.
But it's a good pedagogical tool. It puts your triangle. Nice. Okay. So the way it does that.
So I'm going to just take you through what's basically a cooking recipe. You could do a cooking
recipe on a podcast, right? Like take two eggs or some flour. Yeah. So it's going to be like that.
Nice. So what we're going to do is a cooking recipe to draw a triangle. Okay. All right. So
triangle has three corners. You know, we're going to have to pick a x y coordinates for the first
corner of the triangle. Cause this is going to be a random triangle. The corners could be all over
the place. It's going to be anywhere. So we're going to pick those at random. So let's pick the
first triangle. Maybe we're doing this. I'm going to date myself. But this is going to be a 1024
by 768 JPEG image or something, right? I'm going to draw this triangle. So we're going to pick a
number between one and 1024. And that's going to be the x coordinate. And I'm going to pick another
number at random between one and seven 68. I guess zero and seven 67 on the vertical axis. So we
picked that first coordinate. And then we're going to pick a second coordinate. We have two points
and we draw a line between them. And then, okay. So now we got a line, right with two ends.
And then pick a third point. And then we draw another line. Now we got almost a triangle.
Then we just got to bring it on home, close the triangle, draw the last line. We didn't need any
new points. We just need to connect to the opening. So that was a good probabilistic program.
We had some randomness because we picked the corners at random. We also had some determinism
because we drew the lines straight and just, you know, they're the same every time. If you tell
the points, what points are at the ends, the line is the same every time. That's what probabilistic
programs are good at, sort of combining randomness and determinism. And I could ask a question about
this specific app. Sure. Yeah. And I'm totally biased by this thing that I've seen on the iPad.
Okay. Why are you picking the random points if I'm drawing with my finger or triangle? Yeah.
And I have seen the thing where it'll draw the isosceles triangle and what I drew is like nothing
like that. Right. Right. But why not just figure out what the vertices were that I drew. The
corners changes the direction and the lines. Yeah. You're asking the exact right question. Right.
So we've got this cookbook recipe, but we want the real corners of the triangle you meant to draw.
So here's what we're going to do. We're going to take this cookbook recipe and we're going to run it
over and over and over again. And every time we run it, we're going to adjust those random three
corners and move them a little. And then we're going to move them and then we're going to re-render
the triangle and we're going to compare it to the triangle you drew. And we're going to score it.
And if it got better, if it got closer to the triangle that you drew this random cookbook
recipe output, then we're going to keep that new set of corners. And if the corners got,
if the output got worse, like it doesn't, it's moved away from being like the triangle you drew,
then a lot of the time where we're going to reject that and try again, try some new corners.
Is this like some of the squares of the distances between the vertices or something like that?
Yeah, any distance metric. This is the red light district, the CD underbelly
that side at the railroad tracks of probabilistic programming is you always have to have a good
way of scoring at the bottom there. Mean squared errors gives any. That's basically saying,
hey, I think the triangle that the cookbook output, if I add some Gaussian noise to it,
it would look like your triangle. That's really what mean squared distance means there in that context.
So anyway, so yeah, so you could pick absolute value, L1 distance, you could, and that's
it's another thing that's really saying there's pass on noise between your cookbook recipe and what
I drew the real observed triangle. So anyway, so that's the south side of town. But once you get
that figured out, then you can just keep adjusting those corners until it matches. And once it matches,
as best as it's going to, then you could take, say, the most likely run you had of the cookbook
recipe. And you say, what are the corners there? You're like, okay, I've got a set of corners.
They've matched as, you know, the best ones we found. And you could draw a triangle with those
corners. You take that triangle and you draw it right on the tablet. And the person goes, wow,
that looks like the triangle I meant to draw. Now, what I just described to you is totally not all we do
because it is insane idea to run a program over and over again and adjust the parameters
or random and hope you hit the output. So that would be like, I don't know, throwing
from our hotel room here at a top Manhattan, we would be throwing darts and trying to hit the
statue of Liberty or something. So we don't actually do that. But I think that's a good way to think
about it. And for simple programs, simple policy programs, you can actually do it that way.
What it is, it's a good way to think about what's happening. And what this algorithm will do is
it also those talked on the show recently in the context of industrial applications of AI.
We've talked about simulation a lot. Simulation. This is a simulator, right? This is a simulator.
So what did you just did? You just simulated where your data came from. This is a story or in fact,
the way we usually teach us to new employees or new people that we're trying to teach it to is
we say, oh, you have some data and you want to do machine learning on it. You want to do
probabilistic programming on your data. Okay. Well, the first thing you should do is in English,
get out your literary cap in your quill pen. And write down in English, the story of how you think
your data came to be, right? Which is a simulation. It's a simulation of the system that made your
data. Whether that's a biological thing, you know, this is heartbeat, data, or whether that's
financial data or whatever. And the characters in your story, those are going to be the variables in
your probabilistic program. And then the things they do, the actions they take are going to be some
of the determinism like like the straight lines we drew. And if they have choices to make, those
are going to be random coin flips or dice rolls in your probabilistic program. You know, if you
knew exactly your system, if you could deterministically simulate it, it wouldn't be a probabilistic
program, it would be a regular program. So the whole point of this is that there are certain things,
you know, you have a pretty good idea of the story that created your data, but there's some stuff
you're not sure about. Whatever that is, that's where you put the random variables in your
probabilistic program. And then whatever those random variables are, the program's going to try
as many possibilities through those random variables as a kin to try to match your data. And that's
what gives you the fancy term, the posterior distribution. That's what tells you if I made a coin flip
and, you know, if I flip the coin heads, I choose to draw a triangle. If I drop flip the coin tails,
I choose to draw square. And I've got my data, you know, looks like a square. Then if I run this
over and over again, that coin flip is going to tend toward the side where the, yeah, I'll put
ahead and square. And so you'll, you'll figure out that's the kind of choice that this square-drawing
system is doing is making a lot of the time. Probably probabilistic programming then is you just
really summarize it for us. It's kind of a methodology for programming that allows us to introduce
randomness, right? And, yeah, and for, and really for simulating systems, simulating systems that
create data. And I think when people say probabilistic programming, they don't just mean the programming
language with random variables, because like Python has random variables. Technically, Python's
a probabilistic programming language, but that's not what we mean in the field. We also mean the
solver, the thing that tried lots of different values of the random variables and tried to find
good ones. And that was actually a segue to my next question, which is, you know, when I think about,
you know, not knowing a whole lot about probabilistic programming applied, you know, and I think about
how I might try to approach this. It's like, you know, Python either, you know, do, you know,
get a loop and do a bunch of random stuff, you know, or get a loop and, you know,
deterministically do like a brute force search of my space or something like that.
Right. Is, you know, how are you doing this, you know, or what different techniques and
the programming languages, platforms, frameworks, that kind of thing are you are being used for
probabilistic programming? Yeah. Well, may I give you a little quick overview of, you know,
three sentence overview of what people are doing in general on this? So I would say people are
doing all kinds of different things. So some people, if they want to figure out, was it a square
or triangle? And they write a program that flips a coin and if it's a heads, it draws it square,
and if it's a tail draw triangle, there's a bunch of different ways you could try to evaluate the
way to that coin. So you could run it over and over again, and that's called a sampling method.
And you could do a Monte Carlo style thing there. And then within Monte Carlo methods, there's all
the tons of those. There's metropolis Hastings and important sampling and Gibbs sampling and all
those things. And then other people will use variational methods. And there's black box variational
methods and there's mean field and there's, you know, all kinds of things there.
And what are the principal differences between Monte Carlo, Sim, and variational methods?
If I had to like summarize it well, just like in a sentence, I would say a sampling method picks
a value over and over again, and a variational method fits a curve or a function. Okay. So like,
it's basically think of a regular old Gaussian distribution, right? And how did it get made? Well,
say there's some, your data actually has a real Gaussian distribution. And you want to fit that.
So one thing you could do is you could pick a mu, pick a sigma, draw the curve,
take the mean square to the actual data, didn't get it right. Okay, adjust a little,
keep doing that, keep moving the mean, keep moving the sigma until it fits. That's a variational method.
Okay. Because what you did was you changed some parameters of this curve and fit the curve model.
Yeah. Fitting a curve is basically a variational method. And then the other way you could do it
is Monte Carlo method, which is you could just sample a bunch of samples from a Gaussian with some
mean invariance and then compare the histogram you got to the data and keep adjusting the parameters
of where you're sitting. So one way to do it, you know, the science museum, they got those pegboards
and the ping pong balls fall down and they make a Gaussian pile at the bottom, right? So you could,
you know, you could change the spacings of the pegs in there until that would be a more like a
sampling method. You know, change all the maybe there's biases of those pegs like they push the
balls more to the right or the left, you get a skew. Okay, stuff like that. So, you know, so there's
all different kinds of ways to sort of fit variables to data in a probabilistic program. And I would
say the community is in this massive exploration of ways to do it. Another way is gradient-based
methods, which is what's usually done in neural networks. You can do backpropagation through a
probabilistic program using auto differentiation methods and there's a bunch of papers on that.
What we do at Gamalon is a little different. We sort of look at each of these core methods
as or even some of their sub components like taking a gradient as kind of like an atom
or a subatomic particle or like an amino acid like a building block. And then what our system does
is kind of evolves solvers on the fly to do the best job of solving the probabilistic program you
throw at it. So, it's a pretty complex piece of engineering. Yeah, what does that mean? Does that
mean that the system knows about some, you know, a handful of archetypal solvers and it kind of
picks one and fits its parameters or is it it's kind of like more evolutionary than that? It's more
evolutionary than that. It's kind of like doing some approximation of what maybe a human mathematician
who want to design a solver for a model would do. What's the cookbook for that? There's no good
cookbook, right? In fact, there's a theorem that says there's no good cookbook. It's called the
no free lunch theorem, which basically says given a problem, there's no one solver that will solve
all problems best. So, every problem, you know, they're definitely always going to be for any given
problem. You know, you might there may be a general class of methods that work pretty well,
but better than some other class of methods. But that class of methods would work that worked well
on that problem could work terribly on some other problem. So, there's no guarantees, right?
That a particular solver will be particularly good on a particular prompted program. So,
you really just have to try stuff, which is what humans do. You know, if you look at like, you know,
nips the conference or AI stats or any of these conferences, you kind of look through a lot of the
papers historically, like somebody said, here's a model I invented. I want to solve, you know,
this problem. I wanted to, I don't know, cluster documents by topic or something. And then,
okay, this model was hard to solve. So, I had to spend a year of grad school or two years or five
years figuring out a solver method that would work on it. Right. And sometimes for very complex
models, people cobble together a couple of different solver methods for different parts of the
model. And then, you know, at the end of grad school, they get it working and they publish their
paper. Yeah. And, you know, if you're real good, you can do one of those a year. And so, most
papers are are a choice of a model and a choice of a solver kind of made it. Uh-huh. And what we're
trying to do is automate that, you know, grad, we're trying to, I guess, automate grad school. It's
funny. It's funny that you describe it like that that I've spent a lot of time and have asked a
bunch of folks on the podcast about, you know, trying to understand deep neural network architectures
and how do folks get to Google Net or, you know, one of these kind of, how do you arrive at that?
Yeah. And the best explanation, the best sarcastic explanation that I heard recently was
gradient descent by graduate student. And there's an acronym for it totally. But here's a non-sarcastic
because there's a theorem for that too, which is if a model is at its core, a simulation of where
your data came from. Think about what that, what a synonym is for that. Another synonym for that
is scientific theory. A scientific theory, a good one is a very clean, accurate simulation
for your data came from. Whether it's a black hole or a mitochondria or something. And a good
scientific theory will, you know, fit the data. It'll predict future events. It'll do all these
things great because it's a great simulation. It really models the system well. Well, we know that
the space of scientific theories is super exponential. There's a ton of them. There's way more than
even NP complete. Right. So the search for scientific theories is by its definition, a computationally
hard exercise. Like, you know, there's never going to be, well, we hope there's not going to be
a polynomial time algorithm that just gives, well, there'd be some pros and cons. So if there was
like a fast, you could run on your laptop and it could find a scientific theory to fit any data,
if that algorithm existed. The good news is science, we'd know all science, right? Any data we
got from anything we'd understand it immediately, science would be done. That'd be kind of cool in a
way. Problem is if the aliens come, if the aliens come, they probably discovered this too. How
they get here, they had like really good science. They've got a fascinating light speed travel.
And they're really not interested in our culture, right? They don't want to hear about our science
and our theorems and trade because we came up with different ones because it's hard. Like,
they already have them all because they have this polynomial time algorithm. So the only reason
they're here is for our water and our, you know, probably going to eat us or something.
So that would be, so we most of us hope that there's no polynomial time algorithm for finding
good models. You don't think there are benevolent aliens that just want to explore the universe and
make friends? Well, if they have, if they have all theorems, why don't they stay home, right? Still play.
Anything we would say would be boring to them. Yeah. Yeah.
Because they could simulate, they could make a theory of everything about the Earth.
They could just have us running in an aquarium and simulation. Yeah, exactly.
Why come all the way here? My father. Yeah. Yeah. Interesting. I guess that's the other
alternative is we would be, if they had this algorithm, then we would be that simulation.
Right. Yeah. So I need to get you. If anyone has a connection with Elon Musk,
so I can get him on to talk about this, you know, we are a simulation theorem, make it happen.
So the triangle example, I think, is interesting and illustrative because it's of its simplicity,
but it's not satisfying because it doesn't tell me where I would use this. And more specifically,
I guess, what are the classes of problems for which this Gaussian approach is better than any of
the other things that I would have otherwise tried to do? And by the way, it's much more than
Gaussian. So we use all kinds of different random distributions and positive programs and
also the determinism. So in fact, programming is more much more than Gaussian.
Because in fact, we can express any probability distribution.
Progressive programs are sort of turning complete, if you will, for describing probability
distributions, they can make any probability distribution, any space. So here is where we should
probably make a distinction between the model and the solver. So on the model side, a process
program can express a model of any data. It's a great scientific tool. It's a great, you know,
I mean, what if all scientific theories were written in a clear stochastic lambda calculus,
so across all different branches of the sciences, we could all just have this clear
language that we could trade our theories in. So someone said, you know, Bayesian modeling is,
oh, you know, who was this Pedro Domingos said to me, you know, the Bayesian tribe think they're
they're right, they're doing things the right way. He wrote the master algorithm, yeah.
Yeah, because Bayesian is like clearly they're kind of the like correct way, you know,
you need like a British accent. So like express, express a theory on anything, you know,
a probability theory is the theory of uncertainty, like this is the right way to do. But of course,
all but the simplest Bayesian models are computationally intractable to solve. And so, you know,
I think people who are in other tribes, like neural networks would say, well, you know, we restricted
ourselves to set of probabilistic programs that you can use gradient based methods on. And that's
how we're getting all these great results. And so we would say, oh, great, gradient methods sound
good to us. We're incorporating that into our probabilistic programming solver platform,
along with all these other methods. And when they come in handy, we'll use them. And so,
we do everything that TensorFlow does. In fact, our system, like David Blisystem in Columbia,
Edward actually is built on top of TensorFlow. So there's probably a programming system on top of
TensorFlow. Okay. Interesting. Yeah. So David BliB-L-E-I. Okay. David Bli. Brilliant. Faculty member at Columbia
University and good colleague. Okay. So yeah, absolutely. And so, you know, there are some
architectural limitations in using TensorFlow. But you get the benefit of, you know, this
open source project that has a lot of good momentum and energy behind it. And so, you know,
probably the takeaway is it's not an either or. But I like to start my design flow when I'm
thinking about machine learning with a probabilistic program with an English story in English with
my quill pen of where my data came from. Because I think it helps you do model discovery by
graduate student creating descent to know what that generative story is of your data. That's a good
starting point. So can you maybe walk us through that design thinking process for application that
you've applied this to? Yeah. That's a good question. I hope to think of one. Yeah. I mean, so think
about enterprise data dirt. You're trying to clean up enterprise data. So you can think about,
well, what are all the ways that data gets corrupted? Oh, it gets abbreviated. So someone deleted
some letters, gets permuted. There's a whole bunch of things you can you know, sat down for a half
hour with your friend and brainstormed ways that data could get corrupted. You could write all
those down and then you could make a story of data dirt. Okay. So that would be an example. There's
a really beautiful example. My friend Julian at MIT who used, he didn't actually use a probabilistic
programming system because they didn't exist at the time yet. But essentially did this for finding
exoplanets. So exoplanet is a planet that is circling a star, you know, in a distant, not galaxy,
but distant solar system. And he found clouds on a planet that was a thousand light years away.
And he did that by writing a story. So he used Kepler space telescope to receive the data.
And he wrote a story of where the data came from. You know, the light came from the star. I had to
pass through the atmosphere of the solar of the planet. And then it had to disperse, you know,
through the scatter through through molecules in its atmosphere. And then it had to then disperse
through the traversal to Kepler. And then Kepler's optics, he had to model all that. And so
he went from that to all the way back to what was the density of the atmosphere at different
locations on the planet, just inverting that that model. And he had all kinds of different
solver methods. So the orbital dynamics were continuous variables. He did gradient descent on
those. But the, I think the distribution over the scattering, that stuff was deterministically
done because they had put hot gases into a kiln and they knew their scattering properties
at very high densities and temperatures. And so, you know, that was like a deterministic system
with some parameters that needed to be Markov chain money, Carlos sampled. All these things kind
of cobbled together. So doing that kind of science, I think astrophysics is a really great example.
You know, that's the kind of thing you can do really beautifully with the probabilistic programming.
And so in one of the cases that you see on the enterprise side, whether it's this dirty data,
a problem or something else, like so you start out, you write out your problem in English,
like what next, where how do you evolve that to a solution? We translated into Python. Okay.
So just take your English and turn into Python simulation. And that, did you mention DSL earlier,
you have a descriptive language for doing this or we just use Python. So straight up Python.
Okay. You know, if you look at what we call particle is our probabilistic programming platform.
Okay. An idea learning platform. Get an idea learning at the end here.
The simulations are just straight up Python. And you can do anything you can, you can do
in Python. If you have a science library or a business process thing that you wrote that
simulates part of your business process or whatever, you can just, you know, patch that right in.
Python's a great glue language. So it's a really great way of putting together simulation.
And so that's the first step is you just build that Python model of your data. And it should
spit out random data, kind of nonsense data, but it should look statistically like your real data.
So you've got a problem. You model your problem in English. You create a Python
version of your model. What we're calling a simulation here. And I think I guess what
is interesting here is you're not, this Python isn't trying to solve your problem. It's just
trying to model your problem. That's what's different than like traditional approaches. And then
yes, kind of apply the solver to that exactly back. Yes. It works backwards to figure out what
the actual model is to the actual parameters are right. Okay. Exactly. We call it posterior. Yeah.
Okay. Yeah. Exactly. That's it. Yeah. Okay. Oh, very interesting. So it's a very rational design
flow. Mm-hmm. You know exactly what you put into your model and you know exactly what you left
free for the solver to noodle with. So on that last point, one of the big challenges
in applying neural networks to, you know, problems that matter, if you will, is explainability.
Yeah. Does the approach that we're talking about here, because you know your model,
better it is at lead to better results from an explainability perspective, or there's still
challenges there. I mean, it gives you a knob you can turn from perfect explainability to the
same situation you're in with a neural network. Okay. So neural network is just a probabilistic
program. You can write it. Right. A probabilistic program. The neural network written as a probabilistic
program is flip these million coins. Uh-huh. Now multiply their heads and tails by some weight,
which sampled from a Gaussian. Right. And then add them some number of times. Yeah. Do all that,
you know, how that looks. And then add them up and do the sigmoids and then get to make that be
the weight of another batch of coins. Okay. The weights of another batch of coins. And that's
the next layer of the neural network. So there's your neural network as a probabilistic program.
Okay. So you can do that. That's a pretty, you know, you can run that model. You can train it on
data. You can use back prop in the probabilistic program as the solver. And now you're just doing
tensorflow. You're doing neural network. Right. So the fact that it is a probabilistic programming
language, it's just one that only has Bernoulli variables, Gaussian variables, and gradient descent
solver. Okay. This is very limited probabilistic programming system. Okay. And it only can express
models which tend to be not very explainable because that there's no deterministic code. You can't
really put any ideas in there. But we can turn a knob all the way over to a super explainable model
if you want to, like a very causal model, where if, you know, you flip a coin to decide whether
the person was crossing the street and you flip a coin to decide whether the bus was coming at
that same time. And then if they were crossing the street and the bus was coming at the same time,
they get hit by the bus else they don't. And then you sample the statistics of people getting hit
by buses and like someone gets hit by, gets hit by a bus. You go in the model and you say like,
why do you think they got, you know, we're like good to get hit by a bus and say, oh, look,
you know, it's very likely for them to cross the street when the bus was coming.
Right, right. It's kind of a morbid example. But, but super explainable, super simple. You can
make them. Did you happen to see the video on Twitter of the bus that hit the guy and the guy
like bounce off the bus and got up. This happened today. And I think in the UK somewhere.
I'm so glad that so that's what happens in this process. Every time someone does get hit by a bus,
he just bounces off. Everybody's fine. That's great. And it's 100% probability of that happening.
Just good. So yeah, so what you do is you get a knob. And the knob is what we call model capacity.
Not so the neural network is of extreme. It's a universal function approximator. It's a super wide
variance model. It can if with enough training data can be do me anybody be anybody it wants to be
right. It can learn any to fit any data. And it's totally unexplainable and it takes a ton of data
to or very unexplainable and it takes a ton of data to train it. And as you turn this knob toward
narrower variance, you get models which are tighter, more deterministic, more understandable,
more explainable. And if they're the right model, they also take a lot less data to fit and they
also make much better predictions. If they're the wrong model of their biased, then you got a problem.
And so that's the second thing. In addition to making this really fancy solver system for the
second thing our system has is a bunch of it's basically the first IDE for probabilistic programming.
Because so it lets our staff basically get a lot of the kinds of profiler and debugger
feedback kind of the analogy to profiler and debugger feedback that you get from regular
program. So it tells you, you know, is this line of code helping fit your data or hurting you when
you try to fit your data? Is it helping your solver converge or is it hurting you with your
solver conversions? Things like that. And that's super important. We need development tools for
a machine learning next. We, you know, like take tensor flow, you know, it doesn't give you a ton
of feedback when your model is the wrong model. You mentioned wanting to get to idea learning.
Oh, idea learning. Yeah. So that's our kind of new aha at Gamlon. And I don't know if we
have really time to get into it. But the simple idea is that instead of inputting the probabilistic
programs by probabilistic programmers programming probabilistically, you just talk to the system.
And tell it stuff. And it interprets what you're telling it as a probabilistic program. And so
you can insert ideas into the middle of it. So be as if you could talk to tensor flow in
English and have it adjust its weights. Not in terms of supervisor unsupervised data. But in
terms of like, but almost be like saying, Hey, tensor flow, I want weight number 219 to be 1.3.
You'd be adjusting the insides of it. Of course, that wouldn't make a lot of sense in the case
of a neural network. But in the case of the kinds of models we build, you can actually have a
pretty nice little conversation with your system. So the analogy here is, you know, training a dog.
So Pavlovian conditioning, right? If you want a normal supervised neural network, whatever machine
learning, you ring the bell. You show the food, the meat, delicious meat, the dog salivates.
You do that over and over again. Now the dog salivates every time they hear the bell.
Right? So what did you do? You basically give it, it's just like when we teach tensor flow,
how to recognize a cat. You show a picture of a cat. You say, this is a cat. If it gets it right,
then you reward it with that prop. If it's a wrong, you punish it. It's the same thing. Stimulus
and a response. And then you course it to give you the right response for the stimulus, desired
response for the stimulus. Do that over and over again. With a dog, it's like 12 repetitions.
With a tensor flow, it tends to be, you know, 30,000 cat images or labeled data points for each
category. And that's how we ordinarily, but when we were the human, you know, with my kids,
you know, when I went on the comfort dinner, you know, and they was just a summer now. So we
got it, they're out playing. So we got the dinner bell. And you just say, look, this is the dinner
bell. And when I ring it, that means it's dinner's ready and you should come. And, you know, normal
people would hear that once. And they would just come to the dinner. They don't need repetitions.
They're not heavy in learning stimulus responses. We're not conditioning them. I mean, if you're my
kids, you have to repeat yourself like three or four times. But, you know, I mean, what did you,
you did something different? You didn't put an input output stimulus response and train now. What
you did was you stuck an idea in their head in between the input and output right in there,
like conception, by talking to them. So that's what we need for machine learning because there's no
way we're going to just like, how do you build modern civilization if humans could only train
each other through stimulus and response? It's nuts. That's crazy. This isn't going to work.
Right. Interesting. Interesting. Great. Well, what's the, for folks that want to learn more about
this, you've mentioned the Gamalon website is one place. There are other. If you want to play with
models, you don't even have to install any software. There's probmods.org, P-R-O-B, M-O-D-S. I guess
prob stands for probabilistic. I don't know what mod stands for. Models. Dot org. There's a lot of
good examples. That's Josh Tenenbaum, no goodman. Fikashman, Shinga, some others collaborate on that.
It's fun to play with because it's all in JavaScript. I think it's, it's all in the browser.
You just literally go this web page and you can live play with probabilistic programs and edit them
and run them. It's kind of nice start. Any papers that are seminal and this area?
Yeah, there's the, there's a lot of seminal papers and I would say go play. The papers are really
pretty tough to read. They tend to combine programming languages, semantics with compiler theory
with heavy vision math and everything in between. It's going to be an expert in like three different
terrible vocabularies, mathematical notation. So yeah, I think playing is maybe the, could be
more fun. Awesome. Awesome. Well, it's so great to have you on the show. I really appreciate you
taking the time out. Yeah, thanks, Robbie. All right, everyone. That is our show. Thanks so
much for listening and for your continued support, comments and feedback. A special thanks goes
out to our series sponsor, Intel Nirvana. If you didn't catch the first show in this series where
I talked to Naveen Rao, the head of Intel's AI product group about how they plan to leverage
their leading position and proven history and silicon innovation to transform the world of AI,
you're going to want to check that out next. For more information about Intel Nirvana's AI
platform, visit intelnervana.com. Remember that with this series, we've kicked off our giveaway
for tickets to the AI conference. To enter, just let us know what you think about any of the podcasts
in the series or post your favorite quote from any of them on the show notes page on Twitter
or via any of our social media channels. Make sure to mention at Twomo AI, at Intel AI,
and at the AI come so that we know you want to enter the contest. Full details can be found on
the series page. And of course, all entrants get one of our slick Twomo laptop stickers.
Speaking of the series page, you can find links to all of the individual show notes pages
by visiting TwomoAI.com slash O'Reilly AINY. Thanks so much for listening and catch you next time.
