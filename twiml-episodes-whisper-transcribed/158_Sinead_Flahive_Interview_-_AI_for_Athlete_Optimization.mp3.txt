Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington. Perhaps especially appropriate given that much of the globe
is glued to the world cup at the moment, we're excited to kick off this week a series of
shows on AI and sports. While I'm not personally the biggest sports fan, my producer Amari is
a huge sports follower and this series has been something he's wanted to see since we started
working together. So if you like these shows, be sure to hit him up on Twitter at at Twimble
underscore Amari, I am AI. Before we get into the show, a quick update about July's Twimble
online meetup. On July 17th at 5 p.m. Pacific time, Nick Teague will lead a discussion on the
paper Quantum Machine Learning by Jacob Biamonte at all. The paper explores how to devise
and implement concrete quantum software for accomplishing machine learning tasks. If
you haven't joined our meetup yet, visit twimbleai.com slash meetup to sign up. Also, be sure
to sign up for our weekly newsletter. I recently shared a write up detailing the machine learning
and AI job board we're working on and got a ton of encouragement and interest. To make
sure you don't miss anything, head over to twimbleai.com slash newsletter. In this episode, I'm joined
by Shanade Flahive, data scientist at Dublin, Ireland based Kittman Labs. Shanade joined me to
discuss Kittman's athlete optimization system, which allows sports trainers and coaches to
collect and analyze data for player performance optimization and injury reduction. In our conversation,
we take a look at the different ways this data is collected and analyzed and the various modeling
techniques Shanade and her team use to create player insights for coaches and trainers. Shanade also
shares her view of the data driven sports landscape and how it's evolving. Enjoy.
All right, everyone. I am on the line with Shanade Flahive. Shanade is a data scientist with
Kittman Labs based in Dublin, Ireland. Shanade, welcome to this week in machine learning and AI.
Hi, Sam. Thanks for having me. I delighted to be here. Let's get started by having you tell us
a little bit about your background and how you got started and interested in data science and machine
learning. Yes, so I took not a direct route into the data science area. I initially studied
financial mathematics and actuarial science in my undergraduate towards the end of the
undergraduate. I was more interested in more statistical type-based modules and my university was
very accommodating and allowed me to kind of change the traditional modules that I should have
been sitting and I ended up doing more statistics modules than traditional. So while my undergrad
degree is financial maths and actuary, I traditionally probably have more of a statistics degree.
So I began working straight out of university for a statistical analysis consulting company
where I was doing statistical analysis and using software and for consulting, doing lots of
projects across lots of different areas and I was really enjoying it and I liked the variety and
the different types of data sets that I was working with. So I continued on myself and did a
masters in business analytics. So that steers me more towards the data science role. So that position
I grew into more of a data science role there in terms of the manipulation of data, performing
more analysis into deployment of models going forward. So when I moved on from that position,
one of the things that struck me was I was very much more enthusiastic about working with data sets
that were interesting. So there's an abundance of data out there as we all know and it's growing
very regularly. That I was more enthusiastic and excited about data sets that I had a passion for
and I would be quite a keen sports fan myself. So when the opportunity came to work with a sports
data set as I get to do daily now and in Kidman Labs where I'm working, that I jumped at the
opportunity. So that was how I got into working in data science at sport is kind of combining two
key passions of mine, the data science side of it and getting to work with a really interesting
data set as well. Oh, very nice. What are your favorite sports? I would be a keen rugby union fan.
Okay. And so in Ireland we've been we're quite successful in rugby union. We recently won a
national competition where we play our closest competitors called the Six Nations and the Irish
rugby team who are one of our customers here in Kidman Labs won that outright. So they beat
every other team and we were involved in that and contributed in some small way I like to think.
Awesome. Yeah. And in Ireland then we have our national sports. So they're amateur sports. So
there's Gaelic football and hurling which is quite a it's kind of like hockey but at a much faster
pace that we have here in Ireland. So they would be kind of my own sporting. I don't play any of them
mind you to follow and to keep up with. Awesome. And so what does Kidman Labs do and what's
its role in the sporting arena? Yeah. So here at Kidman Labs we have developed an athlete
optimization system. So our athlete optimization system enables training and medical staff
for elite sports teams teams to collect and analyze their data in that way they can optimize
performance and they can reduce the risk of injury because we collect electronic medical
medical records from our teams as well. So as we have Kidman Labs have a dashboard that
allows the practitioners to look at the current status of all of their athletes based on their own
data collected in their systems. So we have certain ways that data is ingested into our system.
So we have we have our own app that athletes can enter in different things on so kind of subjective
measures. How are they feeling? How did they sleep last night? Do they have any muscle soreness?
We also have as I mentioned the electronic medical record system where the medical staff in the
the clubs would enter injuries when they occurred where in the body they are. So that gives us
a lot a lot of information on the injuries. We also allow the practitioners to impose other
kind of objective tests. So if an athlete was doing a screening it's what we tend to call it.
They would do things like check their hip mobility or their ankle mobility and there's
different tests that do all these things. So the coaches would enter that information for their athletes
in their system as well. And then we also have a capability that allows our teams to ingest
all of the GPS type metrics. So you've probably seen it on the on the the TV sometimes they wear
the the vest that have the GPS monitors inside them. And that that that all gets an ingested into
into our system as well. So we have a we're in a unique position then whereby we are allowed we
are able to link all of that injury from information to all of the other information that the athletes
provide or that their coaches give us. And one of our one of our aims is to identify and drivers of
injury risk based on all that information that we collect from the from the athletes. Interesting.
So you're collecting a lot of information off the field. You mentioned the GPS vests. Are you also
is there some way that you're capturing? You know rugby. It's a contact sport from what I've seen.
Is there a way that you're capturing impacts and contact and that kind of thing as well?
Not directly. So through the through the GPS metrics and that come through from the providers.
There's lots of different vendors that we work with who provide this information. They're one of
their metrics that they would include would be number of impacts. Okay. So we get that information.
It comes in as part of the the GPS that type of data we would consider workload data.
So it's what what what what exertion to the athlete perform on the pitch whether it was in training
and sometimes during in games in in some leagues. They're not permitted to wear the GPS units during
games. But if it's available, we have it. When the injury information comes in in our
Electronical Medical Records, the practitioners would tag whether the injury came from contact
activity or a non contact activity if it was just a something that flared up over time.
And so the sports teams now have you know you've mentioned already tons of different sources of
data and I'm envisioning other things like Fitbit devices and you know even data that's extracted
from like computer vision models of the field, the pitch and the players. You know I imagine
these teams are you know quickly gotten to a point where they're a wash and data and need to
figure out how to use that data to be more competitive. Like what does the overall landscape
of data driven sports look like from your perspective? Yes. So as you mentioned and you're
100% correct there's the velocity volume and variety of data being collected these days.
It's such in a fast-paced sporting environment. It can cause a problem which here we kind of
call paralysis by analysis. I think that's a general general term anyway. What we have found is that
things like the tech wearables, the Fitbits etc. They deliver data and measurements back to the
athletes. However the the kind of crocs of it and where we kind of come in is they get the data
measurements but it's the real insights based on the linking of all the data together. It is what
we do here at Kipman Labs. So what we've kind of found is that while you have more data
that can lead to more decisions but more data here does not necessarily mean that you have
better decisions. So our key service I suppose from an analytical point of view that we provide
is driving insights for our teams based on the data that they put into our system.
And so those insights it sounds like are primarily around you know performance and how to optimize it
on well let me ask is it on an athlete by athlete basis or is it on a team basis and is it
well let's start there. Yeah so our data set we have like we have our system in 120 sports teams
across 35 leagues so therefore we have a lot of data ingested. What you will find is that
the insights that that you would discover they vary sport to sport position to position
and as you mentioned athlete to athlete and that's one of the things that that's really
interesting about our problem here when we try to solve based on say one of the things as I
mentioned was based on injury risk as is in most areas if we go down and down to athlete level
you will get small sample size even though some of our teams that have them with us and they have
them with us for four years so we have a lot of bank data built up with those customers which
makes it easier for a sport. There's interest across all the levels a lot of time there's comparison
so what you'll find is that teams will be interested in comparing say we're just going to like
their forwards to their backs and what are the key differences between those. At the moment at an
athlete level like I said small sample size very very localized insights it's quite good to
that we can we can turn those over but from a comparison point of view suppose positional
level would be good and then looking across the different injury types as well so like one of the
things that that we we understand here at Ekitman Labs is that the actual manifestation of injuries
is quite complex and you could have like obviously the drivers for a hamstring injury are going
to be quite different from the drivers for a shoulder injury for example so they're the kind
of different areas that that people would like to compare different types of injuries different
positions in their teams and we provide the the analytical solution for for our teams to be able
to do that. And you mentioned in your introduction that you apply this model or the the Ekitman works
with some of your favorite sports rugby and some of your national sports but what other sports do
you have you applied this model to? Yes so we have like I said rugby would is one we have soccer
teams we have cricket teams we have baseball teams basketball American football
then Australia we've probably league so we do have like a broad range of sports across a broad
range of continents that that that contribute information into our system. Okay and so you're
now a data scientist in a playground of you know data around your favorite topic how do you
approach trying to deliver insights to these teams with this data that they have?
Yes so we work quite closely with our applied sports science team and our applied sports
science team here at Ekitman Labs they deal directly with our customers find out their needs
and and figure out and if they're there's certain areas that we should be looking at from an
analytical point of view. So our main kind of application and our main insights driver
Ekitman Labs and what we've we've developed and what we've been working on to to help reduce
kind of injury risk across our teams we work on the basis that we that coaches would like to know
what are the things that are driving injury risk so they collect all of this data and in our system
you can view that on a dashboard so when they come in they can see the dashboard which allows
them to view the current status of the athletes and they can then set alarms on that data and alarm
being go red if a if an athlete gets into a certain band or a certain range or over a certain
amount of a variable or it can be green if you're happy with them the color coding think kind of
depends on the the personal preference of the practitioner. So our practitioners traditionally
could just set their alarms based on their own intuition and their own judgment
and expertise but where we come in and where the the main analytics that that we work on
here at Ekitman is to provide data behind that and to potentially provide data driven alarm
thresholds for the practitioners to set that will fire when their athletes get into a certain
range or you think they might be in trouble. So maybe to to apply some examples and be a little
bit more concrete here it sounds like you're saying that traditionally or maybe not traditionally
but you know one way of approaching keeping athletes healthy and in high-performance zones
would be to set a threshold that said you know that would allow a you know one of the sports
medicine staff out of team to say well you know I'm concerned about overtraining I don't want
this athlete to train you know more than X hours a day and so that's a intuition based
threshold that they might set but you're maybe doing some analysis or building some models based
on the data that you've collected to allow them to more dynamically optimize those kinds of
thresholds maybe you know based on based on this starting point maybe you can give us some specific
examples and the kinds of you know modeling models and approaches that you might use for different
teams. Exactly so suppose from the first point is that we initially when we started on this
journey relating injury risk to the different metrics in our system the alarms that we set up
they were on a univariate level so we started small and kind of built it up along as as we
continued through our journey at a univariate level we have a system in place that a practitioner
can set an alarm like you mentioned a certain number of training hours per day I mean we provide
the analysis for them to check that alarm and see how relevant that alarm is based on their
injury risk. And meaning meaning what specifically so one thing you're doing is you're allowing them
to pull different data sources together so they can even easily track how many hours a given
athlete has been training. Exactly so once they put the data into our system it's all
collated into essential repository and metrics that they wish to view or that they wish to set
alarms on that they wish to monitor for their athletes are displayed in their dashboard.
So not not only are the I suppose the raw metrics displayed we also allow them to create different
aggregations and things that they might be concerned about as well so what you'll find is kind of
you know in a sports related area obviously if you're coming up to a game the things that happen
in the few days leading up to a game can be very important to determine whether an athlete is
going to perform well in that game or not. So we allow them to to create different aggregations
for example their workload over the last seven days their max speed over the last seven days
that they did in training we allow them to look at different metrics in those types of aggregations
and also what is very important and what we found to be important is like the change in those
metrics leading up to the game so we allow them to calculate z scores and complex n scores so
they have an abundance of data that they can display across their dashboard and set alarms
off that that I'm concerned if athlete goes into does as you said over XR as a training per week.
The analysis that we perform then takes that data so for their positional group or that
that they they're involved in and looks at how that that metric relates to the different types
of injuries that other people in their positions would have gotten so that if they're concerned about
that they can set the alarm or change their alarm based on what the data is actually telling them
and use that then on top of their own intuition. Tell me a little bit about the kind of the modeling
process and how you as a data scientist have built up these models over time.
Yeah so the most recent I suppose model that that we were working on was what I was talking
about previously was all at a uni-variate level so is this one metric related to injury risk
and more recently we've developed into the multi-variate alarm so the idea with that is that
the customer is identified where their injury problems are for example they look at a diagnostic
injury for their season they had a really bad hamstring problem so they will access our system
and they'll say okay look at my for the season look at my hamstring injuries and we have been
built models that will turn around and tell them different types of injuries for different
combinations of metrics. So the idea then is that they will choose an injury level that they're
comfortable with or they'll see affwatt at what values for different combinations of metrics
was were my athletes at the higher injury risk and then they can set that for their group of
for their group of athletes so going forward into next season hopefully they'll get a warning
if this injury risk increases. So from our point of view then at the on the data science team
the key thing from us from a machine learning point of view is that our analysis has to be
transparent so while there are amazing models out there that would give you a really good risk score
or a prediction as they say what we have learned and what I mentioned our collaboration with the
sport science team earlier our customers in particular here they need to know why so here we need
to know what's going on but going on in the box so the important thing for us is that the models
that we use here are transparent interpretable and that we are able to build on top of the key
metrics and figure out then what the optimal thresholds are for each of those metrics based on
the injury risk specification for the injuries that the teams are interested.
And so what models does that leave you to use? So it would be the more I suppose traditional models
the ones that wouldn't be considered black box that we would so again models that are
quite transparent and easily interpretable like in general and some of the analysis that we would
perform you would find decision trees would be quite an interesting approach to this because you
automatically get both your related metrics and your specific thresholds and that come true
in terms of we then take out from that and kind of make it into a more consumable format
because I suppose the kind of key crocs of that is that the practitioners and the coaches using
our system they don't have a lot of time so if we put a big massive decision tree up in front of
them that's not going to be easily interpretable or consumable for them so we need to and that's
one of the things that's really good about being a data scientist here as well is that we will
work with design and product and figure out how that's going to be implemented kind of from a
conceptual analytical point of view into something that's easily digestible for our coaches.
That's interesting. Can you talk more about that process? Where does it manifest itself? Does it
impact the design that you will ultimately choose or the model type or parameters that you'd
ultimately choose as a data scientist or is it more with a given model that you've chosen
for other reasons like performance? The way you communicate and display the types of things
that customers will want to know about from that model? Yes, we will spend a lot of time
in the conceptual formulation phase where we will develop the algorithms. Our general process
would be to potentially come up with two or three different algorithms, compare them, build
prototypes so that the prototypes can then be validated so they can be validated both internally
and with the other members of our team so with the product and design team with the engineers
if it became that this algorithm needs to be implemented in our product. Can we can you support
that? Can you help us with that? But also for the we would do external validation as well with
our customers so that will be again where the collaboration with the sports science team would
come in. They have the ability to take the prototypes that we build, show them to customers,
we get feedback that gets implemented and then again it's a massive collaboration effort.
When all of that comes together we go back to the design team, figure out how it's going to fit
into the product and it moves on then to engineering into the product and eventually then into
the hands of the customers themselves. And so have you had situations where you know for
example you chose a simpler model because it was easier to present the results to customers or do
use the model but invest extra on the presentation side after assuming a given model in place
is in place. I suppose that there is a bit of both we would always aim for the optimal model
but we would always vary in the back of our mind that the optimal model that we build in our
prototype against our data set that it can be quite resource consuming and potentially not
sustainable given the amount of data that we have that goes into the product. So we have
like I said a lot of collaboration with the engineering team to make sure that the solutions
that we come up with are indeed implement you are able to implement them into the product and that
they won't break everything that it won't be very slow. So we would do a lot of testing with
the different types of data all the aggregations that we have and we would try to come up with
something that satisfies every member I suppose of the team involved and again is the best model
that will get good insights for our customers that that's the most important thing is that the
the customers are getting the insights the why I'm getting such an injury risk score and not just
what the percentage is. And out of curiosity do you use a lot of ensembles of models or do they
tend to be simpler models? We tend to keep it more simple. Okay again at the presentation. Yeah,
the interpretability of models that we would use. I mean in saying that the data science team
we like to be innovative in ourselves so we would have departmental workshops whereby we would
do things that on the side like that try different types of models see how they would work
while we're always dripping that forward. So at the moment we are focused on actionable insights
key deliverables that the practitioners can combine with their own intuition to make their decisions
but that's not to say that that's going forward for different areas that we might be getting into
that that models like that wouldn't be would be more applicable. How is your product delivered?
Is it a cloud-based solution where your customers are uploading their data centrally or is it
mobile or desktop? So there's a web browser that the coaches and the backroom staff I suppose
get access to to login to where everything is displayed and through there they would upload
their information in terms of the EMR, electronic and medical records. From the other ways we
collect data we have a mobile app so we have a mobile app for the athletes themselves so they
install the app and they put in their subjective type measures. We have another mobile app for the
coaches which provides a summary of all of the information that they would see on the dashboard
when they log into the web app. They get that on their phones and you find I think in sports
complexes or in the training grounds particularly throughout the pitch they wouldn't have a lot of
Wi-Fi so having something on the mobile is more efficient for them. We have the web browser as I
mentioned and we also have a motion capture data collection system which is quite interesting
so we have a system where you stand in front of a camera and it uses infrared sensors to detect
the athlete and we take them through a series of movements and they kind of follow a demo as
it's going through, perform the movements and we get all that data back into our system as well.
And what types of analytics does the motion capture roll up into?
So again the outputs from that would they get cleaned and transformed but they would then
essentially just become metrics on the teams can put onto their dashboards as well so you would be
looking for things like angle of your internal shoulder rotation or how aligned were your knees
when you were doing a squash these kind of things so we have metrics that get derived automatically
from them from the system. A lot to do with alignment between say the left and right side of your
body and how good your your movement is as you go through the different movements we have like
squats, lunges, y balance these kind of different things. I was just talking to someone about
they were someone made a comment about how they wanted to get a like a workout coach or something
like that so that they can you know get an analysis of their technique. Do you see that kind of
thing being more commoditized and available just via you know mobile devices and you know deep
learning just kind of point the camera at you while you're doing your squats and it'll tell you
how good your technique is. Yeah a hundred percent I think that that's where where everything is
going. I mean like I mentioned that that our system that we have here is at the moment only
currently provided to like elite teams and professional athletes but in saying that I mean with
the kind of the prosumers of the technology like someone trying to better themselves saying
in a more amateur type setting or as an individual sport all of these things are applicable.
And there's such developments again in technology I mean there's something new coming out every day
that a hundred percent I I would believe that like personal personal workout or your your own
smart trainer your own smart coach these things are definitely not too far down the line from us
with with all of the developments and technology that are happening. Yeah having said that I'm sure
listeners will tweet me like five to ten companies that are already doing this thing. Yeah I wouldn't
I wouldn't doubt that. I mean I know one of the things that that kind of always interests me
and I think that where we're going is kind of the smart sports equipment and I'm sure that there
are companies out there for example if you're using a equipment in your sport like for example say
a baseball bash I'm sure there are companies out there that are developing the technology to
look at your motion as you swing it and hate it and I mean I I guess there are people out there
even with footwear with boots or trainers that people are wearing as they're performing that to
detect from that as well so the the abundance the data that that's going to be coming in it
is is just going to grow exponentially I imagine. And so what do you see as the key challenges face
by data scientists as they're working in fields like this with the the data volumes rising but
where a very personalized approach needs to be taken. I think the key the key challenges
would be in I suppose identifying the noise that that that that is their from us so as that
becomes to kind of a more a more personalized level I think one of the one of the good things
about these is that people like to compare themselves to other people of a similar nature
and so the challenges would be providing good insights at a localized level with with small
sample size whereas the kind of benefit of that is that you can yield from from a larger data
setup of similar population and and if people engaged with that and get people engaged with
in with different ways that they can engage their customers and the the consumers of this information
potentially that would be where they can kind of overcome the challenges of small sample size
and and and that that that would come from a more personal approach. Yeah I was going to ask a
related question to this earlier even with with all of the teams that you work with and all
of the athletes that play for those teams you know often there's a situation where the the events
that you want to model against your your interests set you know our injuries which are relatively
infrequent as compared to your overall data set is that a challenge in your case and how do you
address that challenge. Yeah so within our data set like one of our challenges that we have
is that you have teams that they screen differently so it's you can have a team that will require
their athletes to go through screenings one day a week or you will have teams that will require
their athletes to go through three days a week or five days a week or every single day depending
on whether they're training or not. Okay so that can be quite quite of one of the challenges so
it can be quite difficult to to compare two different teams if they have completely different
training methods and when we're delivering our insights back to our customers that they they're
aware that it's all their own data and if anybody wants something at a kind of a more aggregated
level we will have the caveat that you are aware this is different sport different et cetera so
used as a kind of a guideline. In terms of from our point of view we would have and it's quite good
a lot of our teams would have compliance rules so they would require their athletes to screen
a certain amount so we're aware of that so we know how often the athletes are screening and how
they're meant to screen before we kind of attach any analysis to what they're doing so I mean for
one team they screen three times another team they screen once a week we know that so we can
then adjust any analytics that we perform for them kind of according to that and you would have
as I said the compliance and the teams would expect I think some of them it can be in their
contracts that they're required to screen a certain number of times a week and to provide data.
How do you do that from a you know techniques perspective and is this kind of a sampling exercise
or normalization exercise or how do you work with your data so that you can allow folks to
compare metrics that have different you know volumes of sampling coming in.
Yes so we in general like we would I suppose if have the problem of you would have missing data
if athletes don't screen on certain days we tend to look to the customer and ask them so
why we would have obviously there are statistical methods and as you mentioned yourself normalization
and different things and taking the average over a certain period of time or rolling the last
value that they had forward to all these different or imputing by a model all these different
things we tend to work with customers and see how they would they would feel about that so what do
they think would be the best approach for them for their own specific analysis and that would be
kind of an option it's not currently built in but something that we are looking to to go towards
so even if there is a very poor quality of metric collected they have the option not to include
that in any analysis so for example if they only for the the period of time that they choose
if they only have valid data for say 10% of the time just wrote not going to include that at all
just don't there's not enough information for the the games if it's something that's screened
quite frequently or something you'll find that that they might screen and collect for a while and
then not collect after that so again it is quite and like I said we do with collaborate quite
closely with our applied sports science team who are very close to the customers and take that
guide and so for example one of the things that that if we were to impute by a model there would be
the question that well how is that number calculated and step that kind of led would lead to more
questions being asked so it is quite on a team by team basis and we would do a lot of collaboration
of people and on making that decision for themselves okay so make sure they understand the various
trade-offs and in surfacing those trade-offs via the tooling exactly yeah okay and out of curiosity
mentioning tooling what kind of tools are in your tool chain so the data science team here
acutement labs at the moment utilize mostly ore and python okay so a lot of our analysis
is carried out in ore the prototypes that we build in ore using the shiny app that would be
sent out for validation and where everything that that would eventually end up in the product
kind of grows from but we're kind of developing python types of as well at the moment so
there's a little bit of both going on and you mentioned shiny app what's that so shiny is
part of the R studio package okay shiny allows you to take all the code and display it in a web
browser and build your own little mini application basically so that's kind of what we do with the
analysis and set it up so that the sports science team can can go and take it out to site and they
don't need us with them that they can click around and make selections and it runs the analysis
and displays things back to the customers okay so it sounds like you're actively involved in
helping sports teams further their performance help their help keep their athletes healthy
where do you see this going what are the opportunities for teams to use the data that they have
available and the data that you know will soon be available to them yes so I mean at the moment
we and up until now we've been very injury focused so again the idea would be to keep the athlete
healthy that we would instigate the alarms that would allow them to identify when when a
potential athlete is potentially at risk going forward and for them then to make their their own
judgment and decision about what the action to take on that is so should they potentially reduce
their training load or get them to screen again these these kind of things so from the injury
type of view we've we've kind of been looking at individual risk factors the interactions of those
and identifying kind of different types of responders then to to an action or an intervention
and it's somewhere where we think that that that we might carry on with this and eventually kind of
to work towards the the forecasting and proactive planning so to kind of look forward and say okay
in the next week these athletes should only do this workload and this workload so so that's kind of
the where where where we'd like to get into from an injury point of view also moving on from
that then is is kind of what's becoming quite evident and important is kind of the performance in
games so we have a lot of information about our athletes and that the information that they give us
the pictures we call their psychophysiological metrics and at the moment we've been really
injury focused with that but we're hoping to move into the area of in-game performance and see how
the the information in our system relates to how they perform in games so there are lots of
companies out there opta in stat etc providing breakdowns of of how players performed in games
their technical metrics how many shots they missed they scored tackles missed
interceptions etc depending for all the sports and and we're hoping to to get an area where
we can relate what's in our system with with those things and move on to to performance in-game
so we we we are hoping to to get an area a time where you can assess potentially when teams
are more likely to beat a team they do these certain things and the fifth psychophysiological
metrics that are in our system how we can relate those and and try and get our teams to to boost
their performance and increase their chance of winning well shane thank you so much for taking
the time to share a bit about what you're up to there it sounds like you're doing some really
interesting things yeah and and long hopefully it will continue like that awesome thank you so much
thanks them thanks for chatting to all right everyone that's our show for today for more
information on shaneid or any of the topics covered in this episode head on over to twimmolayi.com
slash talk slash 155 to follow along with the AI and sports series visit twimmolayi.com slash
AI and sports and if you're a fan of the podcast we'd like to encourage you to click into your
podcast app and leave us a five star rating and review they are super helpful to us as we push
to grow this show and community as always thanks so much for listening and catch you next time
