Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington, Hey Twimble listeners, if you're a fan of our AI
platforms coverage and especially if you download our first AI platforms ebook, Kubernetes
for machine learning, deep learning and AI, then today is your day.
While we've been working tirelessly on Twimblecom, I have also been working on Book 2 in the
series, the definitive guide to machine learning platforms.
And I am happy to say that it is finally available to download now.
We created the book as a resource for ML, AI and data science leaders and innovators
to help guide their efforts in scaling and industrializing machine learning and deep learning
in their organizations.
In this book, we address questions such as why invest in increasing your organization's
capacity to deliver machine learning and deep learning models.
What are the key barriers to delivering ML and DL models?
How of organizations like Facebook, Airbnb and LinkedIn overcome these challenges and
how can their learning be applied to your organization?
What are the state of the art, machine learning platforms and tools and how can you put
them to use?
How can you develop an AI platform strategy to support your organization's goals?
To access the definitive guide to machine learning platforms, visit TwimbleAI.com slash
AI platforms.
And now on to the show.
All right, everyone.
I am on the line with Angela Bassa.
Angela is the director of data science at IROBOT.
Angela, welcome to this weekend machine learning and AI.
Thanks so much, Salem.
I'm happy to be here.
I am super excited to have you on the show and to get into a little bit of what you're
up to there at IROBOT.
To kind of get us started, I'd love to hear a bit about your background and how you came
to be working at the intersection of robotics and data science.
Yeah, so my background is mathematics and I came to the intersection of robotics and
data science through an enormous amount of luck.
Most people who come into data scientific practice either come from sort of the analytical,
mathematical, physics sort of background or they come from computer science and software
development and software engineering.
And I am very much on the first camp and I am trying to learn as much as possible from
the second camp's firehose.
My academic training is in applied math.
This was back at MIT.
Since then I left, my sort of journey into data science was always through a heavy use
of data, but under many different disciplines, so I worked in investment banking, in strategy
consulting and agricultural technologies, and marketing and energy trading.
I noticed that you had an incredibly broad background set of experiences before you found
your way into data science.
Yeah, I think it's sort of reflective of my personal and family history as well, so I'm
a third generation immigrant and my family is sort of very transient and almost nomadic
and I think that has translated into my career as well.
And it's also, I mean, all jokes aside, it's actually something that I find comes quite
easily to make so growing up, we spoke several languages at home and I find it very easy
now in a professional capacity to understand that some people are speaking HREs, whereas
some people are speaking engineers or some people are speaking analytics ease and to be
able to provide a translational step has a huge amount of value, especially in a discipline
like data science, where there's sort of this division between the tools and the mechanics
of how you solve problems and the domain expertise of knowing which questions to ask and which
problems are worthy of being solved first.
Right.
And so playing that midfield there has proven incredibly valuable and transferable, thank
goodness.
Nice, nice.
You mentioned that your academic background was in applied math, what any particular focus
or flavor?
I liked graph theory quite a bit.
I spent a lot of time in that domain and also logic and first sort of logic, sort of
model theory, but I learned very early on that academia wasn't going to be my thing.
I just don't have the personality fit for that actually more than a personality fit,
I actually don't have the diligence to focus that long on a single problem.
Yeah.
So I ended up going into industry where my particular flavor of ADHD is actually quite valuable.
I mentioned that you are at iRobot as did you.
I imagine folks are familiar with iRobot, but maybe you should share a little bit
about the company and the focus of the company just to levels it.
Yeah, happy to.
So iRobot is, a lot of folks actually don't know, but iRobot is almost 30 years old.
So we've been around for quite a while.
I've been here for about two and a half years now and I started the data science practice
here.
We've been growing quite a bit over the last two and a half years.
But obviously iRobot builds robots and so we have lots of fantastic algorithms and machine
learning engineers, many of whom predate my tenure here.
But now we have sort of a focused competency whose mandate it is to look at fleet data
and to make sure that we are using that information and feeding that back into the development
of products into the customer experience and into the strategy.
So at iRobot, we're well known for our flagship product, which is the Robotic Vacuum Cleaner.
And we have a whole line of robotic vacuums.
There's not just one, so depending on what specifically a customer might be looking
for, we have different offerings with different levels of data driven features and autonomy.
And we also have the Brava line, which is a robotic mobs and we just announced earlier
this year the ptereline of robotic lawn mowers.
So more and more we have this portfolio of autonomous products that can take care of your
home so you can do other stuff.
If you're like me, you can be a nerd.
I'm one would call an endorsement so I don't use my free time to go outside but if you
like that then you can do that while your robots are back home making sure that everything
is sparkly clean.
You mentioned that you started the data science group there at iRobot.
Did you do that from internally where you already at iRobot or did you join the company
to start the group?
The latter.
So I was at a company called Annernock before and I was also brought in to run their
data science team, although they already had the team in place when I joined.
They had two or three people working in data science there at the time and here at iRobot
I was the first data science hire that they had.
There's always pros and cons as to whenever you're starting a team especially in established
organizations.
So it's very different if your product is data scientific at that point you probably
have data science challenge that's built in from either the founding team or at least very
close to inception.
Whereas when you're coming into an organization that is established and that has a product
or an industry that they work within and you're starting to infuse that organization with
data and data informed decision making.
There are certain times where it makes sense to start with merging your talent and just
flunking and figuring out what value you can extract from that data or you can start
very top heavy and have more of a strategic or even a structural approach to it.
And iRobot chose the latter looking for me and I've been very diligently making sure
that they never think that that was a bad decision on their part.
I had the company even come to know that it needed data science, what precipitated creating
the opening and opportunity for you to join the company.
So I like to believe that it's because some people with a lot of foresight who were
here before me saw that as part of the vision as a compelling part of the story of what
we're trying to do.
So when you read about what iRobot is doing right now we're talking very openly about
this this bet that we're making on the smart home and what we think that smart home ecosystem
is going to mean going forward.
But it all started with a small step towards connecting our products to the cloud and allowing
those products to leave artifacts for us to be able to inspect.
And one of the things that has always been at the forefront here has been the utmost
stewardship that we have of that data.
This data is not being generated from pings that your mobile phone is making to the cloud
that you carry on you.
This is coming from inside your home.
This is one of your most precious havens and to allow somebody to allow a company to come
in and autonomously, a proof that environment and report back is something that has to
be done with a lot of trust.
So I think part of the strategy internally was to make sure that all of that was in place
before letting a whole bunch of nerds loose for linking all that data.
So we had good.
I was just going to ask you to elaborate a bit on what that data is and where it comes
from.
Yeah.
So in late 2015 we had our first connected product and we started aggregating that information.
So the information that we get always with the permission of our customers has to do with
the functioning of the robot.
So we're interested in identifying bugs before our customers are bothered by them before
they impact the functioning of the functionality of the robot.
We're interested in understanding how our customers use their robots.
So one thing that's always important to keep in mind is that I'm not the person who should
be asking the questions because I am a very specific type of nerd who has very nerdy questions
and there's only one of me and millions and millions of all of us.
So we as a company want to make sure that we're answering the questions of all of our customers.
And so the data that we're collecting helps inform what our customers want from our products
that maybe we haven't ideated yet and then it helps us develop that.
But one thing to keep in mind is that we never sell that data, that data is not the thing
that we make money off of the data is essentially the thing that allows us to do what our customers
want from their product better than anybody else.
Yeah.
One of the things that I found, so I was at the AWS Remar's conference a few weeks ago.
And I robot had a big presence at that event as well.
And one of the things that I realized was that I just had a very dated view of the company
and the products.
Like, I remember when the Rumba first came out, and you can correct me if I'm wrong, but
I think it was pretty dumb.
Like, you know, you turn this thing on and it would like bounce in a wall and kind of randomly
change direction.
And the idea was that like, if you kept this thing charged up enough and let it do it
enough, it would eventually clean up, you know, a room, right?
As opposed to, you know, what I saw today was, you know, there were some visualizations
that were like a total, like a slam type of, you know, process where these robots have
all kinds of sensors and they're like mapping out their environments dynamically and, you
know, employing some sophisticated, relatively sophisticated, certainly relative to, you
know, what I recall, algorithms to make sure that they're cleaning up all the parts of
your house.
And then you're getting into this notion of like collaborative cleaning with either multiple,
like the, you know, how does the broom robot work with the mop robot to clean a house?
Like, it's, it's a lot more as like, it's not your, you know, not your father's room
but anymore or something like that is a lot more sophisticated than I remembered.
Well, I think 15, 20 years ago, a lot of things in hindsight look dumber, I certainly
looked umber when I think of myself 15, 20 years ago.
But yeah, I think, I think that's, that's apt.
So the, the robots today, I mean, the thing that happens with a company that has been
around for almost 30 years is you have all of these co-bases with a lot of institutional
knowledge and a lot of love and passion embedded in there.
And so it's hard to just say, yeah, we're going to start over, yeah, no problem.
All the people who came before, what could have, what could they have possibly known?
And it's hard to do that.
But that's sort of a little bit of what it takes.
It takes discharging a lot of technical debt and, and starting fresh to be able to do all
of these things and today, you know, the, the Roomba's and the Bravas, they can, some
of the models, they can work together.
So you can tell your Roomba and your Brava to, to tackle, to tag team on, on a task.
And so your Roomba might know exactly where it is.
And so if you want the kitchen and the dining room to get cleaned and mopped, then the Roomba
can dispatch and go to the kitchen, finish as it's moving to the dining room and communicates
with the Brava mop, that the kitchen is all done, that the, the, the mobbing can start
there and it moves into the dining room.
And then when it's finished with a dining room, it lets the Brava know that it can follow
along.
And so then both of those rooms get, uh, vacuumed and mopped and you don't have to lift
a finger.
And with the Roombas, those, um, also have the clean base now, so the, the, the top models
have the clean base.
So the Roomba can dock itself and the base vacuums, the bin of the robotic vacuum and stores
that.
So you don't have to touch it for sometimes weeks or months at a time until you have
to empty the clean base.
So this, this idea of autonomy is something that, uh, at least our modern product line,
uh, is already delivering on and, uh, the whole product line is always evolving towards.
But what we're going towards really, uh, is beyond autonomy, which is something that
Colin, uh, Angle or CEO talked about are remars as well, which is intelligence is an autonomy,
right?
Um, if you autonomously can do something, that's great.
That's better than, than not doing it and, and to require, uh, active direction.
But, um, if you can coordinate and, um, if you can be responsive and collaborative and
if you can be part of a system that enables, uh, all of that collaborative response of
autonomy to take place, uh, then, then you're really talking about the, the transformative
power of data, which is sort of what we're building our platform to be able to leverage.
Is there an example of that in the context of, uh, Roomba in particular, or robotics
or I robot in general, like, how intelligence is, you know, greater than autonomy, however.
Yeah, I think the, the one example would be, um, if you can send, uh, a robot to, to
perform a mission, right in the parlance, if you can send a robot to go and clean the
room, um, that's great.
But if you can tell that robot where in that room to, uh, spend more of its time, uh, either
because, um, you know that there's a particular stain or you know that there is a particular
area that needs to be, um, focused on or if you, um, know that the, uh, that another robot
in the family should follow along.
And so if you can report back that you've identified, there's something, uh, amiss in this
region or that region.
So the way that Colin sort of articulated it, which was really clever, uh, not just because
he's my CEO actually thought this was very clever, um, is, um, if you think of, of the example
of astronauts, right?
If you have somebody who is able to make it to the moon and back, that's great.
But if they're, or make it to Mars and back, but if, if they're there and they have gone
through a battery of, of training to make sure that they can withstand the journey, they
don't have infinite RAM so they can't know all of the things.
So if you have somebody back in Houston who can tell them, hey, that rock over there that
you're not paying any attention to because you're not a geologist, but I am, pick it up
and bring it home, bring a sample because I want to know what that is, right?
So if, if that relationship goes beyond just a relationship of autonomy, but a relationship
of responsiveness so that you can act on that information while it is relevant rather
than only after the payload has been delivered, um, that's really where, where we're driving
towards.
And so when you think about applying data science in this context, how do you break
down the different roles and, and places that you're applying data science?
Um, and I guess I'm, you know, I'm thinking of it kind of crudely in terms of use cases
maybe like, you know, I'm imagining you could apply this to, you know, certainly the autonomy
of the robots within the home, there are like predictive maintenance types of use cases,
there are like business things like how many of the people that buy these things actually
use them and how many of the people, you know, um, that, you know, buy them and use them
a lot.
Probably want to see like the next bigger version because, you know, their current
one, you know, isn't doing something as good as it could be or like what are all the,
like how do you think about not what are all of them, but how do you taxonomize the different
ways that data science plays at, at I robot?
I think the, the way that I like to think about it is in terms of the, the utility of each
of the different projects and, um, and their priority within the, the greater, greater strategy
that we have both in R&D and, uh, in I robot as a whole.
So, um, especially as I was saying before, when, when you have a company that has a product
that is data scientific, right, the thing that you are selling is the knowledge that you
have about the data that you collect.
It's a completely different ball game, but, uh, in the sense of I robot where our product,
uh, is this physical, uh, robot and the data really plays a supporting role to that.
I think the, the thing that you want to, uh, focus on is the fact that data science is
not a, uh, a cheap investment.
And so as, as I stood up to practice here, the first thing that was top of mind is making
sure that we demonstrate or return on that investment because, uh, the thing that I have
seen happen, uh, in, in similar cases is that there's this, this image of the potential
of what, uh, what this practice could deliver and then, um, that potential isn't realized
in the very near term and everybody gets disenchanted and it becomes the self-fulfilling
prophecy that it was never going to work.
Uh, and that happens over and over, uh, when you're talking outside of sort of the, the,
the Silicon Valley data driven, uh, startup ecosystem.
And that's the thing that I was most cognizant of is what are the things that we can deliver
in the very short term with the information that we already have.
I don't want to re-architect anything yet.
I don't want to change how our software gets, uh, developed or how, uh, data gets, uh,
encoded and, and ingested and transformed process stored all of that, uh, based on the
things that we've inherited, what, what exists of value that we can deliver in the very
short term.
And then based on, uh, the, the moment that you can generate there, um, you can start recruiting
champions and you can start recruiting stakeholders that can help you make the more foundational,
uh, changes that enable really big bets.
So here at IROBOT, you know, one of the big bets that we're making is, um, on the smart
home and what that will mean and, uh, who will win in that space and, and our bet is that,
uh, we will win because of, uh, both our, our capability and our expertise and, uh, our
commitment to customer privacy and all of these things rolled into one.
But that's not something that could have been accomplished in the first six months, right?
And so I really try to think, uh, in terms of sort of your near term horizon and your long
term horizon.
So your near term horizon are the things that your data is already bringing to you that
if only somebody were to pay attention to it, right?
You could, um, you could make smarter decisions.
And so those are easy.
You just need to dedicate the time and effort to look at the tactical to, to, to chat across
the organization to figure out who could do, who could make better decisions if only,
uh, somebody could help them understand how things are getting used.
And that's all already, uh, instrumented.
But, uh, that's really sort of quote unquote bootstrapping, the really big, uh, play, which
then requires, uh, you know, improved data architecture and, um, all of the things that
come, that, that, that, that come downstream from that in terms of, uh, data quality, lineage,
governance, um, all of those other, other things that, that are important.
Yeah, I find this, this conversation really interesting and it's one that I, when I talk
to folks that are, you know, running data science organizations or, you know, machine learning
AI, organization centers of excellence, things like this, this, the whole concept of how
they manage and balance their portfolios.
Also as to kind of demonstrate short-term value, you know, enough short-term value, um,
while also kind of keeping their eye on, you know, a broader vision and, you know, selling
that or making progress to that, like it's a very delicate balance in a lot of places
and one that, you know, a lot of energy is put towards.
Yeah, and it's really easy to sort of hire a team.
I mean, it's not easy, but it's quite possible to hire a team of a hundred people, uh, all,
you know, experts and, and, and really fantastic professionals and throw them at a problem.
And then they will, you know, come up with all of these, I mean, they really are fantastic
ideas that will require two years of additional instrumentation and, um, further investment.
And, um, I like to joke that if we were to do the things that I want to do, we go bankrupt
because I'm not, uh, the target audience for this, right?
There, there are lots of, uh, robotics companies that find it very difficult to, to stay, uh,
in the market for as long as I robot has, uh, to, to do, uh, these things in a cost effective
way.
Uh, and, and that's the game for us is how can we, uh, deliver on the promise of consumer
robotics in a way that isn't going to extinguish itself because, you know, we've, we've been
not more than we can chew.
So this very measured approach, um, can be quite frustrating at times because it, it can
feel like you're, you're funding the, uh, the least interesting parts of the journey.
And in fact, it's quite the opposite, um, what, what I feel like I'm doing is I'm clearing
the midfield so that, uh, my, my key players can then be able to take amazing shots, uh,
without having this, this constant oversight and this demanding voice that, uh, why haven't
we, uh, paid for ourselves yet?
Mm-hmm.
Sounds like you're a football fan.
I am, and I call it football, for me, it's soccer.
So for, for folks who might be listening in, who don't know, I was actually born and raised
in Brazil, and I have just started to learn, uh, American football rules.
So, um, now it gets really confusing.
Nice.
Uh, so, how, how big is the data science team there now?
Um, so we have, uh, a blended team.
So we don't have, uh, just data scientists in our data organization, which is also something
that I think is, is, uh, fundamental to our success so far.
Uh, we started with, uh, data scientists, uh, but as we've, um, grown, uh, the, the, the,
the portfolio of, of solutions that we offer internally and in our production environment,
we've, we've been, um, adding specializations.
So we have a blended team of, uh, data architects, data stewards, data engineers, data analysts
and data scientists that, that help us cover all of the different things that we have in
our road now.
How many on the data team there?
So on the data team per se, I think we have 12 people right now.
One of the things that I wanted to dig into a little bit is how you have built out processes
and platforms to support delivering models in the production and, and, you know, doing
the work of the, the team.
Can you talk a little bit about the, you know, both the philosophy there, but you also like
try to get us to kind of concrete details around, you know, some of the things you're doing.
So for a company like I robot, one of the things that we had to do was we had to discharge
a lot of technical debt.
So, um, a lot of our products, uh, originally were, uh, each one independent platform.
And so they had, uh, a code base, uh, and all of the ancillary things that go with that
that were independent of each other.
And that made it so that each platform was robust and, and there are lots of benefits
with that in terms of manufacturing.
But one thing that, uh, proved, uh, less than helpful was the fact that there was very
little modularization, so it was hard to be able to reutilize learnings, uh, and to shift
priorities, uh, as they needed to, to happen.
So one of the things that, uh, we've recently underwent was, was a reorganization where, um,
we brought data science specifically, uh, closer to engineering and closer to product management.
And we've also, um, created a new design language and a shared code base that's modularized
so that, uh, the different pieces of the software can be interoperable.
And so things like navigation and mapping, things like Wi-Fi connectivity and all of those
parts of, of the, the, the platform can now, um, be, uh, plot, be almost plug and play
with the different products that, that we develop.
And what that does is it, it really allows us to, to be much faster in our ability to,
to write software.
And so what we're, uh, moving towards are these robots that become smarter over time.
So, um, hardware is very different than software.
You can't just release an OTA and get new hardware and new injection molded plastic in,
in people's hands, but you can do that with software.
And so if we can have a smart platform, um, that, uh, is part of the hardware that can
receive improved, uh, direction over time, then that allows us to be able to, to solve
the problems that our customers have, uh, in more intelligent ways.
Mm-hmm.
And so we, uh, we essentially embarked on that, uh, not too long ago and we've been operating
under that model for the, for all of 2019, essentially, where, um, we have now a, uh,
data, uh, a DevOps culture and we have a cloud, uh, culture and we have a data-driven
culture that, uh, is imbued into all of the different teams so that they can leverage
the power, uh, of this new design language that, that is shared across all of our products.
Mm-hmm. And so when you say design language, what is that, what does that really mean?
So, um, it means a lot of things, one of the things, for instance, is we used to have
a, um, homegrown, uh, coding language for some of our robots because of the restricted
nature of the compute that was available to them, to them, which is perhaps what might
have made them feel less than intelligent 15, 20 years ago, um, moving forward into, into
the present and the future, uh, that just wasn't going to cut. And so a lot of our code
base right now is in Python and, uh, that helps both in terms of attracting talent, but
also in terms of shifting talent around and shifting learnings around.
And I was talking about code on the robot or code somewhere else.
Yes, and so, um, uh, not all of the parts are in, uh, the, the new paradigm yet because
this is, this is a transition, but a lot of it, uh, both on robot and off. And also in
terms of the, uh, the types of things that can happen on the robot, um, you know, there's
a lot more, uh, power that the robots have, uh, you know, for, for the things that, that
they're capable of doing right now. So if you're going to have teaming, take place, um,
all of that needs to happen. And it needs to happen on the edge so that that information
doesn't necessarily need to get, uh, sent back home for things to work. Sorry that they
should.
Sure. Yeah, it strikes me that there's, you know, platform and, and this conversation
is going to be a little overloaded in the sense of the robot itself is a platform. It's
a hardware platform. And then you've got a software platform sitting on that hardware
platform. And then you've got, that's presumably connected to the cloud, right? AWS, that's
a platform. And so, you know, in that kind of environment, where does DevOps come in
the play and how, how is that used presumably to help tie all these things together?
So the way that it comes into play is twofold. I think one is just as a, uh, mentality
that all of the software developers, uh, need to have in terms of, of the level of ownership
of code. But on top of that, I think, uh, the, the, the, as you describe the different
layering, um, so we want to have, um, folks work on the things that they're good at, the
things that they're passionate at and not on the things that are unnecessary. So the
same kind of mentality applies to data science. And I'm going to speak to data science because
that just comes more easily to me. But in both data science and machine learning, you,
you want to have that same DevOps culture where you don't want to spend 80% of your time
cleaning data. You want to spend 80% of your time figuring out how your data is dirty.
And then writing code that solves it. So the next person doesn't have to do that as well.
So, um, that has to come individually from each member of our team. But we also have, uh,
a team dedicated to maintaining, uh, all of those different layers, uh, both on the, the
hardware platform, the software platform and the cloud platform. I don't know if that
answers your question. Uh, kind of, it starts to get us there. What is that team called?
So, um, that team is the cloud ops team. I guess one, one question that I've got is,
you know, as, as a company that kind of ships these products that are inherently platforms,
uh, I'm wondering if you also have like horizontal, you know, platforms or tools or processes
that are, you know, just how you develop models at Irobat or how you, you know, do experimentation
or how you do deployments that are kind of independent of the individual, uh, robotics
platforms or, you know, because you're developing these like highly integrated things, you
know, is everything very specific to one product. Well, that's the crux of it. So we were handicapped
by the fact that, um, we were faced with with exactly what you're describing where we had
all of these different, uh, distinct platforms. And so, um, as you well know, and as your audience
knows, machine learning requires a lot of training data. Uh-huh. And so how can we train, uh, these
models, uh, with, with the, the, the ultimate objective of having them be as robust as possible.
And so there's a lot of, of information that, um, that these different, uh, formerly distinct
platforms were collecting that weren't distinct at all. So that information should be able to
all be used, but it couldn't because they were coming in through disparate, uh, mechanisms
using different schemas, using, uh, different co-basis. And so part of this rearchitecture has really
been to have a unified, uh, and we call it a design language because it applies both to the,
the industrial design of the hardware, but also the, uh, code plasticity underlying all of that.
And so now that we have this, this unified, uh, shared, uh, platform, all of the information
that comes in, uh, is much more, uh, readily available for, for utilization in different models.
And so part of what we're doing, um, is increasing the personalization of our products. And to do that,
you know, if I, if you're interested in ever increasing autonomy, you don't want to have to worry
about actually sending your robot out, uh, to clean your home. You want that to just automatically
happen, and you don't want to have to worry about it. And so one of the things that, uh, we imagined
we should do, and now we do, is as you are, um, using your robot over time, we learn how you like
to clean your home. When you like to clean your home, are there specific rooms that you like to clean,
um, with different rates? And so we can make recommendations for you on when you should run your
robot or during what times in what rooms so that you can just say, yes, please do this for me
and subplugging me. And then the robot will take over. And if you have one with a clean base,
then the robot will take over and it will, um, run its, its cleaning missions, uh, on the frequency
that you've specified. And you only touch it when the clean base is full. And so one of the things
that's important to keep in mind with something like that is you're actively telling your customer
to not engage with your product. So you have to make sure that you've covered all your bases
so that your, your product is working as intended, uh, in an unsupervised way for as long as it does.
So what's the experience from the data scientist perspective? Like they,
they, there's not now post this rearchitecture. They, do they, is there a centralized place like a
data warehouse or something where they access all of this data and then, um, are there specific tools
that they are able to use now to build models that are independent of, you know, where those models
are ultimately going to run from a robot perspective. Like how, what is that? What services
or experiences does that layer provide for the data scientists that need to work on these
different models for these different robots? It really depends on the use case, right? So if you
have a robot and your robot, uh, has sent you a message for whatever reason. And so it's blinking
and you go when you look in your app and if your app is not reflecting exactly what your robot
is saying, you're going to think that we don't know what we're doing. So that's one use case where it's,
you know, it has to be extremely low latency and fairly high concurrency. So that, uh, use case for
how, for our data management is very specific. Um, whereas for the data scientists, as you ask, we
don't really have a need for, for extremely low latency because it's a, it's sort of our research
environment that as we discover things that we would like to do, um, we can then go into our data
lake and swim in it. So there are these different architectures that serve different purposes as
what they should. So in our data lake, uh, environment where our data scientists are doing a lot of
their, their researching, that's now a centralized place, um, that has, um, reduced a lot of the overhead
that our data scientists need. So a lot of the processing is taking place centrally and, um,
and we've abstracted a lot of the, the complexity of, of aggregating and transforming all of that
in our lake so that the data scientists are, are, um, essentially dealing with, with derived data sets
that already are in the format that is shared across all of our different products and all of our
different, uh, platforms, so to speak. That data lake, um, is that, what is that, is that S3
or Redshift or something else or some combination of, you know, other things? It's a combination
because of the, the different requirements of how that, uh, uh, those different data stores are
traversed. So, um, for the data scientific case in particular, we rely quite a lot on Athena.
Okay. Um, for, for the, the queering and, and the, the creation of, of, uh, extracts, uh, for,
for research, uh, one important thing to note as well is that there are, uh, significant access
controls to all of these different parts of the environment and, um, there are also the, the,
the different parts of the, the data lake that can be, uh, hashed or tokenized, um, so I don't
necessarily need to know what you call a particular room. I just need to know that you care enough
that you've named things, right? Like I don't need to know what you call your robot, um, but I would
like to know that you love it enough that you've named it. Um, so, uh, those types of, of data, uh,
care and, and maintenance are the things that, that we've centralized so that you don't have to
worry whether the data scientist knows enough to not go spolunking whether or not supposed to,
and we're really trying to protect our data scientists from themselves.
And so you've got the, this data lake environment that is, uh, Athena and other things,
depending on the use case, what are the types of tools that data scientists are typically using
there? Are you doing a lot of deep learning types of things with, uh,
uh, tension flow and that kind of stuff or, uh, psychic learn or what does the modeling experience
look like from a data scientist's perspective at a robot? I tried not to be too dogmatic, uh,
just because different tools, uh, are appropriate for different use cases. So when we are still in
the, uh, ideating and, and researching phase, uh, we've used things, uh, that run the gamut, um,
and one of the things that I mentioned is once these processes are actually, uh, running,
on the robot, they're running in, in a resource constrained environment. So when we're learning
things about the information that we, uh, have access to, those are running on our own, uh, hardware,
our own compute, uh, not necessarily our own hardware, sometimes the Amazon owns the hardware.
But still, those are, uh, we have a lot more flexibility with what we use and how it will be
appropriate. And then it's on us, uh, for whatever algorithms need to run on board, the, the robot,
to make sure that they're, uh, optimized so that they can run in the restricted compute environment.
So as far as what we're using, I mean, yes, we do use sensor flow. We use, um, uh, different
libraries. We certainly use psychic learn as well. Um, and in terms of, uh, what kind of, uh,
methodologies we're using internally. I mean, you mentioned slam, uh, you know, iRobot has,
a pretty strong, uh, published presence, uh, in the development of eSlam, um, but there are, uh,
myriad other, um, algorithms that, that we use as well. Um, and we have teams that focus on deep
learning. We have a team that focuses on reinforcement learning, um, for all sorts of different
use cases that I can't actually describe yet until we launch, uh, but they're imminent. So, um,
yeah, we have a, a pretty strong bench, uh, in terms of, of the different methodologies that
we make use of. And I, I mentioned, we both mentioned slam at this point and I did not define it
earlier. It's simultaneous. Simultaneous is that position in mapping, local addition in mapping.
Yeah. So how the robots able to go out into the world and kind of figure out where it is and
map it, it's environment. And if you've never seen it, uh, it's pretty remarkable. It's a pretty
long demo. Yeah. It is. And I have, uh, I mean, I have a million robots. Um, it's, uh, it's one of the
perks of the job having to test all of these things. But, um, I actually have, uh, I also have a
young son. And so we have, uh, child gates, sort of baby gates all over the house. And it is
remarkable to see the robots sort of figure out, oh, nope, I can't go this way. And it goes all
the way around the floor map to find another point of entry to the room that I wanted to clean.
So it's actually quite smart. And it's, you know, we forget to we who, who, who, who do this
professionally. Um, you live in the zeros and ones and the code and to actually see a piece of
hardware, uh, take that knowledge and apply it, it is actually really, really cool, which is
something that in previous, in previous roles, I didn't necessarily have. But, but to see that
mobile sensor platform take direction and utilize it and, and tangibly move around its, its environment
and understand its, its spatial components. Right. It's actually really fun.
So we've talked a little bit about data access. We've talked a little bit about modeling. I guess
kind of last question in this vein, uh, deployment. How are you deploying models, uh, so that they're
kind of accessible for inference? Like I'm thinking about AWS has like this greengrass thing where
you can like deploy models out to the edge or I'm assuming that your, the, the I robot platforms
aren't like greengrass endpoints or that you're running. I don't know. You tell me are you running
like serverless model deployment on the robots and that kind of thing or how funky does it get?
Yeah. So we, um, we're pretty bought into the serverless architecture paradigm. And so, uh, that
is essentially how most of the, the platforms run on our side. But in terms of deployment, um, for,
for the algorithms that run on the edge, we actually have, um, an OTA pipe that, um, because,
because the OTA, like how you, thank you. Yes. Right. Exactly. Um, I forget my TLAs aren't everybody's
TLAs, three-letter acronym. So thank you. Um, yeah. So, um, we, because these things are running,
on a autonomous vehicle. I mean, these aren't, you know, on the streets. They're in your homes
always. And so once, uh, once we, we introduce those models into the, the, the platform software
and we compile it and we ship it, that there's a, there's an extensive amount of testing that needs to
happen. So that, you know, if, if you're a customer and we're sending you these really cool new
features, the thing you want this robot to do is vacuum your home. That's what you went and,
and got this robot for. So that's the thing that we never want to compromise. And we make sure that
the, the, any new features that, that we introduce, be them, uh, data scientific or not,
is we have to go through this extensive, uh, battery of testing to make sure that the robot
still functions and it's not going to, you know, act all crazy because it's hardware.
It's not just that the zeros and ones are going to fly through the screen. No, the robot, uh,
is, is a thing that can hit your puppy. So don't we definitely don't want that to happen ever?
So, um, we don't have an over the air pipe that delivers just new model, uh, features. But what we do
is we have this robust system for delivery both to factories and to customers. And that's all
delivered through AWS, but it's not, uh, greengrass because that would be specifically just for model
deployment. Well, Angela, thanks so much for taking the time to chat with me about, uh, just a little
bit of what you've got going on there. It sounds like really interesting stuff and, and probably
that we need to like follow up at some point to go into more detail. Yeah, that would be great.
I love that. And thank you so much for the opportunity to turn around. Absolutely. Thanks Angela.
All right, everyone. That's our show for today. If you like what you've heard,
please do us a favor and tell your friends about the show. And if you haven't already
hit that subscribe button yourself, make sure you do so you don't miss any of the great episodes
we've got in store for you. As always, thanks so much for listening and catch you next time.
