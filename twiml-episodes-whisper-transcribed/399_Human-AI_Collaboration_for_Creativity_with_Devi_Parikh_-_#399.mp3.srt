1
00:00:00,000 --> 00:00:06,960
All right, everyone. I am here with Davey Pratik.

2
00:00:06,960 --> 00:00:11,760
Davey is an associate professor in the School of Interactive Computing at

3
00:00:11,760 --> 00:00:16,640
Georgia Tech, as well as a research scientist at Facebook AI Research.

4
00:00:16,640 --> 00:00:19,520
Davey, welcome to the Tomo AI podcast.

5
00:00:19,520 --> 00:00:24,640
Thanks for having me. It's great to get a chance to speak with you and learn a bit about what you're up to.

6
00:00:24,640 --> 00:00:32,400
As is typical, I'd love for us to start by having you introduce yourself a little bit to our audience.

7
00:00:32,400 --> 00:00:42,160
And in particular, share the source of your interest in computer vision and AI and what led you to the field.

8
00:00:42,960 --> 00:00:49,600
Sure. So I think my interest in this field started in I think about the third year of undergrad,

9
00:00:49,600 --> 00:00:55,120
my junior year, where our program had several research projects that students could get involved in.

10
00:00:56,000 --> 00:00:59,920
And especially a funny story, I was interested in computer architecture at the time.

11
00:01:00,640 --> 00:01:03,920
And I thought I had signed up for a computer architecture project, but then when they were

12
00:01:03,920 --> 00:01:08,240
matching students to project, I somehow got assigned to this machine learning project,

13
00:01:08,240 --> 00:01:12,240
which at the time we were calling patent recognition, because I was in the EC department,

14
00:01:12,240 --> 00:01:17,520
and that's what we called it then. But yeah, as I was working with it, that you can accidentally end

15
00:01:17,520 --> 00:01:22,480
up on a bit over two choices. It sounds like a popery kind of class.

16
00:01:22,480 --> 00:01:31,280
Yeah, so this was meant to be like a free form class. It wasn't in class. It was meant to be research

17
00:01:31,280 --> 00:01:36,240
projects, industry projects that students could work on for credit. And so this was through that.

18
00:01:36,960 --> 00:01:42,800
And so that's how I started working in this space. I enjoyed it enough to go to grad school and

19
00:01:42,800 --> 00:01:48,800
pursue this in grad school. And then the transition to computer vision happened about in the first

20
00:01:48,800 --> 00:01:54,960
year of when I started my PhD, where I was working on patent recognition and machine learning

21
00:01:54,960 --> 00:02:01,600
problems for intrusion detection in computer networks. But then I had colleagues around me who were

22
00:02:01,600 --> 00:02:06,400
working on images with computer vision, and they could sort of visually see the output of the

23
00:02:06,400 --> 00:02:11,840
things that they were working on, which to me felt very sort of accessible, intuitive,

24
00:02:11,840 --> 00:02:16,800
and more appealing. And I think that's where the draw came from. And I switched over to that.

25
00:02:16,800 --> 00:02:19,680
And that's what I've been doing for all these years since.

26
00:02:20,640 --> 00:02:24,320
Awesome. And you've been at Georgia Tech for how long?

27
00:02:25,840 --> 00:02:28,880
I think about four years, three and a half four years now.

28
00:02:28,880 --> 00:02:34,960
Okay. Cool. And you're also, as I mentioned, at Facebook,

29
00:02:34,960 --> 00:02:43,200
what are you kind of equally at both, or how do you, how do those go out for you? Yeah.

30
00:02:43,200 --> 00:02:49,280
Yeah. So I split my time between Georgia Tech and Fair. I'm at Georgia Tech in the fall.

31
00:02:49,280 --> 00:02:55,600
So I'm physically in Atlanta from about mid-August to mid-December or so. But I'm teaching classes

32
00:02:55,600 --> 00:03:01,040
and things of that sort. And then I'm on leave from Georgia Tech in the spring. And then that's

33
00:03:01,040 --> 00:03:09,040
when I'm spending time at Fair in the spring and summer. That's a much cleaner, or split

34
00:03:09,040 --> 00:03:12,720
than I imagined. Yeah. And I like that it's this clean. I can't

35
00:03:12,720 --> 00:03:17,920
that our colleagues who have like one day a week and flying back and forth goes to coast,

36
00:03:17,920 --> 00:03:23,680
and that just seems like a lot. So this is a much cleaner and more peaceful split.

37
00:03:23,680 --> 00:03:29,520
Yeah. Yeah. So tell us a little bit about your current research interests. How do you

38
00:03:29,520 --> 00:03:38,080
focus your research at Georgia Tech's last fair? So like we were talking about my background is in

39
00:03:38,080 --> 00:03:44,560
computer vision. In the last several years, five, seven years at this point, I've done a lot of work

40
00:03:44,560 --> 00:03:49,040
at the intersection of vision and language. So things like which were question answering, image

41
00:03:49,040 --> 00:03:55,760
captioning, and things of that sort. So that's been sort of my main research agenda. This whole

42
00:03:55,760 --> 00:04:00,400
time and continues to be. I still spend a lot of time on it. But in the last couple of years,

43
00:04:00,400 --> 00:04:06,080
I've gotten more and more interested in problems at the intersection of AI and creativity.

44
00:04:07,040 --> 00:04:12,640
And so it's still a very early, very exploratory, but I've been thinking about that quite a bit as well.

45
00:04:12,640 --> 00:04:19,840
So I spent my time between vision and language things. Also some body AI work of virtual agents

46
00:04:19,840 --> 00:04:23,760
in virtual environments and things like that. But like I said more recently, I've been thinking a

47
00:04:23,760 --> 00:04:32,320
lot about AI and creativity. And did the work in AI and language or vision and language lead directly

48
00:04:32,320 --> 00:04:40,640
to the AI and creativity or what kind of spurred that interest? Yeah, I think it's hard to kind of

49
00:04:40,640 --> 00:04:47,760
backtrack and figure out exactly what got me interested in this. I think overall I've generally

50
00:04:47,760 --> 00:04:53,680
had an inclination towards AI systems that are interacting with people. And so I think my interest

51
00:04:53,680 --> 00:04:57,680
in vision and language also was the language part of it. My background is in vision, but I think

52
00:04:57,680 --> 00:05:03,680
what drew me to language was the fact that it's sort of a very natural interface for humans for

53
00:05:03,680 --> 00:05:08,560
people to interact with these systems and ask questions or get the descriptions from the machine

54
00:05:08,560 --> 00:05:13,120
and get a sense for what the machine might be seeing and things like that. So I think it is that

55
00:05:13,120 --> 00:05:19,920
human AI interaction collaboration aspect that also interests me is also one of the reasons why

56
00:05:19,920 --> 00:05:28,640
I'm excited about AI and creativity. Cool. And so you're delivering a keynote at the AI

57
00:05:28,640 --> 00:05:37,360
and creativity or AI plus creativity workshop at CVPR. First off, maybe tell us a little bit about

58
00:05:37,360 --> 00:05:45,360
that workshop. What's the focus of the workshop? Is it a new workshop for CVPR? Is this a workshop

59
00:05:45,360 --> 00:05:51,280
that's been going on for a long time? I think it's been around for at least a few years. It's called,

60
00:05:51,920 --> 00:05:57,840
I think the workshop is called Computer Vision for fashion art and design. And I know they've

61
00:05:57,840 --> 00:06:03,200
had at least one iteration of it before this and there may have been others earlier as well.

62
00:06:03,200 --> 00:06:09,440
Neurips also has a workshop on AI and creativity that has been going on for at least a few years

63
00:06:09,440 --> 00:06:16,320
and again may have been longer. Okay, I think the AI and creativity is the title of your presentation

64
00:06:16,320 --> 00:06:25,840
at the computer vision for fashion art and design. And so what's your, tell us a little bit about

65
00:06:25,840 --> 00:06:36,080
your presentation there? Sure. So I guess I start the talk by even talking about why I think AI

66
00:06:36,080 --> 00:06:43,920
and creativity is exciting and could be impactful. And so to do that, I first start by what creativity

67
00:06:43,920 --> 00:06:50,960
even is. And I think it's sometimes hard to forget how general and how powerful just creativity is.

68
00:06:50,960 --> 00:06:59,120
It's essentially sort of any new idea that is of value period. It doesn't have to be in the context

69
00:06:59,120 --> 00:07:06,000
of art specifically or music specifically or poetry specifically. It's all of this but it's also just

70
00:07:06,000 --> 00:07:12,080
even anything of scientific progress and technological progress. All of that stems from new ideas

71
00:07:12,080 --> 00:07:19,200
that are of value in some way. So in that sense, one could even argue maybe a little bit of an

72
00:07:19,200 --> 00:07:25,280
exaggeration, but one could argue that all of progress of any kind of rests and creativity.

73
00:07:25,280 --> 00:07:31,920
And so if we can think of if there are ways in which AI can assist us in this creative endeavor,

74
00:07:31,920 --> 00:07:38,160
I feel like that's that could be that could be very powerful. Is that a is that an accepted

75
00:07:38,160 --> 00:07:45,200
definition of creativity? I'm particularly curious about the value part that seems. And for a lot

76
00:07:45,200 --> 00:07:50,000
of the things that we think of as creative, that seems to be particularly difficult to

77
00:07:51,840 --> 00:07:57,360
nail down. Yeah, yeah. So it is well accepted definition. I mean to the I guess well,

78
00:07:57,360 --> 00:08:03,200
accepted in the sense that that's what Wikipedia says. Wikipedia defines creativity that way as well.

79
00:08:03,200 --> 00:08:08,240
But then a lot of researchers like a lot of computational creativity researchers who do spend

80
00:08:08,240 --> 00:08:13,840
a good amount of time thinking about how we can define creativity. Maybe even attempt to evaluate it.

81
00:08:13,840 --> 00:08:20,000
Those definitions and those ways of thinking also tend to have these two components of novelty

82
00:08:20,000 --> 00:08:27,040
where you want something new. But there are ways of being novel just by being completely random or

83
00:08:27,040 --> 00:08:31,680
sort of sort of if it's a language domain, it's just gibberish and yes, sure, it's new, but

84
00:08:32,240 --> 00:08:39,600
is it really off value in some way? So I think that value component is also often is often thought

85
00:08:39,600 --> 00:08:45,200
about as part of creativity. It doesn't say anything about how to define value. So I think it kind

86
00:08:45,200 --> 00:08:50,400
of still offloads that issue of subjectivity. It just moves it from creativity into that value piece.

87
00:08:51,360 --> 00:08:56,080
And even novelty, if you think about it is not that easy to quantify, even that can be quite

88
00:08:56,080 --> 00:09:01,840
subjective. So I think it's useful to break it down into these components. I found it useful to

89
00:09:01,840 --> 00:09:06,400
think about it that way in the various domains where I've thought about it. But it doesn't really

90
00:09:06,400 --> 00:09:10,640
take the subjectivity away. It doesn't really make it any easier to define each of these spaces.

91
00:09:11,200 --> 00:09:16,560
Just thinking about it in terms of those pieces directly impact some of the things you've done

92
00:09:16,560 --> 00:09:27,280
in the space. I think it does. It's over hasn't directly impacted what kind of problem I look at

93
00:09:27,280 --> 00:09:34,480
in the AI and creativity space. It also hasn't necessarily impacted the kind of approach that I might

94
00:09:34,480 --> 00:09:38,800
use to the problem. But it has very directly impacted how I evaluate the approach.

95
00:09:39,520 --> 00:09:45,040
And the kinds of baselines that I think about when I want to compare the approach. So it's useful

96
00:09:45,040 --> 00:09:50,000
where if there's some approach that we have in mind. And then if we go back and think about where

97
00:09:50,000 --> 00:09:55,440
is the novelty coming from? Where is the value coming from? Then it makes it easier to think about

98
00:09:55,440 --> 00:10:00,160
what baseline would capture just the novelty but wouldn't have the value piece. And what baseline

99
00:10:00,160 --> 00:10:04,160
would capture just the value piece but might not have the novelty. And then those become

100
00:10:04,160 --> 00:10:10,240
national baselines to compare our approach to to see if we are getting a healthier mix of novelty and

101
00:10:10,240 --> 00:10:14,720
value. So I know that's a little abstract, but hopefully that's useful.

102
00:10:16,480 --> 00:10:21,680
When you think about or when you kind of plan out your work in the space, are you

103
00:10:21,680 --> 00:10:33,920
primarily interested in kind of AI augmented creativity where the AI is helping us to be

104
00:10:34,880 --> 00:10:41,680
more creative? You mentioned that earlier. Or do you also look at just kind of creative or

105
00:10:41,680 --> 00:10:50,240
or pseudo creative depending on how rigid you want to define things. Output of AI algorithms.

106
00:10:50,240 --> 00:11:00,160
Even that question, can AI be creative in and of itself? There's a lot of AI-generated art.

107
00:11:00,160 --> 00:11:07,280
You do some of that stuff yourself. Does that qualify as creativity?

108
00:11:08,880 --> 00:11:13,360
I think that's a great question. There's a lot of interesting conversations that are happening

109
00:11:13,360 --> 00:11:18,640
in the community around exactly this. What does it even mean for machines to be creative? Can

110
00:11:18,640 --> 00:11:26,320
machines be creative at all? There are fairly strong opinions on both sides of this and everything

111
00:11:26,320 --> 00:11:35,440
in the middle. I think it's useful to think about that. I don't think that directly impacts

112
00:11:35,440 --> 00:11:41,840
the kind of work I do primarily because like I was saying whether or not machines can be creative

113
00:11:41,840 --> 00:11:46,320
feels like a secondary question in the way I approach it. I'm more interested in knowing whether

114
00:11:46,320 --> 00:11:51,200
machines can help humans be more creative than they would have been on their own. I think if it

115
00:11:51,200 --> 00:11:55,600
has sort of a team setting where if you had the machine alone that was trying to produce something,

116
00:11:55,600 --> 00:12:00,400
if you had a human alone that was where they were trying to produce something and instead if both

117
00:12:00,400 --> 00:12:08,480
work together is the final creative artifact more creative or even if it's not the case but is the

118
00:12:08,480 --> 00:12:13,440
process is the creative process more engaging and more enjoyable for the human than it would have been

119
00:12:13,440 --> 00:12:20,080
if a machine wasn't involved. So that's how I tend to think of it. I do think that there are

120
00:12:20,080 --> 00:12:25,760
multiple stages at which a machine could interact with the human in the creative process. It could be

121
00:12:26,640 --> 00:12:31,440
a very tight engagement where throughout the creative process both are sort of working with

122
00:12:31,440 --> 00:12:35,840
each other to get there as you might with sort of a human collaborator, a human team member.

123
00:12:36,480 --> 00:12:41,920
But I think it can also be something where sort of the seed of inspiration comes from something

124
00:12:41,920 --> 00:12:47,840
the machine did and then the human takes over from there and if we can show that what the human

125
00:12:47,840 --> 00:12:54,080
produces at the end of it or the process that they go through after being inspired by whatever

126
00:12:54,080 --> 00:12:59,600
the machine did is somehow better, more creative, more enjoyable, more satisfying than what would

127
00:12:59,600 --> 00:13:05,440
have happened if if this seed of inspiration didn't wasn't there from the machine. I would still

128
00:13:05,440 --> 00:13:10,240
think of that as success even though the human and the machine are not necessarily closely working

129
00:13:10,240 --> 00:13:16,320
with each other. So in that piece of the machine providing a seed for inspiration, the machine could

130
00:13:16,320 --> 00:13:21,600
be working fairly autonomously where there isn't necessarily human involvement, but I still think of

131
00:13:21,600 --> 00:13:31,200
that as AI assisted creativity for the human. Besides that particular categorization of whether

132
00:13:31,200 --> 00:13:41,440
the two are working together or in series is there like a framework for thinking about

133
00:13:42,800 --> 00:13:49,840
the different directions that people are going in terms of AI and art or even AI and

134
00:13:49,840 --> 00:14:02,880
computer assisted creativity just in terms of laying out a landscape for the different

135
00:14:02,880 --> 00:14:10,560
directions of research and practice. So I don't know if there's a well-established framework for

136
00:14:10,560 --> 00:14:14,720
it and so there's a good chance that I'm missing some frameworks or some ways of thinking about it

137
00:14:14,720 --> 00:14:21,360
that other people have, but if I were to think about it now, I can think of a couple of different

138
00:14:21,360 --> 00:14:32,960
ways of organizing it. One is where the creative task is a very task-driven one and so where

139
00:14:34,080 --> 00:14:39,040
the human might be trying to do something very specific where they're trying to design a bridge

140
00:14:39,040 --> 00:14:44,640
that will work well for a particular scenario. So they're trying to get a particular task done

141
00:14:44,640 --> 00:14:49,760
and to do that task there is a lot of creative thinking that's required and the machine could help

142
00:14:49,760 --> 00:14:56,080
in that in some way and the other is where a human is more just exploring where they are

143
00:14:57,040 --> 00:15:01,760
just sort of like you might like the contrast between sort of drawing versus doodling.

144
00:15:01,760 --> 00:15:06,080
In the former you are very intentionally trying to create something specific whereas if you're

145
00:15:06,080 --> 00:15:10,880
doodling you're just kind of sketching different things. So that kind of thing where you're just sort

146
00:15:10,880 --> 00:15:15,760
of exploring trying to encounter something that is of creative value to you and I think those two

147
00:15:15,760 --> 00:15:22,800
scenarios require different kinds of tools to help you in that. So that's one kind of separation

148
00:15:22,800 --> 00:15:31,440
that we can think of. Another kind of separation could be where the machine tries to mimic humans

149
00:15:31,440 --> 00:15:36,160
in the process of trying to be creative. So for example if you think about trying to get machines

150
00:15:36,160 --> 00:15:42,640
to find a new dance, a new choreography that will go well with music. You could train the machine

151
00:15:42,640 --> 00:15:48,320
using supervised data where you have data of dancers dancing to different forms of music and so

152
00:15:48,320 --> 00:15:53,680
there the machine is trying to mimic humans to be creative whereas you could instead also approach

153
00:15:53,680 --> 00:15:58,320
it as getting the machine to just discover movements that are well-signed with music

154
00:15:58,320 --> 00:16:02,960
where through something like reinforcement learning is just trying to find a series of movements

155
00:16:02,960 --> 00:16:08,000
that is well aligned with the music but is not at all influenced by the kinds of dances that already

156
00:16:08,000 --> 00:16:14,000
exist in the world and those might have pros and cons and different values based on the kind of

157
00:16:14,000 --> 00:16:19,360
application that you're looking at. So these are two ways of organizing the work that I can think of

158
00:16:19,360 --> 00:16:30,160
but there are probably others as well. So in your talk you are going to be reviewing a handful of

159
00:16:30,160 --> 00:16:38,400
projects that you've worked on kind of across this space. I think the first one is the casual

160
00:16:38,400 --> 00:16:46,320
creator or is it causal or casual? It's casual creator and so that actually goes back to the first

161
00:16:46,320 --> 00:16:54,000
point that I was making. So casual creators and this was a term coined in one of the ICCC

162
00:16:54,000 --> 00:16:58,720
papers International Conference and Computational Creativity from a few years ago so it's not

163
00:16:58,720 --> 00:17:06,240
it's not a term that I've come up with but it refers to tools that are meant to aid humans who are

164
00:17:06,240 --> 00:17:13,680
exploring sort of are just exploring and are not trying to build something or create something

165
00:17:13,680 --> 00:17:19,520
for a particular downstream task and so those are called casual creators. And so we've looked at

166
00:17:20,400 --> 00:17:25,680
what we could do in that space to give people tools that might make it a little bit easier

167
00:17:25,680 --> 00:17:32,320
to find something that interests them. And what are some examples of the specific things that you

168
00:17:32,320 --> 00:17:40,320
explored there? Yeah so one is where we have this I've been I guess on the side I've been

169
00:17:40,320 --> 00:17:48,480
dabbling a bit in algorithmic art which which involves it's basically creative coding where

170
00:17:49,360 --> 00:17:55,920
I create these geometric patterns that I think look interesting and so I set the rules of what

171
00:17:55,920 --> 00:18:00,640
these patterns could look like and there's an element of randomness every time you run the code

172
00:18:00,640 --> 00:18:05,120
you're going to see a different pattern. It's going to follow the parameters that I set up so

173
00:18:05,120 --> 00:18:08,640
it's not going to be completely arbitrary but within those parameters you're going to see

174
00:18:08,640 --> 00:18:14,800
different samples. And in that context there are some parameters that I have set but then there

175
00:18:14,800 --> 00:18:19,360
are also some parameters that somebody else could set for example what color palette should these

176
00:18:19,360 --> 00:18:25,040
colors be sampled from and that you as a user could set that to a variety of different

177
00:18:25,040 --> 00:18:30,800
palettes and then see samples from that. So in that context you could think of the tool that I've

178
00:18:30,800 --> 00:18:37,600
built as being a casual creator and that's a tool that you as a user could use to just explore

179
00:18:37,600 --> 00:18:41,280
different patterns try different parameters and see if you find something you like you're not

180
00:18:41,280 --> 00:18:47,200
trying to look for something specific and what we looked at is as you are interacting with this tool

181
00:18:47,200 --> 00:18:52,560
as you're playing with these different parameters can I can we build a model that can predict

182
00:18:53,120 --> 00:18:57,440
what else you might like. So as you're let's say picking one of the different color palettes based

183
00:18:57,440 --> 00:19:02,800
on your choice of the color palette can I make a guess for whether you will like lines with more

184
00:19:02,800 --> 00:19:08,480
curvature or whether you will prefer straight lines and sort of an angular design and if we can

185
00:19:08,480 --> 00:19:14,000
predict that then as you're interacting with these with the stool I can already narrow down the

186
00:19:14,000 --> 00:19:19,200
space of things that you should explore in the future in hopes that you will find something that

187
00:19:19,200 --> 00:19:24,640
you like faster than you would have if you were just exhaustively trying all these parameters out

188
00:19:24,640 --> 00:19:32,800
so that's that's that's one thing that we've looked at in that space. And so the can you talk a

189
00:19:32,800 --> 00:19:43,920
little bit about the kind of the technical contributions or the particular areas of particular

190
00:19:43,920 --> 00:19:51,600
challenge for a work like that it sounds like part of it is the modeling which sounds a little bit

191
00:19:51,600 --> 00:19:57,200
like a recommendation system I'm almost envisioning like you know sometimes I'll pull up an adobe

192
00:19:57,200 --> 00:20:04,000
you know art app or something similar and there are all these palettes of tools and I would just

193
00:20:04,000 --> 00:20:08,080
love for that thing to guess the thing that I need next as opposed to having me having that you know

194
00:20:08,720 --> 00:20:15,120
exactly exactly exactly so yeah it is you can think of it as a smart tool as a recommendation

195
00:20:15,120 --> 00:20:21,200
system I think the the bigger so that the technical approach is fairly straightforward in this

196
00:20:21,200 --> 00:20:27,040
where we sort of collector pairwise preferences from people in terms of what they like better than

197
00:20:27,040 --> 00:20:31,440
something else and we use a subset of those preferences to see if we can reliably predict the

198
00:20:31,440 --> 00:20:37,600
others I think the bigger question here was whether that signal even exists that based on your

199
00:20:37,600 --> 00:20:43,280
choice of a color palette is there would I be able to guess that you might like straight lines over

200
00:20:43,280 --> 00:20:50,160
lines with more curvature or not kind of thing and it's not obvious going in whether that correlation

201
00:20:50,160 --> 00:20:55,200
would exist or not and the answer to this I'm sure depends heavily on the specific domain or

202
00:20:55,200 --> 00:21:01,200
even specific algorithmic art form that you're looking at and so our my main curiosity in doing

203
00:21:01,200 --> 00:21:08,560
this was to see whether this correlation exists or not to begin with and then we have found some

204
00:21:08,560 --> 00:21:13,600
signal that at least in the specific algorithmic art domain that we were looking at that these

205
00:21:13,600 --> 00:21:20,000
correlations do exist we can predict better than chance at least what else you might like based

206
00:21:20,000 --> 00:21:25,200
on some of the preferences that you've given us so far in the algorithmic art the challenge

207
00:21:25,200 --> 00:21:30,400
then remains of how do you plug this into the tool and sort of you would have to look at sequential

208
00:21:30,400 --> 00:21:34,880
decision making whereas you're interacting with this in a sequential fashion we want to be making

209
00:21:34,880 --> 00:21:39,600
these predictions right now everything that we've done is very sort of snapshot at one

210
00:21:40,320 --> 00:21:48,800
instance in time and so the pairwise preferences was that data that you had to collect from

211
00:21:48,800 --> 00:21:56,880
from scratch or were you able to yeah I find that somewhere yeah no we had we had to collect

212
00:21:56,880 --> 00:22:02,160
that from scratch because we were doing this in the context of this particular algorithmic art

213
00:22:02,160 --> 00:22:07,920
tool that I had so we weren't like using preferences on other things that might already exist out there

214
00:22:07,920 --> 00:22:14,320
and so we did this on Amazon Mechanical Turk where we showed people pairs of art pieces and

215
00:22:14,320 --> 00:22:19,760
and and what's nice about these tasks compared to a lot of other things that tend to be on Amazon

216
00:22:19,760 --> 00:22:24,240
Mechanical Turk is these are much more interesting tasks people like looking at pieces of art and

217
00:22:24,240 --> 00:22:29,200
telling you which one they like better and things like that so it's it's quite easy to collect a lot

218
00:22:29,200 --> 00:22:38,400
of data for a bit more about how you set up the task did you show them like two complete pictures

219
00:22:38,400 --> 00:22:46,320
that varied in one particular dimension or did you or or what yeah exactly that exactly that

220
00:22:46,320 --> 00:22:51,600
where we wanted to make sure that the preferences that we are collecting are along specific

221
00:22:51,600 --> 00:22:56,880
dimensions so we tried to keep everything else the same between these two pieces and only change

222
00:22:56,880 --> 00:23:00,960
one variable like just the color palette or just the thickness of lines and things like that

223
00:23:01,760 --> 00:23:06,560
and based on that we collected preferences so that we can then check for correlations across these

224
00:23:06,560 --> 00:23:16,960
okay very cool and is that an example of one of of of portfolio things that you've done in the

225
00:23:17,520 --> 00:23:24,880
this kind of genre of casual creativity or are there others yeah there is there is one other project

226
00:23:24,880 --> 00:23:30,960
that we've looked at in this space which we've been calling neurosymbolic in generative art

227
00:23:30,960 --> 00:23:36,480
okay so it's and it's perhaps an interesting kind of there's a lot of debate in AI right now in

228
00:23:36,480 --> 00:23:41,760
terms of it's sort of neural networks kind of reasoning pattern matching the right kind of

229
00:23:41,760 --> 00:23:47,680
approach to use for many of these challenges challenging tasks or if we need more symbolic reasoning

230
00:23:47,680 --> 00:23:53,600
to do these things and so it's a it's a little bit of a play on that debate in the context of

231
00:23:53,600 --> 00:24:00,240
a generative art or algorithmic art and so what we did there was we look we took these algorithmic

232
00:24:00,240 --> 00:24:07,920
art tools like the ones I told you where the pattern being generated is through these very symbolic

233
00:24:07,920 --> 00:24:11,760
parameters that have been set like the color palettes and shapes and things of that sort

234
00:24:12,640 --> 00:24:17,840
so there's been that line of work in a generative art where in this setting you can

235
00:24:18,400 --> 00:24:22,400
sample different random samples within those parameters and then there's been a huge amount

236
00:24:22,400 --> 00:24:27,840
of work especially with GANS with generative adversarial networks where people have trained

237
00:24:27,840 --> 00:24:32,960
neural networks that allow you to model the distribution of data and then again you can sample

238
00:24:32,960 --> 00:24:38,480
random samples through that and people have found in some domains that to also have artistic value

239
00:24:38,480 --> 00:24:42,160
where some of these generations are very interesting and you can sort of walk through the latent

240
00:24:42,160 --> 00:24:46,960
space and look at interpolations which make for very interesting visualizations and so we were

241
00:24:46,960 --> 00:24:51,920
curious whether there's something that falls at the intersection of these two generative approaches

242
00:24:51,920 --> 00:24:57,840
the sort of the algorithmic and symbolic versus the the neural generative approach and so what we

243
00:24:57,840 --> 00:25:04,560
did was something fairly straightforward again as more of a pilot study where we a generator

244
00:25:04,560 --> 00:25:09,680
many different samples from the algorithmic approach and in theory we can get as much data as we

245
00:25:09,680 --> 00:25:14,480
want because these are just different random samples from the same system and we train a neural

246
00:25:14,480 --> 00:25:19,600
generative modern on it so we trained again on it and we were interested in seeing that if again

247
00:25:19,600 --> 00:25:26,080
trained on these symbolically generated images is is of value to people whether people find it

248
00:25:26,080 --> 00:25:32,800
interesting to look at to play with to look at these interpolations and what they think there

249
00:25:33,680 --> 00:25:40,080
and so what we found is that when we compare these neurosymbolic generations both the final artifact

250
00:25:40,080 --> 00:25:46,240
and the process of interacting with these systems to the symbolic counterpart people prefer the

251
00:25:46,240 --> 00:25:53,440
neurosymbolic approaches fairly frequently compared to the symbolic one and so that seemed like

252
00:25:54,160 --> 00:25:58,880
good validation that there might be something in this direction that is that is worth exploring more

253
00:25:59,680 --> 00:26:04,960
and did your work in the area give you any intuition for why that is?

254
00:26:04,960 --> 00:26:13,920
So I think it maybe goes back to the novelty and value

255
00:26:15,200 --> 00:26:19,280
distinction the trade off that we were talking about earlier I guess not trade off which is

256
00:26:19,280 --> 00:26:29,040
decomposition where I think these patterns looked interesting they looked they look good

257
00:26:29,040 --> 00:26:34,400
to people they seem to be high quality because they are coming from this symbolic generation process

258
00:26:34,400 --> 00:26:38,640
where somebody has thought through and picked these parameters to make sure these patterns look

259
00:26:38,640 --> 00:26:44,960
interesting but then the neural artifacts that tend to be there in these generations

260
00:26:44,960 --> 00:26:50,320
I think probably look intriguing to people and look different than what they are used to

261
00:26:50,320 --> 00:26:56,240
and so I think that combination is our hypothesis for why they may have found it to be interesting

262
00:26:57,520 --> 00:27:01,600
yeah it's hard to know for sure but that's our hypothesis based on the test that we've run

263
00:27:01,600 --> 00:27:06,160
okay very cool and I should have mentioned this earlier but all of the

264
00:27:07,840 --> 00:27:12,640
examples that you know we're talking about we'll be linking to in the show notes

265
00:27:13,840 --> 00:27:20,560
including your CVPR presentation which walks through these as well so that's the

266
00:27:20,560 --> 00:27:29,040
casual creator side the next set of examples were around kind of this idea of machines inspiring

267
00:27:29,040 --> 00:27:37,520
humans talk a little bit about how you you know how you created a project in that area how did you

268
00:27:37,520 --> 00:27:45,280
set that up yeah so one project that we've looked at in that space is on I alluded to this a

269
00:27:45,280 --> 00:27:52,560
little bit earlier is on seeing if machines can discover dance can discover movements that are

270
00:27:52,560 --> 00:28:00,800
in sync with music and so we had what we were the sort of main motivation there or main

271
00:28:00,800 --> 00:28:06,400
goal was there to not train the machine with dances that already exist we wanted to see

272
00:28:06,400 --> 00:28:11,840
what dance sort of emerges if the machine is just trying to produce movement that sings well

273
00:28:11,840 --> 00:28:18,560
with music what does that look like the people find value in that and so so that was that was one

274
00:28:18,560 --> 00:28:26,240
project where we take in as input a snippet of music we have a music representation that essentially

275
00:28:26,240 --> 00:28:32,640
gives us a sense for which to at different points in time when are the pieces of music similar

276
00:28:32,640 --> 00:28:39,920
versus not and then what we try and do is generate a sequence of movements such that when the music

277
00:28:39,920 --> 00:28:46,880
is similar at two points in time the movements are similar at those points in time the similarity

278
00:28:46,880 --> 00:28:52,640
could be in terms of where the agent is on this virtual stage if you will or it could be in terms

279
00:28:52,640 --> 00:28:57,520
of what actions it is taking at those points in time and so we evaluate which one of these

280
00:28:57,520 --> 00:29:03,440
similarities is better and things like that okay now for someone listening to this conversation

281
00:29:03,440 --> 00:29:10,480
who has in senior presentation you might be envisioning like you know open a gym simulation of

282
00:29:10,480 --> 00:29:19,200
humanoid object or something like that or but actually the example that you showed is quite a bit

283
00:29:19,200 --> 00:29:27,280
more simplistic than that absolutely yeah absolutely and it's not even a stick figure if you actually

284
00:29:27,280 --> 00:29:33,920
think about it it's the agent is parametrized in an extremely simple way like you said it can only

285
00:29:33,920 --> 00:29:40,480
take one of K different states at any point in time okay and at any point in time it can go either

286
00:29:40,480 --> 00:29:47,680
one stay once one state up one stay down or stay where it is and it's not allowed to go out of bounds

287
00:29:47,680 --> 00:29:52,720
so it can't go outside of the range and that's it that's all it can do it can just take three actions

288
00:29:52,720 --> 00:29:58,960
at any point in time and it's characterized with just this one ordinal value of states what is nice

289
00:29:58,960 --> 00:30:06,080
about that though is that because it's it's this general you can visualize or instantiate this

290
00:30:06,080 --> 00:30:13,440
agent in many different ways I can make these K states be a sequence of poses that a stick figure

291
00:30:13,440 --> 00:30:19,200
can take and I think that's what you're referring to it can be even simpler where it's just the size

292
00:30:19,200 --> 00:30:25,440
of a dot where it can become bigger or smaller as the music is changing it can be a dot that's

293
00:30:25,440 --> 00:30:32,720
traversing left to right as the music changes and it can even be a fairly complex geometric pattern

294
00:30:32,720 --> 00:30:38,480
that can be set that can be changed based on one parameter so sort of these I don't know if you

295
00:30:38,480 --> 00:30:43,040
have if you saw these videos and I guess the listeners can watch it offline I'm happy to send

296
00:30:43,040 --> 00:30:49,920
your pointers to it but you can have these very leafy visualizations where the sort of the sway

297
00:30:49,920 --> 00:30:54,960
of that of that leafy pattern changes based on this one parameter and so you can have all these

298
00:30:54,960 --> 00:30:59,440
leaves sort of moving and synch with the music and so that is something that I was very excited

299
00:30:59,440 --> 00:31:04,000
about that it's so general that you can have many different visualizations and hopefully

300
00:31:04,000 --> 00:31:08,960
some visualizations are more inspiring in terms of what movements make sense than than others

301
00:31:09,840 --> 00:31:15,920
and I thought that was that was kind of cool I didn't see that the the leafy one if I'm thinking

302
00:31:15,920 --> 00:31:22,880
of the same one and it's really interesting to understand now that those are generated by the

303
00:31:22,880 --> 00:31:27,360
same underlying model because I found the leafy one much more compelling than the stick figure

304
00:31:28,320 --> 00:31:34,320
it's like really interesting visually I think exactly exactly and so there's a lot of yeah

305
00:31:34,320 --> 00:31:39,040
it's exactly that that all of these different visualizations it's the same underlying agent the same

306
00:31:39,040 --> 00:31:43,440
characterization anything a lot of interesting work can be done in figuring out what these

307
00:31:43,440 --> 00:31:49,120
visualizations should look like to make the same underlying movement more or less inspiring more

308
00:31:49,120 --> 00:31:55,040
or less appealing for what a person is trying to do at the end of it and so how do you go about

309
00:31:55,040 --> 00:32:01,440
figuring out what that model should look like as you're starting a project like this so by the

310
00:32:01,440 --> 00:32:07,840
model you mean like what the characterization of the agent should be or right right I think to be

311
00:32:07,840 --> 00:32:15,200
honest in this case it was it was essentially us trying to think about what instantiation captures

312
00:32:15,200 --> 00:32:21,440
the sense of what we're trying to get out so our interest in this was not to figure out how we can

313
00:32:21,440 --> 00:32:28,880
get a humanoid to stay stable and learn the laws of gravity or anything of that sort which sort of

314
00:32:28,880 --> 00:32:34,080
a lot of the reinforcement learning opening I gym like things are meant for so we were not interested

315
00:32:34,080 --> 00:32:40,720
in those things we were interested in this question of if we produce movements that are just in

316
00:32:40,720 --> 00:32:45,520
sync with the music that's that's all the constraint is what does that look like does that look

317
00:32:45,520 --> 00:32:51,280
interesting or not and so we were trying to figure out what is a characterization of the agent

318
00:32:51,280 --> 00:32:56,480
that leaves out all the challenges that we're not interested in but maintains the sense of the

319
00:32:56,480 --> 00:33:02,240
question that we are interested in exploring and this instantiation that that I described was

320
00:33:02,880 --> 00:33:07,680
one that seemed to capture that and so that's what we went with but that could be other starting

321
00:33:07,680 --> 00:33:15,440
points that are equally reasonable and in this particular case where do you go with the

322
00:33:15,440 --> 00:33:22,000
the research does it matter even to try to scale up the you know the model so that it you

323
00:33:22,000 --> 00:33:26,480
know has more stage or is continuous or something like that or is that kind of beyond the point

324
00:33:26,480 --> 00:33:32,240
of what you're trying to show here yeah no I think I think that would be of interest in terms of

325
00:33:32,240 --> 00:33:37,200
because the kinds of movements that we might be able to get might be more interesting if the agent

326
00:33:37,200 --> 00:33:42,560
can take more actions and be in more states than things of that sort so there's probably I'm sure

327
00:33:42,560 --> 00:33:47,200
not probably I'm sure there's a space of movements that cannot be captured with the kind of

328
00:33:47,200 --> 00:33:52,480
instantiation that we have and so I think that would be of interest those could be more inspiring

329
00:33:52,480 --> 00:33:57,840
another thing though is even before that the current approach that we've used to find

330
00:33:58,480 --> 00:34:04,720
this movement that is synced is actually a fairly straightforward just greedy search like approach

331
00:34:04,720 --> 00:34:10,720
there isn't in that sense sort of actual learning that's happening it's more a search process where

332
00:34:10,720 --> 00:34:16,400
we're just optimizing for this movement being synced with music and so what that means is whenever

333
00:34:16,400 --> 00:34:21,840
there's a new piece of input music we're doing the search from scratch it's fairly fast because

334
00:34:21,840 --> 00:34:25,440
it's a greedy approach but it's still every time you give me a piece of music we're just doing

335
00:34:25,440 --> 00:34:30,720
the search from scratch and then finding a dance that goes with it I would be very interested in

336
00:34:30,720 --> 00:34:37,280
doing this in a more machine learning fashion where we've learned mappings of given an input

337
00:34:37,280 --> 00:34:43,440
music what are the characteristics that the output dance needs to have so that at test time we

338
00:34:43,440 --> 00:34:48,480
can now just given an input piece of music just directly predict what the movement should look like

339
00:34:48,480 --> 00:34:54,560
rather than having to run the search process at test time and so starting with a large database of

340
00:34:54,560 --> 00:35:00,720
music of songs and sort of training this model to be able to figure out what pattern makes sense

341
00:35:00,720 --> 00:35:05,200
pattern of movement makes sense and then using that to do the prediction is something that I

342
00:35:05,200 --> 00:35:11,200
think would be would be interesting to do. You mentioned the the search that you're doing on the

343
00:35:11,200 --> 00:35:18,720
music is looking for parts of the music that are similar is that is it analogous to like a beat

344
00:35:18,720 --> 00:35:27,120
detection kind of approach or something different. It is it is related to that like beats would be one

345
00:35:28,400 --> 00:35:33,520
piece of information that affects where the music is repeating but it's it's quite a bit more

346
00:35:33,520 --> 00:35:38,720
fine grained than that that even if the beat so yes if you look at it's I guess it's hard to

347
00:35:38,720 --> 00:35:43,280
describe in words but you can look at this visualization of a matrix that tells you how similar

348
00:35:43,280 --> 00:35:47,280
the music is at different points in time and there's a lot of rich structure there

349
00:35:47,280 --> 00:35:54,080
that is beyond that includes the beats but goes quite a bit beyond that. Okay I'm envisioning

350
00:35:54,080 --> 00:35:59,680
something like a auto correlation where you're kind of shifting the music and trying to protect.

351
00:35:59,680 --> 00:36:05,360
Exactly exactly very much is an autocorrelation in the in an acoustic feature space so where we're

352
00:36:05,360 --> 00:36:10,400
using these rich acoustic features and we're looking for autocorrelation there and in it's the

353
00:36:10,400 --> 00:36:14,000
same thing that we're looking at in the movement that we also have a similar autocorrelation

354
00:36:14,000 --> 00:36:19,600
like matrix for the movement and we're trying to say that the autocorrelation matrix of the movement

355
00:36:19,600 --> 00:36:24,640
should be similar to the autocorrelation matrix of the music and that's the reward if you will

356
00:36:24,640 --> 00:36:33,200
that the agent gets as it decides what actions to take. Okay cool cool you've also got an example

357
00:36:33,200 --> 00:36:41,520
that is illustrating the collaboration that you have spoken about called sketches or focused

358
00:36:41,520 --> 00:36:47,280
on sketches you talk a little bit about that one. Sure yeah so there we've there isn't a machine

359
00:36:47,280 --> 00:36:53,920
there yet this was we studied this in the context of humans with the idea being that if we can

360
00:36:53,920 --> 00:36:59,680
so the the setup is that if you have you're trying to create sketches and if you have a blank canvas

361
00:37:00,320 --> 00:37:05,600
we were trying to look at what collaboration mechanisms lead to sketches that are more interesting

362
00:37:05,600 --> 00:37:10,800
and more creative than others and so the way this collaboration plays out is that you start with

363
00:37:10,800 --> 00:37:17,120
the blank canvas and then one person comes in and draws some strokes on it and then somebody else

364
00:37:17,120 --> 00:37:23,200
comes and draws more strokes on it and and we keep going and we can see how this sketch evolves

365
00:37:23,200 --> 00:37:27,840
and what the final sketch looks like and we were trying to see like I said what collaboration

366
00:37:27,840 --> 00:37:35,600
mechanisms might make sense in that context and so we found a few interesting things here where

367
00:37:35,600 --> 00:37:41,760
what we found is that if just one person draws the whole sketch from start to finish there's

368
00:37:41,760 --> 00:37:46,080
a variance in quality depending on the motivation and skill level off that person

369
00:37:47,680 --> 00:37:52,000
so that's one there's there's large variance in quality and the other is that even when the

370
00:37:52,000 --> 00:37:59,680
quality is high these sketches don't seem surprising or novel to people they kind of like there might

371
00:37:59,680 --> 00:38:04,160
be a sketch of a tree with a bird on it with a sound in the background and sort of things of that

372
00:38:04,160 --> 00:38:08,800
sort that maybe we've seen before and so people don't find them particularly intriguing

373
00:38:10,160 --> 00:38:15,200
the other setup is where you have different people coming and drawing these different strokes

374
00:38:15,200 --> 00:38:20,960
and what we found there is that these sketches look entirely different the qualitative will look

375
00:38:20,960 --> 00:38:26,000
very different from what what happens when one person draws it all out and so people find

376
00:38:26,000 --> 00:38:30,480
them very interesting they're very intriguing but they also find them to be a little too chaotic

377
00:38:30,480 --> 00:38:34,560
where there's just all sorts of things happening on this canvas and it's harder to sort of make

378
00:38:34,560 --> 00:38:40,160
sense of it sometimes it can also look like it's poor quality and so what we found is that a

379
00:38:40,160 --> 00:38:46,880
collaboration setting where at each stage there is some form of a voting mechanism where let's say

380
00:38:46,880 --> 00:38:52,960
I am the person who now has to add strokes to this canvas if I'm shown five versions of the canvas

381
00:38:52,960 --> 00:38:57,760
and I get to pick which one I want to add strokes to then what we found is the evolution of the

382
00:38:57,760 --> 00:39:03,200
canvas through this mechanism leads to pictures that are still quite interesting still very

383
00:39:03,200 --> 00:39:09,600
different from what someone would make if they drew it alone but are not quite as chaotic and noisy

384
00:39:09,600 --> 00:39:14,480
as what happens when there isn't a voting mechanism involved because what happens is the sketches

385
00:39:14,480 --> 00:39:19,200
that are a little bit more coherent are a little bit higher quality are the ones that tend to get

386
00:39:19,200 --> 00:39:24,080
more votes and those are the ones that proceed forward whereas the ones where someone may have

387
00:39:24,080 --> 00:39:29,040
kind of scribbled something or added something to the canvas that didn't that sort of broke its

388
00:39:29,040 --> 00:39:35,600
coherence tend to not get votes and then those don't go forward so it kind of is a good balance

389
00:39:35,600 --> 00:39:41,680
again of novelty and value where you get of these interesting compositions because so many

390
00:39:41,680 --> 00:39:46,240
different people are contributing to it but the voting mechanism keeps sort of the value and the

391
00:39:46,240 --> 00:39:52,080
quality and the coherence high to eventually give you sketches that were rated as more creative

392
00:39:52,080 --> 00:39:58,000
the idea of these sort of other scenarios interesting so does this you know as this plays out does it

393
00:39:59,360 --> 00:40:05,680
produce something that is amazing like is this a mechanism for allowing and you know a crowd of

394
00:40:05,680 --> 00:40:11,440
kind of the unwashed masses you know with no particular art skill to produce like incredible

395
00:40:12,480 --> 00:40:16,240
things that an individual probably couldn't or wouldn't or

396
00:40:16,240 --> 00:40:24,560
is it you know less modest than that and it's in the output so I would say it is less modest than

397
00:40:24,560 --> 00:40:29,920
that I think the way you put it was yeah I think it is it is less modest than that but I think it

398
00:40:29,920 --> 00:40:36,320
is along those lines I think it is taking steps in that direction where as a result of this crowd

399
00:40:36,320 --> 00:40:42,640
of people who may have varying levels of skills in terms of making these sketches we ended up

400
00:40:42,640 --> 00:40:47,280
creating something that no individual would have created it was qualitatively different

401
00:40:48,320 --> 00:40:53,520
whether you like it better or not again a lot of these things are subjective we did find that more

402
00:40:53,520 --> 00:40:58,320
people in our studies liked these collaborative sketches better than they like the ones that

403
00:40:58,320 --> 00:41:02,800
individuals have created yeah there's variance along that but they're certainly qualitatively

404
00:41:02,800 --> 00:41:06,640
very different they're not they're not the same thing so we are getting artifacts that are

405
00:41:06,640 --> 00:41:12,000
different as a consequence of this collaboration yeah the setting sounds really interesting and I've

406
00:41:12,800 --> 00:41:19,360
got to imagine that there have been lots of attempts at you know collaborative art of various forms

407
00:41:20,800 --> 00:41:26,240
and adding in you know some kind of voting mechanism or or something like that or you know

408
00:41:27,360 --> 00:41:34,240
a vetting mechanism of each individual's contribution to this thing or the the prior

409
00:41:34,240 --> 00:41:41,120
or round of contributions to this thing sounds like an interesting way to help the end result evolve

410
00:41:41,120 --> 00:41:47,040
more quickly into something that is appealing yeah exactly exactly and it touches on

411
00:41:48,320 --> 00:41:53,760
much larger questions of what collaboration should look like when people are engaging in a creative

412
00:41:53,760 --> 00:41:58,160
activity I mean we've obviously studied this in a very narrow domain in a very specific setting

413
00:41:58,160 --> 00:42:06,080
but I think the underlying question is quite important in sort of a larger context as well and then

414
00:42:06,080 --> 00:42:14,240
you've got a last category of projects that you've been exploring focused on visual journaling

415
00:42:14,240 --> 00:42:20,720
what's that one about yeah so that one is is a fun project where our our thought was that

416
00:42:20,720 --> 00:42:29,760
if people could see an abstract visualization of their sort of daily journal entry that might

417
00:42:29,760 --> 00:42:34,720
be a way to keep people more engaged that might increase the probability that they will journal

418
00:42:34,720 --> 00:42:40,560
on a regular basis maybe they could also sort of share this entry in a visual way with sort of

419
00:42:40,560 --> 00:42:44,800
family and friends that they're close to or things of that sort and so we're curious to see what

420
00:42:44,800 --> 00:42:50,480
we can do there and if we can create something that is that people do find interesting and so what we

421
00:42:50,480 --> 00:42:58,960
do is we take we asked people with their with their consent to write up a short journal entry of what

422
00:42:58,960 --> 00:43:03,520
the day of what their day looked like and obviously they could decide what they wanted to share in

423
00:43:03,520 --> 00:43:11,200
that journal entry or not and from that we run some sort of natural language processing techniques

424
00:43:11,200 --> 00:43:18,400
to extract what three salient topics were that they were talking about so we had a handful of

425
00:43:18,400 --> 00:43:25,120
categories I think maybe about a dozen or so things like work family friends food sleep

426
00:43:25,680 --> 00:43:29,600
those kinds of things that we can automatically extract figure out which one of these topics

427
00:43:29,600 --> 00:43:34,160
they're talking about and we automatically extract what the associated emotion seems to be I

428
00:43:34,160 --> 00:43:40,160
think we had about 18 different emotions like happy sad frustrated things of that sort that we

429
00:43:40,160 --> 00:43:46,000
can associate with these topics and so with these topics and associated emotions we then create

430
00:43:46,000 --> 00:43:51,040
this abstract visualization where there's a certain shape there is associated with the topic

431
00:43:51,040 --> 00:43:55,440
and there are certain colors that we were associated with these emotions and we have a variety

432
00:43:55,440 --> 00:44:01,440
of visualizations that we produce using these shapes and colors and again we run some evaluation

433
00:44:01,440 --> 00:44:06,560
to see whether people like the fact that the topic is described through a shape whether they like

434
00:44:06,560 --> 00:44:10,880
the fact that the emotion is shown through color do they like having visualizations do they

435
00:44:10,880 --> 00:44:16,240
think they would journal more regularly if their journaling app had this associated visualization

436
00:44:16,240 --> 00:44:21,600
and things like that and we saw a lot of in general positive responses to these things.

437
00:44:22,800 --> 00:44:33,920
Cool. Do you have kind of an overarching message for your workshop audience at the workshop?

438
00:44:33,920 --> 00:44:40,960
I don't know I think the overarching message would just be that I think this intersection of AI

439
00:44:40,960 --> 00:44:47,200
and creativity can be very powerful I think it can be very impactful and it can be a lot of fun to work

440
00:44:47,200 --> 00:44:55,280
on and so I think there's a lot of space for creative ideas no pun intended I guess in terms of what

441
00:44:55,280 --> 00:45:00,560
kinds of things we can look at here what human AI collaboration could look like and things of

442
00:45:00,560 --> 00:45:05,360
that sort I would just sort of encourage people to think about this more and see if they have ideas

443
00:45:05,360 --> 00:45:10,400
in this space and engage if they seem if they feel like they're interested. Awesome awesome well

444
00:45:10,400 --> 00:45:30,720
Davey thanks so much for taking the time to share with you. Thanks for having me this was fun. Thank you.

