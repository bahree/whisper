1
00:00:00,000 --> 00:00:13,400
Welcome to the Twimal AI Podcast.

2
00:00:13,400 --> 00:00:22,120
I'm your host Sam Charrington.

3
00:00:22,120 --> 00:00:24,080
Hey what's up everyone?

4
00:00:24,080 --> 00:00:26,620
Happy New Year and Happy New Decade.

5
00:00:26,620 --> 00:00:31,980
I am pumped to get 2020 kicked off by announcing a couple of new educational collaborations

6
00:00:31,980 --> 00:00:37,420
to add to our current array of Twimal community programs.

7
00:00:37,420 --> 00:00:39,580
The first of these starts next week.

8
00:00:39,580 --> 00:00:43,780
We are super excited to be collaborating with research scientist and instructor Robert

9
00:00:43,780 --> 00:00:50,620
Ness to bring his core sequence, causal modeling and machine learning to the Twimal community.

10
00:00:50,620 --> 00:00:55,460
Cosality has become a very hot topic in the ML&A eye space, but there are relatively few

11
00:00:55,460 --> 00:01:00,540
instructional resources geared towards data scientists and ML developers.

12
00:01:00,540 --> 00:01:04,780
Furthermore, this is the first time we'll have the opportunity to host a course instructor

13
00:01:04,780 --> 00:01:10,020
leading a study group on our platform so this group should be a ton of fun.

14
00:01:10,020 --> 00:01:14,740
The study group will meet at 8 a.m. U.S. Pacific time on Saturdays and to get things kicked

15
00:01:14,740 --> 00:01:22,380
off, Robert and I are hosting an overview session next Saturday, February 1st at that time.

16
00:01:22,380 --> 00:01:27,740
Know how topic in our community is ML&A eye platforms and more broadly, strategies for

17
00:01:27,740 --> 00:01:32,020
efficiently developing and deploying machine learning and deep learning models inside

18
00:01:32,020 --> 00:01:33,180
the enterprise.

19
00:01:33,180 --> 00:01:38,380
I've hinted at this next study group before and I'm mentioning it again now since we're

20
00:01:38,380 --> 00:01:39,380
getting close.

21
00:01:39,380 --> 00:01:45,220
I've partnered with IBM to bring the new IBM AI enterprise workflow specialization,

22
00:01:45,220 --> 00:01:51,060
a six course certificate granting sequence recently published on Coursera to you, our

23
00:01:51,060 --> 00:01:52,060
community.

24
00:01:52,060 --> 00:01:56,340
I'll personally be taking this course sequence and hosting a study group for those of you

25
00:01:56,340 --> 00:01:58,020
who'd like to join me.

26
00:01:58,020 --> 00:02:03,620
If you're doing interested in or would like to learn more about data science, ML or AI

27
00:02:03,620 --> 00:02:08,500
in a real world enterprise context, I'd encourage you to check this one out.

28
00:02:08,500 --> 00:02:12,820
I'll be hosting an informational session on the course in early February.

29
00:02:12,820 --> 00:02:18,820
For more information on or to join either of these programs, visit twimmelai.com slash

30
00:02:18,820 --> 00:02:20,940
learn 2020.

31
00:02:20,940 --> 00:02:22,860
And now on to the show.

32
00:02:22,860 --> 00:02:34,100
Hey everyone, I am here in Vancouver for NERPs continuing our conversations with some

33
00:02:34,100 --> 00:02:40,820
of the researchers that are at and participating in this amazing conference.

34
00:02:40,820 --> 00:02:43,500
And I've got the pleasure of being seated with Janis Bourne.

35
00:02:43,500 --> 00:02:50,100
Janis is a PhD student at ETH in Zurich and the IBM research in Zurich.

36
00:02:50,100 --> 00:02:52,780
Janis, welcome to the twimmelai podcast.

37
00:02:52,780 --> 00:02:54,780
Thank you so much Sam for having me.

38
00:02:54,780 --> 00:02:57,900
Why don't we start out by having you share a little bit about your background.

39
00:02:57,900 --> 00:03:03,300
You're coming at things from a cognitive science perspective, but your poster here is

40
00:03:03,300 --> 00:03:05,140
on reinforcement learning.

41
00:03:05,140 --> 00:03:09,620
How did you get interested in this field and how do all those threads come together?

42
00:03:09,620 --> 00:03:10,620
Right.

43
00:03:10,620 --> 00:03:11,620
Yes.

44
00:03:11,620 --> 00:03:12,620
So you're right.

45
00:03:12,620 --> 00:03:16,660
I'm having a background in cognitive science and in computation in your science.

46
00:03:16,660 --> 00:03:24,860
And so I've been like focusing on brain research for my past five years of education.

47
00:03:24,860 --> 00:03:32,540
And now recently I've been doing more work on computational systems biology and specifically

48
00:03:32,540 --> 00:03:38,260
on cancer and cancer trying to understand mechanisms of how cancer work and how we can

49
00:03:38,260 --> 00:03:41,180
find new treatments against cancer specifically.

50
00:03:41,180 --> 00:03:47,140
And in this work, I've been using mostly deep learning techniques and this will be part

51
00:03:47,140 --> 00:03:51,460
of like my presentation here at this conference also.

52
00:03:51,460 --> 00:03:54,660
And so yeah, so how do those things go together?

53
00:03:54,660 --> 00:04:00,420
So I think like many people think it's in a way weird if you come from brain sciences and

54
00:04:00,420 --> 00:04:03,900
then you're going to machine learning, right?

55
00:04:03,900 --> 00:04:07,660
And this is something where I would say it's like it's a very obvious thing to do in

56
00:04:07,660 --> 00:04:12,300
a way because if you look back into the history of machine learning, where it all came from,

57
00:04:12,300 --> 00:04:18,140
like mecaloch and pits, the first artificial neuron and then a few years later, Frank

58
00:04:18,140 --> 00:04:20,700
Rosen, Bella, the perceptron.

59
00:04:20,700 --> 00:04:26,460
And so these were all computational neuroscientists and they were in the end really trying to understand

60
00:04:26,460 --> 00:04:28,020
how the brain works.

61
00:04:28,020 --> 00:04:33,500
And they basically developed the the the fundament of the field of machine learning.

62
00:04:33,500 --> 00:04:38,420
And so at some point this community then in a way, it split up into two groups.

63
00:04:38,420 --> 00:04:43,340
And one group was more trying to actually understanding how the brain works.

64
00:04:43,340 --> 00:04:48,180
And the other group was more interested in solving the problems, right?

65
00:04:48,180 --> 00:04:53,340
And from this from this community, the machine learning community evolved into, but where

66
00:04:53,340 --> 00:04:57,580
is computation neuroscience right now, it's still a field, it's still out there.

67
00:04:57,580 --> 00:05:02,180
It's has been it's separating more and more from the machine learning community.

68
00:05:02,180 --> 00:05:06,580
I'm still out there and originally it has been one big community.

69
00:05:06,580 --> 00:05:10,980
And so therefore, I think it's quite natural to have this process.

70
00:05:10,980 --> 00:05:11,980
Yeah.

71
00:05:11,980 --> 00:05:18,500
Yeah, I think particularly here at NURBS, I have the opportunity to speak with many folks

72
00:05:18,500 --> 00:05:25,260
that are kind of working on that edge of cognitive sciences, brain sciences, and both using

73
00:05:25,260 --> 00:05:29,860
that to inform the way we think about machine learning, using machine learning to validate

74
00:05:29,860 --> 00:05:32,780
some of the biological theories.

75
00:05:32,780 --> 00:05:40,220
It was maybe more novel is coming from cognitive science and brain science and applying machine

76
00:05:40,220 --> 00:05:45,260
learning to developing cancer pharmaceuticals, how did that come about?

77
00:05:45,260 --> 00:05:46,260
Yeah.

78
00:05:46,260 --> 00:05:47,260
How did that come about?

79
00:05:47,260 --> 00:05:48,220
It's a good question.

80
00:05:48,220 --> 00:05:55,580
So like if you look at brain sciences, there's really this problem of seeing the brain,

81
00:05:55,580 --> 00:06:02,100
which is arguably the most complex thing we have in the universe, and seeing like observing

82
00:06:02,100 --> 00:06:08,100
this brain and trying to understand this brain from a different like scales, a different

83
00:06:08,100 --> 00:06:09,540
spatial scale, so to speak.

84
00:06:09,540 --> 00:06:14,940
So you can think about the brain in a very abstract and cognitive ways, thinking about

85
00:06:14,940 --> 00:06:18,500
cognitive phenomena like language and memory and those things.

86
00:06:18,500 --> 00:06:23,620
And you can think about it more from a neural perspective, like how do actually like what

87
00:06:23,620 --> 00:06:26,500
is the most fundamental unit of information processing?

88
00:06:26,500 --> 00:06:28,620
How do these units interact?

89
00:06:28,620 --> 00:06:30,660
How does information arise?

90
00:06:30,660 --> 00:06:34,420
And so like these are two fundamentally different approaches.

91
00:06:34,420 --> 00:06:38,660
And so I like in the first three years of my studies, I focused on cognitive science,

92
00:06:38,660 --> 00:06:42,980
which has more this top down approach, like thinking from the big concepts and then down

93
00:06:42,980 --> 00:06:45,060
towards the implementation level.

94
00:06:45,060 --> 00:06:49,860
Whereas computational neuroscience, they have more like this bottom up perspective.

95
00:06:49,860 --> 00:06:54,820
In the end, they're trying to solve the same problems, but they start first with the basic

96
00:06:54,820 --> 00:07:01,540
building blocks, like having a biologically plausible neural network model that imitates

97
00:07:01,540 --> 00:07:05,020
basic behavior of neurons and then they try to scale it up in order to understand more

98
00:07:05,020 --> 00:07:07,860
complex cognitive phenomena.

99
00:07:07,860 --> 00:07:12,740
And so like these two fields, they really, they help each other and they need to work

100
00:07:12,740 --> 00:07:15,500
together in order to understand how the brain works.

101
00:07:15,500 --> 00:07:20,980
And so after my undergrad studies, I really had the feeling, okay, I need something more

102
00:07:20,980 --> 00:07:22,060
solid.

103
00:07:22,060 --> 00:07:25,220
And I really wanted to have this bottom up perspective from a computer competition in

104
00:07:25,220 --> 00:07:29,260
your science, which then I got in my masters.

105
00:07:29,260 --> 00:07:35,580
And so afterwards, I mean, I had to say that I was keen to explore applications of machine

106
00:07:35,580 --> 00:07:40,620
learning, because while I mean while studying the brain, I got really interested more and

107
00:07:40,620 --> 00:07:45,380
more into the whole field of data science and machine learning, and I wanted to apply

108
00:07:45,380 --> 00:07:51,300
those techniques, but at the same time, I wanted to, I wanted to still somehow work with

109
00:07:51,300 --> 00:07:54,180
a human body and with humans in general.

110
00:07:54,180 --> 00:08:01,740
So this is how, yeah, how I came about doing cancer, cancer drug modeling.

111
00:08:01,740 --> 00:08:10,900
And so the, the poster is titled Pac-Man, yeah, tell us about Pac-Man, yeah.

112
00:08:10,900 --> 00:08:14,140
So Pac-Man is a frame, I mean, it's an acronym.

113
00:08:14,140 --> 00:08:18,820
So spelled with a double C and double N. So it's an acronym.

114
00:08:18,820 --> 00:08:25,020
We came up during my, like about a year ago, during my master thesis, for a prediction

115
00:08:25,020 --> 00:08:30,180
of anti-cancer compound sensitivity with multimodal attention-based neural networks.

116
00:08:30,180 --> 00:08:35,660
And so like when my supervisor came about with this acronym at one of the very long nights,

117
00:08:35,660 --> 00:08:38,540
we spent in the lab, we like, okay, there's no discussion.

118
00:08:38,540 --> 00:08:41,380
This is going to be the name for the project.

119
00:08:41,380 --> 00:08:45,220
So quite funny how, how this came about.

120
00:08:45,220 --> 00:08:51,540
So, and we, what we're doing in this work, that was the first step of, of the project

121
00:08:51,540 --> 00:08:59,300
I'm presenting here at the conference, we were trying to basically forecast the effect,

122
00:08:59,300 --> 00:09:05,340
the inhibitory effect of a molecule against a specific type of cancer.

123
00:09:05,340 --> 00:09:11,060
And so we are treating this problem of predicting cancer drug sensitivity really as the

124
00:09:11,060 --> 00:09:13,740
property of a pair.

125
00:09:13,740 --> 00:09:19,100
And the pair is like composed of the molecule itself, the chemical, the drug that you give

126
00:09:19,100 --> 00:09:20,420
to the patient.

127
00:09:20,420 --> 00:09:24,900
And then the particular tumor cell that you want to target.

128
00:09:24,900 --> 00:09:28,980
Because cancer is really like, I mean, it's a family of diseases.

129
00:09:28,980 --> 00:09:29,980
And it is so diverse.

130
00:09:29,980 --> 00:09:35,180
I mean, there has probably never been two types of cancer that have been exactly alike.

131
00:09:35,180 --> 00:09:42,100
Because the cascades of mutations you have, they vary like heavily in between of every

132
00:09:42,100 --> 00:09:43,540
individual patients.

133
00:09:43,540 --> 00:09:51,260
So it's really unfeasible to try to investigate whether a molecule has some anti-cancer effect

134
00:09:51,260 --> 00:09:52,340
in general.

135
00:09:52,340 --> 00:09:58,460
So you really need to treat this problem as the property of a pair.

136
00:09:58,460 --> 00:10:05,300
So is this drug like has it inhibitory effect against the specific type of cancer in the

137
00:10:05,300 --> 00:10:07,620
patient individually?

138
00:10:07,620 --> 00:10:11,620
One of the questions that comes up first for me is one of the techniques you're applying

139
00:10:11,620 --> 00:10:13,140
here is reinforcement learning.

140
00:10:13,140 --> 00:10:17,700
How does that play into achieving that goal?

141
00:10:17,700 --> 00:10:19,460
So it comes about in the second step.

142
00:10:19,460 --> 00:10:25,220
So the first step was really just trying to predict the sensitivity.

143
00:10:25,220 --> 00:10:28,540
So the efficacy of this of a drug.

144
00:10:28,540 --> 00:10:37,060
And so what we did in a consecutive step after we had built this model, what we asked ourselves

145
00:10:37,060 --> 00:10:42,500
was like, wow, wouldn't it be amazing to have a model that can generate new drugs?

146
00:10:42,500 --> 00:10:46,940
And that can come up and propose new anti-cancer candidate drugs.

147
00:10:46,940 --> 00:10:51,980
Because in the whole pharmaceutical industry, there's a huge productivity decline in the

148
00:10:51,980 --> 00:10:59,380
last few decades and the estimated costs that you have per new drug, they're estimated to

149
00:10:59,380 --> 00:11:01,500
be 2 to 3 billion USD.

150
00:11:01,500 --> 00:11:05,820
And most of these drugs that are then FDA approved and approved on the market, so they're

151
00:11:05,820 --> 00:11:12,380
really specific only for very few types of diseases or even one disease only.

152
00:11:12,380 --> 00:11:20,460
So the cost in R&D that go our, like, spend in this business, it's just huge.

153
00:11:20,460 --> 00:11:26,300
And so we, I mean, we came up with this framework where reinforcement learning is really

154
00:11:26,300 --> 00:11:33,140
core and component, where we're trying to design anti-cancer drugs specifically for individual

155
00:11:33,140 --> 00:11:35,380
patients or groups of patients.

156
00:11:35,380 --> 00:11:42,340
So we're trying to envision a precision medicine perspective here, where we're not trying

157
00:11:42,340 --> 00:11:46,540
to generically come up with new anti-cancer candidate drugs.

158
00:11:46,540 --> 00:11:53,740
But we try to, like, in the design process itself, we try to tailor the molecule, the

159
00:11:53,740 --> 00:11:58,340
drug specifically, to the need of the patient himself or herself.

160
00:11:58,340 --> 00:12:02,420
And so for this framework, we use a reinforcement learning machine.

161
00:12:02,420 --> 00:12:03,420
Okay.

162
00:12:03,420 --> 00:12:08,900
You also mentioned in the title of the poster transcriptomic data.

163
00:12:08,900 --> 00:12:10,460
What is transcriptomic data?

164
00:12:10,460 --> 00:12:11,460
Right.

165
00:12:11,460 --> 00:12:17,780
So you can think about transcriptomic data as basically the expression of every single

166
00:12:17,780 --> 00:12:21,820
gene that you have in your body, like you know about the human genome.

167
00:12:21,820 --> 00:12:26,500
And so part of the human genome encode for specific proteins.

168
00:12:26,500 --> 00:12:30,020
And these expression of these proteins, you can measure in the cell, there's different

169
00:12:30,020 --> 00:12:31,500
techniques to do that.

170
00:12:31,500 --> 00:12:38,020
So the most commonly used technique and the technique that was used to measure the data

171
00:12:38,020 --> 00:12:44,340
we work with is called RNA sequencing data, where you measure basically the mRNA snippets

172
00:12:44,340 --> 00:12:45,540
in the cell.

173
00:12:45,540 --> 00:12:50,140
And so from this, you can infer basically which genes were expressed to what extent.

174
00:12:50,140 --> 00:12:56,300
So you end up, if you do the sequencing step, you end up with a vector of about 20,000

175
00:12:56,300 --> 00:12:57,980
genes.

176
00:12:57,980 --> 00:13:00,420
And for each gene, you would have an expression value.

177
00:13:00,420 --> 00:13:07,060
This is usually just an integer, like how many times did you find this as the snippet

178
00:13:07,060 --> 00:13:08,060
in the sample?

179
00:13:08,060 --> 00:13:13,460
And then so this vector, you can really think of it as a fingerprint of the cell.

180
00:13:13,460 --> 00:13:17,180
So it's a proper characterization of the cell.

181
00:13:17,180 --> 00:13:21,220
There's a different types of omics data.

182
00:13:21,220 --> 00:13:23,660
So this is transcriptomic data, right?

183
00:13:23,660 --> 00:13:29,820
There's also genomics data, which directly measuring gene data.

184
00:13:29,820 --> 00:13:35,940
And there's also a proteomics data where you actively measuring the proteins.

185
00:13:35,940 --> 00:13:42,700
So the, you know, starting from that first step, you're kind of starting with trying to

186
00:13:42,700 --> 00:13:46,940
predict the effect of a drug on the cell.

187
00:13:46,940 --> 00:13:53,180
Is it, is this a supervised learning type of a problem that you, is that the way you've

188
00:13:53,180 --> 00:13:54,180
framed it?

189
00:13:54,180 --> 00:13:55,180
Yes, yes.

190
00:13:55,180 --> 00:13:56,180
This is supervised learning.

191
00:13:56,180 --> 00:13:59,140
So it's a regression problem in the end.

192
00:13:59,140 --> 00:14:04,020
It's quite simple in the fact that we're really trying to predict a single property.

193
00:14:04,020 --> 00:14:06,180
And this is the IC50 value.

194
00:14:06,180 --> 00:14:12,260
So this is the micro molar concentration of a drug that you need in order to kill 50%

195
00:14:12,260 --> 00:14:13,460
of the cells.

196
00:14:13,460 --> 00:14:18,180
So, and this is the thing you're trying to minimize.

197
00:14:18,180 --> 00:14:23,300
So if you have a smaller concentration of the drug, then this drug is more effective,

198
00:14:23,300 --> 00:14:24,300
right?

199
00:14:24,300 --> 00:14:32,100
So your training data comes from measurements that have been done applying drug, you know,

200
00:14:32,100 --> 00:14:34,500
different types of drugs to different types of cells.

201
00:14:34,500 --> 00:14:35,500
Exactly.

202
00:14:35,500 --> 00:14:39,700
So there's huge databases for, for this problem.

203
00:14:39,700 --> 00:14:44,980
So the two we are working with are GDSC and CCLE.

204
00:14:44,980 --> 00:14:49,380
There's a standard database in the field and they, they usually don't work with patients

205
00:14:49,380 --> 00:14:54,940
directly because you can't try like several hundred drugs on, on the same patient, right?

206
00:14:54,940 --> 00:14:57,980
But they work with them, so called cancer cell lines.

207
00:14:57,980 --> 00:14:59,740
So these are abstractions.

208
00:14:59,740 --> 00:15:03,700
These are cell lines that have been growing in the lab in petri dishes for quite some

209
00:15:03,700 --> 00:15:04,700
time.

210
00:15:04,700 --> 00:15:08,260
And you apply these drugs, I mean, to, to these cancer cell lines.

211
00:15:08,260 --> 00:15:11,900
So these cells have been taken originally at some point from humans, but they have been

212
00:15:11,900 --> 00:15:14,100
growing in the lab for a long time.

213
00:15:14,100 --> 00:15:16,860
And they have been mutations induced downstream.

214
00:15:16,860 --> 00:15:23,620
So they are proxies of real cancer, but it's, I mean, it's an active field of research

215
00:15:23,620 --> 00:15:29,060
to whether or not on to what extent they have problem proxies.

216
00:15:29,060 --> 00:15:35,700
And so in the creation of this data set, somebody carefully administered small quantities of

217
00:15:35,700 --> 00:15:40,900
these drugs and noted the point at which half of the cells were, or just over half of

218
00:15:40,900 --> 00:15:46,500
the cells have died off, and that's the proxy for the efficacy of the drug.

219
00:15:46,500 --> 00:15:47,500
Absolutely, right?

220
00:15:47,500 --> 00:15:48,500
Okay.

221
00:15:48,500 --> 00:15:57,260
And so you, you built a model to predict the performance of new, new arbitrary drugs.

222
00:15:57,260 --> 00:16:00,820
And how do you kind of featureize the drugs?

223
00:16:00,820 --> 00:16:01,820
Right.

224
00:16:01,820 --> 00:16:05,420
So that's a good, it's a good question, because in the end, the drug is immolical, so this

225
00:16:05,420 --> 00:16:13,300
is a graph and graphs are rather difficult to represent in a deep learning regime.

226
00:16:13,300 --> 00:16:21,460
So what traditionally has been done by chemoinformaticians about a few decades ago is they would derive molecular

227
00:16:21,460 --> 00:16:22,460
fingerprints.

228
00:16:22,460 --> 00:16:29,260
These are binary vectors, and in these binary vectors, every item would basically specify

229
00:16:29,260 --> 00:16:31,380
the presence of a certain feature.

230
00:16:31,380 --> 00:16:33,100
And this was completely handcrafted.

231
00:16:33,100 --> 00:16:39,260
So one feature could be like, do I have ax aromatic rings in this molecule or not something

232
00:16:39,260 --> 00:16:40,260
in this?

233
00:16:40,260 --> 00:16:44,260
So, but this is a very arbitrary and handcrafted representation of a molecule.

234
00:16:44,260 --> 00:16:47,260
And the field of deep learning has been moving forward.

235
00:16:47,260 --> 00:16:54,380
So what, I mean, one great thing that deep learning really brought to us is like advances

236
00:16:54,380 --> 00:16:56,860
in natural language processing, right?

237
00:16:56,860 --> 00:17:02,060
So, and a different representation of a molecule can just be a text representation.

238
00:17:02,060 --> 00:17:07,460
So there's certain languages that most commonly use languages called smiles, and smiles

239
00:17:07,460 --> 00:17:13,540
as an in-line notation of molecule, of molecules where you would basically write down and list

240
00:17:13,540 --> 00:17:14,940
of atoms and bonds.

241
00:17:14,940 --> 00:17:20,620
So you basically, you think about the molecule as a graph, and then you do it traverse through

242
00:17:20,620 --> 00:17:24,740
the graph, and you denote step by step the atoms and bonds.

243
00:17:24,740 --> 00:17:30,260
Kind of like a much more rigorous approach to saying H2O for water.

244
00:17:30,260 --> 00:17:31,260
Yes, absolutely.

245
00:17:31,260 --> 00:17:32,260
Okay.

246
00:17:32,260 --> 00:17:34,460
And this is the type of representation we're working with at the moment.

247
00:17:34,460 --> 00:17:35,460
Oh, interesting.

248
00:17:35,460 --> 00:17:42,180
So you've totally skipped the accepted formalism and are primarily working with this natural

249
00:17:42,180 --> 00:17:43,940
language approach.

250
00:17:43,940 --> 00:17:49,700
What's the thinking behind that is that is it that the natural language has more expressiveness

251
00:17:49,700 --> 00:17:55,140
somehow than the binary representation, or is it something else?

252
00:17:55,140 --> 00:18:01,620
So I mean, one thing that's great is that it is much more like it is closer to the actual

253
00:18:01,620 --> 00:18:03,380
representation of the molecule.

254
00:18:03,380 --> 00:18:05,780
It is much easier to understand for any chemist.

255
00:18:05,780 --> 00:18:11,420
Any chemist can look at the smiles notation and can understand the molecule, can draw the

256
00:18:11,420 --> 00:18:14,940
molecule where this does not hold for a fingerprint.

257
00:18:14,940 --> 00:18:19,660
Another advantage of smiles is that it enables data augmentation.

258
00:18:19,660 --> 00:18:24,460
So data augmentation is commonly used everywhere in deep learning, like images, you make rotations

259
00:18:24,460 --> 00:18:26,700
or whatever.

260
00:18:26,700 --> 00:18:31,580
So what you can do is, apparently, if you think of a molecule as a graph, there's not

261
00:18:31,580 --> 00:18:33,340
a single graph traverse, right?

262
00:18:33,340 --> 00:18:34,860
But you can start at different points.

263
00:18:34,860 --> 00:18:35,860
Start at different points.

264
00:18:35,860 --> 00:18:36,860
Exactly.

265
00:18:36,860 --> 00:18:41,300
And then you would get a completely different, not completely different, the atoms and

266
00:18:41,300 --> 00:18:44,740
bonds would be the same, but the ordering would be different and you would get a different

267
00:18:44,740 --> 00:18:45,740
text representation.

268
00:18:45,740 --> 00:18:46,740
Right?

269
00:18:46,740 --> 00:18:50,420
Whereas on the fingerprint, theoretically, they should all resolve to the same fingerprint.

270
00:18:50,420 --> 00:18:51,420
Absolutely.

271
00:18:51,420 --> 00:18:52,420
They do.

272
00:18:52,420 --> 00:18:53,420
They all resolve to the same.

273
00:18:53,420 --> 00:18:57,700
So you have a unique representation for the molecule, in the case of a fingerprint, whereas

274
00:18:57,700 --> 00:19:06,540
in case of a smiles, you can really exploit this smiles augmentation, basically, by exploring

275
00:19:06,540 --> 00:19:11,580
different graph traverse in order to augment the performance of you.

276
00:19:11,580 --> 00:19:12,580
Better generalize.

277
00:19:12,580 --> 00:19:15,700
Yes, it would generalize much better.

278
00:19:15,700 --> 00:19:21,580
And so the advantage of working with text really is also that you can more or less directly

279
00:19:21,580 --> 00:19:29,100
transfer all of the advances of natural language processing, like attention-based models, which

280
00:19:29,100 --> 00:19:33,060
by the way, are absolutely great because they leverage interpretability methods.

281
00:19:33,060 --> 00:19:40,140
So attention, this super commonly used technique in NLP, right, where the model really highlights

282
00:19:40,140 --> 00:19:46,500
only specific parts of the input sequence in order to produce the next output token.

283
00:19:46,500 --> 00:19:51,180
For example, a language translation task, right, or in order to produce a prediction.

284
00:19:51,180 --> 00:19:54,820
And so we can also leverage these techniques into our model.

285
00:19:54,820 --> 00:20:02,100
And this is great because you can understand the reasoning of the model post-talk, basically.

286
00:20:02,100 --> 00:20:08,900
So what we can do with this model is we can understand that the model came to a specific

287
00:20:08,900 --> 00:20:14,380
prediction because it was focusing on a specific substructure of the molecule, right.

288
00:20:14,380 --> 00:20:18,620
And then we can check in the literature, this like a known substructures, it known to have

289
00:20:18,620 --> 00:20:20,820
certain chemical properties.

290
00:20:20,820 --> 00:20:23,900
And in this way, we can validate the performance of the model.

291
00:20:23,900 --> 00:20:24,900
Okay.

292
00:20:24,900 --> 00:20:31,060
Now, others doing similar types of applications have taken, you know, whatever their input

293
00:20:31,060 --> 00:20:38,060
domain is and kind of projected it to like an embedding space and finding related molecules

294
00:20:38,060 --> 00:20:43,940
in that embedding space and then using that to identify candidate, you know, materials,

295
00:20:43,940 --> 00:20:46,420
I think is the example that I'm thinking of.

296
00:20:46,420 --> 00:20:48,500
Is that something that you've looked at as well?

297
00:20:48,500 --> 00:20:49,500
Yes.

298
00:20:49,500 --> 00:20:54,860
So this comes about in the in the drug generation part, which is the second part of the project

299
00:20:54,860 --> 00:20:58,780
that we're trying to design new cancer drugs.

300
00:20:58,780 --> 00:21:04,540
And so what we're doing there is we use a deep generative model, specifically variational

301
00:21:04,540 --> 00:21:06,260
auto encoders.

302
00:21:06,260 --> 00:21:12,820
And what is really awesome, if you're working with variational auto encoders is this property

303
00:21:12,820 --> 00:21:19,940
of the latent space and the fact that like similarity in this latent space, which is

304
00:21:19,940 --> 00:21:26,540
in a way the embedding that you generate for a specific input in our case, a molecule,

305
00:21:26,540 --> 00:21:36,340
that similarity in this in this in this latent space will correspond to a structural similarity

306
00:21:36,340 --> 00:21:40,580
of the molecule, if you decode the points in the latent space.

307
00:21:40,580 --> 00:21:45,060
So this is like the drug molecule in this case, yes, yes.

308
00:21:45,060 --> 00:21:47,620
So I mean, it seems like a supernatural property, right?

309
00:21:47,620 --> 00:21:51,700
You would expect this that similarity in this latent space, although it is hidden somewhere

310
00:21:51,700 --> 00:21:54,380
in the network, it will resemble something meaningful.

311
00:21:54,380 --> 00:21:56,740
But apparently this is not necessarily the case.

312
00:21:56,740 --> 00:22:01,300
So you have to specifically enforce this with a specific constraints that you have to apply

313
00:22:01,300 --> 00:22:05,500
during training this model, but they, and this is like the core property of variational

314
00:22:05,500 --> 00:22:08,660
auto encoders, but this doesn't come along naturally, basically.

315
00:22:08,660 --> 00:22:09,660
It's not for free.

316
00:22:09,660 --> 00:22:14,340
You have to figure out what the relationship is between two drugs that causes them to

317
00:22:14,340 --> 00:22:19,500
have a similar effect on the target molecule, yes, in a way, or the target cell.

318
00:22:19,500 --> 00:22:20,500
Yeah.

319
00:22:20,500 --> 00:22:26,260
So I mean, what you can do, and this would be a pure chemistry model, this doesn't necessarily

320
00:22:26,260 --> 00:22:30,260
need to have anything to do with cancer or with drugs.

321
00:22:30,260 --> 00:22:34,340
It can be the same way for materials, like all kinds of chemicals, basically.

322
00:22:34,340 --> 00:22:39,260
So what you can do, for example, is you have a certain point in the latent space, you decode

323
00:22:39,260 --> 00:22:40,260
a molecule from it.

324
00:22:40,260 --> 00:22:42,300
It is some kind of molecule.

325
00:22:42,300 --> 00:22:43,820
Let's say it's aspirinous, right?

326
00:22:43,820 --> 00:22:44,820
It could be.

327
00:22:44,820 --> 00:22:48,660
So and then you take a different point and you decode from there, and let's say you take

328
00:22:48,660 --> 00:22:50,660
it, you get paracetamol, right?

329
00:22:50,660 --> 00:22:55,300
And then what you can do is you can in the latent space, you can traverse, you can basically

330
00:22:55,300 --> 00:23:02,740
make a walk, like a walk from this point of paracetamol to the point of aspirin.

331
00:23:02,740 --> 00:23:09,100
And you can decode intermediate positions, and you will end up with molecules that are

332
00:23:09,100 --> 00:23:15,620
in a way intermediate mixtures in between of aspirin and paracetamol.

333
00:23:15,620 --> 00:23:22,740
So and this is a super nice property for everybody working in drug discovery, because you can

334
00:23:22,740 --> 00:23:26,500
much better explore the chemical space.

335
00:23:26,500 --> 00:23:30,540
And so this is something that, I mean, it's not obvious, but it is extremely important

336
00:23:30,540 --> 00:23:34,900
to have better models and techniques to explore the chemical space.

337
00:23:34,900 --> 00:23:38,900
The size of the chemical space, it is about 10 to the, it's estimated to be around 10

338
00:23:38,900 --> 00:23:40,740
to the 60 molecules.

339
00:23:40,740 --> 00:23:42,300
So this is massive.

340
00:23:42,300 --> 00:23:45,860
The amount of atoms in the universe, I'm not sure it's like a few orders of magnitude

341
00:23:45,860 --> 00:23:47,660
higher, but it's not crazy.

342
00:23:47,660 --> 00:23:52,180
I don't, I think it's below 10 to the 100, I'm not, I would need to look it up.

343
00:23:52,180 --> 00:23:59,420
But so, and you need to have techniques to navigate this space meanfully, specifically

344
00:23:59,420 --> 00:24:07,700
at a time where, where we have generated and synthesized already so many compounds,

345
00:24:07,700 --> 00:24:11,700
like I think it's in the order of 10 to the nine or 10 to the 10 that have ever been

346
00:24:11,700 --> 00:24:18,700
synthesized and tested, but it is completely unfeasible to just continue like a random sampling

347
00:24:18,700 --> 00:24:19,700
process.

348
00:24:19,700 --> 00:24:20,700
Right.

349
00:24:20,700 --> 00:24:26,260
And therefore, you really need to have this guided, guided sampling and guided navigation.

350
00:24:26,260 --> 00:24:34,540
Kind of going back to that phase two of your project, you are applying, you mentioned

351
00:24:34,540 --> 00:24:41,060
a generational or a generative rather model as kind of an intro to where the reinforcement

352
00:24:41,060 --> 00:24:42,060
learning comes in.

353
00:24:42,060 --> 00:24:43,460
What's the connection between those two?

354
00:24:43,460 --> 00:24:44,460
Yeah, absolutely.

355
00:24:44,460 --> 00:24:49,140
So, this is the part of the project where I'm really most excited about, is about generating

356
00:24:49,140 --> 00:24:51,340
new drugs.

357
00:24:51,340 --> 00:24:56,140
And so not so much the old prediction model that I've been talking about before.

358
00:24:56,140 --> 00:25:02,780
So what we're really trying to do there is that given the transcriptomics profile of

359
00:25:02,780 --> 00:25:07,260
cancer patients, so this kind of theory work in the following way, that you have a medical

360
00:25:07,260 --> 00:25:14,700
doctor making a biopsy from a tumor cell, this biopsy is then sequenced.

361
00:25:14,700 --> 00:25:17,620
You get the gene expression, this is the transcriptomics data.

362
00:25:17,620 --> 00:25:19,500
You put it into the model.

363
00:25:19,500 --> 00:25:25,820
You have a variational autoencoder for this cell profile, so only for the transcriptomics

364
00:25:25,820 --> 00:25:26,820
data.

365
00:25:26,820 --> 00:25:33,620
You encode this transcriptomics data into some latent representation.

366
00:25:33,620 --> 00:25:40,580
And they are in this latent space, you fuse together the chemical, like another variational

367
00:25:40,580 --> 00:25:41,580
autoencoder.

368
00:25:41,580 --> 00:25:44,100
So it's really like a combination of two variational autoencoders.

369
00:25:44,100 --> 00:25:46,820
One is for chemistry, it's just for pure chemistry and molecules.

370
00:25:46,820 --> 00:25:52,420
And the other one is for cell profiles, specifically cancer cell profiles in transcriptomics

371
00:25:52,420 --> 00:25:53,420
data.

372
00:25:53,420 --> 00:25:57,460
You fuse together the latent embeddings of these two models.

373
00:25:57,460 --> 00:26:01,220
And then you decode from there a molecule.

374
00:26:01,220 --> 00:26:06,580
And how you can use this model is really by, you can feed it, a cancer cell profile from

375
00:26:06,580 --> 00:26:11,100
a patient, and it will propose you an anti-cancer drug.

376
00:26:11,100 --> 00:26:16,820
So originally, like in the first place, this will be like a random molecule, but now the

377
00:26:16,820 --> 00:26:21,660
reinforcement learning comes into play, what we can do with this molecule is we can plug

378
00:26:21,660 --> 00:26:25,220
it into the prediction model that we developed in the first step, right?

379
00:26:25,220 --> 00:26:30,420
So in the first step, I said we have this prediction model that takes as two inputs, namely

380
00:26:30,420 --> 00:26:35,220
a molecule, and a cancer cell profile, and it tries to predict the efficacy of a drug,

381
00:26:35,220 --> 00:26:36,220
right?

382
00:26:36,220 --> 00:26:39,780
So it's kind of providing our scoring function for the RL learner.

383
00:26:39,780 --> 00:26:40,780
Absolutely, absolutely.

384
00:26:40,780 --> 00:26:41,780
Okay.

385
00:26:41,780 --> 00:26:45,660
So we use this prediction model to get a reward, and then this reward is used in turn in

386
00:26:45,660 --> 00:26:47,580
order to update the generator.

387
00:26:47,580 --> 00:26:52,020
And then we have a closed loop system, which we can train with a policy gradient and reinforcement

388
00:26:52,020 --> 00:26:53,020
learning techniques.

389
00:26:53,020 --> 00:27:00,020
And then on the long run, we can, and this we've shown quite, quite consistently, we can

390
00:27:00,020 --> 00:27:05,500
like propose molecules that have an higher predicted efficacy, according to our prediction

391
00:27:05,500 --> 00:27:06,500
model.

392
00:27:06,500 --> 00:27:12,220
The two various auto encoders, are those trained independently, or are they trained in

393
00:27:12,220 --> 00:27:13,220
the end somehow?

394
00:27:13,220 --> 00:27:14,220
Yeah.

395
00:27:14,220 --> 00:27:18,060
So they are initially pre-trained completely independently, so you can really thinking

396
00:27:18,060 --> 00:27:24,260
about these auto encoders as learning completely disentangled representation.

397
00:27:24,260 --> 00:27:31,100
So one is really for molecules, just to understand like this smiles language notation, to understand

398
00:27:31,100 --> 00:27:33,860
how chemistry works in a way.

399
00:27:33,860 --> 00:27:40,140
And so the other auto encoder for the transcriptomics data, you can, yeah, so this is just trying

400
00:27:40,140 --> 00:27:44,700
to approximate and learn the space of possible cancer cells, so to speak.

401
00:27:44,700 --> 00:27:48,860
So these are pre-trained independently, and then what we do is really, we, we, like we

402
00:27:48,860 --> 00:27:54,660
think is that second one is it, it's, yeah, so it's creating the representation of the

403
00:27:54,660 --> 00:28:01,460
cancer cells, and then the, there's a decoder step that's taking these two and coming up

404
00:28:01,460 --> 00:28:04,860
with a prediction of the, of a, of a drug molecule.

405
00:28:04,860 --> 00:28:05,860
Yes.

406
00:28:05,860 --> 00:28:13,460
So there's decoder that basically combines the two latent representation of the cell profile

407
00:28:13,460 --> 00:28:19,100
of interest and a drug, and then comes up with a new cancer drug.

408
00:28:19,100 --> 00:28:20,700
So how is this one trained?

409
00:28:20,700 --> 00:28:23,380
So this is trained jointly in this reinforcement learning.

410
00:28:23,380 --> 00:28:24,380
Okay.

411
00:28:24,380 --> 00:28:27,220
So it's part of that reinforcement learning circle, got it?

412
00:28:27,220 --> 00:28:28,220
Yeah.

413
00:28:28,220 --> 00:28:29,220
Absolutely.

414
00:28:29,220 --> 00:28:33,900
So what's important to note here is that it's highly non-trivial, how you combine these

415
00:28:33,900 --> 00:28:40,340
different data modalities, because it, it, it seems extremely arbitrary in a way to,

416
00:28:40,340 --> 00:28:45,100
to fuse latent representations of a molecule with the latent representation of a cancer

417
00:28:45,100 --> 00:28:46,180
cell profile.

418
00:28:46,180 --> 00:28:52,220
What we're doing there, it is, I mean, in a way, it is just the first thing that came to

419
00:28:52,220 --> 00:28:56,140
our mind is we're summing up the latent representations.

420
00:28:56,140 --> 00:29:02,100
But because we're doing this consistently, while we're being in this reinforcement learning

421
00:29:02,100 --> 00:29:10,540
regime, we, we think that we can basically warp this latent space representation from

422
00:29:10,540 --> 00:29:14,140
originally, according structural similarity between molecules, right?

423
00:29:14,140 --> 00:29:19,380
I was talking before in between, like, about morphing aspirin into paracetamol, right?

424
00:29:19,380 --> 00:29:26,140
So we can, like, morph this latent space into encoding functional similarity.

425
00:29:26,140 --> 00:29:29,940
And functional, by functional similarity, I mean different functional pro, like similar

426
00:29:29,940 --> 00:29:32,020
functional properties of the molecule.

427
00:29:32,020 --> 00:29:36,460
So that you have a certain subset of the space, and in this subset of the space, you will

428
00:29:36,460 --> 00:29:43,620
find molecules more frequently that have high predicted anti-cancer effects, basically,

429
00:29:43,620 --> 00:29:45,300
according to our prediction model.

430
00:29:45,300 --> 00:29:54,620
Do you or, have you come across research that looks into the algebraic combinations of

431
00:29:54,620 --> 00:30:00,660
latent spaces and, and how that, you know, what, the, how, what the right intuition is there?

432
00:30:00,660 --> 00:30:03,060
People, you know, how, how much has that been studied?

433
00:30:03,060 --> 00:30:04,060
Have you come across stuff?

434
00:30:04,060 --> 00:30:09,660
I mean, to the best of my knowledge is something that is not very, very actively studied.

435
00:30:09,660 --> 00:30:15,380
So there is a paper from, actually, from Europe's from two years ago called deep sets.

436
00:30:15,380 --> 00:30:20,340
And they are talking about how, how to, how to deal with sets data.

437
00:30:20,340 --> 00:30:25,060
And what they're proposing is, I mean, it's important because this is my second conversation

438
00:30:25,060 --> 00:30:28,780
today where someone said, oh, we just sum up these two latent spaces, and that's what

439
00:30:28,780 --> 00:30:29,780
we use to.

440
00:30:29,780 --> 00:30:34,540
I mean, I was, yes, actually, I was today at a poster session, and I talked to somebody

441
00:30:34,540 --> 00:30:36,860
who was doing exactly the same thing.

442
00:30:36,860 --> 00:30:42,060
And like, I mean, I told them, honestly, this is kind of an arbitrary choice.

443
00:30:42,060 --> 00:30:43,820
I'm doing the very same thing in my work.

444
00:30:43,820 --> 00:30:44,820
I'm just interested.

445
00:30:44,820 --> 00:30:48,940
I do have a better justification for it than I do, right?

446
00:30:48,940 --> 00:30:55,420
So, so, I mean, in a way, what they proposed on this deep sets paper from two years ago,

447
00:30:55,420 --> 00:30:59,260
where they're talking about how to deal with sets and in a deep learning framework is

448
00:30:59,260 --> 00:31:04,300
that you need to have a permutation in variant operation in order to combine sets, because

449
00:31:04,300 --> 00:31:08,300
the thing is with sets, for me, that was the justification that was given to me in the

450
00:31:08,300 --> 00:31:09,300
previous conversation.

451
00:31:09,300 --> 00:31:10,300
Right.

452
00:31:10,300 --> 00:31:16,100
So, it kind of eliminates the role of order in, yeah, the order doesn't play a role.

453
00:31:16,100 --> 00:31:17,100
Right.

454
00:31:17,100 --> 00:31:19,580
So, this holds for many operations, right?

455
00:31:19,580 --> 00:31:24,660
It like, it holds for the, for an averaging for some, for many others.

456
00:31:24,660 --> 00:31:30,500
But so, like, the sum is something that we came up with, and it is an obvious choice.

457
00:31:30,500 --> 00:31:36,300
But, to be honest, I, to me, in a way, it still feels like we're mixing apples and oranges

458
00:31:36,300 --> 00:31:40,580
in bit, and I'm not super satisfied with how we're solving this part of the framework.

459
00:31:40,580 --> 00:31:42,620
Also, losing information in the process.

460
00:31:42,620 --> 00:31:47,020
Just like if you were to do an average, there's, you know, unique information that you're,

461
00:31:47,020 --> 00:31:48,980
that you're just kind of throwing away.

462
00:31:48,980 --> 00:31:49,980
Yeah.

463
00:31:49,980 --> 00:31:54,300
There's information being lost, and there's a, actually, there's a paper also, like, I

464
00:31:54,300 --> 00:31:59,380
saw another paper where they've been at this conference just yesterday, where they've been

465
00:31:59,380 --> 00:32:05,220
looking into different ways of combining latent spaces, and so they, they proposed, I

466
00:32:05,220 --> 00:32:06,620
think, three ways.

467
00:32:06,620 --> 00:32:11,020
One was just like a uniform sampling, so you would basically have a mixture of both.

468
00:32:11,020 --> 00:32:15,420
So you would sample, like, from a uniform distribution between zero and one, and then

469
00:32:15,420 --> 00:32:20,180
you would say, okay, I wait the one representation with 80% the other one with 20, and so I just

470
00:32:20,180 --> 00:32:22,100
have a weighted average, basically.

471
00:32:22,100 --> 00:32:28,020
So another thing they proposed was a Bernoulli distribution, where you would basically pick,

472
00:32:28,020 --> 00:32:33,260
like, the latent representation is it's an embedding of a certain amount of dimension,

473
00:32:33,260 --> 00:32:34,260
right?

474
00:32:34,260 --> 00:32:37,860
It's a vector of a certain length, and then you can say for every dimension, you pick

475
00:32:37,860 --> 00:32:41,740
either one or the other, and you do this important distribution, and then you have a mixed

476
00:32:41,740 --> 00:32:43,060
representation.

477
00:32:43,060 --> 00:32:47,580
Or the third thing they were suggesting is like a learned embedding, basically, where

478
00:32:47,580 --> 00:32:54,620
you have a specific, like, a few deep, a few dense layers of a neural net to learn this

479
00:32:54,620 --> 00:32:55,620
embedding.

480
00:32:55,620 --> 00:33:01,260
So, but still all of these, they didn't seem specifically instructive to me, but rather,

481
00:33:01,260 --> 00:33:04,820
like, okay, you can do it this way or this way, and we can check what works best, and we

482
00:33:04,820 --> 00:33:09,620
see empirically this works best, but it wasn't super, yeah, they didn't provide a, like,

483
00:33:09,620 --> 00:33:11,100
a great justification for it.

484
00:33:11,100 --> 00:33:17,020
But still, I'm curious and to try it out, and this, I will definitely try it out.

485
00:33:17,020 --> 00:33:24,300
Very particularly interesting observations in training the DRL learner to solve this

486
00:33:24,300 --> 00:33:30,260
problem, is it kind of similar, you know, to other use cases, or were there specific things

487
00:33:30,260 --> 00:33:32,940
that you had to do here to get it to converge?

488
00:33:32,940 --> 00:33:39,740
So, it's an actor and critique framework, so to speak, where you have the actor is this

489
00:33:39,740 --> 00:33:44,300
conditional drug generator that comes up with a new compound, and the critique is the

490
00:33:44,300 --> 00:33:47,300
separately pre-trained, this prediction thing.

491
00:33:47,300 --> 00:33:48,620
Running it through this prediction thing.

492
00:33:48,620 --> 00:33:49,620
Exactly.

493
00:33:49,620 --> 00:33:52,980
So, and you can assess other properties of the molecules as well, right?

494
00:33:52,980 --> 00:33:58,980
So, because this, like, predicted property, this ICFIT, it's not the only property qualifying

495
00:33:58,980 --> 00:34:03,260
or disqualifying a molecule for being a drug, so there's also other things, like, water

496
00:34:03,260 --> 00:34:06,100
solubility is something that's extremely important, or...

497
00:34:06,100 --> 00:34:07,100
Will it kill you?

498
00:34:07,100 --> 00:34:08,100
Yeah, yeah.

499
00:34:08,100 --> 00:34:14,260
Or, like, cytotoxicity is a common thing that just, like, you have a drug that is generally

500
00:34:14,260 --> 00:34:19,060
so psychotoxicity will just kill everything, right, and then it doesn't have either, right?

501
00:34:19,060 --> 00:34:24,420
So, and there's many of those things that you really need to incorporate, and then this

502
00:34:24,420 --> 00:34:29,260
reward function for the generator can become very complex, right, because you need to trade

503
00:34:29,260 --> 00:34:35,220
off what is more important, do I wait solubility higher than, like, at, uh, cytotoxicity, or

504
00:34:35,220 --> 00:34:39,820
how about, like, uh, synthesize ability of the molecule, some structures are just extremely

505
00:34:39,820 --> 00:34:44,060
difficult to synthesize, and although you can, like, draw them on the paper, you cannot

506
00:34:44,060 --> 00:34:46,220
really make them chemically in the lab, right?

507
00:34:46,220 --> 00:34:47,220
Yeah.

508
00:34:47,220 --> 00:34:49,020
So, this is another thing, and so...

509
00:34:49,020 --> 00:34:52,780
Presumably, that's all future work, and right now you're focused on performance relative

510
00:34:52,780 --> 00:34:53,780
to this predictor.

511
00:34:53,780 --> 00:34:58,740
Right, so, this has been the first step, just, uh, performance relative to the predictor.

512
00:34:58,740 --> 00:35:03,260
We have the framework now there with all these, like, a panel of critiques, so to speak, to

513
00:35:03,260 --> 00:35:05,300
evaluate other chemical properties.

514
00:35:05,300 --> 00:35:10,300
This is something that is commonly studied, um, or has been commonly studied to, to train

515
00:35:10,300 --> 00:35:17,700
generative models to, um, to come up with a molecule that's full, full specific chemical

516
00:35:17,700 --> 00:35:23,940
criteria, what's really novel about our work is this bridging drug design and systems

517
00:35:23,940 --> 00:35:29,540
biology, basically, where you leverage, um, biomolecular information, in this case of the

518
00:35:29,540 --> 00:35:34,300
cancer cell, into the design process directly, and this is something that, like, has never

519
00:35:34,300 --> 00:35:41,100
been done in any way, and this is what, what distinguishes our work from, from, like,

520
00:35:41,100 --> 00:35:44,900
a lot of what is happening in, in, in, in, in, in, in, in the computational chemistry domain,

521
00:35:44,900 --> 00:35:47,860
and the drug, um, drug discovery domain.

522
00:35:47,860 --> 00:35:51,700
With respect to your previous question about reinforcement learning, so one thing that

523
00:35:51,700 --> 00:35:57,380
happens commonly in generative models is this, this mode collapse, where, um, basically,

524
00:35:57,380 --> 00:36:04,900
you are generating only a single, um, element that can, in a gun setting, for example, can

525
00:36:04,900 --> 00:36:09,860
really fool the discriminator very well, but you lose the variety of the samples that

526
00:36:09,860 --> 00:36:10,860
you're generating.

527
00:36:10,860 --> 00:36:12,540
But this is kind of a form of overfitting.

528
00:36:12,540 --> 00:36:16,220
In a way, absolutely, exactly, because the model in a way it learns, okay, I have this

529
00:36:16,220 --> 00:36:19,940
specific instance and it works super well, so I just always go for this one, right?

530
00:36:19,940 --> 00:36:21,380
Why should I explore something else, right?

531
00:36:21,380 --> 00:36:23,500
And it makes a lot of sense to behave in this way.

532
00:36:23,500 --> 00:36:24,500
Yeah.

533
00:36:24,500 --> 00:36:29,460
And this is something we, we also observed, um, in the fact that, um, the model we had,

534
00:36:29,460 --> 00:36:32,980
it tend to, um, like, produce non-carbon chains.

535
00:36:32,980 --> 00:36:37,420
And for some reason, these carbon chains, they, under some circumstances, had the, the

536
00:36:37,420 --> 00:36:41,540
property of that being having a high predicted efficacy, according to our prediction model,

537
00:36:41,540 --> 00:36:46,980
but still we know that they, they, they can't, they don't really qualify as actual drugs.

538
00:36:46,980 --> 00:36:49,740
And so this was one of the challenges we were facing.

539
00:36:49,740 --> 00:36:55,300
So with respect to the results, what I'm most impressed by when I, when I look at this

540
00:36:55,300 --> 00:37:00,380
and what really surprised me, what I didn't expect when I started working on this is that

541
00:37:00,380 --> 00:37:06,420
the drug, the drugs, the molecule, the model comes up with, they really resemble closest

542
00:37:06,420 --> 00:37:11,500
with the known anti-cancer drugs that are known to work for this type of disease.

543
00:37:11,500 --> 00:37:17,580
So what this means is that we train that generative model to design a new lung cancer drug.

544
00:37:17,580 --> 00:37:23,020
We eventually arrive at a new compound and we check the chemical properties of these compounds

545
00:37:23,020 --> 00:37:28,740
and we see, okay, from all known cancer drugs, we can measure the similarity and we see

546
00:37:28,740 --> 00:37:34,940
it's not most similar to any kind of cancer drug, but it's most similar to known approved

547
00:37:34,940 --> 00:37:36,620
lung cancer drugs.

548
00:37:36,620 --> 00:37:41,300
And we, we have the same result for breast, we generate a new drug against breast cancer,

549
00:37:41,300 --> 00:37:46,380
we, uh, check the database of known cancer drugs, we check which molecules are more similar

550
00:37:46,380 --> 00:37:52,580
by like a nearest neighbor search and we find the nearest neighbors of this new drug cancer,

551
00:37:52,580 --> 00:37:58,980
uh, sorry, new breast cancer drug, uh, actually proved breast cancer drugs and not, and this

552
00:37:58,980 --> 00:38:04,380
is nearest neighbor search in your, uh, latent space or this nearest neighbor's, uh, search

553
00:38:04,380 --> 00:38:07,220
of the fingerprints of these molecules.

554
00:38:07,220 --> 00:38:08,220
Okay.

555
00:38:08,220 --> 00:38:12,340
So because on a, like again, if you take the smiles notation, you cannot really compute

556
00:38:12,340 --> 00:38:16,500
a nearest neighbor in between our packs, right, doesn't make sense. So we compute the

557
00:38:16,500 --> 00:38:17,500
fingerprint first.

558
00:38:17,500 --> 00:38:18,500
Okay.

559
00:38:18,500 --> 00:38:21,260
And then we make a nearest neighbor search there by tiny motor similarity.

560
00:38:21,260 --> 00:38:23,940
This is like the standard metric to use in this case.

561
00:38:23,940 --> 00:38:30,580
Um, and they are, yeah, again, what we find is that the molecules we generate, they seem

562
00:38:30,580 --> 00:38:35,780
to be closest to known cancer drug, cancer drugs that are approved for this specific site

563
00:38:35,780 --> 00:38:38,220
of cancer and not anything else.

564
00:38:38,220 --> 00:38:43,180
And this, in a way, it shows us that we are on the right track and that in a way the

565
00:38:43,180 --> 00:38:47,420
model understands that a lung cancer drug should have different properties to breast cancer

566
00:38:47,420 --> 00:38:48,420
drug.

567
00:38:48,420 --> 00:38:49,420
Nice.

568
00:38:49,420 --> 00:38:55,420
And so in terms of your qualitative results and metrics, how are you approaching that?

569
00:38:55,420 --> 00:39:00,580
This is extremely difficult in the sense that the actual validation for such a framework

570
00:39:00,580 --> 00:39:06,660
is to test it in the way that you synthesize the drugs that the model comes up with.

571
00:39:06,660 --> 00:39:07,660
Right.

572
00:39:07,660 --> 00:39:15,180
You run, you run, you run screening tests and you try to basically start the entire pipeline

573
00:39:15,180 --> 00:39:17,420
of clinical trials.

574
00:39:17,420 --> 00:39:19,380
And this is something we're working on at the moment.

575
00:39:19,380 --> 00:39:27,060
So at IBM, we do have options to synthesize molecules.

576
00:39:27,060 --> 00:39:29,580
And this is something we're starting to do.

577
00:39:29,580 --> 00:39:34,300
But at the moment, we are looking for collaborators when it comes to the experimental validation.

578
00:39:34,300 --> 00:39:39,020
This is a skill and expertise that we do not have in-house.

579
00:39:39,020 --> 00:39:42,900
Also, we don't have the equipment in-house to run these essays.

580
00:39:42,900 --> 00:39:47,300
But therefore, we are, at the moment, we are actively seeking for collaborators to work

581
00:39:47,300 --> 00:39:53,100
with us together to run these drug screening essays to basically, like, in a petri dish

582
00:39:53,100 --> 00:39:56,420
measure, how, what's the efficacy of this drug?

583
00:39:56,420 --> 00:40:04,180
Taking a step back to the evaluation criteria we were discussing earlier, is that something

584
00:40:04,180 --> 00:40:13,060
that is automatable, maybe the better way to ask the question is, in your training loop,

585
00:40:13,060 --> 00:40:16,180
what do you use as, like, a loss function?

586
00:40:16,180 --> 00:40:20,540
So the loss function is, because it's the real problem of the machine.

587
00:40:20,540 --> 00:40:21,540
Right.

588
00:40:21,540 --> 00:40:22,540
Right.

589
00:40:22,540 --> 00:40:25,220
Like, the reward is coming from the prediction model that we have.

590
00:40:25,220 --> 00:40:26,220
Right.

591
00:40:26,220 --> 00:40:31,300
I mean, what Pac-Man really tries to do is, it tries to run this drug screening essay for

592
00:40:31,300 --> 00:40:32,300
you.

593
00:40:32,300 --> 00:40:33,300
Right.

594
00:40:33,300 --> 00:40:35,740
I mean, as opposed to, you have to double do it by hand, right?

595
00:40:35,740 --> 00:40:36,740
Right.

596
00:40:36,740 --> 00:40:41,020
So it's spitting out these candidate drugs that pass its test of, you know, being able

597
00:40:41,020 --> 00:40:45,420
to fool, you know, the, the critic or, you know, pass your predictor model.

598
00:40:45,420 --> 00:40:53,060
And then you're manually kind of comparing these to other known drugs for similar types

599
00:40:53,060 --> 00:40:57,740
of tissue for kind of a qualitative sanity check.

600
00:40:57,740 --> 00:41:00,620
Or has that, have you integrated that into the training process somehow?

601
00:41:00,620 --> 00:41:01,620
Mm-hmm.

602
00:41:01,620 --> 00:41:09,740
In a way that, if you train long enough, you see that the model, like, with a high probability

603
00:41:09,740 --> 00:41:14,660
comes up with a drug that has a high predicted efficacy, which means it passes this drug screening

604
00:41:14,660 --> 00:41:18,900
essay, this virtual drug screening, it performs very well.

605
00:41:18,900 --> 00:41:23,260
And it has chemical properties that are desired, basically.

606
00:41:23,260 --> 00:41:26,660
So it is more or less easy to synthesize it.

607
00:41:26,660 --> 00:41:30,020
It has the right amount of water solubility, all of these properties.

608
00:41:30,020 --> 00:41:36,020
And so, but then what we do is, like, we store those molecules that have basically passed

609
00:41:36,020 --> 00:41:37,700
all of these tests.

610
00:41:37,700 --> 00:41:42,940
And then post-talk what we can do is we can then look at these molecules together with

611
00:41:42,940 --> 00:41:47,700
a chemist and then check whether it is feasible to synthesize them.

612
00:41:47,700 --> 00:41:52,420
And because this is like, I mean, it's another set of problems, like, how do you synthesize

613
00:41:52,420 --> 00:41:53,420
a molecule?

614
00:41:53,420 --> 00:41:54,420
Right.

615
00:41:54,420 --> 00:41:56,700
So there's a whole active field of research on retro synthesis, right?

616
00:41:56,700 --> 00:42:04,700
Just trying to basically decompose the target molecule that you want to have into the reactants

617
00:42:04,700 --> 00:42:09,060
and reagents you need in order to get and arrive at this molecule, right?

618
00:42:09,060 --> 00:42:12,180
And this is like, I mean, it's a huge problem by itself.

619
00:42:12,180 --> 00:42:17,900
So you really need to have this, like, recipe of basic ingredients that you can purchase anywhere

620
00:42:17,900 --> 00:42:21,620
in order to arrive at this new compound that probably has never been synthesized in the

621
00:42:21,620 --> 00:42:22,620
world before.

622
00:42:22,620 --> 00:42:27,220
Awesome, well, Yannis, thanks so much for chatting with me about what you're out to.

623
00:42:27,220 --> 00:42:28,220
Very cool stuff.

624
00:42:28,220 --> 00:42:29,220
Thank you so much.

625
00:42:29,220 --> 00:42:30,220
Appreciate it.

626
00:42:30,220 --> 00:42:35,860
All right, everyone, that's our show for today.

627
00:42:35,860 --> 00:42:41,300
To learn more about today's guests or the topics mentioned in the interview, visit twomelai.com

628
00:42:41,300 --> 00:42:43,380
slash shows.

629
00:42:43,380 --> 00:42:47,900
For more information on either of our new study group offerings, causal modeling and machine

630
00:42:47,900 --> 00:42:56,220
learning or the IBM Enterprise AI workflow, visit twomelai.com slash learn 2020.

631
00:42:56,220 --> 00:43:00,700
Of course, if you like what you hear on the podcast, be sure to subscribe, rate, and

632
00:43:00,700 --> 00:43:03,740
review the show on your favorite pod catcher.

633
00:43:03,740 --> 00:43:20,900
Thanks so much for listening and catch you next time.

