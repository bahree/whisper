Welcome to the Twimble AI Podcast, I'm your host Sam Charrington.
Hey, what's up everyone?
If it's been a while since you've checked out the Twimble online community, now would
be a really good time to stop by and get reacquainted.
We've got a ton of interesting things happening for folks looking to grow their machine learning
and AI knowledge.
Here's a sample of what's new.
The new Kaggle Slash Projects Meetup, led by Michael, Christine, Philip, and Mahul,
is off to a very strong start.
They'll be meeting on Saturdays at 10am Pacific and focused on competing in Kaggle competitions
together, and more generally supporting one another and working on ML and AI projects.
If natural language processing is more your interest, we've got a study group for the
Fast.ai NLP course starting December 14th.
The course will cover NLP applications like topic modeling, classification, language
modeling, and translation.
If that sounds interesting but you don't want to wait, the Fast.ai deep learning from
the foundation study group is starting Lesson 12 this Saturday, which is essentially
a three week NLP crash course.
You're welcome to join in.
We've also got group leaders organizing study groups for the Fast.ai deep learning for
coders, i.e. the Part 1 course, which is a great place to get started with deep learning,
as well as Andrew Ng's deeplearning.ai course, which takes a more traditional and math oriented
take on the topic.
Finally, if you're more interested in learning how to use and deploy machine learning and
AI in the Enterprise, I'll be leading a study group focused on the IBM AI Enterprise
workflow certification, which is a sequence of courses hosted over on Coursera.
That group will start in January.
The way to get started with any of this is to join the Twimal community at twimalai.com
slash community.
Submitting that form will get you invited to our Slack, and once you're there, you can
join the appropriate study group channels.
Hope to see you online.
All right, everyone. I am on the line with Mike Tong. Mike is the founder and CEO of Diffbot.
Mike, welcome to the Twimal AI podcast.
Thanks for having me, Sam.
Yeah, I am looking forward to this chat.
We first talked about cover Diffbot in a newsletter.
When you announce, I think it was the company's knowledge graph project, and the headline
of that newsletter was all the world's knowledge on tap, and so it's taken us a while, but
we will finally dig into what that was all about.
But before we do, let's explore your background a little bit.
You were a patent lawyer at one point.
Yes.
Among many random jobs I've held, quick background on me.
I'm a machine learning researcher, right?
So I studied at Berkeley electrical engineering, and then at Stanford, I started grad school
in AI, and I've worked as a software engineer before at Microsoft, at eBay, and Yahoo.
I was the founder of a startup that was sold to Cisco, called Click.TV, that was like a video
search engine, and I was a founding engineer of a startup called Defined that was a product
search engine.
I was sold to Facebook, and in between all that, while I was in grad school, doing research
and AI, I held a side job as a patent attorney.
So as a patent prosecutor, helping people write patents.
So I was the patent prosecutor for Panasonic out here in the Bay Area, and that's sort
of how I bootstrapped the company and paid the bills at the very beginning.
So I got really good at writing patents, could basically pull all nighters and jam out
a patent over the weekend and make like 20K.
So I have like my rent covered for a few months here in the Bay Area.
That's awesome.
So does that mean that before the engineering degrees, you had a law degree?
No, so the thing about patent law is, you know, first of all, it's federal, right?
So it's Washington, DC.
So you don't have to have a state bar, but you get the patent bar.
So all I did was I sat for the patent bar, took that exam, passed it, and could represent
clients and helping them get patents.
That's awesome.
I wonder if we'll have any takers, you know, listeners that try to pick up this side hustle.
Sounds like a nice one.
Well, I really doubt tell with my interest, right?
Because I mean, patents are kind of, especially the claims part of the patent is almost
like a programming language in itself, it's a legal programming language.
And to write the description part of the patent, you have to be technical, right?
So you have to be an engineer and I was, since I had a CS and electrical engineering
training, I was able to translate that into a patent language.
And then think of like alternative embodiments of the invention, right, that the inventor
came up with.
Nice.
Nice.
Yeah, my sister sat out to Lori is a patent, an IP lawyer at Intel.
And we have really interesting conversations about the public aspects of what she does.
It definitely sounds like interesting work.
But you know, on to machine learning AI and Diffbot, tell us a little bit about the
company.
You know, as I mentioned, I was at Stanford in grad school and, you know, I was, you know,
kind of procrastinating from writing my thesis, you know, and thinking of like what kind
of area of AI research to specialize in.
But I realized that, you know, there's essentially three key drivers to improving AI, right?
There's people that work on the hardware.
There's people that work on improving the software and algorithms.
And there's people that work on data, right?
And there's large public companies that focus on essentially Moore's law, like making the
hardware faster, like NVIDIA and, you know, where your relative works at Intel, right?
They're making the chips faster.
There's tons of people now making the algorithms better, right, including what I was supposed
to be doing as a grad student, as well as, you know, things like TensorFlow and PyTorch,
like these actual frameworks.
Yeah, I was going to say, I'd argue that there's at least a fourth category of tools that
support the folks that are using the algorithms, but not to take away from your point.
I get it.
Totally.
Yeah, the tools, I mean, I would include that in software, right?
It's the algorithms itself plus a software, but yeah, you could separate that out.
But the third category data, I feel like there isn't like sort of like an everything
store of data, right?
If you're building an AI application, you generally have the data as part of your current
process, right?
Or you start rolling up your own sleeves and gathering information, right?
So this became really clear, actually, at that time, I was at Stanford because that's around,
you know, just down the hall, Fei-Fei Li was coming up with the ImageNet, right?
Which is a very large set of annotated images, right?
And, you know, I think it's like about a million images classified into about a thousand
since set categories of WordNet.
And that dataset is really what kicked off the deep learning revolution, right?
Just that amount of labeled structured data.
And so, you know, a lot of neural networks were invented way before, right?
Like in the 70s and 80s, and we've made some tweaks to improve how fast they train
and our new architectures and so forth, but it was really that dataset that made computer
vision go from something that was basically a research grade, you know, task into something
that's production grade, right?
Something that's a little bit better than random to something that's approaching human
level of classification accuracy.
So at that time, I was thinking about, you know, how could you build like an ImageNet
for language or general concepts, right?
And the way that they built ImageNet, basically using Google Image Search and Amazon Mechanical
Turk, you would require a calculated about 50 manures with a team of about 20 people to
build a similar kind of dataset for language because there's languages way more complex
than vision, right?
Like human beings alone have language and like all animals have computer vision.
But then there's way more concepts, right?
So if you think about a number of concepts even on Wikipedia, there's about a million or
so a quarter of magnitude pages on Wikipedia and so just having about a thousand labeled
examples of each of those concepts, you quickly stack up like how much it would take.
So I started thinking about, well, where is all this knowledge?
It exists on the public web.
It's the web is the largest, you know, resource of public knowledge we have as a species.
But the problem is the information is stored in all of these documents.
So it's not structured data, right?
It's not machine readable.
And so if only we could create an algorithm that could actually read and understand all
of those pages on the web and convert it into a coherent machine readable structure, then
we would have solved this problem, essentially using AI.
And so that got me to thinking about the idea behind Diffbot.
So the mission of our company is to build the world's first complete map of the human knowledge
and make it machine readable so that other companies can build all kinds of smart experiences
are on top of it.
And so we can have that future that we all won't watch with intelligent agents all around
us, right?
That can benefit from structured information.
So how to do that?
It's kind of a big, a big task and we don't have the resources, you know, bootstrapping
to crawl the whole internet from day one.
In fact, one of the first things that I thought as you kind of laid out that mission is, you
know, Google and Microsoft are both out there talking about their knowledge graphs and
how they're kind of the very core of what they're able to do in many cases, machine learning
and AI and beyond.
Yeah.
A lot of those come from, you know, their experience is building the Google and being search
engines.
You know, massive, massive investments in pulling all that together, sounds like how can we
do it?
Exactly.
That's a lot of people ask us for sure.
So how Google really coined that word knowledge graph.
So how they did it is basically the history behind that, they acquired a company called
MetaWeb, right?
They had a project called Freebase and Freebase was essentially that.
It's Freebase was basically imported all of the information from Wikipedia, those info
boxes on Wikipedia.
And then they had like a crowd editor that basically kind of allowed you to edit Freebase,
like random people on the internet, right?
So kind of crowdsourcing the problem.
Mm-hmm.
And Google acquired.
Yeah.
Sorry.
Go ahead.
Yeah.
It's interesting that I think I envisioned something much more, I don't know, glamorous
is the right word, but you know, something more learned than something that started with
Wikipedia.
Like they kind of used the page rank graph and figured out what the concepts were and
you know, did something, I guess exotic is what I envisioned.
Yeah.
I mean, people just, they have the assumption that, okay, they're Google, they have infinite
resources.
So everything is machine learning, right?
You see, right?
The knowledge channels and everything like that, right?
But the reality is, when you're searching on Google, only things that generally have a
Wikipedia page have a knowledge panel, at least that was originally when it launched,
like you type in someone who's famous and you'll get a knowledge panel, right?
But you type in like a regular Joe, right?
Or you type in one of your relatives, your friends, your colleagues, they don't get a knowledge
panel, right?
Look, why is that?
Because no one's added it.
You know, it's actually great, even though there's pages about them for sure, right?
And so what the, at these large companies, many of which are customers actually go more
into that, you know, if we have time, but they basically start out with Wikipedia and then
allow there's ability to edit and curate it.
And then this knowledge graph basically becomes like a file format within the company that
many teams contribute to actually, right?
So a lot of these data sources, they're licensed from third parties, right?
Like the sports scores and things like that, the weather feeds and stats, other pieces
of information that go into it are built by a specific department at the company.
So there'll be like a recipes department that focuses on the recipe section of the knowledge
graph.
And they'll have an entire army of curators and stuff that is uncurrating those particular
sections.
But the different knowledge graph is the only one that is fully built by an autonomous
system, right?
We don't have the resources to hire thousands of curators and labelers to curate all
different aspects of knowledge.
So the biggest difference is between us is a, well, first of all, our knowledge graph is
much larger, right?
Because it's based on actually a different technique of crawling all the pages on the web and
building it.
So it does have like those average Joe entities and startups and smaller companies in it.
It has about 10 billion entities in the knowledge graph and about a trillion edges.
Thirdly, it's, secondly, sorry, it's, you know, it's available for use, right?
So it's not just for like consumer search where, you know, it's good for like the Kanye
West or Taylor Swift query, right?
But it's good for the kinds of entities that you would interact with in the business world,
your suppliers, your vendors, right?
Your customers, people you're trying to recruit, right?
So I always like to say, you're not usually trying to recruit, you know, like Donald Trump
or like higher tide, you know, sell something to Tiger Woods, these kind of entities that
are in these consumer knowledge graphs, right?
But those entities that you would deal with in the business world are actually in ours.
So ours, I would argue, is much more useful to building real things.
And then you can use it.
So that's a very important point too.
Like the Google Knowledge Graph, you can't actually pay like to access it, right?
And that has to do with, you know, for strategic and business reasons, they don't want people
to just build a skin on top of Google and, and they just have like a, you know, a competitive
product offering.
So they haven't focused on that as their main revenue model.
One of the use cases that I often hear Google and Microsoft talking about the contribution
of their knowledge graphs is with virtual assistants.
Do you find folks using Diffbot as a kind of foundational component for building that
kind of virtual assistant bot experience?
Yes.
I can't share too many details, right, about the companies that use it in that way.
But they include big companies as well as startups.
The main problem that everyone's trying to solve in this category is basically a virtual
assistant needs to have knowledge in order to be intelligent, right?
Most of the time you ask Alexa or Siri a question, you know, if it hasn't been something that's
been pre-programmed and it's not going to be able to answer that, right?
You have to almost talk like a robot to communicate with these systems.
You have to talk in certain templates, right?
And if they could solve actually the problem of knowledge, they'd be able to answer, right?
Almost any question that's, that's askable.
That's like a public fact.
That is definitely one of the applications that we see of the knowledge graph.
In general, though, we have, you know, over 400 companies that currently use Diffbot.
There's, that's example of a consumer application, like an intelligent assistant.
We have a lot of the major search engines like DuckDuckGo, Yandex, Bing, where we're
powering like their knowledge panels that you see, you know, so we're powering parts
of their knowledge experience.
And then we have a lot of consumer apps like Instapaper, Snapchat, we power like the articles
for you and that.
There's like a wedding planning app, Zola, where people build like a wedding registry.
And then there's a whole bunch of business process applications.
So you can use a knowledge graph to find sales leads.
You can use it to find people to hire.
You can use it to enrich your current CRM to better understand your customer insights,
right?
If you're a brand, you can use it to track like all the places online that are selling
Nike's and monitor if anyone's selling fake Nike's or have counterfeit goods and things
like that.
So there's a whole bunch of BI and market intelligence applications too that we're seeing
now.
This new product.
Interesting.
And so what's the typical user developer experience?
So if you're a developer wanting to use DiffBots products, there's basically three main ways
you can use it.
The first is our extraction APIs, right?
So you can pass in an individual URL from the web to our endpoint and then our machine
learning will classify that URL and then extract it into an entity, right?
So if you pass in like a product page, it'll say this is a product page.
It's a type product and here's the price and here's the image and name of the product
and description and SKU and weight and all those product facts, right?
Actually, let's just pause on that because I've got a little bit of experience trying
to extract data from pages.
I'm sure a lot of people that are listening have tried to do this and it is historically
very, very hard.
I mean, you have, first of all, trying to do if you're doing it based on regular expressions
or X-Path, there's all different kinds of ways to do it.
They're all super fragile.
The sites change and they break all the time.
They break all those roles.
Yeah.
Right.
So what you're saying sounds like magic, like, you know?
Yeah.
So we launched that on hacker news, right?
I'm sure some of your listeners are familiar with that site and that's what a lot of
developers say.
This is basically like magic.
As an alternative, you'd have to use something like impar.io or scrapy, right?
And like you said, create all these patterns and then maintain them.
That's actually fine if you just want to get information from one site on a one time
job, right?
Right.
And maybe take a few minutes to configure that.
But it's a problem when you want an ongoing process, right?
And you want to get information at large scale, like from thousands of sites, right?
It starts to become tractable to maintain that, like 15% of your roles will break each
week, right?
Right.
Right.
And so with the machine learning based approach, it's robust to any changes, like you
said in the design or the layout and you don't have to create any roles.
You just pass in the URL and we don't have to create any roles because you can literally
pass in a URL from anywhere.
So it's like we can't, right?
And then the other thing that's quite distinctive too is it works across any language on the web
too.
So you can pass in a page, like a Japanese e-commerce page, which has totally different
design conventions, right?
Or like a German article page and it'll parse it perfectly as well.
So a lot of people use it because of that aspect.
So that was our first product, really popular as an alternative to writing your own custom
web scraper.
The second way developers can use it is called crawlbot.
So that's crawling an entire domain essentially, right?
So it'll start from those C-D-R-Ls and then it'll, that's how you can get essentially
the entire database from a site, right?
So you can say, I want all of the products from Target, Macy's, J-Crew, Dan or Republic
Home Depot, and then you get the entire product catalog, right, of those sites synchronized.
And then the third way is, of course, the knowledge graph.
And the way that you interface with that as a developer is with the Diffbot query language,
which is basically kind of like a structured semantic search.
So you can almost search the web as if it was like a huge, you know, a structured semantic
database.
And we also have like a UI that allows you to help you build those queries, sort of for
the less technical users.
And then for like business users, we integrate, right, the knowledge graph into the tools
they already use, right?
So you can export it as CSV, and so you can open it in Excel, or you, we plan to build
integrations directly into things like Tableau, Salesforce, Excel, the actual tools that you
might be, you know, your actual daily driver, right, where you're doing your data manipulation,
being able to tap into the knowledge graph directly from those.
And so when you're writing these queries, you're using machine learning on the backend
to do the crawling and kind of understand the pages and please elaborate on what specifically
you're doing there.
But are you also applying some kind of machine learning and interpreting the query itself?
So, you know, if I put in a term, it's not just the literal term, but maybe hitting
some embedding or, you know, abstraction that's kind of trying to figure out what I'm looking
for.
Yeah, so there's, like I was saying earlier in this call, like our almost our entire company
is one big machine learning problem.
There's about actually like a 50 or 60 separate machine learning problems that we study
at the bottom, right?
So we're about a, now a 35 person company and like 80% of our company is machine learning
researchers.
So when we crawled the web, that's largely, our VP of Search is Matt Wells, he was the
founder of a search engine called Gigablast, right?
So that's how we're able to, as a small start up, crawl the full web.
But what we, what differs is we render the whole web.
So we're actually running the web inside real, real browsing engines and playing the web,
almost like a video game.
We serialize from every page, essentially all the pixels on the page, the geometry of
the page, all the visual styles and layout and the internal state of the virtual machine,
the JavaScript and CSS layout engine.
And those are essentially just like a long, you know, string of numbers.
And that's where our algorithms use those numbers to classify the type of the page, right?
So this page look like a article page.
It has a very different look and layout from a article page or a product page or like
a person page.
And then we use machine learning to extract the particular fields after we've classified
it, right?
So on a product page, look for the things that look like the price of the product, look
for the things that look like the image of the product, right?
And then analyze the actual image to determine what's the color of the product, what material
is it made from?
Right?
Is it a, you know, red sports car inside at which model of cars it, right?
Is it a brown sweater, right?
Like what kind of fabric and swatch pattern and such and so forth.
And then we're analyzing the text of the page as well.
So, you know, inside an organization's description, it might include like what is the category
of that organization when it was founded, where it's based, right?
Who are the main officers of the company?
So to do that, you need to do various kinds of natural language processing.
So we have folks that have developed the state of the art in entity linking, working at
Diffbot to find the entities in the text.
We do what's called a relation extraction to find the relations between those entities.
And we also do machine translation, right?
Because the text could be a non-English to start out with like Arabic or Chinese, right?
And then once we've extracted these things, we then need to be able to link it across pages,
right?
There could be one page about Sam Charrington and then another one on a different page
on the web.
But we know they're the same real world person, right?
You don't want to have two entries in the knowledge graph for that, right?
So we need to use machine learning to link together those extractions across multiple
pages.
And then we work on a problem called knowledge fusion, which is given all that evidence,
what is the probability of truth of each of those statements?
And then we write the really highly confident facts, like as triples, into the knowledge
graph.
And that's kind of like end-to-end kind of soup to nuts, how it goes from a page into
an entity, right, inside this AI-sensized system.
We build a new knowledge graph, like around every four days.
And then on the query side, of course, we have structured querying, right, like such as
the default query language, there can be ambiguity, right, in parts of the syntax.
Like if I say I'm looking for machine learning engineers that live in Mountain View, well,
it needs to interpret whether that's Mountain View, California, or Mountain View, Arkansas,
right?
There's another city over there that's called Mountain View.
There's also another Mountain View, you know, outside of the US.
But we all know which one, you know, we're likely referring to.
So it needs to take in the stats, right, to interpret that statement.
And then we're also doing at the research level, natural language question answering, right,
which is more in line with the kind of earlier question about assistance.
Yeah.
You know, what's fascinating about this is that, you know, when you talk about the extraction
problem and identifying the pictures and identifying the, you know, what's probably the price,
it sounds both super, you know, simple, really from the straight forward, but also like
terribly, terribly complex at scale.
The trick is getting it to, it's easy to get 80% accuracy, but to get to the level back
or see needed by commercial customers, you know, and at an at scale across, you see a
lot of weird stuff when you crawl the whole internet, right, there's all kinds of, of
wacky stuff going on in the long tail of the web, but to get it to work perfectly there
as well, right, that's where it's really hard and we'll be working on this problem for
many years.
Now, often when a company is tackling these kinds of problems, you know, whether it's information
extraction or a natural language processing, there's, you know, we're using machine learning,
but also whether, you know, for exceptions or, you know, the kind of under the covers
thing that's doing the heavy lifting is, you know, some old school, you know, rejects
or rule rules base or something like that.
I can't imagine that, you know, again, scaling working in this context, do you kind of totally
issue that, you know, those types of approaches or do you, do you do them and have you found
a way to fuse them in a way that works?
I mean, I guess, you know, we established a Google kind of does this.
So, you know, it can be done at scale, but perhaps not with the team of 35.
Yeah.
So actually, if you are a user of this bot and you have access to developer APIs, when
you log into our developer dashboard, there is an ability to override what's extracted
by our AI.
So essentially, if, for example, you know, our attraction works pretty well.
It has over 95 percent, you know, like precision and recall.
But if it made a mistake for whatever reason, you have an ability to actually say, hey, no,
this was the actual price of the product and override that with a rule as a customer.
And so you kind of crowdsource the corrections?
Yeah, exactly.
That basically allows someone who's non-technical with like a visual interface, right, to kind
of correct it.
That basically, you know, it works now for you.
And then the second thing it does is basically, it takes that rectangle, right, that they
clicked on and then it adds it to our training set, right?
So it improves the global model for everybody.
So it doesn't create a rule that is, you know, an override for everyone just for that
user.
Okay.
Yeah.
Interesting.
Yeah.
Yeah.
That is basically trained in that.
It's kind of like your spam, right?
Like you might mark stuff as spam or not spam in your own inbox and it affects you.
But then it also helps, you know, your email provider's global model.
So I'm curious when you set out to start the company or, you know, thinking about the
evolution of the company, is it like a machine learning, research project organization
that turned into a commercial entity or was it a commercial entity that, you know, eventually
found in order to really do this, you have to be a really heavy research organization.
Well, I mean, the purpose was, you know, as I said, it was before, it's a try to build
the first complete map of human knowledge, right?
And it just turns out that a corporate structure, I found is the best way to organize labor,
right?
But at the, for the first couple of years, yes, it was just pretty much me sitting in a
dark basement, like working on the math problems, right?
Because I really wanted to make sure that the technology actually worked before trying
to do things like hire a bunch of people or scale it or raise money or things like that,
right?
Because I think all too often with a lot of AI projects, like they might work well at
a researcher prototype phase, but then they're not at the level of quality that someone would
actually pay to use it, right, in the business world, right?
And then so they, they'll have problems down the line trying to commercialize it, right?
So another unique aspect of our company, even though it is primarily an AI research company,
is that we're profitable.
So a lot of other groups that do AI research are either subsidized by another part of the
company, right?
Like, like, most of the major tech companies, right, they aren't themselves a profit center,
or they're funded by, you know, like a philanthropist, like, like one of those nonprofit,
you know, AI research companies.
Formerly nonprofit?
Yeah.
Well, open AI, well, also the Alan Institute, I think, is another example where it's funded
by, you know, primarily Paul Allen, but that, I think it's great though, right, that money
is going into advancing the research that we definitely benefit, right, from those
results.
But yeah, so then over time though, as, you know, this kind of web scraping machine learning
AI became popular, we needed to hire people to help keep the servers up, and to grow the
data center.
We crawled the web out of two data centers here in the Bay Area, and so that's when I
started kind of tapping into my Stanford network, eventually got connected with Andy
Backelstein, who was the first investor in Google, so he led our angel round and defbot
and invested twice as much in our company, and then partnered with Skydatin, who is the
founder of both Earthlink as well as cloud kitchens, and then in the series they partnered
up with some of the folks behind Tesla and SpaceX, and folks at Tencent.
I mean, you mentioned that there's kind of 50 machine learning problems or challenges
as you kind of look across the things that you need to do to deliver this offering or
solve this problem.
Are your researchers also, do you publish, do you go to conferences like Noreps and kind
of contribute to the community in that way?
Yeah, so basically the area of machine learning, machine learning is a big tent, right?
But the area that we care about is information extraction, right, from unstructured information,
whether it's text or images or document layout, right, and also knowledge fusion.
So this particular corner of AI, the people that are working at Defbot are in general way
more qualified than me, so I'm probably the least qualified person in the company, and
that they've probably developed a state of the art system in that area, right?
So in unstructured relation extraction, open relation extraction, the folks that developed
the state of the art system there now, in during their PhD work on that problem at Defbot
and have scaled it to the size of the Defbot knowledge graph, one of the previous CTO
of DPPDIA, which is another well-known knowledge graph joined Defbot to focus on knowledge fusion.
So we benefit from these top researchers, and then another thing I should mention is
we give free access to our knowledge graph to about a dozen or so different academic
AI research groups, and the thinking is that those professors and PhD students and grad
students should be able to stay within academia and do fruitful research in this area of knowledge
graph and large-scale information extraction without having to join a big company.
So we kind of see them and give them access to our knowledge graph, and they've used that
to produce some interesting results.
So we had a collaboration like that that had a paper at NERIPS, and we've also done more
active, more recently, some of our own publishing.
So at the last EMNLP, we released a data set called KnowledgeNet that allows you to, in
the research world, build your own end-to-end knowledge graph.
It's the largest knowledge graph construction data set that's been released so far, and
it's very high quality compared to previous data sets.
And we also released like a baseline system in the open source that is a reference system
on that knowledge-based construction task.
And so that's also being used by a lot of other AI centers right now.
So I think in the earlier years, we're just pretty heads down on getting stuff to work,
and now we're trying to have a more capacity to publish and help other research groups,
and kind of help with knowledge sharing, and help see more research in this area.
So one of the bottlenecks to productive research in this area is, like if you, there hasn't
been a lot of progress in knowledge fusion, for example, in academia, because you need
access to a really large database as a knowledge graph to study that problem, right?
And so hopefully we're unblocking one of the bottlenecks to more research going on in
the state of yarn in academia.
Can you talk about those couple of challenges that you mentioned, one, knowledge fusion,
and what's there?
And you also mentioned the knowledge-based construction task.
How's that problem framed, and what are the, you know, the success metrics there?
Totally, yeah.
So knowledge-based construction, so like a very classical academic shared task for that
is run by a tech KBP, so that's like, I think, was originally organized by the National
Institute of Standards, but the input to that problem is basically text, right?
So like, newswire articles and things like that, and the output to that problem is, is
a knowledge graph.
So it's like, what are the entities mentioned, and all those documents, and what is the
relationship between those entities, right?
Like is it company A, acquired company B?
Those would be two different entities mentioned, and then the relationship would be like acquisition,
right?
Or person A is the founder of company B.
Those are all examples of relations or triples.
So knowledge fusion is probably not a very, you know, probably, it's not very well publicized.
A lot of people have heard about this research problem, but what it is is basically how do
you fuse multiple sources of data, right, into a singular resource or database, right?
So on the web, you can think about, you know, there's many different kinds of sites and
variety of different kinds of levels of quality of information on the web, right?
And you know, you might trust, for example, something you read on Wikipedia more or so
than on a blog that's hosted in Ukraine that just, you know, was created a month ago, right?
Or something posted on social media, for example, right?
And also there's the time aspect, right?
So what was true at one point in time may not be true at another point in time, like people
change jobs, people switch roles, relationships change, right?
Products change.
There's new stuff coming out all the time.
And the recency of information is critical, right, to any kind of business application,
right?
So what Knowledge Fusion does, we've created essentially algorithms at Diffbot, kind
of equivalent to what we call knowledge-based trust.
So think about PageRank, but not for site authority, but for trustworthiness of the facts,
like from that origin, right?
Okay.
So we almost have an algorithm that propagates truth, right, through this graph that learns
on its own to know that Wikipedia, if something is published there, is more trustworthy, right,
than a random social media post, right?
Because why?
Because Wikipedia has a higher track record in previous iterations of knowledge-based trust
of producing facts that agree with other sources, right?
So there's kind of like a consensus algorithm going on and cross-checking going on.
Within Knowledge Fusion, there's a whole kinds of different ways of approaching the problem.
There's ontological inference.
So for example, if you see on a page, Mike Tung, who's me, lives on the planet Venus, right?
Our algorithms would ideally say that that's not very likely to be a true fact.
Why?
Because other pages say Mike Tung works at Diffbot.
Diffbot is based in Menlo Park, Menlo Park is in California on the planet Earth, right,
which is millions of miles away from Venus, right?
Those are all entities in our knowledge graph, right?
So that logical chain of reasoning would assign very low weight to that fact being true, right?
And also the fact it's not being corroborated by other trustworthy sources, right?
So this kind of mechanical calculation of how likely something is to be true is part
of Knowledge Fusion, which fuses it together to estimate a probability of truth.
One question that I've got, you know, as you describe this knowledge-based construction
task and the example that you gave of the kind of knowledge-based that one might want
to extract from newswire articles, et cetera, I guess I'm trying to work through the relationship
between a knowledge-based that you've got, you know, that's kind of a global knowledge-based
and a knowledge-based that, you know, I want to create around my documents.
Should I be trying to, you know, if I've got a problem and I want
to, you know, say, you know, I'm at a large enterprise and I've got kind of stores of internal
knowledge and I want to, you know, create some kind of knowledge graph based on that.
Should I be building a knowledge graph from scratch that is not aware of kind of the
broader global knowledge graph or knowledge-based or should I somehow be, you know, not to overload
the worth fusing, but, you know, kind of fuse the knowledge that, you know, service
like yours might make available to me about the broader world, you know, maybe treat
that as some kind of framework or ontology or something to get me started.
How do you see folks kind of dealing with those questions?
Yeah, so that's a really good question.
So, I mean, there's all kinds of vendors in this burgeoning space, right, of knowledge
graph. I think it's recently been added as one of kind of like the things that attract
in like the hype cycle, gardener's hype cycle.
There's people that provide actually knowledge graph databases, right, like graph databases.
There's people that are kind of provide consulting services to help your organization build
their own knowledge graph.
Our focus is on just structuring the public knowledge, right, of the public entities and
that's a big enough space for us, but what we find though is that a lot of the entities
that companies care about are public knowledge, they are public entities, right, like all
of the accounts inside your CRM, like an inside your customer database, those aren't specific
to you.
There are companies that exist out there in the real world, right, so are the people,
like we have a vast majority of the people on earth inside our knowledge graph.
So however, the key thing is being able to connect the internal knowledge graph to the
external one and benefit from it, right, so be able to import the facts that we know
in the Diffbag Global Knowledge Graph into your internal stores, right, so that's where
the integrations are key, right, so there's a API that we have called Enhance that actually
allows you to, let's say imagine, for example, you're a small business, you have some
leads inside a database that you collect from your website, you might know, okay, the first
name, email address, and company that one of your customers works for, you can essentially
look that up in our knowledge graph, just only using those three facts, what we call a
impartial entity, and match our entity in our knowledge graph, and then you'll gain
basically like 200 or 300 additional facts like about that entity, so Diffbag can be used
as a tool to both correct your internal data and to keep it up to date with new information.
So if you think about enterprise knowledge, a lot of people's effort is spent just keeping
that database up to date, right, you have like a big vendor database and how many of these
vendors are still in business, or is this the current mailing address of this company
anymore, right, it's a huge headache, right, and a lot of effort is spent in many functions
across the whole enterprise, just maintaining the currency and accuracy of all this information,
and that's the kind of work that we hope to alleviate human beings from having to do in
the future by basically tapping into this global knowledge base.
Awesome, lots of good stuff in this conversation, you know, I guess one quick question I have,
just pulling up the Diffbot page and looking at, or the Diffbot site and looking at pricing,
it doesn't look like there's a kind of developer free tier, that kind of thing, so maybe folks
listening to this shouldn't get excited and say, oh, I'm going to go try this out, you've
got a free trial, but you're not necessarily taking that kind of freemium type of a model,
is that correct, or is there something available for folks that want to play around, hobby
projects, that kind of thing?
So we call our business model knowledge as a service, right, so it's a subscription
to access information called the knowledge graph, like you said, we do have a two-week
free trial for trial access, if you need to use it longer than that for certain projects,
like I mentioned, we do provide free access to certain kinds of groups, if it's a student
project, or if it's like academic research for things like that, I think we have pretty
friendly pricing for startups, starting at $2.99, it'll basically be the same cost as
your EC2 server, probably that you host your application on, or less if you're like a startup,
for the larger companies, large enterprise, usually those kind of companies like to pay
annually with annual contracts, so those are basically gone through sales rather than
the website.
Cool, well Mike, thanks so much for taking the time to chat with me, share a bit about
what you're up to, definitely enjoy it.
Yeah, likewise, it's been pleasure talking to you, Sam, thanks for having me on.
Thank you.
All right, everyone, that's our show for today, to learn more about this episode, visit
homolei.com, as always, thanks so much for listening and catch you next time.
