1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,360
I'm your host Sam Charrington.

4
00:00:23,360 --> 00:00:28,800
Let me start this show by sending a huge thank you to everyone out there listening.

5
00:00:28,800 --> 00:00:33,680
We've dropped a ton of great interviews over the past few weeks, but through your dedication,

6
00:00:33,680 --> 00:00:40,480
we continue to see a growing outpouring of feedback, comments and shares with each release.

7
00:00:40,480 --> 00:00:44,920
If you're a regular listener, but don't normally send in feedback, we would absolutely

8
00:00:44,920 --> 00:00:46,520
love to hear from you.

9
00:00:46,520 --> 00:00:52,160
So please head on over to Apple Podcasts or wherever you listen and leave us a review.

10
00:00:52,160 --> 00:00:57,480
Of course, a 5 star review is appreciated, but what's most important is that your voice

11
00:00:57,480 --> 00:00:58,480
is heard.

12
00:00:58,480 --> 00:01:03,160
It lets us know what you like or what you feel we could improve on, and it lets those

13
00:01:03,160 --> 00:01:08,000
looking for a new machine learning and AI podcast know that they should join the Twimble

14
00:01:08,000 --> 00:01:09,400
community.

15
00:01:09,400 --> 00:01:15,440
Speaking of community, the details of our next Twimble online meetup have been posted.

16
00:01:15,440 --> 00:01:22,080
On Tuesday, November 14th, a 3pm Pacific time will be joined by Kevin T, who will be presenting

17
00:01:22,080 --> 00:01:27,800
his paper, active preference learning for personalized portfolio construction.

18
00:01:27,800 --> 00:01:31,800
If you're already registered for the meetup, you should have received an invitation with

19
00:01:31,800 --> 00:01:33,680
all the details.

20
00:01:33,680 --> 00:01:39,520
If you've yet to join the meetup, head on over to twimbleai.com slash meetup to do so.

21
00:01:39,520 --> 00:01:41,080
We hope to see you there.

22
00:01:41,080 --> 00:01:46,160
Now, as some of you may know, we spent a few days last week in New York City, hosted

23
00:01:46,160 --> 00:01:49,520
by our great friends at NYU Future Labs.

24
00:01:49,520 --> 00:01:54,000
About 6 months ago, we covered their inaugural AI Summit, which is an event they hosted

25
00:01:54,000 --> 00:01:58,800
to showcase the startups in the first batch of their AI Nexus Lab program, as well as

26
00:01:58,800 --> 00:02:02,360
the impressive AI talent in the New York City ecosystem.

27
00:02:02,360 --> 00:02:07,200
Well, we were more than excited when we found out they would be having a second summit

28
00:02:07,200 --> 00:02:08,680
so soon.

29
00:02:08,680 --> 00:02:13,760
This time, we had the pleasure of interviewing the four startups of the second AI Nexus

30
00:02:13,760 --> 00:02:20,840
Lab batch, Mount Cleverist, Bite.ai, Second Mind, and Bowtie Labs.

31
00:02:20,840 --> 00:02:25,080
We also interviewed a bunch of the speakers from the event and will be sharing those discussions

32
00:02:25,080 --> 00:02:27,040
over the upcoming weeks.

33
00:02:27,040 --> 00:02:32,480
In this first episode of the series, you'll hear from Mount Cleverist, a startup started

34
00:02:32,480 --> 00:02:37,480
by childhood friends, James Villarubia, and Bernie Pratt.

35
00:02:37,480 --> 00:02:42,480
Mount Cleverist is an online service for teachers and students that can take any text via

36
00:02:42,480 --> 00:02:48,160
the web and generate a quiz along with answers based on the content supplied.

37
00:02:48,160 --> 00:02:52,800
To do this, they employ a pretty sophisticated natural language understanding pipeline,

38
00:02:52,800 --> 00:02:54,920
which we discuss in this interview.

39
00:02:54,920 --> 00:02:59,760
We also touch on the challenges they face in generating correct question answers, how

40
00:02:59,760 --> 00:03:05,240
they fine tune their machine learning models to improve those answers over time and more.

41
00:03:05,240 --> 00:03:07,600
And now on to the show.

42
00:03:07,600 --> 00:03:18,000
Alright everyone, I am here at NYU Future Labs, meeting with

43
00:03:18,000 --> 00:03:21,240
some of the AI Nexus Lab companies.

44
00:03:21,240 --> 00:03:27,000
And the first company into the interrogation room is Mount Cleverist.

45
00:03:27,000 --> 00:03:33,560
And I'm here with the CEO, James Villarubia, and the COO, Bernie Pratt.

46
00:03:33,560 --> 00:03:36,280
Welcome to this week in machine learning and AI.

47
00:03:36,280 --> 00:03:38,280
Thanks for having us, yeah.

48
00:03:38,280 --> 00:03:43,560
So why don't we get started with an introduction to the two of you, your backgrounds, as well

49
00:03:43,560 --> 00:03:46,280
as the company and what the company is up to?

50
00:03:46,280 --> 00:03:47,280
Sure.

51
00:03:47,280 --> 00:03:51,480
So my background is really as an engineering statistician.

52
00:03:51,480 --> 00:03:56,360
I got an engineering degree from UVA, then a master's in public policy, mostly focused

53
00:03:56,360 --> 00:03:57,680
on tech policy.

54
00:03:57,680 --> 00:04:02,320
And what I found was the coolest, most interesting problems out there to solve were just engineering

55
00:04:02,320 --> 00:04:03,320
ones.

56
00:04:03,320 --> 00:04:04,320
They were political ones.

57
00:04:04,320 --> 00:04:05,800
They're big picture policy stuff.

58
00:04:05,800 --> 00:04:10,400
So I jumped into the Pentagon as a statistician and then briefly went to the White House and

59
00:04:10,400 --> 00:04:12,040
then find the DOJ.

60
00:04:12,040 --> 00:04:16,800
And then I got kind of tired of DC and got the startup bug and came up to here to New

61
00:04:16,800 --> 00:04:20,760
York and helped run a cybersecurity company for a couple of years, until eventually this

62
00:04:20,760 --> 00:04:25,280
idea that we had about Mount Cloverist finally kind of peaked the right person's interest.

63
00:04:25,280 --> 00:04:26,960
And they said, go do that.

64
00:04:26,960 --> 00:04:30,800
And we said, great, we've been trying to get it going for a long time, so we're really

65
00:04:30,800 --> 00:04:31,800
excited.

66
00:04:31,800 --> 00:04:32,800
Thanks, James.

67
00:04:32,800 --> 00:04:33,800
And Bernie, how about you?

68
00:04:33,800 --> 00:04:34,800
Sure.

69
00:04:34,800 --> 00:04:39,080
So I moved up to New York right after college and we did some work in a startup in finance

70
00:04:39,080 --> 00:04:43,840
where we were pulling data out of press releases to send to programmatic traders.

71
00:04:43,840 --> 00:04:48,840
And this allowed us to get into machine learning and natural language processing early on in

72
00:04:48,840 --> 00:04:49,840
my career.

73
00:04:49,840 --> 00:04:53,720
Not as an engineer, but as a manager of engineers doing product work primarily.

74
00:04:53,720 --> 00:04:57,680
From there, I bounced around into a few different places, again, in product positions, but

75
00:04:57,680 --> 00:05:00,560
very, very data heavy, API heavy.

76
00:05:00,560 --> 00:05:03,200
And James and I, we've actually been friends for about 25 years.

77
00:05:03,200 --> 00:05:04,200
We met in kindergarten.

78
00:05:04,200 --> 00:05:05,200
Oh, wow.

79
00:05:05,200 --> 00:05:06,200
Yeah.

80
00:05:06,200 --> 00:05:07,200
And so.

81
00:05:07,200 --> 00:05:08,200
It's the first time I've heard that.

82
00:05:08,200 --> 00:05:09,200
Photo evidence, too.

83
00:05:09,200 --> 00:05:11,200
It used to be part of our pitch.

84
00:05:11,200 --> 00:05:12,200
Nice.

85
00:05:12,200 --> 00:05:16,280
We were friends for a very long time and had always wanted to work together after doing.

86
00:05:16,280 --> 00:05:19,960
So we went to high school together as well and did some good work in a few number of

87
00:05:19,960 --> 00:05:20,960
different areas.

88
00:05:20,960 --> 00:05:22,960
But this was the chance for a school.

89
00:05:22,960 --> 00:05:23,960
Yeah.

90
00:05:23,960 --> 00:05:24,960
We were in ROTC together.

91
00:05:24,960 --> 00:05:30,560
James was doing the band and the newspaper and I was a member of that and we were just

92
00:05:30,560 --> 00:05:31,560
all over the place.

93
00:05:31,560 --> 00:05:36,040
We had ones in Bangkok.

94
00:05:36,040 --> 00:05:39,040
Bernie never went, but I don't, I don't, we don't talk about that.

95
00:05:39,040 --> 00:05:40,040
I know.

96
00:05:40,040 --> 00:05:41,040
Yeah.

97
00:05:41,040 --> 00:05:42,040
Nice.

98
00:05:42,040 --> 00:05:43,640
This is an opportunity for us to work together.

99
00:05:43,640 --> 00:05:44,640
Yeah.

100
00:05:44,640 --> 00:05:45,640
Finally.

101
00:05:45,640 --> 00:05:46,640
Awesome.

102
00:05:46,640 --> 00:05:47,640
Awesome.

103
00:05:47,640 --> 00:05:48,640
And so Mt.

104
00:05:48,640 --> 00:05:49,640
Cleverist.

105
00:05:49,640 --> 00:05:50,640
I love the name.

106
00:05:50,640 --> 00:05:52,240
It's actually rather clever.

107
00:05:52,240 --> 00:05:53,800
What does the company do?

108
00:05:53,800 --> 00:05:56,280
So we actually started the company kind of based off an idea.

109
00:05:56,280 --> 00:05:59,560
We had seven, some seven years ago.

110
00:05:59,560 --> 00:06:00,680
My parents are both teachers.

111
00:06:00,680 --> 00:06:04,320
I actually still teach at UVA part-time, cybersecurity.

112
00:06:04,320 --> 00:06:09,200
And what we realized is that growing up, I see my parents deal with kind of bad textbooks,

113
00:06:09,200 --> 00:06:13,000
that kind of handed down to them from the administration that they had to kind of bend

114
00:06:13,000 --> 00:06:15,000
to meet the needs of the classroom.

115
00:06:15,000 --> 00:06:18,440
And we were iterating through ideas and that was the one that I said, no, like if we could

116
00:06:18,440 --> 00:06:21,960
figure out a way to solve this, like this would be really valuable because my parents

117
00:06:21,960 --> 00:06:24,160
just always were complaining about it.

118
00:06:24,160 --> 00:06:27,960
So we didn't really quite know the approach yet and we didn't have necessarily the NLP

119
00:06:27,960 --> 00:06:30,480
and machine learning skills to really tackle it yet.

120
00:06:30,480 --> 00:06:34,080
But as the industry has grown and kind of our skills have grown, we said, okay, this is

121
00:06:34,080 --> 00:06:35,680
something we can apply.

122
00:06:35,680 --> 00:06:39,520
NLP, machine learning, neural nets, and solve this kind of selection problem.

123
00:06:39,520 --> 00:06:45,680
So what Mount Clevrist does is we can take any content on the web, URL, piece of text,

124
00:06:45,680 --> 00:06:49,640
and then generate quiz questions on the fly on that text in a matter of seconds.

125
00:06:49,640 --> 00:06:53,240
And then the kind of the real advantage, though, is not just creating the questions.

126
00:06:53,240 --> 00:06:55,840
But after that, we track every interaction with that quiz.

127
00:06:55,840 --> 00:06:59,840
What students get wrong, what they get right, how long they take with each question.

128
00:06:59,840 --> 00:07:03,480
What questions and answers teachers like and don't like, what they want to use, feed

129
00:07:03,480 --> 00:07:08,200
that into a neural net that then improves the system, improves the quiz for the next person.

130
00:07:08,200 --> 00:07:12,120
So it's actually really at the end of the day, it ends up being one big online textbook

131
00:07:12,120 --> 00:07:16,000
that actually improves itself the more you use it.

132
00:07:16,000 --> 00:07:17,000
Interesting.

133
00:07:17,000 --> 00:07:18,000
Interesting.

134
00:07:18,000 --> 00:07:24,520
And so I'm familiar with the, there's a ton of research happening around question answering,

135
00:07:24,520 --> 00:07:28,360
which is, you know, you have a body of text, you kind of start with some questions and

136
00:07:28,360 --> 00:07:32,120
then you use AI machine learning to try to answer those questions.

137
00:07:32,120 --> 00:07:37,240
You've kind of inverted that and you're using AI to generate the questions, as well as

138
00:07:37,240 --> 00:07:42,040
the answers and track the kind of track and adjust over time.

139
00:07:42,040 --> 00:07:47,160
Is that as established a research area, the question asking piece?

140
00:07:47,160 --> 00:07:49,160
Not so much.

141
00:07:49,160 --> 00:07:54,560
I mean, a few years ago, there were very few papers, at least now there are some interesting

142
00:07:54,560 --> 00:07:58,240
work being done, but again, nothing substantial because a lot of it has been driven by kind

143
00:07:58,240 --> 00:08:04,000
of the question answering Alexa, kind of Siri approach to machine learning.

144
00:08:04,000 --> 00:08:09,160
What the question that has, or that what has been tackled in machine learning is this idea

145
00:08:09,160 --> 00:08:12,760
of taking a mass amount of text and figuring out a good question, come around it, kind

146
00:08:12,760 --> 00:08:13,760
of the Watson model.

147
00:08:13,760 --> 00:08:14,760
Okay, Jeopardy.

148
00:08:14,760 --> 00:08:18,360
So being able to parse mass amounts of text and generate one question, maybe a very well-formed

149
00:08:18,360 --> 00:08:20,720
question, but it's one question.

150
00:08:20,720 --> 00:08:25,360
Our problem and the really kind of the heart of our tech is that we take a very limited

151
00:08:25,360 --> 00:08:31,040
amount of text and be able to generate 100, 120 questions off of one piece of text, each

152
00:08:31,040 --> 00:08:32,920
asking about something different.

153
00:08:32,920 --> 00:08:36,600
Then the kind of extra level of difficulty is then great, you've got a question, you've

154
00:08:36,600 --> 00:08:38,520
got an answer that you've drawn out.

155
00:08:38,520 --> 00:08:40,440
How do I generate good, wrong answers?

156
00:08:40,440 --> 00:08:45,160
How do I find a question or an answer that is a good distractor from the correct answer?

157
00:08:45,160 --> 00:08:47,960
So I put a multiple choice question in front of a kid.

158
00:08:47,960 --> 00:08:51,640
If it's so close to the right answer that it's confusing, that's bad.

159
00:08:51,640 --> 00:08:55,320
If it's so far away that they would never guess it anyway, it's also bad.

160
00:08:55,320 --> 00:08:59,840
So you've got to find the kind of that Goldilocks middle ground on kind of good distractors.

161
00:08:59,840 --> 00:09:02,960
And that was really probably the heart of the NLP problem.

162
00:09:02,960 --> 00:09:08,320
I'm imagining like a dial where you can kind of tune the question for difficulty or I

163
00:09:08,320 --> 00:09:12,720
guess a big part of the neural net piece that you described is about kind of normalizing

164
00:09:12,720 --> 00:09:18,920
the question answer set so that your kind of average ends up where you want it to be.

165
00:09:18,920 --> 00:09:20,480
Is that a good way to think about it?

166
00:09:20,480 --> 00:09:25,120
Yeah, so we can actually look at kind of the readability of the text or kind of industry

167
00:09:25,120 --> 00:09:29,400
standard scoring mechanism to take a chunk of text and figure out what grade levels this

168
00:09:29,400 --> 00:09:30,400
would be appropriate for.

169
00:09:30,400 --> 00:09:34,560
So the origin text, we can actually kind of guess at what good, what these questions are

170
00:09:34,560 --> 00:09:37,960
going to come out kind of referring to in terms of like is this a fifth grade text or

171
00:09:37,960 --> 00:09:39,040
is this a seventh grade text.

172
00:09:39,040 --> 00:09:43,040
We're actually working on some tech to be able to convert something that is maybe written

173
00:09:43,040 --> 00:09:46,960
at a 12th grade level down to a ninth grade level and then kind of use questions that are

174
00:09:46,960 --> 00:09:48,240
more appropriate for that.

175
00:09:48,240 --> 00:09:50,240
That's kind of in a coming release.

176
00:09:50,240 --> 00:09:55,520
But yeah, it's being able to correctly pick questions that are appropriate for grade

177
00:09:55,520 --> 00:10:00,480
level and answers that are appropriate for a grade level is a whole layer of complexity

178
00:10:00,480 --> 00:10:04,040
that a lot of other, you know, tech solutions don't really think about, but it's unique

179
00:10:04,040 --> 00:10:05,520
to the education space.

180
00:10:05,520 --> 00:10:06,520
Okay.

181
00:10:06,520 --> 00:10:13,200
I think of educators as folks that kind of want to have a lot of control over their source

182
00:10:13,200 --> 00:10:14,200
materials.

183
00:10:14,200 --> 00:10:19,640
Like how does this approach land for them relative to what they're used to?

184
00:10:19,640 --> 00:10:22,360
So we're kind of taking this problem in two different ways.

185
00:10:22,360 --> 00:10:27,200
The first is the initial product allows a teacher to bring in whatever content they would

186
00:10:27,200 --> 00:10:28,200
like.

187
00:10:28,200 --> 00:10:32,280
So if they found a news article that is exciting and relates to their class or if they

188
00:10:32,280 --> 00:10:37,000
have a page that they've been using and sending students to for years instead of having

189
00:10:37,000 --> 00:10:42,400
that all based on paper in terms of the grading, we're actually pulling that in and tracking

190
00:10:42,400 --> 00:10:43,640
that information.

191
00:10:43,640 --> 00:10:47,840
On the other side, there's a search component that you kind of brought into it and we're

192
00:10:47,840 --> 00:10:52,960
working towards it, that is the broader vision of having a collection, a universe of content

193
00:10:52,960 --> 00:10:54,760
and then being able to rank and sort that.

194
00:10:54,760 --> 00:10:57,760
So there's the create problem and then there's the ranking and sorting.

195
00:10:57,760 --> 00:10:59,800
So we kind of split those intentionally.

196
00:10:59,800 --> 00:11:02,880
The control issue, it's something we want to get into.

197
00:11:02,880 --> 00:11:07,600
We know that it's a political battle in the lightest of terms because it's not true

198
00:11:07,600 --> 00:11:10,280
politics, but yes, that is something that we see often.

199
00:11:10,280 --> 00:11:15,440
So we're coming up with ways to either encourage behavior in a certain way to kind of let

200
00:11:15,440 --> 00:11:20,120
go of that, including automatic randomization of questions or adding in questions from

201
00:11:20,120 --> 00:11:23,600
a different source that are applicable to the source that was provided.

202
00:11:23,600 --> 00:11:28,840
So we're actually swapping in new information and using that as part of the quiz for students.

203
00:11:28,840 --> 00:11:34,560
So it's not a standardization, but it's instead a way for us to help determine the quality

204
00:11:34,560 --> 00:11:37,200
of content as well as the students understand.

205
00:11:37,200 --> 00:11:39,720
And so there's kind of a couple of different problems there.

206
00:11:39,720 --> 00:11:45,400
There's also a distinction in education between formative assessment and somewhat of assessment.

207
00:11:45,400 --> 00:11:50,200
And this idea that teachers get really kind of close hold on exams because they want to

208
00:11:50,200 --> 00:11:54,480
be able to kind of assign really clear grades and hold those students accountable and make

209
00:11:54,480 --> 00:11:57,560
sure they can kind of deal with parents that disagree with those grades.

210
00:11:57,560 --> 00:11:59,520
They have to have kind of a clear, clear chain.

211
00:11:59,520 --> 00:12:04,160
But what has been kind of lost is this idea of this formative assessment that I want

212
00:12:04,160 --> 00:12:08,400
to have homework that a kid can try over and over again until they get it right because

213
00:12:08,400 --> 00:12:12,280
I'm actually interested in them learning it, not just grading on their first guess.

214
00:12:12,280 --> 00:12:16,400
So what Mount Clevver says really focuses on is kind of trying to get the teacher to

215
00:12:16,400 --> 00:12:21,120
not think about the quiz that we are providing as summative, as yet you're going to get grades

216
00:12:21,120 --> 00:12:22,880
and this is going to account to the report card.

217
00:12:22,880 --> 00:12:27,560
But more of a, get good questions in front of the kid to make sure that they understand

218
00:12:27,560 --> 00:12:31,560
the content and they can take that quiz as many times as possible until they really grasp

219
00:12:31,560 --> 00:12:32,560
it or master it.

220
00:12:32,560 --> 00:12:33,560
Okay.

221
00:12:33,560 --> 00:12:37,280
Can you talk a little bit about the pipeline that you used to deliver this from a machine

222
00:12:37,280 --> 00:12:38,600
learning perspective?

223
00:12:38,600 --> 00:12:39,600
Yeah.

224
00:12:39,600 --> 00:12:44,720
It's, it's funny because we get a lot of, we get a lot of questions about like, oh,

225
00:12:44,720 --> 00:12:49,360
we can't, like, can't, can't just be done by a machine learning model off the shelf.

226
00:12:49,360 --> 00:12:55,080
And yes and no, in the sense that, in the sense that we are using some kind of, you know,

227
00:12:55,080 --> 00:13:00,520
some basic, you know, basic kind of industry tried and true NLP models and neural nets.

228
00:13:00,520 --> 00:13:01,520
What are some of those?

229
00:13:01,520 --> 00:13:06,080
I mean, we are leveraging a lot of NER for a name that's a recognition using some kind

230
00:13:06,080 --> 00:13:10,280
of interesting, interesting math around word vectors, what do I call like the donut model

231
00:13:10,280 --> 00:13:13,320
saying, okay, I want to find similar words, but then, like, go up and then remove the

232
00:13:13,320 --> 00:13:17,360
word that are really similar to find those kind of, again, the Goldilocks distractors.

233
00:13:17,360 --> 00:13:19,840
So those are kind of the approaches that we're doing in the neural nets.

234
00:13:19,840 --> 00:13:23,560
We're trying lots of different things because that part of the product is still kind

235
00:13:23,560 --> 00:13:27,840
of not nascent, but we're getting there, so we're still kind of refining that.

236
00:13:27,840 --> 00:13:31,520
But the pipeline itself, actually, what's interesting about Mount Cleverist is that it's not

237
00:13:31,520 --> 00:13:37,400
just one huge big model with a model, is that we have to build, you know, an NLP that

238
00:13:37,400 --> 00:13:41,240
can generate, you know, dozens of types of questions, so each one has its own kind of

239
00:13:41,240 --> 00:13:42,240
pipeline.

240
00:13:42,240 --> 00:13:46,320
She's that into a unified data structure, but then we have to normalize questions against

241
00:13:46,320 --> 00:13:49,360
questions, answers against answers, formats against formats.

242
00:13:49,360 --> 00:13:53,440
So even within the ranking system, within one lesson, within one subject, we might have

243
00:13:53,440 --> 00:13:58,680
a whole series of models, each, again, not necessarily huge, robust, crazy big models,

244
00:13:58,680 --> 00:14:01,680
but each doing is a unique specific thing.

245
00:14:01,680 --> 00:14:02,680
Live right on that.

246
00:14:02,680 --> 00:14:06,280
What do you mean by normalizing questions against questions, and are we talking about in terms

247
00:14:06,280 --> 00:14:08,320
of their difficulty and things like that?

248
00:14:08,320 --> 00:14:09,320
Right.

249
00:14:09,320 --> 00:14:14,240
So in terms of their difficulty, so imagine you're a teacher and you've created a lesson,

250
00:14:14,240 --> 00:14:18,000
and you want to, like, we've generated, let's say, a hundred quiz questions.

251
00:14:18,000 --> 00:14:20,960
Now some of those are not going to be great because the NLP isn't perfect.

252
00:14:20,960 --> 00:14:23,280
No, we don't know many products that are perfect.

253
00:14:23,280 --> 00:14:25,560
So we want that kind of human and the loop feedback.

254
00:14:25,560 --> 00:14:28,840
So we are capturing, kind of, what, you know, the upvotes and downvotes similar to kind

255
00:14:28,840 --> 00:14:33,280
of Reddit of what teachers like and don't like, but at the question at the answer level.

256
00:14:33,280 --> 00:14:36,720
So we get that, just that base level, kind of, like, how many people have upvoted, how

257
00:14:36,720 --> 00:14:39,720
many people have liked or disliked this particular piece.

258
00:14:39,720 --> 00:14:42,040
But then we've got this kind of student performance data on the back end.

259
00:14:42,040 --> 00:14:46,600
So okay, well, when I showed this question in this format, in this context, like, this

260
00:14:46,600 --> 00:14:48,920
is how well a student did, given how long they took.

261
00:14:48,920 --> 00:14:52,920
So normalizing that data means that I have to take every interaction with every question

262
00:14:52,920 --> 00:14:56,840
or format or answer, and then trying to figure out, okay, even though this question has

263
00:14:56,840 --> 00:15:01,200
been shown to, you know, 10 different students in 10 different ways, how do I judge its effectiveness?

264
00:15:01,200 --> 00:15:04,800
Is this a good measure of learning on this particular topic?

265
00:15:04,800 --> 00:15:07,120
So like, that's the normalization that we're talking about.

266
00:15:07,120 --> 00:15:12,960
And is that, like, some big batch job that runs every X day or week or something, or

267
00:15:12,960 --> 00:15:16,960
is it something that you just kind of trigger it's erratically?

268
00:15:16,960 --> 00:15:22,520
So we've actually made kind of a goal of the product to not do things in batch.

269
00:15:22,520 --> 00:15:26,120
Which was, it was a bold goal, it may slow this down a little bit.

270
00:15:26,120 --> 00:15:30,120
But we actually wanted, we set the goal from the user experience levels that we wanted

271
00:15:30,120 --> 00:15:33,320
the quiz to improve on a, like, per interaction basis.

272
00:15:33,320 --> 00:15:39,920
So like, every time a kid answers a question, exactly, it re-jiggers the entire, re-, does

273
00:15:39,920 --> 00:15:40,920
that mean-

274
00:15:40,920 --> 00:15:45,040
So by the time the second student sees the quiz, it's actually improved and changed and

275
00:15:45,040 --> 00:15:47,520
learned from the results of the first student.

276
00:15:47,520 --> 00:15:53,840
And is that learning, does that mean that you are, like, retraining models in that whole

277
00:15:53,840 --> 00:15:54,840
pipeline?

278
00:15:54,840 --> 00:15:55,840
Or does it mean that-

279
00:15:55,840 --> 00:15:59,200
Are there some set of heuristics that you're using to kind of massage weights or things

280
00:15:59,200 --> 00:16:01,360
like that without having to retrain all your models?

281
00:16:01,360 --> 00:16:02,360
A bit of both.

282
00:16:02,360 --> 00:16:06,080
So we don't retrain the model every run through, though we do have some kind of tail-trained

283
00:16:06,080 --> 00:16:07,200
models kind of worked in.

284
00:16:07,200 --> 00:16:11,280
But most of it is capturing kind of the heuristics of the performance with those questions in

285
00:16:11,280 --> 00:16:12,600
this format.

286
00:16:12,600 --> 00:16:16,680
And capturing that and then feeding that back in as additional information into the model

287
00:16:16,680 --> 00:16:19,960
as we then kind of randomize and select what we want to do and what we want to show to

288
00:16:19,960 --> 00:16:21,400
the second student.

289
00:16:21,400 --> 00:16:25,440
So it's the heuristics of the first student fed back into the same model, tail-trained

290
00:16:25,440 --> 00:16:29,200
a couple pieces, and then kind of what you get, we're like, oh, tried this version of

291
00:16:29,200 --> 00:16:32,880
this content, or this version of this question with these answers in this format instead

292
00:16:32,880 --> 00:16:36,840
of the old one because that old version, it wasn't a great test, but this one might

293
00:16:36,840 --> 00:16:37,840
be.

294
00:16:37,840 --> 00:16:40,920
So it's a little bit of randomization, a little bit of kind of design of experiments,

295
00:16:40,920 --> 00:16:44,520
constantly trying to say, okay, how, you know, reduce how many experiments or variations

296
00:16:44,520 --> 00:16:47,200
do we need to run before we figure out what the best stuff is?

297
00:16:47,200 --> 00:16:48,200
Okay.

298
00:16:48,200 --> 00:16:54,760
And in terms of identifying the target content in the first place, is that are the educators,

299
00:16:54,760 --> 00:17:00,240
you know, feeding URLs into the system to direct you, or are you doing some ML, German,

300
00:17:00,240 --> 00:17:04,480
crawling, or something like that to figure out the interesting content out there?

301
00:17:04,480 --> 00:17:08,680
At the moment, we're relying on the, what we consider the expert networks of teachers.

302
00:17:08,680 --> 00:17:12,960
So we want the educators to be the one providing content that they have used in the past, and

303
00:17:12,960 --> 00:17:17,000
then we'll be doing that ranking in order to help them either bubble up what is better,

304
00:17:17,000 --> 00:17:20,240
or take advantage of the stuff that they've tried in true sources.

305
00:17:20,240 --> 00:17:24,880
So a lot of the open educational resources movement from the Obama administration has been

306
00:17:24,880 --> 00:17:25,880
very helpful in that.

307
00:17:25,880 --> 00:17:31,200
And a lot of institutions, as well as a lot of individuals, are now providing content

308
00:17:31,200 --> 00:17:36,200
openly available under Creative Commons license, or MIT license, whatever it might be, is

309
00:17:36,200 --> 00:17:40,880
now available to us and not behind the paywall, not under the umbrella of one of the large

310
00:17:40,880 --> 00:17:42,640
publishers or anything like that.

311
00:17:42,640 --> 00:17:45,480
So it's taking advantage of that recent trend.

312
00:17:45,480 --> 00:17:46,480
Okay.

313
00:17:46,480 --> 00:17:47,480
Interesting.

314
00:17:47,480 --> 00:17:51,480
What have been kind of the biggest challenges in pulling this all together?

315
00:17:51,480 --> 00:17:55,040
Well, I think that the biggest challenge was designing that data structure.

316
00:17:55,040 --> 00:17:59,920
So again, we have all of these different models, all looking at essentially the same data,

317
00:17:59,920 --> 00:18:03,800
and how you store that, and how you store that in a way that can be kind of lightweight,

318
00:18:03,800 --> 00:18:07,200
pulled in the moment, you know, in between quiz questions.

319
00:18:07,200 --> 00:18:10,440
That was something that I think both of us had to kind of take a step back and say,

320
00:18:10,440 --> 00:18:17,680
how do we store this data at scale, but as we're small, but also at scale, kind of building

321
00:18:17,680 --> 00:18:22,200
towards this bigger architecture, being able to track what I like to call kind of the context

322
00:18:22,200 --> 00:18:26,440
mapping, that it was this version of the question with these answers shown, like maybe there

323
00:18:26,440 --> 00:18:30,520
are 10 wrong answers, but we only showed four, and it was a true false or a multiple choice

324
00:18:30,520 --> 00:18:32,400
with the none of the above, not this.

325
00:18:32,400 --> 00:18:37,920
So being able to capture all that context, and store that, and then correctly tease it

326
00:18:37,920 --> 00:18:40,320
out, and then build a model against it.

327
00:18:40,320 --> 00:18:44,600
Turning out what that included, and how to put all the pieces of data together.

328
00:18:44,600 --> 00:18:45,600
That was interesting.

329
00:18:45,600 --> 00:18:52,680
We have a model in the tool called a quinstance, which is a quiz instance, because we've got

330
00:18:52,680 --> 00:18:57,080
to generate a quiz, and it might have teacher preferences at one given moment, but then

331
00:18:57,080 --> 00:19:01,640
within that quiz, within the context, we need to have an individualized version for each

332
00:19:01,640 --> 00:19:04,600
student that they experience at that moment in time.

333
00:19:04,600 --> 00:19:06,400
It's like, how do we further that?

334
00:19:06,400 --> 00:19:08,080
It's a quiz, but that's also a quiz.

335
00:19:08,080 --> 00:19:12,360
So it's quinstance became our term, and it's been great.

336
00:19:12,360 --> 00:19:15,560
But we have a lot of those little things that we have to figure out on the way that we

337
00:19:15,560 --> 00:19:20,400
have to structure this and store this in a unique way that I think gives us an advantage

338
00:19:20,400 --> 00:19:23,800
in the market that I think other people have really thought about data for education this

339
00:19:23,800 --> 00:19:24,800
way yet.

340
00:19:24,800 --> 00:19:28,160
And so for folks that are like, how did you approach that problem?

341
00:19:28,160 --> 00:19:32,000
Did you just stumble upon the answer, or did you just try out everything that was out

342
00:19:32,000 --> 00:19:35,800
there and see what worked, and like, what did you end up doing?

343
00:19:35,800 --> 00:19:36,800
These are so-or-subject.

344
00:19:36,800 --> 00:19:41,880
Oh man, flashbacks.

345
00:19:41,880 --> 00:19:47,520
I actually, when we first started trying to build this, I was just like a, you know, a budding

346
00:19:47,520 --> 00:19:48,520
web developer.

347
00:19:48,520 --> 00:19:53,600
I actually built the whole tool without a lot of the neural nets I hadn't quite gotten

348
00:19:53,600 --> 00:19:54,600
there yet.

349
00:19:54,600 --> 00:19:58,120
But I built my own kind of parsing engine and NLP engine out of PHP, because it was the

350
00:19:58,120 --> 00:19:59,360
only language I knew.

351
00:19:59,360 --> 00:20:01,920
Right, so I had a lot of lessons learned.

352
00:20:01,920 --> 00:20:05,520
Right, so it was a terrible, terrible idea.

353
00:20:05,520 --> 00:20:08,120
I think, on the front end, it was like a Drupal 6.

354
00:20:08,120 --> 00:20:09,120
It was.

355
00:20:09,120 --> 00:20:10,120
Right, exactly.

356
00:20:10,120 --> 00:20:13,800
Not out of these moments, but like, it was a learning experience.

357
00:20:13,800 --> 00:20:14,800
But exactly.

358
00:20:14,800 --> 00:20:18,200
And like, I got 10 times better as a developer, and it's like, it jumps under, I think,

359
00:20:18,200 --> 00:20:20,360
a lot of my career just being, having to suffer through that.

360
00:20:20,360 --> 00:20:24,080
So having a really good problem to chew on for a long time.

361
00:20:24,080 --> 00:20:26,560
And then I eventually said, OK, well, no, Python is better for this.

362
00:20:26,560 --> 00:20:28,560
There's Java libraries that I can incorporate.

363
00:20:28,560 --> 00:20:30,480
I need to stand up microservices architectures.

364
00:20:30,480 --> 00:20:34,160
Right now, we have, I think, 14 different microservices, each running even different parts

365
00:20:34,160 --> 00:20:37,640
of the models, all talking to each other, leveraging the same data set, caching some parts

366
00:20:37,640 --> 00:20:38,640
here and there.

367
00:20:38,640 --> 00:20:42,640
So I mean, but I had to learn that kind of all on my own, starting with that poor, poor

368
00:20:42,640 --> 00:20:43,640
Drupal site.

369
00:20:43,640 --> 00:20:47,000
But yeah, that's, that's, is, is trial and error could have been more press.

370
00:20:47,000 --> 00:20:54,040
It, it, it, it, it almost was, I thought it was a band when I found Lyravelle.

371
00:20:54,040 --> 00:20:57,920
I was like, oh man, it's not Drupal, but, yeah.

372
00:20:57,920 --> 00:21:02,280
And in terms of the data store, did you like, is it like some kind of document oriented

373
00:21:02,280 --> 00:21:07,520
MongoDB type of thing or like a Cassandra or what direction did you go?

374
00:21:07,520 --> 00:21:11,440
We actually, because we didn't really know what we were doing, and I think that's actually

375
00:21:11,440 --> 00:21:15,600
a great use case for Mongo is that it's a kind of a turnkey solution and you can kind

376
00:21:15,600 --> 00:21:17,240
of drop in whatever you want.

377
00:21:17,240 --> 00:21:19,960
And then there are a lot of kind of lightweight ORMs on top of it.

378
00:21:19,960 --> 00:21:22,320
So you can change the model and it doesn't break everything.

379
00:21:22,320 --> 00:21:24,560
You just have to go back and kind of clean some stuff later.

380
00:21:24,560 --> 00:21:28,920
So we've been doing Mongo for probably the last year as we kind of moved to a more production

381
00:21:28,920 --> 00:21:33,280
level product, but we've now hit the wall or think, okay, the type, you know, the model

382
00:21:33,280 --> 00:21:34,520
types have kind of settled.

383
00:21:34,520 --> 00:21:35,880
We kind of know what our structure is.

384
00:21:35,880 --> 00:21:37,520
We know what it needs to be.

385
00:21:37,520 --> 00:21:38,520
We've thought it out.

386
00:21:38,520 --> 00:21:41,000
We've been in the wild and see what happened.

387
00:21:41,000 --> 00:21:43,680
So now we're actually moving to kind of a combination of things.

388
00:21:43,680 --> 00:21:48,200
Probably some kind of Mongo or other, you know, no SQL database for a lot of the document

389
00:21:48,200 --> 00:21:49,200
structure.

390
00:21:49,200 --> 00:21:53,680
And then probably Cassandra for a lot of the, like the interactions, the, in the moment

391
00:21:53,680 --> 00:21:57,440
interactions because it's ability to scale kind of linearly where everyone else kind

392
00:21:57,440 --> 00:22:00,360
of stops at a certain certain point.

393
00:22:00,360 --> 00:22:01,360
So yeah.

394
00:22:01,360 --> 00:22:03,960
So we were, I'm really excited to move to Cassandra, but Cassandra, you know, also has some,

395
00:22:03,960 --> 00:22:06,800
you know, issues around search, you got to, you got to figure out how to get searched

396
00:22:06,800 --> 00:22:07,800
on.

397
00:22:07,800 --> 00:22:10,120
So there's a lot of other, you know, different ways looking at, you know, postgres for

398
00:22:10,120 --> 00:22:12,520
other certain features because you can index and search there.

399
00:22:12,520 --> 00:22:14,960
So we're actually moving to a more complex model.

400
00:22:14,960 --> 00:22:19,200
But again, each database has to fit a different part of the system.

401
00:22:19,200 --> 00:22:23,040
And we now know how that system really needs to, like, be set up to, you know, run at

402
00:22:23,040 --> 00:22:24,040
light speed.

403
00:22:24,040 --> 00:22:25,040
Okay.

404
00:22:25,040 --> 00:22:30,000
So given that you're doing kind of the interactive updating and all that kind of stuff, I'm assuming

405
00:22:30,000 --> 00:22:35,560
that's not so PHP, is that like so far or it is almost like there's a little bit of

406
00:22:35,560 --> 00:22:39,960
Python on the back end, some Java libraries that haven't like written, but kind of leveraging

407
00:22:39,960 --> 00:22:41,120
some open source stuff.

408
00:22:41,120 --> 00:22:45,760
But primarily the entire stack has written in JavaScript, leveraging Amazon Lambda and

409
00:22:45,760 --> 00:22:47,040
then react to the front end.

410
00:22:47,040 --> 00:22:53,200
So we have made this is a if, you know, the heavens opened up and, and to God said, yes,

411
00:22:53,200 --> 00:22:57,760
please like go use this product and we had massive scale that we are set up to, you know,

412
00:22:57,760 --> 00:22:58,760
I assume handle it.

413
00:22:58,760 --> 00:22:59,760
Scale breaks everything.

414
00:22:59,760 --> 00:23:02,920
But we knew that there was going to be so much compute that we wanted to make sure we

415
00:23:02,920 --> 00:23:05,000
could kind of turn every little lever.

416
00:23:05,000 --> 00:23:09,040
So all those microservices are, most of them are speaking, you know, Lambda to each other.

417
00:23:09,040 --> 00:23:13,440
And it also means that the models are lightweight enough in some respects that we can offload

418
00:23:13,440 --> 00:23:16,080
some of that model computation to the browser.

419
00:23:16,080 --> 00:23:18,360
So we have this JavaScript written neural nets.

420
00:23:18,360 --> 00:23:23,800
So I can actually load some of the early computation onto the computer for the teacher or the user

421
00:23:23,800 --> 00:23:27,800
or the phone and then do the computation and just pass back the results and kind of offload

422
00:23:27,800 --> 00:23:30,800
a good 20 to 30% of our load back onto the user.

423
00:23:30,800 --> 00:23:33,680
So we're not doing it now, but we are set up to do that eventually.

424
00:23:33,680 --> 00:23:34,680
Oh, wow.

425
00:23:34,680 --> 00:23:40,080
And are you using any particular open source library to do the front end inference?

426
00:23:40,080 --> 00:23:42,360
Oh, I want to do right that yourself.

427
00:23:42,360 --> 00:23:47,560
No, that's a combination of synaptic, I think synaptic.js was the one reason right now.

428
00:23:47,560 --> 00:23:49,480
And that is, there have been many variations.

429
00:23:49,480 --> 00:23:51,960
I think the first one we used was called brain.

430
00:23:51,960 --> 00:23:56,080
There's a lot of JavaScript libraries that are just coming out where they said, I want

431
00:23:56,080 --> 00:23:58,360
to write JavaScript and I want to do neural nets.

432
00:23:58,360 --> 00:24:00,480
And they can do some pretty cool things on the browser.

433
00:24:00,480 --> 00:24:04,320
Not necessarily the big scale stuff that we want to do on some of our calculations, but

434
00:24:04,320 --> 00:24:07,880
a lot of the smaller, like within a document, within a document, you could have known

435
00:24:07,880 --> 00:24:11,200
document space, we can do that on the browser side and we're, you know, going to shift

436
00:24:11,200 --> 00:24:12,600
to that model later.

437
00:24:12,600 --> 00:24:13,600
Hmm.

438
00:24:13,600 --> 00:24:14,600
Interesting.

439
00:24:14,600 --> 00:24:18,960
I'm trying to think through the way I've envisioned your process.

440
00:24:18,960 --> 00:24:23,560
You get these documents, you're doing a bunch of what I think of as backend processing

441
00:24:23,560 --> 00:24:28,320
to come up with questions and answers and normalize them and all that kind of stuff.

442
00:24:28,320 --> 00:24:32,680
What would you want to do on the front end that would require, you know, running the inference

443
00:24:32,680 --> 00:24:36,040
locally or would take advantage of that if not required?

444
00:24:36,040 --> 00:24:39,840
So the first thing you do kind of as a user is you drop in the URL, eventually it'll

445
00:24:39,840 --> 00:24:43,440
be search term or URL, but right now we're focused on kind of new content capture.

446
00:24:43,440 --> 00:24:48,600
You drop into URL and then immediately we go scrape that content from that URL and then

447
00:24:48,600 --> 00:24:49,600
start parsing it.

448
00:24:49,600 --> 00:24:52,440
And a lot of that parsing work right now we're handling the backend, but it can be handled

449
00:24:52,440 --> 00:24:53,440
by the browser.

450
00:24:53,440 --> 00:24:54,440
Oh, got it.

451
00:24:54,440 --> 00:24:55,440
Right.

452
00:24:55,440 --> 00:24:58,000
So that is actually a big portion of the compute because it's a lot of parsing.

453
00:24:58,000 --> 00:25:02,320
But if that can be off offload instead of 10 people doing it all on one of our machines

454
00:25:02,320 --> 00:25:06,440
or a series of Lambda functions, but pushing that to the browser, because that's kind of,

455
00:25:06,440 --> 00:25:09,800
it's not proprietary stuff, it's not crazy, you know, complicated, but it just needs to

456
00:25:09,800 --> 00:25:10,800
get done.

457
00:25:10,800 --> 00:25:13,800
Someone needs to pull out, you know, named entities, someone needs to, you know, to

458
00:25:13,800 --> 00:25:16,960
break, do sentence barrier detection, all that stuff can be handled, then we just want

459
00:25:16,960 --> 00:25:17,960
the results.

460
00:25:17,960 --> 00:25:21,840
And then we get to kind of the nitty gritty of the data on the backend.

461
00:25:21,840 --> 00:25:26,200
It strikes me that if a lot of folks aren't doing that now, that's going to be kind of

462
00:25:26,200 --> 00:25:30,400
a popular way to do cooperative compute.

463
00:25:30,400 --> 00:25:34,120
It's almost like, you know, having your users, you know, mine Bitcoin for you before the

464
00:25:34,120 --> 00:25:41,120
legitimate link.

465
00:25:41,120 --> 00:25:42,120
Right.

466
00:25:42,120 --> 00:25:43,120
The only other industry that I know is really doing that is Bitcoin and not, you know, like,

467
00:25:43,120 --> 00:25:49,560
oh, like, my advertising window is mining Bitcoin for someone in the Ukraine, so, yeah.

468
00:25:49,560 --> 00:25:52,560
But I was like, okay, well, how, like, when I read that, I was like, that's a really cool

469
00:25:52,560 --> 00:25:53,560
architecture.

470
00:25:53,560 --> 00:25:56,480
And like, we'd already been kind of thinking about this as like, oh, so like someone's

471
00:25:56,480 --> 00:25:58,000
proving that this is doable.

472
00:25:58,000 --> 00:26:01,760
So it was kind of a check in the box with, yes, this is maybe where architecture should

473
00:26:01,760 --> 00:26:02,760
go.

474
00:26:02,760 --> 00:26:06,600
And it strikes me that that could be a startup in and of itself, right?

475
00:26:06,600 --> 00:26:10,680
So there's an architecture because there's all kinds of problems that you can run into

476
00:26:10,680 --> 00:26:15,240
of like, you know, the process is stealing all the compute and usability issues and stuff

477
00:26:15,240 --> 00:26:16,240
like that.

478
00:26:16,240 --> 00:26:17,240
Yeah.

479
00:26:17,240 --> 00:26:19,200
If we figure that out, then we can shift to maybe that'll be our second business once we

480
00:26:19,200 --> 00:26:20,200
sell this.

481
00:26:20,200 --> 00:26:21,200
Yeah.

482
00:26:21,200 --> 00:26:22,200
Nice.

483
00:26:22,200 --> 00:26:27,080
You know, given all that, all that technology, like, there's tons of folks, particularly

484
00:26:27,080 --> 00:26:31,640
here in New York City, right, doing ed tech, what makes you different.

485
00:26:31,640 --> 00:26:34,600
So we've been, you know, been doing this project for a long time.

486
00:26:34,600 --> 00:26:38,080
So we've been watching the ed tech market when the booms and busts thing were on the third

487
00:26:38,080 --> 00:26:40,800
boom right now that we've been paying attention to.

488
00:26:40,800 --> 00:26:44,120
And we keep seeing investors getting burned and mostly because they keep investing kind

489
00:26:44,120 --> 00:26:47,240
of this, what seems like a really cool new thing.

490
00:26:47,240 --> 00:26:50,880
But in reality, it falls into kind of like two standard business models.

491
00:26:50,880 --> 00:26:54,520
One we call it kind of a warehouse model, which is just collect as much information as possible

492
00:26:54,520 --> 00:26:56,040
and then make it searchable.

493
00:26:56,040 --> 00:27:00,440
But if you look at some of the products out there, you find that those, the search algorithms

494
00:27:00,440 --> 00:27:02,080
are poor at best.

495
00:27:02,080 --> 00:27:04,760
And they're not searching on like real performance data, just keywords.

496
00:27:04,760 --> 00:27:08,200
So you end up getting like a big warehouse and you'll search for the War of 1812, for

497
00:27:08,200 --> 00:27:10,680
example, you get 342 results.

498
00:27:10,680 --> 00:27:14,280
I'm not speaking about any product, particularly.

499
00:27:14,280 --> 00:27:18,240
And all of them are ranked 3.9 or four stars out of four stars.

500
00:27:18,240 --> 00:27:22,000
So as a teacher, like, I tried to use that, I was like, this is useless for me.

501
00:27:22,000 --> 00:27:23,000
Great.

502
00:27:23,000 --> 00:27:26,800
So I'm like, am I going to open 342 PDFs and then read them and say, oh, I think this

503
00:27:26,800 --> 00:27:27,800
want to work.

504
00:27:27,800 --> 00:27:30,400
And even if I learned, oh, this one actually was effective.

505
00:27:30,400 --> 00:27:33,840
I have no way to really transfer that knowledge back in and share that with my community.

506
00:27:33,840 --> 00:27:36,480
So that was like one thing, okay, we can solve that part.

507
00:27:36,480 --> 00:27:39,920
And the other business model is we call kind of the wall of the garden model, which is

508
00:27:39,920 --> 00:27:44,440
more like the, you know, 1920s newspaper business model, right?

509
00:27:44,440 --> 00:27:47,680
Whereas, you know, like EdTech companies are essentially taking investor money, paying

510
00:27:47,680 --> 00:27:51,360
authors to write content and then putting it behind a paywall, just like a newspaper,

511
00:27:51,360 --> 00:27:52,680
traditional media.

512
00:27:52,680 --> 00:27:54,000
And they're saying, oh, no, no, no, you can't read it.

513
00:27:54,000 --> 00:27:55,000
But I promise you.

514
00:27:55,000 --> 00:27:56,000
It's the best.

515
00:27:56,000 --> 00:27:57,000
Right.

516
00:27:57,000 --> 00:28:01,560
So I was going to say it.

517
00:28:01,560 --> 00:28:06,920
So you have this model where the kind of the incentives are misaligned, or is that it's

518
00:28:06,920 --> 00:28:10,680
not in their interest to share what pieces of content they like and don't like, because

519
00:28:10,680 --> 00:28:14,360
you kind of get like, oh, you buy this whole suite of stuff.

520
00:28:14,360 --> 00:28:17,440
So yeah, they want to improve it, but they're not necessarily helping the teacher do that

521
00:28:17,440 --> 00:28:21,080
and really enlisting the teacher's help, being honest about what is and is not working.

522
00:28:21,080 --> 00:28:24,080
And if I ask, you know, if someone at the New York Times, if I think they're, their

523
00:28:24,080 --> 00:28:27,880
company, or the newspapers better than the Washington Post, I know who they're going to say,

524
00:28:27,880 --> 00:28:28,880
right?

525
00:28:28,880 --> 00:28:29,880
I know what that answer is.

526
00:28:29,880 --> 00:28:33,880
So getting real data and performance out of kind of this traditional model is just

527
00:28:33,880 --> 00:28:34,880
hard.

528
00:28:34,880 --> 00:28:39,080
So you've got this kind of high quality, you know, hard to produce, expensive to produce

529
00:28:39,080 --> 00:28:43,600
new content, model wall garden, and they got warehouse, you know, high quantity and very

530
00:28:43,600 --> 00:28:44,760
low quality.

531
00:28:44,760 --> 00:28:48,480
And the more, you know, more stuff you get, the worse the user experience gets.

532
00:28:48,480 --> 00:28:52,520
So we said, can we tie quality and quantity together?

533
00:28:52,520 --> 00:28:54,640
Can we make it kind of a positive feedback loop?

534
00:28:54,640 --> 00:28:57,960
And that's really where the AI and the machine learning, you know, kind of cuts in is that

535
00:28:57,960 --> 00:29:03,360
we are capturing at scale enough information to kind of keep floating the best stuff up

536
00:29:03,360 --> 00:29:08,520
to the top, but searching through it and capturing it in a way is not just traditional search.

537
00:29:08,520 --> 00:29:12,560
That means we can kind of cut through the top and get quantity and quality at scale.

538
00:29:12,560 --> 00:29:20,960
Have you found that a better way to rank and rank the way you present content is by kind

539
00:29:20,960 --> 00:29:26,160
of bubbling up what you've seen with the interactions as opposed to asking for an explicit

540
00:29:26,160 --> 00:29:27,680
star rating or things like that?

541
00:29:27,680 --> 00:29:29,920
Is that the direction you're going with this?

542
00:29:29,920 --> 00:29:35,360
What I would say is that we know that star rankings are not working.

543
00:29:35,360 --> 00:29:36,360
So it's been tried.

544
00:29:36,360 --> 00:29:40,720
We are capturing that data, but instead of just having someone vote on like, oh, like

545
00:29:40,720 --> 00:29:42,040
I like this piece of content.

546
00:29:42,040 --> 00:29:46,280
Instead, we can capture more interesting data, but like, I've got this piece of content

547
00:29:46,280 --> 00:29:47,920
and there's a hundred questions in it.

548
00:29:47,920 --> 00:29:51,840
I've seen tons of people who have strong opinions about the top 20.

549
00:29:51,840 --> 00:29:57,320
So it's kind of the ranking and sorting algorithm is a bit more off of the Reddit idea

550
00:29:57,320 --> 00:30:01,560
of how do you have these kind of layered nested pieces of information, how do you float all

551
00:30:01,560 --> 00:30:06,320
of that and some kind of recursive loop of like, oh, now I know that this piece of content

552
00:30:06,320 --> 00:30:07,800
is better than this one.

553
00:30:07,800 --> 00:30:12,040
And I'm not just using the uploads and downloads on those top level pieces, but everything

554
00:30:12,040 --> 00:30:13,040
inside.

555
00:30:13,040 --> 00:30:16,280
And that's really what's enabled us to kind of take the next level in terms of ranking.

556
00:30:16,280 --> 00:30:20,080
And then you combine that with performance data and now you've got something that, you

557
00:30:20,080 --> 00:30:24,400
know, no one else is going to be like, all right, all right, that's a very cool story.

558
00:30:24,400 --> 00:30:25,400
What's next?

559
00:30:25,400 --> 00:30:34,040
So if you take what we're doing right now and you really tease out that there's teachers

560
00:30:34,040 --> 00:30:36,920
using up the system, what we can do is we can then take the data that the teachers and

561
00:30:36,920 --> 00:30:41,840
students have produced and bring that to institutions themselves and say, here's a view

562
00:30:41,840 --> 00:30:47,480
of your school that you've never seen before, one that would benefit you in terms of looking

563
00:30:47,480 --> 00:30:51,880
at how your students are actually learning as opposed to just the output grades like

564
00:30:51,880 --> 00:30:55,480
where we're looking at are the students digging deeper into the content?

565
00:30:55,480 --> 00:30:59,920
Are they actually mastering something as opposed to did they just memorize it and move on?

566
00:30:59,920 --> 00:31:06,280
So looking at the next phase is using aggregated data of students and teachers at the school

567
00:31:06,280 --> 00:31:10,320
level, at the district level, the local government level and that type of thing.

568
00:31:10,320 --> 00:31:14,960
If you remember, we were talking about earlier about the being able to come normalize and

569
00:31:14,960 --> 00:31:18,200
standardize questions against questions, answers against answers.

570
00:31:18,200 --> 00:31:22,160
Well, there's nothing preventing us from using very similar models to rank students

571
00:31:22,160 --> 00:31:25,520
against students and not to students against their classmates or against themselves, but

572
00:31:25,520 --> 00:31:28,720
against every other student who's ever touched the system.

573
00:31:28,720 --> 00:31:33,080
So what I think is really unique about the way that we're doing this is that even if students

574
00:31:33,080 --> 00:31:37,840
see different pieces of content and take different quizzes, we can, you know, compare

575
00:31:37,840 --> 00:31:41,480
them and say, okay, which student actually learned more is doing better?

576
00:31:41,480 --> 00:31:45,520
And if you look at the way we are standardizing students for results today, kind of standardize

577
00:31:45,520 --> 00:31:49,640
tests, it's shove a student in a room on a Saturday and put 300 questions in front of

578
00:31:49,640 --> 00:31:50,640
an prey.

579
00:31:50,640 --> 00:31:53,640
And you hope you get good data.

580
00:31:53,640 --> 00:31:58,400
But with Mt. Cleveris, though, instead of that 300 questions, you can get 30,000 data

581
00:31:58,400 --> 00:32:00,720
points per student per year over the course of a year.

582
00:32:00,720 --> 00:32:04,520
And you can finally get to this as Bernie alluded to, the second order metrics of success

583
00:32:04,520 --> 00:32:09,600
that are kind of the holy grails of the education policy of questions like, did the student become

584
00:32:09,600 --> 00:32:12,040
more curious about what did they become more curious?

585
00:32:12,040 --> 00:32:16,320
Did the student get, you know, did they learn how to learn over time?

586
00:32:16,320 --> 00:32:20,160
And figuring out kind of where and what was, you know, what the most successful at?

587
00:32:20,160 --> 00:32:24,040
That's the stuff that a lot of kind of this typical standardized test models can't get

588
00:32:24,040 --> 00:32:25,040
to.

589
00:32:25,040 --> 00:32:28,560
So we know that at scale, that's where we think kind of a lot of this data will be valuable

590
00:32:28,560 --> 00:32:33,680
is that we can actually provide real, you know, real standardized testing data to schools

591
00:32:33,680 --> 00:32:36,160
without them having to actually do any standardized testing.

592
00:32:36,160 --> 00:32:37,760
It's just part of the product.

593
00:32:37,760 --> 00:32:38,760
Awesome.

594
00:32:38,760 --> 00:32:42,720
But James and Bernie, it was great getting to learn a little bit about Mt. Cleveris and

595
00:32:42,720 --> 00:32:44,760
kind of explore how you pulled it all together.

596
00:32:44,760 --> 00:32:45,760
Fascinating story.

597
00:32:45,760 --> 00:32:47,600
I really appreciate you taking the time.

598
00:32:47,600 --> 00:32:48,600
Thank you.

599
00:32:48,600 --> 00:32:49,600
Yeah.

600
00:32:49,600 --> 00:32:57,160
All right, everyone, that's our show for today.

601
00:32:57,160 --> 00:33:02,160
Thanks so much for listening and for your continued feedback and support.

602
00:33:02,160 --> 00:33:07,520
For more information on Bernie, James, Mt. Cleveris, or any of the topics covered in

603
00:33:07,520 --> 00:33:13,600
this episode, head on over to twimlai.com slash talk slash 63.

604
00:33:13,600 --> 00:33:18,680
To follow along with the NYU Future Labs AI Summit series, which will be piping to your

605
00:33:18,680 --> 00:33:25,200
favorite pod catcher all week, visit twimlai slash nexus labs too.

606
00:33:25,200 --> 00:33:30,680
Of course, you can send along your feedback or questions via Twitter to at twimlai or

607
00:33:30,680 --> 00:33:36,160
at sam charrington or leave a comment right on the show notes page.

608
00:33:36,160 --> 00:33:40,720
Thanks again to NYU Future Labs for their sponsorship of the show and the series.

609
00:33:40,720 --> 00:34:09,240
And of course, thank you once again for listening and catch you next time.

