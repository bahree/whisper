All right, everyone. Welcome to another episode of the Twomool AI podcast. I'm your host,
Sam Charington. And today I am joined by Malika Paven, a research scientist at the Institute
of Neuroinformatics at University of Zurich and ETH Zurich. Before we get into today's
conversation, be sure to take a moment to head over to Apple Podcasts or your listening
platform of choice. And if you enjoy the show, please leave us a five-star rating and review.
Malika, welcome to the show. Thank you for having me here, Sam. It's a pleasure.
It's my pleasure. And I'm really looking forward to digging into our conversation. We will be talking
about your research, of course, and your keynote talk at Partware Aware, efficient training
workshop at ICML this year. But before we dig into that, I'd love to have you share a little bit
about your background and how you came to work in kind of this intersection of neuroinformatics
and machine learning. Okay, thanks a lot. So hello, everyone. It's a pleasure to be here. So my
background is electrical engineering. I did my PhD at the University of California in Santa Barbara.
And during my PhD, I was basically focused on designing analog mixed-techno circuits.
So I was basically a VLSI GIP designer. And I was interfacing silicon technology with novel
emerging memory technologies. So these memory technologies are based on resistive switching.
So how they work is that you can imagine you have a resistor that has a memory. And by applying
an electric pulse to it, you change the state of the resistor in a non-lawful manner.
But the cool thing about them is that they are very small, so they're a nanoscale,
and they can be integrated in a third dimension on top of the silicon technology.
And as it turns out, these can bring like significant advantage to AI accelerators and AI hardware.
Because as you can imagine, the key component of an AI hardware is memory. So you need a lot of
memory to store a lot of weights perimeters. And you also need to read from this memory. And actually
most of the power in current hardware for training and inference goes into reading the memory.
So current hardware has what is called the fun-knowement architecture. So all the CPUs and GPUs
where the memory and the processing units are separated. So you would have to go fetch data
from memory, come back to the processor, and do this all the time. And most of the energy actually
goes into this shuttling of information between processing and memory units. So the idea is that
you, we need to bring this memory and the processing units closer together. And these kind of memory
technologies actually solve these two problems. So one is that they are small, so you can get a lot
of memory, you can get a lot of density, memory density in a small area in the third dimension.
And they also, they have a physical property that they can do computation inside the memory.
So if you imagine, if you have a resistor and you map the weight of your neural network as a
conductance to this resistor and you apply a voltage as an input, then through own law,
you get the multiplication, right? So you get V times G, which is a multiplication. And if you
have a bunch of them in parallel, then through Kirchhoff's law, you sum these current and you get
a sum of the product of the input to the weight. Basically, you get this multiply and accumulate
operation or MAC, which is the key or the essential computation in all of these neural networks.
So basically, they bring the computation closer to the substrate, right? It's closer to the physics.
And this, interestingly, is basically what the idea of neuromorphic engineering field is. So
neuromorphic engineering is the field that is trying to understand how computation can rise from
underlying substrate by getting more inspiration from how brain does this very exact thing, right?
So in the brain, you don't have an operating system. The physics or the brain itself is the algorithm,
is what is running the computation. And the institute where I currently am is one of the leading
institutes in this field. And then after my PhD, I basically moved here. And my research has,
therefore, been in the intersection of understanding neuroscience as basically an inspiration.
And understanding machine learning as a guiding principle that kind of grounds this inspiration
into math and something that we know would work. And bringing it more to circuits and physics to
implement more efficient AI systems. And these kind of, let's say, neuromorphic technologies is
what we call them. Have the potential to solve some of the current problems that we are seeing
in AI, for example, that there is an exponential rise in the amount of data and in the amount of
power that is required to process this data. And also basically that, you know, since increasingly
AI is becoming part of our daily lives, privacy is becoming an issue adaptation of these devices to
every, to a personalized user is becoming an issue. And therefore, we are working on, you know,
online learning, which is the topic of my talk at ICML. Nice, nice. And your talk is called
brain-inspired hardware and algorithm code design for low power online training at the edge,
on the edge. Exactly. And thinking about the kind of memoryster technology that you're
discussing, what makes that brain-inspired? Or is there some evidence that the brain has some
similar type of architectures? I hope that's the right word for it. Right, right.
Lecturers, I guess. Yeah, so I mean, it's kind of independent, but also related. So memory,
it's a, remember, there's a memory technology. So it's in, in a way, it's very independent
from the brain. But what it is interesting about it or what it makes it similar to the brain is,
is two things. One is that in the brain, and like I said, the memory and the processor are
co-located. So a neuron is really sitting next to its synapses, right? You have a soma,
and then you have these dendrites and dendrites are taking the information, and these two are really
co-located. They're not separated. And these members of devices are enabling these co-location,
right? By being very small and being able to basically sit, let's say, on top of a silicon neuron.
So basically, if you make a silicon neuron and you make the synapses with these members of
devices, they are really co-located. Another thing is that a membership device, really kind of,
I guess, in an abstraction level, works like a synapse. So a synapse, basically, you can think
of it as a really like a conduct, like a conductance, right? So if the weight increases
of a synapse, it is as if the path resistance goes down. So you can kind of model that,
like a resistor that has memory that can change. And interestingly, the brain basically sends
out information with what is called as action potentials or spikes, right? There are these short
electrical pulses that the neurons receive, they integrate, and then once that integration passes
a certain threshold, it sends out another spike. So that's basically the information processing
pipeline in the brain. And a membership device basically could act like the conductance or
or exactly like the synapse. And the way that we read and write from these devices are actually
also through pulses. So in that way, they are very similar. Got it. Got it. And you mentioned online
learning. Where does online learning come into the picture? So online learning come into the
picture in a way that so basically this membership device can change its state, right? And because it
can change its state, it's good for online learning because what we can do is that we can,
when we talk about the edge, right? So we're talking about being at the close to the sensors.
So these sensors are streaming information. Based on this sensory information that is arriving,
we can adapt our system to these input. And to adapt this system, we have to change these
resistances. And this device is capable of changing its resistance through pulsing in a non-violet
highway. And that is why it kind of enables this online adaptation. You've referred to the device.
Do you have devices in? Have you created examples? And what kinds of applications do you,
like what's the application setting that you are thinking about when you're creating this?
So the devices I don't create, I'm actually collaborating with a lab in France, it's called
SEALETI. So they kind of have these devices in almost as an industrial setting. So they have a CMOS
or a silicon foundry. And then between, so in the CMOS foundry, you kind of
integrate a layer by layer, these layers that are required for creating a transistor and then
putting metal layers on top to connect the other transistors. And between the fourth and the
fifth metal layer, they integrate these membership devices. So I collaborate with them.
And then we basically build circuits and architectures based on the data that we receive from them,
the third characteristic of the device. We design circuits that can interface with these
memory devices that can implement a brain-inspired algorithm. Now the applications that we're targeting
are more in the real mode, let's say, biomedical signal processing for personalized medicine
applications. For example, it matches really well for online learning because every patient is
different. For example, if you want to monitor someone's heartbeat or muscle activity or
brain activity or whatever it is, it is much better to adapt that device that you have, the
wearable device that you have to each patient based on exactly the biomedical signal that each
patient has. So biomedical signal processing, for example, for wearable devices is one big
application. The other applications are any application scenario that requires always on
monitoring, right? So also in an industrial application, people are thinking about, for example,
monitoring engines. So anything that requires always on battery-operated monitoring of
of real-world signals. They could also be, you know, temperature sensing, pressure sensing,
has a lot of people are working on keywords for example, you know, for
Alexa or Siri or any smart homes, right? So whatever you have, these devices have to be always
on operating, waiting for you to give them a command. So that would, if this kind of monitoring
has to continuously be on, it has to be very power efficient because then otherwise it's
continuously joining your battery. Can you talk a little bit about the challenges of adapting
online learning style algorithms to this hardware? Right. So online learning is a really difficult
problem actually because, because you can imagine, so you don't have, so you don't have like stored
data. It's not like you can, you know, normally when you want to go and train a neural network,
you would just have a, you know, you just download this data set and just run it through your
network. You don't have that, like your data is just, it's what it's called like batch size one,
right? So it's just streaming as you go. This, for example, has the problem that you don't have
access to the past and you don't have access to the future. So your algorithm has to be able to
cope with temporal locality. So information has to be locally available in time. So that's, let's
say, one challenge. And the other challenge is that, you know, for example, back propagation,
back propagation, which is basically a workhorse of all training online networks.
It requires information when you want to back propagate this area. It requires information from
all the synapses. And if you want to build that in hardware, you're going to blow up this entire
system with wires because you would have to, to update one synapse or one weight, you would have
to take information from all the other synapses and kind of bringing it to this one synapse.
Right. And basically connected problem. Exactly. So basically your whole architecture kind of
blows up with with with wires. So this information has to be spatially locally available. So temporal
locality because you don't have access to the past and future and spatial locality because
information of the update of the synapse or weight has to be locally available to the synapse.
So this is the second problem. The third problem is that also, you know, when you train your
neural networks, you know, you have a luxury of using 32-bit, bit-float-to-point memory,
right? Like on GPU, you can just use, you know, any variable with anything you want. But if you
want to have that on a hardware that is small, you can't just put a lot of memory there, right? Like
you want to reduce the precision of your memory because your device is tiny and has to kind of
sit next to your sensor. So you cannot have a big device. And because of that, then you have
low-bit precision. So your memory or the weight basically has a lower bit, has, like I say,
four bits or it has eight bits. Therefore, your learning rate is high, right? So because every time
you want to make a jump, your jump would be, you know, so you let's say if you have four levels,
you have four bits, you have 16 levels. So every time you make a jump, you have your jumping
once 16 of your entire memory range or your weight chain. So that's another difficulty, right?
And another thing is that, so let's say you calculate your gradient and your gradient has to
whatever it is, let's say, with whatever bit precision you do, you have to kind of map that into
your low-bit precision memory. So that also becomes another problem. And in the talk, I'm kind of
trying to say some of the potential solutions that we have worked on to tackle these three problems
that I have just told you about. Okay. Before we jump into those solutions, just to clarify,
the architecture that you're working with here, it's fully neuromorphic. It's not like you have
this kind of memory bank that is you're swapping out the memory bank in a conventional
von Neumann architecture with, you know, these fancy memoirsters. You're trying to do all your
computations in this hardware. Exactly. So basically, we are, so the idea is that
you're kind of replacing the hardware with an end-to-end neuromorphic hardware.
It doesn't mean that, you know, it would completely replace the current hardware because the current
hardware, of course, is great for offline learning. So basically, you know, whatever you have in
the cloud is going to be a lot more powerful than what you have close to the sensor. So you
can basically have a very power efficient, very low power edge device that is doing this always
on monitoring. And when, let's say, it detects something that requires the more powerful processing,
then it can maybe send a trigger to a more powerful machine, computing machine, that is,
that is in the cloud, let's say. I guess I'm kind of struggling to think through,
I guess I'm thinking of like a bootstrapping type of problem, you know, on this hardware like,
you've got this hardware, you don't have any operating system, you don't have any like higher level
things or lower level things. Like, how do you even start to work with it? Is it, you know,
is it that you're interfacing with, you know, systems that you know how to control on the edges,
and that's how you program it? So it's an end-to-end system. It's a very good question. It is
difficult, it's actually not a solved problem. But basically, the idea is that it's an end-to-end system.
So it goes from sensor to processor and to an actuator, or to something that gives you an output.
Let's say, you know, I want to see, so I'm giving my input, is my heartbeat. I give it to this
processor, which is this normalific processor, and then it kind of raises the flag and says,
hey, you're going to have a heart attack, or, you know, or I detect that the keyword, or
or your engine is about to blow up or something like that. So basically, it kind of, it's an
end-to-end system. And so the control that you're exerting to get this thing to do what you want
it to do is basically you're modulating the parameters of these members, or basically this network
that's on the thing. Exactly. So your network basically sitting on the hardware. So your parameters
of your neural network is basically sitting at the conductance of these devices physically.
So you just map, you have to map your weights into the conductance, and you just give inputs,
and then, yeah, so your network is basically your hardware.
And so kind of jumping into this spatial locality challenge, how do you start to address that?
Right. So basically, like I said, you have to have rate updates that are
that are local to the synapse. So if you write down, if you write down gradient descent,
so the derivative of the cost function with respect to the weights, you can basically write it down
as the multiplication of three factors. So one becomes, let's say, the derivative of the cost
function with respect to your error, with respect to your output, the derivative of your output
with respect to hidden state, which is basically directly proportional to your weight.
And then the derivative of that hidden state with respect to your, to your, to your weights.
And this actually basically becomes an activity of your pre-synaptic neuron.
So activity of your neuron, the previous layer, times the activity of the neuron in the,
in the post synaptic neuron, so in the next layer, times an error.
So basically, pre and the post are local because every synapse is sitting between a pre
and a post synaptic neuron. So that is, that information is local to the synapse, times an error,
which is, which can come globally. So basically, what you do is that you, you take the information
it is local, and then you multiply it by a global signal that is, that, that, that is coming to you
and you're, you're calculated, and then you calculate, you calculate the weight of the weight.
And what, what we have done is that this actually was as a collaboration with
the University of California in Irvine with, with Embranevgy and Muhammad Fudah. So we realized that we can encode the error into,
into events. So basically, whenever the error is, let's say, hired in a certain threshold,
we send an error event, and we say, now we have to update because the error,
there's, there's, there's an error that is hired in certain threshold. And based on the information,
of pre and the post, then we have a local update information to, to update the synapse. So that was,
let's say, one way of going around this spatial locality. Otherwise, that people have tried,
is, is basically that at each layer. So, so let's say you have, you have a deep network.
So at each layer, you employ these kind of local classifiers. And these local classifiers at each
layer are telling you what the output should be. And then based on that, then you calculate the error
for that, for that layer. And that kind of generates the error for that layer for you in a local manner.
Is one of the implications of the approaches you're describing, that this kind of neuromarfic
computation is happening asynchronously across the compute layers, more like a distributed system,
then you're just kind of rolling an error backwards across a, exactly. So I'm actually one of the,
one of the key points is that we want temporal sparsity. Because like I said, you don't want a system
to be continuously running, right? So you want this to only run when something happens. That's
something is basically an event, right? So you're encoding your signal into,
into a train of events. So, and that is actually how, for example, the Redna encodes, encodes
information. So when I'm, when I'm looking at this computer right now, it's not like my brain is
taking frame by frame information. It just basically looks at what is changing and, and just encodes
the, the change in time. And the same way, you can use the same kind of encoding mechanism to
take a signal. And then if, if it's nothing is happening, then you just don't, don't encode
anything. You don't send any input. Your, your processor is just sleeping. And then as soon as
something is happening, depending on the rate of change of your input, you just, you, you,
you, you send this pulse density coding scheme. And you send, you send information basically
asynchronously to the system. And the same thing can happen for, for, for, for learning. So your,
your streaming data, your, your, your system starts to kind of have an error, or it does have an
error based on whatever the, the person is experiencing or the device under test is experiencing.
And then whenever that's error is high, you say, you have to learn. This is the time to learn.
And then based on the local information of the pre and the post-synaptic spike, post-synaptic
activity, then you, you do an update and you, you change the, the resistance of these members
of devices sitting on the fly. I don't think you mentioned this previously, but are, is this,
are the, the use cases that you're describing are these fundamentally supervised problems where
you've got some target. And that's how you create your error and, and kind of propagate that
through. Or is it more of an unsupervised scenario? So we have actually worked on both.
So the field of, it's actually interesting that you say. So, you know, this field of neuromorphic
engineering is kind of, let's say linked to the spiking neural network field, right? Because,
because information is going into this chips in the format of spikes or events, and then coming
out of it. So it's like an end-to-end event-based system. And spiking neural networks for a long time,
we have not had a good learning algorithm that can, that can learn them. That's something a,
a lot of people complain about. So for a long time, the field was kind of working with Hibian
plasticity. So basically, kind of working with correlation-based learning. So you change the
weight just because of the correlation between the pre and the post-enaptic activity. And so basically
correlation-based learning without, without any error, without any guide. And if you're doing
good or you're doing bad. And then the problem with, with Hibian learning is that it's also an
egregious algorithm, right? So you, you know, if things are correlated, your weight starts to go high. But then,
because this weight is now high, whenever an input comes, let's say the neuron that has the highest
weight is always going to be the one that will have the highest activity. And then its weight
kind of grow more. So basically, it's kind of like a positive feedback process. So you need
a negative feedback to kind of keep things in check and in balance. So make sure that all the neurons
that you have in the system are kind of being part of the computation. It's not like one,
you just wonder greening neuron that happened to have, you know, initial good initial condition
that kind of just responds to everything. So you need to kind of this negative feedback mechanism,
which is kind of inspired also by the, by some of the findings in neuroscience in terms of
homestatic plasticity. So homestatic plasticity apparently is a negative, negative feedback loop
in neuron networks in the brain that tries to keep the activity of the neurons within a certain
range. So it doesn't let neurons to be very underactive, so to be completely silent or to be
really overactive. So it's just always tries to bring the neuron in a certain regime of operation.
So we have kind of worked on kind of bringing this to hebe on learning and homestatic plasticity
together as like an unsupervised learning mechanism, also for sequence learning. So we have also done
that, but, but it helps to have air, I must say, it's now it helps to have, to have a guiding
teacher and tells you where to go. So we talked about the spatial locality. Can you talk a little
bit about how you've approached the temporal locality problem? Yeah, that's a good question. So,
so basically for temporal locality, so you would want to, what problem does it, does it require
temporal locality? For any input that requires, that has a temporal sequence. So if you don't have
any temporal, if your data set has no temporal information, then you don't need this. But if it does,
then you need to keep some information. And apparently in the brain, there is this kind of
filtering mechanism, which is called the eligibility traces. So interestingly, you know, our neurons
and synapses are kind of behave or acting in a timescale of the and the order of tens to hundreds
of milliseconds. So they kind of keep just from the information and integration. So they then for
about 10 to 100 milliseconds. But our, but we are behaving in the real world in the timescales
of seconds or tens of seconds, right? And if we want to learn anything, then the question is,
how, how is this temporal gap closed? How is it that, you know, my, my brain is processing
something. Then I receive like saying, let's say a reward or a punishment or some surprise,
some 10 seconds later. But then my brain knows which synapses to go and change. And so how is
this temporal, what is what is closing this? So then apparently there is this kind of filtering
mechanism called the eligibility traces, which are keeping the activity of the, let's say the
correlation between the pre and the post-ynaptic neurons for tens of seconds. So it's kind of,
you can think of it as an exponential decay filter, which it's, it's amplitude goes high,
and then decays within, within tens of seconds. But it keeps this information basically
for, for that amount of time. And if within this like filtering time, filtering time constant,
it receives a reward, then a neuromodulation, neuromodulatory signal kind of reads this, let's say,
eligibility trace and then changes the corresponding synapses. So, and then, so this is kind of like
a neuroscience inspiration, let's say. But then some, some two years ago, a group in university of
Graz in Guillaume-Belleck and and co-authors, basically they realized that you can write down
the backpropagation through time algorithm as a multiplication of the learning signal
and an eligibility trace. And with an approximation that you
forget about the future terms, because backpropagation has, has, has terms in the future, right? Because,
because we basically feed the information to, to the activations, we keep all the activations,
and then we go back through time to see what activations were there and based on that we update.
But we don't, we cannot do this. So, if you approximate to kind of eliminate those future terms,
you can still get good accuracy on, on a certain task, so they've tried it also on reinforcement
learning tasks. So, basically from, let's say this eligibility traces, their, their usefulness
are kind of seen in neuroscience and they're kind of also backed by, by these experiments that
they've disrupted. And we have implemented them in hardware using an interesting solution,
because, so basically at the end, what you need to solve the poor locality is a filter
that has a long time constant, okay? And this is now backed by neuroscience and backed by
math. So, so capacitors into your, exactly. But, but capacitors are really expensive to have,
because they take a lot of space, especially if you want to keep information for a long time,
you need to have a big capacitor. And if you ever want to have a big capacitor, person apps,
then, then your area kind of blows up. So, what we found was that there's the specific type
of members of devices called face change memories. And these face change memories,
basically how they work is that they change their state from a amorphous state to a crystalline
state. And that's basically the on and off state, right? So, it's a amorphous state,
and then you apply a current, the device literally melts, and then it becomes crystallized,
and then it resistance drops. But, interestingly, when these devices are in this amorphous state,
they are not happy. They are, they are, you know, they're not in a favorable glass state. So,
they want to, they start to kind of drift to a higher resistance. So, and this drift actually
happens within the time constant that we like. So, this drift time constant is really in the order
of 10-0 seconds. So, then we realize that by one device that is in its amorphous state,
we can implement these eligibility traces very efficiently. And, basically, that is, let's say,
our our solution to this, to implement the implementation of this temporal locality problem.
And so, the idea then is for the applications that require this kind of temporal locality,
you, you can see kind of market difference in performance, you know, with and without kind of
your implementation of the eligibility traces. Exactly. So, so basically, without the eligibility
trace, well, you, you either need to have a lot of memory to keep information, you know, in the past.
If you don't have it, then you're not saving any temporal sequence or any temporal information.
And if you want to, yeah. So, then if you want to have a, let's say, efficient implementation
with lower, with low area consumption, then this will be a potential solution to, to use kind of
this drift of a piece, piece again, face change memory device in its amorphous state.
And then the last challenge that you mentioned was dealing with the limited bit precision,
and the kind of coarse grain nature that, that that imposes. How do you deal with that?
Yeah. So, another, so these devices, these membership devices, basically another good thing about
them is that they have multiple states. So, it's not like, it's not just an on and off state,
so they can, they can have multiple resisted state. But there's not a analog. I mean, the hope
or the dream is that they are analog, but they're not really. So, the reason why it cannot be
analog is because of basically physics. So, when a device does resisted switching, what happens
is that there, so you have two electrodes, and then you have a, let's say,
a member's div layer in between. So, you have an oxide in between. For example, in the case of
oxide based devices that has some oxygen deficiencies, and these deficiencies kind of respond to
electric field. So, these deficiencies are charged, so they're, and they respond to electric
field, and they create a filament. So, basically, these kind of ions, they, they create a filament
from one electrode to another, and that's how the resistance kind of lowers, because then you,
you're kind of creating a conductive path from a conductive filament or a path from one
electrode to another, and then the resistor drops. And the resistance of this device then depends
on the geometry of this filament. The thicker it is, then the lower the resistance, because then
these two electrodes are very well connected, and the, the less the diameter of this filament,
the resistance is higher. So, if you can kind of try to control this filament growth,
you know, you can, you can kind of get the device to, to show it's good, it's, it's, you know,
states. So, you can, you can kind of control the states of the device. So, that's what one thing we
did. So, we, and the thickness of these paths, this is also non-ballot. Yes, exactly. So,
basically, let's say the thick, and you, you program the device with a certain, let's say,
geometry of the filament, and I, and I will say how we do that, and then it just states that way.
So, it's non-ballot. So, the one way that you can control the, let's say, the geometry of this
filament is by how much current you push to it when you're programming the device. So, when you
want to change the state of the device, the more current you push, you push the, this filament
kind of grows thicker. So, we realized that if we basically map the error of our system,
at the error of the network to a current, then we can say, hey, if the error is high,
that means that you, the device has to change more. So, its filament has to change more.
And if the error is lower, then you, then you can have like, then you can push less current,
because that means that the device has to change less. So, this is basically what we mean by
co-design, because now you're really taking algorithm level concept, which is error of a network,
and you're really bringing it into a current that is changing a device filament, you know, like,
so just kind of telling, an error is really changing how the ions move in a physical system.
Yeah, yeah, that's fascinating. But more over, I guess the impression I have is that
in kind of normal operation, this, you would be applying the current in a programming phase up
front. But this error, when you're trying, when you're using the technique that you're describing,
are you applying the current, like, during the operation of the device, because we're talking
about online learning. So, there's...
Oh, right, right, yeah, that's a good question. So, this is something that is not solved yet.
So, basically, while you're programming the device, you're missing input.
So, basically, let's say your hard work kind of goes into learning mode, and for that,
whatever microstackens that you were, because these devices actually changed their state very fast.
So, you just have to apply a pulse that is in the order of maximum and microstacken.
But in that microstacken, whatever input you're receiving is getting tossed away. You're not,
you're not receiving it, right?
Yeah, I was imagining something more like an e-prom where it was taking much longer time to program.
No, no, no, these devices are very, very busy, the programming time, the access time and the
programming time are very low. So, basically, you can even go to nanoseconds or hundreds of nanoseconds.
Oh, wow, wow. And so, you introduced this by talking about this analog versus digital,
like, you're wanting to get to full analog, but not really. How does that tie into this,
the mechanism you're describing?
So, basically, this whole competition is really analog, right? Because you are,
so, let's say, just for doing multiplication and addition, it's not like you have digital gates
that are doing the multiplication and you have an adder that is doing the adder. So, it's just really
the physics of the devices doing this for you and that's kind of, that's basically analog computation.
So, that's how you were saying that you wanted, you wanted it to be full analog, but you can't
get it to be full analog or it's not full analog. Right. So, the computation is analog,
and it's basically locally analog, but then when you want to communicate this information to other
parts of the chip or to other neurons, then you go to events or spikes, which is then digital,
and that's basically where the mixed signal design comes into place. So, your competition
is really locally analog, but then it's digital communication through spikes. Because when you
want to send out information, if you want to send out analog information, that's very difficult
because if an analog signal has to go through a path or a distance, then this distance is kind of
dissipating your analog signal. Right. So, you would have to put like drivers that is pushing
enough current so that this analog precise analog value can stay wherever it is. And that
that requires again a lot of power, a lot of space for these kind of buffers and amplifiers that
you have to employ for doing this. And therefore, it's good that if you want to communicate a signal
to go digital and then send out your information in a digital way to another neuron,
as a voltage pulse, and this voltage pulse again goes through the members, there's becomes a
current and then gets integrated in an analog fashion in the next neuron. So, so you go from
analog to digital and back to analog. So, you've overcome these three key challenges that you
mentioned in the beginning. Are there other pieces that are required or what other pieces are
required to bring it all together so that you can actually do online learning? So, I think that's
so currently what we're still missing is kind of scalability. So, scalability both in terms of
algorithms to algorithms that can. So, all of these, let's say kind of hacks that I've mentioned
to you, they work maybe for, you know, two, three layers. But if you want to kind of go deeper,
then they don't work because there's a lot of approximation that is involved, which, you know,
if you want to go to larger networks, they're not going to work. So, it's a basically, we need
scalability in terms of algorithms and we need scalability in terms of hardware. So, these kind
of devices are still kind of maturing, although they have kind of emerged really exponentially
fast in the past, you know, five years. But they're still kind of emerging. There's a lot of,
let's say problems in terms of noise, bit precision, devices, basically, these devices that you have,
they have a lot of variability between them. So, they don't all work the same. They have also
noise in time. So, every time you program the device, it doesn't. So, let's say if you set and
reset the device like 100 times, it kind of sits on a Gaussian distribution in terms of the
state it ends up in. So, it kind of, it's, it's noisy, which actually a lot of people even try to
exploit, for example, for, for Bayesian computation, right? So, let's say, like it brings you like a
search space in a way. So, every time you set and reset it, kind of you're kind of sampling from
these distributions. So, I would say this is like basically scaling, I would say, is the main
problem in terms of algorithm and hardware? How close are we from seeing this in kind of practical
use? Are we, are we there already, you know, in some ways, or, you know, long way out? What's your
take on that? So, actually, there's some startups. I would, even from, from the Institute of Narrow
Romatics that are trying to take this to the market, but they're still working in the digital domain.
If you want to go analog and a lot of people are doing in the, in the, in the world,
so, I think it would be something, I would say, maybe five years plus, if we want, if you want to
go to the market, because there, it's still really a research field. I'm trying to like, you know,
bringing all of these concepts from five different fields together, while the technology is still
emerging, I would say, it is, it still has time, it requires time. Awesome, awesome. Well, by the
time folks here this, you will have a deliverger keynote at the workshop, which sure will be
super interesting for folks, but best of luck. Thank you so much. Yeah, thanks a lot.
Cool. I'm looking forward to, to the conference and seeing and chatting about these concepts with
the years, and I hope your audience likes this concept also. Absolutely. Thanks so much, Malika. Thank you, Sam.
