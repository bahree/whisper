WEBVTT

00:00.000 --> 00:15.480
Hello and welcome to another episode of TwimoTalk, the podcast where I interview interesting

00:15.480 --> 00:20.720
people, doing interesting things in machine learning and artificial intelligence.

00:20.720 --> 00:25.120
I'm your host Sam Charrington.

00:25.120 --> 00:28.160
First and foremost, I'd like to start off by thanking you.

00:28.160 --> 00:33.680
It's your dedication and support of this show that keeps us pumping week after week.

00:33.680 --> 00:38.800
All your downloads, listens, reviews, comments, and general love for the show give us the

00:38.800 --> 00:43.160
ability to grow and to continue to bring you great content.

00:43.160 --> 00:48.280
As always, thank you to everyone who's sending quotes this past week.

00:48.280 --> 00:52.360
And to all those who've received stickers in the mail, be sure to take pictures and show

00:52.360 --> 00:56.400
them off by tweeting them to at TwimoAI.

00:56.400 --> 01:03.120
For you new listeners to receive your TwimoSticker, just send us a tweet, Facebook comment, or comment

01:03.120 --> 01:08.720
right on the show notes page with your favorite quote from today or any episode of the show.

01:08.720 --> 01:12.240
The next couple weeks will be super busy and exciting for me.

01:12.240 --> 01:16.480
Next week, I'm in Silicon Valley for the NVIDIA GTC conference.

01:16.480 --> 01:20.640
If any Twimo listeners are planning to attend and would like to get together, I am totally

01:20.640 --> 01:26.880
game to host a listener meetup, just let me know if you're interested and will make something happen.

01:26.880 --> 01:30.880
And of course, the week after next will be the future of data summit that I'm hosting

01:30.880 --> 01:32.480
in Las Vegas.

01:32.480 --> 01:36.320
If you haven't already made plans to attend, it's not too late.

01:36.320 --> 01:42.080
For more information about the summit, visit TwimoAI.com slash future of data.

01:42.080 --> 01:46.400
And if you have any questions at all about the event, feel free to reach out to me via

01:46.400 --> 01:49.800
the contact page at TwimoAI.com.

01:49.800 --> 01:51.680
Now let's get to this week's show.

01:51.680 --> 01:58.280
Today, we bring you our final interview from backstage at the NYU Future Labs AI Summit.

01:58.280 --> 02:00.840
Our guest this week is Matt Zeeler.

02:00.840 --> 02:05.600
Matt graduated from the University of Toronto, where he worked with deep learning researcher

02:05.600 --> 02:11.320
Jeffrey Hinton, and he went on to earn his PhD in machine learning at NYU, home of

02:11.320 --> 02:13.000
Jan LeCoon.

02:13.000 --> 02:20.720
In 2013, Matt founded Clarify, a startup whose cloud-based visual recognition system gives

02:20.720 --> 02:27.560
developers a way to integrate visual identification into their own products and whose initial image

02:27.560 --> 02:34.920
classification algorithm achieved top five results in that year's ImageNet competition.

02:34.920 --> 02:40.760
I caught up with Matt after his talk, which was titled, From Research to the Real World.

02:40.760 --> 02:45.400
Our conversation focused on the birth and growth of Clarify, as well as the underlying

02:45.400 --> 02:48.640
deep neural network architectures that enable it.

02:48.640 --> 02:52.760
If you've been listening to the show for a while, you've heard me ask several guests

02:52.760 --> 02:58.200
how they go about evolving the architectures of their deep neural networks to enhance performance.

02:58.200 --> 03:03.520
Well, in this podcast, Matt gives the most satisfying answer I've received to date by

03:03.520 --> 03:04.920
far.

03:04.920 --> 03:05.920
Check it out.

03:05.920 --> 03:07.720
I really think you'll enjoy this one.

03:07.720 --> 03:17.160
And now on to the show.

03:17.160 --> 03:18.160
All right, everyone.

03:18.160 --> 03:24.200
I am here with Matt Zealer, CEO and founder of Clarify.

03:24.200 --> 03:28.240
And we are live at the Future Labs AI Summit.

03:28.240 --> 03:29.840
Matt, how are you doing?

03:29.840 --> 03:30.840
Good.

03:30.840 --> 03:31.840
Thanks for having me, Ellen.

03:31.840 --> 03:32.840
Absolutely.

03:32.840 --> 03:33.840
Thanks for being on.

03:33.840 --> 03:40.120
We just left the stage where you were talking about, from research to the real world.

03:40.120 --> 03:42.720
And we'll take a second to get into your talk in a moment.

03:42.720 --> 03:47.520
But why don't you tell us a little bit about your background and about Clarify?

03:47.520 --> 03:48.520
Sounds good.

03:48.520 --> 03:54.680
So, I, way back, I grew up in Canada and in a small farm town, so I was never exposed

03:54.680 --> 03:55.680
to big tech stuff.

03:55.680 --> 04:01.560
And that always got me excited seeing it on TV and gave me excitement about starting

04:01.560 --> 04:08.760
a company someday and for engineering at University of Toronto is what I did in my undergrad.

04:08.760 --> 04:12.000
It was a pretty cool program called Engineering Science where you take every discipline of

04:12.000 --> 04:16.560
engineering and then for the first two years and then the last two you specialize.

04:16.560 --> 04:22.920
And when I was deciding which option to specialize in, I talked to one of Jeff Hinton's PhD students.

04:22.920 --> 04:28.360
So Jeff is very famous in this field of AI and he was a U of T professor at the time.

04:28.360 --> 04:32.720
And his student showed me this video of a flame flickering and he said it was completely

04:32.720 --> 04:35.400
created by artificial intelligence.

04:35.400 --> 04:39.360
And that's when I knew this was something completely different than anything else I've

04:39.360 --> 04:43.880
seen before and anything else I could program, which I knew I had to do at the time.

04:43.880 --> 04:48.280
And so I had to learn more and I took a computer option and Jeff Hinton's course in third

04:48.280 --> 04:50.680
year and then did my undergrad thesis with Jeff.

04:50.680 --> 04:54.000
So that was quite the opportunity.

04:54.000 --> 04:55.000
Absolutely.

04:55.000 --> 05:00.200
And I didn't know enough having just taken undergrad to start a company in this field.

05:00.200 --> 05:05.880
So I decided to do my PhD and that's what brought me to New York to go to NYU.

05:05.880 --> 05:11.480
And I focused over four years on neural networks applied to understanding images and that's

05:11.480 --> 05:14.440
exactly what we do today at Clarify.

05:14.440 --> 05:20.440
And the last year was particularly exciting where there was this event called ImageNet that

05:20.440 --> 05:26.760
held every year and in 2012 Jeff Hinton again and two of his PhD students had some really

05:26.760 --> 05:32.480
groundbreaking results applying neural networks to this competition compared to other algorithms

05:32.480 --> 05:36.280
like edge detection, color detection, simple stuff.

05:36.280 --> 05:42.080
And they blew out everybody and by a huge margin it was really a step function improvement

05:42.080 --> 05:44.200
and accuracy of these things.

05:44.200 --> 05:48.160
And so everybody who didn't believe in neural nets all of a sudden started believing in

05:48.160 --> 05:49.160
them.

05:49.160 --> 05:53.000
So what really triggered this explosion we're seeing in the AI world.

05:53.000 --> 05:57.200
And so being at NYU where I was already working on this stuff I could get up and running

05:57.200 --> 06:04.960
pretty quickly with that result and at the start of 2013 and continue to improve it throughout

06:04.960 --> 06:05.960
the year.

06:05.960 --> 06:11.360
And I realized that after interning at Google Brain, which is their neural net team, the

06:11.360 --> 06:16.360
tech I had working back in New York was actually working better than what they had internally.

06:16.360 --> 06:21.120
And so I saw that as a big opportunity to start a business because Google is well known

06:21.120 --> 06:24.960
in the AI space and they were already ahead of many other companies out there.

06:24.960 --> 06:30.600
And so that's what triggered it in the fall of 2013 incorporating Clarify.

06:30.600 --> 06:34.600
And we ended up winning right off the start of this ImageNet competition.

06:34.600 --> 06:39.800
So that was a great way to kick off the company and triggered a lot of inbound press and

06:39.800 --> 06:41.560
invested from there.

06:41.560 --> 06:46.640
And we've been offering this technology up as APIs and continuing to grow the business

06:46.640 --> 06:47.640
through that.

06:47.640 --> 06:49.040
That's pretty amazing.

06:49.040 --> 06:53.360
We talk about ImageNet from time to time on the podcast.

06:53.360 --> 07:00.360
Anything you can share about the experience building up to competing in ImageNet and successfully

07:00.360 --> 07:01.360
winning it?

07:01.360 --> 07:03.320
Yeah, it was a lot of fun.

07:03.320 --> 07:06.400
It was back in the very early days of Clarify.

07:06.400 --> 07:12.920
I really started programming our library and everything back in August of 2013.

07:12.920 --> 07:15.320
And the submission deadline was in November.

07:15.320 --> 07:20.640
And so I just had in my apartment one desktop with a couple of graphics cards in it because

07:20.640 --> 07:24.200
they use GPUs for all this type of neural net stuff.

07:24.200 --> 07:27.400
And it was just training away constantly.

07:27.400 --> 07:32.040
And I submitted five results to the competition and they ended up winning the top five places.

07:32.040 --> 07:37.680
So it was really exciting to have those early days of Clarify where it was just me and

07:37.680 --> 07:39.200
the one machine.

07:39.200 --> 07:42.520
And now we just surpassed 50 people in the company.

07:42.520 --> 07:46.960
So it's also exciting now that it's been created to grow the company.

07:46.960 --> 07:47.960
That's awesome.

07:47.960 --> 07:52.960
Well, one of the questions that I ask frequently and haven't really, I think, to date got a

07:52.960 --> 07:59.640
very satisfying response is, you know, when you're trying to, you know, starting from what

07:59.640 --> 08:06.440
Hinton Steamed did in 2012 and you're trying to evolve a neural net architecture to take

08:06.440 --> 08:11.560
on a problem, or if you're starting from scratch, like how do you approach the problem

08:11.560 --> 08:14.520
of neural network architecture?

08:14.520 --> 08:19.760
What's the thinking and the primitives that go into that that get you to winning image

08:19.760 --> 08:20.760
net?

08:20.760 --> 08:21.760
Yeah.

08:21.760 --> 08:28.120
I had the very last paper on my PhD was actually focused on understanding these neural networks.

08:28.120 --> 08:32.560
And people have understood what the very first layer of these networks do.

08:32.560 --> 08:37.720
So neural nets are composed of many layers of processing that are learned from the data,

08:37.720 --> 08:40.120
which is what makes them really powerful.

08:40.120 --> 08:45.120
And the first layer, you can just visualize if you look at a neural net applied to images,

08:45.120 --> 08:49.560
it ends up learning different edges and different colors very simply in the first layer.

08:49.560 --> 08:51.640
But nobody really knew what was happening beyond that.

08:51.640 --> 08:55.520
In the second layer, third layer, all the web to however many layers you have.

08:55.520 --> 09:00.840
So the last paper of my PhD was focused on visualizing and understanding convolutional

09:00.840 --> 09:02.200
neural networks.

09:02.200 --> 09:08.280
And we saw that these edges form into things like corners and circles and T junctions and

09:08.280 --> 09:12.120
parallel lines kind of mid-level things by the second layer.

09:12.120 --> 09:17.920
The third layer starts extracting things like eyeballs and noses and ears.

09:17.920 --> 09:22.200
And then the fourth and fifth layers might start learning faces and then the final layers

09:22.200 --> 09:24.200
will output person.

09:24.200 --> 09:29.120
So it actually builds up these levels of abstraction in a very sensible way.

09:29.120 --> 09:36.200
And so in visualizing these things, we actually robbed Fergus and I at NYU, realized some deficiencies

09:36.200 --> 09:42.520
of a neural net architecture that Jeff Hinton used with his team in ImageNet 2012.

09:42.520 --> 09:47.240
And so we could actually improve the architecture kind of systematically by looking at these

09:47.240 --> 09:48.240
visualizations.

09:48.240 --> 09:52.160
And that gave a multiple percentage points improvement.

09:52.160 --> 09:56.360
And then other things are more of an art than a science.

09:56.360 --> 10:00.480
There's not a lot of theory around these neural networks.

10:00.480 --> 10:06.680
It's more from experience when you see this kind of behavior change these types of parameters.

10:06.680 --> 10:13.600
And so that's why there's very few experienced people in this field and that's why they're so

10:13.600 --> 10:14.600
valuable.

10:14.600 --> 10:17.680
It's that kind of experience that they bring to the table.

10:17.680 --> 10:21.480
What's an example of if you see this change that?

10:21.480 --> 10:27.560
So one example is if there's something called a learning rate, which tells you how big

10:27.560 --> 10:32.800
of a step to update your model every time you see a new image in the case of our stuff.

10:32.800 --> 10:38.240
And so if you have a really high learning rate, you'll see the accuracy just explode and

10:38.240 --> 10:41.800
you'll see the parameters of the model just explode into really high values.

10:41.800 --> 10:44.040
It becomes an unstable system.

10:44.040 --> 10:49.000
And so you know you can actually decrease the learning rate to make that more stable.

10:49.000 --> 10:53.720
And that's something that we see with non-neural network machine learning models as well.

10:53.720 --> 10:58.560
Are there things that, is there an example specifically related to neural network architecture?

10:58.560 --> 11:04.200
Like if you're seeing your neural network do X or not do X, maybe you need to add this

11:04.200 --> 11:05.760
kind of layer or that kind of layer?

11:05.760 --> 11:06.760
Yeah.

11:06.760 --> 11:12.400
So the visualizations that we notice that looked incorrect in some sense were when we looked

11:12.400 --> 11:16.000
at higher layers, there was a lot of blocking artifacts.

11:16.000 --> 11:20.600
So it didn't look like a very sharp visualization.

11:20.600 --> 11:26.640
And so that was a result of the first layer being really large filters and not being applied

11:26.640 --> 11:32.040
at every pixel, one pixel stride, but every four pixels it was taking big jumps.

11:32.040 --> 11:36.840
And so when you visualize it also plops down in big jumps.

11:36.840 --> 11:41.440
And so that has to be throwing away information, it's skipping over too much.

11:41.440 --> 11:46.720
And so by reducing the stride, reducing the filter size, it actually increased the accuracy.

11:46.720 --> 11:53.440
So it sounds like the lesson then is or lessons are that as you said it's you know there's

11:53.440 --> 12:00.120
art as well as science involves it's highly iterative.

12:00.120 --> 12:04.760
But also I think what I learned in this discussion is that what really gave you the edge was being

12:04.760 --> 12:10.000
able to kind of introspect if you will what was happening at the different layers of the

12:10.000 --> 12:15.600
architecture and using the knowledge that you gain there to evolve the architecture.

12:15.600 --> 12:17.280
Yeah, exactly.

12:17.280 --> 12:20.720
Is the do you remember the name of the paper that you referred to?

12:20.720 --> 12:25.880
It's called visualizing and understanding convolutional neural networks.

12:25.880 --> 12:30.320
And is that paper related to the deep dream work?

12:30.320 --> 12:31.720
So it's funny.

12:31.720 --> 12:32.720
It's smiling here.

12:32.720 --> 12:33.720
It's funny.

12:33.720 --> 12:34.720
You mentioned that.

12:34.720 --> 12:36.600
Yeah, I think it's a very similar technique.

12:36.600 --> 12:44.320
So the purpose of my paper was to just go through a network, you input an image, it goes

12:44.320 --> 12:48.320
feed forward through a network as if it was about to predict the categories.

12:48.320 --> 12:54.440
And then you reconstruct back down to generate a pixel and deep dream basically did that

12:54.440 --> 12:59.840
process in multiple loops so they would reconstruct a visualization, add it back to the original

12:59.840 --> 13:02.720
image and then continue that in a cycle.

13:02.720 --> 13:10.440
And that's where the system essentially gets locked into what it's dreaming about and

13:10.440 --> 13:16.400
it starts visualizing kind of crisper objects that it can think about.

13:16.400 --> 13:17.400
Okay.

13:17.400 --> 13:24.040
So clarify is a bit of a success story in the NYU ecosystem, kind of where is the company

13:24.040 --> 13:29.600
at now in terms of, you know, however you describe it size scale, you know, the problems

13:29.600 --> 13:31.280
that you're going after, things like that.

13:31.280 --> 13:36.880
Yeah, so it's been really exciting starting it in my apartment and then the very first

13:36.880 --> 13:41.080
office was at NYU's incubator on Verix Street.

13:41.080 --> 13:46.120
And then once we had about 10 people, we got our own office and that was around when we

13:46.120 --> 13:50.280
raised our series B, which was a pretty big round, 10 million dollars.

13:50.280 --> 13:57.440
And then just last fall in October of 2016, we raised our series B, which was a 30 million

13:57.440 --> 14:01.880
dollar round, so lots of funding for growth in the future.

14:01.880 --> 14:07.240
And we just surpassed 50 people, so growing really quick and we were only about 30 people

14:07.240 --> 14:08.440
at the start of the year.

14:08.440 --> 14:09.440
Wow.

14:09.440 --> 14:10.440
Yeah.

14:10.440 --> 14:11.440
That's amazing.

14:11.440 --> 14:12.440
Yeah.

14:12.440 --> 14:21.200
And so the, as I understand, the solution that you guys are offering is, and you can,

14:21.200 --> 14:26.840
you know, correct and iterate on this, but it is kind of a visual understanding API if

14:26.840 --> 14:32.600
you will, where you feed it images and it will tag those images for you and give you

14:32.600 --> 14:37.360
probabilities of the likelihood of those tags.

14:37.360 --> 14:41.720
And you know, that's something that we see, you know, there are numerous versions of this

14:41.720 --> 14:46.680
available in a marketplace, you know, including by, you know, big players like Google and Microsoft

14:46.680 --> 14:47.680
and Amazon.

14:47.680 --> 14:51.680
Like what makes clarified different and how do you compete in a crowded field?

14:51.680 --> 14:58.640
Yeah, so that's a good summary of what we offer and have been offering for over three years.

14:58.640 --> 15:03.520
Now, so one big advantage for us is that we've been out at least three times longer than

15:03.520 --> 15:08.560
most other people in this space, which means we've, and because of winning ImageNet, early

15:08.560 --> 15:11.160
it means we've had a lot of conversations with customers.

15:11.160 --> 15:15.480
We really understand lots of different industries and the problems that each of these customers

15:15.480 --> 15:16.640
have in them.

15:16.640 --> 15:19.640
And so we try and build those features into our platform.

15:19.640 --> 15:23.560
And so some examples of that were just launched in the fall.

15:23.560 --> 15:26.120
One is a search product and one is a training product.

15:26.120 --> 15:30.720
So search very simply lets you throw in your images to our system and we take care of

15:30.720 --> 15:31.720
the rest.

15:31.720 --> 15:35.280
We understand them from the pixels up to recognize all these different concepts.

15:35.280 --> 15:40.480
And then we let you search by the concepts that we can recognize, but also by image.

15:40.480 --> 15:45.280
So if you take a picture out in the world, you can find visually similar pictures automatically

15:45.280 --> 15:46.640
without even saying a word.

15:46.640 --> 15:50.720
So that's really powerful as a discovery tool, and that applies across every industry.

15:50.720 --> 15:53.560
Like retail, you can use it for shopping, gardening.

15:53.560 --> 15:58.880
You can use it for gardening ideas or travel for planning your next vacation.

15:58.880 --> 16:02.080
It's a universally useful feature in our platform.

16:02.080 --> 16:07.600
And likewise, training is another universally useful feature.

16:07.600 --> 16:11.480
We started off with this one size fits all model we call the general model.

16:11.480 --> 16:17.560
We started building what we like to call domain models for food, travel, wedding, real estate,

16:17.560 --> 16:18.560
nudity and so forth.

16:18.560 --> 16:21.240
So there are more focus on different industries.

16:21.240 --> 16:24.480
And then with custom training, we've gone one step further.

16:24.480 --> 16:28.640
Now you can teach the platform to recognize whatever you care about.

16:28.640 --> 16:33.800
And this is a huge step ahead of a lot of the other people out there.

16:33.800 --> 16:38.200
And it's really important for our customers because now if you take a retail setting, they

16:38.200 --> 16:43.640
have a way of categorizing their products, or e-commerce marketplaces.

16:43.640 --> 16:49.200
People are used to manually tag in this content, so they already implicitly have a categorization.

16:49.200 --> 16:55.120
Or for filtering out unwanted content, they already have a terms of use that includes nudity

16:55.120 --> 17:01.080
and drugs and weapons, and even non-offensive stuff like, you know, they just don't want

17:01.080 --> 17:05.760
advertisements on their site or stock photos on their site or money or people.

17:05.760 --> 17:10.400
And so now with custom training, you can customize it to recognize exactly what you care about

17:10.400 --> 17:13.520
in your business, which is very exciting.

17:13.520 --> 17:19.640
What kind of accuracy lift do you see customers obtaining with custom training relative to

17:19.640 --> 17:21.600
standard or domain models?

17:21.600 --> 17:27.400
Yeah, it's a big lift because it's usually trained on their specific data.

17:27.400 --> 17:34.400
So in terms of accuracy, numbers, I think it's not fair to compare because the general

17:34.400 --> 17:38.480
model is meant for if you take your phone out of your pocket and take a picture and tell

17:38.480 --> 17:40.240
you something meaningful.

17:40.240 --> 17:44.680
We at Clarify have collected massive data sets to make that really accurate.

17:44.680 --> 17:51.000
But when you focus on the 10 or 100 or 1000 categories that you care about only, then you

17:51.000 --> 17:56.560
can end a strain on data that you have access to, then you can really drive the accuracy

17:56.560 --> 17:59.800
because it's really solving your specific problem.

17:59.800 --> 18:07.520
So as Clarify does Clarify offer both a consumer solution, take a, you know, an app that I take

18:07.520 --> 18:11.800
a picture and it will recognize things as well as a business offering.

18:11.800 --> 18:17.640
Yeah, we do have a consumer app called Forever, which lets you apply our general model and

18:17.640 --> 18:21.240
our facial recognition to understand your personal photos.

18:21.240 --> 18:24.520
And it's available on iOS right now.

18:24.520 --> 18:28.440
That's spelled forever with a Y at the end, it's for every one of your photos.

18:28.440 --> 18:30.400
And it even lets you teach things.

18:30.400 --> 18:35.000
So this custom training that we just launched in our API, we actually launched it first

18:35.000 --> 18:36.160
in forever.

18:36.160 --> 18:40.400
So you can teach it like the name of your pet or your favorite sports car and all that

18:40.400 --> 18:44.960
becomes searchable over your personal pictures as well as, you know, your mom's name and

18:44.960 --> 18:47.400
your sister's name, it actually recognizes people.

18:47.400 --> 18:51.040
So whenever you take a new picture of them, it'll automatically tag them and index them

18:51.040 --> 18:52.040
for search.

18:52.040 --> 19:00.200
Okay, and to what degree does having that is the main reason why or one of the main reasons

19:00.200 --> 19:04.880
why you offer that because it allows you to expand the data set for which you're able

19:04.880 --> 19:06.040
to train over.

19:06.040 --> 19:07.040
Yeah.

19:07.040 --> 19:08.880
How does that play into the model?

19:08.880 --> 19:09.880
Yeah, exactly.

19:09.880 --> 19:14.280
That was the initial, well, there was two initial incentives at the data collection and

19:14.280 --> 19:16.480
it was always really a passion of mine.

19:16.480 --> 19:22.920
Even before starting Clareify, before deciding on the API as building a platform, I was always

19:22.920 --> 19:27.320
passionate about applying this technology to my own personal pictures and that's when

19:27.320 --> 19:29.880
I knew it was actually ready to start a business around.

19:29.880 --> 19:34.600
I built a very simple demo and just dragged and dropped my pictures into it and it gave

19:34.600 --> 19:36.400
meaningful results.

19:36.400 --> 19:42.600
And so it's always been a passion plus it's a great way for us to crowdsource data collection.

19:42.600 --> 19:44.880
That's awesome.

19:44.880 --> 19:50.920
What are some of the most popular business use cases that you're seeing?

19:50.920 --> 19:55.120
Yeah, I like to bucket them into two big buckets.

19:55.120 --> 19:59.680
One is organization and one is moderation and these apply across all different industries.

19:59.680 --> 20:05.720
So organization, we have companies like Travago, for example, that are in the travel space.

20:05.720 --> 20:11.800
They want to take all the user uploaded and hotel uploaded photos and tag them with our

20:11.800 --> 20:16.920
travel model so that people may be the next time you're planning your vacation, you can

20:16.920 --> 20:21.200
search for the best pool in Jamaica and it shows you the pictures to compare and make

20:21.200 --> 20:22.920
your decision easier.

20:22.920 --> 20:25.960
Same story applies in the wedding space with Stanley Pretty.

20:25.960 --> 20:30.560
They have users upload their entire wedding album and they use our wedding model to categorize

20:30.560 --> 20:36.200
them and that helps new users come to Stanley Pretty and find inspirations for their wedding.

20:36.200 --> 20:40.400
The more new users and the more content, the more ad revenue that they can drive from

20:40.400 --> 20:46.280
Stanley Pretty and on the moderation side, whenever there's an upload button on the internet

20:46.280 --> 20:51.400
or in a mobile app, there's a chance that you're going to get offensive content and that

20:51.400 --> 20:57.440
could be nudity, drugs, weapons, violence, lots of different stuff that you don't want

20:57.440 --> 21:03.200
on your marketplace and advertisers don't want to be associated with this content either.

21:03.200 --> 21:10.800
So now with our moderation models, you can build a brand safe section of your site and for

21:10.800 --> 21:15.600
your community or to drive ad revenue and do that automatically.

21:15.600 --> 21:21.760
And this is traditionally done with a manual work and it just doesn't scale both in terms

21:21.760 --> 21:28.360
of how fast a human can respond to new uploads and to how much new content is being created

21:28.360 --> 21:35.400
by cell phones all over the world. So we solve both of those by automating the process.

21:35.400 --> 21:42.040
So I'm curious what your thoughts are on where you see opportunities in this space.

21:42.040 --> 21:49.440
We're here at the Future Lab Summit. In addition to many of the New York AI community, there

21:49.440 --> 21:55.960
are lots of NYU students. The next AI entrepreneur might be in the audience there.

21:55.960 --> 22:01.560
Where do you think the opportunities lie for folks that are looking to do something?

22:01.560 --> 22:07.320
Yeah, I think there's a huge amount of opportunity leveraging artificial intelligence and we're

22:07.320 --> 22:13.280
starting to see that by the sheer number of startups that are being formed around AI.

22:13.280 --> 22:18.280
I think one thing that excites me a lot is this personalization capability I mentioned

22:18.280 --> 22:25.240
in talking about training your pets, training your mom's name and your photos. But that

22:25.240 --> 22:30.040
could be anywhere. It could be in your Alexa learning about you. It could be in all your

22:30.040 --> 22:36.800
devices. And the more we see that, the more AI is going to fit to each individual and I

22:36.800 --> 22:39.720
think that's going to be the next wave of AI.

22:39.720 --> 22:42.960
It's awesome. It's awesome. Any parting thoughts?

22:42.960 --> 22:48.480
I would urge that any person interested in starting an AI company is not doing it to

22:48.480 --> 22:54.200
ride the wave, I think. And not doing it just because you have cool technology, I think

22:54.200 --> 22:59.440
you really want to have a passion for starting a company because as the company gets bigger

22:59.440 --> 23:03.920
and bigger, you'll be doing, if you're the CEO, you'll be doing less and less of the

23:03.920 --> 23:08.880
technology yourself. So just keep that in mind when you're thinking about building a business.

23:08.880 --> 23:12.680
You mentioned that on stage. Does that sound like hard one, hard learn lessons?

23:12.680 --> 23:21.640
Yeah, it's always itch that I want to scratch to get into the code and work on new stuff.

23:21.640 --> 23:26.560
But there's a lot of things that only a CEO can do. And so that's my priority.

23:26.560 --> 23:31.040
Right. Well, Matt, thank you so much for taking the time and being on the show is very

23:31.040 --> 23:32.040
chatting with you.

23:32.040 --> 23:33.640
Thanks for having me.

23:37.640 --> 23:42.960
All right, everyone. That's our show for today. Once again, thanks so much for listening

23:42.960 --> 23:48.360
and for your continued support. Please don't forget to share your favorite quote from this

23:48.360 --> 23:54.680
show via the show notes page via Twitter or via our Facebook page. If you do, we'll be

23:54.680 --> 24:01.000
happy to send you one of our laptop stickers. The notes for this show will be up on twomolei.com

24:01.000 --> 24:07.040
slash talk slash 22 where you'll find links to Matt and clarify in the various resources

24:07.040 --> 24:20.560
we've mentioned in the show. Thanks so much for listening and catch you next time.

