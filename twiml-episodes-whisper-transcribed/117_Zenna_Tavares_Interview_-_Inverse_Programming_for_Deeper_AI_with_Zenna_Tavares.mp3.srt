1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,080
I'm your host Sam Charrington.

4
00:00:31,080 --> 00:00:36,040
I want to start out with a huge thanks to everyone who joined in on our My AI discussion

5
00:00:36,040 --> 00:00:37,840
over the last few weeks.

6
00:00:37,840 --> 00:00:42,800
We received some outstanding entries to the contest, and now it's your turn to check

7
00:00:42,800 --> 00:00:45,000
them out and vote for a winner.

8
00:00:45,000 --> 00:00:51,240
Do this by visiting our contest page at twimbleai.com slash My AI.

9
00:00:51,240 --> 00:00:57,360
Swimming remains open through Sunday March 14th at 11.59pm Eastern time.

10
00:00:57,360 --> 00:01:00,680
A quick bit about the next Twimble online meetup.

11
00:01:00,680 --> 00:01:06,080
The meetup will be on Tuesday March 13th, and Sean Devlin will be doing an in-depth review

12
00:01:06,080 --> 00:01:11,520
of reinforcement learning and presenting the Google Deep Mind paper, playing Atari with

13
00:01:11,520 --> 00:01:13,920
deep reinforcement learning.

14
00:01:13,920 --> 00:01:22,280
Get on over to twimbleai.com slash Meetup to learn more or register.

15
00:01:22,280 --> 00:01:27,000
For today's show, the final episode in our Black and AI series, I'm speaking with Zena

16
00:01:27,000 --> 00:01:32,680
Tavarez, a PhD student in both the Department of Brain and Cognitive Sciences and the Computer

17
00:01:32,680 --> 00:01:36,600
Science and Artificial Intelligence Lab at MIT.

18
00:01:36,600 --> 00:01:41,040
I spent some time with Zena after his talk at the Strange Loop Conference, titled Running

19
00:01:41,040 --> 00:01:44,680
Programs in Reverse for Deeper AI.

20
00:01:44,680 --> 00:01:49,240
Zena shared some great insight into his work on program inversion, an area which lies

21
00:01:49,240 --> 00:01:54,960
at the intersection of Bayesian modeling, deep learning, and computational logic.

22
00:01:54,960 --> 00:01:59,120
We set the stage with the discussion of inverse graphics and the similarity between graphic

23
00:01:59,120 --> 00:02:01,520
inversion and vision inversion.

24
00:02:01,520 --> 00:02:05,680
We then discussed the application of these techniques to intelligent systems, including

25
00:02:05,680 --> 00:02:08,080
the idea of parametric inversion.

26
00:02:08,080 --> 00:02:13,400
Last, but not least, Zena details how these techniques might be implemented and discusses

27
00:02:13,400 --> 00:02:19,920
his work on reverse flow, a library to execute tensorflow programs backwards, and sigma.jl,

28
00:02:19,920 --> 00:02:25,840
a probabilistic programming environment implemented in the Dynamic Programming Language, Julia.

29
00:02:25,840 --> 00:02:29,320
This talk packs a punch, and I'm glad to share it with you.

30
00:02:29,320 --> 00:02:34,320
Let's get to it.

31
00:02:34,320 --> 00:02:38,840
Hey everyone, I am here at the Strange Loop Conference, and I have the pleasure of being

32
00:02:38,840 --> 00:02:49,320
joined by Zena Tavarez, and Zena is a PhD student at MIT, and he is, actually, he spoke

33
00:02:49,320 --> 00:02:55,960
this morning here at the conference on Running Programs in Reverse for Deeper AI, and I'm

34
00:02:55,960 --> 00:03:01,200
really interested in hearing more about what that's all about.

35
00:03:01,200 --> 00:03:02,200
So welcome.

36
00:03:02,200 --> 00:03:03,200
Thank you, Zena.

37
00:03:03,200 --> 00:03:05,800
Great to have you on.

38
00:03:05,800 --> 00:03:09,840
So why don't we start by having you tell us a little bit about your background, how

39
00:03:09,840 --> 00:03:14,160
you got interested in AI, what are you up to at MIT, all that stuff?

40
00:03:14,160 --> 00:03:16,640
Yeah, so I'm from London.

41
00:03:16,640 --> 00:03:22,760
I studied electronic engineering for my undergrad, and I think I first got into research.

42
00:03:22,760 --> 00:03:27,920
I became interested in research when I studied abroad in Japan, and so I went to Japan,

43
00:03:27,920 --> 00:03:31,880
and I worked in this lab, the PI for that lab, the advisor for that lab.

44
00:03:31,880 --> 00:03:37,280
His famous Japanese guy, you might have seen him, he builds these really lifelike robots,

45
00:03:37,280 --> 00:03:40,760
so he builds them of people in the lab, so look, there's one of him, and there's one

46
00:03:40,760 --> 00:03:46,200
of some of the lab students, oh wow, and so that was my first kind of touch of research,

47
00:03:46,200 --> 00:03:50,400
and I thought, this is a cool environment, and also I thought studying the brain is a

48
00:03:50,400 --> 00:03:55,720
cool thing, and so I finished my undergrad, I did a master's degree, which is in basically

49
00:03:55,720 --> 00:04:00,000
neuroscience, and so then after that I thought, okay, let me come to the States, and I came

50
00:04:00,000 --> 00:04:05,640
to MIT, and I joined MIT in the BCS, which is the brain and cognitive sciences department,

51
00:04:05,640 --> 00:04:10,480
so it's a mixture of neuroscience and cognitive science, which is basically psychology,

52
00:04:10,480 --> 00:04:14,880
okay, and from there I kind of transitioned more into the computer science side, and so

53
00:04:14,880 --> 00:04:19,760
now I sit in C cell, the computer science AI lab, and where I work on basically using

54
00:04:19,760 --> 00:04:25,240
ideas from computer science and programming languages to study things about how the mind

55
00:04:25,240 --> 00:04:26,240
works.

56
00:04:26,240 --> 00:04:33,640
But wow, wow, sounds like a, you've been a bunch of interesting places, for sure.

57
00:04:33,640 --> 00:04:39,640
So I read the abstract for your talk, running programs in reverse, and it sounds like

58
00:04:39,640 --> 00:04:43,840
that's a thing, like programming version, I hadn't heard about that before, you tell

59
00:04:43,840 --> 00:04:48,920
us a little bit about programming version and like, how, where's the intersection between

60
00:04:48,920 --> 00:04:49,920
that and AI?

61
00:04:49,920 --> 00:04:57,760
Sure, so maybe the best way to describe it is how I came to the problem, and so there's

62
00:04:57,760 --> 00:05:03,600
a professor at MIT called Just Ten and Bound, and when I joined MIT he was talking about

63
00:05:03,600 --> 00:05:04,600
this idea.

64
00:05:04,600 --> 00:05:10,720
Just Ten and Bound, the networking guy, or operating systems, I don't think so, he's

65
00:05:10,720 --> 00:05:16,680
more of a psychologist, a co, okay, I think there's another Just Ten and Bound that wrote

66
00:05:16,680 --> 00:05:24,280
a book, and I forget which book that we use in, in my engineering program, either networking

67
00:05:24,280 --> 00:05:27,400
or operating systems or something.

68
00:05:27,400 --> 00:05:30,720
Yeah, well I think it's the same thing, it could be the same thing, anyway, so Just Ten

69
00:05:30,720 --> 00:05:39,120
and Bound, MIT and MIT, okay, and he told me about this idea of inverse graphics, and

70
00:05:39,120 --> 00:05:44,360
the way he describes it is basically like this, so you can think of rendering this process,

71
00:05:44,360 --> 00:05:49,960
which using animation films like Toy Story to go from a 3D representation of the world

72
00:05:49,960 --> 00:05:55,840
to 2D images or a video that you're going to see when you go to the movies, and you

73
00:05:55,840 --> 00:06:01,360
can think of vision as in seeing as the inverse of that process, in the sense that I get

74
00:06:01,360 --> 00:06:06,040
into my eyes two dimensional images, and somehow from now I infer the three dimensional

75
00:06:06,040 --> 00:06:11,160
structure of the world, I infer the geometry I can figure out where the light saw, I can

76
00:06:11,160 --> 00:06:15,600
figure out where I am in relation to the world, and so there's this like inverse relationship

77
00:06:15,600 --> 00:06:22,480
between rendering or graphics and vision, okay, and so it's not, I don't think it's his

78
00:06:22,480 --> 00:06:27,160
idea, it's an old idea in computer vision, but nobody's really taking it literally,

79
00:06:27,160 --> 00:06:32,360
right, and so some other people in Josh's lab, like Tedges and Elka, they've worked on similar

80
00:06:32,360 --> 00:06:38,120
projects, and the idea I had was okay, what if we like literally literally took this

81
00:06:38,120 --> 00:06:44,080
idea, like what if we took a rendering algorithm similar to the kind they use in computer graphics

82
00:06:44,080 --> 00:06:49,520
and tried to run that algorithm backwards, from the output, from the image literally backwards

83
00:06:49,520 --> 00:06:57,080
to the 3D structure, oh wow, okay, so that was the kind of the motivation, like how I came

84
00:06:57,080 --> 00:07:03,080
to this project, and then after we started, I mean there's many issues that arise, but

85
00:07:03,080 --> 00:07:06,840
we realized that it's actually kind of a general framework that we can use to think about

86
00:07:06,840 --> 00:07:12,640
many different kinds of problems, okay, and it sounds like at least in the graphics case,

87
00:07:12,640 --> 00:07:20,120
it works generally, I mean it works in the research sense, right, so I mean it produces

88
00:07:20,120 --> 00:07:26,480
something, yeah, we have a working prototype for a particular kind of graphics, so we can

89
00:07:26,480 --> 00:07:34,120
take in 2D images from a fairly primitive voxel renderer, so the images in the output

90
00:07:34,120 --> 00:07:40,560
are 3D voxel shapes, so we can't do like super complicated geometric structure, but we

91
00:07:40,560 --> 00:07:45,080
can do kind of cool interesting shapes, and we're doing it in a way which I don't think

92
00:07:45,080 --> 00:07:51,600
anybody has done before, so we hope that we can scale up to these, to real realistic

93
00:07:51,600 --> 00:07:57,800
scenes, but that's going to require a lot more work, okay, okay, and so what you were talking

94
00:07:57,800 --> 00:08:03,520
about here was applying that to AI, so yeah, so I started with this example of inverse

95
00:08:03,520 --> 00:08:10,200
rendering, inverse graphics, right, but the way I opened my talk was talking about this

96
00:08:10,200 --> 00:08:15,840
idea of mental simulation, so mental simulation is an idea, it's an old idea in psychology,

97
00:08:15,840 --> 00:08:19,440
and the basic idea is that the way that you can reason about the world, like the way that

98
00:08:19,440 --> 00:08:24,480
I can pick up objects or know that something is stable or unstable, is that I have a kind

99
00:08:24,480 --> 00:08:28,880
of simulator in my head, right, and so I look at the world, I can show up to model of

100
00:08:28,880 --> 00:08:32,480
the world inside my head, and then I can run that simulation and figure out what's going

101
00:08:32,480 --> 00:08:37,120
to happen, so I can figure out, oh, this is, this is, this object's not stable because

102
00:08:37,120 --> 00:08:43,840
in my simulation it falls over, right, and so one of the ways that we're trying to basically

103
00:08:43,840 --> 00:08:48,400
extend this idea of inverse graphics to more general problems is say, or can we like

104
00:08:48,400 --> 00:08:53,800
do inverse physical simulation, right, so for example, you could say things like, oh,

105
00:08:53,800 --> 00:09:00,680
what I want to do is fold some clothes, right, or I want to, you know, pick up some object

106
00:09:00,680 --> 00:09:04,680
in some, you know, in some dynamic environment, and so one way to frame that problem is to

107
00:09:04,680 --> 00:09:10,560
say, well, I have some end state that I'm trying to get to, let me run a kind of a physical

108
00:09:10,560 --> 00:09:15,000
simulation backwards and say, okay, what are the inputs that have to go into that system

109
00:09:15,000 --> 00:09:19,560
for me to reach the desired end state, okay, and so that's the way that we're trying to solve

110
00:09:19,560 --> 00:09:22,920
the problem, I mean, many people approach the problem in various different ways, I would

111
00:09:22,920 --> 00:09:26,320
say that the kind of the main distinguishing point about our approach is that we really

112
00:09:26,320 --> 00:09:30,200
try to take this idea literally, we take real physical simulations and we're trying

113
00:09:30,200 --> 00:09:34,400
to run them backwards, the tools that we've developed, they're quite general, so they

114
00:09:34,400 --> 00:09:39,240
can apply to many different problems, so if you can reformulate your problem in terms

115
00:09:39,240 --> 00:09:44,040
of a kind of programming version, then hopefully we can have a like a stab at trying to solve

116
00:09:44,040 --> 00:09:45,040
it.

117
00:09:45,040 --> 00:09:52,040
And so do I need to reformulate my problem in terms of, in the terms of programming

118
00:09:52,040 --> 00:09:55,920
version, or is that something that your tools will do or help me do?

119
00:09:55,920 --> 00:10:02,080
That's something you need to do, but I mean, it's not like, you're speaking of me reformulating

120
00:10:02,080 --> 00:10:09,520
my problem at the level of a problem statement, or like, I've got the, okay, not my program.

121
00:10:09,520 --> 00:10:13,600
Yeah, yeah, so the problem statement, that's what I'm talking about, so if you can formulate

122
00:10:13,600 --> 00:10:19,920
your problem in your head or like, as a former programming version, and what I would argue

123
00:10:19,920 --> 00:10:24,000
is that actually many problems can be formulated in terms of programming version, right, because

124
00:10:24,000 --> 00:10:30,560
programs are very general things, right, can you give us some examples of ones that will

125
00:10:30,560 --> 00:10:32,400
help us wrap our heads around the concept?

126
00:10:32,400 --> 00:10:38,160
Sure, so, okay, so for example, and I'm not saying that we can solve this kind of problem

127
00:10:38,160 --> 00:10:43,760
yet, right, but for example, you know, if you had a big kind of quantum simulator, right,

128
00:10:43,760 --> 00:10:49,320
which takes this input, some molecules, and as output, you know, it says, okay, how efficient

129
00:10:49,320 --> 00:10:54,280
would this molecule be as, you know, in a solar panel, for example, okay, so this is like

130
00:10:54,280 --> 00:10:57,640
a forward simulator, it does all kind of quantum simulations, and it says, okay, the efficiency

131
00:10:57,640 --> 00:11:03,160
of this molecule, you know, is 90%, whatever, right, so you can think of the inverse of that

132
00:11:03,160 --> 00:11:08,280
process as going from the efficiency that you want back to the molecule, so now you have

133
00:11:08,280 --> 00:11:14,440
a kind of discovery of chemicals, right, got it, or optimization, right, so, you know,

134
00:11:14,440 --> 00:11:19,320
optimization, optimization comes up in all kinds of fields, and so you have some loss function

135
00:11:19,320 --> 00:11:23,560
which takes in something and says, okay, how good is that thing, right, if you can invert

136
00:11:23,560 --> 00:11:27,960
an optimization, so if you can invert a loss function, you can do optimization, you can say,

137
00:11:27,960 --> 00:11:32,600
okay, here is the cost that I'm trying to achieve, right, what is the input that, you know,

138
00:11:32,600 --> 00:11:37,640
realizes that cost, right, it strikes me from hearing the examples that you gave that,

139
00:11:37,640 --> 00:11:47,160
you know, the challenges that the, in the forward direction, the output space is like much more

140
00:11:47,160 --> 00:11:52,760
constrained, it's a number, right, whereas in the reverse direction, the output space is massive,

141
00:11:52,760 --> 00:11:58,360
if not infinite, yeah, yeah, yeah, exactly, so, yeah, so when I first came to this, you know,

142
00:11:58,360 --> 00:12:03,240
this idea, you know, I remember I was sitting in one of Josh's, just telling Bob, so that

143
00:12:03,240 --> 00:12:07,480
means, I think, okay, why don't we just try and run this program backwards, right, and obviously,

144
00:12:07,480 --> 00:12:12,360
the first thing you get into is that often these functions or these programs are not invertible,

145
00:12:12,360 --> 00:12:16,840
right, which means that there are many outputs which map to the same, so many inputs which map

146
00:12:16,840 --> 00:12:22,520
to the same output, and so in the inverse direction, you have a choice, like, which way should you go,

147
00:12:22,520 --> 00:12:26,760
which way should you go backwards, right, if I've got any x's which map to y, and I'm going

148
00:12:26,760 --> 00:12:31,320
backwards from y to x, like, what should I choose, how do I do that, right, and so the theory that

149
00:12:31,320 --> 00:12:37,640
I came up with, we now call parametric inversion, okay, and basically says, if you're trying to invert

150
00:12:37,640 --> 00:12:42,280
a non-invertical function, so there's multiple x, there's multiple inputs which map to the same

151
00:12:42,280 --> 00:12:48,440
output, we can parameterize that choice, okay, we construct this new thing, we call it a parametric

152
00:12:48,440 --> 00:12:54,760
inverse, so we'll take in some value y, but also a parameter theta, and give you back one of the

153
00:12:54,760 --> 00:13:01,080
x's which map to y, so just to give me a very simple example, absolute value function is not invertible,

154
00:13:01,080 --> 00:13:06,040
right, so because if I take the absolute value of five, I get five, yeah, if I take absolute value

155
00:13:06,040 --> 00:13:10,120
of minus five, I get also get five, right, but I can construct this thing called a parametric

156
00:13:10,120 --> 00:13:15,880
inverse, and it will take in some value, let's call it y, five in this case, and the parameter,

157
00:13:15,880 --> 00:13:21,560
let's say it's either one or minus one, and it will just return this parameter theta times y,

158
00:13:22,120 --> 00:13:26,040
right, so the point is that the output, depending on your choice of theta, will be either

159
00:13:26,040 --> 00:13:32,440
five or minus five, right, obviously that's a kind of a trivial example, but the intuition or the

160
00:13:32,440 --> 00:13:37,160
idea that we had was, oh, you can define these simple inverses for all of our simple functions,

161
00:13:37,160 --> 00:13:43,080
like absolute value, addition, multiplication, sign, and so on, and it turns out with a little bit of

162
00:13:43,080 --> 00:13:48,840
work, actually you can define inverses for much more complicated functions, or much more complicated

163
00:13:48,840 --> 00:13:54,600
programs. And is the idea then for, with the example that you gave around finding a molecule that

164
00:13:54,600 --> 00:14:01,160
achieves x, you know, a level of efficiency in a solar panel that you would be able to

165
00:14:02,280 --> 00:14:08,280
constrain by some set of molecules, or for example, that would be your parameter.

166
00:14:08,280 --> 00:14:11,960
So in this case, so, yeah, so suppose you give me some program, it's forward simulation,

167
00:14:11,960 --> 00:14:16,760
right, and I think I can construct this parametric inverse, so you'll have many parameters,

168
00:14:16,760 --> 00:14:21,240
and as you vary over the parameters, you'll get out different molecules with the desired

169
00:14:21,240 --> 00:14:27,320
efficiency. And so if you have some further constraints, I don't know, maybe you want a small

170
00:14:27,320 --> 00:14:31,400
molecule, or maybe you want a molecule that you can synthesize, then you can add these constraints

171
00:14:31,400 --> 00:14:35,960
to the, you can impose those constraints on the parameter space, right, and so a parametric

172
00:14:35,960 --> 00:14:40,040
inverse basically gives you the choice, you choose a parameter value, and it'll be back one of

173
00:14:40,040 --> 00:14:45,720
like a different input which maps to the same output. And so you mentioned that you have

174
00:14:45,720 --> 00:14:52,280
your current researches, or you mentioned in your abstract, I should say your current researches

175
00:14:52,280 --> 00:14:58,680
applying this specifically to TensorFlow programs, and inverting the computational graphs for

176
00:14:58,680 --> 00:15:03,480
deep neural nets. So yeah, so we built a lot of machinery around TensorFlow programs.

177
00:15:03,480 --> 00:15:11,080
Okay. It's not so much that we're focused on inverting neural networks, although that's

178
00:15:11,080 --> 00:15:15,400
something that we've been considering, just that TensorFlow programs have a nice kind of

179
00:15:15,400 --> 00:15:20,120
representation which is amenable to our algorithms, right, and so TensorFlow, you know,

180
00:15:20,120 --> 00:15:26,120
the graph structure, the graph structure, yeah, so people often use it for, you know,

181
00:15:26,120 --> 00:15:29,960
neural networks, but really it's a general kind of programming language, like in a better

182
00:15:29,960 --> 00:15:38,760
programming language. And so we have a tool, some GitHub, in some kind of slightly broken

183
00:15:38,760 --> 00:15:44,840
state, but one thing I would say is that more recently we've been moving over to using the

184
00:15:44,840 --> 00:15:50,680
Julia program in language. Okay. And so we've kind of been building our own version of TensorFlow

185
00:15:51,560 --> 00:15:56,920
in Julia. It's still thing. Yeah, so we still can compile down to TensorFlow if you want to use

186
00:15:56,920 --> 00:16:00,920
TensorFlow. Okay. TensorFlow has all these great things for optimization and so on that we want to,

187
00:16:00,920 --> 00:16:06,120
you know, I don't want to re-implement. Right. So we can still compile down to TensorFlow and Python,

188
00:16:06,840 --> 00:16:11,880
but we basically we move to Julia because, um, basically because of the type system it allows us

189
00:16:11,880 --> 00:16:17,080
to do a lot more things more efficiently with a lot less code. So that's the, that's the

190
00:16:17,080 --> 00:16:21,240
direction we're going. And I would also recommend other people check out Julia if they get the

191
00:16:21,240 --> 00:16:27,800
chance. Huh. So can you give me some examples of the application of this AI systems or deep learning

192
00:16:27,800 --> 00:16:35,000
systems? Yeah. So, so the ones, I mean, the ones I've spoken about in vision. So, you know,

193
00:16:35,000 --> 00:16:39,480
basically if we're trying to build robots that act in the real world, they're going to have to

194
00:16:39,480 --> 00:16:43,880
manipulate objects in the real world. Right. So, you know, for example, you can pick up a cup,

195
00:16:43,880 --> 00:16:47,640
right. This cup on the table and you know, it's, you know, it's a little bit elastic. It has a

196
00:16:47,640 --> 00:16:51,880
particular shape. It has some, you know, resistance. All these things you know about the physical world

197
00:16:52,440 --> 00:16:56,280
allow you to freely interact with the physical world. Right. And so you have some physical

198
00:16:56,280 --> 00:17:02,200
intuition. And I would argue that in order to build robots that aren't so rigid in how they

199
00:17:02,200 --> 00:17:07,800
interact with the world, we're going, we're going to have to kind of embed that physical knowledge

200
00:17:07,800 --> 00:17:13,720
into their brains as well. Okay. And one way to do that is to allow them to have a simulator in

201
00:17:13,720 --> 00:17:19,080
a mind. But many of the things that they'll use this simulation for are kind of inverse simulation.

202
00:17:19,080 --> 00:17:23,720
So they'll, you know, for example, they may see the cup on the floor and they can figure out,

203
00:17:23,720 --> 00:17:30,760
oh, it fell over at some point in time. Or to go to the lower, like the lower perceptual things,

204
00:17:30,760 --> 00:17:34,760
like how does a robot learn to see? How does a robot see in the world? Well, it's got to take in

205
00:17:34,760 --> 00:17:39,480
images, you know, in its camera eyes and somehow figure out the geometric structure of the world.

206
00:17:39,480 --> 00:17:43,960
So it knows that the door, you know, is so, you know, so far away, it can just

207
00:17:43,960 --> 00:17:48,760
ambiguous between the colors of the lights versus the color of the material. So I think many of

208
00:17:48,760 --> 00:17:54,280
like the core, I don't have a like a concrete thing that we're trying to build, but I think many of

209
00:17:54,280 --> 00:18:01,400
the core problems in AI, you know, this kind of technology is relevant to me. It's still a research

210
00:18:01,400 --> 00:18:08,200
project. I mean, yeah. So it's kind of thing that we do. And so you were careful to kind of

211
00:18:08,200 --> 00:18:16,520
distinguish between TensorFlow as a general programming framework and it's common use in deep

212
00:18:16,520 --> 00:18:24,920
learning. But does the work that you've done and the results that you've seen with reverse flow

213
00:18:24,920 --> 00:18:32,200
apply to deep neural nets that are constructed in TensorFlow? And like, what are there any like

214
00:18:32,200 --> 00:18:40,440
practical examples that you can cite of taking like a real TensorFlow program and doing this program

215
00:18:40,440 --> 00:18:46,920
in version to it and having it produce something? Yeah. So there was a lot of, I mean, there's a

216
00:18:46,920 --> 00:18:52,040
lot of work with like adversarial examples recently. And like, but before, you know, those work

217
00:18:52,040 --> 00:18:57,000
basically say, okay, if I've trained some neural network, I want to find out, you know, what

218
00:18:57,000 --> 00:19:01,640
inputs would cause a kind of weird misclassification. People have worked on this for a little while.

219
00:19:02,680 --> 00:19:08,120
And so in some sense, we can invert neural networks in a kind of, in a sense that, you know,

220
00:19:08,120 --> 00:19:15,000
even a complicated neural network eventually just boils down to some sequence of primitive operations.

221
00:19:15,000 --> 00:19:20,040
Sure. Basically multiplications, sounds, and some right, nonlinearity. Even that nonlinearity

222
00:19:20,040 --> 00:19:25,160
also boils down to even simpler things. So because our inversion algorithm is defined in terms

223
00:19:25,160 --> 00:19:31,160
of these primitive operations, in principle, we can invert, you know, a neural network with

224
00:19:31,160 --> 00:19:36,360
the current framework. But in practice, it's not the best way to do it. And so one of the things

225
00:19:36,360 --> 00:19:43,000
that we've been working on is how can we kind of take a better approach to inverting neural networks?

226
00:19:43,000 --> 00:19:45,960
And so to the second part of your question, like, why might you want to do that?

227
00:19:45,960 --> 00:19:51,640
But for me, I think the most interesting application is, again, inverting models of the world. So

228
00:19:52,440 --> 00:19:57,720
I've worked on inverse graphics. And to do that, I write down a normal render in algorithm.

229
00:19:57,720 --> 00:20:01,560
I happen to write it in TensorFlow, but, you know, I could have written it in Python or see

230
00:20:01,560 --> 00:20:08,200
or so on. But I think humans, we learn algorithms. We learn algorithms, you know, from experience.

231
00:20:08,920 --> 00:20:14,520
And so it'll be nice if we could take a learned algorithm. So something like a neural network

232
00:20:14,520 --> 00:20:19,000
and also invert that. So I do, I can do inverse graphics. But the algorithm that I'm

233
00:20:19,000 --> 00:20:24,840
inverting is a more realistic version of reality. Is there an implication there that you're

234
00:20:26,200 --> 00:20:31,960
inverting not a, I guess the picture that I had in my head of this was that you're

235
00:20:33,240 --> 00:20:40,520
not you're inverting a, I guess an architecture absence of like having been trained.

236
00:20:40,520 --> 00:20:45,640
Yeah. But it sounds like what you're saying is you're, you know, the learning is coming in through

237
00:20:45,640 --> 00:20:50,760
the training. And so we're inverting this trained. No, it's not something that we're doing right now.

238
00:20:50,760 --> 00:20:56,200
Right. Right now we think conceptual. This is conceptual. I mean, maybe like a better example would be

239
00:20:57,000 --> 00:21:03,080
in like physics and dynamics. So we can build pretty impressive physical simulators that work

240
00:21:03,080 --> 00:21:08,120
well for, you know, rigid bodies and, you know, some elastic bodies. But they're not so good at

241
00:21:08,120 --> 00:21:13,240
things like hair, for example, and they're not so good at simulating things like cloth. And yet

242
00:21:13,240 --> 00:21:18,520
humans can still, you know, manipulate cloth. We still have a good intuition about how that works.

243
00:21:19,240 --> 00:21:24,200
And so I think a learning approach could supplement that so we can maybe have some part of that

244
00:21:24,200 --> 00:21:28,440
model which is, you know, handwritten and some part of that model is learn from experience. And there

245
00:21:28,440 --> 00:21:33,480
are people who are working on this right now. It's interesting. So one of the examples that

246
00:21:33,480 --> 00:21:39,960
comes to mind for me is there are some folks at Berkeley in their intelligent robotics lab that

247
00:21:39,960 --> 00:21:48,280
are applying reinforcement learning to teaching a robot how to tie a knot. Right. Right. And a rope.

248
00:21:49,800 --> 00:21:56,280
And so, you know, they're, you know, the rope, the rope is basically trying to mess around with

249
00:21:56,280 --> 00:22:04,360
the rope and learn the rope dynamics. And it sounds like, you know, the approach that you're describing

250
00:22:04,360 --> 00:22:10,040
would be, I don't know, how, how would the approach you're describing fit into that? It's like,

251
00:22:10,040 --> 00:22:18,040
once you learn this model for kind of basic rope dynamics, you can invert it to what is the

252
00:22:18,040 --> 00:22:23,640
conceptual thing that you're inverting it to? So like the way you have to formulate this,

253
00:22:23,640 --> 00:22:28,360
formulate it in this way, you'd say, okay, I have a model of, you know, rope dynamics.

254
00:22:28,920 --> 00:22:33,320
Right. And you can think about this as a, probably a temporal model, right. So the time is

255
00:22:33,320 --> 00:22:39,320
available. And I have some desired state, like I want, you know, after some amount of time to

256
00:22:39,320 --> 00:22:44,120
whatever, right. I want the rope to be in a knotted state. Right. And so the inputs that

257
00:22:44,120 --> 00:22:51,480
at system are my actions. And obviously the system also acts in the absence of me doing anything.

258
00:22:51,480 --> 00:22:55,000
Right. Right. And so it's the inversion in the sense that I have to figure out what are the

259
00:22:55,000 --> 00:23:02,280
actions that I need to input into the system for me to tie them not. Right. Right. And so this is,

260
00:23:02,280 --> 00:23:07,960
I'm supposed to, these actions produce this model. Right. And so like, I mean, in some ways,

261
00:23:07,960 --> 00:23:11,320
you know, people have an intuition. It's like, if I want to do something, like, what do I have to

262
00:23:11,320 --> 00:23:16,360
do for that to be true? Yeah. And so that's how you would formulate the problem in this way.

263
00:23:16,360 --> 00:23:25,080
Um, but the rope dynamics, as I'm saying, as I've been saying, this is something I think you

264
00:23:25,080 --> 00:23:29,880
could learn. Right. We don't, I mean, maybe people do have, you know, good models for rope dynamics,

265
00:23:29,880 --> 00:23:33,080
I'm not sure. I think it's so work in progress. Right. Okay. So yeah.

266
00:23:34,920 --> 00:23:38,680
Interesting. Interesting. So what else did you cover in the talk?

267
00:23:40,200 --> 00:23:44,520
So the third, I mean, the first, I talked a bit about Julia. I would say that the first,

268
00:23:44,520 --> 00:23:48,920
you know, 10 minutes was, actually, I talked a little about psychology experiments.

269
00:23:48,920 --> 00:23:56,280
Okay. Um, from what perspective? So there's an experiment from the 1970s. I mean, so

270
00:23:57,160 --> 00:24:01,480
these are all about this idea of mental simulation. Okay. And it's kind of, you know,

271
00:24:01,480 --> 00:24:06,840
it's kind of hard to describe without diagrams, but the basic idea, it's called mental rotation,

272
00:24:06,840 --> 00:24:11,720
the basic idea is that you can see different shapes. And they're either the same shape,

273
00:24:11,720 --> 00:24:17,400
but rotate it from different angles or their different shapes. Like different shapes entirely.

274
00:24:17,400 --> 00:24:22,520
Okay. And so people did these studies where they said, okay, look at many of these shapes and

275
00:24:22,520 --> 00:24:26,360
say whether you think they're the same or whether you think they're different. And what they found

276
00:24:26,360 --> 00:24:32,840
is a very tight linear correlation with the angle of rotation and the amount of time it took people

277
00:24:32,840 --> 00:24:38,760
to respond. Okay. Like, lending some support to the idea that the way people answer this question

278
00:24:38,760 --> 00:24:42,600
is that they look at these, they look at the shapes and they do a kind of mental rotation. And they

279
00:24:42,600 --> 00:24:48,440
say, oh, I can rotate shape A into shape B. And like, if they're more, you know, if they're more

280
00:24:48,440 --> 00:24:54,280
rotated, they're longer than simulation takes. Yeah. And so like a whole subfield of psychological

281
00:24:54,280 --> 00:24:59,400
research came out of that idea. And so some part of my talk was saying, okay, this is, you know,

282
00:24:59,400 --> 00:25:04,040
obviously there's a lot of who work there. And I always see they've done a lot of studies,

283
00:25:04,040 --> 00:25:08,520
can we take that idea and make it computational? Can we build computational models of it?

284
00:25:08,520 --> 00:25:13,720
And can we build an AI that can do something similar? And if we were to do that, what kind of

285
00:25:13,720 --> 00:25:19,080
technologies would we need? What kind of algorithm would we need? So like, personally, I'm

286
00:25:19,080 --> 00:25:23,480
motivated by like core interest in small studies like this, which pinpoint something interesting

287
00:25:23,480 --> 00:25:28,040
about how the mind works. And then you realize that despite all the kind of core stuff that's

288
00:25:28,040 --> 00:25:32,600
happening in AI at the moment, deep learning, there are all these really simple things that we really

289
00:25:32,600 --> 00:25:36,520
haven't even got the right way to think about. Right. And so those are the things that interest

290
00:25:36,520 --> 00:25:44,680
the most. Right. Right. Cool. And then you mentioned Julia. You mentioned the type, the type safe

291
00:25:45,480 --> 00:25:53,400
aspect of it. Is Julia something that comes up a lot in the context of AI? Does it lend

292
00:25:53,400 --> 00:25:59,880
itself to that type of work? Specifically, I haven't heard it come up in that context much.

293
00:25:59,880 --> 00:26:08,200
Yeah. So I'm in the main frameworks for AI definitely in Python. Sure. Right. And I guess

294
00:26:08,200 --> 00:26:13,720
that's taught, which is a lure. Right. But I would say Julia is building momentum. So Julia,

295
00:26:13,720 --> 00:26:19,000
I mean, it came out of MIT and the people who did it, you know, well, kind of data scientists,

296
00:26:20,280 --> 00:26:25,320
maybe not machine learning people as such, but people who use MATLAB or see, I think that

297
00:26:25,320 --> 00:26:29,480
I was watching a guy watching a talk. And one of the main developers who said he had this

298
00:26:29,480 --> 00:26:36,040
huge stack of C, R, MATLAB, and Python. Right. And it's like, why is it so complicated? And so

299
00:26:36,040 --> 00:26:40,680
that was kind of the birth of of this language. To the main point, so that one, it's very fast.

300
00:26:41,240 --> 00:26:47,480
Okay. It's dynamic. It's also compiled. And it has a kind of interest in type system,

301
00:26:47,480 --> 00:26:51,320
like a multi-method dispatch type system. I mean, it's what does that mean?

302
00:26:53,240 --> 00:26:58,840
So like in an object-oriented language, like Python, for example, or C++, you have some

303
00:26:58,840 --> 00:27:04,520
object, like, I don't know, you have like cat, and you do cat dot, you know, make a sound, right?

304
00:27:04,520 --> 00:27:11,160
Cat dot meow. Cat dot meow. Um, in Julia, the methods, so this is what people call a single

305
00:27:11,160 --> 00:27:16,280
dispatch, right? But in Julia, the methods are not part of the object. They live, they live in

306
00:27:16,280 --> 00:27:23,400
like a separate space. Okay. And so you would do meow, which takes in an object of type cat,

307
00:27:24,280 --> 00:27:27,720
and it would meow that cat. And so obviously you can do more things. You can have meow

308
00:27:27,720 --> 00:27:32,520
taking an object of type cat and some other object, dog and, you know, the cat meow as a dog.

309
00:27:33,480 --> 00:27:38,360
So it sounds like a, you know, a simple thing, but it turns out that if you build your language

310
00:27:38,360 --> 00:27:44,440
on that principle, lots of nice, elegant features fall out. Um, is this related to the content

311
00:27:44,440 --> 00:27:49,320
of mixes? It's, you know, it's definitely not used in machine learning so much, but I would say there's

312
00:27:49,320 --> 00:27:55,080
a few packages like flux.jl. There's also a TensorFlow binding, TensorFlow.jl. Okay.

313
00:27:55,080 --> 00:27:59,880
Um, and so I think it's getting momentum. And I think because it's built on like a, like a nice

314
00:27:59,880 --> 00:28:05,560
set of core principles, I think actually it has the opportunity to strive as a machine learning,

315
00:28:06,760 --> 00:28:13,880
language. Okay. That's what I want. Nice. Nice. And does it, it presumably, it has some kind of,

316
00:28:13,880 --> 00:28:20,040
you know, native or provided by a package, uh, strong notion of matrices and arrays and all

317
00:28:20,040 --> 00:28:24,920
that stuff. Yeah. Yeah. So yeah, all of that stuff is. Oh, that's there. And it's really well designed

318
00:28:24,920 --> 00:28:30,760
as well. They put a lot of thought into how to take what's good about MATLAB, discard, what's bad.

319
00:28:32,360 --> 00:28:37,080
And so you have multi-dimensional arrays and you have all the kind of things that you would expect

320
00:28:37,080 --> 00:28:43,080
from like a numerical program language. Right. And it's fascinating. Also, there's like a GPU

321
00:28:43,080 --> 00:28:48,520
library now so you can call native CUDA. Okay. So there's a lot of stuff. Okay. Cool.

322
00:28:48,520 --> 00:28:55,000
Uh, did we hit on everything? Did you cover it in your talk? I think so pretty much. Yeah. Awesome.

323
00:28:55,000 --> 00:29:00,360
Awesome. Well, thanks so much for taking a few minutes to chat with us. All right. Thanks a lot. Appreciate it. Thanks.

324
00:29:03,640 --> 00:29:09,720
All right, everyone. That's our show for today. For more information on Xenna or any of the topics

325
00:29:09,720 --> 00:29:15,640
covered in this episode, head on over to twimlai.com slash talk slash 114.

326
00:29:15,640 --> 00:29:23,560
And definitely remember to vote for your favorite My AI video at twimlai.com slash My AI.

327
00:29:23,560 --> 00:29:53,480
And of course, thanks so much for listening and catch you next time.

