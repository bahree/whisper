WEBVTT

00:00.000 --> 00:19.440
All right. So once again, I am at NYU Future Labs with the AI Nexus companies. And this time,

00:19.440 --> 00:29.040
I'm with Muticia Nunda, the co-founder and CEO of Alpha Vertex. Say hi. Hi, thanks. Thanks for having

00:29.040 --> 00:38.240
me. So why don't we get started by having you tell us a little text and what you guys are up to?

00:38.240 --> 00:46.320
Sure. So Alpha Vertex is an innovative financial technology company that is using the next generation of

00:46.320 --> 00:55.280
AI tools to help support investing around the world. Practically what that means is that we develop

00:55.280 --> 01:00.560
predictive models that try to forecast the returns of stocks over multiple time horizons.

01:01.200 --> 01:08.400
And at present, we cover all major markets around the world. So we cover 30,000 stocks globally,

01:08.400 --> 01:15.280
which represent about 95% of the investable universe. Okay. And so presumably you came out of

01:15.280 --> 01:21.360
financial services prior to this? Yeah. So my background is in finance, I've spent over 17 years,

01:21.360 --> 01:29.040
I started out in investment banking, did private equity and ended up as the chief of staff of one

01:29.040 --> 01:33.760
of the largest proprietary market-making businesses in the world at a company called Sescohana International

01:33.760 --> 01:38.880
Group. And then after leaving that, I spent five years at Bloomberg as the head of strategy and

01:38.880 --> 01:44.160
business development for Bloomberg enterprise solutions. Okay. So I've kind of done my tour of duty

01:44.160 --> 01:48.480
on Wall Street and around Wall Street. You've got quite a few punches on your ticket.

01:48.480 --> 01:54.240
You know, it strikes me that of all the companies that I've talked to

01:55.600 --> 02:04.720
here at ANX this today, the trying to help people make better trades with financial data is

02:05.600 --> 02:14.560
there's nothing new about it. Right? That is a classical idea and lots of people have tried to apply,

02:14.560 --> 02:20.720
you know, we've been trying to apply analytics to this for many, many years. What is new and different

02:20.720 --> 02:26.800
about your approach to it? So I'll first just start by sort of saying you're absolutely right that

02:26.800 --> 02:33.520
it is not a new idea because it's not a new problem, but the present moment there's about 98% of

02:33.520 --> 02:39.760
all funds underperform their benchmark over 10 years. And the simple reason is that they rely on

02:39.760 --> 02:46.480
kind of traditional portfolio managers to act as stockpickers. And what happens there is that you

02:46.480 --> 02:52.640
have maybe 1% of all fund managers are kind of really good at making money, but then the 99%

02:53.280 --> 02:59.920
of the population ends up underperforming. And so you're subject to kind of the talent that you

02:59.920 --> 03:06.720
bring in. As financial markets get more and more complicated, you know, there's about 2.5 billion

03:06.720 --> 03:11.840
bytes of data nowadays that people kind of have to keep track of. It's increasingly difficult

03:11.840 --> 03:17.200
for a human being to sort of incorporate all of this information in a useful way into the investment

03:17.200 --> 03:22.960
strategy. So with the onset of, you know, innovations in machine learning and AI in general,

03:23.760 --> 03:30.000
you know, we're able to build models that can capture all of these pieces of information, much

03:30.000 --> 03:36.560
similar to the butterfly effect. So if you think about, we have AI models that sort of will see

03:36.560 --> 03:42.640
things that are happening in Asia and then model how they ripple through global markets to affect

03:42.640 --> 03:48.560
a stock like Apple or Google in the US. It's really, really challenging to be able to do that as a

03:48.560 --> 03:54.800
human being or to build a model that can capture that complexity. So that's sort of what we're doing

03:54.800 --> 04:00.800
that's completely different is we have these very sophisticated models that can kind of look out

04:00.800 --> 04:06.320
to 10 or, you know, 20 degrees of separation away and analyze how things that are going on very

04:06.320 --> 04:10.640
in very distant places can kind of ultimately come back to impact stocks.

04:15.120 --> 04:20.560
So that the, I mean, certainly the hedge funds have been trying to apply this type of stuff for

04:20.560 --> 04:27.440
a very long time as part of what you're doing, bringing the, you know, the quant type of technology

04:27.440 --> 04:33.920
that hedge funds have been doing to the traditional investors, the institutional side.

04:34.480 --> 04:39.680
Yeah, so we, you know, interestingly enough, the earliest adopters of our technology are obviously

04:39.680 --> 04:45.440
the quantitative of systematic hedge funds. They kind of understand how powerful this technology is

04:45.440 --> 04:51.200
and, you know, they employ data driven technology based investment strategies. And so this to them

04:51.200 --> 04:57.280
is a high value signal that is additive to maybe other things that they do on a proprietary basis.

04:58.160 --> 05:02.960
Ultimately, over the long run, what we want to do is make these tools kind of more broadly

05:02.960 --> 05:08.800
accessible to the 99% of the investment managers out there that don't have, you know,

05:08.800 --> 05:15.600
this technology driven investment platforms. So we're working on things like having, you know,

05:15.600 --> 05:21.360
kind of machine learning driven institutional class research and analytics facilities that,

05:21.360 --> 05:27.440
you know, can be accessed via natural language. So you don't have to have the technical capability

05:27.440 --> 05:33.680
of a data scientist or a statistician or a PhD person to be able to do the types of analysis

05:33.680 --> 05:40.080
that we're going to be developing. So I think, you know, in the near term, the earlier adopters

05:40.080 --> 05:44.640
are the more quantitative and hedge funds, but over the long run, we want to go after everybody

05:44.640 --> 05:52.240
in the space. Okay, so you guys are, it's not so much arming the folks that can't keep up with the

05:52.240 --> 06:03.840
quants is that you guys have developed some really cool stuff that the quants need to. Okay, and so, um, thinking about how one might

06:03.840 --> 06:13.200
try to build a machine learning AI, fly effect, that sounds super complex. Like how do you, what's the,

06:14.000 --> 06:19.920
what's the approach there? So it is actually a pretty huge problem. The first thing is you have to try

06:19.920 --> 06:24.880
to represent all the world's financial information in a way that makes sense. Oh, well, that's easy.

06:28.080 --> 06:34.640
So the approach that we've taken is we've modeled everything as a computational graph. And for people

06:34.640 --> 06:41.120
who aren't familiar with that is literally this multi-dimensional relationship map of how everything

06:41.120 --> 06:48.080
is interconnected to everything else. So you can describe things like Apple competes with Samsung,

06:48.080 --> 06:53.600
Apple is a customer of Samsung's and Apple is suing Samsung and all of these are relationships

06:53.600 --> 06:59.200
between these two nodes or these two entities. In a traditional model, you can't represent these

06:59.200 --> 07:05.680
multi-dimensional relationships across companies. And in our case, like in the case of where Apple

07:05.680 --> 07:12.160
is suing Samsung, Apple, the relationship has a direction. So Apple is instigating the legal

07:12.160 --> 07:17.600
lawsuit on Samsung and we can encode the value of the lawsuit, how long it's been going on.

07:17.600 --> 07:22.400
And then you can actually do computations off of all of these connections between companies.

07:23.440 --> 07:28.960
But to do this, you have to monitor all the world's information, not just financial information.

07:30.240 --> 07:36.000
So to be able to just do that, we monitor over a million pieces of information in a given day.

07:36.560 --> 07:42.960
And these are across all types of sources. So we look at structured data sets like financial

07:42.960 --> 07:49.760
market data, we look at unstructured data sets such as regulatory filings, would say the SEC,

07:49.760 --> 07:57.120
the FDA, whatever. What companies are saying in press releases, news articles, we read about 300,000

07:57.120 --> 08:03.760
sources of news in a given day. And one of the things we had to build early on was this ability for

08:03.760 --> 08:09.680
the machine to understand the news on its own, extract relationships that it thought were

08:09.680 --> 08:14.480
meaningful, and then also weigh the quality of that source of information. So not all things

08:14.480 --> 08:21.120
are really created equal. If I read something on a blog in Asia, it might be actually a really

08:21.120 --> 08:27.600
high quality source or it may not be. And so you have to make these autonomous machines

08:27.600 --> 08:31.440
have the capability to sort of weigh the quality of the source of that information.

08:32.240 --> 08:37.040
And once it's extracted and you're putting it into this computational graph,

08:37.040 --> 08:42.080
you know, it has to say that I think this is actually a really good fact. Or if it's not,

08:42.080 --> 08:47.520
then it says it's not a high quality fact. And I need to wait on confirming or additional sources

08:47.520 --> 08:52.560
of, you know, to confirm this relationship that I just found. And that's just the starting point,

08:52.560 --> 09:01.040
right? So we cover, I guess 80,000 publicly traded companies around the world. We monitor 15

09:01.040 --> 09:08.000
million private companies and we track about 200 million people that work at these companies as

09:08.000 --> 09:13.120
a starting point. And then from there, we try to figure out all their products, who they do

09:13.120 --> 09:17.040
business with, whether they're contracting with other companies or with the government,

09:17.920 --> 09:23.360
any kind of litigation that may be going on, who their investors are and what their investors

09:23.360 --> 09:27.280
are doing. So, you know, it's just spider web of knowledge that we have to build

09:27.280 --> 09:34.400
before we can actually do a computation. Right, right. To your, there's so much in there.

09:34.400 --> 09:43.840
Like, just the issue of trying to identify the newsworthiness, the trust level associated

09:43.840 --> 09:48.880
with a given site. I mean, that's Google, right? It's PageRank, right? Are you using something

09:48.880 --> 09:55.040
similar to PageRank in? Yes, but no. So, I mean, Google's an amazing

09:55.040 --> 10:01.200
piece of technology. But, you know, again, with machine learning and a lot of things that we do,

10:01.200 --> 10:07.840
the domain knowledge is extremely important. So, Google doesn't have PageRank for finance.

10:08.720 --> 10:15.280
Right. So, we kind of have to build that ourselves. The good thing is, I guess Google tries to

10:15.280 --> 10:21.040
index the world. We just need to index the financial world. So, it's a subset of what Google does.

10:21.040 --> 10:26.800
But, we can take a lot of the same concepts from what Google does and incorporate that into

10:26.800 --> 10:32.480
our own algorithms. One of the things that we've done is we apply like this machine learning

10:32.480 --> 10:37.040
approach to teaching things whether or not this is a high quality source. So, we can give

10:37.600 --> 10:42.320
the AI good examples of what high quality, you know, like this is the Wall Street Journal,

10:42.320 --> 10:46.400
this is a high quality source. These are the types of relationships of pieces of information

10:46.400 --> 10:52.080
that come from this source versus here as a, you know, like a known-in blog. And then the machine

10:52.080 --> 10:56.800
could kind of extrapolate from that. So, it's a supervised learning problem, as opposed to

10:57.520 --> 11:01.840
go out and index all of these financial sites and figure out which ones are high quality

11:02.640 --> 11:08.640
the way Google. Yeah, because Google basically has boiled the ocean ahead of time. And we kind of,

11:08.640 --> 11:13.920
when we come across new stuff, we make a determination at that point in time. Right, right.

11:13.920 --> 11:19.680
That's super interesting. Tell us about some of the other interesting kind of machine learning

11:19.680 --> 11:26.720
problems that you... Yeah. So, yeah. So, the other thing that is actually really, really hard to do

11:26.720 --> 11:32.400
is kind of twofold. The first one is entity resolution. So, you're reading all of this information

11:32.400 --> 11:38.160
about people, places, companies, whatever. The way things are written is not necessarily always

11:38.160 --> 11:42.800
clear. And so, you might be reading something about Apple, but it's the fruit and not the company,

11:42.800 --> 11:48.160
and you have to be able to do some biguate that. So, we do a lot of really cool stuff in the

11:48.160 --> 11:53.840
entity resolution space. And then we've started to do some really exciting things that were in the

11:53.840 --> 11:58.640
domain of intelligent services, but I think kind of the technology is leaking out now in the sense

11:58.640 --> 12:04.800
of something called record linkage. So, if you have these giant data sets that you can onboard or

12:04.800 --> 12:12.400
acquire or, you know, create yourself, what typically happens is that something may call Apple, Apple

12:12.400 --> 12:17.360
in one dataset. It may call it Apple Incina, a different one, or it might just be a reference to

12:17.360 --> 12:24.160
the CEO of Apple. So, you need to be able to link all of these data sets together. And basically,

12:24.160 --> 12:31.040
you don't have a clear key on which to join everything. So, you have to make these calculated sort

12:31.040 --> 12:35.120
of, you know, similar, you have to basically say, this thing is likely this other thing.

12:35.120 --> 12:40.400
This ambiguity. Correct. And connecting things based off of, you know, you say, is this in the

12:40.400 --> 12:47.200
same location? Or, you know, is it referencing a product of this company? So, you know, and then

12:47.200 --> 12:51.360
basically be able to say, well, actually it is talking about Apple, but it was actually talking

12:51.360 --> 12:58.160
about the iPhone. So, basically merging, like, say, the iPhone to the Apple company without ever

12:58.160 --> 13:03.520
having a necessary mention of Apple in both datasets. Right. So, the record linkage is actually

13:03.520 --> 13:08.720
really, really, really hard. We started to do a lot of that. And it's a really fascinating

13:08.720 --> 13:13.440
kind of area in the big data world. How do you attack that? What technology approaches are you

13:13.440 --> 13:20.880
applying to? So, obviously, the first one is we have to be able to within the data extract

13:20.880 --> 13:25.680
kind of attributes or features that we think are important for the links that we're trying to

13:25.680 --> 13:30.800
establish. So, what are we trying to like in the first place? Yes, company data. So, if we go

13:30.800 --> 13:38.240
and grab every patent in the US for companies, and that's just one giant data dump, linking that

13:38.240 --> 13:44.320
back to, well, all these patents are actually owned by these companies. You know, the US government

13:44.320 --> 13:50.000
patent office might not have the same names as, you know, the publicly traded companies themselves.

13:50.000 --> 13:55.520
Right. So, you have to look at things like, is the address the same? The people mentioned as

13:55.520 --> 14:01.200
the patent holders, employees of these companies. So, you're looking for bodies of evidence that

14:01.200 --> 14:06.320
suggests that these two things are kind of mapped together. And you have different algorithms that

14:06.320 --> 14:11.760
can kind of give you a score and a confidence measures to how closely two records are to each

14:11.760 --> 14:17.840
other. So, that's one. And then another one is a, I think, called relationship extraction. So,

14:17.840 --> 14:24.960
if you read a piece of news as a human being, it's very easy for you to sort of boil it down to

14:24.960 --> 14:31.360
what it means, right? So, you know, this company is buying another company. But in the real world,

14:31.360 --> 14:36.880
that might be written out over three paragraphs. And so, for a computer to sort of establish that

14:36.880 --> 14:44.320
NTTA is acquiring NTTB after reading a paragraph or two is actually a pretty challenging problem.

14:44.320 --> 14:48.880
Right. And so, yeah, there's a lot of really interesting stuff that we use there, but most of it is

14:48.880 --> 14:54.560
in the deep learning, you know, kind of kind of space. So, we're using a lot of TensorFlow models

14:54.560 --> 14:59.920
that, you know, to try to understand the representation of language, extract kind of entities,

14:59.920 --> 15:07.040
and then the relationships that we're looking for. So, today's end up looking like, you know,

15:07.040 --> 15:15.360
those single or individual, like super, you know, very deep neural networks or they many neural

15:15.360 --> 15:21.840
networks that are each serving their own purposes. Yeah. So, we would, we've realized is that

15:22.720 --> 15:29.360
we've had better results with building specialized machine learning models and neural networks

15:30.080 --> 15:36.000
as opposed to one kind of generalized AI or generalized network. And so, even with our

15:36.000 --> 15:41.680
relationship extraction, what we do is we have thousands of models that kind of work in Unison,

15:41.680 --> 15:47.200
and each one is highly specialized in one thing. And so, if you think about having a very wide

15:47.200 --> 15:53.760
funnel at the beginning where you say, this is a draw document, the first sort of set of models

15:53.760 --> 15:58.800
will basically say, this document is actually talking about this concept. And then that gets filtered

15:58.800 --> 16:03.680
into, okay, so within this concept, these are the types of relationships I should be looking for.

16:03.680 --> 16:09.200
And then have more sophisticated models kind of take that information and then say, okay,

16:09.200 --> 16:14.960
fine. So, this is about a corporation, and corporations can have M&A as a relationship. And so,

16:15.440 --> 16:21.760
I kind of, I'm seeing a very strong signal that this document in general is talking about M&A,

16:21.760 --> 16:26.560
let me give it to the most sophisticated guy to go and extract that very specific relationship.

16:27.200 --> 16:30.480
And by sophisticated guy, are we talking about a person or another model?

16:30.480 --> 16:37.760
Another model, sorry, yeah. And so, we have this kind of pipeline of AI models that kind of work

16:37.760 --> 16:43.840
together that start really broad and then end up kind of very high-professionalized at the end.

16:44.720 --> 16:48.400
And are you doing any human and a loop anywhere, or is it all?

16:48.400 --> 16:54.080
We do, but there's a bit of reinforcement learning that goes on, especially with the record

16:54.080 --> 17:01.200
linkage stuff. And then we obviously retrain our models fairly frequently. And so, we'll have

17:01.200 --> 17:08.080
the human and the loop on the retraining of the models. But on a given day, everything's kind

17:08.080 --> 17:15.920
of running autonomous. Yeah, super interesting. So, and what you talked about the identifying the

17:15.920 --> 17:20.320
relationships and how you have the, you know, you can have the three paragraphs, you get to,

17:20.320 --> 17:26.800
yeah, you know, that there was an acquisition that makes me think of like, you know, CFO speak,

17:26.800 --> 17:33.360
right? Do you have a model that can train that is trained like decipher when a CFO is saying

17:33.360 --> 17:38.080
that they're going to miss? Yeah, yeah. Actually, it's an area of interest to us. We haven't yet

17:38.080 --> 17:45.040
done any kind of hard core development there, but there is actually a huge community of users in

17:45.040 --> 17:50.560
the kind of, you know, hedge fund space that you understand tone, not even just the text, but like

17:50.560 --> 17:56.160
the tone. Yeah. If there was a video of the guy making the statement or he was darting around.

17:58.160 --> 18:02.720
There is a lot of kind of interest in that. We just haven't yet had a chance to spend the time in

18:02.720 --> 18:09.120
that space, but it's clearly something, you know, okay. And so, where are you guys in the process?

18:09.120 --> 18:16.320
Yes. So, we've launched a product about, I guess, less than two months now called Precog,

18:17.040 --> 18:23.120
which is our, like, it's a predictive service that basically tries to measure the butterfly effect

18:23.120 --> 18:28.880
and then produce short on forecasts for the returns of these 30,000 stocks around the world.

18:29.680 --> 18:34.400
That is currently in production and we have a number of clients that we service.

18:34.400 --> 18:43.920
So, meaning you give it, you know, a company and you probably have some unique company thing.

18:45.280 --> 18:51.680
Well, just going to database and tell you, you know, you give it maybe say 30 days and it'll tell

18:51.680 --> 18:57.280
you a projected stock price in 30 days, is it? Yes, a lot. That, yeah, it's along those lines. So,

18:57.280 --> 19:03.680
what we do today is we only produce predictions on specific time horizons. So, it would be like a

19:03.680 --> 19:08.320
one week forecast, two week forecast or one month forecast. Okay. But it would be kind of a

19:08.320 --> 19:14.000
rolling day forecast for those horizons. Okay. Today being Monday, we'll give you a forecast for

19:14.000 --> 19:19.120
the return of the stock, not the price, but the return of the stock by next month. 714 and 30 days.

19:19.120 --> 19:26.080
Okay. And that, you know, again, if you do this systematically over a broad universe of stocks

19:26.080 --> 19:29.840
and you sort of, you know, you're never going to get 100% accuracy, which is impossible,

19:29.840 --> 19:35.840
which is, you have this winning prediction, you know, like right now, we think we get anywhere

19:35.840 --> 19:46.080
from 60 to almost 70% accurate in depending on the horizon and the stocks themselves. But 60 to

19:46.080 --> 19:51.920
70 is kind of the average, but across 30,000 names, that is like Vegas odds, right? So, if you're

19:51.920 --> 19:59.360
the casino, you may lose a hand to one player, you know, one table, but across all players, you're

19:59.360 --> 20:04.880
systematically making money. And so, the customers that are using our predictions want them

20:04.880 --> 20:09.520
on a very large universe of stocks, and then they are obviously not betting the firm on one prediction

20:09.520 --> 20:13.360
on one day. They're making sure. This is one signal that they're using out of a portfolio

20:13.360 --> 20:21.280
of signals. So, you're obviously gaining, you're able to make a prediction at day zero, and then, you

20:21.280 --> 20:27.360
know, at days 17, 14 and 30, you're getting additional signals as to, you know, how accurately

20:27.360 --> 20:34.480
your model is performing. How do you then use that signal to retrain? And then how do you deal with,

20:35.760 --> 20:42.160
like attribution issues? You know, you were off by, you know, 50% or even plus minus, like,

20:42.160 --> 20:45.840
how, where in your model did you go wrong? Have you started to figure, look at that?

20:45.840 --> 20:51.520
Yeah, we do. One of the things that we've tried to stay away, shy away from just kind of with

20:51.520 --> 20:58.240
our models is that we've tried to avoid using deep neural nets and all of these types of things

20:58.240 --> 21:04.240
when we're doing our forecasting. And the reason being with these deep neural networks, you actually

21:04.240 --> 21:09.600
don't know kind of what is driving the model's decision to produce the outcome that it produces.

21:09.600 --> 21:16.160
So, the models that we generally rely on tend to have a way to sort of reverse engineer

21:16.160 --> 21:21.200
why it made the decision it made. So, more like decision trees or something else?

21:21.200 --> 21:28.400
It's never one thing. So, we use kind of a hybrid approach where we will use an ensemble of

21:28.400 --> 21:35.120
methods to come up with a single prediction. But most of them have an ability where we can actually

21:35.120 --> 21:39.200
query the model and ask it, what was the most important thing in the decision that you made?

21:39.200 --> 21:45.680
Okay. And then those, those, those weights or those factors are things that we can kind of just,

21:45.680 --> 21:51.920
you know, sanity check in the markets to see if it is what it was. So, you know, we make, say,

21:51.920 --> 21:57.520
for financial stocks, we think, you know, yield spreads and things of that nature should be important

21:57.520 --> 22:02.560
to financials. But there may be a group of financials that are aren't moving with respect to

22:02.560 --> 22:07.280
interest rates. So, the model might rely on that. But then, you know, in a month's time, we could

22:07.280 --> 22:11.760
go back and say, well, why were you way off? And they'll say, well, I over waited, you know,

22:12.480 --> 22:17.520
this moving interest rates. Okay. We will try to retrain the model to make sure it doesn't do that.

22:18.800 --> 22:26.800
The thing we try to do is we don't want to superfluously or just over engineer the models,

22:26.800 --> 22:32.480
because you can end up with overfitting. So, we're really careful about when we train the models

22:32.480 --> 22:37.520
and then what we give them to retrain, you know, and there's a lot of art and science that goes

22:37.520 --> 22:43.520
into kind of being like, you know, 60 percent is good enough or not given everything that we know.

22:45.680 --> 22:52.000
So, it sounds like going back to your funnel analogy at the top of the funnel, you're using a

22:52.000 --> 22:59.280
lot of deep learning to extract signal from various sources and then closer to the end of the funnel,

22:59.280 --> 23:04.240
you're using more using models that have greater explainability.

23:04.240 --> 23:09.920
Absolutely. That's great. Okay. Interesting. Anything else that you'd like to share about what

23:09.920 --> 23:15.120
you guys are up to? I mean, just kind of long term. One of the things, obviously, we're trying to

23:15.120 --> 23:20.720
build, like I said in the beginning, was the capability for then, you know, non-technical users to be

23:20.720 --> 23:29.520
able to sort of surface some of these insights or even, you know, ask the discover new facts that

23:29.520 --> 23:34.240
are kind of not obvious, right, within this knowledge base that we've built and then also be able

23:34.240 --> 23:38.800
to take advantage of some of these predictive models that we're building. So, what we're really

23:38.800 --> 23:44.480
trying to do here is develop, you know, like, an ability for the machine to understand human intent

23:45.440 --> 23:50.400
and then also the context in which the intent is being asked. So, for example, you sound fairly

23:50.400 --> 23:55.840
kind of familiar with the financial domain, but like my grandmother may have a similar question to you,

23:55.840 --> 24:00.960
but the response that the machine should give her versus you needs to be kind of adjusted for that.

24:00.960 --> 24:06.720
So, we're really looking to build on intelligent agent that would be able to work under different

24:06.720 --> 24:11.840
contexts, right? So, if you're dealing with another professional investor, kind of, you know,

24:11.840 --> 24:16.400
having a conversation at that level, if you're dealing with somebody looking for financial advice

24:16.400 --> 24:21.440
who's not that sophisticated, then you kind of want to boil down some of these things and just have,

24:21.440 --> 24:26.320
you know, them explained back to the user in a format that they can understand. Right. So,

24:26.320 --> 24:31.840
that ultimately sort of where we're driving towards. Okay. Now, working folks, learn more about

24:31.840 --> 24:38.560
what you guys are doing. So, on our website is a great place to start. They can also check out,

24:39.280 --> 24:44.080
at least for individual investors or people interested in sort of these signals that we're

24:44.080 --> 24:52.080
producing. They're available on Quantopian. So, they're free to use until you want to put them

24:52.080 --> 24:57.600
into a production strategy. Okay. And they are available for 500 of the most liquid names in the

24:57.600 --> 25:06.240
United States. Okay. And so, the company website is alphavertex.ai. Alphavertex.ai and Quantopian is

25:06.240 --> 25:14.240
the site that is available. Okay. And if folks want to get in touch with you, can they do it

25:14.240 --> 25:21.120
through one of those sites? Yeah, they can email me at infoatalphavertex.ai and we will be glad to,

25:21.760 --> 25:26.400
you know, reach out to them and just understand what their needs are. Awesome. Well, thanks so

25:26.400 --> 25:30.800
much for being on the show. I really learned a lot about, really learned a lot from what you guys

25:30.800 --> 25:40.800
are doing and it sounds really exciting. Yeah, it was a pleasure. Thank you so much. Great. Thank you.

