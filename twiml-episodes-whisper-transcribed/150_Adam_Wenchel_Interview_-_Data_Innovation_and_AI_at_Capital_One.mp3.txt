Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
In this episode I'm joined by Adam Wenzhel, Vice President of AI and Data Innovation at
Capital One to discuss how machine learning and AI are being integrated into their day-to-day
practices and how those advances benefit the customer.
In our conversation we look into a few of the many applications of AI at the bank, including
fraud detection, fighting money laundering, customer service, and automating back office processes.
Adam describes some of the challenges of applying machine learning and financial services
and how Capital One maintains consistent portfolio management practices across the organization.
We also discuss how the bank is organized to scale their machine learning efforts and
the steps they've taken to overcome the talent shortage in the industry.
A big thanks to our friends at Capital One for their sponsorship of this show.
As you hear in this conversation with Adam, Capital One is hosting their second annual
Data Intelligence Conference, which will bring together machine learning practitioners
and researchers for several days of presentations and talks.
The conference will take place later on this summer.
I'm really looking forward to it, so I'll keep you posted.
A quick thanks to everyone who joined us for the first session of our Twomo Fast AI Study
Group this past weekend.
We had a great discussion, and I'm excited to get the group rolling.
This first session was just an orientation, so there's still time to join in if you missed
it.
Keep an eye out for the recap video going up this week via the Slack group.
You'll find more information at twomola.com slash fastai.
Finally, our next Twomo online meetup is taking place next week on Tuesday, June 12th.
Kelvin Ross will be presenting the paper cardiologist-level arrhythmia detection with convolutional
neural networks, which is worked by researchers in Andrew Eng's lab at Stanford.
For more information, visit twomola.com slash meetup.
Alright, let's do it.
Alright, everyone.
I am on the line with Adam Wenzhel. Adam is vice president of AI and data innovation
at Capital One.
Adam, welcome to this weekend machine learning and AI.
Thank you, Sam.
I appreciate you having me on.
Absolutely.
Why don't we get started by having you tell us a little bit about your background and
how you got involved in AI?
Absolutely.
I studied computer sciences and undergrad at the University of Maryland and took the only
two AI courses that were available at the time, which is actually still the case fit at
many undergraduate curriculums.
When I graduated in the late 90s, I actually went to work.
One of my professors had gone to DARPA to start a new program there, and so I was able
to, you know, I immediately went to DARPA and was working in AI research there for the
first couple years of my career, so I have been involved in this field for quite a while.
It's funny to look around now and see all the, you know, how many jobs there are in this
industry at the time, it felt like a very small community and was seen as somewhat quixotic
at the time.
So, this current, you know, massive surge in interest has been fascinating to watch.
And from there, I went into a series of startups after working in DARPA for a couple years,
some of which involved a little bit of AI, but a lot of more were straight, you know,
web application startups.
And then about five or six years ago, maybe a few more than that, I started, you know,
with the kind of confluence of these really enabling technologies like GPU and big data
and cloud computing that have kind of led to the recent resurgence of machine learning
and coming together, you know, really started to get back into it in a big way, in particular
in the cyber security domain, which is really ripe for machine learning.
And so for the last six or so years, I've been really focused on machine learning.
And then joined Capital One about two and a half years ago, initially to lead up a big
project they had to create a new data platform and, you know, machine learning, suite of machine
learning analytics for cyber security.
And that has since kind of, my scope here is kind of expanded now, I help with machine
learning implementations all across the company.
Oh, fantastic. Well, maybe we can, we can have you give us a lay of the land and overview
of the different ways ML and AI are being used at Capital One.
Absolutely. So in financial, there's really kind of no end to, to the way machine learning
can be deployed. There's a, there are a lot of possible use cases, huh?
Absolutely. I mean, it's just a fundamentally quantitative field. And so everything from,
you know, the way we fight fraud and there's many different flavors of fraud to financial
crimes, like money laundering to, you know, to the way we service our customers, you know,
making sure that they have the best experience as possible and he can get answers to the questions
they need as quickly as possible, whether they're talking to a human or a bot or on their
mobile app or the web app, we use it all over the place as well as for, you know, a lot
of our internal back office processes, which for any large scale company, you know, bringing
automation to that can create huge efficiencies.
What would you say is an example of one of the more innovative projects that you're working
on there?
I think a lot of the way we're taking on fraud, both transaction fraud as well as account
takeover fraud and, you know, identities after are really innovative. Similarly, that's
the work we're doing and money laundering has really begun to bear some fruits recently.
Can you walk us through one of those examples? You know, I'm curious about, you know, some
of the data sources that come into play, you know, what you're, you know, the way you
approach modeling there and, you know, there is related to those topics that might help
us understand the way you go about applying ML and AI in your environment.
Yeah, absolutely. So one of the ones that we like to talk about is an application we have
called Second Look. And Second Look is for something that helps our customers out very
directly. And it's, you know, I know that I'm sure all the listeners to your, to your
podcast have are very dutiful about checking their, their credit card bill, you know,
every day and making sure that all the transactions look correctly. But for those of us who are
perhaps a little bit less diligent about it, you know, what we've done is we've actually
trained a machine learning system to go and spot transactions that, you know, that, that
we should highlight to our attention because everyone's busy. And so, you know, you don't
always have time to review your bill. And so it's good to know that, that someone's kind
of checking it for you, if you will. And so that can be things like spotting, say, a
suspiciously high tip on a restaurant bill or getting double charge for the same service
or product or just having sort of a recurring payment that, that one month, all of a sudden
significantly higher than usual. Though there's a number of reasons why, you know, things
that, that you might want to kind of be notified about on your credit card statement. And,
you know, obviously there's a real, there's a real kind of a, um, precision that's needed
because if you go lower down too many things, then it just becomes a frustrating user experience.
But we also want to make sure that, um, that stuff doesn't slip through the cracks either.
And so we put quite a lot of work and it's, it's really one of the, um, the kind of
innovative ways that we're improving our customer experience. And it's funny. Like when
I go, when I meet people at, you know, a party or something and tell my work at Capital
One, by far and away, this is the, the thing that, you know, people mentioned the most
consistently is, you know, how much they love this feature and how, and, and they always
have a story about some, you know, some charge at cost that they wouldn't have caught otherwise.
That was incorrect. They've been able to straighten out. So I think that's a great example of
the way machine learning is, is, um, bringing some transformation into the financial services
industry.
Oh, that sounds like a feature I'd like to have. I imagine that the, the training data for
something like this comes from the traditional customer reported issues. Yeah. So we do have,
you know, there's a number of ways we look at it. Um, you know, we do have sort of a, um,
a customer feedback loop in there where they can kind of tag stuff as being problematic
or if alert, you know, not being problematic. I think with those kind of, um, those kind
of systems that, that where you have kind of human generated tagging, um, they are, they
are one source of ground truth. They're not the, the, you don't over rely on that kind
of stuff, but it can be very helpful. I think there's also a lot of work from our, uh,
our data scientists looking at, uh, things like, you know, using sort of, um, unsupervised
learning and anomaly, uh, detection kind of approaches to kind of, uh, tease out some
of the patterns and the data and, and, and that's another way that, um, through things
like, uh, you know, label propagation, we can, we can, um, uh, begin to, you know, really
hone in on the transactions that, that we want to alert off of. Oh, interesting. Uh, and
you mentioned that you came in to, uh, capital one with a focused on cyber security.
I imagine that that's a big deployment area as well. It is. Yeah. There's a, you know,
that with, with cyber security, you just have such massive, um, amounts of data and even
with a large team of analysts who staff are, um, cyber security operations center, uh,
they're really constrained to only be able to look at a really small amount of the number
of events that we have on our, our network and our computers every day. And so, you
know, machine learning really gives, uh, a great opportunity to number one, cut through
all that noise and really kind of surface the events that are, um, most that, that, that
we really want to have the analyst focus on that may be suspicious that, you know, or
maybe they're completely benign, but we need to have someone to check into and then we
kind of get smarter, uh, along the process. And so that can be anything from a piece of
malware on a computer to some sort of, uh, attempted data exfiltration. There's, there's
a lot of, um, a lot of different attack vectors, malicious emails, whether that's phishing
or spearfishing or extortion attempts or, you know, there's just quite a lot of, uh, threats
that, that any large company faces and particularly one that, um, uh, manages a great deal of money.
And a situation like cyber security where, you know, capital one certainly is far from alone
and having to worry about these kinds of concerns. Do you find that, uh, your primary vector
for kind of inserting machine learning into solving some of these problems is via off
the shelf software, meaning your vendors kind of built, uh, ML and AI into their products
or you kind of out in front of it with your own data scientist building kind of custom
systems to help you stay, uh, ahead of, uh, your cyber adversaries.
Yeah, it's a, it's a very good question. I think for us, we do buy a lot of kind of
best-to-breed, um, cyber security products and I think it would be, um, uh, you know, it's
certainly advantageous. It's really important to take advantage of, of kind of the rich
product ecosphere that's out there. Um, there are, you know, when, when you kind of deploy
a lot of these solutions, um, there are still opportunities that present themselves that
are either, you know, unique to the, to the, to the, to capital one or just, um, that
are created by the way that the, the product marketplace landscape, um, lines up to, uh,
to, um, kind of even strengthen things beyond that. And that's, we, we focus on those opportunities.
Are there any examples in that domain you can give us at least at the high level?
Um, sure. One of the ones that we've, we've talked about, uh, at a couple conferences
recently is on detecting malware callouts and a, and, um, specifically malware callouts
that use, uh, DGA, DGA's domain generating algorithms. Um, we've done some pretty innovative
work there that we've presented on a conferences and, and, you know, um, we'll potentially, uh,
be sharing in the future. But that's, uh, you know, it's, it's been a fun challenge
where we've applied some of our really, um, uh, interesting machine learning approaches
using convolutional neural networks and other features, um, to, to bring kind of a, uh, this,
this, this problem has been around for a while. And it's kind of one that, uh, a number
of AI researchers have taken on and, and, you know, we have a pretty novel approach which
has been, um, working well for us. So what's, uh, what's a malware callout?
So you can imagine if you're, you know, if, if I'm sure it would be you, but if one of
your friends' computers got infected because they clicked on the wrong link or, you know,
double clicked on the wrong attachment and their email, uh, and then had a piece of malware
on their computer, it might, you know, once it, once your machine's infected, the next
stage is for it to reach out to a server controlled by the attacker and say, hey, I managed to affect
the, in fact, this computer, what was you like me to do? And that can be anything from
lock their computer to we pay, to they pay us a, a, a ransom and cryptocurrency to, um,
look, search the computer for, um, any files containing with a title financial disclosures
or something like that. And, and, you know, uh, download those to the, to the most
a server, I mean, there's a wide variety of things you can do once the computer's infected.
A lot of times it's participation in a botnet where you're, um, maybe trying to, you know,
hack into another, a system controlled by another company, um, through some sort of
brute force method. And so when it makes that call out to the, to the server, it, um, uh,
you know, we, we focus on kind of detecting at that point. Um, uh, that's one of the areas
that we've explored. And there, those, the, um, the way that those callouts are made,
the way that those servers are effectively domain names they use, um, some of the attackers
have gotten come up with some really complex algorithms for, um, basing the host names
on either some sort of time-based algorithm where, you know, maybe there's like 20,000
different domain names per given day. And you can say at any given, at any given time,
there could be one that you decided to register that your malware will call out to, which
makes, you know, the traditional kind of blacklist, whitelist approaches to blocking
malware callouts very difficult. Um, and, and so we've focused, you know, that's one
of the categories of attacks that we've focused on. And you mentioned that part of the solution
here is involves the use of convolutional neuralness. CNNs are typically used in, like, image
recognition types of tasks. How have you applied them to, uh, the cyber security use case?
Yes. So CNNs are famous, certainly, for a kind of computer vision task, but more recently,
there's been quite a lot of work. I think a real kind of, um, you know, surge of interest
in using them for more NLP-based tasks. And that's, that's, this, this, this, this kind
of category of, of, um, problem that I'm describing fits into that NLP category.
Can you elaborate on that a little bit more? Sure. So, you know, really what we're trying
to do is distinguish between, uh, you know, a host name that, um, that maybe is, let's
say, phonetically plausible, but not a real word, like Google, um, to one that, uh, is just
a string of jumbled up letters. Um, that's, that's kind of the first, uh, step. And then,
you know, some of the more recent attacks actually use, uh, our dictionary-based attacks,
where they'll generate the domain name from real dictionary words, but just put them in
odd combinations. So understanding, like, what's an odd combination and what's not as Facebook,
an odd combination, or does that make sense? And it really kind of gets into, uh, a decent
amount of kind of language understanding to, to really, um, uh, to, to create a model
that can accurately distinguish between those types of, uh, domain names. Ah, it sounds
a bit like, uh, the challenge at Google and others face keeping up with, with spammers
as spammers learn how to use proper grammar. Very, very much, very much so it's, you know,
it's continually, uh, whether it's spamming or cyber security, it's a constant cat
and mouse game, right? So, uh, it's, it keeps it fun. I never gets boring. And so one of
the challenges that the industry has been, you know, faced with is, uh, is the talent
shortage. Um, how have you managed at, at the bank to address that? Yeah, it's a good
question. There is, there is a massive talent shortage going on right now. And, you know,
there's no, there's no silver bullets to that answer to that question, but, um, there's
a number of ways we're addressing it. So obviously, we, we are hiring, you know, going
aggressively after recruiting people who have, um, good amounts of experience in that
field. They're not a lot of those people, but, but we're certainly, uh, you know, very,
uh, you know, work very hard to make sure that we can attract as many as possible. We
also have a program at Capital One called the TDP, the technology development professional
where we go out to primarily the top 20 computer science departments in the nation and, uh,
and recruit heavily from that. And once they're here, they work all over in a bunch of
different technology areas, but the ones that come to the center for machine learning,
um, we actually have a pretty rigorous, um, process around, you know, training them
and getting them up to speed on machine learning. And so we're, we're kind of famous for
being the group that, uh, gives homework. And, um, we do things like we have a weekly
paper sessions where we'll, we'll review kind of academic papers and, and, and sort of
discuss their merits. And, you know, I think that's one of the things that really distinguishes
the machine learning from, uh, other kind of software engineering computer science disciplines
is it, it still has a very academic bent to it. Um, so even though there's like massive
applicability across a wide range of business problems, um, there's still kind of a culture
of, you know, making sure that you're keeping up with the latest and academic literature.
And the academic literature is, is, is produced, you know, by, uh, and, you know, probably,
this is much by commercial teams as it is by academic teams. And so, uh, it really creates
a unique culture. So that's, you know, making sure that you have, you're continuing to do
ongoing training and that you're, you're able to take people into the, into the group
and train additional machine learning talent. That way is, uh, immensely important to
being able to meet the, the talent needs that we have. It sounds like you're going after
the same students that, uh, Google and a Facebook might go after. Do you find that you're challenged
to convince them to, uh, to join a bank as opposed to, you know, one of these more sexy kind
of internet-borne social media type of plays? Yeah, it's a good question. We, we definitely
do compete head with, with a lot of the tech companies, um, for, for talent. And, you
know, and that is a challenge. It's, fortunately, um, getting easier is more and more people
become aware of, of, you know, really what a tech company, Capital One has become. Um,
but, you know, the, the way I look at it is, uh, I, I, Capital One, you know, I think that
we've seen disruption happen via machine learning across a wide range of industries,
right? Whether we're talking logistics with self-driving cars or healthcare or commerce.
And I, and I really think that, um, financial services is, is, you know, you're beginning
to see the, you're seeing the beginnings of a similar kind of disruption. And so I
think there are a lot of people who are really excited about, uh, you know, not just taking
on marketing and advertising, but actually being able to, to apply their machine learning
skill to something really impactful, like, how do people manage their money and, and how
can we empower people more for their, to take better control of their financial lives
and really kind of set them up for lifelong financial success? Uh, you mentioned Capital
One kind of becoming a, a more and more like a tech company. And I think we kind of throw
around in the industry that, you know, all companies are going to need to look more and
more like software companies over time, sooner rather than later. In fact, uh, but Capital
One actually has a pretty long history at this. I remember, um, Capital One was featured
in, and a book that I read many years ago, competing on analytics by, uh, Thomas Devon
Port, I think is the name of the author, uh, but really talked about how the company
was before machine learning became cool, like it is now, um, really applying predictive
analytics and other things to, uh, to the way it, you know, made decisions to the way
the company made decisions. So my question is, in the company, do you find that having
that history is kind of predisposed the, your business counterparts to kind of understand
and be ready and willing to work with, uh, machine learning and, and predictive and statistical
kinds of approaches. And, and algorithms already still find yourself, you know, with many
of the cultural challenges that some of your counterparts and, and companies that don't
have that history might have. Yeah, it's a, it's a great question. And, uh, and I think
that's really good context about Capital One. Um, it's something that I didn't fully appreciate
when I first started talking to them about joining, but, but I've really come to appreciate
now, um, which is that the, the DNA of the company is very much in that, um, data analytics
space. And that's how they, you know, that was their whole initial kind of founding hypothesis.
And, um, Capital One is still founder led. And so Rich Fairbank, who's the CEO who started
the company with that conviction still runs the company with that conviction. And it really
trickles down. I think where, um, you know, machine learning is obviously a pretty, uh, pretty
different shift from kind of the, some of the traditional, uh, stats and quants that have
been done, um, and a lot of companies for, for many years, and it requires sort of a slightly
different way of thinking about problems. And so I think that, yes, there's a long, um,
it's, it's squarely in the company's DNA to think about, um, uh, you know, to think
in a data driven way and data driven insights are worth their weight in gold. Um, I think
we have had to evolve like a lot of people, um, along, you know, more machine learning
lines. And that's something that we're, that we're embracing. But the DNA of the company
is, is definitely there. Um, and it's been amazing to watch how much the company has, has
embraced that other specific aspects that you can point to or examples you can give
as to the way that that, uh, cultural shift is manifesting at Capital One. What are the,
the things that you're finding, uh, your business counterparts kind of needing to hear the
most and how are you articulating helping them come to terms with those things? Yeah, I
think they're, you know, there are a number of changes. And I think, you know, everyone's
very, um, I think everyone's really excited and enthusiastic about it. And so there's been,
you know, what I've seen, people have really taken it upon themselves to kind of go out
and educate themselves on, um, what machine learning can, can accomplish and, you know,
separating the hype from their reality. I think, uh, one example is the, of, of kind of
the evolution that's needed is, um, you know, traditionally, I think in a lot of large
companies, uh, data science and, and software and systems engineering were sort of distinct
activities. And a lot of the, the really disruptive, um, machine learning, uh, systems that
you're seeing being built at, you know, in any industry are really kind of, uh, being
produced when you have that software engineering, data engineering and, um, the, the kind of
data science all working together as one, um, whole. Um, so if you talk about like a reinforcement
learning system or, you know, any, any sort of interactive system machine learning system,
you know, it's, it's critical that, uh, it's, it's not just a standalone model, but, but
it's part of a system. And so I think that's been, um, a big, uh, you know, it's been kind
of an evolution for us to, to really make sure we're building teams and, and setting up projects
in that way, um, to take advantage. But that fundamental belief that, that data driven
insights or, or, or data analytics can really, um, power great games is, is, is, has always
been in the company's DNA. One of the big things that came out in, uh, an event that I recently
held, uh, AI summit was that, you know, often companies, particularly large companies get caught
up and comparing traditional software engineering with, uh, data science and, uh, data science driven
efforts. And, uh, the particular area that was mentioned was just this notion of the, you know,
the keyword and data science being science and it's a much more exploratory type of, uh, type of
process and doesn't lend itself to, you know, agile, for example, uh, in the way that traditional
software development does, is that, uh, is that your experience there as well? And how,
how have you been kind of working to, you know, what are your methodologies there? And how have
you been working to kind of fuse software engineering and, and, uh, data science and the other,
you mentioned data engineering as well into a process that kind of works well for Capital One.
Yeah, it's a good question. There's a couple, a couple big themes, um, wrapped up in that. The,
the first one is you're talking about the science and data science and a lot of times it has been,
essentially humans kind of experimenting with the data, uh, looking for, for insights, right,
like trying to find, you know, in search of an insight and then finding that insight and then
turning it into some sort of model that, that gets, um, uh, that can be, that can be put into
production and make predictions. Um, the, uh, with machine learning systems, what we're really
trying to do is create a system that sort of, uh, continually generates these insights in an
automated way. And that's, you know, a pretty, pretty big shift from sort of a human looking for
insights for themselves to generate building a system that can kind of, uh, continually look for
insights and, and generate them. And so it does require a slightly different skill set in a slightly
different way of, of thinking. Um, and then in terms of the methodology, you know, agile, uh,
is great for software development. I think a lot of modeling is much less deterministic. Like,
if you're trying to achieve a certain degree of accuracy on a model or efficacy on a model, um,
it's really tough to, to predict and plan out, you know, how quickly you'll get there and,
and what you, you know, you may have theories, but, um, it's just not that deterministic about
when you're going to achieve the kind of results that you need to make a model really valuable.
And so you, you know, the process, I think that, that people end up adopting is a little bit
different than the traditional kind of agile methodology because, uh, you just, you have to take
a really exploratory, um, approach to it because you're not sure, you know, what each step,
you, whenever you take a step forward, it's going to, you're going to learn sort of on the fly,
what the next avenues of exploration are going to be and you need to be prepared to react with that.
Right, right. Uh, yeah, one of the, the interesting slides that came out of this session was that,
you know, whereas you can kind of think of traditional engineering and, and agile as being more linear,
right, we have these burn down charts and we're kind of creating linear value over time
with, uh, machine learning is more of an S curve because of that exploration up front. And this is,
uh, you know, kind of in mapping out ROI, that ROI takes longer to kind of get to and require
some critical mass, but then when you do, you're, uh, able to, to, you know, get a significant ROI
in your efforts relative to, again, traditional development. Do you see that kind of relationship
between ROI and machine learning as well? I definitely agree that there's a lot of times a longer
up front period of exploration. Um, we've seen uncertain projects and pretty dramatic ROI on these
projects like, um, just because, uh, if you're, if you're coming into a system or, or, or a, uh,
a business area that hasn't, you know, essentially right now with machine learning because
it hasn't been applied broadly, there's a lot of kind of green field opportunities and
kind of low hanging through. Yeah, a lot of low hanging fruit, um, but, but, you know,
stuff that can be really impactful. And, and so, you know, some of the, some of the RF,
the ROI on, on, on some of these initial like, on, on projects can be, can be pretty dramatic.
I think that the, you know, the hard part is just scaling up the talent so that you, you can,
you can, you can, uh, implement systems in all the, the opportunity areas that, that you have.
And so given, uh, a constrained base of talent, how do you approach portfolio management across
the business? Um, do you, uh, you know, I've talked to some folks that kind of take, you know,
all their talent and apply it to, you know, their most pressing problems, kind of like a moonshot
approach, you know, with the idea that, you know, if they solve or make a dent in that, they'll
have a huge impact, you know, other folks, you know, go for kind of quick wins to help establish,
you know, a machine learning way of thinking within organization. How do you balance that?
Yeah, I think that's, you know, that, that's right on the mark for us. We started this center for
machine learning about a year and a half ago. And I think when initially we were getting started,
and we were sort of building some organizational muscle, um, we took on a fairly broad kind of
organic set of projects that really allowed us to, um, help the business partners understand
what machine learning could do and help us develop a little muscle around delivery. And, um, and,
and that's what we got started. But, you know, once we've been doing that for a while, we sort of, uh,
said, all right, we need to take a step back and actually sort of take a, a top-down assessment of
the, of the, um, uh, of the enterprise and understand, like, where are the really high leverage
opportunities for machine learning? And so that was, it's obviously, um, a conversation that we had
with our business partners who have a lot more context around, you know, their business areas.
And we really worked together to help understand and prioritize what those areas are. And we've
devoted, you know, probably the lion's share of our resources against those really transformative
opportunities. Um, that said, we still do hold back a team, uh, our internal consulting team
that's available for sort of, like, the, the broader ones that may not be, um, the moonshots,
but that, uh, but that are really important. Um, so we want to make sure we're servicing
both. And we're, we have the right balance there between going after these really transformative
opportunities, but also not ignoring, like, the, the hundreds of efficiency gains that collectively
can be, uh, really add up to something pretty powerful. How are you organized around data science?
It sounds like you've got a center. So there's some central centralization there. But what's the
relationship between, uh, that center for machine learning and the various business units?
Um, yeah. So, you know, it is, we have a center of excellence, but it's the machine learning
expertise is, you know, across the company and the data science community is, is there's,
you know, data sciences spread all across the company. So I don't, I certainly don't want to give
the impression that it's all central, because that's, that's not the case. I think having,
having the center of excellence has allowed us to have a, a small core of that, like,
you know, really work closely together to sort of, um, help define best practices and really,
you know, it's nice when you have a tight cluster of people because the amount of knowledge
share and shared learnings, um, is, is tremendous. And it really kind of accelerates the, the growth
uh, professionally of, of that group. Um, but, but we are, you know, we have people who rotate
out from that center and go into the lines of business and, and help kind of see teams that way.
And so there's a number of ways that we kind of manage that balance and, um, and so machine
learning is really like our, all the, the business teams have embedded data science groups in them
as well that are, that are really doing great things with machine learning. And, um, so the center
of excellence is kind of one of the, one of the mechanisms we have towards building out
machine learning systems, the capital one. So for an enterprise, you know, in, uh, financial services
or elsewhere, um, that, you know, recognizes the importance of machine learning, you know,
and is somewhere on the, the spectrum, but doesn't yet have a center of excellence of some sort.
Is that something that you recommend? And, and if so, what, what do you think? Well, groundwork has
to be in place before, uh, one can do that. Um, I, I do think it, uh, it's something I recommend.
I think that it, one of the reasons why we've been able to attract a very high level, uh, you
know, three of talent and a very, very competitive, um, talent segment is that working in the center
of excellence is, is very, um, it's a very compelling opportunity for machine learning professional.
And, and so, you know, from that perspective, I think it's been, uh, enormously helpful. Um, so I
think that the, you know, as to what the groundwork you need to lay is, essentially, if you need
to have a strong core of people and initial core, and because that's what's going to attract, you
know, the, the additional talent. And, and so that's for us a big part of the reason why we initially
created the center was to, to, to create that really kind of attractive place for, for talented
machine learning professionals to come work at. When you look out across your industry,
what unique challenges do you see to applying machine learning within the financial services
context? I think the, the big challenges are just, you know, it's a heavily regulated environment,
right? And so, um, it's one of the reasons we are focusing or, or investing heavily in areas like,
explainability and fairness, um, because, you know, there's obviously many, many, uh, years of,
of regulation and, and, um, working with the regulators to understand best practices for managing
models and, and making sure that you're managing the risk and that's generated from those models
appropriately. And so I think that's a, um, you know, it's, it's, it's a really kind of unique
to financial services, um, practices around that and, and understanding how to navigate that.
You know, it's tough. I think one of the reasons why I think we've seen less disruption from
startups in the financial services industry is because of those type of challenges. And it really
takes, you know, a, a larger bank that has the, the, um, all the teams and the personnel and the
experience of having dealt with, uh, you know, those type of regulatory processes for many years to,
to, uh, to be able to push more aggressively into, um, deploying machine learning in, in, in some
of these, uh, heavily regulated areas. Uh, so on the one hand, financial services has had to deal
with a lot of these issues before, but at the same time machine learning is, is changing things.
What are some of the things that are changing in the way a bank would have to think about or deal
with the issues that you've mentioned, you know, ethics, fairness, transparency, those kinds of things?
Yeah. So I think that the, the, we could, we could talk for hours just about this subject, uh,
uh, but I think, um, with, with a lot of these models, there's, they're effectively,
you, there are more complex than, than the models that have been traditionally used and what that
complexity becomes, comes additional power, but there also makes it, uh, a little bit harder to,
to, uh, really kind of fully understand everything that the model is doing. And so having to invest in
kind of automated ways of bringing that level of transparency, uh, it has been a big focus for us.
And so, you know, I think that that's, um, that's a pretty big shift and then working with the
regulators to make sure that these new ways of kind of understanding the models are, um,
sufficient and, and kind of meet the, you know, meet, meet the, the spirit of the regulation. And
it's not just working with the regulators, we're also working with kind of academic partners and
others to, to really, um, understand collectively as a group, like what the best way is to bring
that same level of understanding that, that we've had from traditional quantitative models to,
to machine learning. And that's, you know, it's very much a work in the progress, in progress,
but it's also a process that we're, um, we're very committed to and, and, and putting quite a lot
of effort into. You mentioned in their automation, can you talk about some of the ways that you've
approached automation around explainability? Um, sure. Well, some, I think a lot of it is there,
there's a number of, um, papers that have been written and, and we've done our own internal work
around, um, you know, if you have this extremely complex model, how do you get it to kind of explain
its actions when it makes a prediction and why it made the prediction? And so having some sort of
automatic system that can, you know, it's not something you, these, obviously, these models are so
complex, you're not going to manually trace through it and understand the, the decision logic.
But this, uh, you know, but there are, there are sort of a growing set of techniques for,
for dealing with this in a, in a automated way that, you know, the systems will actually generate
explanations for you that do a pretty good job of talking about the major, um, uh, reasons why
a particular prediction was made. So are these techniques like, uh, you, like the line paper or
like fitting more transparent, more explainable models to more opaque models, or did you have some
other, uh, things in mind? Those are certainly two big areas. You have the line paper was, is,
is a very seminal one. And, uh, probably the best known in this field. And I think that, um,
there's a, there's just a tremendous amount of interest in this topic. And so there's,
there's a lot more work, uh, the newer work that's coming out as well on this topic. And,
and so I think it's, uh, um, it's an exciting area to, to be in, and, um, uh, you know, I've been
at a couple major ML conferences recently. And this has been a huge topic for, for people at them.
And, uh, um, so I, so I'm really excited by what I see in terms of, uh, the progress that's being
made in, in getting to a point where we do have that good, you know, a good degree of explainability
from these really complex models. What's kind of the, the, the lay of the line in terms of, um,
the, the spectrum of model complexity that you're using there, like, is it, um,
I, I guess I'm pausing because I, yeah, I'm guessing that I know the answer that, you know,
it's like a 80 percent, you know, relatively simple things. And then you've got some more complex
stuff, but like how, I guess maybe the question is more, you mentioned using CNNs, like how much
are you using CNNs? How much are you using deep learning? And, and you mentioned reinforcement
learning. Like, do you have reinforcement learning based apps and production? I'd like to get a
sense for the range of complexity of the things you're doing. Yeah. So, you know, a lot of the stuff
we're doing is, so for starters, you know, anytime you have a system where you're bringing
machine learning to it for the first time, a lot of times you can get a big benefit just comes
from kind of the basic data engineering. And, and, and, you know, and kind of getting the system
straightened out and, uh, and even applying a relatively simple, uh, non deep learning type
model to it can, can, you know, gives you massive gains. Right. There's, you know, that's another
reason for the pause, right? There's nothing wrong with like taking the simplest approach and
spreading it far and wide, right? You can get a lot of benefit in doing that.
Yes. And, and, and, you know, those simpler models are really good about like telling
you feature importance and things like that. And so, that's really good when you're in your initial
stages to make sure there's not like some weird quirk in the data that's causing some,
some results in the lab that will never be reproducible in production data. And there's a number
of reasons to start simple. But, all that said, like, we know that, you know, deep learning,
like CNNs is, is really like, there's, there's, there's certainly, there's a reason there's a
lot of excitement around that type of stuff. And, and, and then techniques like reinforcement
learning, you know, where you, where you really kind of give the systems a little more autonomy
to explore the, the space are just fascinating. Um, when you can kind of, when, when you have a
problem that's appropriate for it. And so we, we are doing a lot of research or a lot of work on,
you know, deep learning based models, CNNs for computer vision, NNLP type applications and,
you know, LSTMs for a lot of, like, time series based type prediction and things like that. And
so there's, there's, you know, there's a lot of excitement about what those techniques can do.
I think that, as I mentioned, the center is relatively new. So a lot of those uses are,
not yet in production, but, but certainly, you know, driving in that direction. And,
you know, excited to see what that yields over the next couple of years.
I'm curious. Are there any applications of how far have you gotten with reinforcement learning?
Have you identified some potential applications within Capital One?
Yeah. So, you know, I'm not going to go too much into specifics, but we, there are a couple that
were, that were eyeing. You know, it's not right for every, every situation. And one of the things
about the financial world is for many of the problems, the, you know, you may not know whether a
prediction was successful for three or four years, right? And so doing reinforcement learning
with, when your feedback cycle is that long is creates its own set of challenges. And so,
you know, it's something that we're, that we definitely focus on, because we do think it's
a really powerful technique. But, you know, you need to, you need to make sure you have the right
problem to focus it on and, and, and are doing it in the right way.
I imagine that, uh, the bank has come across that kind of issue. These attribution problems
in, in lots of different areas, trying to attribute, you know, the success of marketing campaigns
and other things. Do you, all right? So, what degree do you, uh, have you identified or you,
do you think that, you know, a path forward is in bringing some of the techniques that you've
learned in that traditional space and applying it to RL, or is that more the domain of research
and your way to, like, gets figured out? Uh, you know, what's interesting is, as you mentioned
earlier in the podcast, Capital One has a lot of, uh, uh, history, uh, in analytic space. And,
in particular, testing, you know, which we're talking about here, um, the, the more I've kind of
learned, and as we've, we've kind of gone into, you know, talked to, explored more business areas
for applying machine learning. Um, it, it's really interesting to see, I think in, in the early days,
so that that was something, Capital One's, like, always been very good at is, is really,
you know, having kind of, uh, control groups and test groups and, and really being disciplined
about that. And so, um, I think there's a lot of practices that we're able to, the kind of
leverage that we're existing in Capital One for, for that type of testing. Hmm. Okay, so maybe
shifting gears a little bit, your group is sponsoring an event at Capital One coming up soon,
the data intelligence conference. Can you talk a little bit about the objectives for that conference?
Yeah, absolutely. So we're, we're really excited about that. Um, we held the first one,
last year was the first one we did. Uh, it's called the data intelligence conference. It's held in
McLean, Virginia in June. And I think our website is data-intelligence.ai. Um, and what this is,
is really kind of intended to be a, a hybrid between an academic conference and a practitioner
focus conference, um, really kind of blending the best of both worlds. And they're, they're, uh,
we really saw a need, um, in, in that space with that focus. Um, we had a great lineup of speakers
last time. We're gonna have the lineup of speakers this time is shaping up to be even, even better.
We have separate tracks on, uh, the couple key tracks on, um, uh, one on fairness and explainability.ai,
another one on, uh, data and ML visualization that, that I think are going to be quite good.
And, um, and so, uh, it's just an opportunity to really kind of convene a group to get together.
And lots of great conversations happen. It's a very kind of collegial feeling conference, um,
uh, conference. It's held being in the DC area. There really isn't a major machine learning conference
in the, the mid-Atlantic. And so, um, it's really kind of filled a nice gap and, and attracted a
pretty big crowd force. We sold out last year and we've increased the, um, the capacity, uh,
significantly this year, but, but I'm still expecting it to, to sell out well in advance.
Any particular session you're really looking forward to this year?
Um, I think we're still kind of finalizing the list. So I don't want to, uh, I don't want to
be my favorite quite yet at the risk of alienating anyone, but, uh, there'll be some good ones.
Who's the target audience for it? So I think it's really, you know, it's really focused on
practitioners, although we do have a lot of, um, you know, students, grad students and put,
we have poster sessions and things like that. So there's, uh, um, there is an academic bent to it,
but, but really it's for, for machine learning practitioners and financial services in particular
or more broadly, more broadly. Um, yeah, I would say it's, I wouldn't say it's, um,
primarily focused on financial services. There, there obviously is some content that are using
examples from financial services industry, but, um, it's a, it's a, it's a full spectrum machine learning
conference. Awesome. Awesome. Well, from what I've seen, it looks like a, a great event.
Any kind of parting thoughts or additional perspective that you'd like to share with our audience
before we close out? No, just, you know, I think that we're, uh, we're at a very interesting time.
As I mentioned, the being of the podcast, having been a machine learning, uh, for the better part of,
it's not continuously, but it's starting 20 years ago. Um, it, it's just amazing to see, and I think
that, uh, um, you know, there's a lot of kind of important questions like we were talking about
around fairness and explainability and ethics in AI that are, um, are critical to think about
along with the, uh, all the exciting technology technological aspects. And, and so I think, um,
the next few years should be very interesting for, for us and we're excited to be a part of it.
Fantastic. Well, Adam, thank you so much for taking the time to chat with us.
Great. Thank you.
All right, everyone. That's our show for today. For more information on Adam or any of the topics
covered in this episode, head over to twimlai.com slash talk slash 147. Thanks once again to Adam
and capital one for their sponsorship of this episode. And thank you so much for listening.
And catch you next time.
