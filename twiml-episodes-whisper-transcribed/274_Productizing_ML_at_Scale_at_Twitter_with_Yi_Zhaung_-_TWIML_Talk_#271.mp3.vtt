WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:32.440
I'm your host Sam Charrington.

00:32.440 --> 00:37.840
Two weeks ago we celebrated the show's third birthday and a major listenership milestone.

00:37.840 --> 00:42.840
And last week we kicked off the second volume of our listener favorite AI platform series,

00:42.840 --> 00:47.200
sharing more stories of teams working to scale and industrialize data science and machine

00:47.200 --> 00:49.800
learning at their companies.

00:49.800 --> 00:54.160
We've been teasing that there's more to come and today I am super excited to announce

00:54.160 --> 00:59.360
the launch of our inaugural conference, Twimblecon AI platforms.

00:59.360 --> 01:04.600
Twimblecon AI platforms will focus on the platforms, tools, technologies and practices

01:04.600 --> 01:09.400
necessary to scale the delivery of machine learning and AI in the enterprise.

01:09.400 --> 01:14.840
Now you know Twimble for bringing you dynamic practical conversations via the podcast and

01:14.840 --> 01:18.640
we're creating our Twimblecon events to build on that tradition.

01:18.640 --> 01:24.240
The event will feature two full days of community oriented discussions, live podcast interviews

01:24.240 --> 01:30.440
and practical presentations by great presenters sharing concrete examples from their own experiences.

01:30.440 --> 01:34.640
By creating a space where data science, machine learning, platform engineering and ML ops

01:34.640 --> 01:39.640
practitioners and leaders can share, learn and connect, the event aspires to help see

01:39.640 --> 01:44.800
the development of an informed and sustainable community of technologists that is well equipped

01:44.800 --> 01:48.560
to meet the current and future needs of their organizations.

01:48.560 --> 01:52.880
Some of the topics that we plan to cover include overcoming the barriers to getting machine

01:52.880 --> 01:58.120
learning and deep learning models into production, how to apply ML ops and DevOps to your machine

01:58.120 --> 02:03.040
learning workflow, experiences and lessons learned in delivering platform and infrastructure

02:03.040 --> 02:07.520
support for data management, experiment management and model deployment.

02:07.520 --> 02:11.680
The latest approaches, platforms and tools for accelerating and scaling the delivery of

02:11.680 --> 02:17.280
ML and DL and the enterprise, platform deployment stories from leading companies like Google,

02:17.280 --> 02:23.480
Facebook, Airbnb, as well as traditional enterprises like Comcast and Shell and organizational

02:23.480 --> 02:27.000
and cultural best practices for success.

02:27.000 --> 02:31.600
The two day event will be held on October 1st and 2nd in San Francisco and I would really

02:31.600 --> 02:33.600
love to meet you there.

02:33.600 --> 02:39.520
EarlyBurt Registration is open today at Twimblecon.com and we're offering the first 10 listeners

02:39.520 --> 02:45.720
who register the amazing opportunity to get their ticket for 75% off using the discount

02:45.720 --> 02:48.160
code TwimbleFirst.

02:48.160 --> 02:54.920
Again, the conference site is Twimblecon.com and the code is TwimbleFirst.

02:54.920 --> 03:00.080
I am really grateful to our friends over at Sigopt who stepped up to support this project

03:00.080 --> 03:01.880
in a big way.

03:01.880 --> 03:07.000
In addition to supporting our AI Platforms podcast series and next ebook, they've made

03:07.000 --> 03:12.960
a huge commitment to this community by signing on as the first founding sponsor for the event.

03:12.960 --> 03:17.760
App Software is used by enterprise teams to standardize and scale machine learning experimentation

03:17.760 --> 03:23.200
and optimization across any combination of modeling frameworks, libraries, computing

03:23.200 --> 03:25.760
infrastructure and environment.

03:25.760 --> 03:31.480
Teams like Two Sigma, who will hear from later in this podcast series, rely on Sigopt Software

03:31.480 --> 03:36.520
to realize better modeling results much faster than previously possible.

03:36.520 --> 03:41.440
Of course, to fully grasp its potential, it's best to try it yourself and this is why

03:41.440 --> 03:46.760
Sigopt is offering you an exclusive opportunity to try their product on some of your toughest

03:46.760 --> 03:49.600
modeling problems for free.

03:49.600 --> 03:55.760
To learn about and take advantage of this offer, visit Twimbleai.com slash Sigopt.

03:55.760 --> 04:00.920
And now on to the show.

04:00.920 --> 04:03.600
All right, everyone.

04:03.600 --> 04:09.400
I am on the line with Yizhuang, E is a senior staff engineer at Twitter and tech lead

04:09.400 --> 04:13.320
for the machine learning core environment on the core techs team.

04:13.320 --> 04:16.520
E, welcome to this week a machine learning and AI.

04:16.520 --> 04:17.520
Thank you.

04:17.520 --> 04:19.320
My pleasure to be here.

04:19.320 --> 04:20.320
It's great to chat with you.

04:20.320 --> 04:26.640
I'm really looking forward to digging into what you are working on on the platform side

04:26.640 --> 04:28.720
of things.

04:28.720 --> 04:32.600
Before we do that, I'd love to start out with a little bit of your background and how

04:32.600 --> 04:36.720
you started working in machine learning platforms and infrastructure.

04:36.720 --> 04:41.440
Sure, actually, I would say there are two parts to this question.

04:41.440 --> 04:46.600
There's how I, I guess, how I started working on machine learning and also how I started

04:46.600 --> 04:48.960
working on platform and infra.

04:48.960 --> 04:50.960
So I can dive into both.

04:50.960 --> 04:51.960
Does that sound good?

04:51.960 --> 04:52.960
Absolutely.

04:52.960 --> 04:53.960
Yeah, let's do it.

04:53.960 --> 04:54.960
Okay.

04:54.960 --> 05:02.280
So I think ever since I was a kid, I always had an affinity to both math and computer

05:02.280 --> 05:08.880
science, so that's why I got attracted to discipline like machine learning where I get

05:08.880 --> 05:11.600
to practice both.

05:11.600 --> 05:16.600
So I would say the first time I touched machine learning was actually in college.

05:16.600 --> 05:23.680
I was on my college's robotics team and we programmed these robot dogs to play soccer.

05:23.680 --> 05:29.400
Those are Sony eyeballs and the competition was called Robocop and we participate in

05:29.400 --> 05:35.680
this competition and program robot dogs to play soccer against each other.

05:35.680 --> 05:41.080
Unlike what you would have guessed today, machine learning actually wasn't used in, wasn't

05:41.080 --> 05:43.800
used very much in our vision system.

05:43.800 --> 05:46.520
It was actually used for a different case.

05:46.520 --> 05:51.360
We used machine learning to tune the gates of the robots by gate.

05:51.360 --> 05:56.200
I mean, the walking posture, there is a set of parameters that needs to be optimized

05:56.200 --> 05:58.880
and the search space is pretty large.

05:58.880 --> 06:05.480
So what we did was we essentially made the robot dogs walk back and forth on the playing

06:05.480 --> 06:13.200
field and recorded the running speed and then we tune each parameter by a little bit and

06:13.200 --> 06:15.800
then make them walk the playing field again.

06:15.800 --> 06:22.240
Then we can compute the gradient of the walking speed with respect to that parameter we

06:22.240 --> 06:28.000
nudged by a little bit and we do that to all the parameters and then we perform one round

06:28.000 --> 06:35.640
of gradient descent that allowed us to optimize the running speed of our robot dogs.

06:35.640 --> 06:37.720
It's a very tedious process actually.

06:37.720 --> 06:39.320
That sounds super tedious.

06:39.320 --> 06:41.160
Yeah, exactly.

06:41.160 --> 06:48.400
I remember these Sony Ibo dogs from many years ago, I didn't realize they were quite

06:48.400 --> 06:52.160
that programmable.

06:52.160 --> 07:01.080
They were programmable, but yeah, the experience was pretty, it was not as good as today.

07:01.080 --> 07:06.720
Essentially, for example, if we get a segmentation fault, the whole robot turns off, basically

07:06.720 --> 07:08.840
the operating system shuts down.

07:08.840 --> 07:14.200
But one thing that was pretty amazing was our college's robotics team.

07:14.200 --> 07:22.840
We started as the last place in the U.S. open competition in around 2015.

07:22.840 --> 07:28.880
The same team actually won World Championship in 2007 and 2007.

07:28.880 --> 07:29.880
Wow.

07:29.880 --> 07:36.360
We actually beat very reputable teams like Carnegie Mellon 8-1 in terms of score.

07:36.360 --> 07:42.760
I would say it was the definitely hard working team and the techniques we were using, using

07:42.760 --> 07:48.880
machine learning to tune the gate of the robots, they worked out well.

07:48.880 --> 07:49.880
Wow.

07:49.880 --> 07:51.400
And where did you go to school?

07:51.400 --> 07:53.760
I actually went to Carnegie Mellon right after.

07:53.760 --> 07:59.160
I think for basically beating their robotics team, definitely helped me get that offer

07:59.160 --> 08:05.240
from both Carnegie Mellon's robotics institute and computer science department.

08:05.240 --> 08:11.480
What I ended up choosing, though, was I was both a math major and a CS major in college.

08:11.480 --> 08:17.320
I ended up choosing a very mathematical field of computer science at Carnegie Mellon where

08:17.320 --> 08:26.480
I model system performance by building mathematical models, essentially building a mark of models

08:26.480 --> 08:33.000
and analyze queuing, et cetera, to basically predict the performance of computer systems.

08:33.000 --> 08:35.160
That's what I do in grad school.

08:35.160 --> 08:42.080
And I got into platform around, like I would say, system engineering around roughly two

08:42.080 --> 08:47.920
years into my PhD program at Carnegie Mellon, I interned at Google.

08:47.920 --> 08:54.600
So I worked on the basically performance modeling for the next generation storage system

08:54.600 --> 08:55.800
at Google.

08:55.800 --> 09:00.480
And I offered to, for example, build math models predict performance there.

09:00.480 --> 09:02.320
And they were less excited.

09:02.320 --> 09:08.040
They were more, yeah, they were like, we don't want you to build math models.

09:08.040 --> 09:12.160
We want you to actually measure and tune the parameters.

09:12.160 --> 09:15.880
So this is, again, very similar to the robotics case, right?

09:15.880 --> 09:21.320
It's, essentially, we have like a black box storage system, but we have many knobs we can

09:21.320 --> 09:22.320
tune.

09:22.320 --> 09:29.720
Essentially, we're looking for the best set of parameters that can actually perform best.

09:29.720 --> 09:33.520
So that was my Google internship and afterwards.

09:33.520 --> 09:39.120
I started realizing that my PhD program, I do a lot of math, but I don't do a lot of

09:39.120 --> 09:41.120
hands-on engineering.

09:41.120 --> 09:45.840
And I actually found myself to like building stuff.

09:45.840 --> 09:51.280
And that's when I dropped out of my PhD program and came to Twitter.

09:51.280 --> 09:56.280
My first projects were actually on Twitter search.

09:56.280 --> 10:03.720
And this is where I learned to be an actual engineer and learned about system and platform

10:03.720 --> 10:05.200
engineering.

10:05.200 --> 10:09.760
And I took like around 2014 or so.

10:09.760 --> 10:16.880
I led a group of people and built this trillion documents scale search engine at Twitter.

10:16.880 --> 10:21.200
This allowed Twitter to index every single tweet ever published.

10:21.200 --> 10:27.640
And now you can search for Jack's first tweet setting up my Twitter and that tweet would

10:27.640 --> 10:28.640
show up.

10:28.640 --> 10:29.640
Oh, wow.

10:29.640 --> 10:33.080
That's briefly how I got into platform engineering.

10:33.080 --> 10:38.440
And afterwards, I came to cortex building machine learning platform for Twitter.

10:38.440 --> 10:44.640
And so cortex, it was, is cortex a team that grew organically in Twitter or there was an

10:44.640 --> 10:49.360
acquisition that was part of that as well, right?

10:49.360 --> 10:54.000
Yes, actually, there were multiple acquisitions.

10:54.000 --> 10:59.200
There was a tweet from Jack around Jack was our CEO.

10:59.200 --> 11:07.000
He tweeted about this around 2016 and Twitter acquired three companies.

11:07.000 --> 11:09.040
One of them is called Mad Bits.

11:09.040 --> 11:13.080
One of them is called Magic Pony and one of them is called WetLab.

11:13.080 --> 11:19.720
These three companies, the acquisition formed the original cortex org.

11:19.720 --> 11:28.080
And the original focus was deep learning research, essentially, we inherited the DNA from these

11:28.080 --> 11:30.080
three acquisitions.

11:30.080 --> 11:31.080
Got it.

11:31.080 --> 11:32.080
Got it.

11:32.080 --> 11:40.160
And so to what degree was machine learning really heavily used at Twitter or maybe the

11:40.160 --> 11:47.040
right way to ask this is broadly used, it sounds like you, there were some activity around

11:47.040 --> 11:51.080
search and I imagine there were some other kind of point use cases, but was it in broad

11:51.080 --> 11:54.040
use at Twitter before cortex?

11:54.040 --> 12:01.640
So machine learning before cortex was used, but it wasn't practiced in a consistent way.

12:01.640 --> 12:07.080
It was definitely used for us to do advertisements.

12:07.080 --> 12:16.720
For example, CTR prediction to fight spam and adversarial users, bad accounts on our platform

12:16.720 --> 12:20.120
and also used to rank search.

12:20.120 --> 12:27.480
Cortex, essentially, in the past two years or so, transitioned from a deep learning research

12:27.480 --> 12:30.960
org to a machine learning platform org.

12:30.960 --> 12:37.880
And the cortex is basically bringing consistency to how machine learning is used across all

12:37.880 --> 12:41.400
sorts of product teams at Twitter.

12:41.400 --> 12:46.280
So I wouldn't say machine learning wasn't used at Twitter widely before cortex, machine

12:46.280 --> 12:53.320
learning was widely used, but exactly because it was widely used and it was practice, like

12:53.320 --> 12:56.760
there are practitioners across many different teams.

12:56.760 --> 13:02.480
It was a very fragmented landscape and different teams did things differently.

13:02.480 --> 13:10.240
So cortex around 2017, our CTO product took over the org and started focusing the org

13:10.240 --> 13:14.360
around serving customers and being a platform team.

13:14.360 --> 13:20.760
And later our current director sent deep to cover and continued to sharpen our customer

13:20.760 --> 13:27.720
focus, now we are a platform team building machine learning platforms to serve various

13:27.720 --> 13:29.320
product teams.

13:29.320 --> 13:37.000
And as we currently stand, most Twitter product teams are using cortex machine learning platforms

13:37.000 --> 13:40.080
to practice and know at Twitter now.

13:40.080 --> 13:48.040
Is the goal of cortex and building platforms, would you say, it's to drive more consistency

13:48.040 --> 13:56.800
and efficiencies in the way folks use machine learning or is it to broaden the kind of the

13:56.800 --> 14:01.480
base of people that can use machine learning, not that those are strictly a dichotomy,

14:01.480 --> 14:08.080
but I'm wondering if one or the other really drove the establishment of the organization.

14:08.080 --> 14:15.600
I think it's both actually ultimately our goal is to empower practitioners at Twitter

14:15.600 --> 14:22.160
to use and know both more efficiently and empower more people to be able to leverage machine

14:22.160 --> 14:23.160
learning.

14:23.160 --> 14:28.960
So it's, I would say the emphasis is more on the latter.

14:28.960 --> 14:33.840
Bringing consistency itself is a intermediate goal in my mind.

14:33.840 --> 14:40.040
We're hoping to bring efficiency to the company by bringing consistency.

14:40.040 --> 14:47.480
And once everybody is practicing ML in a consistent way using our offerings, it makes our job

14:47.480 --> 14:50.560
easier to bring productivity to them.

14:50.560 --> 14:52.760
I don't know if this answer makes sense.

14:52.760 --> 14:54.760
I can further elaborate.

14:54.760 --> 14:56.480
Yeah, it absolutely does.

14:56.480 --> 15:01.520
And I've got one more question on kind of these meta organizational questions before

15:01.520 --> 15:07.000
we dig into some more detail about the platform there and it, and that is around this transition

15:07.000 --> 15:13.200
from deep learning research focused organization to a platform organization.

15:13.200 --> 15:18.280
It strikes me that those are very different missions, perhaps calling for very different

15:18.280 --> 15:19.960
skill sets.

15:19.960 --> 15:24.040
What was the experience of going through that transition like?

15:24.040 --> 15:34.160
Yeah, it was definitely a difficult transition, I would say, and the most, the biggest

15:34.160 --> 15:41.880
shift is the mindset from doing cutting edge research to serving internal customers.

15:41.880 --> 15:49.840
And the customer focus mindset is the biggest change in the org and it took us, many took

15:49.840 --> 15:57.040
us a lot of effort to get our, for example, engineers and researchers to be aligned on

15:57.040 --> 15:58.560
that.

15:58.560 --> 16:03.760
Part of it comes from, did most people buy into the idea of doing that shift or did the

16:03.760 --> 16:07.320
org turn over quite a bit in order to get there?

16:07.320 --> 16:09.120
Both, both.

16:09.120 --> 16:14.960
We had some turnovers as the transition, but most people actually stayed and bought into

16:14.960 --> 16:19.640
this new vision or focus.

16:19.640 --> 16:25.280
And we are now very customer oriented and we do what our customer asked for.

16:25.280 --> 16:32.120
And we still have a research org, but even that research org is focused on, for example,

16:32.120 --> 16:36.320
improving the production model performance of our customer teams.

16:36.320 --> 16:40.640
So for people who wants to do like machine learning, deep learning research, we still

16:40.640 --> 16:46.600
have a place, but we definitely repurposed the goal of the research.

16:46.600 --> 16:57.400
Yeah, the idea of kind of a customer, a customer centric view in providing platforms, I think

16:57.400 --> 17:05.960
is one that makes a lot of sense is kind of, it's a very kind of straightforward approach.

17:05.960 --> 17:10.760
And I'm thinking specifically about this conversation that I recently had and was published

17:10.760 --> 17:16.480
on the podcast just a couple of shows ago with Eric Colson at StitchFix.

17:16.480 --> 17:25.080
And when he talked about the role of the platform's team in his group, it was the way that

17:25.080 --> 17:31.880
they figured out the features that the platform needed, it was, it was really focused on things

17:31.880 --> 17:33.840
that their customers weren't asking for.

17:33.840 --> 17:40.720
It's like how could they add value that the user doesn't even know about versus the way

17:40.720 --> 17:45.520
I think of traditional kind of product management, your understanding requirements and kind

17:45.520 --> 17:51.760
of organizing those requirements and figuring out how to get there with a platform is either

17:51.760 --> 17:59.120
one of those approaches resonate with the way things tend to happen at Cortex?

17:59.120 --> 18:01.320
I think actually both.

18:01.320 --> 18:06.440
So we can talk about our strategy for last year and this year.

18:06.440 --> 18:12.480
Last year is about adoption and consistency, we need to get our users to use our platform.

18:12.480 --> 18:18.680
And this year we started to look into, for example, ease of use and iteration speed.

18:18.680 --> 18:24.320
This is when we think about what kind of features make our users' lives easier.

18:24.320 --> 18:31.520
So I would say for 2018, getting customers to adopt our product and essentially switching

18:31.520 --> 18:39.720
from their current machine learning tool kits to our platform, a customer-focused mindset,

18:39.720 --> 18:43.400
customer-driven feature development is more valuable.

18:43.400 --> 18:48.960
We really need to listen to our customers to understand what makes them to change from

18:48.960 --> 18:58.760
their current ML tool kits and ML, for example, frameworks that switch to our offering.

18:58.760 --> 19:04.720
And afterwards, when we think about what features makes their life easier, we need to adopt

19:04.720 --> 19:11.480
a strategic thinking and think about what our customers are not asking for.

19:11.480 --> 19:13.040
Does this answer make sense?

19:13.040 --> 19:18.000
So I think it's a gradual shift in the beginning of creating this platform.

19:18.000 --> 19:26.080
We definitely need to put more focus on serving customers and catering to their asks.

19:26.080 --> 19:32.960
And as the platform matures, we gradually increase the strategic bets in our portfolio

19:32.960 --> 19:40.320
and do more work that's not necessarily being asked by customers, but we're anticipating.

19:40.320 --> 19:44.200
So we've talked very abstractly about the platform.

19:44.200 --> 19:47.040
Maybe walk us through the platform now.

19:47.040 --> 19:48.840
What are the major components?

19:48.840 --> 19:54.440
How do you think about it architecturally or how would you describe it to someone?

19:54.440 --> 19:55.440
Sure.

19:55.440 --> 20:03.520
So Quartex right now, we offer multiple solutions in our ML platform.

20:03.520 --> 20:12.520
We offer the core model training and evaluation part, which is based on TensorFlow.

20:12.520 --> 20:20.200
And we offer data preprocessing and featureization, something we call feature store.

20:20.200 --> 20:27.640
It allows users to consistently prepare features for machine learning models, both at training

20:27.640 --> 20:34.760
time and prediction time, which is offline in offline and online context.

20:34.760 --> 20:40.760
And we offer production model serving based on JVMs.

20:40.760 --> 20:46.760
This is like a TensorFlow serving equivalent, except it's specialized and custom-bued for

20:46.760 --> 20:47.920
Twitter.

20:47.920 --> 20:56.920
And we have pipeline orchestration, which is a automation solution that allows people to

20:56.920 --> 21:04.760
run dependency graphs of machine learning workloads and basically chain a dependency

21:04.760 --> 21:09.960
of tasks into a single graph and run them in an automated manner.

21:09.960 --> 21:17.360
And we have also added more efforts in our platform, including embeddings, nearest neighbor

21:17.360 --> 21:20.160
search for candidate generation.

21:20.160 --> 21:26.760
We have added machine learning observability, which allows us to observe feature distributions

21:26.760 --> 21:29.480
and also analyze models.

21:29.480 --> 21:35.400
And in the end, we also started a new team inside Quartex, which is called meta, which

21:35.400 --> 21:47.280
is studying the bias and accountability, fairness, those concerns inside algorithmic decisions.

21:47.280 --> 21:51.560
That's a high level overview of what Quartex comprises of today.

21:51.560 --> 21:53.920
Lots of interesting stuff to dive into.

21:53.920 --> 21:58.240
The first of the things that you mentioned was at the framework level?

21:58.240 --> 22:02.520
Yes, the first one is what I mentioned is called the DeepBird.

22:02.520 --> 22:06.400
It's our model training and evaluation solution.

22:06.400 --> 22:08.280
So maybe let's start there.

22:08.280 --> 22:13.880
What is the goal of DeepBird and how do users use it?

22:13.880 --> 22:14.880
Yes.

22:14.880 --> 22:23.400
So DeepBird started as, so historically, Twitter Quartex uses Torch, which is Lua Torch,

22:23.400 --> 22:24.760
not PyTorch.

22:24.760 --> 22:32.720
It's the initial, I would say it's one of the older established deep learning frameworks.

22:32.720 --> 22:39.600
What we noticed around 2017 was that the Torch community started to lose steam and the

22:39.600 --> 22:45.880
tensor flow and PyTorch started gaining popularity in the community.

22:45.880 --> 22:55.040
And DeepBird and actually DeepBird version 2 is our effort in partnership with Google

22:55.040 --> 22:58.440
to bring tensor flow to Twitter.

22:58.440 --> 23:09.000
So the goal of this component DeepBird V2 is to unlock latest technology backed by Google

23:09.000 --> 23:16.560
mostly tensor flow and its ecosystem and tensor flow extended for use at Twitter.

23:16.560 --> 23:26.600
And specifically to be more specific, Twitter is more of a Java shop like most of our code

23:26.600 --> 23:33.480
are either in Java or Scala, basically JVM languages, whereas tensor flow is mostly Python

23:33.480 --> 23:35.200
and C++.

23:35.200 --> 23:43.320
So we had to build quite a lot of production, gluing logic to actually make tensor flow

23:43.320 --> 23:45.160
work at Twitter.

23:45.160 --> 23:52.840
And also DeepBird provides an additional abstraction layer between tensor flow and our machine learning

23:52.840 --> 23:55.680
practitioners at Twitter.

23:55.680 --> 23:58.640
We do this for multiple goals.

23:58.640 --> 24:02.240
One is to reduce the complexity of using tensor flow.

24:02.240 --> 24:08.840
This tensor flow was actually released, production released was in February 2018.

24:08.840 --> 24:14.560
It's a relatively new thing and we would like to hide complexity whenever possible.

24:14.560 --> 24:20.440
And inside the abstraction layer, we prescribe default values for different knobs and we

24:20.440 --> 24:28.880
also include optimizations that are specialized and customized for the Twitter data centers

24:28.880 --> 24:30.480
and Twitter workload.

24:30.480 --> 24:38.000
A ton and there to dig into, you mentioned needing to build a lot of glue code to bring

24:38.000 --> 24:44.360
this Python oriented system into your primarily JVM based environment.

24:44.360 --> 24:48.520
Can you give some examples of specific things that you had to do?

24:48.520 --> 24:54.440
Yeah, the main example I can give is that tensor flow is serving, right?

24:54.440 --> 25:03.920
So tensor flow serving is actually a C++ app speaking GRPC at Twitter, with GRPC is not

25:03.920 --> 25:10.360
our standard RPC protocol and also C++ is not the main language.

25:10.360 --> 25:14.240
Our engineers don't know how to maintain C++ apps.

25:14.240 --> 25:21.080
So we essentially built an equivalent of tensor flow serving, but inside using Java

25:21.080 --> 25:25.400
and Scala and we ship that app to our customers.

25:25.400 --> 25:32.320
This is mainly for internal maintenance so that our teams knows how to be on call and

25:32.320 --> 25:36.120
fix issues for the serving solution.

25:36.120 --> 25:41.120
And also it's for tighter integration with our internal observability stack.

25:41.120 --> 25:49.360
This allows us to integrate with our monitoring and alerting solution seamlessly because tensor

25:49.360 --> 25:53.080
flow serving doesn't have that integration.

25:53.080 --> 25:54.440
Does that make sense?

25:54.440 --> 25:55.440
Yes.

25:55.440 --> 26:00.320
So deeper V2 is very focused on bringing tensor flow to Twitter.

26:00.320 --> 26:08.920
Does that mean it's a highly opinionated system and user that is interested in using PyTorch

26:08.920 --> 26:13.920
for example, isn't supported with deep bird?

26:13.920 --> 26:15.840
That's currently the case.

26:15.840 --> 26:22.680
So remember what we started with, the goal was we were trying to defragment the machine

26:22.680 --> 26:24.920
learning practices at Twitter.

26:24.920 --> 26:32.720
What we noticed was in 2017, we had users of LuaTorch and we had tensor flow users,

26:32.720 --> 26:37.840
we had scikit learn users, we had XG boost users.

26:37.840 --> 26:43.160
So this fragmentation caused several issues.

26:43.160 --> 26:47.160
First of all, it causes difficulty sharing.

26:47.160 --> 26:53.200
Different teams can't share their machine learning models, they're tooling and resources.

26:53.200 --> 26:58.600
And sometimes it prevents expertise sharing as well, like if an engineer wants to move

26:58.600 --> 27:05.560
from one team to another, he has to learn a new set of expertise in order to be effective.

27:05.560 --> 27:10.400
So that's when we noticed the fragmentation is a problem and then we also noticed work

27:10.400 --> 27:12.000
duplication, right?

27:12.000 --> 27:21.320
So Twitter is a very large scale company and I can introduce our scale maybe separately,

27:21.320 --> 27:26.800
but essentially we have to invest in a lot of resource to duplicate serving solutions.

27:26.800 --> 27:33.000
For example, let's say to serve a scikit learn model versus serving a PyTorch model versus

27:33.000 --> 27:40.120
serving a tensor flow model, if we end up building like three different set of serving solutions,

27:40.120 --> 27:44.920
which is what happened before, it wastes a lot of engineering resource.

27:44.920 --> 27:52.280
So that's why deep bird is an opinionated, like you said, prescribed opinionated way of

27:52.280 --> 27:59.400
doing machine learning based on top of tensor flow that tries to get our machine learning

27:59.400 --> 28:05.240
practitioners to do things in a consistent way that allows different teams to share machine

28:05.240 --> 28:12.000
learning models, share their tools and resources and even knowledge across teams.

28:12.000 --> 28:18.960
You mentioned scikit learn is deep bird also an abstraction for traditional machine learning

28:18.960 --> 28:23.640
workloads and beyond the deep learning workloads.

28:23.640 --> 28:29.760
So there's really not a clear line between deep learning and traditional machine learning.

28:29.760 --> 28:36.360
So yes, deep bird can support traditional machine learning, tensor flow supports, for

28:36.360 --> 28:41.680
example, traditional machine learning methods as well.

28:41.680 --> 28:46.040
One of the why it is to use the traditional machine learning method is actually logistic

28:46.040 --> 28:47.440
regression.

28:47.440 --> 28:55.120
It's very widely used inside Twitter and in fact, there's really not a clear line between

28:55.120 --> 29:00.560
logistic regression and deep learning because we can actually think of logistic regression

29:00.560 --> 29:04.560
as a one layer neural network with a single output.

29:04.560 --> 29:12.640
So sure, but often folks find the overhead of deep learning frameworks relative to the

29:12.640 --> 29:18.800
tools that they might use for traditional ML to be a pretty heavy weight.

29:18.800 --> 29:19.800
Yes.

29:19.800 --> 29:27.120
So for example, tensor flow itself, the estimator API is the main API tensor flow recommends

29:27.120 --> 29:30.480
for productionization in tensor flow one.

29:30.480 --> 29:35.720
And that API we acknowledge that it's very clunky and many of our users don't really like

29:35.720 --> 29:36.720
it.

29:36.720 --> 29:38.080
They think it's too heavy weight.

29:38.080 --> 29:43.000
That's exactly what we provide in our deep bird abstraction.

29:43.000 --> 29:49.640
We're trying to hide the complexity whenever possible and prescribe good defaults.

29:49.640 --> 29:54.080
So I usually use a camera analogy.

29:54.080 --> 29:59.760
Think of tensor flow as a very powerful DSLR camera.

29:59.760 --> 30:04.960
Many users actually prefer like a mobile phone, one button point and shoot camera.

30:04.960 --> 30:12.000
So what we're trying to do is we're trying to wrap tensor flow inside our layer of abstraction.

30:12.000 --> 30:17.680
We try to encapsulate all the knobs and buttons on the digital SR camera.

30:17.680 --> 30:21.680
And we expose a single button point and shoot solution.

30:21.680 --> 30:24.160
So this is a double edge sword, right?

30:24.160 --> 30:28.920
It's most users like it, especially the production ML engineers.

30:28.920 --> 30:31.840
They really like solutions where they type a single command.

30:31.840 --> 30:34.200
It trains a machine learning model for them.

30:34.200 --> 30:40.040
But some of the more advanced users and deep learning researchers actually don't necessarily

30:40.040 --> 30:42.480
like the point and shoot solution.

30:42.480 --> 30:46.800
It's just like how a professional photographer might feel like it's an insult.

30:46.800 --> 30:49.160
If you're giving a point shoot camera, right?

30:49.160 --> 30:56.880
So I would say to answer your question, we added this abstraction layer to hide complexity

30:56.880 --> 31:01.840
of deep learning frameworks such that if you want to do logistic regression using our

31:01.840 --> 31:04.680
ML platform, it's very simple.

31:04.680 --> 31:08.920
And we aim for like a simple solutions where you type a command.

31:08.920 --> 31:13.200
We can launch training and save models on HDFS and you type another command.

31:13.200 --> 31:19.560
We launch hundreds of prediction servers serving the model saved on HDFS.

31:19.560 --> 31:23.920
But we do need to think about how to cater to the more powerful users as well.

31:23.920 --> 31:30.000
To what degree does DeepBird replicate a lot of the work that has been done with Keras

31:30.000 --> 31:37.200
as a front end to TensorFlow, it seems like there are similar goals in terms of increasing

31:37.200 --> 31:42.480
usability, although Keras is certainly not a one button type of solution.

31:42.480 --> 31:43.720
Correct.

31:43.720 --> 31:49.000
So I would say there's definitely some overlap.

31:49.000 --> 31:56.800
Essentially TensorFlow 1.0 made this, basically, in TensorFlow 1.0, there are these two ways of

31:56.800 --> 32:03.280
practicing ML estimators and Keras estimator was more targeting production use, scaling

32:03.280 --> 32:07.600
to large data set, while Keras was targeting ease of use.

32:07.600 --> 32:14.160
So DeepBird is basically building on top of estimator and hoping to improve ease of

32:14.160 --> 32:15.160
use.

32:15.160 --> 32:23.120
Upcoming in TensorFlow 2.0, TensorFlow is consolidating estimator and Keras into a single Keras API.

32:23.120 --> 32:30.320
So users no longer need to choose between scalability and usability.

32:30.320 --> 32:37.200
We also envision that going forward once TensorFlow 2.0 is released, DeepBird will also

32:37.200 --> 32:41.520
most likely adopt the Keras based API.

32:41.520 --> 32:45.520
So that is the training elements.

32:45.520 --> 32:52.520
Do you also, does DeepBird also offer features focused on experiment management, tracking

32:52.520 --> 32:57.160
model parameters, hyperparameter tuning kind of that whole space?

32:57.160 --> 32:58.760
Yes, we do.

32:58.760 --> 33:05.520
So before our ML platform, most of our customers track to these in spreadsheets and we

33:05.520 --> 33:12.560
notice that, so we build a repository where our DeepBird training jobs can automatically

33:12.560 --> 33:21.240
push the hyperparameters used and the experiment name and the resulting metrics like a PRAOC,

33:21.240 --> 33:24.720
accuracy, et cetera, into this model repository.

33:24.720 --> 33:31.400
And then you can query the repository for the experiments you have run and examine their

33:31.400 --> 33:34.320
hyperparameters and metrics.

33:34.320 --> 33:43.040
And do you support visualization with TensorBoard or do you have your own solution or an alternate

33:43.040 --> 33:45.960
solution for visualization?

33:45.960 --> 33:49.520
We mostly visualize using TensorBoard.

33:49.520 --> 33:56.440
So when you launch a DeepBird training job in our internal private cloud, we automatically

33:56.440 --> 34:04.200
start TensorBoard to watch the training process and render loss and other metrics.

34:04.200 --> 34:12.240
So this model repository we just talked about, once you query for experiment that finished,

34:12.240 --> 34:16.400
there's actually a button right in the UI that says launch TensorBoard.

34:16.400 --> 34:23.400
If you click on that button, it launches TensorBoard on an instance in our internal private

34:23.400 --> 34:29.160
cloud and it points the TensorBoard to that experiment that actually finished running

34:29.160 --> 34:36.360
and shows how the loss came down and how the resulting metrics look like.

34:36.360 --> 34:45.200
Is the platform also opinionated in terms of whether users use a notebook experience or

34:45.200 --> 34:49.240
traditional code files or ID?

34:49.240 --> 34:58.240
We're not opinionated on how the user developed code, but we do offer a notebook solution

34:58.240 --> 35:04.880
that's integrated with our internal clusters.

35:04.880 --> 35:11.400
We offer this thing called PyCX where our users can type a single command and it launches

35:11.400 --> 35:18.120
a notebook instance and it tunnels to the instance and gives back a URL that the user can

35:18.120 --> 35:19.120
use.

35:19.120 --> 35:25.360
It's a semi-hosted notebook solution, basically our users can type a single command and

35:25.360 --> 35:32.000
we launch a notebook server on our internal cloud and the user can use the notebook and

35:32.000 --> 35:36.840
it contains most of the dependencies our users would need.

35:36.840 --> 35:40.360
But we don't force our users to use notebooks for development.

35:40.360 --> 35:49.720
Are you doing anything to try to streamline the process of going from notebook to production,

35:49.720 --> 35:57.480
like some kind of automated code pulls or code extraction from the notebooks that kind

35:57.480 --> 35:58.480
of thing?

35:58.480 --> 36:00.000
I've seen that from time to time.

36:00.000 --> 36:01.480
Yeah, not yet.

36:01.480 --> 36:05.440
This is definitely an area that's worth considering.

36:05.440 --> 36:12.040
I've seen in the industry that there's paper mill that allows people to execute notebooks

36:12.040 --> 36:19.640
as a parameterized script and there's also git plugins that allows people to create

36:19.640 --> 36:22.520
very nice looking diffs of notebooks.

36:22.520 --> 36:30.560
Those are not yet explored in PyCortex, but it's a upcoming area that we plan to look

36:30.560 --> 36:31.560
into.

36:31.560 --> 36:33.680
Also, hyper parameter optimization.

36:33.680 --> 36:35.800
Did you mention anything in that regard?

36:35.800 --> 36:36.800
Are you doing that?

36:36.800 --> 36:39.080
Are you providing a solution to automate that?

36:39.080 --> 36:40.800
Yes, definitely.

36:40.800 --> 36:45.840
So this touches on the machine learning workflow component that I talked about.

36:45.840 --> 36:49.600
I briefly mentioned earlier to the pipeline orchestration piece.

36:49.600 --> 36:51.120
Yes, exactly.

36:51.120 --> 36:55.800
One thing we learned about machine learning is it's a very tedious process, and when we

36:55.800 --> 37:06.520
don't automate, our users don't necessarily do things in exhaustive or they don't, for

37:06.520 --> 37:07.520
example, typewriter.

37:07.520 --> 37:10.280
If you don't help them too much, they'll stay on their laptops and do it the way they

37:10.280 --> 37:11.280
used to.

37:11.280 --> 37:12.280
Exactly.

37:12.280 --> 37:13.280
Exactly.

37:13.280 --> 37:14.520
And hyper parameter search is one of them.

37:14.520 --> 37:23.360
We noticed that it often requires very repetitive and tedious repetitions of experiments.

37:23.360 --> 37:29.240
So our machine learning workflow solution allows our users to perform randomized search

37:29.240 --> 37:36.160
and grid search by launching a large array of experiments on our internal cloud and

37:36.160 --> 37:40.360
automatically recording hyper parameters and results.

37:40.360 --> 37:44.200
And they can essentially just pick the best solution.

37:44.200 --> 37:53.160
We also have a solution based on Bayesian optimization, where we have a service called wetlab,

37:53.160 --> 37:55.360
this is from the company we acquired.

37:55.360 --> 38:02.280
We give it the set of hyper parameters that we just tested and the results and the service

38:02.280 --> 38:06.160
tell us back what's the next set of hyper parameters to test.

38:06.160 --> 38:12.080
It automatically takes into account exploration and exploitation and recommends sets of hyper

38:12.080 --> 38:14.640
parameters to try next.

38:14.640 --> 38:24.080
And that's so far seems very effective and our ML workflow solution has completely automated

38:24.080 --> 38:26.520
solution for using wetlab.

38:26.520 --> 38:31.000
Essentially, you just need to say I want to do hyper parameter tuning and configure the

38:31.000 --> 38:36.840
hyper parameter tuner to be wetlab instead of grid search or randomized search.

38:36.840 --> 38:42.040
And the automated solution would take care of the hyper parameter tuning for you.

38:42.040 --> 38:46.360
I guess what's the kind of the fundamental currency in this system?

38:46.360 --> 38:52.600
Is it code that's checked into Git repository?

38:52.600 --> 38:54.360
Some people focus at the code level.

38:54.360 --> 39:00.000
I see others are dealing with containers and checking it and checking out containers.

39:00.000 --> 39:04.760
Is the core artifact for your system?

39:04.760 --> 39:10.200
For our system, the core artifact, I would say, are tensor flow graphs or actually the

39:10.200 --> 39:13.120
code that's defining the tensor flow graphs.

39:13.120 --> 39:19.600
The tensor flow graphs essentially defines the machine learning model.

39:19.600 --> 39:25.800
And as part of it, we also define which features are used.

39:25.800 --> 39:31.800
After that, we send this for training and training spits out another artifact called

39:31.800 --> 39:33.280
saved bundles.

39:33.280 --> 39:35.520
It's a tensor flow concept.

39:35.520 --> 39:40.320
And these saved bundles are stored on HDFS for serving.

39:40.320 --> 39:47.720
So I would say the core artifacts are both the tensor flow graph and the trained models.

39:47.720 --> 39:53.560
And presumably, you're versioning all of these and tracking the versions transparently

39:53.560 --> 40:00.160
to the end user, or is the end user thinking about development workflow explicitly?

40:00.160 --> 40:05.680
The end users do need to think about development workflow and how they version their code.

40:05.680 --> 40:10.320
Essentially, the tensor flow graph is code, so it's version by Git.

40:10.320 --> 40:16.440
But the models are end users need to version themselves.

40:16.440 --> 40:24.200
And have you seen within your user base that you've got ML engineers that are very comfortable

40:24.200 --> 40:28.160
with that kind of workflow, but data scientists that are less comfortable with that workflow

40:28.160 --> 40:32.480
and prefer it to happen transparently?

40:32.480 --> 40:40.280
So we have definitely seen that one of the things we learned was that there's a wide

40:40.280 --> 40:47.960
variety of machine learning practitioners ranging from machine learning engineers all the

40:47.960 --> 40:51.640
way to deep learning researchers and data scientists.

40:51.640 --> 41:00.040
And their use cases differ from production engineering versus more exploration and analysis.

41:00.040 --> 41:03.120
And they prefer quite different solutions.

41:03.120 --> 41:05.680
And what you mentioned is one.

41:05.680 --> 41:12.080
The scientists, they tend to prefer, for example, notebook, centric exploration and development

41:12.080 --> 41:19.000
and machine learning engineers prefer to write code and just git and check into Git.

41:19.000 --> 41:25.400
Right now, we don't have a very opinionated solution or we don't prescribe a development

41:25.400 --> 41:31.600
workflow across this different type of machine learning practitioners.

41:31.600 --> 41:40.360
We are, we start with catering to production ML engineers, we're in the process of starting

41:40.360 --> 41:46.280
to look at how deep learning researchers and data scientists test to use our platform

41:46.280 --> 41:48.480
and how we can make their lives easier.

41:48.480 --> 41:53.560
We jumped over to talking about that workflow or pipeline orchestration layer.

41:53.560 --> 42:00.480
Is that based on something open source like airflow or is it proprietary orchestration

42:00.480 --> 42:01.480
tool?

42:01.480 --> 42:04.600
It's based on top of Apache airflow.

42:04.600 --> 42:10.520
Are you doing both kind of online and offline workflows with that?

42:10.520 --> 42:17.800
Are you like doing offline scoring and or batch scoring using the workflow tool as well

42:17.800 --> 42:26.960
or is it primarily for the experimentation and kind of model development loop?

42:26.960 --> 42:31.960
It's primarily for offline training.

42:31.960 --> 42:35.880
For Twitter, the online part is actually real time, right?

42:35.880 --> 42:44.200
So we have prediction servers for that machine learning workflow is for training the models.

42:44.200 --> 42:49.920
I didn't fully understand what you mean by batch scoring like our predictions are like

42:49.920 --> 42:52.680
this like a user comes to twitter.com.

42:52.680 --> 42:57.680
For example, we need to present advertisement, we immediately need to respond.

42:57.680 --> 43:03.720
So this request hits our prediction servers and we generate scores in a real time manner.

43:03.720 --> 43:06.680
That's not using machine learning workflows.

43:06.680 --> 43:11.680
I think we thoroughly explored the first thing on your list of like seven things and we're

43:11.680 --> 43:15.320
40 minutes in.

43:15.320 --> 43:17.320
I see.

43:17.320 --> 43:23.160
We may need to to to be continued this.

43:23.160 --> 43:28.800
I am very curious about the meta team that you mentioned and maybe we can spend a few

43:28.800 --> 43:36.520
minutes talking about what you're doing there because it is an issue the issues around

43:36.520 --> 43:42.880
bias and accountability are and fairness are ones that are you know folks are starting

43:42.880 --> 43:50.200
to realize they need to pay more attention to and I'm curious how you've staffed up a

43:50.200 --> 43:55.240
team with the charter of that team is what the teams practices are and how they're tackling

43:55.240 --> 43:56.720
this issue.

43:56.720 --> 43:57.720
Sure.

43:57.720 --> 44:04.560
So this started from a year ago RCU Jack publicly tweeted that we're committing to

44:04.560 --> 44:10.200
increasing the collective health openness and civility of public conversations.

44:10.200 --> 44:15.560
And as part of that we're using machine learning to make algorithmic decisions to curate

44:15.560 --> 44:17.760
the public conversations right.

44:17.760 --> 44:25.480
So one thing we realize is we don't yet fully understand the impact of those algorithmic

44:25.480 --> 44:34.440
decisions and for example these algorithms decide what our users see right and what people

44:34.440 --> 44:41.160
see might actually change their behavior in response to the algorithmic recommendations

44:41.160 --> 44:47.440
and as a result their behavior shift and their behavior creates training data which feeds

44:47.440 --> 44:53.520
back to the algorithms which feeds back to the training data we use to train our machine

44:53.520 --> 45:00.760
learning models and this creates feedback loops and it's not yet super clear to us what

45:00.760 --> 45:09.480
exactly these feedback loops cause and for example there's right now there's research

45:09.480 --> 45:15.600
about how machine learning in social networks cause like polarization of opinions.

45:15.600 --> 45:25.880
So we started this team called meta to study like the bias for example and fairness and

45:25.880 --> 45:32.200
accountability and explainability of our machine learning models and we're staffing the

45:32.200 --> 45:37.440
team by partnering up with UC Berkeley professors.

45:37.440 --> 45:45.640
This is for two reasons for one this is the interdisciplinary effort it involves not

45:45.640 --> 45:53.880
just engineering there's also social science concerns there's legal concerns there's I

45:53.880 --> 45:58.680
don't know there's a lot of like essentially human concerns other than engineering concerns

45:58.680 --> 46:04.480
that's why we want diverse perspective and we're partnering with UC Berkeley professors

46:04.480 --> 46:11.640
and researchers the second thing they bring is they bring a like a because we're thinking

46:11.640 --> 46:18.880
about fairness and bias right the third party which is UC Berkeley which is not really a

46:18.880 --> 46:27.920
part of Twitter they bring a I think they bring exactly exactly that's why we staffed

46:27.920 --> 46:35.920
the team to be a partnership between Twitter engineers and UC Berkeley professors and researchers

46:35.920 --> 46:41.200
we want to make sure that we're not we're getting perspectives not just from engineers

46:41.200 --> 46:46.680
because this is not just an engineering problem it's also a social problem and when you when

46:46.680 --> 46:53.440
I think about a role like this or a team or a charter like this and what we want from

46:53.440 --> 46:59.560
them in today's environment it strikes me that a big part of this by necessity is kind

46:59.560 --> 47:06.120
of research and exploration and building understanding of these issues and how they play out in

47:06.120 --> 47:12.000
a network like Twitter's but you also want that to have engineering impact and you want

47:12.000 --> 47:16.440
to create a place where data scientists that are working on a problem or machine learning

47:16.440 --> 47:20.480
engineers that are working on a problem can take advantage of you know some degree of

47:20.480 --> 47:26.960
expertise in a very kind of practical tangible today kind of way how do you manage that

47:26.960 --> 47:36.000
that dichotomy with this team yes so this team is right now the main objective is to provide

47:36.000 --> 47:45.360
for example tooling and resource to increase explainability and transparency of our machine

47:45.360 --> 47:52.320
learning models for now we need to first understand what's going on right before we actually

47:52.320 --> 48:02.200
propose what to change so I think for now there really isn't a dichotomy yet between engineering

48:02.200 --> 48:10.520
impact and research essentially we're trying to measure for the first step and we are providing

48:10.520 --> 48:15.960
tools for different teams to be able to measure well it has been a great conversation

48:15.960 --> 48:23.680
still so much more for us to chat about but I think this was a very very interesting exploration

48:23.680 --> 48:28.640
of deep bird and how you're approaching training and I appreciate you taking the time to chat

48:28.640 --> 48:34.800
with us about it happy to continue the conversation next time if we we get a chance yeah absolutely

48:34.800 --> 48:43.560
thanks so much all right everyone that's our show for today for more information about

48:43.560 --> 48:49.520
today's guest or to follow along with AI platform volume 2 visit twimmelai.com slash

48:49.520 --> 48:57.480
AI platforms to make sure you visit twimmelcon.com for more information order register for twimmel

48:57.480 --> 49:03.280
con AI platforms thanks again to seek out for their sponsorship of this series to check

49:03.280 --> 49:07.760
out what they're up to and take advantage of their exclusive offer for twimmel listeners

49:07.760 --> 49:14.440
visit twimmelai.com slash sigopt as always thanks so much for listening and catch you next

49:14.440 --> 49:42.640
time.

