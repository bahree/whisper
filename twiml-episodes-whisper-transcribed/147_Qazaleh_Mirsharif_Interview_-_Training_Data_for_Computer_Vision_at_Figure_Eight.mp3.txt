Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
For today's show, the last in our train AI series, I'm joined by Kazale Mir Sharif, a machine
learning scientist working on computer vision at Figure 8.
Kazale and I caught up at the train AI conference to discuss a couple of the projects she's worked
on in that field, namely her research into the classification of retinal images and her
work on parking sign detection from Google Street View images.
The former, which attempted to diagnose diseases like diabetic retinopathy using retinal
scans, is similar to the work I spoke with Ryan Poplin about on Twimble Talk 122.
In my conversation with Kazale, we focus on how she built her datasets for each of these
projects and some of the key lessons she's learned along the way.
If you've been following this series, you've heard me thank Figure 8 for their support
and sponsorship.
But have you taken a moment to check them out at figure-8.com yet?
If not, you should.
They provide the essential human in the loop AI platform for data science and machine learning
teams, which trains tests and tunes machine learning models to make AI work in the real
world.
Finally, we're celebrating the second anniversary of the podcast this week.
Have you found this podcast useful?
If so, we want to hear how.
Submit your written comments via our anniversary page at twimble.ai-2-A-V or leave us a
voicemail at 636-735-3658.
A quick note before we jump in, this episode was recorded live on-site at the Train AI
conference, so there is some unavoidable background noise.
All right, everyone, I'm here with Kazale Mir Sharif, Kazale is a machine learning scientist
and computer vision at Figure 8, and we are here, as you can tell, perhaps by the background
noise, at the Figure 8 Train AI conference in San Francisco.
Kazale, welcome to this weekend machine learning and AI.
Thank you.
I'm excited about being here.
I am as well, you know, it's the tradition on the podcast to have guests start out by introducing
themselves and talking about how they got interested and started and machine learning
in AI.
What's your story?
Sure.
So, I'm currently a machine learning scientist with a focus in computer vision, Figure 8.
So I completed my PhD in computer science last summer, and before that, I did my master
in Iran in artificial intelligence.
Then I applied for the PhD program in United States and came here for a school.
So my focus was mainly computer vision, and I have work on different topics and application
of computer vision in different areas, which I really enjoyed so far, and I decided that
I want to do the same with joining the industry, so that's where I'm here now.
What initially sparked your interest in computer vision?
How did you choose that as a field to study in grad school?
Yeah.
When I was an undergrad student, I met this professor in one of the master program at University
in my hometown.
So he was doing research on a medical project and like a detection of diseases using the
retinal images, I was really interested in that research and I talked to him and started
to learn about that project.
Then I applied for the master program and got into the artificial intelligence program
in Iran, and I decided that after taking courses and image processing and computer vision,
I said that this is an area that I really like to be in, and I like to learn how I can
apply AI and computer vision to help in different topics, like medical project, which is really
my interest, and I have experience in medical image processing.
So that's where I decided to, I wanted to work on my thesis on this topic, and I got
back to that professor, and I collaborated with him on this particular project and did
my thesis on that, so that's how it all started.
Okay.
And so what was your thesis on?
My thesis was on classification of retinal images, retinal vessels, and retinal images
into arteries and veins.
So this is still one of the latest topics in medical image processing that because retinal
vessels, they can be indicative of eye diseases and prevent eye disease like diabetic retinopathy,
which is the leading cause of blindness.
So any alternation changes in the vessels could be early indicative of these such diseases.
So we have this data collected from patients, these retinal images, and we wanted to process
the data and classify the vessels into arteries and veins, and then measure the width of vessels
and the vessels like arteries and veins and based on the ratio, and comparing it to a normal
like this normal ratio in patients, to see if we can detect these such diseases that
are earlier stages.
So this was one of the topics that I work on, so I basically worked on classification
of vessels into arteries and veins to help with doing some measurements, I can help predict
such diseases at earlier stages and hopefully prevent blindness by detecting this at early
stages.
Interesting.
So not too long ago I did an interview with Ryan Poplin, who's a research scientist at
Google, who recently had some work published around starting from a assuming similar types
of retinal scans, retinal funda scans, and from that determining all kinds of demographic
types of information or indicators like whether it was a male or a female or their age,
things like that from these retinal images, apparently we can learn a lot from the eyes
in addition to just kind of preventing eye health.
Yeah, I heard about that, actually, yeah, I saw that and I know like they're looking at
the Western networks in images for females and for males and there are some differences
that they can use in computer vision or artificial intelligence, they are now able to extract
those patterns from the images and understand the small changes and find this network
with a female or male, which is really hard to do by a human eye.
So for your research, how did you get started?
Did you inherit some training data set that was already labeled that you could just start
working on or did you have to build that up from scratch?
Yeah, that's a good question, without training data really, you kind of go anywhere, that's
the first step to do a research is collecting data and ensuring that the data is clean
and has the labels and then once you have enough data, you kind of start training the models
and then improving the model by collecting more data.
So a lot of time research is stuck at the first stage because that is like time consuming
and hard process, especially for medical image annotations.
It needs some expertise to label and annotate medical images, so we collect those images
from a hospital and eye hospital in my hometown, we collaborated with a doctor and a team
of doctors that were monitoring the research and then we used some online data sets that
were publicly available with the labels, which have helped me to do the research, but
not currently I'm a figure eight and providing training data is much easier and I think the
research goes much faster from here.
So when you had the collaborations with the hospital to provide access to training data,
how did you, how did the project evolve, what were the key steps for you?
The key step, like collecting the images or hard process, like medical images are collected
in hospitals and using devices that can be expensive and like we learned from the doctors
how to label that data and then they monitor the research, so make sure that we have the
ground truth data that we can develop our model and validate our model.
And then once we build that data, we started by looking through the computer vision methods
that could be exploited to further this research.
So I started reading papers, literature, people have done, the work that people already
have done and decided that this, after like validating and testing different models, I decided
that these particular kind of features are giving me good accuracy and this images for
this type of task and then I write a paper on the list.
What were some of the models that you explored?
The model I used was some traditional model, at that time I was doing that research, it
was like maybe six or seven years ago.
So the advancement in deep learning, the super end, like at this stage.
So I used some traditional models, computer models, some classifiers, like LDA, method
to, like we did the feature extraction from the vessels, arteries and veins are different
in color.
And because like arteries carry the blood with oxygen, so they are brighter than veins,
veins are darker.
So from the pixel intensity, we could extract some features from the profile of vessels that
could be differentiated vessels from each other.
And then there is this specific structure in the vessel network that is like a tree that
every vessel branches into two other vessels.
And then arteries and veins never cross the same type of vessels, but arteries can cross
veins.
So if you have an intersection of arteries and veins, you know that one of them is artery
and the other one should be vein.
So using such information, we have improved the method and correct the vessels that were
not returned as the correct labors by the model and we improved the model.
Oh, interesting.
And what were the key lessons learned that you discovered through this process that you
have continued to use in your work today?
Yeah, at that time, like I said, there were in that much training data, so we used some
traditional models.
And once you expand your research to like more images, you edit on more images, then you
see that like you can explore, for example, at this time, there are deep learning models
that they use a lot of training data and can do such, more accurately, classifying the
vessels.
And then if we can classify the vessels correctly, more accurately, then we can do this
measurements, small measurements in the veins and arteries separately and help with, like
help with the early detection of the diseases.
So that I learned that at this time, like I really like to go back to that research again
and provide more training data and like improve my model, use more advanced learning models
to that, I know that deep mind, a Google deep mind are already doing a lot on this.
And this is still an ongoing research because the diabetic retinopathy is prevalent.
This is causing the leading cause of blindness in the world.
And this research could really help to prevent that.
I learned from the conversation with Ryan that there are a number of public datasets of
retinal images.
Did you use any of those?
Yeah, there are coming like more and more data sets now people, I think it's really good
to share data that research can, we can further research, but a lot of time we cannot really
share medical data because it contains personal data and it's hard to call it that data.
But yeah, that's good to know, like it's a research that I have done like a few years ago,
but I really like to get back on that and see more of the data sets that are available
now.
And we can use our current AI human and the loop platform to get more labels and further
the research.
What are some of the things you're working on nowadays?
Yeah, I'm currently working on this project, Parking Sign Detection, which I've heard
about.
I'm really excited about it.
So I'm working on this with my co-workers, Dr. Huayner Schott.
And it happens like when I came to San Francisco for work during a summer, I shipped my car
from Houston, it was during the hurricane Harvey in Houston, so I really didn't have that
time to explore how tough driving can be here in San Francisco.
So I started driving and in the first couple of months I got a lot of parking tickets and
I started using this app called the Spot Angel, Spot Angel, yes, like the app helps you
based on the GPS information on your car, like you can't say what is your current location
and then based on the parking regulation applied to curves, can send you a notification
on when you need to move your car, for example, not to get a ticket for as retaining because
that's something I forget a lot.
And I remember about that app and I saw the app and that really saved me many times from
getting tickets.
So I said that I want to work on this research because this is something we started last
year when he was doing an internship in Spot Angels by detecting parking signs, finding
the location of parking signs, the actual location on the map, and like extracting a parking
regulation that is assigned to each car, digitizing such information can help then with
helping with drivers to have a less stressful experience driving as it is like San Francisco,
including myself.
So I'm kind of looking at myself with this research too.
So if Spot Angel exists and does this, what are you trying to accomplish with the research
that's different?
Yeah, Spot Angels have been going through the street level images, Google street view
or images that their user can collect, and then they have been going through these images
manually and extracting the parking regulation.
This is a really time-consuming process and it's costly.
So computer vision models can help to extract a lot of those information in an automated
way.
So that's what I was doing there and now we are extending the research by using the
planning models, by providing more training data on parking signs in San Francisco and
then we're hoping to build more accurate models to then read the text on the parking
sign and extract the parking rules.
Have you found getting access to the Google Street View Data Difficult or is that freely
available?
Google Street View is a public data system that you can go and see the street view images
but to download them and publicly release that then you need to talk with the providers
of the data.
So since we are doing this research and we contacted them and they are allowed us to release
this data and use for this research because this would be a research that I'm sure a lot
of people would benefit from because especially people who are driving in San Francisco or
New York they know how hard it could be like we can have a safer environment by helping
the drivers find parking spots or like understanding the regulations faster.
So yeah we have that data now and then we are providing a training data on top of that
building more accurate model.
What kinds of techniques have you had to use to make this research work?
Yeah like every other research the first step was training data.
We actually announced that that data set that we used for the initial training of the
model is released now publicly so everybody can run and build their models on that and
test it.
So we used our figurative AI human loop platform to label the data that we collected from Google
Street View imagery and then we tested different learning models such as SSD and YOLO model
and Sutter results and then using different round of active learnings we trained them
retrained the model several times and fit new data to the model and improve the model.
So currently like we can detect parking sign in the images with the like accuracy more
than 90% and with very low false positive rate and we're hoping that we can extend this
to other cities other dense areas such as Los Angeles, New York, San Diego to using transfer
learning models to extend this model to those cities.
And to wrap things up what advice would you have for someone who wants to take on a project
like this?
What I was, whenever I start a project like this like for me like when I was doing research
in university a hard part was that like a lot of time you're spending a lot of time
on creating and labeling the data like having access to data is not that easy and a lot
of researchers are stuck in that step to build their models.
I found that in the story like by providing more training data I can be able to like
accurate more accurate models much faster.
So when I learned about this like I could build models faster.
So it's good that when people start a research they explore the resources that could be
able to them to like the models that are already available like what data are publicly
out of the bed or how they can access more data to like further research and that's good
to know.
Awesome, awesome.
Well Casala thank you so much for taking the time to chat with us.
Thank you for having me here.
Thank you.
Alright everyone that's our show for today.
For more information on Casale or any of the topics covered in this episode head on over
to twimlai.com slash talk slash 144.
Thanks again to figure out for their sponsorship of this show and the train AI series.
To follow along with the entire series visit twimlai.com slash train AI 2018.
And show some love for this podcast second anniversary and share how it's been helpful
to you over at twimlai.com slash 2av.
Thanks so much for listening and catch you next time.
