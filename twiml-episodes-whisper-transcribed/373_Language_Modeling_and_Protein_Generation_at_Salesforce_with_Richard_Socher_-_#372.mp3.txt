Welcome to the Twimal AI Podcast.
I'm your host Sam Charrington.
Hey, what's going on everyone?
A few weeks ago we held our very first interactive podcast screening with Google's Kwaklay.
Attendees got to watch the video interview together and chime in with their own questions
which Kwak and I addressed live during the session.
We had a bunch of fun with this and got a lot of great feedback and so while we still haven't
quite figured out what to call this thing, we have scheduled our next one and it's coming
up this Thursday, May 7th at 12 noon Pacific time.
This time around I'll be hosting Lucas B.Wald, founder of Weights and Biosys for a live
interview screening and an interactive Q&A session.
We'll be discussing data versioning, managing machine learning pipelines, managing ML experiments,
and much more.
You don't want to miss this one.
To join us, visit youtube.com slash Twimal AI, subscribe to the channel and then hit the
bell to turn on notifications so that YouTube will let you know when we're about to get started.
In the meantime, Weights and Biosys is extending a special offer to Twimal listeners, including
unlimited private projects and priority support.
For more details, visit WNB.com slash Twimal, that's w-a-n-d-b.com slash Twimal.
That said, May the 4th be with you.
Hey everyone, I am on the line with Richard Socher.
Richard is the Chief Scientist and EVP at Salesforce.
Richard, welcome to the Twimal AI podcast.
Aloha, great to be here, wants to chat with you soon.
You said Aloha and I was surprised that you're actually in the Bay Area.
I always see these wonderful photos of you all over the place and I only get to ever
see you in person at NURPS nowadays and the Black and AI events and stuff like that.
So it's great to get a chance to connect with you mid-year, how is everything?
Life is pretty good, I'm very grateful.
Our research can continue working on some research during this crisis now, food that is specific
to COVID-19 but by and large, I sometimes joke that the PhD prepared me for several years
for staying at home, meeting pasta every day and working on a computer all day.
So I'm in pretty good spirits trying to have a little bit of positive impact and still
go about my work and make sure my team is doing well throughout this crisis and it's a tough
time but I'm very grateful for the line of research we can work remotely and do quite
well.
Awesome, awesome.
I'm glad to hear that.
It is, don't usually do this but it's April 10th that we're recording this.
What is it week four for you for lockdown shelter in place thereabouts?
That's right, yeah.
Yeah, it's crazy to time, weirdly it's slow and fast at the same time, days more
than to each other, you know, the home office is just the home and the office and everything.
So yeah, time definitely does not seem linear going through this.
It is very strange but hey, before we jump into some of the main topics that we want to
cover and particular language models and some of the recent work you've been doing applying
that to the bio space, share with us a little bit about your background and how you came
to work in AI.
Sure.
Boy, it almost starts in high school when I re-liked math and languages and when you think
about those two fields, one you would hope is true even if you go light years in some
other direction and language is this constantly morphing system where every teenager could
just say, yo-lo and boom, you have a new word and now the signs are going to mess the
deal with that and so they marry when you try to use computers to use math to try to understand
language.
So I studied linguistic computer science back at 2000 and early 2000s and that at the
time seemed kind of like an orchid, kind of cute, cruxotic, niche topic to my parents.
But I thought, man, if we can get computers to understand language, that would be just
incredible.
All the things they could do, especially if you're lazy and you want to re-repetitive
tasks to be done by a computer would be quite amazing.
And so that kind of morphed into a couple of other interests and trying to use eventually,
initially just statistical machine learning and sort of machine learning by itself and
then AI more broadly applied to computer vision problems.
But I really do think in the end language is the most interesting manifestation of human
intelligence.
There's some quite incredible visual systems and apparatuses in the animal kingdom, like
the mantis shrimp with all kinds of focal vision and so on and each eye and all of that
and a lot of animals have quite sophisticated visual systems, but it's really language
that is connected with thought and culture and society and information.
And so I got really excited about language and then in 2010 I saw a handful of people
apply neural network techniques and extend them to computer vision.
And at the time, I had also just become a little bit disillusioned myself around how
much time natural language processing folks spend on feature engineering.
And so I thought, couldn't we use some of these ideas from computer vision and neural networks
for natural language processing and it was not easy.
And the beginning early days had a lot of rejected papers, reviewers just ignoring reasonably
good experimental results saying, oh, why are you submitting neural network stuff to
this conference, this is not the 90s anymore, this stuff doesn't work and so on.
But eventually, more and more people kind of joined the small core that initially was
read just Yoshiro Benjo and Jeff Hinton's labs and Andrew Hings lab at Stanford and it expanded
more and more and now it's kind of the default way for doing things as to use neural networks
of course, they've developed more and more novel architectures too and it's just been
super exciting.
So now I work not just on the research side anymore, but also on a lot of applied problems.
You know, in the end, I often think about trying to have impact and in the end, when you
do research, you hope that people will pick up that research, extend it and actually apply
it to some real world problems, but if you have the opportunity to both do research and
apply it to real problems, you kind of reduce the variance of the impact that you have and
so I work on a lot of NLP problems with chatbots and service and sales and marketing applications
trying to, for instance, automatically reply to emails or to phone conversations or having
chat conversations is a really great one also during a lot of stuff in computer vision trying
to identify different objects and super market shelves and doing complex OCR for forms
and a lot of interesting things, recommendation engines, voice, machine translation.
Now the group is pretty large and so we get to work on a lot of different things.
You know, it's a research organization, but it's part of Salesforce which we, you know,
is kind of a, you know, do you still, does Salesforce still think of itself as a CRM company
or is it much harder than that now?
Yes, the term CRM has kind of expanded and now includes everything that you might do
with a customer, right?
So we're one of the largest e-commerce platforms because customers buy stuff online.
Yeah, we're obviously the largest sales service and marketing organization, but we also
have help companies integrate all their different data.
Now with Tableau, we help people understand their customer data and do a lot of analytics
behind it and then we look at, you know, where are the customers and we help governments
see their citizens as their customers and help them, especially now also in this crisis,
build software really quickly, build chatbots so they can answer questions.
You know, the, in the end, if you go to the DMV Department of Motor Vehicles and you
have a question, chatbots that give you answers there are also, you know, your customer
there of the DMV.
We work with healthcare providers where the patients are customers.
So the definition of what a customer is is getting broader and broader and we're in all
those areas.
And so with the company being in all those areas and being a very product focused company
as opposed to, you know, an academic institution, you know, how does the company balance investments
in, you know, research with product requirements and how does that specifically impact you
and your team and what you decide to, or, you know, end up working on?
It's a great question and it's definitely something that I think every company struggles
with as they can sort of think past their next quarter and think about, you know, the next
couple of years, we, I wear really a couple of different hats.
On the pure research side, we really can work on and have a lot of freedom and we can work
on a lot of different things and we basically look for what's, what's the, what could have
the biggest impact on both the field of AI research as well as on application fields
like economics or a natural language processing or medicine even in other areas.
So there, we have a lot of freedom, but then the, another large part of my group is really
just part of engineering and we're building real products like chatbots or case classification
of emails or opportunity and lead scoring where, you know, a salesperson might have 5,000
people they could email or call in any given day and you can use systems to rank and say,
these customers are the most likely to actually want to buy your product today and then help
them kind of get through and triage that we work with marketing where we can classify
the sentiment of different tweets, for instance, or we can identify company logos on tweets
and surface them even if you don't say at or hashtag this company name.
We work with industries to understand super market shelves and do visual things.
So there's a lot of product development and as long as that product development feels
like and we feel like we're having a lot of positive impact on the business through AI,
we get the carve out a niche where we just think about all the stakeholders, not just
to share all this but all the stakeholders of the ecosystem and there we can work on things
like even protein sequence models and medical computer vision, classifying different types
of breast cancer and a whole host of fundamental research programs and optimization of neural
networks which is pretty theoretical as well as on some really applied NLP projects that
are actually very nicely at the intersection of pure research and applied research.
So for instance, one paper was published a while back and have extended for a while now
on a sequence of SQL where we translate natural language English questions into SQL queries.
And that is a fundamental problem you tried to disambiguate language that sort of touches
upon what is the meaning of a question which is pretty hard and one way to define the
meaning of a question is well it's a program that you once you execute it over the right
set of knowledge will give you the correct answer to the question that the person asking
the question had in mind and one way of doing that is to translate it into code or into
SQL because a lot of data in the world is stored in databases and so that is a very fundamental
question that we actually started with pure research but now with Tableau and other
analytics and so on it is actually quite relevant and business users might also want to ask
questions like how many customers bought this particular product and this particular zip
code between this time range and you just want to be able to answer that question in normal
English language and get a real answer for it and so there are some more and more connections
between the fundamental research group and the applied research group and then all the
product groups and engineering groups.
That provides really interesting context for talking a little bit about one of your recent
papers which is and you mentioned this on protein generation even with all of that in mind
what was how did you end up working on protein generation?
Yeah it's a good question originally we're inspired by language modeling so we've worked
on language modeling for almost four years since we since met a might my startup got acquired
by Salesforce and for a while had the best language models there are still LSTMs or quasi-recurrent
neural networks and variants of these with pointer mechanisms that could copy over words
as they try to predict the next word and it's a very interesting fundamental task in
natural language processing right in some ways it's NLP complete in the sense that if you
can always predict correctly what the next word is then that means you can also do all of
question answering right I can ask you know what's the capital of California and then the next
word should be the capital of California and if you do that correctly it means you have knowledge
about the world you can answer questions you can ask what is the translation of ithibadi from
German into English and then you should get the translation as the next couple words so as you
can get better and better at predicting the next word you might be able to solve a lot of different
natural language processing problems now at the same time that is kind of the long term future
nobody actually thinks that you're you could be good enough especially not a couple of years ago
to do all of these different NLP problems as question as language modeling but originally language
modeling was just used to disambiguate words for instance if I ask you what's the price of wood
is this the wood W-O-U-L-D auxiliary verb or is it the W-O-O-D the noun from a tree wood and so
but with the price of it's much more likely to have a noun after and so you can disambiguate you
know either a translation or speech recognition models or you can come up with better selection
of sentences that were generated by a translation model to say this is more fluent of an English
sentence than another alternative and so that was originally what language modeling was used for
but then we were able deep learning and our group and in other groups and now all these
transformer models and bird models and so on really get better at predicting not just the next word
but you can also predict works in the middle of the sentence and you train really good
general representations of language that capture general knowledge we actually use these
kinds of language models to give explanations for why you make choose a certain classification
output and it turns out that in several cases they actually capture common sense even which is
really hard to capture an illogical or database kind of structure. Can you give some examples of
what you're describing there? Yeah sure so the paper was done by Nadine in our group
at Salesforce Research and basically she created natural language explanations for common sense
reasoning questions and so the paper was we have actually a couple but one was explain yourself
leveraging language models for common sense reasoning and so the idea here is we had a couple of
different multiple choice questions and in with you want to give the answer you also ideally
will say why you gave that particular answer so for instance if you push a glass off a table
what will happen? A it will float, be it will fall down or in break and things like that and then
you will basically say oh why will it fall down and it's not because of gravity and so this seems
like a simple thing and for any particular small scenario you could possibly generate all the logical
consequences but if you think about anything like I was going to say it seems like a simple thing
for anyone who's not involved in AI and say oh the person blows the lease from a grass area using
the blower the blower A puts the trimming product over her face in another section B is seen
up close with different attachments C continues to blow mulch all over the yard several times
and so on so you know these kinds of questions and knowing how to answer that it's just requires a
lot of common sense and common sense is incredibly hard to really formulate in a knowledge representation
such that AI models can really make use of it so long story short I got a little off of a
tangent there language modeling super fascinating lots of other applications that people hadn't thought
about that that came out in the last couple of years and in our case we also wanted to actually
make it more controllable we had these interesting language modeling results from open AI that could
actually generate long texts and it was quite surprising to a lot of people that these models were
so good at doing that at the time but all you could do is you primate with the beginning of a sentence
you say like a knife and then we're just kind of ramble on and on and we thought couldn't we make
this more controllable so we edit control codes based on different training data and based on
basically the whole internet so you can make a control code and say this is a horror story
now say a knife and then you know sort of peek through the keyhole of the door and the door slightly
started creaking and opening and you say oh my god what's going on but you can also say a knife
and then say give me a review and so I just say oh knife is really great cutting and fits well
into our kitchen and so on you could basically control the language modeling a little bit better
and we thought that would make it more useful and now people can kind of collaborate with these
models to generate texts and it almost helps you if you're not trying to do creative writing to
to give you sort of spitball with you and just generate stuff and then you can modify it
you can create marketing messages and have control codes based on these were successful marketing
campaigns and of course you know you have certain things in mind so you want to kind of play
with the model and its output so that was control and that paper just or folks we'll link to it
in the show notes but that's conditional transformer language model for controllable generation
CTRL that's exactly right and that is the largest model is 1.6 billion parameter language model
you train it on a very large corpus you can create any URL as a control token that will
talk in the language of that URL in like cnn.com and so on it's quite fascinating and for a while
we're actually worried also that it might have ethical issues but really I don't think that is the
case people unlike GANs that generate images where people thought images were you know despite
Photoshop people still thought of images as a good proof for something you can forever in human
history since we've had language just misattribute text to somebody else you can just write an
email and say oh this other person sent the email and like well we have to actually show metadata
to really verify that that is really something that somebody said so don't think it helps with
sort of creating misinformation also because you while it's more controllable in terms of the
style now with CTRL or control you still can't force it to say the things that are in your head
like you want to usually when you want to create misinformation campaigns you have something
specific in mind that you would like the models to say but long story short quick question on that
the control code you mentioned you can generate them from any URL when you have something like a
review or a movie or horror I think was the example used it does that particular code map to
a specific URL that you've selected or is there something more to that mechanism so the
control codes are very broad you can say like this is Wikipedia or like Wikipedia style or coming
from Wikipedia like training data it can be just a URL it could be a style like a kid story or a
horror story like you can you can have any set of control codes and one set of control codes are
URL so if you can say create me a Kickstarter campaign for like some new gadget that you come up
with and it'll literally write you a Kickstarter campaign with that URL it's it's actually pretty
hilarious what people have been able to generate with it in terms of the text and the control codes
those are you're providing those to the model at inference time they're not baked in during the
training process is that correct so they are in that we use the whole internet as the training data
and so every URL hat was in some way a control code sure but you don't have to specify a subset of
the internet that will serve as your control codes later why you don't have to yeah you don't have
to but you can but you can yeah the control codes are very general and some of them where we knew
for instance where they came from like Wikipedia we can kind of stylize them and we had certain
groups of documents where we said all right these are all Wikipedia articles so let's just you know
say this is the style of Wikipedia it's very factual you don't just ramble on you don't use
colloquial language and things like that and so can you kind of describe the the general mechanism
that the model is using to base output on these control codes sure um so essentially in a language
model you have a sequence of words and at at the end you have a classifier and that classifier
goes over the whole vocabulary sometimes that vocabulary can be just the characters of the English
language for instance sometimes the vocabulary can be full words and in some cases they're so
called bite-pair encodings and don't want to get too technical but it's basically like character
sequences that are very frequent and you can basically at each time step classify what's the next
most likely token that you want to generate and the control tokens are just another input in the
beginning of these language models and say this is the current input and then after that you say
now start you know you can also have a sequence of words to prime the model further and then it
just continues to generate so it's essentially just another input also in a vector representation
uh based on on these control tokens i'm trying to get at what's special like if i took gpt2 for
example and you know started my prompt with Wikipedia i'm imagining that wouldn't produce the same
effect as your model conditioned on Wikipedia as you're token that's right yeah because the original
language models just took raw text they didn't think about metadata of that text so it's not
hard to say like a knife and then control like in which direction you want that to go it'll
generate whatever is the most likely based on all of the text it's seen okay right so you have no
no way of controlling it in any which direction you want it to go you want to have a colloquial
story you want to have a tweet you want to have a very factual story that sounds very you know
standard uh and so on so this is kind of the metadata associated with with language and you can use
that to control where the output uh is headed in in which general direction it should
so then we trained these language models uh it's quite exciting uh and uh we we released a whole
model and it's it's basically the largest model that would still fit on on fit on a general gpu
that you couldn't get uh AWS like a p100 um and and once it's larger there are some larger language
models that people have trained but they become impossible for anybody else to run like and we're
up to like 17 billion parameters now that's Microsoft that's right and so you know in Nvidia I had
some other ones but they're just like okay if you have a gigantic you know a million dollar cluster
then and you can do this or you want to spend a lot of money per hour of even just loading it up
and and and so on so we felt like this would marketize a little bit what these methods can do uh
and allow basically anybody who can spawn a reasonably cheap AWS instance to play around with
these models and and fine tune them too and and make them work for their uh their particular use
cases and then we thought about what what would other use cases be where else do you have data and
you want to generate useful sequences and uh that uh in in our group we have uh Ali Madani uh
who's a great researcher in our group he's working some medical applications around computer vision
two uh and he basically wanted to study the language of biology uh and basically tried to generate
proteins in a controllable fashion and proteins uh and I don't want to get to technical in the
biocide also I'm not a biologist but basically proteins govern everything uh in human biology
in our bodies and viruses everything and so this AI system which we called progen uh for protein
generation uh with this uh controllable language model is this really high capacity language model
that was trained on the largest protein database that's available so we had 280 million proteine samples
and now we can actually do something as really challenging for science and basically unlock the
potential of protein engineering for synthetic biology material science and human health and we
started this project uh almost a year ago uh and at the time we thought about you know really
pressing uh diseases like cancer and and others uh or material science where you can try to generate
bacteria that might eat plastic and things like that so it was pretty good uh and it's a super
fascinating area of research that I think can have a lot of uh positive potential for the world
and the environment and people but now of course uh it's COVID-19 is is on everybody's mind and
it turns out that even there uh like two years ago the Nobel price in medicine uh was started to
uh or was given to a team that built uh was able to create synthesize new proteins that didn't
exist before to that had a specific function and in the case of these control tokens now the
functions can be a specific type of control token like make the the cell glow or uh make this
uh particular cell uh be a spike protein for a specific receptor and things like that and that
is exactly uh what we can now do for for trying to work uh on on viruses and and antibodies and
things like that to try to generate the right antibody and things like that so it is it just me or
is it pretty amazing that you know we can now build AI models that we're solving you know that
can be applied to what a couple of years ago won a Nobel Prize. Yeah well so yes and no I mean
I don't want to push that too far but that's right that's right and so we we have to we have to be
careful uh it's still very ongoing research and I don't want to hype it up too much until we have
more real results but basically the previous line of research that won the Nobel price they basically
randomly permuted these proteins and then tested out many many iterations until they found something
that would have the actual biology and functions that they wanted and in our case we're able to
reduce the search space because you know there there are a lot of potential uh protein sequences
that you might get with these random permutations but if you had a sense from reading 280
million of these proteins before that a sense of what's a reasonable structure what's most likely
to come after this sequence of uh characters and amino acids and so on uh then you might create
much more uh guided and directionally correct proteins and we actually see you know the energy
how stable they would be and there are a couple of metrics uh that we show uh in the progen paper
that the proteins that this model generates are much more likely to be viable to be synthesized
and to have the functions that you want them to have then randomly permutated ones and that's obviously
a relatively low baseline right random permutation is not that okay better than random permutation
but it's really hard because the human AI the human intelligent system has evolved uh over many
many years to do a deal with human language and the statistics and correlations that human language
has and so we're not very good at looking at you know a b like so the contribution here is not that
you're making a dent in this actual problem but rather that you're applying this language model
that's built on human language to a totally different type of language that kind of underlies
biology that's correct and now and then we show that this new tool can be useful for a broad range
uh of of applications and now we're actually collaborating with people to actually go and and
generate and synthesize these proteins and we're partnering uh of a lot of different universities
and now there's a lot of exciting space a lot of exciting work in this space but it's all a little
bit too early to to tell we just uh released uh progen and so now uh sort of follow up work as
is in the pipeline and so can you go into that follow up a little in a little bit more detail
in the sense of to you know validate the results of this model what has to happen it sounds like it's
what it's ultimately producing is candidate proteins that have to then be validated uh
experimentally is that the idea or that basically it yeah you first want to generate them
computationally then you want to synthesize synthesize the actual proteins in real biology
create the molecules then you want to see if uh on a very simple chemistry level they would actually
exhibit uh the functions that you want if you then think you have some successful candidates
then you would want to run some animal studies and eventually you hope to create new antibodies
new uh ways to deal with uh and uh protect people from certain diseases long line there's
there are many many steps and then obviously we don't have a wet lab and things like that so we're
going to depart people on that we we only go so far uh-huh uh-huh is there it's your knowledge
is there role for simulation or do we are we not there in terms of simulating protein structure
before you go and actually synthesize you could and I guess uh some people work work in that space
it might also be helpful it turns out it's not actually that expensive to synthesize a protein
it's about ten bucks okay uh and so uh depending on the time cost computation tradeoffs and so on
uh you and if you really reasonably certain that you were able to give good candidates to be
actually synthesized then maybe yeah but yeah it's like I said it's very early work synthetic
biology as a field has been around for a while but it's still quite nascent in comparison to a lot
of other fields so I don't want to go into too many details until we have some more more concrete
results yeah yeah and is the you know the idea in this line of work around language models to
hey we've got some interesting thing here with proteins let's you know push that a lot further
or hey we you know demonstrated that we can apply this to you know this biological code what other
types of codes or languages are that we can apply this to like where where you headed with
this general uh you know line of research so I think there are a couple of really exciting areas
of research uh several which have connections to language models in some ways I think of
three equivalent super tasks of NLP actually language modeling is one question answering is another
and dialogue systems is the third and they're equivalent in terms of in the sense that every NLP
problem can be cast as one of those three tasks and you know you can sentiment analysis people
think of it as just classification but really if you ask here's a sentence yes what is the sentiment
of the sentence then the next word that you predict should be uh that you know the classification
uh and the label that that sentence has so even sentiment analysis can be seen as question
answering and then everything that's question answering is also language modeling and in some ways
with insights were kind of irrelevant because some people said that yeah but so what but now we
actually have these models with billions of parameters and we may actually be able to build a single
model for all of NLP and that's been kind of my dream ever since I started in 2010 training
these neural nets uh on on language and because I realized the underlying substrate matters less and
less it becomes more and more important I think in the future to be able to train these large
neural network architectures for multiple tasks so you can have transfer learning between them
you can get to zero shot learning tasks like I want to be able to have NLP systems that answer
questions that they haven't seen before in the training data and I think better that they're
examples like that in squad the Stanford question answering data set uh but it mostly extracts phrases
from a from a document and it doesn't really have to capture complex knowledge uh in and of itself
but language models are very tied to this uh also for I think one of the most exciting and least
soft tasks of our time and that is summarization uh we've had a bunch of summary papers in the group
two uh white check and in our group has just released one on factual uh correctness and consistency
of uh summaries it turns out the whole field of summarization worked with pretty bad datasets
and including ourselves some of the models that were very we're called them abstractive uh versus
extractive so the difference there is extractive summarization just takes chunks and phrases
and sentences from the original document you want to summarize just says this is an important
sentence and then you have it uh whereas abstractive you have the hope that you would understand
what's going on and then you can rephrase it in a different or shorter form uh and some of these
language models get us closer to being able to do that that's exactly right but it turns out they
also often learn to copy phrases from the input uh in just a really clever way and so long
story short the biggest problem uh for NLP and summarization is for instance that uh first names
proper nouns are often have similar vector representations so Jason, Jeremy, John uh they all
look like similar to to these neural network models they are a list of 500 roughly similar numbers
and the problem with that is that in a summary it's really crucial like when you say like
there's converter or you know an accident or something you mix up the names it's really
really different right but to a model this isn't really that different into all the evaluation
metrics of the field of summarization you don't get really dinged hard uh and reduce your metrics
by mixing up one name with with another but for people it's very crucial and so uh looking at
factual uh consistency and accuracy of summarization is something that we care about a lot
and interactively working on and there's again a connection to the language models too.
Huge uh commercial implications of this like we're all inundated with textual data
and you know if we could easily and cost effectively and accurately summarize that that would be
huge. I'm just speaking from personal experience and 500 open browser tabs.
That's exactly right I think it's a super impactful uh technology for our time where ignorance is
almost a choice uh for for most people right but the fact is that there's too much information
and sorry to really get through it and that's what AI is really good good at right uh take
laborious tasks that just don't scale with people and automate them for us.
And going you know for a full circle or at least circling back to progen I've talked to
the folks that are not necessarily trying to apply summarization to scientific literature but
to otherwise use AI to mine insights from scientific literature and kind of project into
you know where future innovation might come from and you know summarization that is you know
the preserve kind of the scientific essence the facts of a you know research paper could be a step
in that direction as well. Absolutely yeah like uh researchers like everybody else are inundated
with too much information right if you try to follow the archive uh and and see all the new papers
that come around AI in just specific fields uh it's it's almost impossible to keep up with the
literature and still do your own work and not just be reading on top uh and so I think summarization
is going to become more exciting and now that we have solved other tasks that can be a little less
ambiguous uh the field of NLP can kind of move towards these these tougher more ambiguous kinds of
tasks. What do I mean by this? So for instance machine translation uh you have a pretty small set
of uh outputs that make sense given an input sentence from German that you want to translate into
English short there may be like two or three different variants like thank you it can be translated
as fiendank or dankersh√∂rn. I know two two options but it doesn't make sense to just say like
katsun to it to just cadendok like it so you have a pretty small variant in the outputs that
makes sense for that input to be generated. On the other hand in summarization boy there's so many
possible variants and uh when you think about it in the end summarization is also highly contextual
and needs to in the limit be highly personalized. For instance when Elmo came out the first sort
of language model uh that had really really good representations uh personally to me a good
summary of that paper would have been oh it's like cove contextual vectors but instead of
trained with machine translation it's trained as a language modeling objective and it works really
well on a lot of different tasks. But if you don't know what Elmo or language models or word
vectors are that is a completely useless summary and really the good summary of that paper introduces
you and maybe it pulls in even text from elsewhere and helps understand what is going on in the first
place with this field and then gives you sort of the incremental novelty of that uh you know new
research result that comes out so and the same is true for for every sort of conflict you might
follow on earth or if you read you know COVID-19 news every day uh you don't need to know
there's a virus but if you just came from that arctic uh and you know for last month and all
the time there's a lot of new stuff uh use the summaries would be very very different and obviously
there's different sort of reading levels if you're doing summarization for kids versus adults and
and so on. So I think summarization there's a lot of interesting things that we can still do in
that thing. Well Richard thanks so much for taking the time to catch up with me and share with all
of us what you're up to there. That sounds like really cool stuff and looking forward to checking
in more frequently uh with you and keeping up with what you're doing there. Yeah, love your
podcast and uh always always enjoyed talking about AI. So thanks for having me. Take care, thanks
so much. All right everyone that's our show for today. For more information on today's show
visit twomolai.com slash shows. As always thanks so much for listening and catch you next time.
