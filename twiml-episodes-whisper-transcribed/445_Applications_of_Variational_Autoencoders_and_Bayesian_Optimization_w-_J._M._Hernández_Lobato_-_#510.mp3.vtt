WEBVTT

00:00.000 --> 00:16.520
All right, everyone. I am here with Jose Miguel Hernandez-Lobato, who is a university lecturer

00:16.520 --> 00:22.960
in machine learning at the University of Cambridge. Miguel, welcome to the Tumbo AI podcast.

00:22.960 --> 00:30.400
Thanks. Thanks a lot for inviting me. Hey, I'm looking forward to digging in, learning a bit

00:30.400 --> 00:36.480
about what you're working on, but I'd love to have you start by sharing a bit about your background

00:36.480 --> 00:43.920
with our audience. How did you come to work in machine learning? So good. That's a good question.

00:43.920 --> 00:49.920
So I was, as an undergrad, always interested in artificial intelligence, and obviously the

00:49.920 --> 00:55.760
exposure that I had to artificial intelligence was more the traditional AI. For example,

00:55.760 --> 01:03.360
as an undergrad, I started coding my own test programs, and so on. And then when I finished my

01:03.360 --> 01:09.600
undergrad, I was deciding what to do, and there was this opportunity of doing a PhD, and at the time,

01:10.320 --> 01:17.360
the most similar thing to a PhD in AI was focused on this topic of machine learning, and I just

01:17.360 --> 01:24.320
started working in machine learning, and actually I think I was quite lucky, because I started

01:24.320 --> 01:29.120
at a time where machine learning was not so popular and so hot, and now recently it has

01:29.680 --> 01:36.640
exploded in interest and opportunities. So I think I was quite lucky to get just

01:37.440 --> 01:43.680
when it was not so popular, and I'm in an actually very good position to take advantage of that.

01:43.680 --> 01:48.560
That's awesome. Tell us a little bit about your research interests.

01:50.080 --> 01:59.040
Good, so yeah, so I'm faculty in Cambridge at the moment, and Cambridge is well known for having

01:59.040 --> 02:09.360
a strong focus on Bayesian methods. My interest is at the intersection of Bayesian methods and

02:09.360 --> 02:16.480
deep learning, and I think Bayesian methods, they bring a lot of opportunities to quantify uncertainty,

02:17.120 --> 02:23.120
and this will help us a lot to solve many problems, where uncertainty is very important,

02:23.120 --> 02:29.120
especially in decision-making problems. For example, in active learning, if we want to know

02:29.120 --> 02:36.640
what data to collect next, so that we learn fast about a particular problem, how to, for example,

02:36.640 --> 02:44.720
find the new molecules with improved properties fast, we can also make use of this uncertainty,

02:44.720 --> 02:50.160
and even if we want to, for example, compress the parameters of neural networks,

02:51.040 --> 02:56.560
so that they have reduced the size, for example, if we want to transfer a neural network

02:57.840 --> 03:02.960
to a smartphone or download it, for example, or we want to implement the neural network in

03:02.960 --> 03:11.280
hardware, and we want to store the neural network in a low memory device, you can use these

03:11.280 --> 03:20.240
techniques, and in general, I'm very excited about the challenges of obtaining uncertainty

03:20.240 --> 03:24.000
as to much with deep learning. It's not a straightforward, but there are many opportunities for

03:24.000 --> 03:33.440
having a big impact by doing this. If you were to taxonomize the different approaches,

03:33.440 --> 03:38.640
the folks are taking kind of at this intersection of Bayesian and deep learning,

03:39.360 --> 03:46.080
where is the activity happening right now? Good, so what happens at the moment is that as I said,

03:46.080 --> 03:51.360
it's not really easy to obtain the accurate estimates of uncertainty, and in practice,

03:51.360 --> 03:56.160
the problem is interactable and you have to do approximations. So there are many different ways

03:56.160 --> 04:02.480
of doing these approximations. You could use, for example, sampling based methods that

04:02.480 --> 04:09.360
draw approximate samples of posterior distribution. You could also think of the

04:09.360 --> 04:14.000
instead of drawing samples to come up with a deterministic approximation that

04:14.000 --> 04:20.000
quantifies your uncertainty. This will be, for example, Gaussian distribution. We will try to

04:20.000 --> 04:25.760
obtain a Gaussian distribution that quantifies your uncertainty about the weights of your new

04:25.760 --> 04:35.280
network. This is a different approach, and another alternative is to have something even kind

04:35.280 --> 04:41.200
of in between of the two, something more flexible than a Gaussian, but not as complicated as drawing

04:41.200 --> 04:50.160
samples. And this could be, for example, implicit models that work with very flexible distributions.

04:50.160 --> 04:57.520
So people work a bit on these different techniques to obtain uncertainty estimates.

04:57.520 --> 05:05.840
And at present, there is not really like a very well, like one method that is really known to be

05:05.840 --> 05:10.960
better than the others, and this sort of activity of trying to come up with methods that have

05:10.960 --> 05:17.360
good trade-offs in terms of the computational cost that it takes to obtain these uncertainty

05:17.360 --> 05:26.880
estimates and the quality of the uncertainty estimates. And one of the areas that you've

05:26.880 --> 05:34.160
been applying this kind of work is around in some recent papers around molecular design.

05:34.160 --> 05:42.160
Yeah, that's right. So that's an idea that I'm really excited about. Finding new molecules

05:42.160 --> 05:48.880
with improved properties is really challenging. So usually you have to propose a new molecule

05:48.880 --> 05:54.320
and maybe you have to collect data to see how good that molecule is. And based on that data,

05:54.320 --> 06:01.920
you may update your models and propose another molecule and the whole process repeats.

06:01.920 --> 06:09.840
And the idea is how to achieve this in a way that you find faster some molecule with good properties.

06:10.640 --> 06:19.360
So in this, yeah. Is there a particular aspect of this problem that lends itself to

06:19.360 --> 06:23.200
a Bayesian approach, or where these uncertainty estimates are particularly useful,

06:23.200 --> 06:31.920
or are those kind of separate areas of research for you? So there are some

06:31.920 --> 06:37.040
the estimates in this case are very useful because you will use your uncertainty to guide

06:37.040 --> 06:42.640
the search for better molecules. So typically, you will want to

06:44.080 --> 06:50.240
collect data on those molecules for which you have a chance of getting good results.

06:50.240 --> 06:56.560
And this means that there should be some uncertainty or some probability that the value

06:56.560 --> 07:00.560
or the properties of the molecule are actually maybe better than what you found before.

07:00.560 --> 07:06.720
So you will use this uncertainty and actually the quality of your predictions for the properties

07:06.720 --> 07:12.480
of the molecules to decide what molecules to find next. And the molecules that we choose are

07:12.480 --> 07:20.240
those that have some trade-off between the, if you think about it, the point estimate of how good

07:20.240 --> 07:27.360
the molecule is, but also some high uncertainty. And when you are able to balance these two things,

07:27.360 --> 07:31.520
like molecules where you have uncertainty and there is the probability that you will obtain

07:31.520 --> 07:37.200
actually something better than what you have found before, then you will be

07:37.200 --> 07:43.520
interested in collecting data for those molecules. Got it. And now you've taken a couple of different

07:43.520 --> 07:52.560
approaches to this problem. One paper was focused on kind of searching over the possible chemical

07:52.560 --> 08:02.560
reactions. And then more recently, you're doing this via 3D and in 3D space. And this was a

08:02.560 --> 08:10.880
paper that was featured or that you presented at ICLR recently. That's right. So yeah. So the whole

08:10.880 --> 08:17.360
thing of finding the molecules is actually quite challenging because you, molecules have discrete

08:17.360 --> 08:22.720
objects and they have a lot of structure. And it's not really a straightforward how to come up

08:22.720 --> 08:27.280
with something that looks like a realistic molecule like the ones that you find in the real world.

08:27.280 --> 08:32.080
So the approach that we follow to do this is to use deep generative models. And these are going

08:32.080 --> 08:39.040
to be deep unit networks that are trained on large amounts of existing molecules. For example,

08:39.040 --> 08:44.240
and they will be able to generate new molecules. And the question is how do you want to represent

08:44.240 --> 08:50.880
the molecules and how do you want to train these models to generate new molecules? So obviously,

08:50.880 --> 08:56.480
you may want to synthesize those molecules in practice. So what you could do is to have a deep

08:56.480 --> 09:04.000
generative model that is trained on existing data about chemical reactions, how how

09:04.000 --> 09:09.680
existing molecules are synthesized using chemical reactions. And then you will be able to generate

09:10.320 --> 09:16.160
molecules via chemical reactions. So the model will tell you how to synthesize the generated

09:16.160 --> 09:23.120
molecules. The other approach that is also actually quite important is based on

09:23.120 --> 09:32.560
the actual location of the atoms. So most generative models of molecules they work using molecular graphs.

09:33.360 --> 09:40.560
And we just generate a graph with the atoms that form the molecule and the connections

09:40.560 --> 09:47.040
between those. But there is a lot of important structure in the 3D configuration of the atoms

09:47.040 --> 09:53.760
that is missed by these models. And another approach is to actually generate molecules in 3D

09:53.760 --> 09:59.200
space instead of generating these molecular graphs. That is what the approach based on chemical

09:59.200 --> 10:05.760
reactions does. You can generate the molecules in 3D space placing one atom and then connecting

10:05.760 --> 10:11.200
that atom with previous ones and so on. And the advantage of this is that you have actually more

10:11.200 --> 10:15.520
information about the structure of the molecule and this can be very important for determining

10:15.520 --> 10:21.440
the properties of the molecule. As an example you have that the molecule of water actually

10:21.440 --> 10:26.480
is not the way the hydrogen atoms are connected to the oxygen atom is not the

10:28.400 --> 10:33.840
for example flat. You have like a small angle between the bonds and this gives the the

10:33.840 --> 10:41.120
molecule of water specific properties. And if you just work with graphs without taking into account

10:41.120 --> 10:45.600
for example this angle between the bonds then you won't be able to capture those properties.

10:45.600 --> 10:52.160
So that's why I think capturing these properties and being able to generate molecules in 3D

10:52.160 --> 11:00.880
spaces is quite interesting. So I just want to say that just to motivate this at the moment

11:00.880 --> 11:05.920
there is a huge interest in the application of deep learning methods to this problem because

11:05.920 --> 11:12.080
there are many many opportunities to in particular accelerate the design of new

11:12.080 --> 11:18.240
tracks for example this is something that is very very expensive companies are spending a huge

11:18.240 --> 11:23.920
amounts of money into designing new tracks and deep learning now is offering a lot of possibilities

11:23.920 --> 11:35.360
to accelerate this process. I can see how having worked with this data in kind of the two-dimensional

11:35.360 --> 11:43.760
kind of the flat graph realm would leave you wanting to try a 3D approach. Did your

11:45.920 --> 11:53.200
specific approach or architecture for approaching the 3D problem? Did you start over? Was that kind

11:53.200 --> 12:00.880
of built on what you did for the 2D problem? Yeah so actually the work on 3D is one of the

12:00.880 --> 12:06.400
first works in this area so we really were starting almost from scratch because the approach is at

12:06.400 --> 12:13.760
the moment not as sophisticated as previous models but we are able to successfully generate

12:13.760 --> 12:18.160
these molecules in 3D space. So some of the molecules that we are generating in 3D space they

12:18.160 --> 12:24.640
are relatively simple much simpler than the ones generated with previous models but it's really

12:24.640 --> 12:31.040
exciting. Just to clarify how we do this the idea is to have our reinforcement learning agent

12:31.040 --> 12:38.720
that is going to learn how to place these atoms in a space. The agent is given an initial back

12:38.720 --> 12:45.840
of atoms and the agent has to choose what atoms to place in a space and how to arrange those

12:45.840 --> 12:51.920
and the only feedback that the agent gets is the final energy or the configuration the energy of

12:51.920 --> 12:56.800
the configuration of the atoms. So the agent has to learn by trial and error how to find 3D

12:56.800 --> 13:02.320
configurations of atoms that have the energy and they are physically possible in their work.

13:04.320 --> 13:12.080
And so some of the traditional challenges with reinforcement learning are the sample

13:12.080 --> 13:22.800
inefficiency and the challenges of creating the objective function. How did issues like that manifest

13:22.800 --> 13:30.640
themselves in this paper? That's right so typically reinforcement learning methods are data hungry

13:30.640 --> 13:39.520
and the way we address this is to use some fast numerical methods that approximate the energy

13:39.520 --> 13:45.120
of the atoms in a space. So we are actually able to collect a relatively large amount of data

13:45.920 --> 13:53.200
to find this. The problem with this is that obviously you may want to find molecules that are

13:53.200 --> 13:58.400
stable and that have like this 3D configuration that is physically possible but you may also want

13:58.400 --> 14:03.360
to find molecules with interesting properties. And the question is that then you have to combine

14:03.360 --> 14:09.920
these two different objectives. One is the energy of the molecule that might be cheap

14:09.920 --> 14:16.240
to obtain and then you may also have another property of the molecule that could be actually

14:16.240 --> 14:21.840
quite expensive to obtain. You may have to do experiments in a laboratory to finally test the

14:21.840 --> 14:25.200
properties of that molecule in the real world that are the ones that you would expect.

14:26.320 --> 14:32.240
So in practice you would have to find a balance between how to combine the two approaches

14:32.240 --> 14:38.560
and the one way to do this is to use for example sub-agat models. The idea is how to solve

14:38.560 --> 14:44.480
sub-agat models. These models will, for example, make predictions about the expensive properties

14:44.480 --> 14:49.280
based on some existing data. And that reinforcement learning agent will try to

14:49.280 --> 14:53.120
will be working with the predictions of these sub-agat models that will be that will be

14:53.120 --> 15:05.520
very fast to a lot of weight. And to what degree have you integrated in kind of the Bayesian

15:05.520 --> 15:11.440
approach into this reinforcement learning oriented formulation of the problem?

15:12.320 --> 15:17.680
In the reinforcement learning approach we haven't really done that yet but we have done that

15:17.680 --> 15:24.800
in the case of the, for example, the models with chemical reactions. And the idea here is to do

15:24.800 --> 15:29.600
something called the Bayesian optimization methods. Bayesian optimization methods are actually

15:31.040 --> 15:37.520
in the world, correct? Yeah, that's in the in the 2D graph setting. The idea is that

15:39.520 --> 15:45.520
Bayesian optimization methods work also by using these sub-agat models and the idea is that you will

15:45.520 --> 15:52.640
you will fit, for example, a predictor of the properties of the molecule that gives you estimates

15:52.640 --> 15:57.360
of uncertainty. And this could be, for example, a Gaussian process. These are very good models

15:57.360 --> 16:05.360
that work quite well to provide the estimates of uncertainty. And then you can use these

16:05.360 --> 16:12.640
uncertainties to decide what data to collect next. What is super interesting is that we are using

16:12.640 --> 16:20.800
deep generative models to generate the molecules, but to connect these models with a Bayesian optimization

16:21.920 --> 16:27.360
approach, what we do is that we work with the latent representation of molecules given by the

16:27.360 --> 16:34.400
deep generative models. These deep generative models, like variation algorithm colors, they learn

16:34.400 --> 16:41.360
a compressed representation of the data. They have some latent variables. And by using these

16:41.360 --> 16:46.880
models, we are actually able to map molecules to a low dimensional latent space that is

16:46.880 --> 16:53.520
actually continuous. And then we can map points from this latent space back to the original space

16:53.520 --> 16:59.920
of molecules. So what we do is then use Bayesian optimization techniques to do molecule optimization

16:59.920 --> 17:07.920
in this latent space. So this is like a super interesting idea. And the advantage of this is that

17:07.920 --> 17:13.440
you have now an approach that is going to do efficient optimization because you are using this

17:13.440 --> 17:18.400
Bayesian optimization methods that work very well in continuous spaces and relatively low dimensional.

17:19.120 --> 17:24.800
And we are combining these methods with a deep generative model that will generate molecules

17:24.800 --> 17:30.400
that are similar to those found in the real world. And this is going to be done in a way without

17:30.400 --> 17:35.760
having any expertise on how the molecules are constructed. You just have a data set of molecules.

17:35.760 --> 17:41.920
You fit your deep generative model to this data. You obtain this latent space that represents

17:43.360 --> 17:49.040
the molecules in a continuous representation. And then you can do molecule optimization in that

17:49.040 --> 17:57.280
space. So this is some areas where I'm currently working quite a lot with members of my group.

17:57.280 --> 18:07.760
Got it. And does the surrogate model extension to the 3D setting allow you to do some more things?

18:08.720 --> 18:12.240
Yeah. In principle, you could do similar things. This is something that we haven't really

18:12.240 --> 18:18.160
explored yet. But you could have your reinforcement learning agent optimizing some combined

18:18.160 --> 18:24.160
objective between the energy of the molecule that you are constructing and the prediction of

18:24.160 --> 18:29.520
the property of the molecule according to the surrogate model. This is obviously something

18:29.520 --> 18:35.040
that we haven't done yet. But it's a very exciting direction for future work.

18:36.320 --> 18:40.560
Awesome. Awesome. So you also do some work in compression. Tell us about that.

18:41.040 --> 18:47.920
That's right. So this is something that I'm really excited about. And this is some work that

18:47.920 --> 18:54.480
has been done by some of my PhD students in particular, Martin Harasi and Greg Flamick.

18:54.480 --> 19:01.360
And this is a completely radical new way of doing compression. So most compression methods,

19:01.360 --> 19:10.640
they actually work by mapping, for example, a sequence of characters to another representation

19:10.640 --> 19:16.800
of that sequence that has a size that is proportional to the log probability of the original

19:16.800 --> 19:22.080
sequence. This is what typically you do in compression. And it's well known. Not that the

19:22.080 --> 19:27.840
information that a particular value of a random variable has is determined by the log probability

19:27.840 --> 19:34.720
of this of this random variable. So typical methods for compression, they just compress

19:35.920 --> 19:40.800
a specific value of a random variable. They find a new representation that is more efficient.

19:40.800 --> 19:45.600
And there are many methods for doing this like arithmetic coding is an example.

19:45.600 --> 19:50.240
Well, this is really cool of the methods that we are working with, which we call them

19:50.240 --> 19:56.160
relative entropy coding methods. The idea is that we are not really compressing one value of a

19:56.160 --> 20:03.680
random variable. We are compressing random samples. So we just have distributions. We could have

20:03.680 --> 20:10.800
like a base distribution that is shared by the center and the receiver. And what we want to

20:10.800 --> 20:16.880
compress is a random sample from a target distribution. And we don't really care exactly

20:16.880 --> 20:24.000
about the particular sample that we get. We just want to be able to transmit a random sample

20:24.000 --> 20:30.000
from this target distribution to the receiver without actually telling the receiver what the

20:30.000 --> 20:34.400
distribution we are sampling from. The receiver only has this base distribution that is shared

20:34.400 --> 20:39.200
between the center and the receiver. And yeah, we call this method the relative entropy coding.

20:39.200 --> 20:46.000
And what is interesting is that this technique is able to find the compressed representations

20:46.000 --> 20:52.720
of the weights of neural networks that are currently state of the, these methods are really

20:52.720 --> 21:00.080
state of the ad for compressing neural networks. And so how does compressing the distribution

21:01.040 --> 21:06.640
lend itself to compress communication from the center to the receiver?

21:06.640 --> 21:13.680
Yeah, so what you actually do is you don't really send the distribution. So you just send some

21:13.680 --> 21:21.120
bits that will allow the receiver to reconstruct a random sample. And this random sample in general,

21:21.120 --> 21:29.280
the center doesn't really control what sample you send. You just are able to choose randomly one

21:29.280 --> 21:35.840
and then send some bits to the receiver. And the receiver will take those bits, use the shared

21:35.840 --> 21:40.160
distribution, the base distribution that is shared between the center and the receiver,

21:40.160 --> 21:45.120
and use that the base distribution to recover the sample. So in general, you don't really send

21:46.640 --> 21:52.720
the distribution itself, but you are able to send samples from the distribution.

21:53.360 --> 21:59.040
And that's because the distribution, the compressed distribution is, you consider as pre-shared,

21:59.040 --> 22:01.200
it's known to both center and receiver.

22:01.200 --> 22:05.360
Yes, that's right. So that's some information that is

22:06.960 --> 22:10.960
agreed between center and receiver. And typically this could be a very simple distribution that

22:10.960 --> 22:18.800
is easy to sample from, for example, a standard Gaussian distribution. And what is interesting

22:18.800 --> 22:24.880
of these method is that you are really just sending random values of random variables without

22:24.880 --> 22:30.320
caring much about the value of those. And this is extremely useful for compressing the weights

22:30.320 --> 22:35.600
of neural networks. Because neural networks are very, very tolerant to perturbation of the weights.

22:35.600 --> 22:40.800
So it might be fine if you just send some randomly corrected version of your weights,

22:40.800 --> 22:46.000
your neural network might still be able to make accurate predictions using that corrected

22:46.000 --> 22:52.640
version of the weights. So by doing that, by sending some small perturbation of the weights,

22:52.640 --> 22:57.840
and not exactly caring about sending a specific value of the weights, we are able to achieve

22:57.840 --> 23:05.760
the best existing compression rates for neural networks. Got it. But you might not want to apply

23:05.760 --> 23:11.840
this to traditional communication. That's right. So the question is, what type of communication

23:11.840 --> 23:16.240
you can apply these to? Yeah. You think some of that you can actually apply these to many other

23:16.240 --> 23:21.760
types of data, not only the weights of your networks. For example, images, you may say,

23:21.760 --> 23:29.200
I want to send some image. You may also tolerate some error in your image. And it turns out

23:29.200 --> 23:34.960
that it might be fine if you send just some version of your image that is slightly corrected.

23:35.840 --> 23:40.880
This is usually called the lossy compression. So you won't be able to send the original image,

23:40.880 --> 23:46.480
but the reconstruction quality of the image could be still quite good. And obviously,

23:46.480 --> 23:52.480
all this depends on the tradeoff that you have between how much you want to compress the image,

23:52.480 --> 23:58.080
and you would have a potential loss, and maybe you don't want to compress the image so much,

23:58.080 --> 24:08.000
and the loss is not so high. And then you've also been applying deep generative models to robust

24:08.000 --> 24:13.360
prediction. Tell us about that work. That's right. So this is something that we have been really

24:13.360 --> 24:19.520
working on very recently, and there is a lot of interest in this area. So it turns out, I mean,

24:19.520 --> 24:25.920
this is widely known. Deep learning methods, they are not very robust, especially to

24:25.920 --> 24:34.880
experience features, for example, that could be looking as useful to make predictions in your

24:34.880 --> 24:41.760
data, but they're actually not like this. And the typical example of this is this problem where you

24:41.760 --> 24:49.840
have to classify images of camels and images of cows. And you could imagine that the cows appear

24:49.840 --> 24:56.640
typically with a background of a green field, and the camels could appear with a background of a

24:56.640 --> 25:02.320
desert. And if you try to see that deep learning methods to classify these images, the deep learning

25:02.320 --> 25:09.120
method is very likely to fix on the background pixels, which are not really representative of what

25:09.120 --> 25:15.280
you want to learn. It's not really differentiating between the shape of the cow and the camel. And when

25:15.280 --> 25:20.960
you try to make predictions, then for example, for a cow that is standing in a beach and not in a

25:20.960 --> 25:27.440
green field, then it's going to make a horrible mistakes. So the idea is then how can you make

25:27.440 --> 25:34.080
deep learning methods more robust so that they don't fix on these patterns in the data that are

25:34.080 --> 25:40.560
just spurious and they are not really representative of the prediction problem that you want to solve.

25:40.560 --> 25:46.640
So there has been a lot of interesting work in this area, especially with some methods

25:46.640 --> 25:52.080
called the invariance risk minimization. And they actually come up with solutions to this problem,

25:52.080 --> 25:57.680
but they are based on using linear models. And obviously linear models, they are not really going to

25:57.680 --> 26:04.960
be very accurate in many different settings where actually the patterns in the data are not linear.

26:04.960 --> 26:08.240
So what do we propose with invariant risk minimization?

26:08.240 --> 26:12.080
Yeah, that's right. So this is the work around, yeah, that's what I didn't know about this work.

26:12.080 --> 26:15.840
It's very widely known and it's having, it's had like a lot of impact.

26:15.840 --> 26:22.400
Well, I was going to ask that you explain that as a broad concept, independent of linear versus

26:22.400 --> 26:30.000
non-linear. Yeah, so the idea is that you want to find some, the idea here to solve this problem

26:30.000 --> 26:36.880
is to find some predictor that is going to be invariant across different representations of the

26:36.880 --> 26:43.280
data or environments so that, for example, you could imagine that you have these images of

26:43.920 --> 26:50.880
cameras and cows and the type of background maybe changes slightly in across two different

26:50.880 --> 26:56.480
versions of your dataset. And then what happens is that this correlations between the background

26:56.480 --> 27:03.040
pixels and the target label is going to change from one version of the data and the other. Maybe in

27:03.040 --> 27:08.640
one version of the data, the fraction of the cows with green fields is slightly higher than

27:10.160 --> 27:15.680
in another version of the data. So if you have a predictor that focuses on these pixels,

27:15.680 --> 27:21.600
then it's going to be changing across this environment. So in some environments,

27:21.600 --> 27:26.160
the predictor could be more reliable and in other environment it might be less reliable.

27:26.160 --> 27:32.080
And this allows you to identify that the patterns that the predictor is capturing are probably

27:32.080 --> 27:38.160
not realistic and curious. So there is to find some predictor that will be invariant

27:38.880 --> 27:42.880
and it's going to work well across different environments. And for example, this predictor that

27:42.880 --> 27:49.040
focuses on the shape of the cow or the camel will be invariant. And the idea is to have a predictor

27:49.040 --> 27:56.800
that, for example, could work in the non-linear case. So I can say briefly how we solve this problem

27:56.800 --> 28:01.920
and the idea is that we use deep generative models also to solve this problem and we use something

28:01.920 --> 28:07.360
really cool and that is really exciting at the moment. And it's a family of deep generative models

28:07.360 --> 28:14.400
operational to encoders that are identifiable. This is well known that the existing variational

28:14.400 --> 28:18.960
to encoder models, if you flip them to the data, the latent variables that you will be obtaining

28:19.680 --> 28:26.880
could be different if you train different times your methods. So there are many different

28:26.880 --> 28:34.960
transformations of your latent variables and the model could just run to achieve those transformations.

28:34.960 --> 28:40.400
So in general, every time you learn your model, the latent variables that you could obtain and

28:40.400 --> 28:44.480
calling the data could be different. And this makes these methods not very reliable if you want

28:44.480 --> 28:51.360
to use the latent variables for predictions. What has been very recently developed is a family

28:51.360 --> 28:56.720
of deep generative models for variational to encoder models that are identifiable. And this

28:56.720 --> 29:02.960
means that every time you train these models on the data using, for example, different initializations

29:02.960 --> 29:09.040
of your neural networks, you will always obtain the same latent variables. And actually,

29:09.040 --> 29:16.320
this can be useful for solving this invariant risk immunization problem. The idea is that you

29:16.320 --> 29:24.800
will find latent variables that represent the data and then you can use causal identification

29:24.800 --> 29:31.920
methods to choose those latent variables that are actually predictive of the target property.

29:31.920 --> 29:38.080
So in the case of the images and the of camels and cows, you could think of fitting an

29:38.080 --> 29:43.360
identifiable variational to encoder model to this data. And then finding some latent variables

29:43.360 --> 29:49.760
that some will be describing the grass and other variables will be describing the shape of the

29:49.760 --> 29:58.000
cows and the camels. And using the causal identification methods, you can choose those latent

29:58.000 --> 30:04.240
variables that are actually connected with the shape of the cows and the camels with the final

30:04.240 --> 30:11.520
label. And the other latent variables like the green fields and that determine the green field

30:11.520 --> 30:18.560
or the desert, they won't be captured and they won't be identified as cows are related to the

30:18.560 --> 30:24.080
target label. Can you give us an overview of how the causal identification part of that works?

30:24.080 --> 30:33.920
That's right. So what happens is that you have an underlying cows and models. So you have

30:33.920 --> 30:39.040
these latent variables that you have learned with the identifiable variational to encoder model,

30:39.040 --> 30:45.360
and you have now data for the values of the latent variables and data for the target property.

30:45.360 --> 30:48.880
And obviously you also have data for the different environments that I mentioned before. All

30:48.880 --> 30:55.200
these works only if you have these different environments where things change. So once you

30:55.200 --> 30:59.680
have observations from these latent variables, you can try to identify what's the actual

30:59.680 --> 31:05.920
causal direction in the generation of the data. For example, the latent variable points

31:06.800 --> 31:12.480
towards the label. And that means that the label is actually generated by the latent variable

31:12.480 --> 31:19.680
or actually the label for the image points towards the latent variable. And that means that

31:19.680 --> 31:24.640
the actually the latent variable is caused by the label. So the causal identification methods,

31:24.640 --> 31:33.440
they will apply either independence tests to identify what is this right direction for the

31:33.440 --> 31:42.560
other roles that connect the different variables. For they are based on other underlying assumptions.

31:42.560 --> 31:50.320
Like, for example, something that is used in practice is to assume that the label is obtained

31:50.320 --> 31:58.640
as a nonlinear transformation of the latent variable plus some additiveness.

31:58.640 --> 32:04.000
And if you have a model that works in that way, you have that the label is actually generated

32:05.040 --> 32:09.200
as a nonlinear transformation of the latent variable plus some noise. You can actually

32:10.400 --> 32:16.400
identify the right direction by just fitting the nonlinear model in both directions. You can try to

32:18.080 --> 32:23.040
use a nonlinear model to predict the label from the latent variable or a nonlinear model to

32:23.040 --> 32:29.760
predict the latent variable from the label. And you can then look at the statistical patterns

32:29.760 --> 32:37.760
in the noise. And the right direction will actually have a specific properties that allows you

32:37.760 --> 32:45.600
to identify that. This is some work on Cups and inference that has been really exciting.

32:46.560 --> 32:52.480
This was done in the Bernhard circles that and this work actually that we are, I mean, we're

32:52.480 --> 32:56.560
working on this and we plan to submit it to new ribs. This is done also in collaboration with

32:56.560 --> 33:07.600
Bernhard circles and one of my PhD students. Got it, got it. And so how in the case of this last

33:08.560 --> 33:13.520
work that we've been discussing, how do you evaluate the results and how well is it working?

33:14.720 --> 33:19.840
Good. So yeah, so right now evaluating the performance of these methods is challenging.

33:19.840 --> 33:25.360
And right now there is a benchmark problem that people are considering for the evaluation of

33:25.360 --> 33:31.360
these methods and this is called the colored M-nist. It's a, I mean, M-nist, everyone is familiar with

33:31.360 --> 33:36.800
M-nist, everyone that works in the planning. So you have the M-nist, this data set with digits,

33:37.680 --> 33:43.760
and you will have that some digits are half different colors. So you color the digits with

33:43.760 --> 33:50.160
the colors that are red or green and you will choose these colors in a way that they are

33:51.840 --> 33:55.760
spiritually correlated with the target label. So you would have some of these fake

33:55.760 --> 34:01.600
correlations between the colors and the target label. And obviously, for example, you could say,

34:02.720 --> 34:08.320
I mean, you typically classify the digits in two categories, I think, from 0 to 4 is

34:08.320 --> 34:16.880
category one and from 5 to 9 is category two. So you will say the color of the digit, most of the

34:16.880 --> 34:23.520
times, agrees with the actual category. So you have these colors that are correlated with the

34:23.520 --> 34:31.040
label. And what happens is that you have two different versions of your data where this

34:31.040 --> 34:36.800
probability of agreement of the color with the label changes slightly. And this is related to

34:36.800 --> 34:44.080
this thing that I mentioned before that you need some variation in the spurious correlations

34:44.080 --> 34:52.480
to be able to identify them as spurious. So you can then train a deep learning methods on this

34:52.480 --> 35:00.080
data. And what happens is that the test data, actually, the color has no association at all

35:00.080 --> 35:06.320
with the label. So actually if you train a deep learning method on this data and then you evaluate

35:06.320 --> 35:11.600
the predictive performance on the test data, a normal deep learning method is going to perform

35:12.240 --> 35:17.920
extremely poorly because the colors are actually the opposite. The combination of the colors

35:17.920 --> 35:26.880
is the opposite at test time. So you could use this benchmark to see how well you are doing.

35:26.880 --> 35:33.360
And actually, we have extremely good results in this benchmark because we are able to both

35:33.360 --> 35:41.200
find nonlinear representations of the data and also nonlinear predictions. We are able to do

35:41.200 --> 35:46.240
nonlinear predictions with the methods that we have developed. We achieve some of the best

35:46.240 --> 35:58.720
existing results in this particular benchmark. Awesome. And talk a little bit about how your

35:58.720 --> 36:07.440
broader work around applying Bayesian methods and uncertainty estimation applies in this particular

36:07.440 --> 36:13.520
problem. And that's right. So in this case, the idea is the variation out on color model.

36:13.520 --> 36:21.040
So we have this latent variable model that explains how the data is generated. And obviously,

36:21.040 --> 36:26.640
you have latent variables. So these are variables that are not really observed. So the deep

36:26.640 --> 36:32.320
genetic model uses these latent variables to generate the data but do not observe those.

36:32.320 --> 36:38.400
So you really need to infer those latent variables from the data. And you need to use Bayesian

36:38.400 --> 36:45.120
methods for this. For example, you have to do something called the typical evaluation

36:45.120 --> 36:50.480
and inference where you feed a simple approximate distribution to the posterior distribution

36:50.480 --> 36:54.560
over the latent variables. So you could use a variation and inference to solve this problem.

36:54.560 --> 37:02.080
However, it's much better if you use other techniques. And this is what I mentioned before

37:02.080 --> 37:06.400
about the different trade-offs that you have in Bayesian methods. That you could have simple

37:06.400 --> 37:12.560
methods that are maybe computationally cheap and they work relatively well. But you could have

37:12.560 --> 37:17.760
more advanced methods that are maybe more expensive. But they can be much more accurate.

37:17.760 --> 37:22.480
And an example in this case could be sampling based methods. You could think of instead of

37:22.480 --> 37:26.640
using variational inference, which is what most people use when they train

37:29.520 --> 37:35.440
every variation out on colors, you could use some sampling based method to do something

37:35.440 --> 37:45.200
more efficient and more accurate in this case. Awesome. You've got a few other papers at

37:45.200 --> 37:54.000
this latest iClear conference. Yeah. Why don't we quickly kind of talk through those? One of them is

37:57.200 --> 38:02.480
Yeah, so I can talk a bit about some of those papers as well. There is also another paper,

38:02.480 --> 38:10.080
which I'm also really excited about. And it got an oral presentation that I clear. And it's

38:10.080 --> 38:16.240
called the clue. And it's a method for interpretability in machine learning. Right now there is a lot of

38:16.240 --> 38:21.760
interest in trying to open the black box of deep learning methods. No, you train these methods and

38:21.760 --> 38:28.080
you don't really know why they make some predictions. So a lot of people have been focusing on

38:28.080 --> 38:34.320
interpretability methods for normal deep learning techniques. And they will say, oh, my deep learning

38:34.320 --> 38:41.440
method now says that my loan should be rejected, for example. And the joint interest is knowing why

38:41.440 --> 38:48.720
that happens. However, as I mentioned before, uncertainty is very important in many decision

38:48.720 --> 38:55.440
making problems and in many prediction tasks. And if you care about uncertainty, you may have

38:55.440 --> 39:02.560
that your base and deep learning method just tells you, I don't really know what's the prediction,

39:02.560 --> 39:07.920
what's the prediction in this particular setting. For this particular data point, maybe I don't

39:07.920 --> 39:15.520
really know if you should be given your loan or not. So I'm very uncertain about what the right

39:15.520 --> 39:21.280
predictions should be. And the question is then, why is your base and deep learning method

39:21.280 --> 39:30.480
and certain? You may want to actually try to understand what's maybe making the data your deep learning

39:30.480 --> 39:36.960
method and certain. So can the general explainability is focused on the prediction and in this

39:36.960 --> 39:41.760
clue paper, you're focused on the uncertainty estimate? That's right. We are actually focusing on

39:41.760 --> 39:48.960
interpreting uncertainty estimates and trying to come up with interpretability of why deep learning

39:48.960 --> 39:55.440
methods might be uncertain. And what is interesting is that we also use deep generative models and

39:55.440 --> 40:04.000
variation and color models for this. So the idea is that it's similar techniques and obviously

40:04.000 --> 40:10.240
there are many applications of these methods. So what we do is we say, okay, we have this

40:10.240 --> 40:16.480
base and deep learning method and it's saying that this particular data point is highly uncertain.

40:17.520 --> 40:22.320
So what we do is we train a deep generative model, a variation and color model on the data.

40:22.320 --> 40:28.880
And this will map the data into some low dimensional late in the space. And now what you can do

40:28.880 --> 40:35.680
is try to find new points in this latent space that are close to the original data point.

40:36.720 --> 40:44.720
But where the uncertainty of the neural network when you decode those latent points back and

40:44.720 --> 40:51.360
you make predictions, the neural network becomes more confident. So by doing this, we are now

40:51.360 --> 40:56.560
able to say, you have this data point for which your neural network is very uncertain.

40:57.280 --> 41:01.920
Now I have this other data point that is very close to the original one, but the neural network

41:01.920 --> 41:06.800
is much more confident and it's much more certain. And now you can look at the two data points,

41:06.800 --> 41:10.320
the one for which the neural network is uncertain and the one for which the neural network now is

41:10.320 --> 41:17.360
confident. And this will give you a lot of information telling you why the neural network is uncertain.

41:17.360 --> 41:21.360
And you can look at the differences between the two data points and you will be able to understand

41:21.360 --> 41:27.520
why this is the case. And we have tested this on obviously N-next. We have this N-next digit

41:27.520 --> 41:33.920
and we get some of these digits. We have for example, a four looks like a nine, but you

41:33.920 --> 41:39.120
wouldn't really be able to say this is a four, this is a nine. And then this method precisely tells you

41:39.120 --> 41:45.680
the pixels in the image that are actually creating the confusion in the Bayesian deep learning method.

41:45.680 --> 41:51.120
This highlighting, for example, those pixels that make the four look like a nine or not.

41:52.400 --> 41:57.360
And I'm really excited about this because I think it's opening now a new area for research

41:57.360 --> 42:02.320
into interpretability because people will now think, okay, now we can apply interpretability

42:02.320 --> 42:08.880
methods to answer this and we can try to understand better why our methods don't know what they should know.

42:08.880 --> 42:24.880
So you're, help me understand how the approach gives helps you interpret what's happening.

42:24.880 --> 42:35.200
So you are finding close points in the latent space and we understand kind of some geometric

42:35.200 --> 42:39.520
properties about the relationships between points and the latent space. But we don't necessarily

42:39.520 --> 42:49.760
understand the latent space itself and kind of what the dimensions in that space mean.

42:49.760 --> 43:03.280
So how does knowing, how do you get from knowing the two close points, share similar values?

43:03.280 --> 43:07.600
How do you get from there to understanding the causes or being able to interpret?

43:08.960 --> 43:14.000
Yeah, so that's that's I would question. So why does this whole thing works? No, and how

43:14.000 --> 43:19.120
how just operating in this latent space makes makes any sense. So the idea is that the latent space,

43:19.120 --> 43:26.560
the way you train these models is that the latent space has some structure and it captures some

43:26.560 --> 43:33.040
similarity between the different data points. So because the latent space has low

43:33.040 --> 43:40.320
dimension, you will have to find some compressive representation of data points in this latent

43:40.320 --> 43:43.760
space. And whenever two data points are close to each other in the latent space,

43:43.760 --> 43:48.880
this should still exhibit some similar patterns or regularities. Otherwise, you wouldn't be able to

43:48.880 --> 43:54.960
compress the data. So we know that now data points in latent space that are close to each other should

43:54.960 --> 44:05.760
be relatively similar. So our goal is to find these different versions of the original data point

44:06.480 --> 44:11.840
for which the neural network is more confident, the answer is less. So what we can do is now

44:12.720 --> 44:19.920
map these points from latent space into the predictions of our model by just decoding from the latent

44:19.920 --> 44:26.160
space, feeling that as an input to the base and neural network and then getting the value of the

44:26.160 --> 44:30.880
uncertainty. And then you could just do gradient based optimization in the latent space

44:32.560 --> 44:38.560
to find some new points in the latent space that decodes into something that the

44:38.560 --> 44:46.160
neural network is highly like much more confident. And obviously, you want to stay close to the

44:46.160 --> 44:51.040
original point because otherwise what you could get could be very different and that would be

44:51.040 --> 44:55.440
not very informative. No, if you just say, oh, this is a data point where you are very confident

44:55.440 --> 44:59.120
and the other one where you are very uncertain and they are completely different, you don't really

44:59.120 --> 45:07.440
find anything, any pattern that you could explain why things happen. So this technique is actually

45:07.440 --> 45:15.200
called counterfactual, it's a counterfactual method for interpretability. And what typically

45:15.200 --> 45:23.440
means is that you say, I have this data point and actually my predictions are very uncertain.

45:23.440 --> 45:30.640
And by using this counterfactual approach, you say how my data point should have been so that my

45:30.640 --> 45:36.960
network is very confident in your predictions. That's what we are trying to do our counterfactual

45:36.960 --> 45:42.080
by saying, okay, this is the data point that I got and I imagine that things would have been

45:42.080 --> 45:47.520
otherwise and I got another version of this data point for which my neural network is much more

45:49.200 --> 45:53.760
confident. And then by just sticking to something that is close in late in the space,

45:53.760 --> 45:58.480
but we are the uncertainty actually decreases quite quickly, then we are able to

45:59.120 --> 46:04.960
obtain this informative data points. Got it, got it. Awesome.

46:04.960 --> 46:11.600
Well Miguel, thanks so much for joining us and sharing a bit about what you're up to. Thanks

46:11.600 --> 46:41.440
thanks a lot. Yeah, thanks a lot for inviting me. Awesome. Thank you.

