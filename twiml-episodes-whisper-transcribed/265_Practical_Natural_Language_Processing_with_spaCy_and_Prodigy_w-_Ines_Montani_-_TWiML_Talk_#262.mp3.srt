1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,160
I'm your host Sam Charrington.

4
00:00:31,160 --> 00:00:35,280
This week on the podcast we're featuring a series of shows that highlight just a few of

5
00:00:35,280 --> 00:00:39,800
the great innovations and innovators at the intersection of three very important and

6
00:00:39,800 --> 00:00:46,280
familiar topics, data science, the Python programming language and open source software.

7
00:00:46,280 --> 00:00:49,960
To better understand our listeners' views on the importance of open source and the projects

8
00:00:49,960 --> 00:00:54,520
and players in this space, I'm conducting a survey which I'd be very grateful if you

9
00:00:54,520 --> 00:00:57,040
took a moment to complete.

10
00:00:57,040 --> 00:01:01,760
To access the survey, visit Twimbleai.com slash Python survey.

11
00:01:01,760 --> 00:01:09,800
Please hit pause now and we'll wait for you to get back.

12
00:01:09,800 --> 00:01:15,880
That's twimbleai.com slash Python survey.

13
00:01:15,880 --> 00:01:19,840
Before we dive into the show, I'd like to send a huge thanks to our sponsor for this

14
00:01:19,840 --> 00:01:22,200
series IBM.

15
00:01:22,200 --> 00:01:27,200
Speaking of open source, IBM has a long history of engaging in and supporting open source projects

16
00:01:27,200 --> 00:01:33,040
that are important to enterprise data science, projects like Hadoop, Spark, Jupiter and

17
00:01:33,040 --> 00:01:35,680
Cubeflow to name just a few.

18
00:01:35,680 --> 00:01:41,640
IBM also hosts the IBM data science community, which is a place for enterprise data scientists

19
00:01:41,640 --> 00:01:47,320
looking to learn, share and engage with their peers and industry renowned practitioners.

20
00:01:47,320 --> 00:01:52,440
Here you'll find informative tutorials and case studies, Q&As with leaders in the field

21
00:01:52,440 --> 00:01:57,800
and a lively forum covering a variety of topics of interest to both beginning and experience

22
00:01:57,800 --> 00:01:59,560
data scientists.

23
00:01:59,560 --> 00:02:05,160
Check out and join the IBM data science community by visiting IBM.com slash community slash

24
00:02:05,160 --> 00:02:06,160
data science.

25
00:02:06,160 --> 00:02:12,120
Alright everyone, I am on the line with Inez Montani.

26
00:02:12,120 --> 00:02:20,960
Inez is the co-founder of Explosion, a co-developer of the popular NLP open source library

27
00:02:20,960 --> 00:02:24,920
Spacey and lead developer of Prodigy.

28
00:02:24,920 --> 00:02:27,960
Inez, welcome to this weekend machine learning and AI.

29
00:02:27,960 --> 00:02:28,960
Yay, thanks.

30
00:02:28,960 --> 00:02:30,360
I'm really happy to be here.

31
00:02:30,360 --> 00:02:32,400
I'm excited to have you on as well.

32
00:02:32,400 --> 00:02:37,160
I've been looking forward to speaking with you for quite some time now.

33
00:02:37,160 --> 00:02:42,920
I'd love to hear a little bit about how you got started on this path of working at this

34
00:02:42,920 --> 00:02:48,320
confluence of open source and AI and Python.

35
00:02:48,320 --> 00:02:49,960
How did it all happen?

36
00:02:49,960 --> 00:02:54,920
Yeah, so I actually had to try out quite a few things to kind of end up at this point

37
00:02:54,920 --> 00:02:58,920
where I found kind of like the perfect job that combines all of the things I like doing

38
00:02:58,920 --> 00:03:02,480
and all of kind of my skills and things I'm good at.

39
00:03:02,480 --> 00:03:06,600
So I initially, I've always been into programming.

40
00:03:06,600 --> 00:03:09,520
So I grew up on the internet.

41
00:03:09,520 --> 00:03:13,680
I've made websites where we got our first computer when I was like 11.

42
00:03:13,680 --> 00:03:14,680
So I was really into that.

43
00:03:14,680 --> 00:03:20,480
So I spent most of my teenage years building websites basically.

44
00:03:20,480 --> 00:03:23,360
But I didn't actually choose to go into computer science.

45
00:03:23,360 --> 00:03:28,360
So I did my degree in communication science and linguistics, which are also things I was

46
00:03:28,360 --> 00:03:29,360
really interested in.

47
00:03:29,360 --> 00:03:30,800
I worked in media for a while.

48
00:03:30,800 --> 00:03:35,800
But I was always kind of programming on the side and doing those kinds of things.

49
00:03:35,800 --> 00:03:42,000
I eventually, I met my co-founder and also the initial Spacey author Matthew Hannibal

50
00:03:42,000 --> 00:03:44,600
in 2014 here in Berlin.

51
00:03:44,600 --> 00:03:47,360
And yeah, we just started working together and we quickly realized that we had very

52
00:03:47,360 --> 00:03:54,400
similar ideas about like building software, making the technology accessible, making it

53
00:03:54,400 --> 00:03:56,400
usable.

54
00:03:56,400 --> 00:04:00,640
And so yeah, so we eventually, we decided to find a company together, explosion.

55
00:04:00,640 --> 00:04:05,760
Initially we bootstrapped with a bit of consulting and then focused 100% on product.

56
00:04:05,760 --> 00:04:08,400
And development for developer tools.

57
00:04:08,400 --> 00:04:11,560
And yeah, Prodigy was our first product that we launched.

58
00:04:11,560 --> 00:04:12,560
Awesome.

59
00:04:12,560 --> 00:04:14,880
And so Spacey came before Prodigy, correct?

60
00:04:14,880 --> 00:04:16,400
Prodigy is relatively new, right?

61
00:04:16,400 --> 00:04:21,120
Yeah, Prodigy, I think we launched, we went on sale in December 2017.

62
00:04:21,120 --> 00:04:25,360
So it's actually been out for quite a while and we've been really, really happy about like,

63
00:04:25,360 --> 00:04:29,680
you know, response to it and how well, like how many people have been adopting it.

64
00:04:29,680 --> 00:04:34,960
But yeah, Spacey's been there before, Matt basically, he left academia when he realized

65
00:04:34,960 --> 00:04:38,320
that like, wow, you know, the technology is becoming a lot more mature.

66
00:04:38,320 --> 00:04:43,080
People, companies wanted to use his research code and asked him about licensing terms and

67
00:04:43,080 --> 00:04:48,080
he was like, well, you know, if I actually focus on this and write a library that's really

68
00:04:48,080 --> 00:04:52,760
focused on doing all of this in production and getting stuff done, that could be, you

69
00:04:52,760 --> 00:04:54,400
know, really useful to people.

70
00:04:54,400 --> 00:05:01,480
So yeah, he developed Spacey, it was, you know, released open source and I kind of started

71
00:05:01,480 --> 00:05:05,640
working on it pretty much kind of around the time I was first released, but that's when

72
00:05:05,640 --> 00:05:07,600
we started working together.

73
00:05:07,600 --> 00:05:13,360
And so as I mentioned in the intro, Spacey is a very popular library.

74
00:05:13,360 --> 00:05:20,240
I hear it come up all the time in the context of NLP, but for those that aren't familiar

75
00:05:20,240 --> 00:05:25,960
with it, can you maybe share a little bit about what makes it unique and the philosophy

76
00:05:25,960 --> 00:05:31,840
behind it relative to the many other libraries kind of in the NLP landscape?

77
00:05:31,840 --> 00:05:32,840
Yeah, sure.

78
00:05:32,840 --> 00:05:36,440
So Spacey is a library for natural language processing in Python.

79
00:05:36,440 --> 00:05:41,200
So basically, if you have lots of text and pretty much any company, any kind of use case,

80
00:05:41,200 --> 00:05:43,360
you always end up with lots of text.

81
00:05:43,360 --> 00:05:46,880
And at some point, you want to find out more about that text that also goes beyond like

82
00:05:46,880 --> 00:05:51,000
what you can personally read and also goes beyond a bit of like keyword search.

83
00:05:51,000 --> 00:05:56,280
So you know, we want to find out like what companies I mentioned, what people, who says

84
00:05:56,280 --> 00:05:59,920
what and to whom and how are the people, how are there all the things and concepts and

85
00:05:59,920 --> 00:06:00,920
ideas related.

86
00:06:00,920 --> 00:06:06,720
And so Spacey is a library that can help you do that using rule-based methods, but also

87
00:06:06,720 --> 00:06:10,400
with using machine learning models and by training.

88
00:06:10,400 --> 00:06:13,440
And you know, that also helps you train your own machine learning models to do these things.

89
00:06:13,440 --> 00:06:18,720
And the focus is really specifically on industry and production use cases.

90
00:06:18,720 --> 00:06:22,400
So I would say that's also where Spacey is a bit different from a lot of other libraries

91
00:06:22,400 --> 00:06:24,200
that focus a lot more on research.

92
00:06:24,200 --> 00:06:27,680
And you know, research is clearly like also a very important field, but we say okay, instead

93
00:06:27,680 --> 00:06:32,160
of giving you lots of different ways to do one thing so you can, you know, compare

94
00:06:32,160 --> 00:06:38,760
them and you know, compare different model architectures, we give you one way to do things.

95
00:06:38,760 --> 00:06:43,800
And you know, one API, you know, we focus a lot on having a concise API and also having

96
00:06:43,800 --> 00:06:49,560
like one implementation that does one thing and, you know, that and also I think I guess

97
00:06:49,560 --> 00:06:52,760
one another thing Spacey is kind of famous for is that it's very fast.

98
00:06:52,760 --> 00:06:57,320
So that's another very important kind of goal we set ourselves that like whatever we build

99
00:06:57,320 --> 00:07:02,680
and whatever we ship to people has to run fast enough that you can process millions, billions

100
00:07:02,680 --> 00:07:07,240
of documents, you know, in a time that's feasible for a production use case.

101
00:07:07,240 --> 00:07:15,440
I imagine the 900 pound gorilla in the space is NLTK, is that kind of the, the, the

102
00:07:15,440 --> 00:07:21,320
the fact of standard for, you know, folks doing NLP and Python or is there something else

103
00:07:21,320 --> 00:07:23,600
that comes to mind for you?

104
00:07:23,600 --> 00:07:28,000
So NLTK is definitely very popular library and it's also one, a library that many people

105
00:07:28,000 --> 00:07:33,040
have started working with when they, you know, learned NLP, it's very, it was initially

106
00:07:33,040 --> 00:07:38,160
developed for teaching and research, so it still has, you know, very wide adoption, but

107
00:07:38,160 --> 00:07:43,920
it's also very much research focused, like a lot of other, you know, libraries, we now

108
00:07:43,920 --> 00:07:50,840
have, you know, also there are lots of implementations that use PyTorch or TensorFlow to do NLP, but

109
00:07:50,840 --> 00:07:55,480
still there's a very, you know, but a lot of focus is on, you know, really building the

110
00:07:55,480 --> 00:07:59,840
model architectures and we kind of start like kind of on the other side where we say,

111
00:07:59,840 --> 00:08:05,720
okay, we give you APIs and basically the whole like, you know, container objects and the

112
00:08:05,720 --> 00:08:10,720
whole like infrastructure plus optimized statistical models to solve your NLP problems.

113
00:08:10,720 --> 00:08:17,240
And you mentioned the, that part of it is that it offers kind of facility for rule-based

114
00:08:17,240 --> 00:08:20,760
processing in addition to models.

115
00:08:20,760 --> 00:08:22,160
Can you elaborate on that a little bit?

116
00:08:22,160 --> 00:08:27,600
Yeah, obviously a lot of the excitement is around machine learning and models, but

117
00:08:27,600 --> 00:08:32,200
I just did an interview yesterday, it hasn't been published yet, but we were talking about

118
00:08:32,200 --> 00:08:36,560
how, you know, in the real world, you know, in these production use cases, especially at

119
00:08:36,560 --> 00:08:40,320
scale, sometimes, you know, it just makes sense to do things with rules.

120
00:08:40,320 --> 00:08:44,280
Yeah, absolutely, yeah, I would definitely agree with that, like that's also something

121
00:08:44,280 --> 00:08:46,120
we see a lot.

122
00:08:46,120 --> 00:08:50,720
So, you know, what space your office is kind of imagine regular expressions, but with

123
00:08:50,720 --> 00:08:54,040
like, you know, a lot of additional features that you can take advantage of because, you

124
00:08:54,040 --> 00:08:59,680
know, we can now predict a lot of things about a sentence that holds a lot of deeper information.

125
00:08:59,680 --> 00:09:05,320
For example, you can find things in, but only if they attach to a verb or you can, you

126
00:09:05,320 --> 00:09:11,280
know, use a lot of those like linguistic attributes to build a very, very complex or

127
00:09:11,280 --> 00:09:16,880
also a very simple straightforward set of rules that lets you extract content or information

128
00:09:16,880 --> 00:09:17,880
that you're looking for.

129
00:09:17,880 --> 00:09:23,040
And especially actually if combined with statistical models, rule-based systems can be incredibly

130
00:09:23,040 --> 00:09:24,040
powerful.

131
00:09:24,040 --> 00:09:28,320
And also something we see a lot in a lot of industry use cases that actually, yeah, it's

132
00:09:28,320 --> 00:09:32,840
kind of, you know, the fun part is training all your hip neural network models and fiddling

133
00:09:32,840 --> 00:09:37,440
with the hyperparameters, but actually in production, what often really makes a difference

134
00:09:37,440 --> 00:09:43,320
is a really good set of rules that's been tested, validated, and build up over a long

135
00:09:43,320 --> 00:09:46,360
period of time and is really, really specific to the use case.

136
00:09:46,360 --> 00:09:51,640
And in that enhanced, with some machine learning can actually often be much more effective

137
00:09:51,640 --> 00:09:54,040
than like an end-to-end approach.

138
00:09:54,040 --> 00:09:59,480
Are there any use cases that come to mind as, you know, particularly exciting or even

139
00:09:59,480 --> 00:10:04,320
surprising why I never would have imagined someone would have done this with this code

140
00:10:04,320 --> 00:10:05,320
that we wrote?

141
00:10:05,320 --> 00:10:10,280
I mean, in general, like I'm one thing I'm always very, you know, excited about, or like

142
00:10:10,280 --> 00:10:14,640
what that was very eye-opening was that like, it's really, there's, there's no like boundaries

143
00:10:14,640 --> 00:10:19,440
in like the industries that use NLP, like, you know, often people think, oh, well, of course

144
00:10:19,440 --> 00:10:24,440
that the large like tech companies or anyone's doing something with like tech modern stuff

145
00:10:24,440 --> 00:10:31,440
will be using NLP, but it's like a lot of from aerospace to like, I don't know, energy

146
00:10:31,440 --> 00:10:36,080
companies, like everyone has text and everyone uses NLP.

147
00:10:36,080 --> 00:10:40,720
So often also when, you know, we have like new companies who are like, who start using

148
00:10:40,720 --> 00:10:45,480
prodigy or annotation tool, we're like, oh, wow, you use spacey in production and you

149
00:10:45,480 --> 00:10:46,480
do NLP.

150
00:10:46,480 --> 00:10:51,280
Yeah, I guess it makes sense, but it can still, it's basically like, you know, it's

151
00:10:51,280 --> 00:10:54,040
not, it's everywhere.

152
00:10:54,040 --> 00:10:58,000
And in terms of, I mean, use cases, it's, I do, I do have to say that the things that

153
00:10:58,000 --> 00:11:03,440
work best are probably not the most like, oh my god, exciting use cases.

154
00:11:03,440 --> 00:11:07,640
Like, you know, people love to talk about the really like, you know, like cutting edge,

155
00:11:07,640 --> 00:11:10,840
like, I don't know, things you could have never guessed, but actually the stuff that works

156
00:11:10,840 --> 00:11:15,080
well is just like, really good old like information extraction.

157
00:11:15,080 --> 00:11:21,360
You have some problem, you want to, for example, pre fill a database with information from

158
00:11:21,360 --> 00:11:23,320
natural language text.

159
00:11:23,320 --> 00:11:26,440
And that's actually, that's the stuff that actually works really, really well.

160
00:11:26,440 --> 00:11:31,920
And luckily, it's also kind of the stuff that like offers the biggest, I guess, return

161
00:11:31,920 --> 00:11:37,200
and monetary value to like companies doing that.

162
00:11:37,200 --> 00:11:40,680
When you say the stuff, that's the stuff that works really, really well, a library on

163
00:11:40,680 --> 00:11:47,080
that is that mean that it's the stuff that the library does best or the stuff that folks

164
00:11:47,080 --> 00:11:52,840
have the most success in actually implementing or, or something else.

165
00:11:52,840 --> 00:11:57,080
I would say actually we're just, we're just with NLP in general, whether technology or

166
00:11:57,080 --> 00:12:01,320
doing machine learning with text actually, it has proven to work.

167
00:12:01,320 --> 00:12:04,560
Like there are other fields like, you know, we are seeing a lot of like, you know, really

168
00:12:04,560 --> 00:12:11,000
cool like achievements in even conversational stuff, but like it's just that, and you

169
00:12:11,000 --> 00:12:15,160
know, that that just doesn't yet work as well as, you know, people would maybe, you know,

170
00:12:15,160 --> 00:12:17,280
people on the outside would maybe imagine it to work.

171
00:12:17,280 --> 00:12:21,800
Like you still don't have like a magical computer that can answer any question, whereas,

172
00:12:21,800 --> 00:12:25,640
okay, yeah, but about the kind of, the more information extraction stuff, which also

173
00:12:25,640 --> 00:12:30,520
is something we kind of focus on a bit because it works so well is really what's, you know,

174
00:12:30,520 --> 00:12:35,480
that works, we can, you know, we can predict the right things, we can augment, you know,

175
00:12:35,480 --> 00:12:41,600
the predictions with rules, and that's actually, yeah, it's just more successful than other

176
00:12:41,600 --> 00:12:43,440
more speculative areas.

177
00:12:43,440 --> 00:12:49,440
Is explosion you and Matt, or is it a bigger company than that today?

178
00:12:49,440 --> 00:12:53,520
So it started out with only us, and it was only us for quite a while.

179
00:12:53,520 --> 00:12:56,800
We're now working with a few other people on different types of projects.

180
00:12:56,800 --> 00:13:01,440
So, you know, we currently have one person working full time together with us on cool new

181
00:13:01,440 --> 00:13:04,360
features for Spacey, which is really exciting.

182
00:13:04,360 --> 00:13:09,240
And then we have a few developers working on kind of an extension product to Prodigy,

183
00:13:09,240 --> 00:13:13,600
which we're currently finishing, but we still, we still have a small company and a

184
00:13:13,600 --> 00:13:16,840
very small team, and we also plan on staying a very small team.

185
00:13:16,840 --> 00:13:20,080
So that's definitely an important part of kind of our strategy.

186
00:13:20,080 --> 00:13:26,400
And so when you think about Spacey as an open source project, is the contribution

187
00:13:26,400 --> 00:13:35,400
and the code from that primarily contributions made by the explosion team, or do you have,

188
00:13:35,400 --> 00:13:39,680
there's clearly a broad community there, but is it a broad user community, or contributing

189
00:13:39,680 --> 00:13:43,960
community, or a little bit of both, how is that aspect of the project then?

190
00:13:43,960 --> 00:13:49,000
So I would say compared to other more community open source projects, we still have a fairly

191
00:13:49,000 --> 00:13:52,120
small number of my core contributors.

192
00:13:52,120 --> 00:13:56,680
That's true, so a lot of the sort of direction is driven by us, but it's also something

193
00:13:56,680 --> 00:14:01,000
that works well because, you know, users use Spacey because they want to have like, you

194
00:14:01,000 --> 00:14:04,600
know, a good implementation, and they're like, okay, you guys do the implementation,

195
00:14:04,600 --> 00:14:08,200
and we'll use it, and we'll report bugs, and that's okay, that's fine, that's something

196
00:14:08,200 --> 00:14:13,680
we accept, but where we see a lot of contributions, especially like recently, is all the language

197
00:14:13,680 --> 00:14:14,680
specific stuff.

198
00:14:14,680 --> 00:14:20,360
So Spacey ships with a bunch of rules and a bunch of kind of base, basically the kind of

199
00:14:20,360 --> 00:14:25,160
basic setup for all kinds of languages that we support, and that's really where people,

200
00:14:25,160 --> 00:14:28,800
even people who are kind of new in the field can very easily help out, like, you know,

201
00:14:28,800 --> 00:14:32,080
you could, if you speak, or if you know some language, you could maybe add some rules

202
00:14:32,080 --> 00:14:37,600
to improve the way Spacey can tell what a word is and what's not a word and what's punctuation,

203
00:14:37,600 --> 00:14:43,560
for example, or, you know, add some other rules for limitization, or, I don't know, just

204
00:14:43,560 --> 00:14:44,560
add some more tests.

205
00:14:44,560 --> 00:14:47,400
So that's really, that's where we see most of the community contributions, and that's

206
00:14:47,400 --> 00:14:50,640
also where the community contributions are most valuable.

207
00:14:50,640 --> 00:15:00,120
Given the focus on rules and some of the fundamental NLP techniques, do you also track closely

208
00:15:00,120 --> 00:15:09,720
the more cutting edge stuff, like how does Spacey relate to, you know, these new models

209
00:15:09,720 --> 00:15:15,800
like Bert and GPT2, do you try to implement those and ship those with Spacey, or are

210
00:15:15,800 --> 00:15:17,520
they kind of separate?

211
00:15:17,520 --> 00:15:21,960
Yeah, so we, I mean, basically, so our mission has always been, we take what's proven to

212
00:15:21,960 --> 00:15:25,680
work in research and bring it into production so people can views it reliably.

213
00:15:25,680 --> 00:15:29,880
So that's always been our focus, of course, we track what's going on, and then the next

214
00:15:29,880 --> 00:15:33,840
challenge is, okay, we have to see how are we implementing this in a way that it makes

215
00:15:33,840 --> 00:15:37,040
sense for people, because, you know, often what's a bit unintuitive to people is that,

216
00:15:37,040 --> 00:15:40,640
well, you can't just, you know, you can't just pip install Bert, and then it will just

217
00:15:40,640 --> 00:15:46,520
like run magically in your production application, but it's like, you know, sometimes people

218
00:15:46,520 --> 00:15:49,960
have like this idea, it's like, oh, what can be so hard about like just, you know, giving

219
00:15:49,960 --> 00:15:54,320
us all of these models, but, you know, so what we do is we see, okay, how can we make

220
00:15:54,320 --> 00:15:55,320
this work?

221
00:15:55,320 --> 00:15:57,960
Also, how can we make this work with the performance targets we have?

222
00:15:57,960 --> 00:16:03,400
Like, you know, if you have a system, you know, like Bert, where we, basically, we predict

223
00:16:03,400 --> 00:16:08,200
the next word given, you know, the context and the previous words, that's like, those

224
00:16:08,200 --> 00:16:12,120
models are very, very large, and they're also not necessarily very fast.

225
00:16:12,120 --> 00:16:18,240
And at Spacey, we have like, you know, performance target of like 10,000 tokens per second.

226
00:16:18,240 --> 00:16:19,240
That's pretty fast.

227
00:16:19,240 --> 00:16:24,360
So like, for example, to be able to implement this sort of idea, we came up with kind

228
00:16:24,360 --> 00:16:26,520
of our own way of doing this.

229
00:16:26,520 --> 00:16:30,360
So what we're doing in Spacey is we're actually predicting the vector of the next word,

230
00:16:30,360 --> 00:16:34,080
which makes our models much, much smaller and makes it much, much faster.

231
00:16:34,080 --> 00:16:38,120
But actually, yeah, with the latest version of Spacey, we were able to ship a pre-training

232
00:16:38,120 --> 00:16:43,960
feature that basically, you know, let's, let's people use the way, those very new transfer

233
00:16:43,960 --> 00:16:48,520
learning techniques in NLP that I've made the headlines recently, that's a, that's a

234
00:16:48,520 --> 00:16:49,520
very cool thing.

235
00:16:49,520 --> 00:16:53,840
Yeah, can you elaborate a little bit more on that distinction, the distinction of predicting

236
00:16:53,840 --> 00:16:57,760
the vector of the next word as opposed to the next word and how that gives you the performance

237
00:16:57,760 --> 00:16:58,760
increases?

238
00:16:58,760 --> 00:17:03,760
Well, basically, I mean, if you, you know, if you predicting the vector, you're only predicting

239
00:17:03,760 --> 00:17:07,840
kind of an approximation and we can also take advantage of pre-trained word vectors that

240
00:17:07,840 --> 00:17:08,840
we already have.

241
00:17:08,840 --> 00:17:13,400
So like, you know, something like word-to-vec, we also ship like a pre-trained package,

242
00:17:13,400 --> 00:17:16,640
and you can actually, so instead of always keeping track of, you know, all of the individual

243
00:17:16,640 --> 00:17:21,040
words and having representations of all of these words, we actually only have like kind

244
00:17:21,040 --> 00:17:24,600
of the rough meeting representation, the word vector.

245
00:17:24,600 --> 00:17:29,880
So, you know, we can predict that, we can use take, you know, we can take advantage of

246
00:17:29,880 --> 00:17:34,280
a pre-trained word vectors we already have, and it basically makes, it makes the overall

247
00:17:34,280 --> 00:17:39,360
artifact much smaller, and we can rely on that at runtime, so it makes it, it makes it

248
00:17:39,360 --> 00:17:43,960
faster and smaller, and like, you know, there's some other tricks that we have in spacey in

249
00:17:43,960 --> 00:17:50,720
a way we, you know, store those vectors and, you know, cache the data, that also, you

250
00:17:50,720 --> 00:17:53,200
know, contribute a bit to the performance.

251
00:17:53,200 --> 00:17:58,280
And so, yeah, we tried this out, we actually, we had this idea for a while, but we're like,

252
00:17:58,280 --> 00:18:02,440
we weren't sure if it would work, we ran some tests, it looked good, and actually what

253
00:18:02,440 --> 00:18:06,280
was really great was that, like, while we were trying this out, someone actually published

254
00:18:06,280 --> 00:18:10,760
a paper showing that it worked with exactly kind of the same idea, and we were like, yay,

255
00:18:10,760 --> 00:18:14,320
they did, like, of course, of course, they did like much better experiments, and we could

256
00:18:14,320 --> 00:18:18,640
have ever done, and, you know, they really did this well, so we were like, okay, that gave

257
00:18:18,640 --> 00:18:20,600
us a lot of confidence.

258
00:18:20,600 --> 00:18:24,600
And yeah, so we actually, yeah, we just shipped that with spacey 2.1, and there are a lot

259
00:18:24,600 --> 00:18:28,720
of other things we also were like, you know, working on, and spacey does have like its own

260
00:18:28,720 --> 00:18:33,080
neural network model implementations, and we actually have kind of our own little library

261
00:18:33,080 --> 00:18:34,080
for that.

262
00:18:34,080 --> 00:18:38,640
So it is, you know, it's, we're obviously baking to keep up with what works, but it's also

263
00:18:38,640 --> 00:18:43,280
not like, you know, if you want to try out some deletus like model architecture by, you

264
00:18:43,280 --> 00:18:47,480
know, in some paper that was recently published and compare that and hack around with it, that's

265
00:18:47,480 --> 00:18:51,840
maybe, spacey is maybe not the best choice for that, because, you know, we give you one,

266
00:18:51,840 --> 00:18:55,040
the implementation once it's ready and once it's usable.

267
00:18:55,040 --> 00:19:02,080
And so is spacey, is it pure Python, or is it written in C, or underneath, or, yeah,

268
00:19:02,080 --> 00:19:04,600
so it's Python with C extensions, yeah.

269
00:19:04,600 --> 00:19:05,600
Okay.

270
00:19:05,600 --> 00:19:10,760
And the NLP stuff that you're doing, are you writing that in, Sython, are you writing

271
00:19:10,760 --> 00:19:16,480
that, like, are you, do you ever like popping down in the C to get speed, or is it all done

272
00:19:16,480 --> 00:19:17,480
in Python?

273
00:19:17,480 --> 00:19:22,160
I mean, it depends, like some aspects of the library were actually, you know, that, that

274
00:19:22,160 --> 00:19:26,080
really matters, is written in Sython, other parts, we can write in pure Python.

275
00:19:26,080 --> 00:19:30,120
I mean, it's kind of a nice, that's the nice thing about Sython is that you can actually

276
00:19:30,120 --> 00:19:36,040
write Python, but can take advantage of the C whenever you need that, and it still all

277
00:19:36,040 --> 00:19:40,720
looks like Python, which, you know, makes it, at least makes it a bit more approachable.

278
00:19:40,720 --> 00:19:43,800
It still means that, okay, maybe for some contributors, it's a bit of a barrier because

279
00:19:43,800 --> 00:19:50,400
it's just like, I don't know, you have to know some arbitrary stuff, many needs to be compiled,

280
00:19:50,400 --> 00:19:55,840
so it's maybe not as approachable as a pure Python project, but yeah, so it's, I'm

281
00:19:55,840 --> 00:19:58,680
not even sure, I'm not sure it's 5050, it's like probably a bit less, like the most of

282
00:19:58,680 --> 00:20:04,920
the models, of course, the model implementations, obviously, and Sython, then some other, you

283
00:20:04,920 --> 00:20:09,520
know, all the stuff that, all the objects, container objects, all that, like, kind of infrastructure

284
00:20:09,520 --> 00:20:13,600
that needs to be really fast, yeah, and then some Python around it.

285
00:20:13,600 --> 00:20:14,600
Okay.

286
00:20:14,600 --> 00:20:20,880
So all that familiar with, with Sython, I assume that it was Python with an underlying

287
00:20:20,880 --> 00:20:28,040
C implementation, but it sounds like you're a bit more exposed to the C part with Sython.

288
00:20:28,040 --> 00:20:32,000
If you're doing compiling and stuff like that, well, yeah, you, in the end, you compile

289
00:20:32,000 --> 00:20:34,840
it, but it's more like what I meant was like, okay, the syntax, like, I don't know, if

290
00:20:34,840 --> 00:20:38,720
you, if you look at, okay, if you, if you look at spacey source and you look at, look

291
00:20:38,720 --> 00:20:42,240
at the code and what it looks like, it's, you know, you'll be able to read it because it

292
00:20:42,240 --> 00:20:43,400
looks, it's Python.

293
00:20:43,400 --> 00:20:44,400
Okay.

294
00:20:44,400 --> 00:20:47,600
Like, the syntax is way, you know, it will look way familiar.

295
00:20:47,600 --> 00:20:52,000
They're just like some, you know, some little things that look a bit different.

296
00:20:52,000 --> 00:20:53,000
Okay.

297
00:20:53,000 --> 00:21:02,480
And is, is spacey as well a commercial product for explosion or is, is prodigy the first

298
00:21:02,480 --> 00:21:03,480
commercial product?

299
00:21:03,480 --> 00:21:07,240
prodigy is, prodigy is our first commercial product, and we also, it was very important

300
00:21:07,240 --> 00:21:11,520
to us to kind of have a clear distinction between like the open source library and how

301
00:21:11,520 --> 00:21:12,520
we make money.

302
00:21:12,520 --> 00:21:16,240
Um, I mean, at least in terms of, okay, what, you know, what you can use like spacey will

303
00:21:16,240 --> 00:21:20,280
always, spacey is a free library and the code we believe is always, you know, that, that's

304
00:21:20,280 --> 00:21:22,600
always going to be free and open source.

305
00:21:22,600 --> 00:21:27,520
And instead, we think that actually it's much nicer to monetize all the, you know, the

306
00:21:27,520 --> 00:21:28,520
space around it.

307
00:21:28,520 --> 00:21:32,680
Like, for example, um, you know, we can say, Hey, if you, if you power use of spacey and

308
00:21:32,680 --> 00:21:36,880
you really like our open source software, we have something else that, you know, you

309
00:21:36,880 --> 00:21:41,800
might be interested in, which our first product of, our first example of this is prodigy.

310
00:21:41,800 --> 00:21:45,800
So, um, you know, we, we actually think it's like, you know, there's, there's a lot of

311
00:21:45,800 --> 00:21:48,480
talk around like, Oh, how do you monetize open source?

312
00:21:48,480 --> 00:21:53,480
And we think that having a very clear separation between, okay, here's our free library.

313
00:21:53,480 --> 00:21:56,200
Here's our free product and here's our paid product.

314
00:21:56,200 --> 00:21:58,840
Um, it's actually very useful and very good.

315
00:21:58,840 --> 00:21:59,840
Mm-hmm.

316
00:21:59,840 --> 00:22:01,880
Do you also provide commercial support for spacey?

317
00:22:01,880 --> 00:22:02,880
No.

318
00:22:02,880 --> 00:22:05,360
So we've actually, that's, that's another thing.

319
00:22:05,360 --> 00:22:08,240
Like, you know, we, of course, it's, this is also a common, but they come in like business

320
00:22:08,240 --> 00:22:10,840
model and it's, it is what a lot of people do.

321
00:22:10,840 --> 00:22:13,560
And, um, in, you know, in some cases, it works, it actually works quite well because you

322
00:22:13,560 --> 00:22:17,000
can have like, you know, especially in, like, infrastructure cloud staff, there's, there's

323
00:22:17,000 --> 00:22:19,040
a big space for like that sort of stuff.

324
00:22:19,040 --> 00:22:24,040
But for us, we always felt like you end up, if you also, if you're the vendor, um, and

325
00:22:24,040 --> 00:22:28,360
you also like the author of, um, inner the product, uh, you often end up in this really

326
00:22:28,360 --> 00:22:33,040
weird situation where you want to, you want to provide like as much free support as possible.

327
00:22:33,040 --> 00:22:36,640
Like, you want to have really great documentation, you want to have all of, um, that stuff, because

328
00:22:36,640 --> 00:22:39,960
you want people using the library, but at the same time, you sort of want, you want people

329
00:22:39,960 --> 00:22:42,640
to pay you to help them with it.

330
00:22:42,640 --> 00:22:47,720
And if you, you know, if you, a software is like quite easy to use, um, well, then, you

331
00:22:47,720 --> 00:22:50,080
know, you're making less money because people don't actually need you.

332
00:22:50,080 --> 00:22:54,200
Um, if you make your dog shit, cool, people will actually come and want to pay you for,

333
00:22:54,200 --> 00:22:58,920
uh, providing the dogs, but then, you know, you, you're soon running out of customers because

334
00:22:58,920 --> 00:23:02,040
you're, you know, you're product is so shit that always going to use it.

335
00:23:02,040 --> 00:23:05,560
So that's, that's kind of, there's a real dilemma and it's like, to be fair, okay, machine

336
00:23:05,560 --> 00:23:09,160
learning, there's a lot more, actually any, you know, support wouldn't necessarily be

337
00:23:09,160 --> 00:23:11,480
support in terms of, hey, how do I install this?

338
00:23:11,480 --> 00:23:13,200
So how do I write this kind of logic?

339
00:23:13,200 --> 00:23:16,320
It's more like, how should I structure my, you know, P projects?

340
00:23:16,320 --> 00:23:18,400
So how should I do that kind of stuff?

341
00:23:18,400 --> 00:23:22,000
But, um, we actually think there's, you know, you can, uh, people, people say, oh, you

342
00:23:22,000 --> 00:23:25,120
can run lots of companies, but like, in reality, you could run one company, like, you

343
00:23:25,120 --> 00:23:29,400
could really only run one company and we were like, okay, the company, we run one, where

344
00:23:29,400 --> 00:23:34,560
we have the best, like, edge and what, you know, where we actually, you know, like, also

345
00:23:34,560 --> 00:23:39,880
what we enjoy doing is building developer tools, it's not running a support company.

346
00:23:39,880 --> 00:23:42,640
Can you talk a little bit about prodigy and the focus there?

347
00:23:42,640 --> 00:23:50,280
Is it, uh, specifically focused on annotation for NLP types of problems or, or textual data

348
00:23:50,280 --> 00:23:53,120
sets or, uh, is it broader than that?

349
00:23:53,120 --> 00:23:58,360
I mean, in general, I would say, um, more generally machine learning, but of course, I would

350
00:23:58,360 --> 00:24:02,760
like, I think our, of course, the NLP support is probably, um, the best because that's

351
00:24:02,760 --> 00:24:07,240
also, I mean, compared to the other, um, areas of machine learning, also just because that's

352
00:24:07,240 --> 00:24:08,320
what we also know best.

353
00:24:08,320 --> 00:24:13,080
So I would say, um, okay, maybe we have, we have a bit more, um, in there for, that's useful

354
00:24:13,080 --> 00:24:17,600
for NLP compared to, uh, computer vision, um, but the idea is basically, yes, it's an annotation

355
00:24:17,600 --> 00:24:22,080
tool for data science and machine learning and, um, it was basically inspired by us, like,

356
00:24:22,080 --> 00:24:25,960
you know, very early on the company for a few months, we took on some consulting projects

357
00:24:25,960 --> 00:24:29,520
and we saw that like one topic that always came up in every single, or everyone we

358
00:24:29,520 --> 00:24:35,320
talked to, um, was labeling data and also this all like, okay, you know, a lot of companies

359
00:24:35,320 --> 00:24:39,160
would either do it in like Excel spreadsheets or they just send it off to mechanical Turk,

360
00:24:39,160 --> 00:24:44,440
then they'd get it back, train a model, wouldn't work, um, people with a, yeah, we're not very

361
00:24:44,440 --> 00:24:45,960
happy with their workflows around that.

362
00:24:45,960 --> 00:24:51,680
And there was, we kind of saw a gap for like, um, actually a tool that lets the data scientists

363
00:24:51,680 --> 00:24:56,760
get a bit closer to that sort of data collection process because, um, if you just, a lot, if

364
00:24:56,760 --> 00:25:01,400
you outs, just outsource that completely, you're actually outsourcing a lot of the decisions

365
00:25:01,400 --> 00:25:05,840
about how your model is going to perform and what, what your model is going to do because

366
00:25:05,840 --> 00:25:09,720
the, you know, ultimately the labels are, uh, what you're going to predict and how your

367
00:25:09,720 --> 00:25:11,280
application is going to work.

368
00:25:11,280 --> 00:25:12,280
Right.

369
00:25:12,280 --> 00:25:13,280
And that's actually quite ineffective.

370
00:25:13,280 --> 00:25:18,000
So instead, um, what we, what we're suggesting is a much, much closer workflow, um, where

371
00:25:18,000 --> 00:25:23,360
the data scientists can, or the, um, developers, engineer, whatever, uh, can we bait them involved

372
00:25:23,360 --> 00:25:27,960
in the initial, uh, labeling process, um, SIT, you know, you can, you can write little

373
00:25:27,960 --> 00:25:29,800
Python scripts that queue up the work.

374
00:25:29,800 --> 00:25:34,040
You can try out concepts, um, much more quickly because we've built a very, very efficient,

375
00:25:34,040 --> 00:25:35,040
very fast interface.

376
00:25:35,040 --> 00:25:39,640
So let's you move through the examples quickly, um, we have some approaches where you can

377
00:25:39,640 --> 00:25:44,640
try and put a model in the loop and, um, instead of, you know, doing everything from scratch

378
00:25:44,640 --> 00:25:50,080
correcting the model's predictions and BIDs, sure, we're not saying all the data scientists

379
00:25:50,080 --> 00:25:55,200
just have to do it all themselves by hand, but you can actually, you know, you can label

380
00:25:55,200 --> 00:26:00,440
a few thousand examples in an hour and then train your model, see if your idea worked.

381
00:26:00,440 --> 00:26:04,080
Most likely you won't work because nothing ever works on the first try or most things.

382
00:26:04,080 --> 00:26:08,160
We'll never work at all in data science and that's just the reality of things.

383
00:26:08,160 --> 00:26:12,360
And you say, okay, you need to, you know, if you can find what fails quicker and find

384
00:26:12,360 --> 00:26:16,920
what succeeds quicker as well, um, you're actually going to be more successful.

385
00:26:16,920 --> 00:26:22,200
And that was what motivated, um, Prodigy and the way we set it up as a developer tool and

386
00:26:22,200 --> 00:26:24,520
not just as some like platform.

387
00:26:24,520 --> 00:26:30,040
It's interesting that you describe it like that as a developer tool and not just some

388
00:26:30,040 --> 00:26:34,160
platform, because when I think about the things that you've done, it, in my head, it sounds

389
00:26:34,160 --> 00:26:38,360
a lot more like a platform than a developer tool in a sense of, you know, for example,

390
00:26:38,360 --> 00:26:42,440
you talk about how you can put the model in a loop and I've heard Prodigy come up in

391
00:26:42,440 --> 00:26:48,000
a number of conversations in the context of active learning and that starts to sound

392
00:26:48,000 --> 00:26:53,160
to me a lot more like platform than, you know, tool like in Excel or some other kind of

393
00:26:53,160 --> 00:26:58,400
desktop thing that's just a lie me to like crank through a bunch of text or images and

394
00:26:58,400 --> 00:26:59,640
put labels next to stuff.

395
00:26:59,640 --> 00:27:00,640
Yeah.

396
00:27:00,640 --> 00:27:03,720
I mean, I think that one of the big differences as well is that like, okay, we build developer

397
00:27:03,720 --> 00:27:06,960
tools and all our tools are very privacy, day privacy focused.

398
00:27:06,960 --> 00:27:10,040
Like, you know, space you in full that you run it on your machine.

399
00:27:10,040 --> 00:27:14,160
Um, it's not just like some software as a service API and also it's, you know, it's

400
00:27:14,160 --> 00:27:19,400
just like an open source, um, and the same with, uh, Prodigy is, it's not like, you

401
00:27:19,400 --> 00:27:23,480
know, an open, free open source product, but it's a product and it's a library as well

402
00:27:23,480 --> 00:27:26,840
and you can download it, you install it on your own machine.

403
00:27:26,840 --> 00:27:31,080
It works completely offline and it just like runs on your hardware.

404
00:27:31,080 --> 00:27:34,640
And so in that sense, you know, it feels a bit more, you know, like, I was often compared

405
00:27:34,640 --> 00:27:39,280
to like, you know, this, remember Adobe Creative Suite before they went all cloud, you

406
00:27:39,280 --> 00:27:42,440
know, you could actually, you could buy Photoshop and then you would download Photoshop and

407
00:27:42,440 --> 00:27:43,440
then you would have it.

408
00:27:43,440 --> 00:27:44,440
Right.

409
00:27:44,440 --> 00:27:47,600
And then they wouldn't take it away from you and you could use it.

410
00:27:47,600 --> 00:27:52,040
And then if in two years, you pick up your design project, it's all still there because

411
00:27:52,040 --> 00:27:56,400
you still have Photoshop and that's also, that's kind of, that's, that's also how we see

412
00:27:56,400 --> 00:28:00,560
these things and that's also how Prodigy functions, at least, uh, you know, the developer tool

413
00:28:00,560 --> 00:28:01,560
version.

414
00:28:01,560 --> 00:28:02,560
Got it.

415
00:28:02,560 --> 00:28:03,560
And, yeah.

416
00:28:03,560 --> 00:28:07,600
And also because, you know, people, yeah, another thing is actually, so I'll, um, we

417
00:28:07,600 --> 00:28:09,720
call this let them write code.

418
00:28:09,720 --> 00:28:16,480
It's basically developers can program and they like to program and often instead of coming

419
00:28:16,480 --> 00:28:23,080
up with like very complex arbitrary configuration languages and APIs to do stuff, often the best

420
00:28:23,080 --> 00:28:27,040
way to configure a program or configure something that you want to do is to write a few lines

421
00:28:27,040 --> 00:28:28,040
of code.

422
00:28:28,040 --> 00:28:31,680
So, um, Prodigy can be configured fully in a Python script.

423
00:28:31,680 --> 00:28:36,120
So if you, you want to let load some data from some arbitrary database that you have and

424
00:28:36,120 --> 00:28:40,200
then like filter it that way, we're like, cool, can you write that in Python?

425
00:28:40,200 --> 00:28:41,200
Yes.

426
00:28:41,200 --> 00:28:42,200
Cool.

427
00:28:42,200 --> 00:28:43,200
You can use it.

428
00:28:43,200 --> 00:28:47,200
So, that's, that's another thing where I think the developer tool, um, angle comes in

429
00:28:47,200 --> 00:28:49,960
and also it's something that people actually really, really like about this.

430
00:28:49,960 --> 00:28:54,520
Developers generally like tools that don't lock them in and tools that they can interact

431
00:28:54,520 --> 00:28:58,160
with via a programming language naturally.

432
00:28:58,160 --> 00:29:04,640
Can you elaborate on that last, uh, example and maybe, or maybe provide an example of,

433
00:29:04,640 --> 00:29:10,000
you know, is this the user experience of, of Prodigy and, you know, for a given use case

434
00:29:10,000 --> 00:29:14,200
and what are, what's the code that you might need to write and how you might integrate

435
00:29:14,200 --> 00:29:15,200
a model in a loop?

436
00:29:15,200 --> 00:29:16,640
I had all the pieces fit together.

437
00:29:16,640 --> 00:29:17,640
Yeah.

438
00:29:17,640 --> 00:29:21,120
So, we have, um, we do have a few like built-in workflows, so it's like, you know, you can

439
00:29:21,120 --> 00:29:25,040
use it and maybe you never, you know, you don't often have to really write your own code

440
00:29:25,040 --> 00:29:30,480
from scratch, but the idea is at the center of it are recipes, we call it which are Python

441
00:29:30,480 --> 00:29:31,480
functions.

442
00:29:31,480 --> 00:29:35,360
So there are Python functions that we turn into, um, a command.

443
00:29:35,360 --> 00:29:40,400
So one of them could be, okay, let's say you have some raw text you want to load in and

444
00:29:40,400 --> 00:29:45,280
you have a pre-trend model that you've downloaded from Spacey that can predict, uh, person names.

445
00:29:45,280 --> 00:29:48,440
But because your text is like obviously quite specific and maybe you're working in like

446
00:29:48,440 --> 00:29:53,160
finance or something and it has like person names or organization names that are quite

447
00:29:53,160 --> 00:29:55,640
different from like some generic pre-trend model.

448
00:29:55,640 --> 00:30:00,320
So you're like, okay, you want to see, hmm, can I improve that pre-trend model on my data?

449
00:30:00,320 --> 00:30:02,080
So it performs a bit better.

450
00:30:02,080 --> 00:30:07,160
So you can run one of these command line scripts, you, um, load pass in the path to your data

451
00:30:07,160 --> 00:30:12,240
file, you pass in the pre-trend model you want to use, you pass in some labels and then

452
00:30:12,240 --> 00:30:17,040
you start that up and then you get the annotation interface and it will highlight a prediction

453
00:30:17,040 --> 00:30:22,080
from the model and you can say, yep, that's correct or you can say no, that's wrong.

454
00:30:22,080 --> 00:30:26,800
And what under the hood, what we do there is we load up the model and we'll get all possible

455
00:30:26,800 --> 00:30:33,120
predictions, um, for your, for each example and then, um, all of these, uh, possible predictions

456
00:30:33,120 --> 00:30:37,600
will come with a score and then we've, um, by default, we'll focus on the scores that

457
00:30:37,600 --> 00:30:39,320
are closest to 0.5.

458
00:30:39,320 --> 00:30:45,040
So the ones where, um, the model is most uncertain, um, basically so that's, that's also what's

459
00:30:45,040 --> 00:30:48,680
referred to us, uh, uncertainty sampling in active learning.

460
00:30:48,680 --> 00:30:53,480
So the idea is if we focus on the ones where like, um, the model isn't sure, that's also

461
00:30:53,480 --> 00:30:55,880
where you decision will have the highest impact.

462
00:30:55,880 --> 00:30:59,720
If you're only labeling things where the model is like super confident, that is correct.

463
00:30:59,720 --> 00:31:04,600
The labels and the annotations you provide have like, um, you know, the gradient from

464
00:31:04,600 --> 00:31:11,000
that is just less significant than if you focus on the ones, um, where the model, um, yeah,

465
00:31:11,000 --> 00:31:15,440
isn't sure at all whether it's like A or B or nothing or, um, and so yeah.

466
00:31:15,440 --> 00:31:18,640
So that's, that's one possible workflow that you could use and then, you know, that's

467
00:31:18,640 --> 00:31:21,800
actually super fast, you know, you're just clicking yes or no, you're focusing on one

468
00:31:21,800 --> 00:31:28,000
thing at a time can easily collect a few hundred annotations in like, uh, 10, 15 minutes.

469
00:31:28,000 --> 00:31:33,400
And then you can run a little training, uh, command, update your model and just see, um,

470
00:31:33,400 --> 00:31:34,440
what the results look like.

471
00:31:34,440 --> 00:31:37,360
They're obviously not going to be like the most, you know, they're not going to be the definitive

472
00:31:37,360 --> 00:31:41,880
results that you can report at the end, but they give you some idea whether what you had

473
00:31:41,880 --> 00:31:46,640
in mind, there is good or not, but you know, if you see that like the model is not learning

474
00:31:46,640 --> 00:31:51,080
anything, then you have at least some idea that like maybe, um, my idea wasn't that great

475
00:31:51,080 --> 00:31:53,840
or maybe it's just more difficult than I thought it would be.

476
00:31:53,840 --> 00:31:56,040
Or if you're like, Oh, accuracy is going up.

477
00:31:56,040 --> 00:31:57,040
That looks promising.

478
00:31:57,040 --> 00:31:58,840
I should spend a bit more time on that.

479
00:31:58,840 --> 00:32:06,080
One of the things I hear from folks is about the need to kind of drive repeatability

480
00:32:06,080 --> 00:32:15,480
into the process of collecting and labeling data and producing models does the fact that

481
00:32:15,480 --> 00:32:21,440
prodigies a standalone tool, get in the way of doing that or are there ways to kind of fit

482
00:32:21,440 --> 00:32:26,280
it into a broader pipeline or workload that allow you to establish, uh, some degree of

483
00:32:26,280 --> 00:32:27,840
repeatability or consistency?

484
00:32:27,840 --> 00:32:28,840
Yeah.

485
00:32:28,840 --> 00:32:31,880
No, I think, um, in the end, you know, if you, for example, if you're writing your own

486
00:32:31,880 --> 00:32:35,800
functions, you can actually have, you know, the script that you can, you know, you can

487
00:32:35,800 --> 00:32:39,400
commit your script to your GitHub repository and you have that and everyone can always,

488
00:32:39,400 --> 00:32:44,640
you know, reproduce the logic you use to, for example, select your examples, um, and

489
00:32:44,640 --> 00:32:49,640
also, I mean, another thing, um, that we think is quite important is that a lot of problems

490
00:32:49,640 --> 00:32:55,840
people have down the line often come down to, um, problems with, uh, you know, the label

491
00:32:55,840 --> 00:32:58,840
scheme and how the task is defined in the first place.

492
00:32:58,840 --> 00:33:03,360
Um, so, uh, you know, often you're like, Oh, I want a label like, you know, I want my

493
00:33:03,360 --> 00:33:04,360
model to predict this.

494
00:33:04,360 --> 00:33:09,480
So my system needs to do X and often people approach this from the very end to end viewpoint

495
00:33:09,480 --> 00:33:14,040
and often that's not necessarily with the one that like, uh, works best on any label scheme,

496
00:33:14,040 --> 00:33:17,520
any, anything, you know, basically defining what you want your model to predict often

497
00:33:17,520 --> 00:33:19,120
needs lots of iterations.

498
00:33:19,120 --> 00:33:23,200
And once you, you know, once you get that right, you're often, um, that's where it really

499
00:33:23,200 --> 00:33:24,200
starts working.

500
00:33:24,200 --> 00:33:27,520
Is there a specific example of that, uh, that comes to mind?

501
00:33:27,520 --> 00:33:31,960
Um, so for example, I mean, one, um, one thing we see a lot is that like people, people

502
00:33:31,960 --> 00:33:36,480
often start, you know, a machine or a data science project often starts with like, um,

503
00:33:36,480 --> 00:33:40,720
you know, so a defined set of categories that you want to, uh, for example, uh, categorize

504
00:33:40,720 --> 00:33:45,760
your text into so you might have like something like, you know, um, different type, different

505
00:33:45,760 --> 00:33:50,560
types of clothing, for example, and you want to, you know, extract, uh, that from like,

506
00:33:50,560 --> 00:33:52,120
your customer emails.

507
00:33:52,120 --> 00:33:55,400
And so you have like, you know, you start, the data scientist starts off with like a very

508
00:33:55,400 --> 00:34:01,000
broad catalog of like every type of clothing we offer and every type of clothing that

509
00:34:01,000 --> 00:34:02,480
like the system needs to categorize.

510
00:34:02,480 --> 00:34:07,520
And then often, you know, one approach could be, okay, well, we need to take a few million

511
00:34:07,520 --> 00:34:13,600
examples or, you know, emails and have someone label them and select out of our, um, hundreds

512
00:34:13,600 --> 00:34:17,280
of clothing types, what clothing types are mentioned.

513
00:34:17,280 --> 00:34:21,400
And I mean, it sounds like a very straightforward approach, but often probably, you know, at

514
00:34:21,400 --> 00:34:24,200
some point down the line, you'll notice that like your machine learning model is actually

515
00:34:24,200 --> 00:34:30,800
really, really bad at distinguishing adult shoes from kids shoes, uh, for example, in,

516
00:34:30,800 --> 00:34:36,760
you know, like brand names or, um, you know, summer code and winter codes, you know, that's

517
00:34:36,760 --> 00:34:37,760
something.

518
00:34:37,760 --> 00:34:41,200
Maybe, maybe you can, you know, but like that's probably something that's very quite,

519
00:34:41,200 --> 00:34:45,680
that could be quite difficult to predict just on the basis of like the raw text and the

520
00:34:45,680 --> 00:34:47,560
surrounding words.

521
00:34:47,560 --> 00:34:51,840
So, you know, one, one approach that you could then after, you know, you try this out,

522
00:34:51,840 --> 00:34:53,720
you realize our model's not learning anything.

523
00:34:53,720 --> 00:34:56,200
And then, you're like, okay, how could I improve that?

524
00:34:56,200 --> 00:34:59,680
One approach could be, you start with a bunch more broader definition.

525
00:34:59,680 --> 00:35:04,840
You start, okay, first, I'll let my model label whether something is clothing, you know,

526
00:35:04,840 --> 00:35:09,400
you can start, okay, start collecting some data for that, um, and then train it.

527
00:35:09,400 --> 00:35:11,200
Okay, actually looks pretty good.

528
00:35:11,200 --> 00:35:12,200
Um, next step.

529
00:35:12,200 --> 00:35:18,320
Okay, maybe we can add another model component that then given a clothing, um, item or clothing

530
00:35:18,320 --> 00:35:23,280
brand can then, um, you know, assign it to one of our, um, you know, entries in a knowledge

531
00:35:23,280 --> 00:35:26,680
base or to a more fine grained, uh, category and so on.

532
00:35:26,680 --> 00:35:30,320
Like, that's just one, one example that just came, that came to mind based.

533
00:35:30,320 --> 00:35:32,920
And in the end, you know, that, that, that stuff really matters.

534
00:35:32,920 --> 00:35:37,640
Like, you know, you end up at the same results, but, um, the process, how you work there

535
00:35:37,640 --> 00:35:38,960
is very, very different.

536
00:35:38,960 --> 00:35:44,000
And it takes, it can easily take a few iterations, uh, to get to the point, uh, where you,

537
00:35:44,000 --> 00:35:48,960
you kind of, you have a good idea for what, what can my model learn and, um, what's actually

538
00:35:48,960 --> 00:35:53,800
feasible and what machine learning tasks do I have to break this larger, they abstract

539
00:35:53,800 --> 00:35:55,320
business goal into?

540
00:35:55,320 --> 00:36:02,880
I'm curious, what are some of the thing, you know, the, the NLP space as, with all of, uh,

541
00:36:02,880 --> 00:36:06,920
machine learning is, you know, changes rapidly, lots of exciting stuff happening.

542
00:36:06,920 --> 00:36:11,600
We talked about, uh, some of that in terms of these new language models.

543
00:36:11,600 --> 00:36:16,080
I'm curious, what are you most excited about in this space?

544
00:36:16,080 --> 00:36:20,960
Um, so definitely, I mean, the transfer learning stuff was definitely like a big, um, breakthrough

545
00:36:20,960 --> 00:36:23,760
because we've always, for quite a long time, we're like, okay, this should, this should

546
00:36:23,760 --> 00:36:27,600
be possible and, um, it was kind of, you know, I think for, for many people in the space,

547
00:36:27,600 --> 00:36:30,840
it was kind of clear, like, okay, at some point, hopefully someone's going to show here's

548
00:36:30,840 --> 00:36:32,640
how we should do it.

549
00:36:32,640 --> 00:36:37,600
And, um, especially the fact that like, um, you know, we can potentially pre-trained, um,

550
00:36:37,600 --> 00:36:42,120
embeddings that would, um, allow us to get much, much better results, much more quickly

551
00:36:42,120 --> 00:36:45,480
with, um, significant fewer examples.

552
00:36:45,480 --> 00:36:49,480
And that doesn't mean that like, um, you know, labeling examples becomes less relevant,

553
00:36:49,480 --> 00:36:53,440
actually, um, you know, I think it, it means it, you know, you can try out more and

554
00:36:53,440 --> 00:36:57,960
it becomes a lot more relevant because, um, you know, cool, if you only need like 200 labeled

555
00:36:57,960 --> 00:37:02,920
examples to really get a, um, very definitive idea of whether, um, what you're trying to train

556
00:37:02,920 --> 00:37:06,600
works or not, that means you can like, you know, you can train much more, more quickly

557
00:37:06,600 --> 00:37:11,520
and you can train so many more models, so much faster, um, you can try out so many more

558
00:37:11,520 --> 00:37:12,520
ideas.

559
00:37:12,520 --> 00:37:15,440
Um, and I think, I think that's like, that's super exciting.

560
00:37:15,440 --> 00:37:19,000
And, um, yeah, it's really cool to see this already working quite well.

561
00:37:19,000 --> 00:37:24,080
Is there other things happening that are, that you're particularly paying attention to?

562
00:37:24,080 --> 00:37:29,920
Mm, let me think, um, so I mean, one, one thing we, like, I can, I can talk about one

563
00:37:29,920 --> 00:37:33,920
thing we're working on at the moment is entity linking, which I also think is really

564
00:37:33,920 --> 00:37:34,920
cool.

565
00:37:34,920 --> 00:37:38,720
So basically, you know, the concept of you have like a person name and you want to link

566
00:37:38,720 --> 00:37:40,560
that back to a knowledge base.

567
00:37:40,560 --> 00:37:44,400
And it sounds, um, you know, the kind of concept sounds, sounds quite simple, but it's

568
00:37:44,400 --> 00:37:46,960
actually, you know, there's a lot you have to consider and you actually, you know, you

569
00:37:46,960 --> 00:37:52,440
want to, you have a mention of, um, Apple or like, actually, I'm trying to think of it

570
00:37:52,440 --> 00:37:56,120
better, like more, um, you know, ambiguous example, but like there are a lot of these,

571
00:37:56,120 --> 00:37:59,960
like names and their different options, it depends on the context and, you know, you

572
00:37:59,960 --> 00:38:02,160
want to assign those back to large knowledge bases.

573
00:38:02,160 --> 00:38:07,360
Yeah, that's a feature, um, that's, yeah, maybe not as like, oh, shiny, um, new cutting

574
00:38:07,360 --> 00:38:11,320
edge stuff, but it's actually another one that like people really need, people really

575
00:38:11,320 --> 00:38:17,080
want, and that's going to make a huge difference for people using NLP, uh, for variety of like

576
00:38:17,080 --> 00:38:19,080
business use cases and industry use cases.

577
00:38:19,080 --> 00:38:24,800
A feature like that is, are you typically or not typically, but in this case, are you

578
00:38:24,800 --> 00:38:31,000
attacking that using traditional rules based or heuristic types of approaches or machine

579
00:38:31,000 --> 00:38:36,000
learning or neural nets, like we're in a spectrum, uh, you know, what, which of the tools

580
00:38:36,000 --> 00:38:39,360
do you use to, you know, build out a feature like that?

581
00:38:39,360 --> 00:38:43,320
Um, I mean, well, it depends on the feature, like, um, you know, in this case, it's, it

582
00:38:43,320 --> 00:38:48,400
is a combination of machine learning and, um, kind of, uh, kind of ties in, uh, with

583
00:38:48,400 --> 00:38:52,200
the rule based approaches, it also ties in with like the neural network models we already

584
00:38:52,200 --> 00:38:56,640
have, uh, which are the models that actually predict entities in the first place.

585
00:38:56,640 --> 00:39:03,080
Um, so, I mean, it really, like, it always depends on the, um, on the use case, but like,

586
00:39:03,080 --> 00:39:08,120
what, you know, for us, what matters is, well, what works best and what's, what's fast,

587
00:39:08,120 --> 00:39:14,520
what's efficient and what actually, um, works best, what generalizes best and what's, um,

588
00:39:14,520 --> 00:39:17,960
customizable because, you know, ultimately, it's nice if you can provide people with

589
00:39:17,960 --> 00:39:22,760
a pre-train model that happens to work quite nicely on, you know, some academic benchmark

590
00:39:22,760 --> 00:39:27,360
task, but what people really want to do is they want to plug in their own data and they

591
00:39:27,360 --> 00:39:30,880
want to plug in their own stuff and they want to plug in their own, like ideas and, uh,

592
00:39:30,880 --> 00:39:31,880
goals.

593
00:39:31,880 --> 00:39:35,080
And so that, that's also kind of how we decide how to approach a thing.

594
00:39:35,080 --> 00:39:38,760
Like, you know, we're not, we're in, you know, we're not in position where we have to,

595
00:39:38,760 --> 00:39:41,520
you know, come up with like, what's, what's a good paper to write?

596
00:39:41,520 --> 00:39:45,120
Like, that's, you know, that's another way, um, and I'm not even, you know, dismissing

597
00:39:45,120 --> 00:39:46,120
that.

598
00:39:46,120 --> 00:39:50,160
That's a very like, um, you know, genuine, like, um, you know, valid motivation that

599
00:39:50,160 --> 00:39:54,320
people in research would have, but what's, you know, good papers, not necessarily what

600
00:39:54,320 --> 00:40:00,360
like, you know, people actually will find like the most useful as a, in a practical application.

601
00:40:00,360 --> 00:40:06,880
If you were starting over with spacey or they're things that you do very differently.

602
00:40:06,880 --> 00:40:09,280
Oh, that's, that's a really good question, actually.

603
00:40:09,280 --> 00:40:11,880
I'm not, I'm not sure if I thought about this much.

604
00:40:11,880 --> 00:40:17,400
I mean, they're just, they obviously some API decisions that like, um, uh, I would have,

605
00:40:17,400 --> 00:40:22,040
I would have done differently or we, we should have, we would have probably, um, done

606
00:40:22,040 --> 00:40:23,040
differently.

607
00:40:23,040 --> 00:40:25,960
Just like, I mean, it's mostly just like small, small stuff where, you know, you design

608
00:40:25,960 --> 00:40:29,080
something one way and then you realize, ah, that's actually super, that's kind of confusing

609
00:40:29,080 --> 00:40:34,040
or like, kind of taking on this life of its own and sensor on, doesn't send a right message,

610
00:40:34,040 --> 00:40:36,520
um, math, we should have done this differently.

611
00:40:36,520 --> 00:40:40,120
Otherwise, you know, it, of course, it depends on like, it always depends on, okay, what

612
00:40:40,120 --> 00:40:45,960
you have like available and, you know, what was like possible at the time.

613
00:40:45,960 --> 00:40:49,560
But actually, I think I'm quite happy with like, you know, the progression, like sure,

614
00:40:49,560 --> 00:40:53,360
there's sometimes I wish like, you know, we would have had like more time, uh, that we

615
00:40:53,360 --> 00:40:57,920
could have like, you know, spend on the project, uh, to work on that because, okay, you

616
00:40:57,920 --> 00:41:01,000
know, it was very important for us to stay independent and be independent.

617
00:41:01,000 --> 00:41:05,680
And so, um, you know, while we were like initially, like bootstrapping the company, um,

618
00:41:05,680 --> 00:41:11,480
yeah, we had a bit less time, um, but yeah, like in hindsight, like, I'm very happy with

619
00:41:11,480 --> 00:41:18,720
how things turned out and, um, yeah, um, on that theme of independence and you previously

620
00:41:18,720 --> 00:41:25,520
mentioned that you intend for, uh, explosion to remain a small company.

621
00:41:25,520 --> 00:41:34,160
We talk a little bit about that, uh, and your motivation or philosophy there and, um, you

622
00:41:34,160 --> 00:41:39,640
know, maybe, you know, any thoughts for folks that are also interested in kind of contributing

623
00:41:39,640 --> 00:41:45,680
in the space, um, you know, but aren't necessarily excited about doing in the context of a large

624
00:41:45,680 --> 00:41:46,680
company.

625
00:41:46,680 --> 00:41:47,680
Yeah.

626
00:41:47,680 --> 00:41:50,960
I mean, for us, like we've, um, basically, I mean, you already, you already see this in

627
00:41:50,960 --> 00:41:54,520
all kinds of other software projects that like most, a little software is actually written

628
00:41:54,520 --> 00:41:58,440
by a very, very small number of people, like even if you look at very large, like libraries,

629
00:41:58,440 --> 00:42:02,320
it's, um, you know, it's not like, you know, thousands of people kind of wrote on, you

630
00:42:02,320 --> 00:42:04,160
know, worked on the same piece of code.

631
00:42:04,160 --> 00:42:08,800
Um, it's like often development teams are very small and like for a reason because, you

632
00:42:08,800 --> 00:42:11,880
know, it's like, you know, writing a novel with like 200 people.

633
00:42:11,880 --> 00:42:15,280
That's like, you know, that's a fun art project, but that's not, that's not necessarily

634
00:42:15,280 --> 00:42:18,600
like, you know, that's not going to be the best novel, you know, right?

635
00:42:18,600 --> 00:42:23,720
So, um, you know, software teams, I often by definition are quite small.

636
00:42:23,720 --> 00:42:27,640
And, um, another thing is that actually by being quite small, you can really take a lot

637
00:42:27,640 --> 00:42:33,320
of advantage of, um, you know, very diverse skill sets that, that large companies can't

638
00:42:33,320 --> 00:42:34,320
necessarily.

639
00:42:34,320 --> 00:42:37,800
So, you know, large companies often hire in a very particular way, um, because you have

640
00:42:37,800 --> 00:42:40,480
to hire in a way that makes your team more interchangeable.

641
00:42:40,480 --> 00:42:44,480
Like you, you know, you need, you need a lot of people that are quite similar because,

642
00:42:44,480 --> 00:42:48,920
you know, if you're scaling this up, um, that's kind of the most efficient, but if you,

643
00:42:48,920 --> 00:42:54,080
a small team, you can actually, um, you know, hire a lot of people with way, um, specific

644
00:42:54,080 --> 00:42:57,880
skills that work for, um, you know, specific tasks, then you can have people with kind of

645
00:42:57,880 --> 00:43:03,200
overlapping skills, people with a broad foundation in one, um, technology, but who also have

646
00:43:03,200 --> 00:43:07,960
done like other things, like it's typically, it's often referred to as t-shaped skills

647
00:43:07,960 --> 00:43:09,400
because, you know, kind of like a t-shirt.

648
00:43:09,400 --> 00:43:13,160
So, you have like, I've always found these a super weird metaphor because like, it's

649
00:43:13,160 --> 00:43:17,240
a t-shirt, but like, you know, you're brought kind of a broad foundation and then like

650
00:43:17,240 --> 00:43:22,600
these like arms, but, um, I've, I've started calling it more like, you know, I think of it

651
00:43:22,600 --> 00:43:26,640
more as like tree-shaped skills, you know, you have like the stem and then you have all

652
00:43:26,640 --> 00:43:30,680
these like branches and you can have like, um, you know, you can have small branches, you

653
00:43:30,680 --> 00:43:34,800
can have big branches, you can have like different branches and different directions, branches

654
00:43:34,800 --> 00:43:39,640
can overlap overlap with like some other tree, you can grow new branches, which actually

655
00:43:39,640 --> 00:43:43,080
this is another reason like, yeah, I hate the t-shirt metaphor because it's like a t-shirt

656
00:43:43,080 --> 00:43:48,520
that can only like get worse once it's like there for a tree, you know, a tree can grow,

657
00:43:48,520 --> 00:43:52,000
this is like life in it, but basically that's sort of, that's the idea we've had like,

658
00:43:52,000 --> 00:43:58,160
um, for our team, we can actually, you know, really have like, um, you know, complimentary

659
00:43:58,160 --> 00:44:03,840
skills, um, in a team, um, and you know, really take advantage of that and it's not like,

660
00:44:03,840 --> 00:44:06,720
you know, it's not like large companies are not doing that because they're like stupid

661
00:44:06,720 --> 00:44:11,440
and don't see this, they like, aren't because of, you know, they operate slightly differently.

662
00:44:11,440 --> 00:44:17,400
So, um, yeah, like we don't, we are small, but we're still, you know, we can still do things

663
00:44:17,400 --> 00:44:20,920
and it's still, I, yeah, there's one anecdote that like I sometimes tell in this kind of

664
00:44:20,920 --> 00:44:26,920
context, which is, um, once we were asked, um, whether our company would pass the bus test

665
00:44:26,920 --> 00:44:31,640
because for someone who wanted to buy our software, this was like, um, this was important

666
00:44:31,640 --> 00:44:35,120
and yeah, to, yeah, if someone, yeah, for anyone who doesn't know what the bus test is,

667
00:44:35,120 --> 00:44:39,000
it's like, it's a varying number of people, but it's basically if four people were run

668
00:44:39,000 --> 00:44:42,840
over by a bus tomorrow, would your company still exist? And at that time, we were like

669
00:44:42,840 --> 00:44:48,480
two people were like, no, we'd be minus two. But it's also, it's a very weird concept.

670
00:44:48,480 --> 00:44:53,800
The person ended up buying prodigy anyways, but like, um, it's, it's an interesting framework

671
00:44:53,800 --> 00:44:57,280
that some people use and I don't think makes much sense because essentially you're always

672
00:44:57,280 --> 00:45:01,320
asking like, well, how interchangeable are like your people and, um, you know, who could

673
00:45:01,320 --> 00:45:05,640
you afford to like spare in a bus accident? Mm-hmm. And yeah, yeah, so we, I've always

674
00:45:05,640 --> 00:45:09,920
find this kind of weird and like we don't pass, we probably do not pass the bus test. Um,

675
00:45:09,920 --> 00:45:14,680
we kind of pass it now, but like, we'd be in a pretty bad state. And interesting anecdote

676
00:45:14,680 --> 00:45:21,680
along those lines, I was just this morning reading, uh, an article about, uh, long story

677
00:45:21,680 --> 00:45:28,600
this lawsuit that, uh, hurts is apparently suing Accenture for botching this, uh, digital

678
00:45:28,600 --> 00:45:35,360
transformation project. It was going around on Twitter. And if you read the, as a $35 million

679
00:45:35,360 --> 00:45:41,320
project to build some websites, uh, that kind of integrates into, uh, their reservation

680
00:45:41,320 --> 00:45:48,360
systems, kind of, you know, update their website. Uh, and you read the lawsuit and all of

681
00:45:48,360 --> 00:45:52,880
the things that, you know, could have been done so much better on, on both sides, but,

682
00:45:52,880 --> 00:45:57,280
you know, in particular, there's this one point where they talked about how kind of Accenture

683
00:45:57,280 --> 00:46:03,040
had full ownership of this project. And there were two people that knew the project and

684
00:46:03,040 --> 00:46:06,840
they pulled them off and put them onto something else. And that was one of the reasons why this

685
00:46:06,840 --> 00:46:11,360
thing got delayed by two years and never got finished. Yeah. And then, I mean, they built

686
00:46:11,360 --> 00:46:16,000
a website. There wasn't responsive and like everything was, we were so insecure. It

687
00:46:16,000 --> 00:46:19,920
was like unusable when like, wow, that's like, that's almost, that's a skill. Like, you

688
00:46:19,920 --> 00:46:23,960
know, it's, you can build so much stuff nowadays that like works okay, even if it's kind

689
00:46:23,960 --> 00:46:29,840
of crap. So there's so many lessons there, but the thing that, that connected to what

690
00:46:29,840 --> 00:46:34,160
you were speaking was, you know, even Accenture, you know, in this case, couldn't pass the

691
00:46:34,160 --> 00:46:40,000
bus tests. Yeah. Hold these two people off. And, you know, that was a significant contributor

692
00:46:40,000 --> 00:46:46,880
to the failure of this project. So, yeah. So I think it's a very bizarre metric. And yeah,

693
00:46:46,880 --> 00:46:49,920
so that was one of the things we saw this early on. We're like, well, we could, you know,

694
00:46:49,920 --> 00:46:53,200
we already do it. We were already doing great stuff when we're two people. Okay. If we

695
00:46:53,200 --> 00:46:56,640
have a few more people and they're the right people, we can do even more stuff. And that's

696
00:46:56,640 --> 00:47:01,040
like fine, we also get to, you know, focus a lot more on the core work because we have fewer

697
00:47:01,040 --> 00:47:05,440
distractions that, you know, you'd normally have if you, you know, not like a few, for example,

698
00:47:05,440 --> 00:47:09,120
if you're running at a loss, which is also something we said, okay, we don't want to be doing

699
00:47:09,120 --> 00:47:13,920
we actually, because I think, you know, for there are many legitimate reasons why your company

700
00:47:13,920 --> 00:47:18,640
would want to start and run at a loss or at a significant loss fairly on and why you would

701
00:47:18,640 --> 00:47:23,040
have to, you know, where you need capital and why you would have to make the decision to sell

702
00:47:23,040 --> 00:47:27,920
equity in order to function. But we're always in a, you know, very good position that we didn't

703
00:47:27,920 --> 00:47:33,680
have to do that. And so also we thought, okay, for what we're doing, there's absolutely no logical

704
00:47:33,680 --> 00:47:38,880
reason we would have to be running at a loss. We can actually run at a profit because we can have

705
00:47:38,880 --> 00:47:44,240
a product and people can buy our product. And then, yeah, we can sell more products and we can

706
00:47:44,240 --> 00:47:48,560
make more products and do more things. And then people can, you know, give us money and then we

707
00:47:48,560 --> 00:47:53,200
can spend less money than that. And then we'll have some money. It's kind of, it's a very crazy

708
00:47:53,200 --> 00:47:58,800
concept, but like, you know, it works. Virtua cycle. Yeah. Yeah. So, so that was, that was another

709
00:47:59,600 --> 00:48:06,080
thing that really helped us, you know, stay focused and do our things and also being able to really,

710
00:48:06,080 --> 00:48:11,040
you know, it's one thing you can validate your ideas. Like, by, I don't know, talking to people,

711
00:48:11,040 --> 00:48:16,480
doing like surveys and doing like all kinds of things, but like in the end, making a profit and

712
00:48:16,480 --> 00:48:20,960
making money is like a very, very good way to validate what you're doing. And it's also a very

713
00:48:20,960 --> 00:48:24,960
honest way of validate. Like, you know, you, money doesn't really lie. Like, if nobody wants to buy

714
00:48:24,960 --> 00:48:28,560
your product, then well, nobody wants to buy your product. And then, you know, that's, that's a

715
00:48:28,560 --> 00:48:34,560
pre-clear sign. And on the other hand, okay, if you, if you see cool, what I'm doing works, people

716
00:48:34,560 --> 00:48:39,040
like it so far, people are interested in buying that. That's a very good, you know, that's a very

717
00:48:39,040 --> 00:48:45,600
good way to validate your ideas. And yeah, yeah, so it's like, you know, we see this, that's,

718
00:48:45,600 --> 00:48:50,240
that's a much better KPI than a lot of other things. Well, you know, thank you so much for

719
00:48:50,240 --> 00:48:56,960
taking the time to share what you're up to is great getting to know you and explosion and

720
00:48:57,520 --> 00:49:02,720
spacey and prodigy a little bit better. I really enjoyed our chat. Yeah, thanks.

721
00:49:06,560 --> 00:49:11,280
All right, everyone. That's our show for today. If you like what you've heard here,

722
00:49:11,280 --> 00:49:16,400
please do us a huge favor and tell your friends about the show. And if you haven't already

723
00:49:16,400 --> 00:49:21,280
hit that subscribe button yourself, make sure you do so you don't miss any of the great episodes

724
00:49:21,280 --> 00:49:42,320
we've got in store for you. As always, thanks so much for listening and catch you next time.

