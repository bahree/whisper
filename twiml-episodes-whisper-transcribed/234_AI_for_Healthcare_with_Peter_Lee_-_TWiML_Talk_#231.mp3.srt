1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:33,460
I'm your host, Sam Charrington, today we're excited to continue the AI for the benefit

4
00:00:33,460 --> 00:00:37,680
of society series that we've partnered with Microsoft to bring you.

5
00:00:37,680 --> 00:00:41,880
In this episode, we're joined by Peter Lee, corporate vice president and Microsoft

6
00:00:41,880 --> 00:00:45,640
research responsible for the company's healthcare initiatives.

7
00:00:45,640 --> 00:00:49,960
Peter and I met a few months ago at the Microsoft Ignite conference where he gave me some really

8
00:00:49,960 --> 00:00:53,280
interesting takes on AI development in China.

9
00:00:53,280 --> 00:00:56,960
We referenced those in the conversation and you can find more on that topic in the show

10
00:00:56,960 --> 00:00:57,960
notes.

11
00:00:57,960 --> 00:01:03,400
This conversation those centers on three impact areas that Peter sees for AI and healthcare,

12
00:01:03,400 --> 00:01:09,240
namely diagnostics and therapeutics, tools and the future of precision medicine.

13
00:01:09,240 --> 00:01:14,000
We dig into some examples in each area and Peter details the realities of applying machine

14
00:01:14,000 --> 00:01:18,000
learning and some of the impediments to rapid scale.

15
00:01:18,000 --> 00:01:22,160
Before diving in, I'd like to thank Microsoft for their support of the show and their sponsorship

16
00:01:22,160 --> 00:01:24,320
of this series.

17
00:01:24,320 --> 00:01:28,880
Microsoft is committed to ensuring the responsible development and use of AI and is empowering

18
00:01:28,880 --> 00:01:33,880
people around the world with this intelligent technology to help solve previously intractable

19
00:01:33,880 --> 00:01:40,600
societal challenges, spanning sustainability, accessibility and humanitarian action.

20
00:01:40,600 --> 00:01:43,880
Learn more about their plan at Microsoft.ai.

21
00:01:43,880 --> 00:01:51,120
All right, everyone, I am on the line with Peter Lee.

22
00:01:51,120 --> 00:01:56,320
Peter is a corporate vice president at Microsoft, responsible for the company's healthcare

23
00:01:56,320 --> 00:01:57,320
initiatives.

24
00:01:57,320 --> 00:02:00,000
Peter, it is so great to speak with you again.

25
00:02:00,000 --> 00:02:02,840
Welcome to this week in machine learning and AI.

26
00:02:02,840 --> 00:02:05,240
Sam, it's great to be here.

27
00:02:05,240 --> 00:02:11,960
So Peter, you gave a really interesting presentation to a group that I was at at Ignite about

28
00:02:11,960 --> 00:02:18,720
what some of Microsoft was working on at Microsoft Research, as well as a really interesting

29
00:02:18,720 --> 00:02:21,320
take on AI development in China.

30
00:02:21,320 --> 00:02:25,800
They kind of peak my interest and we ended up sitting down to chat about that in a little

31
00:02:25,800 --> 00:02:28,200
bit more detail.

32
00:02:28,200 --> 00:02:33,040
And while we, I did cover that from my blog and newsletter and I'll be linking to it

33
00:02:33,040 --> 00:02:36,600
in the show notes, we won't be diving into that today.

34
00:02:36,600 --> 00:02:41,920
It was a really, really interesting take that I reflect on often.

35
00:02:41,920 --> 00:02:46,800
And I think it's an interesting setup for diving into your background because you do

36
00:02:46,800 --> 00:02:54,480
have a very interesting background and interesting perspective and set up responsibilities at Microsoft.

37
00:02:54,480 --> 00:02:59,200
So on that note, can you share with our audience a little bit about your background?

38
00:02:59,200 --> 00:03:00,200
Sure, Sam.

39
00:03:00,200 --> 00:03:02,200
I'd love to do that.

40
00:03:02,200 --> 00:03:03,200
I agree.

41
00:03:03,200 --> 00:03:09,440
It is a little bit unusual, although I think the common thread throughout has been about

42
00:03:09,440 --> 00:03:12,600
research and trying to bring research into the real world.

43
00:03:12,600 --> 00:03:16,160
And so I am a computer scientist by training.

44
00:03:16,160 --> 00:03:20,000
I was a professor of computer science at Carnegie Mellon for a long time, actually, for

45
00:03:20,000 --> 00:03:22,200
24 years.

46
00:03:22,200 --> 00:03:26,040
And at the end of my time there was the head of the computer science department.

47
00:03:26,040 --> 00:03:31,640
And then I went to Washington, D.C. to serve at an agency called DARPA, which is the

48
00:03:31,640 --> 00:03:35,560
Defense Advanced Research Projects Agency.

49
00:03:35,560 --> 00:03:43,640
It's kind of the storied research agency that built the Saturn V booster technology, invented

50
00:03:43,640 --> 00:03:50,360
the ARPANET, which became the Internet, developed robotics, lots and lots of other things.

51
00:03:50,360 --> 00:03:56,160
And I learned a lot about bringing research to life there.

52
00:03:56,160 --> 00:04:03,120
And then after a couple of years there, I was recruited to Microsoft and joined Microsoft

53
00:04:03,120 --> 00:04:10,200
Research, started managing the mothership lab in Redmond in the headquarters in Redmond

54
00:04:10,200 --> 00:04:17,040
and then a little bit later all of the U.S. research labs and then ultimately all of Microsoft's

55
00:04:17,040 --> 00:04:19,320
13 labs around the world.

56
00:04:19,320 --> 00:04:24,360
And right about that time, Steve Balmer announced his retirement, Satya Nadella, took over

57
00:04:24,360 --> 00:04:34,160
as a CEO, Harry Schum, took over all of AI and research at Microsoft and became my boss.

58
00:04:34,160 --> 00:04:40,760
And they asked me to start a new type of research organization that internally is called Next,

59
00:04:40,760 --> 00:04:44,440
which stands for New Experiences and Technologies.

60
00:04:44,440 --> 00:04:50,120
And we've been sort of trying to grow and incubate new research-powered businesses ever since,

61
00:04:50,120 --> 00:04:52,400
and most recently in healthcare.

62
00:04:52,400 --> 00:05:00,280
I think when I think about AI and healthcare, there's certainly a ton of ground to cover

63
00:05:00,280 --> 00:05:01,280
there.

64
00:05:01,280 --> 00:05:06,680
But I think one of the areas that gets a lot of attention of late is all the progress

65
00:05:06,680 --> 00:05:15,920
that's being made around applying neural nets, CNNs in particular to imagery.

66
00:05:15,920 --> 00:05:22,080
I want to read from your perspective, how do you tend to think about AI applied to

67
00:05:22,080 --> 00:05:25,760
the healthcare space and where the big opportunities are?

68
00:05:25,760 --> 00:05:32,440
Yeah, when I think about AI and healthcare, I'm really optimistic about the future.

69
00:05:32,440 --> 00:05:38,520
Not that there aren't huge difficult problems and sometimes things always seem to grow slower

70
00:05:38,520 --> 00:05:39,520
than you expect.

71
00:05:39,520 --> 00:05:43,160
It's a little bit like watching grass grow.

72
00:05:43,160 --> 00:05:48,280
It does grow and things do happen, but sometimes it's hard to see it.

73
00:05:48,280 --> 00:05:55,000
But over the last 15 years, the thing that I think is underappreciated is the entire healthcare

74
00:05:55,000 --> 00:05:57,400
industry has gone digital.

75
00:05:57,400 --> 00:06:05,040
It was only 15 years ago that, for example, in the United States, less than 10% of physicians

76
00:06:05,040 --> 00:06:10,880
were recording your health history in a digital electronic health record.

77
00:06:10,880 --> 00:06:14,480
And now we're up over 95%.

78
00:06:14,480 --> 00:06:18,800
And that's just an amazing transformation over 15 years.

79
00:06:18,800 --> 00:06:24,360
And it's not like we don't still have problems, the data is siloed.

80
00:06:24,360 --> 00:06:27,000
It's not in standard formats, there's all sorts of problems.

81
00:06:27,000 --> 00:06:33,200
But the fact that it's gone digital just opens up huge, huge amounts of potential.

82
00:06:33,200 --> 00:06:38,280
And so I kind of look at the potential for AI in three areas.

83
00:06:38,280 --> 00:06:43,920
One is sort of the thing that you pointed at, which AI technologies that actually lead

84
00:06:43,920 --> 00:06:47,880
to better diagnostics and therapeutics.

85
00:06:47,880 --> 00:06:52,320
Things that actually advance medical science and medical technology.

86
00:06:52,320 --> 00:06:58,600
A second area for AI is in the area of tools.

87
00:06:58,600 --> 00:07:04,120
Tools that actually make doctors better at what they do, make them happier while they're

88
00:07:04,120 --> 00:07:11,400
doing it, and also improve the experience for you and me as patients or consumers of healthcare.

89
00:07:11,400 --> 00:07:17,440
And then the third area is in this wonderful future of precision medicine.

90
00:07:17,440 --> 00:07:24,120
That's taking new sources of information, digital information, your genome, your proteome,

91
00:07:24,120 --> 00:07:31,200
your immunome, data from your fitness wearables and so on, integrating all of that together

92
00:07:31,200 --> 00:07:34,320
to give you a complete picture of what's going on with your body.

93
00:07:34,320 --> 00:07:39,680
So those are sort of three broad areas, and they're all incredibly exciting right now.

94
00:07:39,680 --> 00:07:45,440
When you think about the first two of those categories, better diagnostics and therapeutics

95
00:07:45,440 --> 00:07:48,720
and tools, how do you distinguish them?

96
00:07:48,720 --> 00:07:55,360
It strikes me that giving doctors a better way to analyze medical imagery, for example,

97
00:07:55,360 --> 00:07:59,160
or to use that example again is a tool that they can use.

98
00:07:59,160 --> 00:08:01,960
But when you say tools, what do you specifically mean?

99
00:08:01,960 --> 00:08:03,800
Yeah, you're absolutely right.

100
00:08:03,800 --> 00:08:09,960
There's an overlap, it's not like the boundaries between these things are all that hardened.

101
00:08:09,960 --> 00:08:16,160
But if you think about one problem that doctors have today is, by some estimates in the

102
00:08:16,160 --> 00:08:22,880
United States, doctors are spending 40 to 50% of their work days entering documentation,

103
00:08:22,880 --> 00:08:29,000
entering notes that record what happened in their encounters with patients.

104
00:08:29,000 --> 00:08:31,280
And that's sometimes called an encounter note.

105
00:08:31,280 --> 00:08:37,560
That documentation is actually required now by various rules and regulations.

106
00:08:37,560 --> 00:08:41,960
It's an incredible source of burnout, and in fact, I'm guessing you've had this experience.

107
00:08:41,960 --> 00:08:46,800
Most people have you go to your doctor, I go to mine, and I like her very much.

108
00:08:46,800 --> 00:08:50,640
But while I'm being examined by her, she's not looking at me, she's actually sitting

109
00:08:50,640 --> 00:08:55,080
at a PC, typing in the encounter notes.

110
00:08:55,080 --> 00:08:59,640
And the reason she's doing that is if she doesn't do it while she's examining me, she'll

111
00:08:59,640 --> 00:09:04,100
have to do it for a couple of hours, maybe in the evening, taking time away from her

112
00:09:04,100 --> 00:09:05,960
own family.

113
00:09:05,960 --> 00:09:14,200
And that burden is credited or blamed for a rise in physician burnout.

114
00:09:14,200 --> 00:09:22,400
While AI technologies today are rapidly approaching the point where an ambient intelligence

115
00:09:22,400 --> 00:09:29,840
can just observe and listen to a doctor patient encounter and automate the vast majority of

116
00:09:29,840 --> 00:09:33,600
the burden of that required clinical note-taking.

117
00:09:33,600 --> 00:09:38,960
And so that's an example of a kind of technology that could, in a really material way, just

118
00:09:38,960 --> 00:09:44,160
improve the lives and the work they said is faction of doctors and nurses.

119
00:09:44,160 --> 00:09:47,040
And that's, I put that in a different category.

120
00:09:47,040 --> 00:09:54,600
And technologies that actually give you more precise diagnosis of what's ailing you,

121
00:09:54,600 --> 00:10:02,360
or ability to target therapies that might actually attack the very specific genetic makeup,

122
00:10:02,360 --> 00:10:05,760
let's say, of the cancer that's inhabiting your body right now.

123
00:10:05,760 --> 00:10:06,760
Got it.

124
00:10:06,760 --> 00:10:07,760
Got it.

125
00:10:07,760 --> 00:10:11,360
So maybe let's take each of these categories in turn.

126
00:10:11,360 --> 00:10:20,120
I'd love to get a perspective from you on where you see the important developments coming

127
00:10:20,120 --> 00:10:28,040
from, from a research perspective, and where you see the opportunities and where you see

128
00:10:28,040 --> 00:10:30,840
things heading in each.

129
00:10:30,840 --> 00:10:31,840
Sure.

130
00:10:31,840 --> 00:10:37,880
Well, why don't we start with your example of imaging because computer vision based

131
00:10:37,880 --> 00:10:43,600
on deep neural nets has just been progressing at this stunning rate.

132
00:10:43,600 --> 00:10:49,880
And it seems like every week you see another company, another startup, or another university

133
00:10:49,880 --> 00:10:58,040
research group showing off their latest advances in using deep neural net based computer vision

134
00:10:58,040 --> 00:11:04,560
technologies to do various kinds of medical image diagnosis or segmentation.

135
00:11:04,560 --> 00:11:09,400
And here at Microsoft, we've been working pretty hard on those as well.

136
00:11:09,400 --> 00:11:18,160
We have this wonderful program based primarily in India that's been trained on the health records

137
00:11:18,160 --> 00:11:24,280
and eye images of over 200,000 patients.

138
00:11:24,280 --> 00:11:30,440
And that idea of taking all that data, you get the signal of which of those patients

139
00:11:30,440 --> 00:11:38,200
have, let's say, suffered from, say, diabetic retinopathy or a progression of refractive

140
00:11:38,200 --> 00:11:40,720
error leading to blindness.

141
00:11:40,720 --> 00:11:46,200
And from that signal in the electronic health record coupled with the images, we are able

142
00:11:46,200 --> 00:11:54,920
to train a computer vision based thing to make a prediction about whether a child whose

143
00:11:54,920 --> 00:11:59,520
eye image has been taken is in danger of losing eyesight.

144
00:11:59,520 --> 00:12:02,520
And that is in deployment right now in India.

145
00:12:02,520 --> 00:12:06,520
And of course, for other parts of the world, like the United States and Europe, which are

146
00:12:06,520 --> 00:12:12,440
more regulated, these things are in various states of clinical validation, as they can be

147
00:12:12,440 --> 00:12:14,560
more broadly deployed.

148
00:12:14,560 --> 00:12:21,840
Another example is a project that we have called Inner Eye that is trying to just reduce

149
00:12:21,840 --> 00:12:31,000
the incredible kind of boring and mundane problem of just pixel-by-pixel outlining the parts

150
00:12:31,000 --> 00:12:36,880
of your body that are tumor and should be attacked with a radiation beam, as opposed

151
00:12:36,880 --> 00:12:38,440
to the healthy tissue.

152
00:12:38,440 --> 00:12:43,560
And that problem of radiation therapy planning has to be done really perfectly, which is

153
00:12:43,560 --> 00:12:47,120
why it's this sort of pixel-by-pixel process.

154
00:12:47,120 --> 00:12:55,600
But there is maybe five or 15 minutes of real black magic that's drawing on all of the

155
00:12:55,600 --> 00:13:02,400
intuition and experience and wisdom of a radiologist, and then two to three hours of complete

156
00:13:02,400 --> 00:13:03,400
drudgery.

157
00:13:03,400 --> 00:13:08,000
And much of that complete drudgery can just be eliminated with modern computer vision

158
00:13:08,000 --> 00:13:09,000
technologies.

159
00:13:09,000 --> 00:13:14,880
And so these things are really developing so rapidly and coming online.

160
00:13:14,880 --> 00:13:21,120
And they tend not to replace completely what doctors and radiologists can do, because

161
00:13:21,120 --> 00:13:25,360
there is always some judgment and intuition involved in these things.

162
00:13:25,360 --> 00:13:30,760
But when done right, they can integrate into the workflow to really enable to kind of

163
00:13:30,760 --> 00:13:38,760
liberate clinicians from a lot of drudgery and to reduce mistakes.

164
00:13:38,760 --> 00:13:44,680
And I think one other thing that's sometimes not fully appreciated is you also, when you

165
00:13:44,680 --> 00:13:48,920
get these tools, you can take these measurements over and over and over again.

166
00:13:48,920 --> 00:13:54,380
When they become cheap, you can take them every day if necessary, which allows you to

167
00:13:54,380 --> 00:14:01,240
track the progression of a disease or its treatment over time much more precisely.

168
00:14:01,240 --> 00:14:08,920
And so these sorts of applications, I think, in medical imaging, I think are really promising.

169
00:14:08,920 --> 00:14:18,440
One thing I, it's a hobby horse of mine before I pause is, you know, in 2015 here in Microsoft

170
00:14:18,440 --> 00:14:22,680
research, we invented something called deep residual networks, which are now commonly

171
00:14:22,680 --> 00:14:23,680
called ResNet.

172
00:14:23,680 --> 00:14:29,080
And ResNet has become part of an industry standard and research standard in computer vision

173
00:14:29,080 --> 00:14:31,560
using deep neural nets.

174
00:14:31,560 --> 00:14:39,720
We ourselves have refrained from using ResNet for doing things like imaging of 3D images

175
00:14:39,720 --> 00:14:43,720
for the purposes of radiation therapy planning, and there are various technical reasons for

176
00:14:43,720 --> 00:14:44,720
that.

177
00:14:44,720 --> 00:14:49,840
And so sometimes we have a mixture of being proud seeing the rest of the world use our

178
00:14:49,840 --> 00:14:54,720
invention for interesting medical imaging, but we also sometimes get worried that people

179
00:14:54,720 --> 00:14:59,480
don't quite understand the failure modes in these things.

180
00:14:59,480 --> 00:15:02,160
But still, the progress has just been spectacular.

181
00:15:02,160 --> 00:15:06,080
I mean, that's kind of an interesting prompt.

182
00:15:06,080 --> 00:15:13,200
Maybe let's take a moment to explore the failure modes and why don't you, it sounds like

183
00:15:13,200 --> 00:15:18,240
you don't advise folks to apply ResNet to the types of images that we tend to see in medical

184
00:15:18,240 --> 00:15:19,240
imaging.

185
00:15:19,240 --> 00:15:20,240
What's that about?

186
00:15:20,240 --> 00:15:26,640
Yeah, it's not advising or warning people against it.

187
00:15:26,640 --> 00:15:32,200
So if you think about, let's say, take the problem of radiation therapy planning, it's

188
00:15:32,200 --> 00:15:33,800
a 3D problem.

189
00:15:33,800 --> 00:15:41,160
You have a tumor that is a 3D mass in your body and you're trying to come up with a plan

190
00:15:41,160 --> 00:15:48,360
for that radiation beam to attack ideally as much of that tumor while preserving as much

191
00:15:48,360 --> 00:15:50,560
healthy tissue as possible.

192
00:15:50,560 --> 00:15:58,320
And of course, your picture into that 3D tumor is as a series of two-dimensional slices,

193
00:15:58,320 --> 00:16:00,720
at least with current medical imaging.

194
00:16:00,720 --> 00:16:11,120
And so one very basic question is, as you examine slice by slice, that tumor with respect

195
00:16:11,120 --> 00:16:17,200
to the healthy tissue, is each slice being properly and logically registered with the

196
00:16:17,200 --> 00:16:19,080
next one.

197
00:16:19,080 --> 00:16:27,800
And a simple or naive application of a convolutional neural network like a ResNet doesn't automatically

198
00:16:27,800 --> 00:16:29,120
do that.

199
00:16:29,120 --> 00:16:37,000
The other problem is it's unclear to what extent a bad training sample or set of training

200
00:16:37,000 --> 00:16:42,560
samples will do to one of these deep neural nets.

201
00:16:42,560 --> 00:16:49,560
And in fact, just in the last few weeks and months, there have been more and more interesting

202
00:16:49,560 --> 00:16:56,440
academic research studies showing some interesting failure modes from a surprisingly small number

203
00:16:56,440 --> 00:17:00,120
of bad training samples.

204
00:17:00,120 --> 00:17:06,680
And so I think that these things are changing all the time, our algorithms and our algorithmic

205
00:17:06,680 --> 00:17:09,680
understanding are improving all the time.

206
00:17:09,680 --> 00:17:16,600
But at least within our research groups, we've taken pains to understand that this application

207
00:17:16,600 --> 00:17:20,040
of computer vision isn't like others.

208
00:17:20,040 --> 00:17:27,200
It's more in the realm of driverless cars where safety is of paramount concern and we

209
00:17:27,200 --> 00:17:32,320
just have to have absolute certainty that we understand the possible failure modes of

210
00:17:32,320 --> 00:17:33,320
these things.

211
00:17:33,320 --> 00:17:41,120
Sometimes with just an authorship application of ResNet or any similar kind of deep neural

212
00:17:41,120 --> 00:17:48,120
net algorithm, we and now more and more other researchers at universities are finding that

213
00:17:48,120 --> 00:17:51,280
we don't yet fully understand the failure modes.

214
00:17:51,280 --> 00:18:00,000
In some ways, there's an opportunity beyond kind of naive application of an algorithm

215
00:18:00,000 --> 00:18:03,000
that performs very well on ImageNet.

216
00:18:03,000 --> 00:18:08,840
Also for, so today you can get data sets that include kind of these 2D representations

217
00:18:08,840 --> 00:18:14,320
of what are fundamentally 3D applications or 3D images and kind of apply the regular

218
00:18:14,320 --> 00:18:18,520
2D algorithms to them and find interesting things.

219
00:18:18,520 --> 00:18:25,560
But you're saying that there, A, we can do better and B, we may not even be doing the

220
00:18:25,560 --> 00:18:30,840
right things in many cases because of these safety issues.

221
00:18:30,840 --> 00:18:36,600
I'm wondering do you, on the first of those two points, the doing better, is there either

222
00:18:36,600 --> 00:18:42,200
a standard approach that's better than ResNet for these 3D images that you've developed

223
00:18:42,200 --> 00:18:50,160
at Microsoft or have seen otherwise or where are we in terms of taking advantage of the

224
00:18:50,160 --> 00:18:54,400
3D nature of medical images and deep learning?

225
00:18:54,400 --> 00:19:01,400
Yeah, it's a good question, you know, for our inner-eye project, which is really run by

226
00:19:01,400 --> 00:19:09,520
a great set of researchers, based mostly in our Cambridge UK research lab and led by Antonio

227
00:19:09,520 --> 00:19:17,440
Kriminesi and he's really one of the pre-eminent authorities in computer vision.

228
00:19:17,440 --> 00:19:23,760
In fact, he, he led an effort some years ago to work out the 3D computer vision for

229
00:19:23,760 --> 00:19:29,320
Connect and so he's really specialized in 3D.

230
00:19:29,320 --> 00:19:36,000
And so the inner-eye project, which is really for us an effort to really understand completely

231
00:19:36,000 --> 00:19:43,320
the workflow of radiation therapy planning, that system actually doesn't use residual

232
00:19:43,320 --> 00:19:44,320
network.

233
00:19:44,320 --> 00:19:51,640
What it does is it uses a kind of an architecture of layered, what a code decision for us.

234
00:19:51,640 --> 00:20:00,520
And that gives not only some benefits in terms of more compact representations of the machine

235
00:20:00,520 --> 00:20:08,560
learned models and therefore some performance improvements, but it allows us to kind of

236
00:20:08,560 --> 00:20:16,280
capture a kind of logical registration of the images as they go slice by slice.

237
00:20:16,280 --> 00:20:24,120
In other words, it's you're inferring not just the segmentation of each 2D image slice,

238
00:20:24,120 --> 00:20:33,400
but you're actually trying to infer the voxel, the 3D voxel volume of these, of the tumor

239
00:20:33,400 --> 00:20:35,320
that you're trying to attack.

240
00:20:35,320 --> 00:20:39,680
And so, and then on top of that, there's a process involved when you're dealing with

241
00:20:39,680 --> 00:20:41,520
medical technologies.

242
00:20:41,520 --> 00:20:45,920
You don't just put it out there and start applying it on people.

243
00:20:45,920 --> 00:20:51,600
You get it peer reviewed, you get it peer reviewed and in this case in computer science journals

244
00:20:51,600 --> 00:20:53,720
and in medical journals.

245
00:20:53,720 --> 00:20:56,640
And you go through a clinical validation.

246
00:20:56,640 --> 00:21:02,080
And if you're in the United States, for example, through an FDA approval process.

247
00:21:02,080 --> 00:21:09,240
And so for us, as we're learning about what does our cloud, what do our AI services, what

248
00:21:09,240 --> 00:21:17,000
do our tools have to be in order to support this future of AI powered healthcare?

249
00:21:17,000 --> 00:21:22,360
In their eyes, an example of us going end to end to try to build it all out and to understand

250
00:21:22,360 --> 00:21:27,680
all of those components and to understand what has to be done to really do it right.

251
00:21:27,680 --> 00:21:31,160
And it's been a great learning experience.

252
00:21:31,160 --> 00:21:37,120
We're now in the process, not only of working with various companies who might want to integrate

253
00:21:37,120 --> 00:21:44,600
this interi technology into their medical devices, but we're starting to now pull apart

254
00:21:44,600 --> 00:21:49,600
the kind of bricks and mortar that we used in the technical architecture for interi

255
00:21:49,600 --> 00:21:54,320
in order to expose those as APIs for other developers to use.

256
00:21:54,320 --> 00:21:57,800
And so our intent is not to get into the radiation therapy business.

257
00:21:57,800 --> 00:22:03,320
Our intent is not to get into radiology, but we do want our cloud and our AI services

258
00:22:03,320 --> 00:22:10,800
and our algorithms to be a great place for any other company or any other startup or

259
00:22:10,800 --> 00:22:17,200
innovator who wants to do that and ideally do it on our cloud using our tools.

260
00:22:17,200 --> 00:22:25,480
So an interesting point in there, you mentioned that the decision for us that you've developed

261
00:22:25,480 --> 00:22:32,360
to address this problem, you know, I guess we often think of there being this trade

262
00:22:32,360 --> 00:22:42,240
off between factors like explainability or, you know, safety as you related that second

263
00:22:42,240 --> 00:22:49,520
point and performance, which we think of as the neuron that is delivering the kind of

264
00:22:49,520 --> 00:22:52,920
the ultimate in performance in many cases.

265
00:22:52,920 --> 00:23:00,720
But in this case, your this decision for us algorithm is outperforming your, at least

266
00:23:00,720 --> 00:23:04,280
your classic 2D resnets.

267
00:23:04,280 --> 00:23:08,960
And I'm imagining also providing benefits in terms of explainability slash safety, is

268
00:23:08,960 --> 00:23:09,960
that correct?

269
00:23:09,960 --> 00:23:16,480
Well, I we feel very strongly that it provides benefits in terms of safety, explainability

270
00:23:16,480 --> 00:23:21,320
is really another very interesting question and the problem.

271
00:23:21,320 --> 00:23:26,640
And so there's a potential for greater explainability, you know, one of the lessons that

272
00:23:26,640 --> 00:23:32,920
we learned when we were working on AI for sales intelligence.

273
00:23:32,920 --> 00:23:37,960
And so we had really developed a tremendous amount of AI that would ingest large amounts

274
00:23:37,960 --> 00:23:44,080
of data from the world as well as from customer relationship management databases, emails

275
00:23:44,080 --> 00:23:47,480
and so on for our sales teams.

276
00:23:47,480 --> 00:23:57,880
And use that through various AI algorithms to do things like synthesize new offers to

277
00:23:57,880 --> 00:24:05,920
specific customers or to surface new prospective customers or to suggest new discount pricing

278
00:24:05,920 --> 00:24:07,720
for specific customers.

279
00:24:07,720 --> 00:24:13,480
And one of the things we learned is that, you know, no self-respecting sales executive

280
00:24:13,480 --> 00:24:21,080
is going to offer 20% discount to a customer just because his algorithm says so.

281
00:24:21,080 --> 00:24:25,720
You know, and, you know, typically doctors are probably similar.

282
00:24:25,720 --> 00:24:26,720
That's right.

283
00:24:26,720 --> 00:24:33,960
And so in that situation, we also moved away from, in that specific case, moved away from

284
00:24:33,960 --> 00:24:40,960
the pure deep neural net architecture to having kind of layered architecture of Bayesian

285
00:24:40,960 --> 00:24:42,960
graphical models.

286
00:24:42,960 --> 00:24:49,160
And the reason for that was so that we could synthesize an explanation in plain English

287
00:24:49,160 --> 00:24:53,680
of not only, you know, offer a 20% discount, but why?

288
00:24:53,680 --> 00:24:59,520
And as we get into away from more kind of point solutions that are kind of machine learning

289
00:24:59,520 --> 00:25:08,000
or AI powered to more of that digital assistant that is the companion to a clinician and gives

290
00:25:08,000 --> 00:25:14,480
that clinician a second opinion or advice on the first opinion, those sorts of explanations

291
00:25:14,480 --> 00:25:19,560
undoubtedly are going to become important, especially at the beginning when we're trying

292
00:25:19,560 --> 00:25:22,560
to establish trust in these things.

293
00:25:22,560 --> 00:25:27,720
And so, you know, as we've been experimenting even with the kind of ambient intelligence

294
00:25:27,720 --> 00:25:34,240
to just listen in on a doctor patient encounter and try to automate a note, one thing we found

295
00:25:34,240 --> 00:25:42,240
is that doctors will look at the synthesized note and not trust everything in it, because

296
00:25:42,240 --> 00:25:46,680
they don't quite yet have the understanding of, you know, why did the note come out

297
00:25:46,680 --> 00:25:47,680
this way?

298
00:25:47,680 --> 00:25:53,440
And so it became important to provide tools so that when you, you know, say, click on a

299
00:25:53,440 --> 00:25:59,840
specific entry in the note that it could be mapped back to a running transcript and

300
00:25:59,840 --> 00:26:03,080
to the right spot in the running transcript that was recorded.

301
00:26:03,080 --> 00:26:08,560
And so these sorts of things, I think, are part of that maybe the human computer interaction

302
00:26:08,560 --> 00:26:15,520
or the human AI interaction that we're having to think about pretty hard as we try to integrate

303
00:26:15,520 --> 00:26:18,680
these things into clinical workflow.

304
00:26:18,680 --> 00:26:26,080
Before we move on beyond diagnostics and therapeutics, all of the examples that you gave fell

305
00:26:26,080 --> 00:26:35,280
into the domain of computer vision, are there interesting things happening in diagnostics

306
00:26:35,280 --> 00:26:39,920
beyond the kind of onslaught of these new computer vision based approaches?

307
00:26:39,920 --> 00:26:46,800
Yeah, I think actually some of the most interesting things are not in computer vision.

308
00:26:46,800 --> 00:26:50,880
And this maybe crosses over into the precision medicine thing.

309
00:26:50,880 --> 00:26:56,200
One of the projects I'm so excited about is something that we're doing jointly with

310
00:26:56,200 --> 00:27:00,600
Seattle biotech startup adaptive biotechnologies.

311
00:27:00,600 --> 00:27:09,600
And so the setup is this, you know, if you take a small blood sample from your body in

312
00:27:09,600 --> 00:27:15,320
that sample, in that one mill sample, you'll end up capturing on the order of one million

313
00:27:15,320 --> 00:27:16,320
T cells.

314
00:27:16,320 --> 00:27:22,000
T cells are one of the primary agents in your adaptive immune system.

315
00:27:22,000 --> 00:27:27,640
And about two and a half years ago, there was a major scientific breakthrough that got

316
00:27:27,640 --> 00:27:35,160
published that showed that the receptor, there's a receptor on the surface of your T cells.

317
00:27:35,160 --> 00:27:40,000
And in that receptor, there's a small snippet of DNA.

318
00:27:40,000 --> 00:27:44,760
And there was strong evidence two and a half years ago that that snippet of DNA completely

319
00:27:44,760 --> 00:27:52,480
determines what pathogen or infectious disease agent or cancer that T cell has been programmed

320
00:27:52,480 --> 00:27:55,440
to seek out and destroy.

321
00:27:55,440 --> 00:28:02,080
And that paper was very interesting because it used a simple linear regression in order

322
00:28:02,080 --> 00:28:10,040
to identify from a read of that little snippet of DNA on your T cell receptor, whether you

323
00:28:10,040 --> 00:28:14,440
had cytomegalovirus or not.

324
00:28:14,440 --> 00:28:19,560
And so it was really just an impressive paper and then just very recent.

325
00:28:19,560 --> 00:28:24,120
Well, the thing that was interesting about adaptive biotechnologies is adaptive biotechnologies

326
00:28:24,120 --> 00:28:30,600
was in the business of giving you a printout of that specific snippet of DNA in all the

327
00:28:30,600 --> 00:28:32,760
T cell receptors in the blood sample.

328
00:28:32,760 --> 00:28:40,760
So they had a business model that would help some cancer centers titrate the amount of

329
00:28:40,760 --> 00:28:45,560
a specific chemotherapy you were getting based on a reading of the DNA.

330
00:28:45,560 --> 00:28:51,080
And so that raised the question, would it be possible to take that printout of those

331
00:28:51,080 --> 00:28:53,880
T cell receptor DNA sequences?

332
00:28:53,880 --> 00:29:01,800
And in essence, think of that as a language and translate it into the language of antigens.

333
00:29:01,800 --> 00:29:08,080
And then if you can do that, can you take those antigens and do a kind of topic identification

334
00:29:08,080 --> 00:29:14,840
problem to figure out what infectious diseases, what cancers, and what autoimmune disorders,

335
00:29:14,840 --> 00:29:17,720
your body is currently coping with right now?

336
00:29:17,720 --> 00:29:23,720
And so it turned into this very interesting new business opportunity for adaptive biotechnologies

337
00:29:23,720 --> 00:29:30,120
that if machine learning could be used to solve those two problems, then they would have

338
00:29:30,120 --> 00:29:36,120
a technology that would be very similar to a universal diagnostic, a simple blood test

339
00:29:36,120 --> 00:29:42,080
powered by machine learning that could do early diagnosis of any infectious disease, any

340
00:29:42,080 --> 00:29:45,440
cancer, and any autoimmune disorder.

341
00:29:45,440 --> 00:29:50,720
And so Microsoft found that interesting enough that we actually took an investment position

342
00:29:50,720 --> 00:29:56,840
in adaptive biotechnologies and agreed to work with them on the machine learning.

343
00:29:56,840 --> 00:30:02,680
And adaptive for their part agreed to build a bigger production pipeline in order to generate

344
00:30:02,680 --> 00:30:09,560
training data to power the machine learning that we're developing at Microsoft.

345
00:30:09,560 --> 00:30:16,120
What has transpired since then has been an amazing amount of progress where we've added

346
00:30:16,120 --> 00:30:22,640
tremendous amount of sophistication actually using deep neural nets and started to feed

347
00:30:22,640 --> 00:30:25,880
it with billions of points of training data.

348
00:30:25,880 --> 00:30:29,920
And in fact, this year the production facility adaptive will be able to generate up to a trillion

349
00:30:29,920 --> 00:30:32,440
points of training data.

350
00:30:32,440 --> 00:30:40,000
And we're now targeting five specific diseases, a varying cancer, pancreatic cancer, type

351
00:30:40,000 --> 00:30:43,520
one diabetes, celiac disease, and Lyme disease.

352
00:30:43,520 --> 00:30:47,240
And so that's two cancers, two autoimmune disorders, and one infectious disease with the

353
00:30:47,240 --> 00:30:50,080
same machine learning pipeline.

354
00:30:50,080 --> 00:30:56,440
And it's still an experiment, but it kind of shows you the potential power of these advances

355
00:30:56,440 --> 00:31:04,600
in immunology, in genomics, and AI all being bound together to give the possibility.

356
00:31:04,600 --> 00:31:07,120
We know the science now is valid.

357
00:31:07,120 --> 00:31:12,240
And if we can now build a technology that ties those things together, we get the potential

358
00:31:12,240 --> 00:31:16,920
for a universal diagnostic, but as close a thing that we could imagine getting to the

359
00:31:16,920 --> 00:31:20,280
Star Trek tricorder as anything.

360
00:31:20,280 --> 00:31:26,800
Yeah, that was the thing that popped immediately to mind for me, the tricorder.

361
00:31:26,800 --> 00:31:38,320
But that example I think captures for me really plainly both the promise of applying machine

362
00:31:38,320 --> 00:31:45,920
learning and AI to this healthcare domain, but also maybe a little bit of the frustration

363
00:31:45,920 --> 00:31:51,600
and thinking through collecting a trillion samples and you've got this pipeline, why does

364
00:31:51,600 --> 00:31:52,600
it take so long?

365
00:31:52,600 --> 00:32:00,360
And there's certainly regulatory and political types of reasons that maybe we'll get into.

366
00:32:00,360 --> 00:32:09,160
But I'm wondering if you can elaborate on with that much training data and the science

367
00:32:09,160 --> 00:32:14,320
in place and a pipeline in place.

368
00:32:14,320 --> 00:32:24,880
What are the realities of applying machine learning in this type of context that impede

369
00:32:24,880 --> 00:32:26,680
kind of rapid scale?

370
00:32:26,680 --> 00:32:32,040
Like why just five diseases and not 25, for example?

371
00:32:32,040 --> 00:32:35,320
Yeah, that's such a great question.

372
00:32:35,320 --> 00:32:41,320
And it's human biology is just so complicated.

373
00:32:41,320 --> 00:32:46,520
You know, let's say there are three ways maybe to take a cut at that.

374
00:32:46,520 --> 00:32:53,880
If we just look at the very basic science, let's just consider the human genome.

375
00:32:53,880 --> 00:32:59,720
Something that geneticists at several universities have taught me, which was really eye opening,

376
00:32:59,720 --> 00:33:07,680
is if you look at the human genome and then look at all the possible variants, the number

377
00:33:07,680 --> 00:33:14,000
of variants and the human genome that would still be considered, you know, homo sapiens

378
00:33:14,000 --> 00:33:17,840
is just astronomically large.

379
00:33:17,840 --> 00:33:24,280
And yet the total number of people on the planet is a relative that number is really tiny,

380
00:33:24,280 --> 00:33:27,000
you know, only what's seven and a half billion people.

381
00:33:27,000 --> 00:33:32,760
And in fact, if we had somehow DNA samples from every human that has ever existed, I think

382
00:33:32,760 --> 00:33:37,640
most estimates say there are fewer than a hundred and six billion people that have ever existed

383
00:33:37,640 --> 00:33:39,600
since Adam and Eve.

384
00:33:39,600 --> 00:33:45,080
And so if we are using modern machine learning, which is basically looking at statistical patterns

385
00:33:45,080 --> 00:33:52,560
and correlations, we have an immediate problem for a lot of basic problems in genomics, because

386
00:33:52,560 --> 00:33:59,000
we basically don't have a source of enough training data, the complexity of human beings,

387
00:33:59,000 --> 00:34:05,120
the complexity of cancer, the complexity, the genetic complexity of disease is just vastly

388
00:34:05,120 --> 00:34:09,760
larger than the number of people that have ever existed.

389
00:34:09,760 --> 00:34:19,720
Meaning relative to the possible combinations of genes, every human is, you know, I guess

390
00:34:19,720 --> 00:34:24,680
it shouldn't be surprising that every human is unique, but even given, I mean, it's a

391
00:34:24,680 --> 00:34:25,680
little counterintuitive.

392
00:34:25,680 --> 00:34:29,520
You think there's only like these four letters that were thrown together to make all this

393
00:34:29,520 --> 00:34:31,200
stuff out, right?

394
00:34:31,200 --> 00:34:38,720
Yeah, it's, and so, you know, and so what that means is that yes, we will, and we have

395
00:34:38,720 --> 00:34:44,360
been making, we meaning the scientific community and the technology community have been making

396
00:34:44,360 --> 00:34:52,320
stunning advances and making really meaningful improvements for neonatal intensive care for

397
00:34:52,320 --> 00:35:02,320
cancer treatments for immunology, but fundamentally, scientifically, we still need something beyond

398
00:35:02,320 --> 00:35:08,640
just machine learning, and we really need something that gets into the basic biology.

399
00:35:08,640 --> 00:35:12,840
And so that's kind of one reason why this is hard, and another reason is these are just

400
00:35:12,840 --> 00:35:13,840
big problems.

401
00:35:13,840 --> 00:35:19,480
In the project with adaptive biotechnologies, there are between 10 to the 15th and 10

402
00:35:19,480 --> 00:35:27,360
to the 16th different T-cell receptors that your body can produce, and on the order of

403
00:35:27,360 --> 00:35:35,480
maybe 10 to the 7th known antigens, and, and so imagine what we're trying to do is trying

404
00:35:35,480 --> 00:35:42,080
to fill out a gigantic X-cell spreadsheet, you know, with 10 to the 16th columns and 10

405
00:35:42,080 --> 00:35:47,680
to the 7th rows, and that's just a heck of a big table.

406
00:35:47,680 --> 00:35:54,040
And so you end up needing a large monitoring data to discern enough structure, find enough

407
00:35:54,040 --> 00:36:00,800
patterns in, in order to have a shot at filling in at least useful parts of that table.

408
00:36:00,800 --> 00:36:08,240
The good news is, you know, everybody has T-cells, and so we can take blood samples from

409
00:36:08,240 --> 00:36:14,240
anybody, from just ordinary healthy people, and then we can go to research laboratories

410
00:36:14,240 --> 00:36:22,560
around the world that have stored the libraries of antigens, and start kind of correlating

411
00:36:22,560 --> 00:36:27,920
those stored libraries of antigens against those what are called naive blood samples.

412
00:36:27,920 --> 00:36:32,760
And that's exactly what adaptive biotechnologies is doing, in order to generate the very large

413
00:36:32,760 --> 00:36:33,760
monitoring data.

414
00:36:33,760 --> 00:36:39,880
So it's a little bit of a good news situation there, that we don't need to find thousands

415
00:36:39,880 --> 00:36:45,000
or millions of sick people, we can generate the data from just ordinary samples, but

416
00:36:45,000 --> 00:36:48,360
it's still a very large monitoring data that we need.

417
00:36:48,360 --> 00:36:56,280
And then, you know, the third kind of way that I think about this is, you know, it gets

418
00:36:56,280 --> 00:36:58,040
back to the safety issue.

419
00:36:58,040 --> 00:37:04,400
You know, we do things a certain way, because ultimately medicine and medical science

420
00:37:04,400 --> 00:37:10,320
is based on causal relationships, in other words, you know, we want to know that A causes

421
00:37:10,320 --> 00:37:18,080
B, but what we typically get out of machine learning is just A is correlated with B, and

422
00:37:18,080 --> 00:37:23,040
we get those inferences, and then it takes more work and more testing under controlled

423
00:37:23,040 --> 00:37:25,960
circumstances to know that there's a causal relationship.

424
00:37:25,960 --> 00:37:33,200
And so all three of those things kind of create, you know, challenges, it does take time,

425
00:37:33,200 --> 00:37:39,960
but you know, it's, I think the good thing is, as the regulatory organizations like the

426
00:37:39,960 --> 00:37:46,080
FDA have gotten smarter and smarter about what is machine learning, what is good for

427
00:37:46,080 --> 00:37:52,520
or what are its limitations, that whole process has gotten, I think, faster and more efficient

428
00:37:52,520 --> 00:37:54,400
over time.

429
00:37:54,400 --> 00:38:00,680
And then, and then there's a second element, which is, of course, companies are in it

430
00:38:00,680 --> 00:38:06,680
to make money at a minimum, even if they have purely humanitarian intentions, at a minimum,

431
00:38:06,680 --> 00:38:09,680
they have to be sustained over time.

432
00:38:09,680 --> 00:38:15,000
And so that means that insurance companies, Medicare, Medicaid, they have to be willing

433
00:38:15,000 --> 00:38:22,440
to reimburse doctors and nurses when they actually use or prescribe these diagnostics

434
00:38:22,440 --> 00:38:23,440
and therapeutics.

435
00:38:23,440 --> 00:38:25,960
And so all of that takes time.

436
00:38:25,960 --> 00:38:34,560
At least on the, the second of your three points in thinking about scaling, solving problems

437
00:38:34,560 --> 00:38:43,600
like this, specifically training data, do you have a, a rule of thumb, a chart that says,

438
00:38:43,600 --> 00:38:48,760
okay, you are one trillion training samples, we'll get us these five diseases, but we'll

439
00:38:48,760 --> 00:38:52,200
need 10 trillion to get to 10 disease.

440
00:38:52,200 --> 00:38:57,160
I realize that that's almost an ass and I question, and it's much more complex than that,

441
00:38:57,160 --> 00:39:01,040
but do you, does it make sense at all to think of it like that?

442
00:39:01,040 --> 00:39:07,720
And I think of, I guess, the impact of collecting training data and what the trajectory looks

443
00:39:07,720 --> 00:39:11,680
like that over time, kind of like the way we thought of, you know, as we drive the cost

444
00:39:11,680 --> 00:39:15,480
of sequencing down, the downstream effects that that'll have.

445
00:39:15,480 --> 00:39:20,240
Yeah, well, when you find the answer to that question, please tell me.

446
00:39:20,240 --> 00:39:28,000
You know, it's, so in my experience, I've seen this go two ways.

447
00:39:28,000 --> 00:39:31,760
You know, one of the wonderful things about modern machine learning algorithms today is

448
00:39:31,760 --> 00:39:39,080
that they're, they're far less susceptible to problems of overfitting.

449
00:39:39,080 --> 00:39:46,240
They come very close to this, this wonderful property that the more data, the more better.

450
00:39:46,240 --> 00:39:53,320
And, but it does happen that sometimes you hit a wall, you know, that you start to see

451
00:39:53,320 --> 00:39:56,720
a trail off in improvement.

452
00:39:56,720 --> 00:40:05,440
And, and so it, we really don't know, we're very, that kind of early results that we've

453
00:40:05,440 --> 00:40:12,040
gotten with admittedly simpler diseases like CMV and then CMV is actually, you know, not

454
00:40:12,040 --> 00:40:18,680
that interesting from a medical perspective, they give us tremendous hope.

455
00:40:18,680 --> 00:40:25,520
And then other kind of internal more technical validations give us supreme confidence that

456
00:40:25,520 --> 00:40:30,280
the basic science, the biological sciences will understand now.

457
00:40:30,280 --> 00:40:35,120
But you know, once you start really attacking much more complex diseases, you know, like

458
00:40:35,120 --> 00:40:39,080
any cancer, it's, it's really hard.

459
00:40:39,080 --> 00:40:44,080
I would be unwilling personally to make a prediction about what will happen.

460
00:40:44,080 --> 00:40:48,200
But you know, there is every reason today for optimism.

461
00:40:48,200 --> 00:40:53,280
And, and I think that only unknown is, you know, whether there is a, whether we fall

462
00:40:53,280 --> 00:41:02,880
off a cliff at some point and, and stop finding improvements, or, you know, if we're, you

463
00:41:02,880 --> 00:41:09,880
know, if, if we're going to just get to a viable FDA approved diagnostic in the near

464
00:41:09,880 --> 00:41:14,680
term, that will be constantly improving as more and more people are diagnosed.

465
00:41:14,680 --> 00:41:18,080
So, so it could really go in either way.

466
00:41:18,080 --> 00:41:23,520
And then, yeah, I'm, I'm really unable and actually unwilling to make a prediction about

467
00:41:23,520 --> 00:41:25,320
which way will go.

468
00:41:25,320 --> 00:41:27,360
But, but we are feeling pretty confident.

469
00:41:27,360 --> 00:41:35,560
Incidentally, I should say, you know, last month, adaptive biotechnologies closed a deal

470
00:41:35,560 --> 00:41:45,320
with Genentech for applications of this T solar receptor antigen map in the therapeutic space

471
00:41:45,320 --> 00:41:50,960
in the area of cellular therapies for targeted cancer treatments.

472
00:41:50,960 --> 00:41:57,080
And, and that deal has a value of over $2 billion.

473
00:41:57,080 --> 00:42:02,680
So there's also some, you know, when you're dealing with kind of commercial relationships

474
00:42:02,680 --> 00:42:07,000
like that, you know, there, you know, there's a tremendous amount of due diligence.

475
00:42:07,000 --> 00:42:13,600
There's also, you know, these are big bets and a big pharma is, is accustomed to making

476
00:42:13,600 --> 00:42:18,800
a large risky bets like this, but I think it's, it's another sign, at least leading scientists

477
00:42:18,800 --> 00:42:25,240
at one of the larger pharmaceutical organizations is also increasingly confident that, that, that

478
00:42:25,240 --> 00:42:27,000
we can fill out this map.

479
00:42:27,000 --> 00:42:31,760
So we've talked about diagnostics, we've talked about precision medicine.

480
00:42:31,760 --> 00:42:38,000
What do you see happening on the tooling side, both from the doctor's perspective as well

481
00:42:38,000 --> 00:42:40,560
as the patient experience perspective?

482
00:42:40,560 --> 00:42:46,440
Yeah, you know, one thing that it's a, it's a simple thing, but it's been surprising

483
00:42:46,440 --> 00:42:50,280
how useful it has turned out to be.

484
00:42:50,280 --> 00:42:57,720
We've been piloting chatbot technology, you know, that we call the Microsoft Healthbot.

485
00:42:57,720 --> 00:43:05,320
And this has been sort of in a beta program with a few dozen healthcare organizations.

486
00:43:05,320 --> 00:43:14,800
And what it does is it, we've sort of advanced our cognitive services for language processing,

487
00:43:14,800 --> 00:43:21,440
natural language processing for conversational understanding, and the tooling to provide

488
00:43:21,440 --> 00:43:28,320
a drag and drop interface so that ordinary people can program these chatbots, at least

489
00:43:28,320 --> 00:43:29,640
for medical settings.

490
00:43:29,640 --> 00:43:35,320
And then we've improved the models, the language models that they understand medical and healthcare

491
00:43:35,320 --> 00:43:37,960
concepts and terms.

492
00:43:37,960 --> 00:43:43,520
And so we've been surprised at the kinds of applications that that people use.

493
00:43:43,520 --> 00:43:48,640
So one example is there are organizations that have made prescription bots.

494
00:43:48,640 --> 00:43:53,880
So the idea is this, maybe you get a prescription from your doctor or from the hospital, you

495
00:43:53,880 --> 00:44:02,520
go to the pharmacy, you get prescription filled, and then day or two later you get a message

496
00:44:02,520 --> 00:44:06,240
from this intelligent chatbot just asking, you know, how's it going?

497
00:44:06,240 --> 00:44:12,360
Yeah, have you had any, do you have any questions or have you had any issues with your medication?

498
00:44:12,360 --> 00:44:21,360
And it invites you proactively to get into a conversation that gives the healthcare provider

499
00:44:21,360 --> 00:44:25,280
tremendous insight into whether you're adhering to your prescription.

500
00:44:25,280 --> 00:44:26,600
That's a huge problem.

501
00:44:26,600 --> 00:44:34,040
Something like 35% of people actually don't follow through with their prescription medications.

502
00:44:34,040 --> 00:44:40,920
And it's just there to answer questions, maybe you have some stomach upset, or some people

503
00:44:40,920 --> 00:44:46,160
who are in a lot of medications hate having all those bottles and they put them all, you

504
00:44:46,160 --> 00:44:50,880
know, dump all the pills into a baggie and then they can't remember which pills are which.

505
00:44:50,880 --> 00:44:55,960
And so the health bot is able to converse with you and say, oh, well, why don't you point

506
00:44:55,960 --> 00:45:02,320
your phone camera at this, at a bunch of pills and I'll remind you what they are and

507
00:45:02,320 --> 00:45:10,600
it uses modern computer vision resonance actually to remind you what these pills are.

508
00:45:10,600 --> 00:45:19,320
And so the kind of engagement that the healthcare providers get, the improvements in engagement

509
00:45:19,320 --> 00:45:27,720
and the satisfaction that people like you and me have is really improved or just asking

510
00:45:27,720 --> 00:45:36,280
simple benefits, questions or medical triage, various sorts, these kinds of ideas have been

511
00:45:36,280 --> 00:45:43,480
surprisingly interesting and in fact, so surprising for us that later this week will be making

512
00:45:43,480 --> 00:45:47,960
that product generally available for sale and so you'll be able to use the micro health

513
00:45:47,960 --> 00:45:53,400
bot technology without any restrictions, well, except for payment of course.

514
00:45:53,400 --> 00:45:58,200
And so that is something that has gone extremely well.

515
00:45:58,200 --> 00:46:05,280
And that technology now is kind of being baked into more and more of I think of what

516
00:46:05,280 --> 00:46:06,920
people will be seeing.

517
00:46:06,920 --> 00:46:14,160
We have a collaboration hub application in Office 365 called Teams and Teams has been

518
00:46:14,160 --> 00:46:21,360
this just wonderful technology for improving collaboration and all sorts of work by settings.

519
00:46:21,360 --> 00:46:27,760
Well, we've made teams healthcare compliant and able to connect to electronic health record

520
00:46:27,760 --> 00:46:35,240
systems and then by integrating great kind of collaboration intelligence tools to just

521
00:46:35,240 --> 00:46:41,240
kind of parse records or know where to go to find certain bits of information or just

522
00:46:41,240 --> 00:46:48,200
to be able to ask an intelligent agent that is part of your team, you know, did so and

523
00:46:48,200 --> 00:46:56,120
so, check, you know, the sutures last night and be able to get a smart answer, whether

524
00:46:56,120 --> 00:47:03,280
people are wake or not, you know, is there are all these little ways that I think AI can

525
00:47:03,280 --> 00:47:07,600
be used in the workflow of healthcare delivery.

526
00:47:07,600 --> 00:47:12,680
One of the things that is I think underappreciated about healthcare delivery today, especially

527
00:47:12,680 --> 00:47:16,440
in acute care settings is it's a super collaborative environment.

528
00:47:16,440 --> 00:47:21,640
Sometimes there can be as many as 20 people, you know, that are working together as a team

529
00:47:21,640 --> 00:47:25,480
delivering care to multiple patients at a time.

530
00:47:25,480 --> 00:47:32,800
And so how to keep that team of 20 people all on the same page and all coordinated is

531
00:47:32,800 --> 00:47:40,720
getting to be a really difficult problem, typically done with, you know, posted notes and

532
00:47:40,720 --> 00:47:47,880
you know, half erased whiteboards, now transitioning to pretty insecure consumer messaging apps,

533
00:47:47,880 --> 00:47:55,760
but the idea of having real enterprise grade collaboration support with AI, I think

534
00:47:55,760 --> 00:48:00,720
just can make all of that much better and then provide much more security and privacy

535
00:48:00,720 --> 00:48:02,200
for people.

536
00:48:02,200 --> 00:48:09,400
So a lot of these applications of AI end up being, you know, more less flashy than doing

537
00:48:09,400 --> 00:48:14,960
some automatic radiation therapy planning on the medical image, but they really kind

538
00:48:14,960 --> 00:48:20,720
of help people, you know, those people on the front lines of healthcare delivery do their

539
00:48:20,720 --> 00:48:21,720
jobs better.

540
00:48:21,720 --> 00:48:27,680
Yeah, I tend to find myself having a really kind of mixed feelings about conversational

541
00:48:27,680 --> 00:48:31,920
applications, at least from the perspective of talking about them on the podcast, like

542
00:48:31,920 --> 00:48:38,840
I think that they are, there's no question that conversational experiences and interfaces

543
00:48:38,840 --> 00:48:43,600
will be a huge part of the way we interact with computers in the future and that there's

544
00:48:43,600 --> 00:48:49,560
tons of work that needs to happen there because of the reasons that you mentioned, like

545
00:48:49,560 --> 00:48:50,560
less flashy.

546
00:48:50,560 --> 00:48:55,440
I wonder if there's still interesting research or at least my question to you is, are there

547
00:48:55,440 --> 00:49:01,000
still interesting research challenges there or is it all, you know, do we have all the

548
00:49:01,000 --> 00:49:05,880
pieces and it's just kind of rolling up the sleeves and, you know, building enterprise

549
00:49:05,880 --> 00:49:08,760
software, which we know is hard and takes time?

550
00:49:08,760 --> 00:49:12,640
Yeah, it's a good question.

551
00:49:12,640 --> 00:49:18,920
It feels like research to me and some of the laboratories are, some of the problems

552
00:49:18,920 --> 00:49:28,000
of anything feel a little difficult, honestly, you know, it's, so, you know, if we just

553
00:49:28,000 --> 00:49:35,840
say take the problem of listening to a doctor patient conversation and from that understanding

554
00:49:35,840 --> 00:49:41,640
what you go into the standard form of a clinical encounter note.

555
00:49:41,640 --> 00:49:47,280
Here's a typical thing, there could be an exchange if, let's say Sam, you're my doctor

556
00:49:47,280 --> 00:49:53,840
and I'm your patient and you might be asking me how I'm doing and I might complain about

557
00:49:53,840 --> 00:50:00,000
you know, pain in my left knee hasn't gone away and what, you know, and we can have an

558
00:50:00,000 --> 00:50:08,760
exchange about how that goes and ultimately what goes into the note by you is a note about

559
00:50:08,760 --> 00:50:16,800
my continued lack of weight loss and that my, you know, being overweight is contributing

560
00:50:16,800 --> 00:50:26,600
to the lack of healing with my knee problem that may or may not have been a part of our conversation.

561
00:50:26,600 --> 00:50:32,880
And so while it's important that the weight loss elements be in that clinical note, in

562
00:50:32,880 --> 00:50:38,120
fact, it might even mean revenue for that doctor because there may be a weight loss program

563
00:50:38,120 --> 00:50:43,680
that gets prescribed and so on, that's important and it's important not to miss that.

564
00:50:43,680 --> 00:50:51,160
But the human exchange here and the things that are implicit in those conversations led

565
00:50:51,160 --> 00:50:59,000
along the fact that I'll say kneecap and you'll say Patela are things that are as close

566
00:50:59,000 --> 00:51:06,880
to general artificial intelligence style problems as anything and so, you know, it's, and

567
00:51:06,880 --> 00:51:11,200
look, we don't kid ourselves that we're anywhere close to solving those kinds of problems

568
00:51:11,200 --> 00:51:16,080
but those are the kinds of problems we think about, even when we just look at the kind

569
00:51:16,080 --> 00:51:21,880
of day-to-day minute-by-minute work that people do to deliver healthcare.

570
00:51:21,880 --> 00:51:22,880
Right.

571
00:51:22,880 --> 00:51:23,880
Right.

572
00:51:23,880 --> 00:51:30,440
Here's another one that's interesting to really unlock the power of AI, what we would

573
00:51:30,440 --> 00:51:38,400
want to do is to just open up huge databases to great researchers and innovators everywhere.

574
00:51:38,400 --> 00:51:43,920
But of course, we need to do that without violating anyone's privacy and so there's one problem,

575
00:51:43,920 --> 00:51:44,920
something called de-identification.

576
00:51:44,920 --> 00:51:51,000
It would be great to be able to take a treasure trove of, let's say, electronic health records

577
00:51:51,000 --> 00:51:54,560
and, quote unquote, de-identify it.

578
00:51:54,560 --> 00:51:58,200
Well, some parts of those electronic health records are easy to do because there might

579
00:51:58,200 --> 00:52:02,000
be a field called Social Security Number, another field called Name, another one called

580
00:52:02,000 --> 00:52:05,440
Address and so on, so you can just scrub those out.

581
00:52:05,440 --> 00:52:12,760
But large amounts of chronicle data involve just unstructured notes.

582
00:52:12,760 --> 00:52:17,760
And to really have a deep understanding of what's in those notes and in order to scrub

583
00:52:17,760 --> 00:52:23,760
those in a way that won't inadvertently build somebody's identity or their medical condition,

584
00:52:23,760 --> 00:52:30,160
again, is something that, in the ultimate, ends up being a very general AI problem.

585
00:52:30,160 --> 00:52:37,440
That's a great reframing of the way to think about this is like, yes, most chatbots are

586
00:52:37,440 --> 00:52:39,960
boring because they're boring.

587
00:52:39,960 --> 00:52:46,920
It's like, you know, the kind of the entity intent framework that, you know, most chatbots

588
00:52:46,920 --> 00:52:52,640
are built on is kind of like table stakes relative to what we're really trying to do with

589
00:52:52,640 --> 00:53:04,480
conversational experiences and that really requires a level of sophistication and our ability

590
00:53:04,480 --> 00:53:08,480
to use and work with and manipulate natural language that is very much at the research

591
00:53:08,480 --> 00:53:09,480
frontier now.

592
00:53:09,480 --> 00:53:14,840
And that's why most current, you know, in production chatbots are kind of boring.

593
00:53:14,840 --> 00:53:21,400
Yeah, we've taken a step forward of trying to think of these things almost in terms of

594
00:53:21,400 --> 00:53:25,480
playing, you know, being able to play a game of 20 questions.

595
00:53:25,480 --> 00:53:33,240
You know, one of the most inspiring applications of health bots that we dream about is in

596
00:53:33,240 --> 00:53:36,000
matching people to clinical trials.

597
00:53:36,000 --> 00:53:40,400
You know, at any point, there are thousands of clinical trials available and you can

598
00:53:40,400 --> 00:53:47,640
go to a website called clinicaltrials.gov and there's a search bar there and you can

599
00:53:47,640 --> 00:53:50,440
type in something like breast cancer.

600
00:53:50,440 --> 00:53:57,280
And when you do that, you get this gigantic dump of every registered clinical trial going

601
00:53:57,280 --> 00:54:01,240
on that might be pertinent to breast cancer.

602
00:54:01,240 --> 00:54:06,680
And while that's useful, the problem with that is it's hard to know which ones of those,

603
00:54:06,680 --> 00:54:12,920
you know, if you are, say, someone who's desperate to find clinical trial to enroll in because

604
00:54:12,920 --> 00:54:22,360
you've run out of other viable options for whatever is ailing you, it's just almost impossible

605
00:54:22,360 --> 00:54:25,960
to go through all of that technical information and try to understand this.

606
00:54:25,960 --> 00:54:32,360
And so, you know, would it be possible to use an AI to read through all of that technical

607
00:54:32,360 --> 00:54:37,640
information and then to synthesize what amounts to a game of 20 questions, something that

608
00:54:37,640 --> 00:54:44,120
will converse with you and ask you questions in order to narrow down to just that one or

609
00:54:44,120 --> 00:54:48,600
two or three clinical trials that might be a match for you.

610
00:54:48,600 --> 00:54:55,400
And it's that kind of thing where it's not fully general conversation of the sort that

611
00:54:55,400 --> 00:55:00,640
I think you and I were talking about just a minute ago, but it is slightly more structured

612
00:55:00,640 --> 00:55:07,760
than that in order to help you more intelligently and more efficiently find the right medical

613
00:55:07,760 --> 00:55:10,320
or healthcare solution for you.

614
00:55:10,320 --> 00:55:17,840
And that kind of application is something that we're really putting a lot of kind of hard

615
00:55:17,840 --> 00:55:21,480
and mind into, along with many others around the world.

616
00:55:21,480 --> 00:55:26,520
And it's exciting that we're starting to see these things actually make it into clinical

617
00:55:26,520 --> 00:55:28,040
use today.

618
00:55:28,040 --> 00:55:32,200
And so, I kind of agree with you.

619
00:55:32,200 --> 00:55:39,120
I roll my eyes sometimes at the overheated hype around intelligently and chatbots as

620
00:55:39,120 --> 00:55:45,160
well, just like anybody else, but it's really getting somewhere in these more limited domains.

621
00:55:45,160 --> 00:55:51,760
I think it also says why the interesting work in domains like this is going to be, you

622
00:55:51,760 --> 00:55:53,120
know, it's not generic, right?

623
00:55:53,120 --> 00:55:57,240
You're solving a specific problem and there's a lot of investment in kind of getting the

624
00:55:57,240 --> 00:56:03,200
machine learning DA right for this particular problem as opposed to implementing a generic

625
00:56:03,200 --> 00:56:04,200
framework.

626
00:56:04,200 --> 00:56:05,200
That's right.

627
00:56:05,200 --> 00:56:06,200
Awesome.

628
00:56:06,200 --> 00:56:12,080
Well, Peter, thank you so much for taking the time to chat with me about the stuff you're

629
00:56:12,080 --> 00:56:15,080
seeing and working on in the healthcare space.

630
00:56:15,080 --> 00:56:22,680
A ton of really interesting examples in there and I'm looking forward to kind of following

631
00:56:22,680 --> 00:56:25,400
all this work and digging deeper.

632
00:56:25,400 --> 00:56:26,400
Thank you.

633
00:56:26,400 --> 00:56:28,000
I didn't even talk about China once.

634
00:56:28,000 --> 00:56:29,000
It's great.

635
00:56:29,000 --> 00:56:36,280
Well, you mentioned ResNet a few times, kind of taunting me to dive into that conversation.

636
00:56:36,280 --> 00:56:40,120
But our fur folks to the article and we'll put the link in the show notes.

637
00:56:40,120 --> 00:56:41,120
Sounds great.

638
00:56:41,120 --> 00:56:44,240
It was really a pleasure chatting.

639
00:56:44,240 --> 00:56:48,240
All right, everyone.

640
00:56:48,240 --> 00:56:53,240
That's our show for today for more information on Peter or any of the topics covered in

641
00:56:53,240 --> 00:56:58,760
the show, visit twimmalai.com slash talk slash two, three, one.

642
00:56:58,760 --> 00:57:04,560
To follow along with the AI for the benefit of society series, visit twimmalai.com slash

643
00:57:04,560 --> 00:57:06,800
AI for society.

644
00:57:06,800 --> 00:57:33,560
As always, thanks so much for listening and catch you next time.

