All right, everyone. I am here with Conrad Tolmar. Conrad is a research director at Electronic
Arts or EA, as you may know it, as well as an associate professor at KTH. Conrad, welcome
to the Twimal AI podcast. Thanks Sam. Thanks for inviting us. It's lovely to be here. I'm really
looking forward to digging into our conversation. We'll be talking about as the audience might imagine,
the intersection of AI and games. Before we do, I'd love to have you share a little bit about your
background. I mentioned KTH. What is KTH? KTH is Royal Institute of Technology in Stockholm. It's
a technical university where I did my undergraduate as well as my PhD. I think my interest for AI started
quite a long time ago, starting with computer vision. I've always been passionate about photography,
and I saw them there was an opportunity to combine my kind of interest for photography with my
academic. That's my starting point here. Nice. Tell us a little bit about the kind of research
that interests you in your professorship and in your graduate studies. My PhD was about media
spaces and we built different kind of interactive environments to connect places with video streams,
but also being able to use sensors to convey other kinds of information if you're close or if you're
in the proximity of the space and so forth. That led me eventually to explore that further
after my I graduated and I spent some time working in smart and interactive environments.
Some of these were for play and some were for more like everyday use and I think some of us could
remember recall the kind of demos you saw out of MIT's Media Lab on the late 90s. A lot of
this was kind of cool demos, but we were not really able to build any kind of more intelligent
environments in this way. I then got the opportunity to do my postdoc at MIT AI Lab with Trevor
Dorrell where I saw an opportunity to dwell into more the underlying technologies and start to
really use computer vision and start to understand how you can track movements in the room, for example,
and then see how this could kind of be come as an input in these kind of interactive spaces.
Nice. That reminds me a little bit of as an undergrad, I went to RPI, Rensselaer, in New York,
and they had interactive design program and they would put these installations up in the library.
This was before a lot of modern things, like connect and other things, but they were always
really interesting. And imagining now as you're describing this intersection of those kinds
of installations and intelligence and machine learning like we've got now,
is that what kind of connected you to games?
Somewhat. I think we need to take a few more steps here, because I guess one of the
really great opportunities, even if we didn't have AI as today. I mean, this was 20 years ago,
almost. So we were just in the beginning of like starting to apply. I mean, the first versions
of OpenCV came out, and we started to play around with this. But we were also able to get
some kind of new cold hardware. So one of the products where we got box from Nokia, which was
the very first camera phones that came out. We also need an integrated web browser.
And this box was basically labeled feel free to play. So what do you do with the camera phone
with off? And then we scratch our head for a bit. And we came up with this idea of, well,
maybe you can search with images rather than keywords. And you take a picture of something.
And that become your sort of research here. And these kind of things. And we also had a very early
version of something similar to the connect camera, like a 3D camera, where we can track body
movements. And we looked upon, okay, how can you use these body movements to interact with this
3D world? And I think that was one of the first kind of things where I saw a bit of a connection
to gaming, because we were trying to set up experiments around this and started to study sort of
how people felt about navigating in a 3D world with your body gestures instead. And we played
with different kind of tools that were available back then. But sort of in the end of the day,
the one that we picked was actually a half-life. So we hacked half-life. And that become like the
engine that we used for to create this more like 3D experiments. And this is something that I've
been carrying with me ever since. And even fairly recently, we did studies on simulators for
self-driving cars. We have been using game engines rather than these kind of physics simulators
that is quite typical in automotive industry. Because somehow, if you're no more looking into
sort of the user experience of these environments, they are the best. And maybe this has kind of
brought me here at the EA to start to then look into more like what could we do with AI into the
games as it is now. Got it, got it. And so tell us a little bit about your role at EA and what
your focus is there. Well, we look into, I'm part of an applied research team called SID.
And we look into all kinds of different emerging technologies that eventually could be used
in the games. So we follow state of the art. We most of well several laws has PhD background.
We research and we also contribute them. We publish papers and so forth. Maybe not the same
extent as you would if you would be in there like an academic research lab. But so we stake
connection with the community. We look upon these techniques and see how we can eventually use
them into the games. And there are lots of different ways that AI can be used in games. What
area of focus do you, what's the kind of more specific area of focus for you and your group?
Well, as you say, there is plenty to do or there is plenty of opportunities nowadays. I mean,
with this kind of formal explosion of AI over the last decade, it's rather a bit hard to pick
what to do and what to not to do because you can do so many things. But I guess, I mean, people
maybe think about AI more into the games. And this is something that we also look into. But for us,
AI has also a fundamental role when it comes to creating the games. I mean, the kind of games that
we do, they're massive. And the production of them are also very long and very costly. And
there is a lot of things that could be done with AI into this. So we can use AI to create assets
of all kinds. We can create, I mean, different kind of media speech. You can create animations
and so forth. But you can also then use AI to test these assets. If they look okay,
if they behave okay. And then you put them into the game and then you can start
continue to look into, okay, how do they behave? How do they affect the gameplay experience?
And then you can march on. And when you eventually have a game, I mean, collecting all kinds of
information around the game, how people experience the game, what they like about the game, what they
don't like about the game, how the game works out. Doing that data analytics is also, of course,
a big part of how we apply AI at EA. When I think about games, this is perhaps true for many folks
in audience, I think about deep reinforcement learning. To what degree are the, is the work
that you're doing centered on the application of reinforcement learning? Yeah, thanks for asking.
And yeah, it's definitely reinforcement learning is on the top of our agenda as well.
However, it's not that easy to use. I mean, we play around with it and you know,
the work that has been going on the past, you can show where you can demonstrate the feasibility.
But then turn it into something that actually works in the game. So that's a bit of a different
matters here. So you mentioned that testing is one of the areas that you focus on and you've
published several papers on the application of machine learning to testing games. Can you give us
an overview of that general area game testing and how AI fits in? Yeah, of course. So game testing
came out actually out of some experiments we did a couple of years back when we looked into how to use
reinforcement learning into the games. And we were successful in actually creating some NPCs,
non-playable characters and put them into the game. And they were trained with reinforcement
learning. But we also learned that it's quite hard actually to fine tune their behavior. So
they actually behave in a way that is believable and that gamers like. And I think here you have
a bit of a different twist as well. I mean, typically when you work with AI, you would like to
make AI that if you have it in a self-driving car, for example, the car should behave like we drive
them or preferably even better. AI into the game have somewhat different constraints. They all
don't always have to work perfectly like that, but they need to be believable. And that is kind of
one thing that we learned and that we can create agents that behave well, but still there is
the subtle qualities or lack of qualities in how they behave that still gamers reacted towards.
So we decided then to take a bit of a step back and order and look upon, okay, how could we use
this agent maybe to start at least to explore testing the games with the agents. So this is
something that we've been doing then for like two years or something like that now with in different
flavors. What does it mean for the characters to be believable? Is it simply a matter of them not
being too good and kind of having their own, you know, foibles or are there nuances to that aspect
of believability? Yeah, so I think there's two parts of that. One is how they behave individually.
And they need to walk as you expect them to do. So I mean, of course, I think we all tend to
behave somewhat different in a game, but I mean, if you walk out in the real world, I mean,
you follow a path and you typically don't walk over a piece of grass. And even in games, that behavior
is happens again. So if this agent just walks straight and doesn't kind of have any
tendency of variations so that we expect humans to have, then they start to appear a bit oddly.
So that is one part, but then it's also, and this is even harder, how they act in the group.
So if you have a group of agents, they need to kind of somehow understand each other. So we
think that they have some kind of shared context or shared goal. If they're just running around on
their own, they will behave also quite odd. At least the behavior of them will look like a bit odd.
And when you think of them in groups, I'm imagining you were talking about both groups of these
NPCs as well as when they're collaborating with humans.
True. Collaborating with humans is also quite difficult because to read the gamers' intent
and to participate in that gameplay, I think that it's still a bit further down the road.
You can have them as companions in the games. And I think you see more and more games now
that start to adapt that. So some of the players are AI agents and some of real humans.
But again, to make this believable, it's depending on the game and depending on what task they have.
If you have a crowd that follows you is one thing. If you should sort out some collaborative task
that is very hard to do today. But on the other hand, if you twist this around, again, if you look
into game testing, some of these constraints you can relax tremendously. Because even you can say
that, well, it's sometimes good that these agents doesn't behave like humans or like everyone would
do. Because you know, the way we test games is too folded. Firstly, I mean, and the most part
of the testing is done by having a notch amount of human testers sit and testing through the games
and through different scenarios or different parts of the game. But then we also work with
some kind of automated tools. So we can create agents, script the agents that could solve some
tasks. And then you can sort of drop them into the game and they you can see that the navigation
mesh, for example, in the game works. So they can take they can go from one position to another
position, but then when you work with reinforcement learned agents, sometimes it's good that they
don't behave as humans. Because then they will find bugs that typically humans will not find.
So they won't walk through a wall. That human testers might not do. You see a wall
and then you'd walk around it, but the agents doesn't care. So they just walks straight
through the wall instead. And that's how you sort of find this exploits in the game.
Interesting, interesting. So when we're talking about testing in the context of,
well, specifics of some of the articles that you share that we'll be talking about,
the improving play testing coverage paper and the augmenting automated game testing paper,
are we talking about using deep learning agents, for example, to test the games broadly,
or are we talking about testing the NPCs in the games using other AI?
I think what we need to realize there, there is a couple of challenges that we need to work on.
And one of them is like a lot of the academic research about reinforcement learning agents
and testing or playing games are still fairly simple games. And if you go into and what
would like to apply that in like a full 3D game with a lot of other things, a lot of other
agents and a lot of dynamics, that is way harder. And then you also need to make this work
on to the game engines that we are using. So it eventually could be used in runtime.
Got it. So I think you're suggesting that the Atari games that we associated with
reinforcement learning are far simpler than the typical game that EA is producing today.
And I get that. I think you mentioned I'm trying to confirm what I thought I heard,
which was a couple of different use cases. One is that you want to introduce these NPCs,
these automated characters into the games, and you need some way to test them.
And then I think I heard separately that you want to be able to test the game
to generally make sure that the walls don't let you walk through them. And that's potentially
another area for the use of machine learning or reinforcement learning. And I'm curious which of
those are you working on? Are you working on both of those? And what that, you know, so I'm curious
to explore those areas. Yeah. So we have published a couple of papers recently and one was on
called last year, where we basically just introduced this notion of using reinforcement learning
agents into 3D games and looked upon what kind of test you can do with them. And then we saw
there was a couple of things you can do. I mean, you can see what kind of coverage they have.
They could find exploits in the games. You can find spaces, for example, where players might get stuck.
But also other things like that. So that was the first stepping stone. And then from that,
we have more looked into how you can generalize this in a couple of different ways. One is like,
like we talked a bit about like an agent. If you train an agent, a typical behavior is then that
it would maximize the sort of the how it goes from A to B. Not on the straight line maybe,
but like as quick as possible. And this is typically not the way we play games. So a more
human-like way to play games is to explore the game somewhat. And maybe you would like to check
whether a place to go is safe enough and you kind of sneak in and sneak out and go around it
in different ways. So that has been one of the explorations to look upon a model that is driven
by curiosity instead of an optimized path as it is. And so tell us a little bit about that work
and the idea of these models that are curiosity driven. How does that differ from kind of this
classical idea of tuning your explorers, type of parameters in reinforcement learning?
It goes along those lines of course, but what we needed to try out here is first kind of to what
sort of what coverage these agents could have. But then as another problem that the rise here is like
when you train these agents and you test the games with these agents, the agents themselves will
not tell you really what they have done. So if an agent goes through a wall for example or if an
agent doesn't find a spot, they will not tell you this. So a second part on this work was really
about also how could you visualize the behavior of these agents. So a game designer eventually could
look upon these visualizations and check whether their map or the world that they have created
works as they wanted it to be. And so that is also become a very important part of that work.
So collect all this data, creating different kind of visualization representations. So you can
find trajectories through the maps, you can find like heat maps where people where agents are
or haven't been and so forth. When you're creating an agent to explore a video game, are you and in
your paper in particular, are you substituting some notion of score based reward system for one
that's purely curiosity based? Do you like do you not care about the score if the agent you know it
gets great coverage of the the game or is there also do you also need to build in some notion of
score so that you're you know testing the things that humans would more likely do.
Yes and no. I think still we are in the face of that this exploration that these agents are doing.
It's fairly early on and make them actually to play the game in full. So they collect
like levels and scores as you would normally do in a game. That is still research to come.
So at this point we more looking into how we can make them navigate around and explore the
space in the best way and also being able to I would say to if you look upon games it's not
just running around in the games anymore. I mean typically in the game you have other kinds of
ways to navigate. You have different kind of instruments. You might have elevators that could
take you from one level to another. You might need to climb. Some of the new games also enable you
to fly through the game so you have a jetpack or something like that and this more advanced
form of navigation is still I would say very much work in progress on our side.
I think I hear you trying to temper my enthusiasm or my sense of where things are with the
class of games that you're working with. Maybe take us back and walk us through where you are
with the agents and the types of games that you are focused on at EA. How far along are you and
what are the key challenges that you run into when you kind of scale from Montezuma's
Revenge to a modern video game? Right. Like we talked a bit about the way you navigate around in
the space kind of comes down to the person now and what kind of game archetype you are if you're
an aggressive player or if you're a cautious player. So this is very things that we are very
much interested in where we look into now. Whether you with some form of imitation based learning
demonstration by game testers or even the game designers could pick up some of these
archetypes and then use this data when we train the agents. So the agents actually tend to
kind of get this kind of more multitude of character when they test or play the game.
So that's that's one thing but another thing that we also look into is one of the problems with
reinforcement learning and training of reinforcement learning agents. I think a lot of us
have discovered is that you do play, you train it on a fairly static environment.
So and if you change something in the environment, you need to retrain the old sort of model again.
And this is kind of very unpractical if you're in a game development cycle where you continuously
change the games and the maps and you make updates and fix bugs and so forth. So this is something
that we also are very much interested in how we can get models that is more adaptive to dynamic
environments. Yeah. And how do you go about doing that? Well, I mean, there is a couple of
different ways you can do that. I mean, one of the known techniques is called poet and that is
kind of used to kind of dynamically change the complexity in the environment. So the agents encounter
more and more complex environment to train on. Our approach is somewhat has drawn quite a lot
of inspiration from poet, but has a bit of a different take in that we take two reinforcement
agents. One is we call the generator and another one is called we as solver. So the generator
basically creates games. So using procedural generated algorithm to create game elements.
And the other agents try to solve this. And then they could work together as a pair in different
ways. So one is you can create models that handle more dynamic environment. But you can also use
this to kind of create levels of various kinds. So think about core ways, for example, where I
have one of the agent is kind of creating the track for you. And the other agent is try to drive
this track. And then they could work in a pair. And you can in that also try out how difficult this
track is by having different agents test the track. And then over manipulation, you can then
determine, well, this is a track level 10 or this is a track level five or something like that.
So this is how you can eventually also then implement it in the game to not only test the game,
but you can also hear tests sort of the complexity in the game. And then appropriately
set different scores on how difficult the tracks are. Got it, got it. So it sounds like that last
example ties into it's got this element of you training up an agent that can allow you to
assess the complexity of a given environment. But you could also start to leverage it for
creating new environments either in the studio or from the game itself. Am I hearing that?
From the game itself, yeah. And I think this is for us a tool that could be used in different ways.
I mean, you can imagine that this could eventually be a stepping stone into real game AI where you
start to sort of adapt the environment towards the actual player and how the player plays the games.
So you get a better gaming experience out of that. But you can also eventually think that this
could be put into the tools when you create games. So if you put this agents into the editor,
you can test sort of the map for or the environment in real time. So if you put two things to
far apart, the agent will tell, well, I will never be able to jump from this to that. But then you
can just in the editor, put them a bit together. And then you see, well, then you have a map that
works. So you don't even have to test it eventually. Besides one of the things that we talked about
this far, there are other aspects of using RL for game testing that you've kind of learned along
the way. I'm curious about the practicalities of trying to apply RL in the ways that you
are and are there, you know, their particular kind of, you know, lessons earned or tricks that
you've come across or anything that will be worth sharing there. I think, and I heard that on
the podcast here before, I mean, if you relate to self-driving cars a bit, there is one thing to
test things in the lab or in an experiment. But then, of course, how you deploy it in the real world
is very different. And of course, a game doesn't need to be bulletproof as a car or a self-driving
car, but this should still work. I mean, the games are used by millions and millions of users,
and they will find all kinds of bugs and problems in there, for sure. So the games need to be very
robust and very functional. And also here, more to that, that some of these techniques are still a
bit controversial, I would almost say, among game designers, because you don't really know what
you get. I mean, AI is still much a black box. So if you train a model of some kind,
you need to make sure that there is a way for a game designer or a tech artist that work with
his assets or content that they could sort of add their flavor to it, and they could feel that
they could control this, because getting to the game experience, it's a delicate piece of art,
actually, to make games that feels good and are playable and are fun. And I think if you introduce
a lot of AI things that kind of work, but still doesn't really behave as you think they should,
I think that could rather ruin the game experience than add to it. So this is something that
we need to work a lot more on how to kind of be able to control this AI agent or do its models
and adapt them to different sort of context and usage. Beyond the work in reinforcement learning,
you've also done some work in the application of CNNs to detecting glitches in games.
Yeah, a little bit about that work. What is a glitch in the context? A glitch is,
well, a glitch could be many different things. I mean, low level glitches are problems
in the hardware or in the drivers. So suddenly you get the white space or a white screen or
something like that. But then you have a lot of other kinds of glitches. Typically, it's more
that when you create these games, there's tons of content and assets. And someone just forget
to put the texture on something somewhere. So we started to then look into, okay, how could we use
in reinforcement learning agent to kind of more walk around in the space to, yeah, look if everything
looks okay or not. And then on top of that, that's kind of then fairly straightforward to use
like a competition detector of some kind to detect when you get these glitches like a missing
texture or something like that. And this is also something that is taking a considerable
amount of time when we test the games. Because the games are huge and it takes a lot of time and
a lot of man hours to sit and look through this kind of walkthroughs that we create over the games.
So to be a little bit more concrete, it sounds like maybe an application of the work that we've
talked about previously where maybe you've got this curiosity driven agent. But now the agent
ends up in a position and a particular orientation. And you are able to capture an image from what it
sees and then feed that into a CNN that's maybe, is it a classifier like glitch no glitch?
Well, depending on the game and depending on how we trained, of course. But it's basically a
classical classifier. And you also get a confidence score. So you kind of know how like
accurate the detection is. And then you flag this and then you kind of walk around and find
these glitches in to get the game. But then again, I mean, it depends on the game. I mean,
the games are different. I mean, if you take some of the more open world games, there is a lot of like
assets like houses, trees, I mean, all of that cars. But if you think about the sport games,
there is other kinds of textures that you really need would like to have there. I mean,
if you have longer types into the games, the closing and so on. And then you train the model
for that kind of game. And you mentioned all these different classes of
textures and things that you didn't insert into a game. Are you
to what is your, I'm trying to think about if your model is looking for those things specifically,
is it some kind of hierarchical model? Or is it just kind of looking broadly at an entire image?
And just based on the training data looking for, for these glitches.
Now, it's more looking broadly for glitches in general into the scene. So you have a specific
camera position. And you change this camera position throughout the object. And you rotate around
the object. You walk around taking different scenes. And that is then how you kind of detect this
missing the textures or the glitches in the pictures. And in terms of your training data for that,
do you have a historical database of glitches? Or I imagine there's a huge opportunity here to
do synthetic data creation, creating artificial glitches or something like that.
Where does the training data come from? I guess that's one of the upside of working at EA
and work within the company. Because we have tons of data. We have tons of data from the game
teams. We have tons of data from game tests. So there is a rich set of data that we can train for.
But of course, we need to label them. And so forth. So in that case, we also annotate and synthetically
generate glitches of various kinds. So we can train a better model, simply that perform better.
So it's a bit of a mix there, actually. So we start with like what kind of glitches are
typically encountered into the games. And then we augment them and sort of build up our data.
That's because in the end, when you train this model, if there should be reliable,
you need quite a lot of data now.
Where do you see AI going in games? I think AI will go into the games in a multitude of ways.
Like we talked quite a lot about here today, in how we create the games, how we create the assets,
how we create the worlds, how we create the behaviors, how we create, if you look into games,
that there is so many things, animations, speech, et cetera, that you can create with AI.
But then eventually, we will more and more look into how AI could will be used in the games.
And how it also could drive the game experience in different ways.
You can imagine, for example, you introduce some AI physics. So you can create a bit more
believable worlds by the parts of this that is driven by an AI model instead.
And there is other things like that you can do into the games. You can, like we talked a bit
earlier about, you can test assets as they are used in the games. So if you have
user-generated content of some kind, that's of course not possible to test beforehand.
But then you can check whether this asset or this kind of thing that someone has created
works in the game. And you can help the user then to create a piece of content that actually
do work in the game. I think that is also a very interesting kind of future challenge to look into.
Awesome. Well, Conrad, thanks so much for joining us. It's great hearing a little bit about what
you're working on there at EA and KTH and looking forward to kind of learning more as you continue
to push forward in this area. Thanks for having me, Sam.
