you need to find a way to translate, you know, the computational insight into the
language of chemistry or biology, which kind of means you need to know chemistry and biology
and draw discovery in addition to knowing the AI.
All right, everyone. I am here with Barat Rumsunder. Barat is founder and CEO at DeepFar
Sciences. Barat, welcome to the Twomo AI podcast.
Thank you for having me on, Sam. Excited to be here.
It's great to have you on the show and I'm looking forward to digging in and talking a little bit
about your work on deep learning for molecular design to get us started once you share a little
bit about your background and what kind of caught your interest about that field.
Yeah, for sure. So a little bit of background about me, I did my PhD at Stanford a few years ago,
worked with VJ Pandey's group at the time. So my, you know, training before then I had been as
a software engineer and pure math person. So I was really, you know, when I started at Stanford,
I kept passing these posters and all that had all these crazy pictures and molecules on them outside
VJ's lab. So I kind of went in one day and was like, oh, let me just talk to these people and
ended up clicking. So we decided to work together. A lot of the work I did there was in applying to say
my previous background, working with software engineering and mathematics to the problem of
molecular design and drug discovery. So I started an open source framework called DeepKem that has
grown since I think we're now probably one of the most popular open source platforms for drug
discovery out there. I also started a benchmark suite called molecule net which helped establish
standard benchmarks for designing new molecular algorithms. That's been widely used in academia and
in the industry. Since then after leaving Stanford, I co-founded a startup in the crypto space.
I worked on that for a couple years but then decided to come back to working on biotech and medicine
discoveries. So the last few years I've been working with different biotech and pharma companies
on getting AI into their drug discovery process. So that's kind of the the heart of my new company
Deep4 sciences. Awesome. Awesome. What do you see as some of the big challenges that the drug discovery
companies are having as they try to incorporate AI into that process? That's it's a great question.
I think there's a whole range of issues like starting at the very basic. Oftentimes IT setup
is not, you know, unable to handle this. You have to think about, all right, do we get up on
cloud? Many companies are transitioning to cloud so that partly is starting to be taken care of
but it's not a core competency. I think in many of these firms, you often see like external
consultants who are running the IT. So it can be an early situation. Other things I would say,
there's just I think things like pay scale and miscaps between, you'll see very talented senior
biologists getting paid less than a fairly junior developer would make at a tech company,
which it's a it's a hard problem. So I think attracting talent, there's a good sound that you're
working on what you could say are arguably more meaningful challenges trying to find medicine,
but you also have to make that make greater sense for people. So I think a lot of these firms
are still struggling to hire and build out their top tier AI talent. And I think that this will
eventually begin to find a medium ground, but for now I have several friends who are all looking
for basically the same type of candidate and they're also looking as far as I know. So it's
definitely a challenge there, but university programs are starting to pick up the slack. I'd say
other challenges. It's, you know, how do you mesh in these systems in well with human scientists?
So I would say the AI is not a replacement for an expert human team by any means, but you need
to find ways to have the human teams and the scientific teams work together in a complementary
fashion. This can be really hard. Like as I'm sure you've heard from your other data scientist,
a guest like it's a state communication problem, you know, the computational insight into the
language of chemistry or biology, which kind of means you need to know chemistry and biology
and drug discovery in addition to knowing the AI, which makes us a bit of a hard feel to get into.
But I think it's worth it. I think it's been a lot of fun.
At the highest level, the promise of AI for drug discovery is just that that some AI will be
able to spit out drugs for us that are effective at solving medical challenges. Tell us a little bit
about, you know, at a lower level of granularity. Like where is the innovation frontier now? And
if all goes right in efforts like yours, you know, what's the promise for AI in the near term
in this field? It's a great question. And I would say divide this field into two parts.
The first I would say is machine learning for chemistry. And the second is machine learning
for biology. I think machine learning for chemistry has made a lot of strides. Like you see,
like a lot of top-tier conferences, like I clear recently announced they had a
ML for drug discovery and molecules. Track on Europe's has had a standalone workshop for a few years.
I think that there's a lot of open packages like DeepCam. There's DGL Life Sciences from Amazon.
And a few others that really have started to support this field. I would say there's still
challenges in generating molecules effectively, but say predicting properties in molecules,
say analogous to predicting properties of images. Is there all to solve task? But it's an
increasingly straightforward task. The challenge I think is still working at the low data setting.
So unlike other parts of the tech industry, you can't have human annotators create data.
You need to have some type of experimental output actually coming from either a trained lab tech
or robot that's been very properly configured. So we're figuring out how to get
transfer learning working, how to get low data methods, meta-learning. Working I think is
the real frontier. Lots of cool papers like people learning things like contrasts of learning,
looking at the 3D structure, using transformers. There's a whole range of papers that are exploring
this. But I'd say that's the frontier right now. The basics work, but how do we make this work in
like practical settings where there's a lot much data. The secondary machine learning for biology,
I think, is much more mysterious. I would have said that there weren't really any successes until
deep-mind announced alpha-folds too. Alpha-fold 2 is really, I think, made a dramatic difference
in this field where you've taken, I'd say, a fundamental problem of biology, you know,
predicting the structure of proteins. And this has been open for about 50, 60 years now.
And been able to push that into a place where you could argue it's even solved. I think this
just really had a sea change in how scientists and biologists see AI methods. Whereas before,
it was something that was kind of exotic and, well, that doesn't really work. Now it's like,
oh, okay, they just whacked this problem out of the ballpark. We need to pay attention.
But besides that one place, I would say that AI and bios still very early stage. To give an
example of the fundamental challenge, like take a disease like Alzheimer's. The what you hope
the AI would tell you is that, okay, the root cause of Alzheimer's is X. So you just need to
design a molecule that modulates X somehow. Then bam, you'll cure Alzheimer's. We wish we knew that,
but then we see all these failed clinical trials for Alzheimer's because that's an extraordinarily
difficult problem. You're trying to untangle, you know, the history of evolution itself in the human
body. So it's going very deep to the heart of medicine, I would say. And that's beyond today's AI.
I think the best we can hope is to create better tools that make our best doctors and biologists
more capable of handling these problems. So I'd say ML for chemistry much further along,
closer to where, say, things like images are, ML for biology, fundamental science. I think
it's a open field and just beginning to be explored. Got it. Got it. Tell us about the origins of
deep chem. Yeah, absolutely. So back during my PhD, I was fortunate enough to do an internship
with the Google accelerated scientists team at Google. So we use a early version of their
internal AI system called disbelief. This is a pre-tensor flow system. And we built I think a
really cool model and explored, say, large scale training on a bunch of data we gathered to do a
multitask deep learning in the system. And this worked pretty well. And I was really excited. We got
a paper out. We had it written up in the Google blog. A lot of people are excited. But as with all
good things and the internship ended, I came back to grad school and it's like, oh, well, what's I
don't have my core research discovery to work with. So at the time, Kyrsten Tionno just really
started to come online. So I hacked together a few scripts to try to replicate the original paper.
I got most of the way and wanted to share it with some friends. We just put it up on I just put
it up on GitHub. And from there, it's sort of grown organically. So we attracted a few talented
early contributors. We made the licensing permissive MIT rather than a more restrictive license.
So we had some early corporate contributors come in really help out a number of grad students
put projects and papers into there. We're also I think fortunate enough to be able to participate
in Google Summer of Code through the Open Chemistry collaboration. We've been participating
in Google Summer of Code. I think for three years now, had a number of excellent students.
One of the big things that we've done is program allows students to come work on your open source
project. Yes, that's correct. And Google will pay them for their time, which I think is
a tremendous advance. You see all these kids who couldn't otherwise like participating in open
source. One of the nice things we've grown is really a community of, you know, teaching and
documentation. So we have about 30 tutorials really laying out the basics of the science.
Also on the way, we ended up writing a book with O'Reilly deep learning for the life sciences,
which introduces a lot of the techniques in this field and how to use deep Ken with them.
So I think we've tried to put a lot of effort into growing a friendly collaborative open
community. And I think that's really drawn people to work with us. A lot of the people who do AI
in this industry, they often get, I think, their first taste of AI in this field through deep
Ken. So I think that's something we want to do more of. So we continue working on it. We just had
a new release come out last week. We had 29 contributors on this release. So we've got a,
I think a vibrant open source community that's working to really build out better tools.
And what are the specific problems that deep Ken solves for practitioners working in the field?
So I think one of the big things that deep Ken does is we effectively serve as a model
zoo slash repository. So we take a lot of these models that come out in the literature,
you know, academics do great work. They invent a new technique. They put it up on GitHub. It's
pretty clean code. But you're not incentivized really to go further beyond that. That's sort of where
we come in. We say, okay, well, we need unit tests. We need to stabilize this. We need to make
sure that this can be maintained. So we wire it into our CI system. We get test put up. We get
now type checks. We get to everything linted. And at the end, we have a stable implementation of
the model. And we have an extensive CI that tests, you know, Windows, Mac, Linux, there's about
600 700 unit tests, a lot of testing on machine learning. How to stabilize machine learning methods?
So we have a robust production grade implementation that can then be used by downstream industry
and also academic practitioners. So we see ourselves as, you know, picking up from where
academia often leaves off. We do have a number of students also interested in designing new models
of their own. So we do have research collaborations with academics. But I think our mission really is
service a high quality repository of good good models and techniques. What are some of the most
popular models today on DeepCam? I would say the most popular historically has been the Graph
Convolution Network. So we had, I think, one of the first quality implementations of a Graph Convolution
Network for molecules. This was before PyTorch Geometric and DGL. In the last few years,
we've increasingly shifted to using DGL and and PyTorch Geometric to underpin our Graph Convolution.
So we have an extensive collection still, but a lot of them are, say, rappers or extensions
around these other frameworks. More recently, I think we've been expanding into, we have a number
of new models, say, at the frontier and material science. People there are just really beginning to
embrace the deep learning mindset. So some newer models there, as I was talking to students this
morning, who's adding a Graph Convolution variant for predicting material structure this morning.
Another frontier, I think, is actually solving partial differential equations. So the PDEs,
as I recall, they're just critical in many fields of engineering and physics. Let's you solve
these complicated systems. So we had a very talented Google Summer of Code student this summer.
Add in a first deep learning PDE solver. It's called the Physics Inspire Neural Network.
It's still very alpha. I think the API needs a lot of work, but it's a great proof of concept.
And the dream of this entire field is, can you solve these high-dimensional PDEs,
I was talking to some engineers at GM a while back. And it takes them, I think, 18 hours to be
able to solve the fluid flow equations around like a car structure. And they can't really do iterative
design. Whereas if you had a fast approximate solver, you could potentially try out these radical
designs. Click a button and have the model give you approximate answer in 30 seconds and then
just keep designing. When these tools mature, I think they'll enable these types of radical
innovations, but that's probably several years off. There's a lot of fundamental work. So
we see our role as continuing to maintain the core, keep it stable for production use,
but also grow out at the frontiers, adding new scientific models and areas.
What's the relationship between DeepCam as a repository and DeepCam as an API? When describing DeepCam,
you describe primarily this model repository, but those models are built using a DeepCam library.
Can you talk a little bit about the library and the capabilities that enables and
my folks use it as opposed to other lower level libraries?
Oh, yes, that's an excellent question. So the DeepCam library itself is, say,
designed to be one level higher up than, say, the underlying tools like PyTorch or TensorFlow.
So for PyTorch or TensorFlow, you often, say, don't know about scientific file formats.
You don't know about how to featureize scientific data sets in a meaningful fashion.
Molecular data sets come in a hole. The prominent open source package that loads these
file formats is called Bable. That should give you some idea of the diversity of formats that
just kind of rest out there. You need to be able to slurp in all these formats. You need to be able
to transform them into either vectors or graphs that you can use in machine learning.
Oftentimes, there are various scientific transformations. You need to apply maybe
types of normalization. There are metrics that you often use to measure these models that,
again, require you to be scientifically aware rather than using it out of the box metric.
So I think where we see a role is coming in is trying to provide these scientifically aware
layer on top. So our goal really is not to try to reinvent the wheel. If something's in
PyTorch geometric or PyTorch or what have you, we just kind of use that very happily.
And part of our extensive collection of tutorials is walking through how do you use DeepCam
with X other library. But there are just cases where something doesn't make sense for the broader.
There's some, what is relatively niche to the broader world way of processing molecules,
but for us is really interesting. That goes in DeepCam. Because that's part of our core mission
or the same for a material. So it really is like, I think the dividing line is,
this is scientific AI tool. And second, is there, if there is already a high-quality open-source
package and community that maintains this, can we just use them? And if the answer to both of
these questions comes out, then we added to DeepCam. Otherwise, we say, hey, why not add a
tutorial that teaches you how to use DeepCam with this other tool to be able to do this right way?
One of the interesting conversations we've been having on the podcast recently,
primarily in the context of reflections on the past year in different areas within machine learning
is kind of this maturing of the field. For example, in natural language processing,
there are so many models off the shelf that a practitioner can take without having to
create a new architecture, for example. And I'm curious about that the state of the field with
regard to molecular design, it sounds like by virtue of the fact that you are primarily offering
a repository, there's a great opportunity for reuse. But I'm wondering if you can elaborate on
kind of this innovation frontier or the extent to which new problems that people want to solve
are solved best by kind of fundamentally pushing machine learning or taking things off the shelf
and implementing them and applying them to their data. How do you see that evolving now for
DeepCam and the molecular design field? This is a great question and something we've been actively
researching for a few years now. So we have this open source consortium within DeepCam,
like a subgroup that works on a series of models called Converta. So Converta is, as you might
guess, a variant. It is a type of transformer. We trained a model on a number of smile strings,
which is the textual representation of a molecule. And you just kind of use a standard NLP style
technique. So Converta one was intriguing, but not really performant, didn't really match the
standard methods out there. We just very recently at the Alice machine learning from molecules
workshop in December put out Converta 2. Converta 2 is now, I would say comparable with the latest
graph convolutional methods, but it's a lot of work and it gets close to the same results,
so I think we have a ways to go. So all the Converta models, we've actually put them up on the
Hugging Face model hub, so you can download those, I think they've been used by actually a
pretty large community people. This is all in the DeepCam org within Hugging Face.
So we do think this is an area where there's going to be major growth. So far, what I would say is
that we are less mature than, say, for natural language processing, things don't work out at the box.
We hope that when we knock on what get Converta 3 out there, maybe that'll take one more step
towards making this a general purpose technology, but as of now, I think it's a cool research
direction. We spent a lot of time thinking about it. We have a very nice team with kind of researchers
who work with DeepCam and also Revery Labs and UC Berkeley and a couple other places
who've been partnering with us. But for now, we hope to see the Hugging Face style off the shelf
models, but we've not yet gotten that to work, where we were able to recommend that. Whereas the
GraphCon, Lusional Methods are always in this field, the random forest, you know, just sometimes
you pull it off, it just works great. I think we'll get there a few more years.
In addition to DeepCam, you've also worked on a molecule net, which is a data set and a benchmark
suite around molecular design. Can you talk a little bit about that in its origins?
Yep, for sure. So, you know, going back to when we started this DeepCam project,
we put kind of these methods out there, and there are a bunch of new methods starting to come
online. And the question naturally was, you know, how do we compare these methods against each other?
So for a long time, I'd been, you know, inspired really by ImageNet. So I was at Stanford at the time,
I kind of joined, right as the ImageNet paper came out. And I could just see the transformative
impact it had on image processing algorithms. So I'd had this vision of, you know, let's try to
do something similar for molecules. And DeepCam provided a platform. So I partnered with
a kind of very talented other student, Michael. He and I put together the kind of core of molecule
net. So we implemented about, say, 15 algorithms in DeepCam that were prominent in the community
at the time. We added about 15 data sets. We ran that matrix roughly of a lot of experiments
right there. We burned up some of the clusters for a while. And yeah, we tried to put out, I think,
quality benchmarks. And we had recommendations on how do you do a trained valid test split,
and that's chemically aware. And I think it's seen a lot of uptake by the community. I'd say it's
also, you know, it's been a few years, like four years at this point, I think, since we put out
the paper. So starting to show its age a little bit, there's a couple of really cool projects.
There's a therapeutic data commons now that MIT has just put out that extends molecule net with
a number of new new data sets that they've gathered and curated. We are working to extend molecule
net ourselves. We have a successor project that's slowly winding its way out the door and that
knock on wood. Maybe this year we'll get out the door for lucky. But we have integrated
molecule net from the earliest days into DeepCam. So the way a lot of people get access to the
data that they do, you know, input DeepCam and the DeepCam.MoleCulnet.loadX4X is whatever data set.
This is kind of modeled on the psychic learn integrated data sets. So I think that we continue
to support this. We continue to add new data sets. We just added a couple, I think, a couple
months ago. But it's again, it's a long-term effort to try to build out a critical mass of data
that can further the science here. Can you talk a little bit more about developing what you
described as a chemistry-aware validation process? So this is a great question. So oftentimes in
well, at least in the earlier papers on machine learning, you do something like a random split
of your data. And this is mostly fine when you're building kind of toy models. But the downside is
in the real world this often doesn't generalize. To use an example from self-driving car world,
it's really the long tail of a squadron of geese fly across the road. Was that in the training
data? Probably not. But you want to test really on the crazy examples. It's something similar
molecules. You're most interested in predicting the structure of molecules that you haven't seen.
So what you want to do is when doing train valid tests, you often want to do a splitting of the data
where the validation and test sets are drawn from chemical scaffolds, as the term is,
that are far away from the scaffolds that you saw in training. And this gives you a better
estimation of the true generalizability of the model. So one of the things we did in molecules
is probably one of the most used parts of deep chemists. We introduced something called the scaffolds
butter. This wrapped the an existing algorithm by Beemis and Mirko. And that was in the Ardekin
library, put it in a nice usable format for people. So I think this is one of our, you know,
little bit, a little part of the project, but maybe one of the most used pieces actually.
So there was an existing library that allowed you to
compare the scaffolds for different molecules and you were able to use that as part of
creating test transplants. Yep. And I think I would definitely give a shout out to Ardekin,
which I think is probably the foundational open project in chemo and formatics. So they kind
of established the machinery that made it possible for us to build on them. They're
probably one of the most important scientific projects that you may or may not have heard of.
So they're a really cool project. I recommend checking them out.
Nice. Nice. Yeah. As deep learning is maturing, you know, a few years ago,
a lot of scientific papers were, hey, I heard about this machine learning thing. I'm going to
throw it at my problem and see what happens. You know, the field has been maturing quite a bit.
And we've got libraries like yours that are able to aid researchers and practitioners.
I'm wondering if you can talk a little bit about, you know, broadly how you see machine learning
and the traditional sciences and what you see the future is there. How does it evolve?
I would say that, you know, probably the biggest shift is going to be that most scientists will
probably want to do some machine learning coursework as part of their core training.
So I think as these tools become more and more established, it'll be just a core part of the
scientific toolkit that new scientists have to learn. I'd say increasingly, what I see now is that
there's a lot more creativity in terms of like, okay, we've got the basics down. So the paper isn't
just, you know, take off the shelf thing and apply it here and see what happens, which is a lot of fun.
I think you could sometimes get some real surprises that way, but now you know the basics,
people have written about it. So what do you do that's creative? So I think at times you actually
see these very innovative applications. You know, I would say that one of the areas I'm most interested
in right now as a researcher is the application of deep learning to solving partial differential
equations. And these are, you know, foundational mathematical tools, I think from the 1800s or
even earlier, you could argue. And but the challenges have been we've only really been able to solve
them in relatively restricted cases. Like in the 70s, under these class of algorithms called finite
element methods, that this is what really underpins I think a lot of CAD and other modeling tools and
really pushed the field forward. But we might now be seeing the second revolution where through
these deep learning methods. And the big shift I think is that these earlier class of techniques,
you often had to put down what's called a mesh. So let's say I have a complicated car, you need
to basically, you know, drop grid points on your car and your computer model. So you can like model,
you know, the airflow at that point. Whereas with the deep net, you can now do what's called a mesh
free method. You can just say, Oh, well, I'm not going to worry about that. I'll just have my deep net
approximated. I'll give me your data. Now, there's still a lot of caveats here. I think this is a
new technique. But I think that it's one of the more exciting things. And it's because you have to
really understand the math and the physics of these systems in addition to the deep learning.
That's where I think you begin to see real scientific creativity. I think so. I think there's like,
you know, a long tail of like really cool innovations. But you, it requires people to understand
both sides, you know, it's all enough to just be a, you know, numerical analyst or a machine learning
person or, you know, a car designer, you kind of have to have someone in the room who does all,
uh, each of these things are all of these things. So your company deep forest sciences started out as
vehicle for doing some consulting with the drug discovery companies, but you're moving in the
direction of productization. Can you talk a little bit more about your vision for the company
and your offerings? Yeah, for sure. So, uh, basically a few years ago, I started almost my
happenstance consulting for a few friends who were working. I was like, well, there's all these
open tools. You really need me to come in and help you. And they're like, yes, I was like, okay,
sure. Why not? I've just left my previous company. Then over time, I think it's grown into a
realization there are the systematic challenges, I think, in applying AI to these problems.
One of the biggest challenges I think is that in drug discovery at the end of the day, like,
you as a company in response over putting out a medicine. That's what your stockholders are
therefore. That's what the market rewards or punishes you for. So the amount of time you can
afford as an organization to really put into building world quality software, world class
software is limited. And it should be because that's not what your market is. So I think there's
a niche to really build out quality AI software and partner with companies and let them do what they
are the best at, which is trying to find new medicine and, you know, work with us to help solve
the hard AI problems we have. So we have built a system that we call internally Kyron. It builds
on deep chem. And, you know, we continue to support and help grow the deep chem community.
But we've also, I think, made some extensions to it that I think make it more useful for our
partners. And we're able to take this technology and work with a drug discovery company who's
say, got a therapeutic hypothesis to really passionate about. But maybe they don't really have
the expertise in house to really throw the kitchen sink at it and figure out what all these AI
techniques can do. There's just a dizzying area of things you can do these days, especially
to feel this grown. That's where we come in. Like we have kind of the extensive capabilities of
deep chem. We have Kyron built on top of that. We've worked with many different companies at this
point. We bring that expertise. So you can focus on the biology, the hard problems of human medicine,
discovery, and we can focus on the AI and we can help you get where you need to be. So that's
the vision of the company in our shell. Well, I wish you the best of luck with the company and
thanks so much for taking the time to share a little bit about what you've been up to. Any time,
that's my pleasure and I had a lot of fun.
