Welcome to the Twimal AI Podcast.
I'm your host Sam Charrington.
Hey what's up everyone?
Happy New Year and Happy New Decade.
I am pumped to get 2020 kicked off by announcing a couple of new educational collaborations
to add to our current array of Twimal community programs.
The first of these starts next week.
We are super excited to be collaborating with research scientist and instructor Robert
Ness to bring his core sequence, causal modeling and machine learning to the Twimal community.
Cosality has become a very hot topic in the ML&A eye space, but there are relatively few
instructional resources geared towards data scientists and ML developers.
Furthermore, this is the first time we'll have the opportunity to host a course instructor
leading a study group on our platform so this group should be a ton of fun.
The study group will meet at 8 a.m. U.S. Pacific time on Saturdays and to get things kicked
off, Robert and I are hosting an overview session next Saturday, February 1st at that time.
Know how topic in our community is ML&A eye platforms and more broadly, strategies for
efficiently developing and deploying machine learning and deep learning models inside
the enterprise.
I've hinted at this next study group before and I'm mentioning it again now since we're
getting close.
I've partnered with IBM to bring the new IBM AI enterprise workflow specialization,
a six course certificate granting sequence recently published on Coursera to you, our
community.
I'll personally be taking this course sequence and hosting a study group for those of you
who'd like to join me.
If you're doing interested in or would like to learn more about data science, ML or AI
in a real world enterprise context, I'd encourage you to check this one out.
I'll be hosting an informational session on the course in early February.
For more information on or to join either of these programs, visit twimmelai.com slash
learn 2020.
And now on to the show.
Hey everyone, I am here in Vancouver for NERPs continuing our conversations with some
of the researchers that are at and participating in this amazing conference.
And I've got the pleasure of being seated with Janis Bourne.
Janis is a PhD student at ETH in Zurich and the IBM research in Zurich.
Janis, welcome to the twimmelai podcast.
Thank you so much Sam for having me.
Why don't we start out by having you share a little bit about your background.
You're coming at things from a cognitive science perspective, but your poster here is
on reinforcement learning.
How did you get interested in this field and how do all those threads come together?
Right.
Yes.
So you're right.
I'm having a background in cognitive science and in computation in your science.
And so I've been like focusing on brain research for my past five years of education.
And now recently I've been doing more work on computational systems biology and specifically
on cancer and cancer trying to understand mechanisms of how cancer work and how we can
find new treatments against cancer specifically.
And in this work, I've been using mostly deep learning techniques and this will be part
of like my presentation here at this conference also.
And so yeah, so how do those things go together?
So I think like many people think it's in a way weird if you come from brain sciences and
then you're going to machine learning, right?
And this is something where I would say it's like it's a very obvious thing to do in
a way because if you look back into the history of machine learning, where it all came from,
like mecaloch and pits, the first artificial neuron and then a few years later, Frank
Rosen, Bella, the perceptron.
And so these were all computational neuroscientists and they were in the end really trying to understand
how the brain works.
And they basically developed the the the fundament of the field of machine learning.
And so at some point this community then in a way, it split up into two groups.
And one group was more trying to actually understanding how the brain works.
And the other group was more interested in solving the problems, right?
And from this from this community, the machine learning community evolved into, but where
is computation neuroscience right now, it's still a field, it's still out there.
It's has been it's separating more and more from the machine learning community.
I'm still out there and originally it has been one big community.
And so therefore, I think it's quite natural to have this process.
Yeah.
Yeah, I think particularly here at NURBS, I have the opportunity to speak with many folks
that are kind of working on that edge of cognitive sciences, brain sciences, and both using
that to inform the way we think about machine learning, using machine learning to validate
some of the biological theories.
It was maybe more novel is coming from cognitive science and brain science and applying machine
learning to developing cancer pharmaceuticals, how did that come about?
Yeah.
How did that come about?
It's a good question.
So like if you look at brain sciences, there's really this problem of seeing the brain,
which is arguably the most complex thing we have in the universe, and seeing like observing
this brain and trying to understand this brain from a different like scales, a different
spatial scale, so to speak.
So you can think about the brain in a very abstract and cognitive ways, thinking about
cognitive phenomena like language and memory and those things.
And you can think about it more from a neural perspective, like how do actually like what
is the most fundamental unit of information processing?
How do these units interact?
How does information arise?
And so like these are two fundamentally different approaches.
And so I like in the first three years of my studies, I focused on cognitive science,
which has more this top down approach, like thinking from the big concepts and then down
towards the implementation level.
Whereas computational neuroscience, they have more like this bottom up perspective.
In the end, they're trying to solve the same problems, but they start first with the basic
building blocks, like having a biologically plausible neural network model that imitates
basic behavior of neurons and then they try to scale it up in order to understand more
complex cognitive phenomena.
And so like these two fields, they really, they help each other and they need to work
together in order to understand how the brain works.
And so after my undergrad studies, I really had the feeling, okay, I need something more
solid.
And I really wanted to have this bottom up perspective from a computer competition in
your science, which then I got in my masters.
And so afterwards, I mean, I had to say that I was keen to explore applications of machine
learning, because while I mean while studying the brain, I got really interested more and
more into the whole field of data science and machine learning, and I wanted to apply
those techniques, but at the same time, I wanted to, I wanted to still somehow work with
a human body and with humans in general.
So this is how, yeah, how I came about doing cancer, cancer drug modeling.
And so the, the poster is titled Pac-Man, yeah, tell us about Pac-Man, yeah.
So Pac-Man is a frame, I mean, it's an acronym.
So spelled with a double C and double N. So it's an acronym.
We came up during my, like about a year ago, during my master thesis, for a prediction
of anti-cancer compound sensitivity with multimodal attention-based neural networks.
And so like when my supervisor came about with this acronym at one of the very long nights,
we spent in the lab, we like, okay, there's no discussion.
This is going to be the name for the project.
So quite funny how, how this came about.
So, and we, what we're doing in this work, that was the first step of, of the project
I'm presenting here at the conference, we were trying to basically forecast the effect,
the inhibitory effect of a molecule against a specific type of cancer.
And so we are treating this problem of predicting cancer drug sensitivity really as the
property of a pair.
And the pair is like composed of the molecule itself, the chemical, the drug that you give
to the patient.
And then the particular tumor cell that you want to target.
Because cancer is really like, I mean, it's a family of diseases.
And it is so diverse.
I mean, there has probably never been two types of cancer that have been exactly alike.
Because the cascades of mutations you have, they vary like heavily in between of every
individual patients.
So it's really unfeasible to try to investigate whether a molecule has some anti-cancer effect
in general.
So you really need to treat this problem as the property of a pair.
So is this drug like has it inhibitory effect against the specific type of cancer in the
patient individually?
One of the questions that comes up first for me is one of the techniques you're applying
here is reinforcement learning.
How does that play into achieving that goal?
So it comes about in the second step.
So the first step was really just trying to predict the sensitivity.
So the efficacy of this of a drug.
And so what we did in a consecutive step after we had built this model, what we asked ourselves
was like, wow, wouldn't it be amazing to have a model that can generate new drugs?
And that can come up and propose new anti-cancer candidate drugs.
Because in the whole pharmaceutical industry, there's a huge productivity decline in the
last few decades and the estimated costs that you have per new drug, they're estimated to
be 2 to 3 billion USD.
And most of these drugs that are then FDA approved and approved on the market, so they're
really specific only for very few types of diseases or even one disease only.
So the cost in R&D that go our, like, spend in this business, it's just huge.
And so we, I mean, we came up with this framework where reinforcement learning is really
core and component, where we're trying to design anti-cancer drugs specifically for individual
patients or groups of patients.
So we're trying to envision a precision medicine perspective here, where we're not trying
to generically come up with new anti-cancer candidate drugs.
But we try to, like, in the design process itself, we try to tailor the molecule, the
drug specifically, to the need of the patient himself or herself.
And so for this framework, we use a reinforcement learning machine.
Okay.
You also mentioned in the title of the poster transcriptomic data.
What is transcriptomic data?
Right.
So you can think about transcriptomic data as basically the expression of every single
gene that you have in your body, like you know about the human genome.
And so part of the human genome encode for specific proteins.
And these expression of these proteins, you can measure in the cell, there's different
techniques to do that.
So the most commonly used technique and the technique that was used to measure the data
we work with is called RNA sequencing data, where you measure basically the mRNA snippets
in the cell.
And so from this, you can infer basically which genes were expressed to what extent.
So you end up, if you do the sequencing step, you end up with a vector of about 20,000
genes.
And for each gene, you would have an expression value.
This is usually just an integer, like how many times did you find this as the snippet
in the sample?
And then so this vector, you can really think of it as a fingerprint of the cell.
So it's a proper characterization of the cell.
There's a different types of omics data.
So this is transcriptomic data, right?
There's also genomics data, which directly measuring gene data.
And there's also a proteomics data where you actively measuring the proteins.
So the, you know, starting from that first step, you're kind of starting with trying to
predict the effect of a drug on the cell.
Is it, is this a supervised learning type of a problem that you, is that the way you've
framed it?
Yes, yes.
This is supervised learning.
So it's a regression problem in the end.
It's quite simple in the fact that we're really trying to predict a single property.
And this is the IC50 value.
So this is the micro molar concentration of a drug that you need in order to kill 50%
of the cells.
So, and this is the thing you're trying to minimize.
So if you have a smaller concentration of the drug, then this drug is more effective,
right?
So your training data comes from measurements that have been done applying drug, you know,
different types of drugs to different types of cells.
Exactly.
So there's huge databases for, for this problem.
So the two we are working with are GDSC and CCLE.
There's a standard database in the field and they, they usually don't work with patients
directly because you can't try like several hundred drugs on, on the same patient, right?
But they work with them, so called cancer cell lines.
So these are abstractions.
These are cell lines that have been growing in the lab in petri dishes for quite some
time.
And you apply these drugs, I mean, to, to these cancer cell lines.
So these cells have been taken originally at some point from humans, but they have been
growing in the lab for a long time.
And they have been mutations induced downstream.
So they are proxies of real cancer, but it's, I mean, it's an active field of research
to whether or not on to what extent they have problem proxies.
And so in the creation of this data set, somebody carefully administered small quantities of
these drugs and noted the point at which half of the cells were, or just over half of
the cells have died off, and that's the proxy for the efficacy of the drug.
Absolutely, right?
Okay.
And so you, you built a model to predict the performance of new, new arbitrary drugs.
And how do you kind of featureize the drugs?
Right.
So that's a good, it's a good question, because in the end, the drug is immolical, so this
is a graph and graphs are rather difficult to represent in a deep learning regime.
So what traditionally has been done by chemoinformaticians about a few decades ago is they would derive molecular
fingerprints.
These are binary vectors, and in these binary vectors, every item would basically specify
the presence of a certain feature.
And this was completely handcrafted.
So one feature could be like, do I have ax aromatic rings in this molecule or not something
in this?
So, but this is a very arbitrary and handcrafted representation of a molecule.
And the field of deep learning has been moving forward.
So what, I mean, one great thing that deep learning really brought to us is like advances
in natural language processing, right?
So, and a different representation of a molecule can just be a text representation.
So there's certain languages that most commonly use languages called smiles, and smiles
as an in-line notation of molecule, of molecules where you would basically write down and list
of atoms and bonds.
So you basically, you think about the molecule as a graph, and then you do it traverse through
the graph, and you denote step by step the atoms and bonds.
Kind of like a much more rigorous approach to saying H2O for water.
Yes, absolutely.
Okay.
And this is the type of representation we're working with at the moment.
Oh, interesting.
So you've totally skipped the accepted formalism and are primarily working with this natural
language approach.
What's the thinking behind that is that is it that the natural language has more expressiveness
somehow than the binary representation, or is it something else?
So I mean, one thing that's great is that it is much more like it is closer to the actual
representation of the molecule.
It is much easier to understand for any chemist.
Any chemist can look at the smiles notation and can understand the molecule, can draw the
molecule where this does not hold for a fingerprint.
Another advantage of smiles is that it enables data augmentation.
So data augmentation is commonly used everywhere in deep learning, like images, you make rotations
or whatever.
So what you can do is, apparently, if you think of a molecule as a graph, there's not
a single graph traverse, right?
But you can start at different points.
Start at different points.
Exactly.
And then you would get a completely different, not completely different, the atoms and
bonds would be the same, but the ordering would be different and you would get a different
text representation.
Right?
Whereas on the fingerprint, theoretically, they should all resolve to the same fingerprint.
Absolutely.
They do.
They all resolve to the same.
So you have a unique representation for the molecule, in the case of a fingerprint, whereas
in case of a smiles, you can really exploit this smiles augmentation, basically, by exploring
different graph traverse in order to augment the performance of you.
Better generalize.
Yes, it would generalize much better.
And so the advantage of working with text really is also that you can more or less directly
transfer all of the advances of natural language processing, like attention-based models, which
by the way, are absolutely great because they leverage interpretability methods.
So attention, this super commonly used technique in NLP, right, where the model really highlights
only specific parts of the input sequence in order to produce the next output token.
For example, a language translation task, right, or in order to produce a prediction.
And so we can also leverage these techniques into our model.
And this is great because you can understand the reasoning of the model post-talk, basically.
So what we can do with this model is we can understand that the model came to a specific
prediction because it was focusing on a specific substructure of the molecule, right.
And then we can check in the literature, this like a known substructures, it known to have
certain chemical properties.
And in this way, we can validate the performance of the model.
Okay.
Now, others doing similar types of applications have taken, you know, whatever their input
domain is and kind of projected it to like an embedding space and finding related molecules
in that embedding space and then using that to identify candidate, you know, materials,
I think is the example that I'm thinking of.
Is that something that you've looked at as well?
Yes.
So this comes about in the in the drug generation part, which is the second part of the project
that we're trying to design new cancer drugs.
And so what we're doing there is we use a deep generative model, specifically variational
auto encoders.
And what is really awesome, if you're working with variational auto encoders is this property
of the latent space and the fact that like similarity in this latent space, which is
in a way the embedding that you generate for a specific input in our case, a molecule,
that similarity in this in this in this latent space will correspond to a structural similarity
of the molecule, if you decode the points in the latent space.
So this is like the drug molecule in this case, yes, yes.
So I mean, it seems like a supernatural property, right?
You would expect this that similarity in this latent space, although it is hidden somewhere
in the network, it will resemble something meaningful.
But apparently this is not necessarily the case.
So you have to specifically enforce this with a specific constraints that you have to apply
during training this model, but they, and this is like the core property of variational
auto encoders, but this doesn't come along naturally, basically.
It's not for free.
You have to figure out what the relationship is between two drugs that causes them to
have a similar effect on the target molecule, yes, in a way, or the target cell.
Yeah.
So I mean, what you can do, and this would be a pure chemistry model, this doesn't necessarily
need to have anything to do with cancer or with drugs.
It can be the same way for materials, like all kinds of chemicals, basically.
So what you can do, for example, is you have a certain point in the latent space, you decode
a molecule from it.
It is some kind of molecule.
Let's say it's aspirinous, right?
It could be.
So and then you take a different point and you decode from there, and let's say you take
it, you get paracetamol, right?
And then what you can do is you can in the latent space, you can traverse, you can basically
make a walk, like a walk from this point of paracetamol to the point of aspirin.
And you can decode intermediate positions, and you will end up with molecules that are
in a way intermediate mixtures in between of aspirin and paracetamol.
So and this is a super nice property for everybody working in drug discovery, because you can
much better explore the chemical space.
And so this is something that, I mean, it's not obvious, but it is extremely important
to have better models and techniques to explore the chemical space.
The size of the chemical space, it is about 10 to the, it's estimated to be around 10
to the 60 molecules.
So this is massive.
The amount of atoms in the universe, I'm not sure it's like a few orders of magnitude
higher, but it's not crazy.
I don't, I think it's below 10 to the 100, I'm not, I would need to look it up.
But so, and you need to have techniques to navigate this space meanfully, specifically
at a time where, where we have generated and synthesized already so many compounds,
like I think it's in the order of 10 to the nine or 10 to the 10 that have ever been
synthesized and tested, but it is completely unfeasible to just continue like a random sampling
process.
Right.
And therefore, you really need to have this guided, guided sampling and guided navigation.
Kind of going back to that phase two of your project, you are applying, you mentioned
a generational or a generative rather model as kind of an intro to where the reinforcement
learning comes in.
What's the connection between those two?
Yeah, absolutely.
So, this is the part of the project where I'm really most excited about, is about generating
new drugs.
And so not so much the old prediction model that I've been talking about before.
So what we're really trying to do there is that given the transcriptomics profile of
cancer patients, so this kind of theory work in the following way, that you have a medical
doctor making a biopsy from a tumor cell, this biopsy is then sequenced.
You get the gene expression, this is the transcriptomics data.
You put it into the model.
You have a variational autoencoder for this cell profile, so only for the transcriptomics
data.
You encode this transcriptomics data into some latent representation.
And they are in this latent space, you fuse together the chemical, like another variational
autoencoder.
So it's really like a combination of two variational autoencoders.
One is for chemistry, it's just for pure chemistry and molecules.
And the other one is for cell profiles, specifically cancer cell profiles in transcriptomics
data.
You fuse together the latent embeddings of these two models.
And then you decode from there a molecule.
And how you can use this model is really by, you can feed it, a cancer cell profile from
a patient, and it will propose you an anti-cancer drug.
So originally, like in the first place, this will be like a random molecule, but now the
reinforcement learning comes into play, what we can do with this molecule is we can plug
it into the prediction model that we developed in the first step, right?
So in the first step, I said we have this prediction model that takes as two inputs, namely
a molecule, and a cancer cell profile, and it tries to predict the efficacy of a drug,
right?
So it's kind of providing our scoring function for the RL learner.
Absolutely, absolutely.
Okay.
So we use this prediction model to get a reward, and then this reward is used in turn in
order to update the generator.
And then we have a closed loop system, which we can train with a policy gradient and reinforcement
learning techniques.
And then on the long run, we can, and this we've shown quite, quite consistently, we can
like propose molecules that have an higher predicted efficacy, according to our prediction
model.
The two various auto encoders, are those trained independently, or are they trained in
the end somehow?
Yeah.
So they are initially pre-trained completely independently, so you can really thinking
about these auto encoders as learning completely disentangled representation.
So one is really for molecules, just to understand like this smiles language notation, to understand
how chemistry works in a way.
And so the other auto encoder for the transcriptomics data, you can, yeah, so this is just trying
to approximate and learn the space of possible cancer cells, so to speak.
So these are pre-trained independently, and then what we do is really, we, we, like we
think is that second one is it, it's, yeah, so it's creating the representation of the
cancer cells, and then the, there's a decoder step that's taking these two and coming up
with a prediction of the, of a, of a drug molecule.
Yes.
So there's decoder that basically combines the two latent representation of the cell profile
of interest and a drug, and then comes up with a new cancer drug.
So how is this one trained?
So this is trained jointly in this reinforcement learning.
Okay.
So it's part of that reinforcement learning circle, got it?
Yeah.
Absolutely.
So what's important to note here is that it's highly non-trivial, how you combine these
different data modalities, because it, it, it seems extremely arbitrary in a way to,
to fuse latent representations of a molecule with the latent representation of a cancer
cell profile.
What we're doing there, it is, I mean, in a way, it is just the first thing that came to
our mind is we're summing up the latent representations.
But because we're doing this consistently, while we're being in this reinforcement learning
regime, we, we think that we can basically warp this latent space representation from
originally, according structural similarity between molecules, right?
I was talking before in between, like, about morphing aspirin into paracetamol, right?
So we can, like, morph this latent space into encoding functional similarity.
And functional, by functional similarity, I mean different functional pro, like similar
functional properties of the molecule.
So that you have a certain subset of the space, and in this subset of the space, you will
find molecules more frequently that have high predicted anti-cancer effects, basically,
according to our prediction model.
Do you or, have you come across research that looks into the algebraic combinations of
latent spaces and, and how that, you know, what, the, how, what the right intuition is there?
People, you know, how, how much has that been studied?
Have you come across stuff?
I mean, to the best of my knowledge is something that is not very, very actively studied.
So there is a paper from, actually, from Europe's from two years ago called deep sets.
And they are talking about how, how to, how to deal with sets data.
And what they're proposing is, I mean, it's important because this is my second conversation
today where someone said, oh, we just sum up these two latent spaces, and that's what
we use to.
I mean, I was, yes, actually, I was today at a poster session, and I talked to somebody
who was doing exactly the same thing.
And like, I mean, I told them, honestly, this is kind of an arbitrary choice.
I'm doing the very same thing in my work.
I'm just interested.
I do have a better justification for it than I do, right?
So, so, I mean, in a way, what they proposed on this deep sets paper from two years ago,
where they're talking about how to deal with sets and in a deep learning framework is
that you need to have a permutation in variant operation in order to combine sets, because
the thing is with sets, for me, that was the justification that was given to me in the
previous conversation.
Right.
So, it kind of eliminates the role of order in, yeah, the order doesn't play a role.
Right.
So, this holds for many operations, right?
It like, it holds for the, for an averaging for some, for many others.
But so, like, the sum is something that we came up with, and it is an obvious choice.
But, to be honest, I, to me, in a way, it still feels like we're mixing apples and oranges
in bit, and I'm not super satisfied with how we're solving this part of the framework.
Also, losing information in the process.
Just like if you were to do an average, there's, you know, unique information that you're,
that you're just kind of throwing away.
Yeah.
There's information being lost, and there's a, actually, there's a paper also, like, I
saw another paper where they've been at this conference just yesterday, where they've been
looking into different ways of combining latent spaces, and so they, they proposed, I
think, three ways.
One was just like a uniform sampling, so you would basically have a mixture of both.
So you would sample, like, from a uniform distribution between zero and one, and then
you would say, okay, I wait the one representation with 80% the other one with 20, and so I just
have a weighted average, basically.
So another thing they proposed was a Bernoulli distribution, where you would basically pick,
like, the latent representation is it's an embedding of a certain amount of dimension,
right?
It's a vector of a certain length, and then you can say for every dimension, you pick
either one or the other, and you do this important distribution, and then you have a mixed
representation.
Or the third thing they were suggesting is like a learned embedding, basically, where
you have a specific, like, a few deep, a few dense layers of a neural net to learn this
embedding.
So, but still all of these, they didn't seem specifically instructive to me, but rather,
like, okay, you can do it this way or this way, and we can check what works best, and we
see empirically this works best, but it wasn't super, yeah, they didn't provide a, like,
a great justification for it.
But still, I'm curious and to try it out, and this, I will definitely try it out.
Very particularly interesting observations in training the DRL learner to solve this
problem, is it kind of similar, you know, to other use cases, or were there specific things
that you had to do here to get it to converge?
So, it's an actor and critique framework, so to speak, where you have the actor is this
conditional drug generator that comes up with a new compound, and the critique is the
separately pre-trained, this prediction thing.
Running it through this prediction thing.
Exactly.
So, and you can assess other properties of the molecules as well, right?
So, because this, like, predicted property, this ICFIT, it's not the only property qualifying
or disqualifying a molecule for being a drug, so there's also other things, like, water
solubility is something that's extremely important, or...
Will it kill you?
Yeah, yeah.
Or, like, cytotoxicity is a common thing that just, like, you have a drug that is generally
so psychotoxicity will just kill everything, right, and then it doesn't have either, right?
So, and there's many of those things that you really need to incorporate, and then this
reward function for the generator can become very complex, right, because you need to trade
off what is more important, do I wait solubility higher than, like, at, uh, cytotoxicity, or
how about, like, uh, synthesize ability of the molecule, some structures are just extremely
difficult to synthesize, and although you can, like, draw them on the paper, you cannot
really make them chemically in the lab, right?
Yeah.
So, this is another thing, and so...
Presumably, that's all future work, and right now you're focused on performance relative
to this predictor.
Right, so, this has been the first step, just, uh, performance relative to the predictor.
We have the framework now there with all these, like, a panel of critiques, so to speak, to
evaluate other chemical properties.
This is something that is commonly studied, um, or has been commonly studied to, to train
generative models to, um, to come up with a molecule that's full, full specific chemical
criteria, what's really novel about our work is this bridging drug design and systems
biology, basically, where you leverage, um, biomolecular information, in this case of the
cancer cell, into the design process directly, and this is something that, like, has never
been done in any way, and this is what, what distinguishes our work from, from, like,
a lot of what is happening in, in, in, in, in, in, in, in the computational chemistry domain,
and the drug, um, drug discovery domain.
With respect to your previous question about reinforcement learning, so one thing that
happens commonly in generative models is this, this mode collapse, where, um, basically,
you are generating only a single, um, element that can, in a gun setting, for example, can
really fool the discriminator very well, but you lose the variety of the samples that
you're generating.
But this is kind of a form of overfitting.
In a way, absolutely, exactly, because the model in a way it learns, okay, I have this
specific instance and it works super well, so I just always go for this one, right?
Why should I explore something else, right?
And it makes a lot of sense to behave in this way.
Yeah.
And this is something we, we also observed, um, in the fact that, um, the model we had,
it tend to, um, like, produce non-carbon chains.
And for some reason, these carbon chains, they, under some circumstances, had the, the
property of that being having a high predicted efficacy, according to our prediction model,
but still we know that they, they, they can't, they don't really qualify as actual drugs.
And so this was one of the challenges we were facing.
So with respect to the results, what I'm most impressed by when I, when I look at this
and what really surprised me, what I didn't expect when I started working on this is that
the drug, the drugs, the molecule, the model comes up with, they really resemble closest
with the known anti-cancer drugs that are known to work for this type of disease.
So what this means is that we train that generative model to design a new lung cancer drug.
We eventually arrive at a new compound and we check the chemical properties of these compounds
and we see, okay, from all known cancer drugs, we can measure the similarity and we see
it's not most similar to any kind of cancer drug, but it's most similar to known approved
lung cancer drugs.
And we, we have the same result for breast, we generate a new drug against breast cancer,
we, uh, check the database of known cancer drugs, we check which molecules are more similar
by like a nearest neighbor search and we find the nearest neighbors of this new drug cancer,
uh, sorry, new breast cancer drug, uh, actually proved breast cancer drugs and not, and this
is nearest neighbor search in your, uh, latent space or this nearest neighbor's, uh, search
of the fingerprints of these molecules.
Okay.
So because on a, like again, if you take the smiles notation, you cannot really compute
a nearest neighbor in between our packs, right, doesn't make sense. So we compute the
fingerprint first.
Okay.
And then we make a nearest neighbor search there by tiny motor similarity.
This is like the standard metric to use in this case.
Um, and they are, yeah, again, what we find is that the molecules we generate, they seem
to be closest to known cancer drug, cancer drugs that are approved for this specific site
of cancer and not anything else.
And this, in a way, it shows us that we are on the right track and that in a way the
model understands that a lung cancer drug should have different properties to breast cancer
drug.
Nice.
And so in terms of your qualitative results and metrics, how are you approaching that?
This is extremely difficult in the sense that the actual validation for such a framework
is to test it in the way that you synthesize the drugs that the model comes up with.
Right.
You run, you run, you run screening tests and you try to basically start the entire pipeline
of clinical trials.
And this is something we're working on at the moment.
So at IBM, we do have options to synthesize molecules.
And this is something we're starting to do.
But at the moment, we are looking for collaborators when it comes to the experimental validation.
This is a skill and expertise that we do not have in-house.
Also, we don't have the equipment in-house to run these essays.
But therefore, we are, at the moment, we are actively seeking for collaborators to work
with us together to run these drug screening essays to basically, like, in a petri dish
measure, how, what's the efficacy of this drug?
Taking a step back to the evaluation criteria we were discussing earlier, is that something
that is automatable, maybe the better way to ask the question is, in your training loop,
what do you use as, like, a loss function?
So the loss function is, because it's the real problem of the machine.
Right.
Right.
Like, the reward is coming from the prediction model that we have.
Right.
I mean, what Pac-Man really tries to do is, it tries to run this drug screening essay for
you.
Right.
I mean, as opposed to, you have to double do it by hand, right?
Right.
So it's spitting out these candidate drugs that pass its test of, you know, being able
to fool, you know, the, the critic or, you know, pass your predictor model.
And then you're manually kind of comparing these to other known drugs for similar types
of tissue for kind of a qualitative sanity check.
Or has that, have you integrated that into the training process somehow?
Mm-hmm.
In a way that, if you train long enough, you see that the model, like, with a high probability
comes up with a drug that has a high predicted efficacy, which means it passes this drug screening
essay, this virtual drug screening, it performs very well.
And it has chemical properties that are desired, basically.
So it is more or less easy to synthesize it.
It has the right amount of water solubility, all of these properties.
And so, but then what we do is, like, we store those molecules that have basically passed
all of these tests.
And then post-talk what we can do is we can then look at these molecules together with
a chemist and then check whether it is feasible to synthesize them.
And because this is like, I mean, it's another set of problems, like, how do you synthesize
a molecule?
Right.
So there's a whole active field of research on retro synthesis, right?
Just trying to basically decompose the target molecule that you want to have into the reactants
and reagents you need in order to get and arrive at this molecule, right?
And this is like, I mean, it's a huge problem by itself.
So you really need to have this, like, recipe of basic ingredients that you can purchase anywhere
in order to arrive at this new compound that probably has never been synthesized in the
world before.
Awesome, well, Yannis, thanks so much for chatting with me about what you're out to.
Very cool stuff.
Thank you so much.
Appreciate it.
All right, everyone, that's our show for today.
To learn more about today's guests or the topics mentioned in the interview, visit twomelai.com
slash shows.
For more information on either of our new study group offerings, causal modeling and machine
learning or the IBM Enterprise AI workflow, visit twomelai.com slash learn 2020.
Of course, if you like what you hear on the podcast, be sure to subscribe, rate, and
review the show on your favorite pod catcher.
Thanks so much for listening and catch you next time.
