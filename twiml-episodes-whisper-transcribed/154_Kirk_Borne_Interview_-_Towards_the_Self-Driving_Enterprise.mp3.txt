Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
A couple of weeks ago I spent some time at the Pegaworld conference in Las Vegas.
The theme of the conference was automation, particularly in service of the customer experience.
And I had a great time seeing all the advancements coming into this field by way of machine learning
and AI.
In this show, the first of our Pegaworld 2018 series, I'm joined by Kirk Born, principal
data scientist at management consulting firm Booz Allen Hamilton.
In our conversation, Kirk shares his views on automation as it applies to enterprises
and their customers.
We discuss his experiences evangelizing data science within the context of a large organization
and the role of AI in helping organizations achieve automation.
Along the way, Kirk shares a great analogy for intelligent automation comparing it to
an autonomous vehicle.
We cover a ton of ground in this chat, which I think you'll get a kick out of.
Before we jump into the interview, I'd like to send a huge thanks to our friends at Pegasystems
for hosting me at Pegaworld and sponsoring this series.
One of the great announcements coming out of the conference was Pegasystems' new self-optimizing
AI-powered marketing capabilities.
This is a really interesting offering designed to reduce marketers' dependence on traditional
segment-based campaigns and transition them towards real-time one-to-one customer engagement.
These new capabilities will be available as part of their new Pegga Infinity platform,
which was also announced at the event.
For more info on Pegga Infinity, head to pegga.com slash infinity.
All right, let's do it.
All right, everyone.
I am here at Pegaworld in Las Vegas, and I have the distinct pleasure of being seated across
from Kirk Bourne.
Kirk is a principal data scientist at Booz Allen Hamilton.
Kirk, welcome to this week in Machine Learning and AI.
Fantastic.
Thank you, Sam.
We're here with you in Vegas, or I should say hot Vegas.
Hot Vegas.
Not hot, Lanna hot Vegas.
Exactly.
The great time to talk about AI, machine learning, and other cool things in a hot environment.
Absolutely.
Absolutely.
Why don't we jump right in and have you tell us a little bit about your background?
Wow.
So, I've been around the block a few times, so my background is astrophysics.
I fell in love with trying to understand the universe years ago, which meant I fell
in love with data years ago, because data tells us about things, how things work, and
the universe is my system that I studied for decades.
I worked at NASA for nearly 20 years on data systems to help other astronomers access data,
as well as myself accessing data to study our universe.
And during that period, I fell in love with concepts like machine learning, data mining,
and things that we call data science nowadays, and even AI.
And how can we do greater discovery from data?
And so during those years, I eventually decided that I wanted to move out of the NASA world
into education, to teach the next generation students, next generation workforce, about
data science and data.
So I left NASA that was 15 years ago, and spent 12 years at George Mason University in Virginia,
teaching data science to students.
And that's what I love doing, teaching, educating, informing people about this.
And then this company, Booz Allen Hamilton, called me up a few years ago, and said, hey, how
do you like to do that for our clients and for a bigger world than just the science world?
And I said, yes.
So I've been doing this principle data science thing for Booz Allen Hamilton for three
years now.
Awesome.
Awesome.
And you're also quite prolific on Twitter, and speaking at conferences, and kind of
the whole gamut, I don't know that there's a point to that other than, I'm one of your
Twitter admirers, and we go back and forth quite a bit on there.
Yeah.
Well, thank you.
Well, one thing I don't do, I admire that you're doing is the podcast series.
My son-in-law gave me a bunch of equipment a few months ago for my birthday and said, hey,
here's your chance.
Nice.
I haven't quite put it to use yet, but no, it's, I really love sharing knowledge about this
field. I mean, it's exciting what's happening.
I don't, and I think we're part of a sharing economy in the world in general, but I think
in the data science community, especially data scientists love to share their knowledge.
If you look at all the hackathons that take place, people love to use their knowledge for
social good.
If you see all the data for good hackathons and competitions and activities that people
participate in.
And so it's just part of our community to share knowledge, to share what we know, to
help things.
And if we can earn a living doing it also, that's fantastic.
Nice.
Nice.
Yeah, that is one of the great things about the community, both from a research perspective
as well as the commercial side of it, the willingness to publish, for example, you don't
see that in a lot of other areas.
Yeah, I think the open source community, which includes Python and R, is sort of ingrained
in this community.
And as such, people are willing to share lots of things.
You know, not just their code, but knowledge that they've learned and ideas that they've
had.
And I mean, I grew up in an era where people were very protective, you know, peer-reviewed
research was published journals that you had to pay subscriptions to receive, and otherwise
you wouldn't have access to the knowledge.
And you know, I think the world has changed a lot that we believe more in sort of open
science, open data, open knowledge, because it's really the benefit to society that this
stuff brings that should take precedence over me getting some kind of special accolades
or attention because I came up with a thought.
Right.
I've learned, if I'm old enough to know that if I came up with a thought, someone else
probably has also thought, so I don't think it's worth arguing over who came up with
the idea first.
The fact is we have great ideas in this community.
We love to share them with each other and to benefit our clients and ourselves and our
society from it.
So what is your day job at Booz Allen Hamilton?
Are you primarily evangelizing and educating or are you doing?
Are you involved in projects as well?
It's mostly the former, but some of the latter, so primarily what they call the horizontal
matrix guy, okay?
So I like to tell people we have a thousand data scientists, the world's best kept secret
and data science, because our data scientists are working primarily on client data, on client
projects, on client site, and we're not allowed to talk about it.
And so people pretty much don't know what we're doing.
So all these different projects are in different vertical markets, mostly in the federal government
space, but things like healthcare or military or intelligence or transportation or energy
or treasury or Homeland Security, we got something going on.
And there's chief data scientists who basically manage, not so much manage, but they basically
oversee the talent acquisition and the work acquisition in those markets.
So we have many chief data scientists, but the firm has one principal data scientist and
that's me.
So one of the ways they were able to extract me at the university made me an offer I couldn't
refuse and he actually created a job title just for me.
So my day job doesn't include interacting with some of these projects and occasionally
doing some advising and mentoring of people who are working on those projects, but more
often than not, it's the evangelization thought leadership is a phrase they like to throw
around.
It means lots of writing and public speaking, even executive advising.
So I say I mentioned the newest members on the block and doing this stuff and the more
senior executives who maybe have heard of this, but don't know quite what it is.
And so I have this desire to share knowledge, and I sort of fulfilled that desire by
being a university professor for 12 years.
And I haven't surrendered that passion of teaching and mentoring and training by going
to Booz Allen.
I'm just doing it in more interesting and diverse environments.
Much more interesting use cases than maybe the galaxies I used to work on, even though
I used to love those galaxies, there's probably a handful of people in the world who cared
about those galaxies.
But now when I tweet something on Twitter, there's 200,000 people who are reading
it.
So that's interesting.
That impact it now has.
Right.
Right.
So we've been here at Peggo World for the past couple of days, and a lot of the conversation
has been around automation, automation and service of digital transformation and service
of customer experiences, and increasingly adding elements of intelligence to that process
of automation.
And what's your take on that?
Well, first of all, I just love this.
And one of the more trivial reasons why I love this is it gives me the opportunity to
use one of my most favorite words in a sentence, and that word is confluence.
So if you understand what confluence means and the confluence of rivers and if you ever
visit such things, that's really interesting.
But that's another story.
But we're living in an age of the confluence of many technologies.
Many technologies converging, merging, working together to a greater outcome in the same
way that many rivers, tributaries, can merge together and create a mighty force.
And so we have automation, we have AI, and when you think about customer experience, things
like that, for me, it's like everyone has a customer.
I get a little bit of friction with some of my astrophysics colleagues from days of
long ago saying, Kirk, what are you doing now?
What is the stuff you're doing now?
And I said, well, that's not really all that different.
Because back then, the people who we needed to impress in order to get grant money might
have been the proposal reviewers or the agencies who fund our research or the paper reviewers
to get our papers published in journals.
And so we're selling our ideas, we're selling our thoughts, we're selling our work in some
sense.
Okay, maybe not in the strict sense of selling, but we're making a good case for what we've
done as a value to someone.
And so customers need to have those value propositions from companies, and they just don't
want to hear the words.
They want to sort of, I say, sort of the three questions have to be answered for that
customer.
What, so what, and now what?
What is it you did for me?
Why should I care?
And what does that mean for me now?
And so being able to answer those questions improves both customer relationship and customer
experience, customer journey, whatever you want to call it.
And every, like I said, everyone has a customer, right?
So whether you're in a government sector and you have stakeholders or publicly traded
company, you have shareholders.
If you're actually customer facing, obviously you have customers, whatever it is, someone
is, will buy your product, will buy your ideas, will listen to you, will pay attention
to you.
You know, if all you're selling are your words and your thoughts and your ideas to someone,
you have to be able to say it in ways that are empathetic, that is puts the words in ways
that they can understand it, that they see the value for them.
And so it's putting yourself in their shoes and allowing them to sort of see it from their
perspective.
And as a data scientist, I love this way of describing what I do, one of the ways I describe
my job to people is I talk the walk, all right?
So there's a lot of companies out there that can talk the talk, right?
There's AI, lots of hype, data science, machine learning, blockchain, I mean, you name it,
there's hype cycles all over the place.
People love to talk the talk, right?
And there's a famous quote from years ago, when big data was at the peak of its hype cycle,
a person said that, you know, big data is like teenage sex.
Everyone is talking about it.
No one really knows how to do it, but everyone thinks everyone else is doing it.
So you claim you're doing it even though you don't know what you're doing, okay?
So I think a lot of hype cycles are like that, people do a lot of talking the talk.
And so we talked about moving beyond that to being able to walk the talk, being able
to actually do the thing you're talking about, and a lot of companies are now reaching
that pace.
So when we see data analytics, I think we're past the hype cycle, AI is sort of peaking
out.
And I think we see tons of implementations, amazing processes being automated and all
kinds of things being implemented, AI showing up and I'll crawl across enterprises everywhere.
And so people are really, you know, walking the talk.
And so I say, I see my role now as to being able to now to describe that to someone.
You know, I don't want to sit there and describe something in very mathematical language
and all about deep learning and neural networks and words that people have no idea what I'm
talking about.
I had to be able to explain it in a way that's empathetic, that is they can see why, you
know, the what, the so what, and the know what, and this thing that we're doing.
And so I take that as my personal role at Booz Allen Hamilton and in my life in general
to be able to explain to people in those terms, what is this stuff we're doing?
And I think this is a very interesting time to do that because of this confluence of
so many technologies.
And to be able to explain what we're doing to people, we have to be able to explain what
machine learning is, what AI is, what big data is, what data, you know, what data privacy
has to do with it.
And we're not trying to steal people's identity.
We're not trying to destroy the world with robots.
I mean, so you got to have all kinds of different kinds of conversations with people, but you
got to put yourself in their shoes at the same time not being untrue to yourself and
untrue to the technology.
And that's, you know, that's a fine line and I sort of enjoy walking that tight rope.
What do you mean by untrue to the technology?
That is slipping into talking to talk.
All right.
It's really easy when you talk to people about the AI machine learning and stuff like this
and say, oh, it's going to cure cancer, it's going to change the world, it's going to
reduce poverty, it's going to remove gender inequalities, it's going to fix our environment.
And all of a sudden, you're just sort of like mouthing all these platitudes.
And it's not being true to the technology because some of this stuff is just plain hard.
And some of the AI's we see in businesses are pretty small and minor and that's okay.
That's really okay.
Like if you use a cell phone, right, use a smartphone and you're using text messaging.
There's an autocomplete, right, a spell check, an autocorrect on your cell phone, right,
as you're typing the word, it sort of completes the word for you, all right, so that's a type
of head feature.
It sees what you're typing and it sort of guesses what the word is going to be, even the
next word.
That's an AI, all right, that I don't think any autocomplete or autocorrect has ever come
out of your phone and taken over the world.
So we, so we can be true to the technology, say this, this is an AI, what you have in
your hand is an AI.
But it's not the kind of AI you see in the movies, right, all right, so I can, so I don't
want to say that AI is this pure force that's going to cure all of the world's illnesses
and problems and will live happily ever after.
I mean, that's not being true to the technology.
It's hard work and a lot of that hard work, it has to deal with the ethical questions
and all the bias questions and data privacy questions.
There's lots of really hard problems to solve there and it's not being true to the technology
or to yourself to ignore those.
I imagine that you have had encounters with executives at Booz Allen where, you know,
you hear, well, why can't we just?
And it's, you know, some, you know, then a miracle occurs type of statement or, you
know, something that is more like, you know, maybe something out of the movies or something,
you know.
How do you deal with that beyond just saying it's hard?
Well, to tell you the truth, it's usually the other way around, really, at least the
bike experience.
I find a lot of the, of course, we're a management consulting firm, right, so we go
to clients and we're pitching our consulting services, whether it's analytics or digital
or cyber security or something.
And so we're selling to a customer, right, and this customer could be a federal director
of some agency or something like this.
And so they're a very critical person, right, they're not going to spend their money any
more than when you would go buy a product, you're going to spend your money just because
some salesperson says so, right, you're going to be critical.
So I see a lot of good critical thinking and critical question asking from that side of
the table, but occasionally what happens is on the data science side of the table, which
is where I sat.
And I see myself as a younger person doing this years ago when I was really getting excited
about this automation and AI and machine learning stuff, and I first just sort of discovered
it, if you will, 20 years ago, I was, I was that, I was that sort of, you know, pying
this guy guy and the other side of the table, talking to my NASA clients, oh, we can be
able to do all this space exploration.
We can autonomously drive spacecraft around Mars and fight all kinds of interesting discoveries
and new, you know, new water deposits and new titanium deposits, and we can build colonies
on Mars and we're going to have an Amazon type service, automatic supply chain of delivery
of the supplies that astronauts need just in time from a supply ship or in orbit that's
delivering packages to their door by satellite deployment.
And so I was going on and on with all this pie in this guy stuff.
So I was, I was the guy who was sort of needed to be pulled back, you know, and of course,
I learned a bit in my old age to rein in some of that sort of unrealism in the stories.
And I think it works better because again, the person who's, who's buying, if you will,
the client, who you're trying to sell a product or a service to, you know, they're not
going to buy that bloney and it's, it's snake oil, right?
And so I remember a friend of mine years ago in astronomy wrote a book called, with the
internet first started.
I mean, not the internet per se, but the web first started.
He wrote this book about the, the internet being silicon snake oil, right?
And he, he predicted the demise of the internet.
He said, this will last a couple of years.
It's just a fad.
This is stupid.
It's just snake oil.
Smoking mirrors, and yeah, completely wrong, right?
And so I sort of forgot about that, but a few years ago, I sort of remembered that he wrote
this book, right?
And so I went back to Wikipedia where, and looked up in his page there, and he actually
has a pretty deep and long apology about how stupid and arrogant and naive he was, even
though he was a PhD astrophysicist, he was, I'm like, a lot of PhD folks who don't normally
admit when they're wrong, he was very humble about the fact that he really screwed up
on that prediction.
It's a tough line to walk, seeing, you know, as we do the promise of technologies like
AI and others, but knowing the limitations or at least as you put it, the hard work that
has to go to get there and knowing, you know, being able to kind of project, you know,
how long it's going to take to get to some vision state X, and it's really hard.
Yeah, exactly.
I mean, if you think about like self-driving cars, there's an example where so many things
have to work together, and autonomous vehicle in order for it to not only do what it does,
but do it safely, and not only safely one time, but safely all the time in very different
environments, and so step one, I mean, just get a car to steer straight, okay, get a
car to recognize a stop sign, get a car to turn a corner, get a car to recognize the
speed limit.
I mean, just one little step at a time, and there's like so many steps.
And so I think a lot of implementations and enterprises using AI, machine learning,
automation, whatever you want to call that stuff, intelligent automation, again, requires
a lot of moving parts to get right, and so we need to be more humble, so to speak, in
our way of believing our own story, believing our own promises, that how far can we get
an X amount of time, and I frequently say to people, and I still believe this, that one
should think big, but start small, that is don't think small and start small, because that's
not very useful, but think big, but no way of saying it is think strategically, but
tactically, and my father was Air Force, so I learned some of that language when I was
younger, that strategy is about winning the war, and tactics have to do about theater or
our battle specific, so sometimes you have to lose the battle to win the war, sometimes
you have to give up the hill in order to win the battle, okay, so it's not always about
win, win, win, win, win, it's about the long-term goal, and that long-term goal is what keeps
sure, certainly your North Star keeps your focus going, so you need to have that, but
recognize that there's a lot of steps on the way, those sort of tactical steps, and tactical
failure is, people say failure is not an option, I say strategic failure is not an option,
but tactical failure is how you learn, so sometimes that's called fast fail, I get a lot
of sort of knee jerk negative reactions from my clients when I talk about fast fail,
they say we don't want to fail here, so now I call it just fast learn, okay, so we
want to have a fast learn environment, and the implication is how do you learn, but you
learn from mistakes, from failures, you learn from edge cases that didn't work out, and
so you want to be in a fast learn environment, so that you can do these smaller incremental
steps, and I learned a new expression this week, we used to call those sort of incremental
steps minimal viable products, the MVP minimal viable product, now you're going to talk
about the MLP, yeah, so this week, that was awesome, so this week I learned about the
minimal lovable product, and I said I like that minimal lovable product, and one of the
keynotes here in the world, so I think that's going to be my new thing, MLPs, I didn't
say NLP for people who are listening out there, that's natural language processing,
I said MLP, minimal lovable product, and remember, I mean data like products are like
your children, you love all of them, because even when something goes wrong, you learn
from that, and that's what this is all about, it's about learning.
You mentioned just a moment ago self-driving cars, and I've heard you use a really interesting
analogy between applying the idea of self-driving cars to the enterprise to explain intelligent
automation, the theme of this event, what does the self-driving enterprise mean to you?
To me, it means basically doing what the self-driving car does.
It senses its environment, it sort of sees what's coming, takes an action that's going
to optimize the outcome, and it uses all the contextual data, so what I just described
is descriptive analytics, predictive analytics, prescriptive analytics, and cognitive analytics.
So a self-driving car, it's collecting data, what's going on now, so it's diagnosing
its environment from sensors in the car.
An enterprise, no matter what it is, whether you're customer engagement, your sales, your
marketing campaign, your employee activities, your human resources, anything in your business,
and across your enterprise, whether it's an enterprise specific or a customer-facing
thing, you're collecting data.
Just like a car, you're collecting data.
You got to do more than just collect data from your sensors, you got to do something.
You want to take some action.
So part of your action is to sort of look ahead and see, well, where is the road going?
So let me make sure I stay on the road as I move forward.
So that's the predictive model, so you see what's ahead, so you can move forward in that
direction.
So if you're trying to increase sales and prove customer interaction or whatever, you
sort of see what kind of steps you can take that will move you in that direction.
That's pretty predictive model, but more so, what's prescriptive that is, you can say,
what can I do to optimize the outcome?
So just like a car driving, it says, if I go down this street, my app tells me less traffic,
even though there's more stoplights, normally I wouldn't go that way because it's a longer
drive and a normal low traffic day, but a high traffic day is going to be faster to go
this other way.
So in the same way with customer engagement, you might have a more optimal outcome.
If you take a particular path or a particular road, so to speak, but it's, again, it's
even more than that, and that's the cognitive analytics, the cognitive phase of driving,
which is now you take in all contextual data.
So using the car analogy again, you look at all the data, what's the weather condition?
What's the road condition?
Are there pedestrians on the road?
Are there children playing down the street?
You know, am I in a school zone?
Is it whatever?
And so all this contextual information now informs you how to take next best action.
So cognitive analytics is about next best action, or I like to say next best question.
What is the thing I should be asking of my data?
What kind of things should I be informed about from my data?
And so that's the cognitive phase of the self-driving enterprise is not just doing the
thing that you always do, collecting data, selling products, serving customers.
What is the thing you ought to be doing?
What is the more contextually based thing you should be doing?
That context could be time of day, right?
So let's just say you're building something as simple as a recommender engine to a customer.
What you recommend a particular customer is not always the same, even for the same customer
could depend upon time of day, or day of week, for example, I might be looking at completely
different products online if I'm at home on a weekend, then if I'm at work, or if I'm
on vacation in Vegas, or if I'm at work.
And so context, location, time, those kind of contextual data points sort of change your
action even for the exact same customer.
And so being able to bring in the contextual data makes you more cognitively aware and
able to take those best, next best actions and ask the next best questions.
And so that enables your enterprise, your business to be that self-driving enterprise in
the sense you can start automating more of the processes, automating more of the activities,
not taking human out of the loop, but augmenting the human with the right information and knowledge
and inputs and insights that they need to do their work.
So I like to say AI is no longer about artificial intelligence.
In fact, there's nothing artificial at all about it in my mind.
It's about other types of AI, amplified intelligence, assisted intelligence, accelerated, augmented,
adaptable, and just go on and on and on.
I mean, there's all these interesting ways of thinking about AI, besides artificial.
And so your self-driving enterprise is that one that, in a sense, it's doing for your
enterprise what an autonomous car is doing for a driver.
You don't want to have the driver completely disengaged from the driving experience, I
think.
I think we've learned that from recent incidents that you still need to have a person there.
And so you still need to have a person there in the enterprise, obviously.
So future of work is another completely different dialogue we could be having in this area.
But you did mention a phrase earlier called digital transformation, which is one of the
big themes here at Peggo World this week, and digital transformation includes two words,
right, digital, which means we're looking at digital information, digital data, digital
signals to inform us and to do our self-driving car thing, self-driving enterprise thing.
But there's the other word, their transformation, and transformation means change, and change
means change.
Love.
So jobs will change, career paths will change, what people do will change in the same
way with every industrial revolution.
And so it is happening, and you can't stop it from happening, it would be ridiculous
to stop it from happening, any more than stopping the invention of the printing press or something
like that.
Oh, my gosh.
What are we going to do with all those monks and monasteries whose job it is to transcribe
our copy to write copies, endless copies, beautifully artistic copies of the Bible or
whatever.
So they found some other things to do, obviously, so work changes, the tasks we do change.
And it means transformation.
So it's okay that we are going through a change now because change is good, and it's
growing pains, you might say we're going through the adolescence phase of digital transformation,
so there's a lot of growing pain right there.
Earlier you mentioned you were discussing tactics versus strategy, tactical, the Hill versus
the battle, the battle versus the war.
A lot of what we talk about in kind of applied AI, automated decision making is very
tactical decisions, what's the next offer, what's the next step.
Are you seeing AI, machine learning applied to helping businesses get a handle on the
strategy, the bigger picture?
That's a good question.
I'm not sure where we are in that state.
I see a lot of a lot more discussion on topics that you might label data strategy or analytic
strategy.
And I imagine also AI strategy.
So I think that the idea would be, let's stop and think what are our business goals,
what are our outcomes we're trying to achieve.
So be outcomes driven and not technology driven.
I mean, I sort of cringe when I see people say that their business is data driven, and
I've used that phrase myself, so I've all pointed myself to be guilty there.
They say they're data driven or technology driven, and I'm starting to catch myself
before I say that.
We're data empowered, we're data fueled, data informed, and we're technology powered.
I mean, that's a better way to say.
We're data informed and technology powered, but we need to be product or outcome or
customer driven, driven, driven.
Right.
Well, outcome driven, because a customer's success might be your desired outcome, customer,
and you might say customer sales might be an outcome.
I mean, that's a metric, right?
So when you think about outcomes, you need to think about the metrics to measure whether
you've achieved your outcomes, right?
So that's traditional KPI, that's traditional six sigma, right?
You say what you're going to do, you do it, and then you prove it, right?
That's how I learned six sigma.
And so how do you prove it?
Well, you have some kind of measurement that you've agreed to, that this is the thing we're
going to capture and measure to demonstrate whether or not we've achieved the outcome.
And so the outcome is customer sale is a metric, I would say customer success, customer
loyalty might be outcomes that you're, that's the big goal, right?
And so you sell a product to a customer, that's a tactic, right?
And so I make a recommendation, the person bought the product, yay, hooray for us, but
is that a loyal customer?
Are they going to come back and buy more from us?
And so sometimes, like I said, you've got to sort of lose the battle to win the war.
So this is why companies offer things like discount coupons and premium type products where
they give you something for free.
Hopefully later you'll buy the more premium plan when you have the sort of the low, the
zero cost plan, which has a fewer bells and whistles, fewer services than the full premium
plan.
But if you really like what you get to see there, you're willing to pay more.
And so the company is willing to take that loss in order to win the bigger, the bigger
war that is going to gain a loyal customer in the end.
So yes, so if you looked at the bottom line, you say, well, we lost money today because
we gave away all this stuff at 20% off and, you know, we have a 15% margin in our company,
so we're doing some money today.
But in the long run, you've gained lifetime customers, loyal customers.
And that, that's really the bigger picture, the bigger, the bigger goal.
And so strategy intact.
I mean, some people interchange those words and not here to argue semantics, but I'm really
arguing about, think about sort of long-term goals versus short-term metrics and accomplishments.
And sometimes that, the negative step backward leads to a bigger step forward later, and
that's okay.
That brings to mind for me, and in fact, this came up in an interview earlier today,
the notion of architecting the, you know, our optimization functions, our reward functions
to, as you put it here, better reflect the outcomes as opposed to the individual transactions.
What kind of progress are you seeing towards data scientists being able to capture a more
holistic view of the, the business strategy and the business outcome in the way that they
optimize, in the way that they build, you know, machine learning algorithms and AI systems
to optimize towards those, and where do you, what's your sense for where we are in the
maturity curve and how we get to, you know, the next best thing?
Well, I think we're in a much better place than just a few years ago, in what sense?
And I mean that primarily in the access to more data, but there's really sort of three
sort of, again, using the word confluence in a sentence, there's sort of three things
that are, technologies that are merging, large amounts of data, that is, sensor technologies
for collecting data on just about every process, person, thing, and enterprises and homes
and cars in the universe.
There's also faster, better, more powerful algorithms, so lots of development and algorithms
for detecting patterns and trends and behaviors and data.
And then the third one is access to high performance computing.
So yes, we've had HPC high performance computing for many years, but you have to buy a super
computer to have access to a super computer.
Now you can rent one on the cloud, right?
So you basically can rent as many CPUs as you need from a cloud service provider for
the two minutes or five minutes that you need it and then give it back.
So all you've paid for is those couple of minutes.
And it's the cloud services provider's job to buy the hardware, to maintain the hardware,
to upgrade the hardware and all these things, which most, and past days, I remember working
in institutions where they didn't want to make that expense because they knew that within
five years it would be obsolete and what a huge capital investment that would be and wouldn't
it be better if we invested our of money and XYZ, other direction, like hiring more staff
or more funding more students or doing whatever, yeah, we all agree, ultimately, no, don't
go buy the big super computer because it'll be buddy down the drain five years or no.
And so we got powerful computing, we got powerful algorithms, we got lots of data.
So what does that buy us?
It buys us insights and the ability to derive insights from data.
And so when you're talking about optimizing a function, if a function is multi-dimensional,
which in this case, I would say it is, there are many, many factors that determine the
optimal, something, right, optimal customer experience, optimal sales, optimal, whatever.
I mean, no matter what it is, optimal performance in a manufacturing plant, optimal supply chain,
think about the traveling salesman problem.
I mean, it's like in factorial, which is a very large number for a traveling salesman
who's going to end different stops, right?
And so this is a challenge problem that's quantum machine learning is addressing.
How can you do a faster, much faster solution to the traveling salesman problem, which
is basically optimal routing, whether it's for any kind of routing, whether it's shipping,
industry, logistics in the military, or whatever, a network traffic, always looking for optimal
routing.
Okay, so how do you solve an in-factoid problem, one that basically is grow so fast, there's
enough computing power on the planet and the universe to solve the problem.
And that is you have more data.
So the data from all these sensors gives us essentially a map of our, if you will, an
indimensional map of the output variable, and then I'll just pick a number, let's just
say revenue.
Okay, let's just say that's our, if revenue is our thing we're trying to maximize, there's
all kinds of factors.
So we can look at all these different conditions and factors and activities and see which
ones lead to the maximum of that function.
And so you no longer have to do complex modeling per se, you can, but the data becomes
the model, because you know, have enough data that the data now tells you, this is how
the system responds, and in the case of say marketing campaigns, right, I heard a story
once years ago that eBay had, they did, like, A.B. testing on their website, you know,
like changing the fonts and changing the colors and changing the locations of things on
the page, they did 10 million A.B. tests every single day.
Every single day, they've moved things around and changed things, changed colors, changed
fonts, changed locations, changed the sizes of the pictures, et cetera.
And at that point, you don't need any kind of model of customer behavior.
You just look at the data, say, this is what works, let's go.
And so I think the, the ability to just use all the different data sources we now have,
and again, if we're going back to the customer story, we got sales data, we got customer
call center data from that customer, we have return data, you know, we have all kinds
of data, customer care data, customer interest data, you know, product history purchased
data, all kinds of information about that customer.
So we can now figure out how to optimize our interaction with that customer based upon
the data as opposed to what we would do in the past with some kind of modeling, right?
So okay, I'm a white male or 50 and might live in a certain zip code, therefore every
white male who lives in my zip code over the 50 must like the same things.
And every morning I walk up my front door on my house, I know that isn't true because
the guy next door to me has a Pittsburgh dealer banner hanging out front of his house,
and I'm a Baltimore Raven thing.
Okay, and so I mean, I'm immediately informed that no, it is not true that every single
person in my demographic likes the same thing, I mean, and of course we know that now,
right?
So I say the big data era represents the end of demographics, we're no longer like
using these limited biased variables to determine outcomes or marketing campaigns or offers
or whatever, we just look at the data and say, what does this individual prefer like desire
and serve them for who they are and what they like and desire?
And again, that's our optimal optimization of customer experience, which leads to optimization
hopefully a revenues is driven by data.
And at the end of the day, that's what I say, it's all about data, therefore digital transformation
is happening.
It's not the gutted instinct anymore that drives your decisions as a business, it's the
data.
Awesome.
Well, that sounds like a great note to close on any parting thoughts before we push the
button.
No, I think this is great.
I thank you so much.
Sam really enjoyed the conversation today.
Same here.
Thanks for.
All right, everyone, that's our show for today.
For more information on Kirk or any of the topics covered in this episode, head on over
to twimmelai.com slash talk slash 151.
To follow along with the Pegaworld series, visit twimmelai.com slash Pegaworld 2018.
For more information on Pegasystems or their new Pegat Infinity offering, visit pegat.com
slash infinity.
As always, thanks so much for listening and catch you next time.
