WEBVTT

00:00.000 --> 00:04.960
All right. What's up, everyone? Welcome to another episode of the Tumol AI podcast. I am your host,

00:04.960 --> 00:09.840
Sam Charrington. And today, I've got the pleasure of being joined by Disha Singla. Disha is a

00:09.840 --> 00:16.160
senior director of machine learning engineering at Capital One. Before we dive into our conversation,

00:16.160 --> 00:20.960
be sure to take a moment and hit that subscribe button wherever you're listening to today's show.

00:20.960 --> 00:23.040
Disha, welcome to the podcast.

00:23.040 --> 00:26.160
Hey, Sam. Thanks for inviting me here. I'm very excited today.

00:26.160 --> 00:31.760
I'm super excited to chat with you as well. I'd love to get started by having you introduce yourself

00:31.760 --> 00:35.920
to our audience and share a little bit about how you came into the field of machine learning.

00:35.920 --> 00:41.280
Sure, Sam. So I joined Capital One earlier this year as a senior director of machine learning

00:41.280 --> 00:46.640
engineering. Before Capital One, I have had opportunity to work at some great companies like

00:46.640 --> 00:54.960
Intuit, Sony, Newstar, etc. So my career, I started as a full stack engineer, but I had a deep love

00:54.960 --> 01:00.880
or passion for data. So the whole end to end lifecycle from collection of data all the way to driving

01:00.880 --> 01:07.600
meaningful insights. So that's how I organically continue to grow in this role. And here at Capital One,

01:07.600 --> 01:12.800
it's a great company. I joined earlier this year, where I'm leading a group of very talented

01:12.800 --> 01:18.000
data scientists, machine learning and software engineers. A group is called data insights.

01:18.000 --> 01:22.480
We are working on something that's very close to my heart, which is democratizing AI,

01:22.480 --> 01:29.520
democratizing ML by making ML available to everybody. So our team has built reusable

01:29.520 --> 01:35.520
libraries components and workflows and have created a platform which allow the citizen data

01:35.520 --> 01:39.840
scientists to drive meaningful insight using our various office within Capital One.

01:40.480 --> 01:48.240
Awesome. Awesome. Can you share maybe an example of, well, a couple of things. First,

01:48.240 --> 01:55.680
when you think of a citizen data scientist, what's the kind of archetype for that person?

01:56.320 --> 02:00.640
What are they typically? What's their day job, so to speak? And then what are some of the things

02:00.640 --> 02:05.360
that they have done with the tools that your team is providing? So to me,

02:06.400 --> 02:11.520
let me take you back like five to seven years back where everybody wanted to build models,

02:11.520 --> 02:19.120
right? But not everybody can formalize. So people grow, they explore data sets, right? Or they want,

02:19.120 --> 02:24.480
they know that there is value in that data. So they want to explore that value. They want to use

02:24.480 --> 02:30.400
those insights to drive some meaningful decisions. So the way I would like to think is to categorize

02:30.400 --> 02:37.040
data scientists are the people who have this formal education of ML, of stats. Whereas the citizen

02:37.040 --> 02:44.160
data scientists in my point of view are the people who are analyst, who have done something with

02:44.160 --> 02:50.000
data, but they do not necessarily are keen or build models. Or there are engineers who are data

02:50.000 --> 02:56.400
engineers or software engineers who want to be able to do ML. That's how I would like to think

02:56.400 --> 03:02.240
about it. So now when it comes to our tooling, if you think about what we are doing is we are building

03:02.240 --> 03:08.000
reusable components. What we are trying to do is that let me give you an example, a concrete

03:08.000 --> 03:13.680
example and that that ever helped. So the way our team is working on, we have built like reusable

03:13.680 --> 03:20.240
libraries, workflow components and algorithms, which are in the field of monitoring and forecasting.

03:20.240 --> 03:26.000
When I say monitoring, we are talking about time series, time series anomaly detection,

03:26.000 --> 03:32.480
change point detection, root cause analysis and time series forecasting. So when we talk about

03:32.480 --> 03:38.160
regular data scientists, they want to build these book models. Everybody wants to quickly spin

03:38.160 --> 03:46.960
up a Jupyter notebook and then do some research, do some analysis of data, then they want to build

03:46.960 --> 03:51.840
the features, they want to train the model, deploy the model and do a bunch of things and drive

03:51.840 --> 03:57.840
the insights. Where we differentiate is our audiences, they want to do something quick,

03:57.840 --> 04:02.960
they might not have strong engineering background or data science background, but what they know

04:02.960 --> 04:08.320
is where the data is, what is they want to drive quickly using our tools and components.

04:08.320 --> 04:13.520
So for example, right, we, for, let me give you an example of forecasting. So we have Workplace

04:13.520 --> 04:20.160
Solutions team. They want to help our associates with our hybrid work environment. So they are

04:20.160 --> 04:25.040
using our solution to kind of forecast how many people are going to be returning to work on

04:25.040 --> 04:31.120
each day, how much the kitchen stocking has to be done. And now, so that's kind of forecasting,

04:31.120 --> 04:35.440
but now let's think about the other thing, which we are very proud of is the transactional fraud.

04:36.240 --> 04:40.800
So this is, for example, right, a third party, our internal team, which is a third party,

04:40.800 --> 04:46.560
fraud team, they came to us. They were looking for some kind of solution to identify the anomalies

04:46.560 --> 04:53.360
in the fraud and automatically defensive to mitigate the losses and reduce the customer friction.

04:53.360 --> 04:58.480
So they partner with our team, they come and say like, hey, we want to do A, B, C, D, E,

04:58.480 --> 05:04.480
and what we help is like we, we help them by creating this workflow, which is under the hood,

05:04.480 --> 05:10.880
is a dad. And then what they do is they work with us, they say, this is where the data is.

05:10.880 --> 05:15.360
And then what happens? Let me give you a little bit more detail. So when a transaction is

05:15.360 --> 05:21.680
marked as fraudulent, right, it is then analyzed by our solutions in a batch mode.

05:21.680 --> 05:25.920
And then what we do is the segments with the highest anomalies are flagged. So anomaly

05:25.920 --> 05:31.680
detection algorithms, they say, this is the segment with the highest, this is the segment with

05:31.680 --> 05:36.640
the highest anomalies. Then another other set of algorithms came in, which say that, okay,

05:36.640 --> 05:42.960
this is the change point happens starting when they start noticing the change. And then there are

05:42.960 --> 05:48.400
another, then after that, they go and see the root cause analysis. And then what happened,

05:48.400 --> 05:53.520
the automatic rules get generated, which then get applied to the real time systems to prevent

05:53.520 --> 05:59.360
the future fraud. And Sam, also if you know with any anomaly detection, one of the biggest

05:59.360 --> 06:06.160
challenges is minimizing the false positives. So we have built an intelligent there with what helps

06:06.160 --> 06:11.520
is all algorithms are open source and proprietary algorithms. So what these algorithms do is that

06:11.520 --> 06:16.880
we have intelligence built in, which also minimize this false positives. For example, right,

06:16.880 --> 06:20.960
if I go for a dinner with my husband, right, a nice dinner, and if my credit card gets declined

06:20.960 --> 06:26.480
after that, that won't be a good thing, right. So it's way, not happy. So it's kind of very important

06:26.480 --> 06:32.800
that we're not just having those algorithms built in, but we are, but we are also like helping

06:33.360 --> 06:38.880
to use the results of this algorithm help with the real time systems to mitigate future fraud

06:38.880 --> 06:44.480
and also give a good customer experience and reduce the friction because false positives are

06:44.480 --> 06:49.520
big concerns. You mentioned some things that I think of as existing in different kind of layers

06:49.520 --> 06:58.720
of a stack. You mentioned anomaly detection and forecasting as kind of these higher level almost

06:58.720 --> 07:04.880
primitives that maybe you offer to these citizen data scientists. You also mentioned workflows.

07:04.880 --> 07:13.920
Has your team, and you mentioned as well, open source and proprietary algorithms. So is your

07:13.920 --> 07:21.280
team kind of curated a collection of these algorithms for forecasting and anomaly detection

07:21.280 --> 07:27.440
and provided a platform that allows them to create these workflows and you're supporting them

07:27.440 --> 07:32.160
in building the applications. Is that the way to think about the way your team engages with the

07:32.160 --> 07:38.880
client? Yes. You said it very right. So let me also give you. So what is important for democratizing

07:38.880 --> 07:47.040
ML and how we are helping is we are focused on the key for us is no low to no code. So what we are

07:47.040 --> 07:52.320
doing is yes, we have an internal platform, which is very scalable built on Kubernetes. We have

07:52.320 --> 08:00.800
this sophisticated orchestra. We have like this sophisticated workflows and libraries built in.

08:00.800 --> 08:08.560
So yes, are the way I would say is are reusable libraries are sophisticated packaging of as you

08:08.560 --> 08:14.320
said, these algorithms which are open source and proprietary algorithms which you have built over

08:14.320 --> 08:20.400
time by researching using white papers and everything. And then under the hood are the low level

08:20.400 --> 08:26.560
decks on which we have an abstraction built out. So we help our customers through providing UI

08:26.560 --> 08:32.400
where the customer just goes. They just say, okay, hey, this is in the s3 bucket or in the snowflake

08:32.400 --> 08:38.080
or wherever many data sources we have where the data sets are. Then they provide us some parameters

08:38.080 --> 08:43.040
that, okay, I want this I want to drive this and these are some of the features which we think

08:43.040 --> 08:48.160
are important for us. And then this is how often the model needs to be retrained and this is the

08:48.160 --> 08:55.200
output sync whether the data has to go to an s3 bucket whether it has to go through snowflake or

08:55.200 --> 09:01.600
whichever other other capital one data and capital one system data systems are. So we kind of collect

09:01.600 --> 09:06.880
all these parameters and under the hood instead of now this person building the whole ML pipeline

09:06.880 --> 09:13.440
which is very sophisticated piece of coding and not easy. So we do it under the hood for them.

09:13.440 --> 09:19.680
And what happens is that we have governance and rules in place. So now what happens is because

09:19.680 --> 09:25.680
they just choose the templates. They provide the parameters under the hood. We have all our algorithms

09:25.680 --> 09:31.280
reviewed by our model review office. We have governance. We have everything in place. So the time

09:31.280 --> 09:35.360
to market for these solutions for our internal platforms is like very, very good.

09:35.360 --> 09:41.040
And what roles do you have on your team supporting all this? Do you have everything from data

09:41.040 --> 09:47.360
engineering to ML engineering to data science? Yes. So the way I'll just share something interesting

09:47.360 --> 09:55.360
you do, right? So for me, what an MLE encapsulates. So an ML engineer is a good mix of data engineer,

09:55.360 --> 10:04.800
software engineer, data science and business acumen and be able to cloud skills. So now to answer

10:04.800 --> 10:09.760
your questions, our team is data scientists, software engineers and machine learning engineers.

10:09.760 --> 10:17.600
So they have all the necessary qualifications to build this end-to-end sophisticated system.

10:17.600 --> 10:24.880
Right. Right. Right. You mentioned that the platform is Kubernetes-based. I recently spoke with

10:24.880 --> 10:32.080
one of your colleagues, Ali Redell, whose team, I think from that conversation, they're very focused on

10:32.080 --> 10:39.200
kind of low-level Kubernetes-based environments for machine learning there. Can you talk a little

10:39.200 --> 10:47.760
bit about how what your team does and any intersection points or how the approach your teams take

10:47.760 --> 10:53.040
and how they differ? Of course. First of all, I heard you. I am, as I said, I'm a huge fan of your

10:53.040 --> 10:57.360
podcast. So I did listen to your podcast with Ali and it was a great talk by the way.

10:58.000 --> 11:03.520
Absolutely. Thank you. The way I would like to answer this question is the way I think Ali's team

11:03.520 --> 11:09.200
and our team is doing is very complimentary. What we are doing is we are building a coherent

11:09.200 --> 11:15.680
ML ecosystem at Capital One catering to all kinds of personas, if you will. So the way

11:16.640 --> 11:22.720
Ali's team is working on is building a sophisticated system for the regular data scientists,

11:22.720 --> 11:29.360
as is done in a lot of companies. They're providing a system for regular data scientists who want to

11:29.360 --> 11:34.240
spend a Jupyter notebook, who want to do feature engineering, who want to train their model,

11:34.240 --> 11:39.600
who want to deploy the model, who want to create an artifact and deploy it, do hyperparameter

11:39.600 --> 11:47.440
tuning. Where we add value, our team is adding value is democratizing ML in the niche, as I said,

11:47.440 --> 11:52.960
around monitoring and forecasting. Where we add value is by building the

11:52.960 --> 11:59.120
providing reusable libraries and components and workflows. For example, back in the day when I

11:59.120 --> 12:04.880
was a data scientist, what I would do is I would spare a spin up a Jupyter notebook or an IDE

12:04.880 --> 12:09.760
that I like. I would like to do feature engineering spend like long cycles to feature engineering

12:10.320 --> 12:16.000
and then training and then hyperparameter tuning and then creating an artifact, creating a

12:16.000 --> 12:20.960
Docker image and then deploy it. I think you mentioned bespoke earlier, like a very handcrafted

12:20.960 --> 12:27.120
process of creating this model. Yes, which is like solving a particular problem, but what we do is

12:27.120 --> 12:32.800
our audiences are the people who want to drive quick insights. They don't necessarily care about

12:32.800 --> 12:37.920
building a model. They are looking at, okay, can somebody put a solution for us where we can

12:37.920 --> 12:43.680
minimize the transactional fault? Can somebody help us like where we can detect anomalies in this

12:43.680 --> 12:52.080
system? This is where we differentiate. Are the users of your platform are there? They build

12:52.080 --> 12:59.840
these models using the algorithms that you provide and the reusable components, as you mentioned.

13:01.040 --> 13:08.400
Are there goal to productionize them in the same way as the traditional data scientists?

13:08.400 --> 13:15.920
We think about the traditional data science or machine learning. You want to eventually get

13:15.920 --> 13:22.240
a model into production, maybe behind some API or even if it's batch, but like it's in production.

13:22.240 --> 13:28.880
Whereas more of an analyst role, they want to get the insight. Maybe it's to generate a report

13:28.880 --> 13:35.280
as opposed to have a model in the production. Curious how is that distinction significant to your

13:35.280 --> 13:41.440
users? It is because at the end of it, they want their own API that they want to hit to drive

13:41.440 --> 13:49.280
the insight. There is this desire for productionization of what they're doing on your platform.

13:49.280 --> 13:57.600
Yes. We have like many productionized use cases. Whatever examples I was giving you before about

13:57.600 --> 14:04.080
the third party card fraud or the workplace team, those are two of the many production use cases

14:04.080 --> 14:09.840
that we have. At the end of it, yes, there is this API that they hit or it is hit automatically by

14:09.840 --> 14:16.080
what we have built in the pipeline, which is kind of giving them the predictions or that they then

14:16.080 --> 14:24.960
use or surface of the stack for the business to make necessary decisions. In a sense, just because

14:24.960 --> 14:31.920
they're the citizen data scientists, they still need a fairly sophisticated set of tooling

14:32.560 --> 14:36.480
to support what they want to do because they want to do a lot of the same things. They just don't

14:36.480 --> 14:42.880
necessarily have the expertise or the desire to tweak all the parameters that the traditional

14:42.880 --> 14:47.760
data scientists might have. Actually, they need more sophisticated because now the onus is on our

14:47.760 --> 14:52.800
team because the contribution from the citizen data scientists, they don't know if they want to use

14:52.800 --> 14:58.560
the dice coefficient versus the binary coefficient. So the onus is on us to kind of build that

14:58.560 --> 15:05.200
sophisticated offering for them that they get the results if not better than same as if somebody

15:05.200 --> 15:11.760
from their team would have created this handcrafted method. Got it. Yeah. Yeah. You mentioned in talking

15:11.760 --> 15:21.680
about the fraud aspects of both batch and real time and when you talk about monitoring and

15:21.680 --> 15:26.480
anomaly detection, real time comes to mind there as well. Can you talk a little bit about real time

15:26.480 --> 15:32.320
requirements for the kinds of things that your users do and how you accommodate that? Sure. So

15:32.320 --> 15:38.000
I'll give you example in general also first of all. So you know how the technology is changing

15:38.000 --> 15:45.360
correct and I represent an average internet user. So if I'm on a website, I don't get what I

15:45.360 --> 15:51.600
need to see in a couple of minutes I believe. And we know that there are so many platforms,

15:51.600 --> 15:59.040
there are so many e-commerce systems. So machine learning has to be fast and it has to be fast

15:59.040 --> 16:05.680
for example, right? If I'm on a e-commerce website, right? I need it needs to tell me like how do

16:05.680 --> 16:09.520
they differentiate their products? There are so many vendors on that one, right? And then if

16:10.800 --> 16:15.840
AI is an ML is getting smarter, right? If I'm leaving the website, they know they want to

16:15.840 --> 16:21.440
intervene to keep me there. They want to upsell a product. So what's needed is something that is

16:21.440 --> 16:29.200
very, very fast. So the way models have to be is not only that they need to be statistically strong

16:29.200 --> 16:36.720
models, they need to be fast also. And what happens is like many a times I see that and even when I

16:36.720 --> 16:42.880
started in my ML journey, the focus was mostly on building the sophisticated models, right? But

16:43.520 --> 16:50.640
a lot of focus doesn't go into how to make them optimized in the sense like fast and also it's a

16:50.640 --> 16:56.240
whole stack if you think about it, right? So you have a model which is fast. Then you have a platform

16:56.240 --> 17:02.880
which is able to like surface the anomalies or surface the outputs of the model fast.

17:02.880 --> 17:08.960
Then another interesting thing that happens is that these things are ultimately like but if you

17:08.960 --> 17:13.280
see the entire stack, you might have a UI layer, you might have a business layer, you might have

17:13.280 --> 17:18.480
different layers which are owned by different teams. So you need to have like an overall system

17:18.480 --> 17:25.840
which deals with the TPS, 99 SLAs and everything so that the time in which the whole stack

17:25.840 --> 17:33.920
responds in like few milliseconds. So what I'm trying to say here is that over time and coming

17:33.920 --> 17:38.160
from the engineering background, the way I like to see a model as we talk a little bit before

17:38.160 --> 17:44.960
also is like a piece of software or an API that's on production. So people need to focus on it.

17:44.960 --> 17:49.840
If it's just a piece of software, I forget about the model development lifecycle. They should at

17:49.840 --> 17:54.720
least think about it as a software development lifecycle and it should go through the same engineering

17:54.720 --> 18:00.240
and operational radar. Real time makes it more interesting because now we are talking about distributed

18:00.240 --> 18:06.160
systems. We are talking about TPS 99. We are talking about SLAs. We are talking about

18:07.600 --> 18:14.000
the cost effective cost usage. So because there are so many things in the stack and they are so

18:14.000 --> 18:20.560
interdependent so real time becomes kind of like challenge these days. So what we are doing is in our

18:20.560 --> 18:27.360
system is that most of our use cases are batch models but there are few which are real time systems.

18:27.360 --> 18:32.240
So what we are doing is like we have put in, so if the data is coming right in the magnitudes

18:32.240 --> 18:37.520
of gigabytes or something, this is like mostly for training but when it comes to like real time,

18:37.520 --> 18:44.000
we are trying to listen to the event bus so that we can listen to the, if some of our features

18:44.000 --> 18:48.080
are coming through the event bus right, we need to factor that and we need to have our model

18:48.080 --> 18:55.760
respond in microseconds or like 100 milliseconds or something. And then we need to make sure that our

18:55.760 --> 19:02.000
that we are doing like parallelization of systems. We are having our DAX like work in a way that

19:02.000 --> 19:08.560
we can parallelize depending on how how the feature vectors are created and everything. And then so

19:09.520 --> 19:15.760
a lot of focus is right now on across the not just like the model has to be good or the algorithm

19:15.760 --> 19:20.240
has to be fast but the whole pipelining that we are doing, it has to be like super fast.

19:20.240 --> 19:25.440
And also the teams who are receiving it, they have to work with the same rigor as we are working

19:25.440 --> 19:32.080
if they want to have like within product intervention. Are you doing much with serverless technologies

19:32.080 --> 19:38.080
for inference? We are doing a lot of work which is serverless but a lot of work which is our own

19:38.080 --> 19:46.240
proprietary internal stuff. Okay, okay. And you mentioned, you mentioned event bus so the idea is

19:46.240 --> 19:52.960
that you've got some model server that is listening for events on an event bus and then hands

19:52.960 --> 19:59.520
that to some model for inference when it sees the appropriate things. There are two ways to do

19:59.520 --> 20:05.360
that actually. So we can read through the topics in real time. Our second thing is also that's

20:05.360 --> 20:11.440
happening is that if a team has a partner teams have sophisticated feature platforms. So what

20:11.440 --> 20:15.760
happens is that they can read from the topic and put it in the feature store from where we can

20:15.760 --> 20:20.400
listen to those features or we can gather those features on the feature store. So both works.

20:20.400 --> 20:26.880
Okay. And so I'm trying to get at other, I guess other challenges that you run into when you're

20:26.880 --> 20:32.240
supporting these real time use cases. Sounds like real time in general is something that you expect

20:32.240 --> 20:37.600
to grow there. You're doing a lot of batch but you're expecting to see more real time over time.

20:38.400 --> 20:43.760
What else do you anticipate having to overcome as you take on more of those use cases?

20:43.760 --> 20:51.200
So what we're also going to do is that for real time systems, we need to have more control

20:51.760 --> 20:59.680
on our overall deployment, our workflows. So what we are also doing is not just for real time but

20:59.680 --> 21:06.080
what we are also trying to do is, as I said, we are trying to centralize the build and centralize

21:06.080 --> 21:13.360
ML ecosystem at Capital One. So not necessarily what my team is doing and what Ali's team is doing.

21:13.360 --> 21:20.800
I see at some point we are going to work together on building something like a more sophisticated

21:20.800 --> 21:26.000
real time serving, more sophisticated integrated batch serving. So we are coming together,

21:26.000 --> 21:33.360
we are trying to do the best practices around like federated learning, automated learning.

21:33.360 --> 21:39.680
So as the system is learning, it's training it's training automatically and then it's providing

21:39.680 --> 21:46.080
better outcomes or better predictions. So we are on that journey, there are a lot of things

21:46.080 --> 21:51.680
that we are working on and I'm pretty sure that we will be able to be almost real time.

21:52.240 --> 21:56.240
I don't think any company is like fully real time but that's just me.

21:56.240 --> 22:01.040
Sure, it's always latency somewhere. Yes. And introducing yourself, you talked about a pretty

22:01.040 --> 22:08.640
wide variety of organization types that you worked at. Can you talk a little bit about how

22:08.640 --> 22:14.960
tackling the kinds of challenges you are discussing here and in the use cases that you are discussing

22:14.960 --> 22:24.720
here are different at a financial services firm like Capital One relative to more of the tech

22:24.720 --> 22:29.680
oriented firm, the startup. What are some of the things that you need to think about that you

22:29.680 --> 22:34.160
haven't had to think about at other places? Yeah, very interesting question Sam. Let me tell you.

22:34.160 --> 22:40.480
So as I told you right, I grew from full stack in general to now being a leader in the

22:40.480 --> 22:46.000
ML space. So I've worked in companies which are like startups to companies which are like Capital One

22:46.000 --> 22:51.120
who are like highly regulated or into it. So the way I would like to answer this question

22:51.120 --> 22:57.040
is in two ways. So if you are working in a startup or in any company who are in its initial ML

22:57.040 --> 23:04.640
journey, you don't think about governance or regulation or compute cost, right? You basically

23:04.640 --> 23:09.680
you don't have a whole lot of rules in place. So what you do is like, oh, I need this. Oh,

23:09.680 --> 23:14.880
let me get this data set and let me just quickly build something. So you feel like very empowered,

23:14.880 --> 23:20.320
you build something quick and snappy. But then when you grow in your ML maturity, that's when you

23:20.320 --> 23:26.800
see like, oh my god, so many issues start surfacing up. Now your cloud pass are out of order. You have

23:26.800 --> 23:31.200
like a data scientist who spun off a big cluster of the three GPUs to train a model and forgot to

23:31.200 --> 23:36.160
shut it, right? And then multiple teams who are doing that, right? So what happens is like your

23:36.160 --> 23:40.960
cloud cars start going up and then you end up seeing that different teams. There are 10 teams

23:40.960 --> 23:46.880
in the company and they all have their ML individual ML platforms or pipelines. So then then the

23:46.880 --> 23:51.120
leadership has to think about and then there is no governance. They are not thinking about PII,

23:51.120 --> 23:58.960
PII, SOX compliance, GDPR, CCPA. As you said, in regulated companies, I can tell you all the names,

23:58.960 --> 24:06.640
right? So then those things kick in, right? So that's why so there is this thing that we're now

24:06.640 --> 24:11.440
eventually there is a tactic that's created, get created. And then the leadership have to make

24:11.440 --> 24:15.920
some RDoS calls around like, hey, we need to throw away work or we need to merge or we need to

24:15.920 --> 24:22.240
merge. But now working in companies which are in the ML maturity space, right? And especially the

24:22.240 --> 24:27.840
regulated environments, what I've seen being a machine learning engineering leader is very important

24:27.840 --> 24:33.280
to standardize the tools. It's very neat. It's very important not just the tools, your processes,

24:33.280 --> 24:39.440
your algorithms, right? What this does is like now these companies are big companies which have a

24:39.440 --> 24:46.400
lot of ML associates, data scientists, MLEs. But what it allows it, it helps them to come with

24:46.400 --> 24:51.200
a centralized process where they can identify they have mechanism, they know how the ingestion

24:51.200 --> 24:56.960
pipelines are working. They know how what's the best way of getting the data? They are scripts

24:56.960 --> 25:02.640
or there are like scripts in place where you just cannot spin off an EC2 by going to your

25:02.640 --> 25:08.080
control plane. You need to follow some rules and practices, right? And then as I'm talking about

25:08.080 --> 25:13.600
governance and auditing. So what happens in like companies like Capra one which are highly regulated,

25:13.600 --> 25:19.600
you need to be able to store your engineering, your training runs, the input and output parameters

25:19.600 --> 25:25.200
that were part of the model, right? So that if needed you are able to recreate the model,

25:25.200 --> 25:31.040
you need to be able to tell the customer that if you get audited why such a decision was taken

25:31.040 --> 25:36.000
fundamentally. And then it's important that you have governance like at Capra one we have our

25:36.000 --> 25:42.320
model review office. So that's where I see the difference. But again I'm not going to shy away

25:42.320 --> 25:49.120
from saying that like all these things add like a lot of processes in place which sometimes

25:49.120 --> 25:56.000
people don't like. And what happens is like these procedures and practices in place,

25:56.000 --> 26:01.680
it at times create a lot of dependencies and then like your time to market or your time to go

26:01.680 --> 26:07.920
to production like slows down. But honestly on this one Sam trust me on this one, it's much better

26:07.920 --> 26:13.360
to be a little bit late than to go to production and then have to deal with the production and compliance

26:13.360 --> 26:23.120
issues. It's it's not fun to do. Meaning in your experience it's better to have those processes

26:23.120 --> 26:29.280
integrated into the development of your model as opposed to trying to bolt them on at the end.

26:29.280 --> 26:37.360
Yes. Yes. And also please follow the processes because everything looks nice but if you ever

26:37.360 --> 26:42.880
get audited because your model behaves a certain way or you have to go through a compliance issue

26:42.880 --> 26:50.480
that takes like weeks or months to work on that. You mentioned this the need for reproducibility

26:50.480 --> 26:56.480
and the idea that you're taking all of your training inputs and training data and kind of

26:56.480 --> 27:02.240
storing that away so that you can reproduce these models. Is that based on internally developed

27:02.240 --> 27:08.720
technology or do you use some external some third party tool to provide for that? No internal build

27:08.720 --> 27:18.000
technology. Internal build technology I can talk a little bit more about it. So in storage costs

27:18.000 --> 27:23.280
are not that great. Storage is cheap. So in without taking name of the company I've worked in

27:23.280 --> 27:30.240
various companies like where logging is our instrumentation is very very important right you need

27:30.240 --> 27:35.360
to instrument what are the features coming and you need to instrument what is the model's output

27:35.360 --> 27:41.040
is and then other things which go in the part of like reprocessing of feature engineering.

27:41.040 --> 27:45.680
So that you have all that data. So now if you get a customer call saying that hey you

27:46.480 --> 27:51.600
said this and I went through this and then maybe that's not the right decision for that customer

27:51.600 --> 27:58.320
then you need to be able to go and see exactly what happened and it helps you by for answering

27:58.320 --> 28:04.000
the question of the customer but also helps you reverse engineer better about what went into

28:04.000 --> 28:09.120
the what went into it and you know like how expandability and responsible AI and all those

28:09.120 --> 28:14.960
things are important. So a good instrumentation of the whole how much ever you can instrument

28:14.960 --> 28:19.680
I think it's never enough. That's just me. That's my engineering mindset.

28:19.680 --> 28:27.760
On the topic of engineering mindset you you kind of alluded to a level of robustness

28:27.760 --> 28:36.400
that's required which makes me think about like testing and the importance of that and that

28:36.400 --> 28:43.040
seems like something that over the past I guess year 18 months like we've kind of gotten to

28:43.040 --> 28:48.640
the state and machine learning where we're you know trying to apply the same level of rigor that

28:48.640 --> 28:56.400
we've had for traditional software to model testing you know have whole companies set up now around

28:56.400 --> 29:02.880
model observability as one kind of expression of of this desire for testing. Can you talk a

29:02.880 --> 29:10.160
little bit about how you approach that for your platforms and teams? Sure so what I want to start

29:10.160 --> 29:17.360
by saying is that what I alluded before also so model when it's on production it's it should

29:17.360 --> 29:23.840
be treated as a piece of software or an API but with more sophistication now because there is the

29:23.840 --> 29:30.320
involvement of the data piece right. Today even today even though you're saying we we are thinking

29:30.320 --> 29:36.880
about like okay MLabs and testing and scalable models still I personally feel a big chunk of time

29:36.880 --> 29:42.320
goes into like creating a sophisticated model which has like a high statistical efficacy.

29:42.320 --> 29:48.240
You want to spend rounds of cycles doing hyperventure to your name feature engineering and everything.

29:48.880 --> 29:56.480
I think defensive coding and exception handling that they are key right there if if anything else

29:56.480 --> 30:01.920
if the model is a piece of software it needs to go through the same rigor right. It needs to have

30:01.920 --> 30:07.280
like end-to-end testing, integration testing, unit testing, load testing, AB testing

30:07.280 --> 30:13.600
but what makes a model special is because there is this data component so data quality testing is

30:13.600 --> 30:19.040
the key and you know what it's interesting as data scientists and machine learning engineers

30:19.040 --> 30:24.960
sometimes we think oh I have spent this humongous cycle of building these features and I've dealt

30:24.960 --> 30:30.480
with everything now my features are good but that's where I think the mistake happens because see

30:30.480 --> 30:35.840
we are the one who are closest to the data the data scientists and ML engineers so I think the

30:35.840 --> 30:43.280
onus is on them to write as part of their code around the defensive coding or data quality test

30:43.280 --> 30:48.800
there is a high ROI in defensive coding right or preventive coding as I mentioned different types

30:48.800 --> 30:54.080
of coding I think data quality testing is the key for example right some of the data quality

30:54.080 --> 31:00.720
testing that we are doing and then I think is value add is checking the data type and the values

31:00.720 --> 31:05.920
of categorical data another one interesting one is the categorical is the cardinality shift right

31:05.920 --> 31:11.920
where there is a sudden shift in the distribution of categories and bam your model is predicting

31:11.920 --> 31:19.200
like it has predicting a particular category data leakage and drift over time and something which

31:19.200 --> 31:25.040
is very close to my heart is missing data there are so many papers around how you want to impute data

31:25.040 --> 31:30.640
and then what are the techniques well particularly for forecasting and anomaly detection that's

31:30.640 --> 31:35.680
going to be a big deal for you yes but then also we need to know where we draw the line let me

31:35.680 --> 31:39.760
talk a little bit more about it right so some you know the feature vectors these days are like

31:39.760 --> 31:45.440
highly complicated they are based on myriad data sources right so I think we need to have some

31:45.440 --> 31:51.360
guardrails and thresholds on how much in which features should be allowed with missing data

31:51.360 --> 31:57.360
how much can be imputed and what we should not be imputing so that's where the responsibility part

31:57.360 --> 32:03.280
comes in also so and at what point the model should just like raise an exception and be like hey

32:04.160 --> 32:10.080
this is not adequate for me to make the predictions meaning at what I'm hearing there is sound like

32:10.080 --> 32:19.600
you you you're speaking to examples where okay you you you kind of do the thing that you learn

32:19.600 --> 32:24.320
in school right you have missing data we're going to impute it but if you don't have if you're not

32:24.320 --> 32:31.120
paying too much attention you could be imputing half of your data and you you really don't know

32:31.120 --> 32:37.280
what your model is basing its decision known it's the signal the noise is not high enough yes exactly

32:37.280 --> 32:42.880
that's what I'm saying like data science is a privilege but it's a responsibility also so we need

32:42.880 --> 32:48.240
to be able to draw a line around what can or cannot be imputed I'll give you a very simple example

32:48.240 --> 32:53.200
and the reason I'm giving you this example because I have carried multiple times at different places

32:53.200 --> 32:59.360
right so I'll you know demographic models we build a lot of demographic models and most of the

32:59.360 --> 33:05.440
times zip port is one of the important features right from which you can drive you can have like okay

33:05.440 --> 33:10.880
short distance from this place long distance or get bunch of other demographic data I've seen

33:10.880 --> 33:16.800
many a times the model is expecting a five digit day zip port but sometimes the users if they it's

33:16.800 --> 33:23.920
a free text they pass in a nine digit and then the mark phase so what I'm suggesting the people

33:23.920 --> 33:28.160
is like hey it's only one or two lines of this extra port which should be part of the model on

33:28.160 --> 33:34.240
the key processing port and it can just save us like bunch of trouble for our use cases right Sam

33:34.880 --> 33:39.840
as I said like we we focus a lot on centralizing of it engineering and operational

33:39.840 --> 33:46.000
regular code standards across capital one so we have standards for coding we do peer review we do

33:46.000 --> 33:52.480
unit testing integration testing end-to-end testing cross validation and like every other company

33:52.480 --> 33:58.720
our data quality testing is evolving to so some of the best industry practices that I've seen

33:58.720 --> 34:04.080
is like creating synthetic synthetic or world and data sets right and then you revisit them

34:04.080 --> 34:09.680
when you find the edge cases other thing we do is like scenario based testing to mitigate output

34:09.680 --> 34:15.440
or surprises are recently I was also reading about how we people do randomizing or first

34:15.440 --> 34:21.040
testing in software engineering that is also becoming becoming like important in the data science

34:21.840 --> 34:29.360
or ML world yes so those are some of the best practices we follow and thinking back to

34:30.560 --> 34:38.720
kind of your role in enabling these these citizen data scientists imagining that

34:38.720 --> 34:45.840
these are things that you want your team thinking about and building guardrails around or

34:45.840 --> 34:51.440
implementing but not necessarily you know that's a lot of cognitive burden to put on a citizen

34:51.440 --> 34:56.640
data scientist to think about you know this and that not impute too much data and that kind of

34:56.640 --> 35:03.760
thing like are they things that you're able to kind of isolate as concerns of your platform as

35:03.760 --> 35:09.280
opposed to concerns of the end user so what we do is as you said we have guardrails built in place

35:09.280 --> 35:15.280
right so where we are today we are doing UI and API based evaluation but where we want to be is

35:15.280 --> 35:20.960
that which we are working towards is like the user just goes on the API go on the UI just say

35:20.960 --> 35:26.480
this is my data press a button and after that we take care of everything right so at every pace we

35:26.480 --> 35:30.800
want a guardrail for example let's just say I'm just going to give an example right let's just

35:30.800 --> 35:38.720
say this user is asking us to frame the model with like some 50 60 gigabyte worth of data right

35:38.720 --> 35:44.880
so we want to be able to do some testing we cannot do like this whole kind of everything but we

35:44.880 --> 35:49.760
want to have some and we want the user to tell us like okay for think about like as a regular

35:49.760 --> 35:56.640
business use case right in the bespoke world what happens is uh the business intelligence

35:56.640 --> 36:02.320
the business analyst or the product sees something is happening on a specific page or something

36:02.320 --> 36:07.200
is happening they think oh there is definitely a signal let's go to the data science team now

36:07.200 --> 36:12.880
and see if they we can have like an ML intervention or like a date or an insight built in during

36:12.880 --> 36:18.480
this journey similarly when people come to us they have already seen oh there has been this fraud

36:18.480 --> 36:24.160
or hey how they are being using something based off excel for the associate student

36:24.160 --> 36:29.520
back to work the uh or sorry in the hybrid work environment right so what's happening there

36:29.520 --> 36:34.480
right so they have some signals so our x our hope is like we'll be at a place where they just

36:35.840 --> 36:41.680
go to our UI they say where the data is which are some of the critical features that they need

36:41.680 --> 36:48.080
and then we have some reg uh based on like our learnings as we are learning every day we go

36:48.080 --> 36:52.320
until like okay for this particular feature these are important we put the guardrails that okay

36:52.320 --> 36:57.600
this kind of data quality checks are in place this much data needs to be there especially as you

36:57.600 --> 37:03.440
said anomaly like time series right what can be imputed what's the best way of imputing we do

37:03.440 --> 37:10.000
some kind of data cleaning randling show the features then have the user take a look at it and say

37:10.000 --> 37:15.920
like okay press the next button we're training happens then they deploy whether they want to go

37:15.920 --> 37:21.200
on batch versus that we are time so that's the end state that we are working on can you talk a

37:21.200 --> 37:28.080
little bit about you know we've we've talked about use cases and kind of technology as far

37:28.080 --> 37:32.640
year in this position where you see all that but you're also kind of looking the other direction

37:32.640 --> 37:39.520
in the organization uh towards the the business side of things um can you talk a little bit about

37:39.520 --> 37:47.840
how you think about kind of ROI of machine learning and um getting buy-in from executives and

37:47.840 --> 37:53.840
you know all the things that you need to think about as uh ML leader sure so let me tell you first

37:53.840 --> 38:00.560
what is working for us right so when we complete a project for our internal user right internal

38:00.560 --> 38:06.560
client right we create detailed documentation around what the problem statement was what were the

38:06.560 --> 38:12.720
challenges that the team was facing what is the solution that we provided what were the results

38:12.720 --> 38:18.480
of that solution and then what's a value proposition like what's a nibbett or like dollars we are

38:18.480 --> 38:26.000
helping in like operational efficiencies and then we ask them as they feel okay to write some

38:26.000 --> 38:30.800
testimonials and then what are the next steps right so there's also our learning like what really

38:30.800 --> 38:37.440
went well what would be done to get better next time right and then what we do is like we uh we

38:37.440 --> 38:43.360
promote our wins with our stakeholders and leaders across the enterprise and then personally as

38:43.360 --> 38:50.240
a leader once uh once we have like some proof points in terms of like ROI and better user experience

38:50.240 --> 38:56.560
it keeps the leadership engaged and that also helps us like okay now that we are preventing

38:56.560 --> 39:04.640
X million dollars here oh it means like if we can invest more in here to like tackle similar kind

39:04.640 --> 39:12.720
of use cases etc so at capital one what we have think what we see is that ROI can be not just money

39:12.720 --> 39:18.880
it's like I personally think it's three things it's like improving user experience generating

39:18.880 --> 39:25.520
operational efficiencies and driving the top line so those are some of the things because not every

39:25.520 --> 39:31.760
model will give you some money directly it could be like oh because we have done that so our analysis

39:31.760 --> 39:37.280
time has decreased from a month to now like two days or something right so those are the ways so

39:37.280 --> 39:44.160
not everything we can put a dollar that we want directly and so have you you know through your

39:44.160 --> 39:54.160
your track record have you demonstrated kind of consistent ROI such that you know the only thing you

39:54.160 --> 39:59.440
know you you would do 10 times as many projects if you had enough people to do them like is it

39:59.440 --> 40:07.360
our is talent the constraint or you know you're still buying for funding relative to other potential

40:07.360 --> 40:16.000
efforts or uses of a resource at the company our team has established ourselves so we are helping

40:16.000 --> 40:24.240
drive the ROI by helping other teams operational efficiencies and like better user experience

40:24.240 --> 40:31.280
so our leadership like trust us and then we haven't hit like the roadblock where we go and say

40:31.280 --> 40:36.400
like we need some resources they understand that but what we also need to do is like we need to

40:36.400 --> 40:40.960
have a good justification hey we have done this we are saving this x million dollars if we get

40:40.960 --> 40:46.080
these two other folks to help us out we can bring in another five to ten use cases of similar thing

40:46.080 --> 40:51.120
because and you'll be like hey the shawaier you're saying two people and five to ten use cases

40:51.120 --> 40:55.680
because I want to remind you like whatever we do is we do it in a reusable fashion so

40:56.560 --> 41:02.240
yes so that's love is and so does that is your implication that you're not so concerned about talent

41:02.240 --> 41:12.400
there you you okay no no no I what I mean is this see top talent in industry especially in

41:12.400 --> 41:18.960
ml is it's not easy to get it so you need to be able to continuously motivate them right give them

41:18.960 --> 41:25.680
work which is challenging let them like people want to work even I want to work on things which

41:25.680 --> 41:32.480
I know is impacting my customers right so some challenging statement so what we do is we continue

41:32.480 --> 41:42.000
to grow our engineers our ml ml folks are data scientists right and also there we are what we do

41:42.000 --> 41:47.360
is like as we are on this cutting edge or bleeding edge of ml right as we are improving our stack

41:47.360 --> 41:53.520
what we continue to do is like we invest in our in our in our associates we train them we

41:53.520 --> 41:59.280
retrain them right and also we have like a strong pipeline of external candidates for which

41:59.280 --> 42:04.800
we have like a very rigorous process built in and then I think you have talked to buy an

42:04.800 --> 42:09.440
an alley before and they might have also talked to you about like how capper one is so invested

42:09.440 --> 42:16.320
and like working with universities like MIT UVA and everybody so we have like and especially

42:16.320 --> 42:22.480
when it comes to ml right I'm very impressed with all the efforts we are putting in we have like this

42:22.480 --> 42:29.360
ml training program we have a product manager ml training program we have like a PhD program

42:29.360 --> 42:36.400
so capper one is doing a lot to keep its associates on this bleeding edge of ml technology and also

42:36.400 --> 42:42.640
we have this DEI like diversity inclusion and belonging kind of culture where we are also

42:42.640 --> 42:50.160
trying to attract up talent from the industry on those on those principles and to be clear my

42:50.160 --> 42:55.280
implication wasn't that you didn't care about your talent or anything like that it was more

42:55.280 --> 43:02.720
was the degree to which talent was a constraint for your particular team ml is interesting because

43:03.360 --> 43:07.840
it's not like saw a simple software in simple engineering where you learn something new packages

43:07.840 --> 43:14.400
like honestly Sam I try to keep myself of the technology by the time I I like carve out time to

43:14.400 --> 43:20.640
do something and I'm like yes this weekend I'm going to study that and then then a new technology

43:20.640 --> 43:27.360
or new thing is out right I was looking at this 2022 Gartner paper where they were talking

43:27.360 --> 43:32.320
about some friends and everything and I just wrote down like five or six things that I'm going to

43:32.320 --> 43:36.640
study in next one or two months and I was then I started talking to my colleagues at capper one

43:36.640 --> 43:41.040
and I was like very impressed by some of the things our team and they are already doing which is

43:41.040 --> 43:48.240
on the Gartner uh next two to five years so there is in ml you need to keep yourself like always

43:48.240 --> 43:56.160
learning it's tough moves quickly it's fun how do you think the way that machine learning is

43:57.200 --> 44:02.160
approached there at capital one will evolve over the next I don't know three years

44:02.160 --> 44:08.000
so it kind of goes into what I was saying like the 2022 Gartner study with the hype cycle for

44:08.000 --> 44:12.960
data science and machine learning so I as I mentioned I was going through that and what

44:12.960 --> 44:17.120
it suggests companies or industries are going to be moving in next two to five years and I'm

44:17.120 --> 44:22.800
very pleased to see capper one is pursuing that earlier we talked about like capper one is trying

44:22.800 --> 44:29.680
to build this ml coherent ml ecosystem right and what we are trying to do is that how we talked

44:29.680 --> 44:36.960
about my peers team and I think we're trying to serve all personas if you'll be citizen data

44:36.960 --> 44:43.120
scientist traditional data scientist right and what we are trying to do is we are trying to

44:43.120 --> 44:49.600
centralize our platforms we're trying to democratize we are trying to do reusability of

44:49.600 --> 44:56.640
libraries components right so what we are trying to do is like ml available accessible and

44:56.640 --> 45:04.960
leverageable for every for all with necessary guardrails and responsibility in place that's

45:04.960 --> 45:12.160
where I see we are growing there is like a lot of emphasis on overall like redeem automating

45:12.160 --> 45:16.640
the overall machine learning development like cycle wise building robust pipelines for ingestion

45:16.640 --> 45:23.360
data ingestion sophisticated feature platforms training and execution platform I'm thinking all

45:23.360 --> 45:30.960
the things my peers are doing and my team is saying something the CID CICD platforms the feature

45:30.960 --> 45:38.480
and model monitoring right we are investing a lot into ml ops extensively ml observability

45:38.480 --> 45:43.920
another interesting thing is like provisioning clean data and govern access to data are important

45:43.920 --> 45:51.040
these days cost optimizations scalable multi-tenancy platform as you said and like multi-regions so

45:51.040 --> 45:58.160
stabilizing our platforms we are also researching a lot of things around graph ml synthetic data set

45:58.160 --> 46:04.400
which I mentioned before ml ops model ops transfer and federated learning and then because we are

46:04.400 --> 46:09.200
in governance we are in the governance it's I would want to say again and again like we have a

46:09.200 --> 46:14.720
model review office and then we continue to invest in our standards for governance transparency

46:14.720 --> 46:21.440
and accessibility for models so I see like capper one is on the beating edge of ml and I'm very proud

46:21.440 --> 46:26.080
to be here and I'm very impressed by the work my particular organization and all my

46:28.560 --> 46:33.920
sounds like you got a lot going on it's it's fun it's fun it's an awesome journey we are on

46:33.920 --> 46:37.840
awesome awesome with this you thanks so much for taking the time to share with us a little

46:37.840 --> 46:47.280
bit about your team and what you're up to thank you thank you

