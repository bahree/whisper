WEBVTT

00:00.000 --> 00:13.400
Welcome to the Twimal AI Podcast.

00:13.400 --> 00:22.360
I'm your host Sam Charrington.

00:22.360 --> 00:23.680
What's up everyone?

00:23.680 --> 00:28.040
This is Amari, producer of the Twimal AI Podcast.

00:28.040 --> 00:29.040
What about now?

00:29.040 --> 00:32.120
You're probably wondering, where's Sam?

00:32.120 --> 00:37.880
Well on the heels of such an amazing event, we decided it was time for him to take a break.

00:37.880 --> 00:40.040
So he's currently on vacation.

00:40.040 --> 00:45.360
But as they say, the show must go on.

00:45.360 --> 00:51.160
Today we continue our Twimal Con coverage with the first of our panel discussions, culture

00:51.160 --> 00:55.840
and organization for effective machine learning at scale.

00:55.840 --> 01:01.400
In this discussion, moderator Maribel Lopez, founder and principal analyst of Lopez

01:01.400 --> 01:09.440
research, is joined by panelists Jennifer Prinky, founder and CEO of Electio, Eric Colson,

01:09.440 --> 01:16.160
emeritus chief algorithms officer of stitchfix, and partist Norzad, data science manager

01:16.160 --> 01:17.800
at Twitter.

01:17.800 --> 01:22.320
Before we move on, I'd like to extend a huge thank you to everyone that joined us at

01:22.320 --> 01:24.880
Twimal Con earlier this month.

01:24.880 --> 01:29.600
We had an amazing time and we can't wait to see you all again next year at Twimal Con

01:29.600 --> 01:31.600
2020.

01:31.600 --> 01:38.280
And now on to the show.

01:38.280 --> 01:44.960
Without further ado, I would like to welcome up the moderator of our first panel, Maribel

01:44.960 --> 01:48.040
Lopez, founder of Lopez research.

01:48.040 --> 01:49.040
Maribel?

01:49.040 --> 01:54.320
Hi, I'm Maribel Lopez, so I'm the founder of Lopez research and also the founder of

01:54.320 --> 01:59.560
data for betterment with this nonprofit organization that helps companies figure out how to move

01:59.560 --> 02:04.720
forward in the land of AI and giving them information about career change and other things

02:04.720 --> 02:05.720
in that area.

02:05.720 --> 02:09.080
And I could think of no better thing to do than to be here today talking about culture

02:09.080 --> 02:14.280
and organization and how to do things like effectively have machine learning at scale.

02:14.280 --> 02:16.800
So without further ado, I'm going to jump right in it.

02:16.800 --> 02:21.360
One of the things that we're seeing with organizations is that there's a tremendous amount

02:21.360 --> 02:24.920
of talk about artificial intelligence in organizations.

02:24.920 --> 02:30.160
Not necessarily a lot of companies or executives or a line of business people actually really

02:30.160 --> 02:34.560
understanding what that means, how to do it.

02:34.560 --> 02:37.560
Sometimes it's like I'm just going to go out and buy something with machine learning

02:37.560 --> 02:39.400
in it and see how that works out.

02:39.400 --> 02:45.240
So one of the challenges I think that all of you in the organization are facing is how

02:45.240 --> 02:50.880
do we get the different groups in an organization to effectively work together?

02:50.880 --> 02:55.640
So if we look at this, if you have a data science team, data engineering, how do you actually

02:55.640 --> 03:00.080
work with line of business managers, how do you work with the C-suite so that you can

03:00.080 --> 03:05.920
actually get to delivering business value with AI technologies and tools?

03:05.920 --> 03:09.560
So I thought that might be a good first place to start as we're talking about culture

03:09.560 --> 03:16.560
and organization because technically you probably can't decide what kind of organization

03:16.560 --> 03:20.240
you want to switch it to, centralize or decentralize, but you will have to try to make

03:20.240 --> 03:23.400
this effective and efficient and delivering business value.

03:23.400 --> 03:26.600
So maybe we can start there, maybe we will start with Jennifer.

03:26.600 --> 03:32.240
You want to give us a few pointer tips or how you've seen this work in terms of talking

03:32.240 --> 03:35.560
to the different groups within an organization.

03:35.560 --> 03:43.280
Yeah, no, I saw as you stated before completely agree that this is certainly probably a

03:43.280 --> 03:46.280
bigger challenge than the technology itself, right?

03:46.280 --> 03:51.520
So the first thing I would say is like first of all, I have very good news is that there

03:51.520 --> 03:56.480
is a very easy way to solve the way you communicate with the C-suite or product management and

03:56.480 --> 04:02.040
that is by educating the people you're going to communicate with.

04:02.040 --> 04:07.800
And the easiest way to do this is to go all the way to an MBA program and teach them and

04:07.800 --> 04:14.400
basically prepare the next generation of leaders and product managers to be ready to interact

04:14.400 --> 04:19.640
with people who are going to handle machine learning research and machine learning product,

04:19.640 --> 04:20.640
right?

04:20.640 --> 04:24.920
So we're basically in survival mode right now, it means that we have to figure out a way

04:24.920 --> 04:32.240
to make it until this next generation of leaders becomes, comes in place and these are actually

04:32.240 --> 04:35.320
the people who are either reporting to or working with, right?

04:35.320 --> 04:40.760
I mean, so in the meantime, obviously, there are different segments and so to me personally

04:40.760 --> 04:46.080
like one of the biggest challenges I always had was like, define what product management

04:46.080 --> 04:50.480
means for machine learning, but that's a long, long story probably.

04:50.480 --> 04:55.120
Okay, we're going to circle back to defining what project management means in machine learning

04:55.120 --> 04:56.120
in a second.

04:56.120 --> 04:58.800
Eric, maybe have some thoughts on this?

04:58.800 --> 04:59.800
Well, sure.

04:59.800 --> 05:05.720
I think one thing you can do to align yourself with the C-suite is you can become the C-suite.

05:05.720 --> 05:09.800
So at StitchFix, we do have a special arrangement, the chief algorithms officer, an officer

05:09.800 --> 05:14.320
of the company, up their peers with the CFO and CTO and so forth.

05:14.320 --> 05:18.280
So that does help change things easier to get alignment as peers rather than somewhere

05:18.280 --> 05:21.120
buried down the org structure.

05:21.120 --> 05:26.120
With officer representation, what happens is you become accountable, you're not a supportive

05:26.120 --> 05:30.360
team to other folks, instead you have your own goals, revenue goals or other metrics,

05:30.360 --> 05:31.360
right?

05:31.360 --> 05:33.480
That you are accountable for not supporting another team.

05:33.480 --> 05:38.240
And so that changes things dramatically on how the company embraces data science and

05:38.240 --> 05:41.560
the other thing that happens with officer representation is you get influence.

05:41.560 --> 05:46.760
You can influence the way companies work and you can do away with the notion of big ideas

05:46.760 --> 05:51.400
and instead companies have hypotheses that are put to the test and it, and once the company

05:51.400 --> 05:55.840
learns after a short period of time that they're wrong a lot, then they set the change of

05:55.840 --> 05:59.680
the way they do even engineering where they're not going to build a certain feature, they're

05:59.680 --> 06:04.440
going to build a general platform to try 100 features because Lord knows the first one's

06:04.440 --> 06:05.440
going to be wrong.

06:05.440 --> 06:09.400
And you need to iterate and do things a little more generally.

06:09.400 --> 06:14.200
So that's one way to go about it is if you get the actual officer representation and

06:14.200 --> 06:18.400
it's, I'll be honest, it's a much easier way to do it than to try to manage it from down

06:18.400 --> 06:19.400
below.

06:19.400 --> 06:25.120
So if you're fortunate enough to be in that situation, it actually is something I highly recommend.

06:25.120 --> 06:31.480
Yeah, I know part of you actually are in a company that has a lot of data behind it and

06:31.480 --> 06:36.080
a lot of data science behind it, but there's also a lot with the marketing organization

06:36.080 --> 06:37.400
and sales.

06:37.400 --> 06:41.840
So how have you looked at approaching this problem in your organization?

06:41.840 --> 06:44.560
Absolutely.

06:44.560 --> 06:51.720
The way I approached working with sales and marketing is kind of the same way as I think

06:51.720 --> 06:56.280
about data science working with these various product teams.

06:56.280 --> 07:03.720
Nowadays, you have continuous integration and you have online products, products in the

07:03.720 --> 07:04.720
cloud.

07:04.720 --> 07:12.000
So products are being launched almost every day and product is changing every day.

07:12.000 --> 07:16.920
And because of that, the way data science is working with the engineering teams needs

07:16.920 --> 07:25.640
to be fully integrated, looking at every feature, launch, every experiment, every kind of change

07:25.640 --> 07:30.680
in order to make sure that the data reflects that and we're accounting for it for in building

07:30.680 --> 07:34.680
our models, updating our models and so on.

07:34.680 --> 07:40.920
And so is the same with sales and marketing because in the past, there were various versions

07:40.920 --> 07:48.680
of, let's say, a product, Windows 95 and the specifications were already made clear.

07:48.680 --> 07:54.400
There was enough time for sales marketing to understand what the market would be like,

07:54.400 --> 07:59.520
but also be able to fully understand the product to go and sell.

07:59.520 --> 08:01.000
Now that's changing.

08:01.000 --> 08:07.000
The product is changing so fast in order for sales to know what to sell.

08:07.000 --> 08:14.440
They need to be as integrated within the kind of product as much as possible to know exactly.

08:14.440 --> 08:21.160
Okay, the real estate on the app is going to be one-tenth of what it used to be so we

08:21.160 --> 08:23.960
need to communicate that to our partners.

08:23.960 --> 08:30.160
Or the targeting algorithm will change and so we're actually going to bring in 10 times

08:30.160 --> 08:38.000
more traffic to your product and so sales could kind of be in the loop for that to be able

08:38.000 --> 08:43.600
to communicate that to the partners and that's how we can like marketing and sales up for

08:43.600 --> 08:44.600
success.

08:44.600 --> 08:45.600
That makes sense.

08:45.600 --> 08:50.400
Having that data and insight to know what's going to happen next so that they can plan

08:50.400 --> 08:53.200
and make changes to their models important.

08:53.200 --> 08:58.800
Now we had a session earlier where Libas was talking about some other things that they

08:58.800 --> 09:01.800
did so that's a longstanding established company.

09:01.800 --> 09:05.280
Jennifer, I know that you actually have done some work with Walmart in the past.

09:05.280 --> 09:09.320
Have you seen any differences in terms of how to think about that?

09:09.320 --> 09:13.200
They're a company that's had a lot of data that's been working with data for a long time.

09:13.200 --> 09:17.880
Did you see a change happen over the course of the time that you worked there in terms

09:17.880 --> 09:19.960
of how they worked with it?

09:19.960 --> 09:26.480
Also when I joined Walmart, one of the big change I had to provide to the company is like,

09:26.480 --> 09:29.600
I think you were talking about integration earlier.

09:29.600 --> 09:33.480
Something I would also like to state here is that I think one of the biggest challenge

09:33.480 --> 09:41.160
like a machine learning team is going to have is lack of integration with engineering.

09:41.160 --> 09:45.880
If you do have that integration, it puts you in a position where you are fully responsible

09:45.880 --> 09:47.200
for what you're building.

09:47.200 --> 09:50.720
It's almost like you do some machine learning research.

09:50.720 --> 09:54.920
You can create a product with it and prove to the C suite and the rest of the organization

09:54.920 --> 09:58.920
that this is actually going to provide money for the company.

09:58.920 --> 10:01.760
Before we talked about Walmart, I would like to state something else that's actually

10:01.760 --> 10:02.760
pretty interesting.

10:02.760 --> 10:09.440
I was lucky to have both like a machine learning at Atlassian and I managed a machine learning

10:09.440 --> 10:12.680
at a smaller startup figure eight.

10:12.680 --> 10:14.680
In both cases, we have the different structures.

10:14.680 --> 10:18.720
For Atlassian, for instance, I was really lucky to have the opportunity to build the

10:18.720 --> 10:25.040
entire team from scratch and basically I brought in like a basically 50% of the team was

10:25.040 --> 10:26.040
engineering.

10:26.040 --> 10:31.640
I mean, so it meant that the algorithms we were building, we were actually able to create

10:31.640 --> 10:36.080
and fully prototype on our own and it was much easier to push this production.

10:36.080 --> 10:40.880
We had other challenges related to the internal organization within Atlassian where you had

10:40.880 --> 10:43.200
to push that into specific products.

10:43.200 --> 10:46.320
But at least there was a prototype that could exist.

10:46.320 --> 10:52.200
By a position when I was a figure eight, my team was 100% machine learning scientist

10:52.200 --> 10:55.000
and this is something I had no control of because the team was already established when

10:55.000 --> 10:56.000
I joined.

10:56.000 --> 11:00.760
Unfortunately, basically we were constantly frustrated that things would not go to production

11:00.760 --> 11:07.040
because there was no engineering that could actually bring these things to production.

11:07.040 --> 11:09.360
That brings me back to Walmart.

11:09.360 --> 11:14.080
I think one of the challenges like companies like a few years ago did not necessarily have

11:14.080 --> 11:19.160
this understanding that a machine learning team is not an engineering team.

11:19.160 --> 11:22.360
They don't think the same way, they don't function the same way and a machine learning

11:22.360 --> 11:27.320
scientist or data scientist is not trained to write production level code and push this

11:27.320 --> 11:28.800
to production.

11:28.800 --> 11:34.040
And so basically this means you have to rethink the organization.

11:34.040 --> 11:40.160
At Walmart, that was a huge challenge because when the machine learning teams started building

11:40.160 --> 11:47.520
new algorithms, for instance, and in particular when we know that because we are machine learning

11:47.520 --> 11:50.960
people, we know that models need to be retrieved on a regular basis.

11:50.960 --> 11:56.640
But the C-suite, except if the C-suite is an engineering scientist, does not know that

11:56.640 --> 12:00.680
you would be surprised the number of people, you created this algorithm, why do you have

12:00.680 --> 12:01.680
to retrain it?

12:01.680 --> 12:06.080
And this is not something that's, and so this is where machine learning life cycle management

12:06.080 --> 12:10.640
is something you have to push onto the organization if you want to be successful.

12:10.640 --> 12:15.280
I actually think this point of machine learning life cycle management is a huge issue and

12:15.280 --> 12:19.080
largely under-addressed in our communities.

12:19.080 --> 12:25.880
Eric, do you have any concepts or thoughts around either a full stack or life cycle management?

12:25.880 --> 12:32.400
Well, yeah, I have strong opinions on the full stack thing, so the team at StitchFix we

12:32.400 --> 12:35.320
built to avoid what we call handoffs.

12:35.320 --> 12:41.280
We don't like when a research scientist wants to do some modeling, so they partner with

12:41.280 --> 12:44.200
somebody called an ETL developer to get them the data.

12:44.200 --> 12:48.960
And then once they find the model, they have a train, they hand it off to a machine learning

12:48.960 --> 12:50.720
engineer to implement it.

12:50.720 --> 12:54.560
And then they also might employ an inference engineer to measure it, right?

12:54.560 --> 12:58.240
So all that is fine and dandy, but it requires handoffs between that.

12:58.240 --> 13:00.880
And that slows you down.

13:00.880 --> 13:04.080
Handoffs are appropriate when you know what it is you're building.

13:04.080 --> 13:07.440
Say if you're manufacturing something, you've got the requirements are crystal clear

13:07.440 --> 13:11.760
down the millimeter of precision, then you can specialize and do those handoffs.

13:11.760 --> 13:17.160
But when it needs to be iterated on, you're not clear what it is you're building or learning,

13:17.160 --> 13:21.840
then I really prefer to have it in as few hands as possible, ideally, even sometimes

13:21.840 --> 13:25.960
one, one full stack data scientist that can do all those parts through the ETL, through

13:25.960 --> 13:30.920
the modeling, implement it him or herself, and set up the AB test appropriately to measure

13:30.920 --> 13:32.080
it.

13:32.080 --> 13:36.200
That's ideal because that person can move as quickly as possible with no handoffs.

13:36.200 --> 13:42.360
So and again, the benefit of the golden data science is to learn something to implement

13:42.360 --> 13:48.160
some new algorithmic capability, preferably that makes a lot of money, but to learn it,

13:48.160 --> 13:49.160
to figure out how to do it.

13:49.160 --> 13:55.080
It's not to do the fine tuning, not to do something more efficient or just a skim, a few pennies

13:55.080 --> 13:56.080
off of something.

13:56.080 --> 14:01.680
It's usually to do something big and profound and something that was new to the company,

14:01.680 --> 14:03.360
a new capability.

14:03.360 --> 14:06.600
And that type of thing, usually with data products, you can't design it up front.

14:06.600 --> 14:07.920
You need to learn as you go.

14:07.920 --> 14:12.000
So you have to design the team to enable them to learn as they go, so they don't get caught

14:12.000 --> 14:14.200
up in so many handoffs.

14:14.200 --> 14:18.480
So that's the thought on the full stack data scientist, as we call it, at Citrix.

14:18.480 --> 14:22.600
Yeah, so what I like about this is it highlights that there are different ways to do it, but

14:22.600 --> 14:29.520
you have to be very specific about understanding what are the different levels that you need,

14:29.520 --> 14:33.200
and who is going to take care of those different levels.

14:33.200 --> 14:37.960
And I think if you're lucky enough and you can find full stack people, that works great.

14:37.960 --> 14:41.120
If you don't have full stack people, you need to know how that you're going to break this

14:41.120 --> 14:45.600
up so that the right people are doing what they're skilled at, but that they're coordinated

14:45.600 --> 14:50.880
enough to make that happen, part of any thought on your side.

14:50.880 --> 14:58.680
I guess the only thing I would add would be around the fact that the data is always changing

14:58.680 --> 15:03.280
because, as we spoke before, the product is always changing.

15:03.280 --> 15:08.280
It's also the fact that sometimes company strategy might be changing, and so you'd want

15:08.280 --> 15:17.760
to update your objective functions accordingly, and another thing is the data could change

15:17.760 --> 15:24.520
because the, you know, your product is growing so fast in additional markets, and suddenly

15:24.520 --> 15:31.320
you have users using the product in a completely different way if you're lucky.

15:31.320 --> 15:38.880
And so all of those various factors kind of change, you know, your product completely.

15:38.880 --> 15:46.160
And so you'd want to be, have people providing always on support to be able to make those

15:46.160 --> 15:48.760
changes in updates as soon as possible.

15:48.760 --> 15:53.000
I'm going to circle back to lifecycle management and maybe we can go down this way and just

15:53.000 --> 15:57.400
talk a little bit about what you think is or isn't happening there and what you think

15:57.400 --> 15:58.800
needs to happen there.

15:58.800 --> 16:01.560
So Eric, why don't we kick off with you?

16:01.560 --> 16:02.560
Sure.

16:02.560 --> 16:07.160
For lifecycle management, so the process I just described earlier is about an initial

16:07.160 --> 16:11.440
implementation of some new capability, and that's what I think goes fastest without

16:11.440 --> 16:16.800
the handoffs, without the specialization you have more of a general full stack data scientist.

16:16.800 --> 16:20.880
That said, once it's in production, supporting it is hard, and so you'll probably need some

16:20.880 --> 16:21.880
help.

16:21.880 --> 16:26.120
And in fact, that's something that's often unintuitive to folks either from the business

16:26.120 --> 16:30.600
side or engineering side is they think that resources will roll off a project once it's

16:30.600 --> 16:31.600
implemented.

16:31.600 --> 16:32.760
And that doesn't happen.

16:32.760 --> 16:35.480
You increase the number of resources you put.

16:35.480 --> 16:39.840
So if something is successful, a new recommendation engine or something, and it's live now, it's

16:39.840 --> 16:42.400
not like you deploy those people to go somewhere else.

16:42.400 --> 16:43.400
No, they double down on it.

16:43.400 --> 16:48.560
They have their best ideas come after implementation, and they can get better, better and better algorithms

16:48.560 --> 16:54.440
in there by testing them against each other and making successive changes to them.

16:54.440 --> 16:59.040
So you end up usually increasing, not decreasing after implementation.

16:59.040 --> 17:01.680
And then the support stuff is problematic.

17:01.680 --> 17:04.960
It becomes more of a burden than actually building the thing.

17:04.960 --> 17:08.680
As you mentioned, data changes a lot, and it could wreak havoc on your stuff.

17:08.680 --> 17:13.240
A new engineering feature goes out and isn't compatible with your algorithm.

17:13.240 --> 17:17.040
Things need to be adjusted and changed pretty constantly.

17:17.040 --> 17:21.500
And that's when you, so you, again, it might take one single person to implement the

17:21.500 --> 17:26.000
capability, but you need to start staffing up that's team to support it.

17:26.000 --> 17:29.720
As that person eventually wants to take a vacation now and then, right, and doesn't want

17:29.720 --> 17:33.920
to be left supporting from wherever they go on vacation.

17:33.920 --> 17:37.680
And so you need to add resources later, and that's something that needs to be kind of explained

17:37.680 --> 17:39.080
and anticipated.

17:39.080 --> 17:44.160
But I wouldn't, we do kind of a tough thing, we wait till it's successful and then start

17:44.160 --> 17:45.160
adding the resources.

17:45.160 --> 17:48.560
So it's always a scramble, because a lot of things do fail, and you don't want to set up

17:48.560 --> 17:51.200
people, hey, you're going to support that thing once it's in production, but it never

17:51.200 --> 17:52.840
gets to production.

17:52.840 --> 17:57.400
So you end up in this game of catch-up by design, we consider it as the lesser of the

17:57.400 --> 17:59.080
two evils.

17:59.080 --> 18:02.920
But you do have to plan as best you can that, okay, if these things are successful, you

18:02.920 --> 18:05.440
got to get ready to staff up to help support.

18:05.440 --> 18:10.120
All right, no, I mean, so going back to the example with Walmart, right?

18:10.120 --> 18:15.000
I mean, so actually when I was at Walmart, and we had more and more models coming out

18:15.000 --> 18:20.000
to production, so I actually started serving my team for, basically, ask them, like, for

18:20.000 --> 18:23.360
every, like, a new model that's coming in how much more work do you have?

18:23.360 --> 18:29.800
So after I served my entire team, turns out that when we were, like, basically, like in periods

18:29.800 --> 18:33.680
where the models had to be retrained frequently, for example, close to Black Friday, or this

18:33.680 --> 18:39.040
type of periods, or close to Christmas, people were spending, like, almost 75% of their

18:39.040 --> 18:44.680
time retraining models, relaunching things, because there was no pipeline to do this

18:44.680 --> 18:45.680
automatically.

18:45.680 --> 18:52.160
Actually, like, one of my pushbacks on management was, like, we need, like, a way to systematize

18:52.160 --> 18:57.120
the way that you actually, like, deploy and retrain the models specifically in an environment

18:57.120 --> 19:02.160
where you need to retrain models every day, like, it's very typical for e-commerce or

19:02.160 --> 19:06.840
similar spaces, I'm sure it's true for social media as well, right?

19:06.840 --> 19:11.240
And yeah, and so eventually, what I saw as being a problem, so I almost had the reverse

19:11.240 --> 19:15.480
problem at some point where it's almost like, you have to think about, like, what really

19:15.480 --> 19:19.240
life cycle management means, like, when you come back to this later, right?

19:19.240 --> 19:24.480
But finally, I convinced the company, like, we need a systematic way to retrain this,

19:24.480 --> 19:29.160
like, using technology such as airflow to, you know, like, keep things going even after

19:29.160 --> 19:31.960
you move forward.

19:31.960 --> 19:38.240
Then the management team almost had the sense that the model is taking care of itself,

19:38.240 --> 19:39.240
right?

19:39.240 --> 19:42.840
I mean, so it's going to be retrained fully automatically, and so this is where I think

19:42.840 --> 19:48.440
people are missing the point, like, in life cycle management, you have life cycle management.

19:48.440 --> 19:54.600
So cycles, and this is actually kind of important because, to me, cycle means feedback, right?

19:54.600 --> 20:00.000
And so there is a huge missed opportunity when you try to fully automate this, to take

20:00.000 --> 20:04.640
the feedback of the model you've trained and basically understand the failures, the

20:04.640 --> 20:09.480
reason why, you know, like, you didn't reach 100% accuracy and feed that information

20:09.480 --> 20:11.280
back into the system, right?

20:11.280 --> 20:15.120
So I think, like, it goes back to, like, maintaining in the long term, right?

20:15.120 --> 20:19.920
I mean, the model and, like, fixing the failures you had at first and so forth and so on.

20:19.920 --> 20:24.680
And so I think it's also important to see life cycle management as being an opportunity

20:24.680 --> 20:30.480
to get your model in a better place, not just keeping it up to par or up to speed with

20:30.480 --> 20:31.480
the current data.

20:31.480 --> 20:32.480
Definitely.

20:32.480 --> 20:33.480
Yeah.

20:33.480 --> 20:39.480
100% agree with that just because so many things are changing around the model, whether

20:39.480 --> 20:45.920
it be, like, sometimes policy, there are policy changes and so the way you're labeling

20:45.920 --> 20:53.440
your data will be, will change and you will need to then think about your model differently

20:53.440 --> 20:55.760
in that kind of space.

20:55.760 --> 21:05.200
Again, the way that you will be, your objective functions might change and the user's

21:05.200 --> 21:09.520
might change as we talked about in a different geography and things like that.

21:09.520 --> 21:17.880
And I also wanted to, like, reiterate something that Eric was talking about around kind of

21:17.880 --> 21:24.120
headcount and the fact that if something is successful, you will need more or not less

21:24.120 --> 21:26.800
people to kind of work on that project.

21:26.800 --> 21:32.440
And so if something is a high priority, a lot of times you would hear, could we just borrow

21:32.440 --> 21:38.000
or two data scientists to kind of think about or opportunity size this project?

21:38.000 --> 21:42.280
And it's usually, well, if this is going to be a priority, we need to, like, think about

21:42.280 --> 21:46.280
long-term data science support for this data product.

21:46.280 --> 21:47.280
Yeah.

21:47.280 --> 21:50.240
I think the one thing that you've heard a lot that you should really take away from this

21:50.240 --> 21:56.920
is that one, because of some of the marketing messaging that's gone out around AI, people

21:56.920 --> 22:02.800
do think it's very automated, and that once you get something that it does just take care

22:02.800 --> 22:03.800
of itself.

22:03.800 --> 22:07.520
And that is something that you really have to get ahead of, because this concept of

22:07.520 --> 22:13.600
resources for whether it's new software or tooling so that you can create a more automated

22:13.600 --> 22:19.240
retraining pipeline flow or whether or not it's actual more headcount, this is going

22:19.240 --> 22:23.160
to be a thing in the culture and organization discussion that you definitely have to get

22:23.160 --> 22:24.160
ahead of.

22:24.160 --> 22:28.160
And we're talking to one bank that did not realize that they were, you know, they spent

22:28.160 --> 22:32.480
a long time going through their model, and it was in the chat bot section.

22:32.480 --> 22:36.600
And they had to retrain it every day for a very long time, because they didn't think

22:36.600 --> 22:40.960
that, well, people don't speak in terms such as activate my card.

22:40.960 --> 22:44.320
You know, something a bank would say, not something a human would typically say, you might

22:44.320 --> 22:47.520
say, turn on my card or some other variant of that.

22:47.520 --> 22:51.760
And those types of, you know, feedback loops and interesting learning meant that it takes

22:51.760 --> 22:56.600
a very long time, a lot longer than people think, which means also that programmatically,

22:56.600 --> 23:00.200
you probably have a pipeline, and your pipeline is going to take a lot longer to get through

23:00.200 --> 23:03.920
than your management originally thought.

23:03.920 --> 23:07.040
We have about three minutes left, and I was wondering if there was one question in the

23:07.040 --> 23:13.200
audience that anybody would like to ask if so, when to raise a hand stand up or anything.

23:13.200 --> 23:21.080
Yeah, great talk about educating the whole company about how building ML machine and

23:21.080 --> 23:22.080
AI product is.

23:22.080 --> 23:28.480
I hear a lot, some solution is to hire different people into the team, so the team actually

23:28.480 --> 23:31.760
have different kind of knowledge they can help each other out.

23:31.760 --> 23:37.280
I think there's another dimension of what's your take is there's a whole company.

23:37.280 --> 23:39.160
You can't solve all the problem.

23:39.160 --> 23:40.160
Like you need data.

23:40.160 --> 23:42.440
Are you going to build the entire data lake yourself?

23:42.440 --> 23:46.920
Are you going to build the entire computational layer for yourself as well?

23:46.920 --> 23:51.640
How would you educate almost like it takes a whole village to build it?

23:51.640 --> 23:52.640
But you're right.

23:52.640 --> 24:00.800
There are certain parts of certain capabilities that the data science team is totally autonomous

24:00.800 --> 24:04.960
for, but most things you're partnering with somebody, they're something with marketing

24:04.960 --> 24:08.360
or merchandising other teams, and it does take a village.

24:08.360 --> 24:13.480
You need a lot of it, and a lot of times integration with engineering, but because data science

24:13.480 --> 24:18.240
works differently, right, much more iterative and much more uncertain inherent uncertainty

24:18.240 --> 24:23.160
in what it is we're building and what we'll find and what becomes significant, you have

24:23.160 --> 24:27.200
to plan for that iteration, and since it's the data science team that works differently

24:27.200 --> 24:33.320
from the rest, what we've done is we've made it a combat that we build the APIs that engineering

24:33.320 --> 24:34.320
will integrate with.

24:34.320 --> 24:38.280
They call the APIs, and that abstracts us, right, we're now behind an API that they're

24:38.280 --> 24:43.200
going to call, so we can change things and test things as much as we can and we don't

24:43.200 --> 24:46.880
need to coordinate those, right, because they're just calling the same API before.

24:46.880 --> 24:53.640
So the little tricks like that really help to decouple teams, and yet still work together.

24:53.640 --> 24:57.600
We have to be aligned on the goals of what we're doing, and then when we work with marketing

24:57.600 --> 25:04.040
and merchants, for example, there's no APIs for buying merchandise or for making new

25:04.040 --> 25:05.040
creatives.

25:05.040 --> 25:11.080
So those are more of a formal relationship that you have, and you want to blend both of

25:11.080 --> 25:15.760
their experiences, you get some of the domain expertise from marketers and merchants,

25:15.760 --> 25:19.880
what they know, and then also get what the data is telling you, which are sometimes very

25:19.880 --> 25:24.720
complementary or different or even contradictory, and both together are usually much better

25:24.720 --> 25:26.720
than anyone on their own.

25:26.720 --> 25:27.720
Any other comments?

25:27.720 --> 25:32.800
No, so I was going to say, so you're actually like a similar comment to what you just

25:32.800 --> 25:33.800
said, right?

25:33.800 --> 25:37.960
I mean, I just want to build on top of that, so Atlassian, we had like a similar kind

25:37.960 --> 25:43.880
of model, so we actually like the data science-lash machine learning team was under the platform

25:43.880 --> 25:49.160
department, and so basically we're like a team that would service the other teams.

25:49.160 --> 25:52.800
And so similarly to what you said, like we had like either APIs, and we're like basically

25:52.800 --> 25:54.640
in charge of building a model, right?

25:54.640 --> 25:59.120
So I think something that's very important to note here, and I think like a not specific

25:59.120 --> 26:01.280
to Atlassian or any company, right?

26:01.280 --> 26:05.720
There is like really like machine learning research, and there is machine learning product,

26:05.720 --> 26:06.720
right?

26:06.720 --> 26:12.960
So for instance, like you, I can imagine a company in which you have like the machine learning

26:12.960 --> 26:17.800
team, the deep, deep down machine learning team that creates, let's say, an OCR model,

26:17.800 --> 26:21.640
and then there is a product or an applied machine learning team that actually applies this

26:21.640 --> 26:25.280
model to create cool new AI products, right?

26:25.280 --> 26:27.280
And these don't need to be the same team, right?

26:27.280 --> 26:31.040
I mean, that's almost the way that I see that it was actually pretty successful to do

26:31.040 --> 26:35.720
that at Atlassian because we would empower the rest of the organization of integrating

26:35.720 --> 26:40.200
AI in their own products, even though they were not AI engineers or machine learning scientists

26:40.200 --> 26:42.200
themselves.

26:42.200 --> 26:43.720
Closing common partners?

26:43.720 --> 26:50.960
I think one aspect of being able to get by and to get more support from engineering on

26:50.960 --> 26:57.760
let's say issues of data quality or building data pipelines was to show kind of the impact

26:57.760 --> 27:04.040
and the fact that they could move faster if, you know, through that collaboration, they

27:04.040 --> 27:10.520
would be able to ship with more confidence and kind of showing that over a couple of

27:10.520 --> 27:11.520
screens.

27:11.520 --> 27:13.200
So slow them down, but speeds them up.

27:13.200 --> 27:14.200
Exactly.

27:14.200 --> 27:15.200
Excellent.

27:15.200 --> 27:16.200
So with that, thank you for your time and attention.

27:16.200 --> 27:17.200
We're finished.

27:17.200 --> 27:28.920
All right, everyone, that's our show for today.

27:28.920 --> 27:36.200
To learn more about today's show or any of our panelists, visit twemalai.com slash shows.

27:36.200 --> 27:41.200
Head over to twemalcon.com slash news to check out Twemalcon shorts.

27:41.200 --> 27:46.960
The series of short interviews recorded straight from the Twemalcon community hall.

27:46.960 --> 27:59.360
Thanks.

