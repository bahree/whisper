WEBVTT

00:00.000 --> 00:13.400
Welcome to the Twimal AI Podcast.

00:13.400 --> 00:22.960
I'm your host Sam Charrington.

00:22.960 --> 00:25.880
Sam is back on the road for the next few weeks.

00:25.880 --> 00:30.020
If you're hearing this on October 31st, you can catch him at TensorFlow World in Santa

00:30.020 --> 00:31.620
Clara.

00:31.620 --> 00:35.800
Next week he'll be at Microsoft Ignite in Orlando, and the week after that, a cube

00:35.800 --> 00:37.520
con in San Diego.

00:37.520 --> 00:40.920
If you see him wandering around, please pull up on him.

00:40.920 --> 00:41.920
Say what's up.

00:41.920 --> 00:45.640
Grab one of our awesome new stickers, or maybe even snap a selfie.

00:45.640 --> 00:49.800
He loves that kind of stuff.

00:49.800 --> 00:54.880
But before we move on, last week we published a show featuring an interview with Phoebe

00:54.880 --> 01:00.480
Devries and Brendan Meade about their paper, deep learning of aftershock patterns following

01:00.480 --> 01:02.520
large earthquakes.

01:02.520 --> 01:06.440
It turns out that since that interview was recorded, some questions have been raised

01:06.440 --> 01:09.560
about the research methodology used in the paper.

01:09.560 --> 01:13.680
This was brought to our attention by Raju Shah, a longtime listener and friend of the

01:13.680 --> 01:17.240
show, who initially raised the concerns.

01:17.240 --> 01:21.680
The issue has been covered in numerous articles, links to a couple of which will add to a

01:21.680 --> 01:23.680
note on the show notes page.

01:23.680 --> 01:26.800
Sorry, we missed this one before publishing.

01:26.800 --> 01:30.680
Happy Halloween, enjoy the show.

01:30.680 --> 01:33.120
All right, everyone.

01:33.120 --> 01:39.120
I am here in Santa Clara for the TensorFlow World Conference, and I've got the pleasure of

01:39.120 --> 01:41.760
being seated with Omoju Miller.

01:41.760 --> 01:45.360
Omoju is a senior machine learning engineer at GitHub.

01:45.360 --> 01:48.680
Omoju, welcome to the Tomel AI podcast.

01:48.680 --> 01:50.320
Thank you for having me.

01:50.320 --> 01:55.640
It's great that we finally got this opportunity to have this chat for folks that are listening

01:55.640 --> 01:56.640
in.

01:56.640 --> 02:02.800
We've been trying to connect on this chat for quite some time, maybe about a year, yeah.

02:02.800 --> 02:06.760
And not only do we get to finally have it, but we get to finally have it in person here

02:06.760 --> 02:08.560
in sunny California.

02:08.560 --> 02:12.880
I'm not in my head, yes.

02:12.880 --> 02:17.920
As is typical for us, why don't we get started by talking a little bit about your background?

02:17.920 --> 02:21.120
How did you get started and interested in machine learning?

02:21.120 --> 02:24.080
When I got started in machine learning, it wasn't called machine learning.

02:24.080 --> 02:29.120
It was just computer science, graduate work.

02:29.120 --> 02:37.120
I think this was around 1999, 2000, and this is C++, there were no packages, you have

02:37.120 --> 02:39.080
to write everything yourself.

02:39.080 --> 02:42.360
I was taking graduate classes, I was a graduate researcher.

02:42.360 --> 02:43.360
This is what I walked on.

02:43.360 --> 02:47.720
I used MATLAB, but then I realized that this is too academic.

02:47.720 --> 02:49.360
Now we're going to apply this thing.

02:49.360 --> 02:54.360
So I pivoted to more knowledge representation on the semantic web.

02:54.360 --> 02:58.920
We had a more press and realistic project to work with the Department of Defense.

02:58.920 --> 03:00.920
And so that's what I did.

03:00.920 --> 03:01.920
2012.

03:01.920 --> 03:03.920
This is like owl ontologies and I can't stop.

03:03.920 --> 03:04.920
Yeah, owl ontologies, yes.

03:04.920 --> 03:09.120
I will have you know, we built one of the first sensor ontologies on owl.

03:09.120 --> 03:10.120
Oh really?

03:10.120 --> 03:13.360
Yes, and I think of it by still one of the most cited in that area.

03:13.360 --> 03:14.360
Oh wow.

03:14.360 --> 03:15.360
But I like that kind of stuff.

03:15.360 --> 03:21.120
I like to do like motors, buttons, motors, torrents, first other predicate logic.

03:21.120 --> 03:22.120
I like that.

03:22.120 --> 03:23.120
It's very clean and clear.

03:23.120 --> 03:25.120
It never quite happened for the web the way it was supposed to do.

03:25.120 --> 03:26.120
It never did.

03:26.120 --> 03:27.120
I don't know what happened.

03:27.120 --> 03:28.640
Well, actually, I do know what happened.

03:28.640 --> 03:30.640
Probabilistic models happened.

03:30.640 --> 03:32.400
Probabilistic models happen.

03:32.400 --> 03:33.640
We have lots more data.

03:33.640 --> 03:38.000
We don't have to do that logical reasoning with enough data.

03:38.000 --> 03:41.240
We can understand like the norms of things and it's good enough.

03:41.240 --> 03:44.320
Humans, I good enough first fit model.

03:44.320 --> 03:48.120
We don't need to have the entire thing, but a good enough solution we can take it there.

03:48.120 --> 03:50.400
So probabilistic models were good enough.

03:50.400 --> 03:53.600
And then Google came and existed.

03:53.600 --> 03:55.080
And that was the end of that.

03:55.080 --> 03:56.080
And it works.

03:56.080 --> 03:57.080
Right.

03:57.080 --> 04:02.360
So I went to parental leave and by time I came back, all the packages had been created.

04:02.360 --> 04:05.400
There was a real ecosystem now for machine learning.

04:05.400 --> 04:10.440
And I actually wanted to stop to study more about how to actually acquire technical knowledge.

04:10.440 --> 04:15.040
Luckily enough, I went to Berkeley where they actually had programs where I could do this.

04:15.040 --> 04:16.040
And I created it.

04:16.040 --> 04:17.040
You need to enter the program.

04:17.040 --> 04:18.040
Yeah, at Berkeley.

04:18.040 --> 04:19.040
Okay.

04:19.040 --> 04:20.040
You know, they had this little small program.

04:20.040 --> 04:21.120
I could do that at Berkeley.

04:21.120 --> 04:25.120
And I was, I also was listening to a lot of JZNB on say, to be honest.

04:25.120 --> 04:27.120
So I was like, I need to spark you too.

04:27.120 --> 04:28.120
Yeah.

04:28.120 --> 04:29.120
I like language.

04:29.120 --> 04:30.120
I love rap music.

04:30.120 --> 04:32.120
So I'm just like, you know what?

04:32.120 --> 04:36.400
Wouldn't it be cool if they actually had like an NLP rap unit?

04:36.400 --> 04:38.480
Like why we always didn't poke in and all this stuff?

04:38.480 --> 04:39.480
Like I like rap music.

04:39.480 --> 04:42.840
A lot of what JZ is thinking, that's what I want to do.

04:42.840 --> 04:45.040
My NLP on is the rap corpus.

04:45.040 --> 04:46.040
Okay.

04:46.040 --> 04:48.920
So we were able to like do that unit in classes.

04:48.920 --> 04:54.080
And I just wanted to investigate like cultural approaches to actually acquiring technical

04:54.080 --> 04:56.280
knowledge.

04:56.280 --> 05:00.960
If people are not, if people are either passionate or extremely dispassionate, but there's

05:00.960 --> 05:07.360
some kind of emotional response versus just like nothing boring, and if people already

05:07.360 --> 05:12.120
come into an environment with mathematics and reasoning that they already have in their

05:12.120 --> 05:17.760
heads, then they're able to actually truly understand the machine learning is a statistical

05:17.760 --> 05:21.200
based approach to solving human problems.

05:21.200 --> 05:26.200
It's not some kind of, it's not just derivatives and partial differential equations.

05:26.200 --> 05:29.800
It's not, yes, we use that, but it's not math.

05:29.800 --> 05:35.920
It's math applied to human context and modeling that.

05:35.920 --> 05:37.760
That's what I wanted people to get at.

05:37.760 --> 05:42.360
So I did that, and I was really excited about it, I wanted to continue.

05:42.360 --> 05:49.280
And so wait, the connection between that and the rap music in J.C., the specific project

05:49.280 --> 05:50.280
that you...

05:50.280 --> 05:51.280
Yeah, I called it hip-hoppathy.

05:51.280 --> 05:52.280
It was a very small thing.

05:52.280 --> 05:53.280
Hip-hoppathy.

05:53.280 --> 05:54.280
Okay.

05:54.280 --> 05:57.000
I made a little thing, just like a little amiz-bush of such a work, you know?

05:57.000 --> 06:01.400
Because you have to do a PhD, you have to get out of there, you have to do something,

06:01.400 --> 06:03.960
study it, and get out of there.

06:03.960 --> 06:09.000
And I wanted to continue working around how humans actually acquire technical knowledge,

06:09.000 --> 06:15.400
and better yet, helping humans acquire that knowledge faster and solving their problems

06:15.400 --> 06:16.400
faster.

06:16.400 --> 06:23.640
So I was like, who would, who has the largest data on humans and computation?

06:23.640 --> 06:24.640
GitHub.

06:24.640 --> 06:30.440
Oh, it will also be in their interest to actually solve this problem too, because people are

06:30.440 --> 06:35.600
not on GitHub, technical people are on GitHub, a lot of people come on GitHub also to learn.

06:35.600 --> 06:39.320
And GitHub is where we build that technology that helps us move forward.

06:39.320 --> 06:42.760
So it would be a great place if you want to study that and actually do work in that area

06:42.760 --> 06:46.760
to go to GitHub machine learning, and they could build things to actually help people learn

06:46.760 --> 06:49.480
better and get their work done faster.

06:49.480 --> 06:53.240
So I reached out to people like GitHub, became friends with them.

06:53.240 --> 06:56.520
Luckily for me, they were creating a machine learning team.

06:56.520 --> 06:59.480
They asked me to interview, the rest is history.

06:59.480 --> 07:00.480
Here we are.

07:00.480 --> 07:01.480
Attensive flow.

07:01.480 --> 07:02.480
In Santa Clara.

07:02.480 --> 07:03.480
Right, right, right.

07:03.480 --> 07:07.480
So when you first had the idea of doing this at GitHub, there was no machine learning team

07:07.480 --> 07:08.480
at GitHub.

07:08.480 --> 07:09.480
There was no machine learning team.

07:09.480 --> 07:10.480
I was just like, hey, GitHub.

07:10.480 --> 07:11.480
Hi, it's me.

07:11.480 --> 07:12.480
What are you all doing?

07:12.480 --> 07:13.480
You must have data.

07:13.480 --> 07:14.480
What do you have?

07:14.480 --> 07:15.480
What are the plans for you?

07:15.480 --> 07:23.480
If people must have data now, because this is 2017, you existed since 2009.

07:23.480 --> 07:24.480
That's a little years of data.

07:24.480 --> 07:25.480
What are your plans for this data?

07:25.480 --> 07:30.480
I think you should have enough now that are to start using machine learning to help accelerate

07:30.480 --> 07:32.480
certain things.

07:32.480 --> 07:38.880
So coincidentally, or maybe I think would have it, the company in a couple of months decided

07:38.880 --> 07:40.480
that that's also what they wanted to do.

07:40.480 --> 07:43.480
They said they were like, oh, well, I already was already interested in this.

07:43.480 --> 07:46.640
But you just have to come and interview and see if you can help.

07:46.640 --> 07:48.480
She can help us be part of this thing.

07:48.480 --> 07:50.480
That's awesome.

07:50.480 --> 07:57.480
What's your, what's the scope of the mission of the ML team at GitHub and your role in particular?

07:57.480 --> 07:58.480
So I'm a machine learning engineer.

07:58.480 --> 08:00.480
I'm a senior machine learning engineer.

08:00.480 --> 08:02.480
I'm part of the inaugural machine learning team.

08:02.480 --> 08:09.480
Our mission is to use GitHub data to accelerate the transaction cost of developer.

08:09.480 --> 08:12.480
To reduce the transaction cost of developer corporation.

08:12.480 --> 08:13.480
And how do we do that?

08:13.480 --> 08:17.480
We do that by super charging GitHub features with data.

08:17.480 --> 08:20.480
Because everything that people are doing in GitHub, we have a lot of data.

08:20.480 --> 08:24.480
So if you've written issues, we've seen a lot of those issues.

08:24.480 --> 08:27.480
So we know what issues are going to get close faster than others.

08:27.480 --> 08:31.480
If you're looking at the same repos as I am, you're seeing a lot of the same issues too.

08:31.480 --> 08:34.480
Yeah, we're seeing the same issues over and over again, like bugs.

08:34.480 --> 08:37.480
Maybe things live all as bugs and get treated fast enough.

08:37.480 --> 08:40.480
Maybe, okay, how can we like uproot this things like that?

08:40.480 --> 08:41.480
Right.

08:41.480 --> 08:42.480
Yeah.

08:42.480 --> 08:48.480
And so you're building primarily kind of internally focused.

08:48.480 --> 08:51.480
What's the way to think of it?

08:51.480 --> 08:52.480
Is it GitHub features?

08:52.480 --> 08:53.480
Yes, GitHub features.

08:53.480 --> 08:54.480
They're not internal to GitHub.

08:54.480 --> 08:58.480
They are product that are put on GitHub itself.

08:58.480 --> 08:59.480
Okay.

08:59.480 --> 09:05.480
So one of the products we have is when you open a GitHub repo, create a new GitHub repo.

09:05.480 --> 09:09.480
Sometimes they give you suggestions of labels.

09:09.480 --> 09:11.480
That is a machine learning product.

09:11.480 --> 09:14.480
Like, oh, we see that you open this repo.

09:14.480 --> 09:17.480
Maybe you want to add this level of deep learning to it.

09:17.480 --> 09:18.480
Mm-hmm.

09:18.480 --> 09:19.480
Yeah, things like that.

09:19.480 --> 09:20.480
That is an example.

09:20.480 --> 09:21.480
Like, oh, it's a topic.

09:21.480 --> 09:22.480
Add this topic to it.

09:22.480 --> 09:24.480
Oh, this things look like Azure, but are notebooks in it.

09:24.480 --> 09:25.480
It has this in it.

09:25.480 --> 09:26.480
It has that.

09:26.480 --> 09:29.480
Maybe it's like the rest of everything that has all that stuff.

09:29.480 --> 09:30.480
That is all machine learning.

09:30.480 --> 09:31.480
Maybe you want to put this tag on it.

09:31.480 --> 09:32.480
Things like that.

09:32.480 --> 09:36.480
So imagine when you were a part of getting this effort started,

09:36.480 --> 09:40.480
the first thing to do was like look across, you know, GitHub and figure out

09:40.480 --> 09:43.480
where are the places that you inject machine learning.

09:43.480 --> 09:45.480
You mentioned the tags, like discoverability.

09:45.480 --> 09:47.480
It's got to be a challenge.

09:47.480 --> 09:51.480
So, you know, tags and search are probably a place to start thinking about machine learning.

09:51.480 --> 09:52.480
Yes.

09:52.480 --> 09:53.480
Search as a natural one.

09:53.480 --> 09:55.480
Discoverability is a natural one.

09:55.480 --> 09:56.480
Mm-hmm.

09:56.480 --> 10:00.480
So when I came in, I was, yeah, I think it was the fourth person.

10:00.480 --> 10:01.480
Okay.

10:01.480 --> 10:02.480
And that came to the ML team.

10:02.480 --> 10:06.480
So my predecessors, all everybody is still within months of each other.

10:06.480 --> 10:13.480
But like, okay, one of the first things we wanted to do was around helping people find open source

10:13.480 --> 10:17.480
communities where they want to participate because we're an open source platform.

10:17.480 --> 10:19.480
And one of the problems is you have all these skills.

10:19.480 --> 10:20.480
You come and GitHub.

10:20.480 --> 10:22.480
You want to give back some time.

10:22.480 --> 10:24.480
How do you even figure out what open source community you want to join?

10:24.480 --> 10:25.480
Right.

10:25.480 --> 10:27.480
So understanding user interest.

10:27.480 --> 10:32.480
And using that user interest, do recommendations for like open source communities.

10:32.480 --> 10:33.480
Mm-hmm.

10:33.480 --> 10:37.480
And the ideas are like, ah, we see you do a lot of ML stuff in here.

10:37.480 --> 10:39.480
Maybe you're interested in TensorFlow.

10:39.480 --> 10:40.480
Right.

10:40.480 --> 10:45.480
Well, even beyond that look, they have issues that we think you might be interested in.

10:45.480 --> 10:46.480
Right.

10:46.480 --> 10:47.480
And smicking those kinds of suggestions.

10:47.480 --> 10:51.480
So that's discoverability is one matching with open source is another one.

10:51.480 --> 10:53.480
Another one is triaging.

10:53.480 --> 10:57.480
Like, you know, putting labels on issues, maybe helping that with notifications.

10:57.480 --> 10:58.480
Security.

10:58.480 --> 11:02.480
There are so many places that machine learning fits in.

11:02.480 --> 11:03.480
Mm-hmm.

11:03.480 --> 11:07.480
Natural language, understanding of all the readmys and this and that.

11:07.480 --> 11:09.480
And GitHub is a global platform.

11:09.480 --> 11:13.480
So there are things that hasn't been built yet, like localization.

11:13.480 --> 11:15.480
Perhaps machine learning could actually help.

11:15.480 --> 11:18.480
If I'm reading a repo that is mostly written in Cantonese and Mandarin.

11:18.480 --> 11:20.480
And I want to extract that knowledge.

11:20.480 --> 11:25.480
Maybe there's a way we can actually help to do some kind of machine translation of some of the readmys.

11:25.480 --> 11:28.480
So I have some idea of what is in this repo that I could use.

11:28.480 --> 11:29.480
Okay.

11:29.480 --> 11:30.480
Things like that.

11:30.480 --> 11:31.480
Interesting, interesting.

11:31.480 --> 11:33.480
Maybe steps, which is beginning.

11:33.480 --> 11:39.480
And so when I think about kind of the scope of those types of problems and applying those problems.

11:39.480 --> 11:44.480
I'm imagining a lot of, but not everything that you're doing is looking at the code.

11:44.480 --> 11:50.480
And I'm wondering the types of tools that you use to enable that.

11:50.480 --> 11:55.480
Is it all kind of natural language processing or there are other things that.

11:55.480 --> 11:57.480
It doesn't sound like a solve solve problem.

11:57.480 --> 11:59.480
No, it's not.

11:59.480 --> 12:09.480
What are the types of techniques that you're kind of constantly using when you're thinking about building models based off of code?

12:09.480 --> 12:11.480
Machine learning on code.

12:11.480 --> 12:16.480
We are lucky enough at the machine learning team that we have sister team called semantic code team.

12:16.480 --> 12:17.480
Okay.

12:17.480 --> 12:24.480
And these are the folks that actually build parsers and build representations of code as abstract syntax trees.

12:24.480 --> 12:29.480
It's very exciting to work at GitHub because you actually get to do the computer science you learn.

12:29.480 --> 12:31.480
Like, you learn ASTs.

12:31.480 --> 12:34.480
And then you go into the role of the software engineer.

12:34.480 --> 12:37.480
If you're not writing compilers off when you're not using ASTs.

12:37.480 --> 12:40.480
So we have a team that actually does those kind of representations.

12:40.480 --> 12:49.480
And we can then ingest the things that create to actually model and build them representation and embedding of an AST.

12:49.480 --> 12:50.480
Okay.

12:50.480 --> 12:55.480
So that's something that is experimental now is not something that we actually have inside the product.

12:55.480 --> 12:57.480
But it's these are the kinds of things that we're working on.

12:57.480 --> 13:00.480
Like will ASTs help us get there faster?

13:00.480 --> 13:06.480
Or should we model code as an AST or should we model code and treat it like natural language?

13:06.480 --> 13:08.480
These are all these things you have to think about.

13:08.480 --> 13:09.480
Right.

13:09.480 --> 13:11.480
Because it's not natural language.

13:11.480 --> 13:12.480
Right.

13:12.480 --> 13:13.480
Clearly it's not.

13:13.480 --> 13:15.480
But it's a language and it's rules are different.

13:15.480 --> 13:19.480
So maybe then the question is how do you model a graph as an embedding?

13:19.480 --> 13:21.480
So they're all these different kinds of questions.

13:21.480 --> 13:27.480
And that is now a slow little subset of people in the world who do that kind of research.

13:27.480 --> 13:38.480
And the question is is there research in that area that is fine enough that can be brought into a production environment and applied environment and can scale.

13:38.480 --> 13:42.480
They can scale very, very well gracefully.

13:42.480 --> 13:46.480
So these are all the paths we actually have to now pave.

13:46.480 --> 13:50.480
Because we're not necessarily and it has to also happen very, very fast.

13:50.480 --> 13:53.480
Because we're not building something bundled in an IDE.

13:53.480 --> 13:54.480
Right.

13:54.480 --> 13:57.480
So these are all the paths we're learning how to pave.

13:57.480 --> 14:05.480
It sounds like at least a part of your team's charter is keeping an eye on that research horizon

14:05.480 --> 14:10.480
and what's happening there and trying to figure out which of those things are worth playing around with,

14:10.480 --> 14:13.480
far enough along to play around with.

14:13.480 --> 14:16.480
Yeah. And we have people who help us do that. We have our product managers,

14:16.480 --> 14:21.480
who help us, you know, the product managers help to also shape what we're going to pursue.

14:21.480 --> 14:22.480
Yeah.

14:22.480 --> 14:25.480
We have the ML team itself saying these are things that we think are,

14:25.480 --> 14:27.480
these are no longer on the horizon.

14:27.480 --> 14:29.480
I think we can do this now.

14:29.480 --> 14:35.480
Let's walk with our product managers to actually see if we can all have this joint vision and bring this to the product.

14:35.480 --> 14:39.480
Then we have our like, you know, infrastructure team saying,

14:39.480 --> 14:43.480
the infrastructure is solid enough or robust enough that we think we can scale this.

14:43.480 --> 14:48.480
So it's like a multiple stakeholders that we have our managers, our VPs,

14:48.480 --> 14:52.480
who have the longer term vision and does this actually fall in line with the longer term vision

14:52.480 --> 14:56.480
of what we want machine learning to really help with the product.

14:56.480 --> 15:00.480
So we are a small part of a big hole and we have multiple stakeholders,

15:00.480 --> 15:05.480
but luckily not wearing a place that we can all work together as one finely oiled machine

15:05.480 --> 15:10.480
to bring things to reality with maybe like a 12 month horizon.

15:10.480 --> 15:15.480
So here at the conference, you've already delivered a couple of presentations.

15:15.480 --> 15:16.480
Yes.

15:16.480 --> 15:17.480
Yeah.

15:17.480 --> 15:18.480
So what were those?

15:18.480 --> 15:19.480
What was the first one?

15:19.480 --> 15:24.480
So the first one was understanding what's happening to machine learning communities

15:24.480 --> 15:26.480
because machine learning and GitHub.

15:26.480 --> 15:29.480
So I had this idea for this talk like two years ago,

15:29.480 --> 15:32.480
a year and a half ago, one of my colleagues on an analytics team

15:32.480 --> 15:35.480
and a pink bench was like, well, what do you think about doing this?

15:35.480 --> 15:36.480
And she pushed me, pushed me.

15:36.480 --> 15:40.480
And I wrote half of it and then work calls,

15:40.480 --> 15:43.480
because it's not actually work.

15:43.480 --> 15:45.480
This is just like brain twiddling.

15:45.480 --> 15:46.480
Like, ah, let's see.

15:46.480 --> 15:47.480
Yeah.

15:47.480 --> 15:53.480
Because we realized that machine learning has a field as existed for a very long time.

15:53.480 --> 15:54.480
Right.

15:54.480 --> 16:00.480
But as a somewhat commercially viable field with real tooling around it,

16:00.480 --> 16:04.480
started its ascendancy around the same time of GitHub's invention.

16:04.480 --> 16:08.480
And so did GitHub help ML grow?

16:08.480 --> 16:09.480
Who knows?

16:09.480 --> 16:10.480
Or maybe it's the other way around.

16:10.480 --> 16:11.480
We don't know.

16:11.480 --> 16:15.480
But we do know that a lot of the stuff around GitHub machine learning communities

16:15.480 --> 16:16.480
have happened in GitHub.

16:16.480 --> 16:18.480
And we have that data going back 10 years.

16:18.480 --> 16:23.480
So we can actually do like a longitudinal retrospective study

16:23.480 --> 16:26.480
of the evolution of machine learning communities in GitHub.

16:26.480 --> 16:27.480
That was the first talk.

16:27.480 --> 16:31.480
And that talk was for the contributors themselves to TensorFlow.

16:31.480 --> 16:32.480
OK.

16:32.480 --> 16:35.480
So quick takeaways on that talk.

16:35.480 --> 16:38.480
What did you find in that study?

16:38.480 --> 16:40.480
Two major things happen.

16:40.480 --> 16:45.480
We have 2010, second learn, pandas, ipathun, Kaggle,

16:45.480 --> 16:47.480
all these things were created.

16:47.480 --> 16:52.480
2011 I think is that it might be 2010 to the Stanford AI course around that time.

16:52.480 --> 16:53.480
Yeah.

16:53.480 --> 16:57.480
100,000 people log on to one of them on machine learning.

16:57.480 --> 16:58.480
Including yours truly.

16:58.480 --> 16:59.480
Oh, good.

16:59.480 --> 16:59.480
Yeah.

16:59.480 --> 17:03.480
Because Sebastian Trump, I remember when did I do that Mass Rover Challenge?

17:03.480 --> 17:04.480
Uh-huh.

17:04.480 --> 17:05.480
I did the Andering one.

17:05.480 --> 17:07.480
So the Sebastian was different.

17:07.480 --> 17:08.480
Yeah.

17:08.480 --> 17:10.480
So why do I do this Mass Rover Challenge?

17:10.480 --> 17:11.480
Yeah.

17:11.480 --> 17:12.480
I was also a student.

17:12.480 --> 17:16.480
My advisor, my teacher, that professor of that time was also doing the Mass Rover Challenge.

17:16.480 --> 17:18.480
So it was like an academic thing.

17:18.480 --> 17:19.480
Yeah.

17:19.480 --> 17:22.480
So even I did nothing 100,000 people.

17:22.480 --> 17:23.480
What is this?

17:23.480 --> 17:24.480
Right.

17:24.480 --> 17:25.480
And most people did that.

17:25.480 --> 17:27.480
The following yet, Udacity was created.

17:27.480 --> 17:28.480
Coursera was created.

17:28.480 --> 17:29.480
Right.

17:29.480 --> 17:32.480
So then you're starting to see machine learning become a commercial,

17:32.480 --> 17:35.480
a viable business enterprise.

17:35.480 --> 17:36.480
Mm-hmm.

17:36.480 --> 17:38.480
No one could just academia and NASA.

17:38.480 --> 17:39.480
Mm-hmm.

17:39.480 --> 17:41.480
They're actually human VCs.

17:41.480 --> 17:43.480
Putting money into this thing.

17:43.480 --> 17:44.480
Right.

17:44.480 --> 17:48.480
So it was the first sign of the AI we until we had had thought.

17:48.480 --> 17:49.480
Right.

17:49.480 --> 17:50.480
Now it's a real thing.

17:50.480 --> 17:53.480
And so it started picking up, started picking up, started picking up, picking up, picking up.

17:53.480 --> 17:57.480
Then Andrew Ying does the cat thing at Google, Google X was it?

17:57.480 --> 18:01.480
Where they trained those neural networks to do it, to learn a representation of cats on YouTube.

18:01.480 --> 18:02.480
Right.

18:02.480 --> 18:04.480
I think there was a TED talk and all this.

18:04.480 --> 18:07.480
And everybody was like, oh my god, it's coming.

18:07.480 --> 18:09.480
Then we see another great rise.

18:09.480 --> 18:10.480
And they are no cafe.

18:10.480 --> 18:11.480
All these things are created.

18:11.480 --> 18:12.480
And then Google.

18:12.480 --> 18:19.480
And they got all of these, these, the rise and these inflections that you're speaking to is based on.

18:19.480 --> 18:20.480
Stars and get up.

18:20.480 --> 18:21.480
Right.

18:21.480 --> 18:28.480
So this is using GitHub stars as a proxy of human interest in these packages.

18:28.480 --> 18:29.480
Mm-hmm.

18:29.480 --> 18:34.480
And I did an analysis of quarter of a quarter growth of stars on GitHub repose.

18:34.480 --> 18:35.480
Okay.

18:35.480 --> 18:39.480
Of all these packages from 2019, all the way to 2019.

18:39.480 --> 18:45.480
To actually see if they're, what is the growth of stars on these packages from a quarter to quarter?

18:45.480 --> 18:46.480
Mm-hmm.

18:46.480 --> 18:49.480
And we notice a trend.

18:49.480 --> 18:50.480
I notice a trend.

18:50.480 --> 18:55.480
How big is just three cycles from 2012 Q4 to Q1 2013.

18:55.480 --> 18:58.480
There is a massive spike.

18:58.480 --> 19:07.480
We see the same thing I think around 2015 or in that 2015 to 2016 or 2016 to 2017.

19:07.480 --> 19:10.480
Another massive spike.

19:10.480 --> 19:16.480
The third cycle, which will be around 2019, no spike.

19:16.480 --> 19:18.480
So it's only 10 years worth of data.

19:18.480 --> 19:19.480
Right.

19:19.480 --> 19:20.480
No spike.

19:20.480 --> 19:26.480
And for the first time, if you look at all the stars of all the major repos in machine learning,

19:26.480 --> 19:30.480
we're talking about your TensorFlow's pie torch, cafe.

19:30.480 --> 19:31.480
Right.

19:31.480 --> 19:43.480
You just boost, cycle learn, Jupyter, and so on and so forth.

19:43.480 --> 19:44.480
Interesting.

19:44.480 --> 19:46.480
So the question is why.

19:46.480 --> 19:49.480
Is this the beginning of another AI winter?

19:49.480 --> 19:51.480
I don't think so because you look at VC funding.

19:51.480 --> 19:54.480
I don't think it has accelerated at all.

19:54.480 --> 19:57.480
And if you look at the dot AI domain,

19:57.480 --> 20:01.480
these things are just going up. One more people are going to nerves.

20:01.480 --> 20:03.480
Nerves are longer and academic pursuits.

20:03.480 --> 20:04.480
Right.

20:04.480 --> 20:07.480
It's not becoming like, I don't even know what it is.

20:07.480 --> 20:09.480
So it's not necessarily slowing down.

20:09.480 --> 20:10.480
So somebody asked a question.

20:10.480 --> 20:15.480
I said, did you look at the production framework repos?

20:15.480 --> 20:18.480
Things like Kubernetes, cube flow, things TF serving.

20:18.480 --> 20:19.480
We looked at those ones.

20:19.480 --> 20:21.480
And I realized I hadn't done that.

20:21.480 --> 20:25.480
I'm going to go back to the office and look at that to see maybe those is where that's where we're putting our energy

20:25.480 --> 20:27.480
because we're actually putting things into production now.

20:27.480 --> 20:28.480
Right. Right.

20:28.480 --> 20:35.480
Or is it that it's longer trended because it has become a permanent part of software engineering?

20:35.480 --> 20:36.480
Right.

20:36.480 --> 20:37.480
It's longer trend.

20:37.480 --> 20:38.480
It's just is.

20:38.480 --> 20:41.480
Or it could be that we've solved all the problems.

20:41.480 --> 20:42.480
We've not solved any problem.

20:42.480 --> 20:44.480
Did you come here and I'll tell you my vehicle?

20:44.480 --> 20:46.480
I don't think so.

20:46.480 --> 20:47.480
Exactly.

20:47.480 --> 20:57.480
And what's interesting about these three phases is that they map very cleanly or directly, I guess,

20:57.480 --> 20:59.480
is the better word to my own experience.

20:59.480 --> 21:00.480
Right.

21:00.480 --> 21:08.480
So in that, I think it was 2011 time frame when Andrew did his course.

21:08.480 --> 21:09.480
That was that first wave.

21:09.480 --> 21:10.480
He's first wave.

21:10.480 --> 21:18.480
I was in that wave doing that course and then in the 2015, 2016 wave,

21:18.480 --> 21:24.480
this podcast was started out of kind of feeling the energy that, you know,

21:24.480 --> 21:27.480
is this inflection point that you're talking about?

21:27.480 --> 21:35.480
And, you know, maybe the silent echo, we call it like this last, you know, these last couple of years.

21:35.480 --> 21:36.480
Now, right?

21:36.480 --> 21:41.480
It's this, yeah, Q4 2019 going to cute.

21:41.480 --> 21:43.480
Maybe, maybe something's going to happen over Christmas.

21:43.480 --> 21:44.480
Right.

21:44.480 --> 21:50.480
Well, I think what's happening from my perspective, what's happening is that a lot of the energy and investment

21:50.480 --> 21:57.480
is going into making it real and productionalizing, operationalizing, a lot of the experimentation

21:57.480 --> 21:59.480
that's been happening.

21:59.480 --> 22:06.480
And so I'm very curious to see what you find around these frameworks.

22:06.480 --> 22:11.480
But even then, I think, and what I mean is the higher level like the production framework.

22:11.480 --> 22:13.480
Yeah, the production frameworks.

22:13.480 --> 22:14.480
Yeah, the production frameworks.

22:14.480 --> 22:20.480
But even then, a lot of it is people like building their own stuff off of the low level things

22:20.480 --> 22:27.480
and just kind of demonstrating value of first kind of building that kind of smooth glide path

22:27.480 --> 22:30.480
and then using that to demonstrate value.

22:30.480 --> 22:45.480
And it could be that, you know, what we're seeing now is, you know, ultimately the growth in kind of the broader market

22:45.480 --> 22:48.480
is people kind of reaping value.

22:48.480 --> 22:50.480
And a lot of that value is internal and not shared.

22:50.480 --> 22:52.480
So that's what I was also thinking about.

22:52.480 --> 22:57.480
Maybe it's actually going to private repose in enterprises.

22:57.480 --> 22:59.480
And so we don't look at any private repose.

22:59.480 --> 23:02.480
But one thing, I don't think we're going into a winter.

23:02.480 --> 23:09.480
But I do think we have a solid five to ten years to say that machine learning is not a trend though.

23:09.480 --> 23:16.480
Because some of the challenges are our lovely friends at the media have written all these stories,

23:16.480 --> 23:23.480
this wonderful stories, everybody has high expectation.

23:23.480 --> 23:26.480
In five years, I expect to, I am hoping the car I have now is the last vehicle I will ever own.

23:26.480 --> 23:33.480
Because I'm hoping that by that time there should be an autonomous vehicle that I hope car ownership would actually go away.

23:33.480 --> 23:37.480
Maybe I just buy some Uber credits or some company of the future thing.

23:37.480 --> 23:39.480
And I just have transportation solved.

23:39.480 --> 23:45.480
And the idea of me as a human being owning a car driving it becomes a hobby like polo.

23:45.480 --> 23:47.480
If I want to drive, I want to track.

23:47.480 --> 23:50.480
But it's not like a transportation thing.

23:50.480 --> 23:54.480
That is my idea of what the next five to ten years is.

23:54.480 --> 23:59.480
If that doesn't happen though, machine learning might then just have become truly a fad.

23:59.480 --> 24:01.480
That'll be the downside.

24:01.480 --> 24:02.480
But I doubt that will happen.

24:02.480 --> 24:04.480
Because there's too much.

24:04.480 --> 24:06.480
Look at Google search.

24:06.480 --> 24:08.480
Burp is already helping with Google search.

24:08.480 --> 24:10.480
There's a real real there.

24:10.480 --> 24:13.480
But I want to see other companies outside of the major Silicon Valley.

24:13.480 --> 24:18.480
The big ones really have a real win with machine learning.

24:18.480 --> 24:21.480
Not Google, not Facebook, not Microsoft, not GitHub.

24:21.480 --> 24:23.480
I want to see a company that doesn't exist today.

24:23.480 --> 24:26.480
And in five years from now revolutionized the world.

24:26.480 --> 24:29.480
That for me will be when we've truly arrived.

24:29.480 --> 24:30.480
Yeah, yeah.

24:30.480 --> 24:33.480
I am very confident that we will see that.

24:33.480 --> 24:36.480
And we probably already know some of those companies.

24:36.480 --> 24:41.480
And if they, you know, they're probably already starting these projects that are going to do that.

24:41.480 --> 24:46.480
The other thing that you, the other thing that what you said made me think of is this

24:46.480 --> 24:51.480
kind of the hype cycle technology adoption hype cycle that I think Gartner popularized

24:51.480 --> 24:52.480
but or created.

24:52.480 --> 24:56.480
But it might have come before them or been someone else.

24:56.480 --> 25:00.480
But he had an inevitable part of this hype cycle is the trough of disillusionment.

25:00.480 --> 25:01.480
Yes.

25:01.480 --> 25:02.480
Right.

25:02.480 --> 25:09.480
So the peak of inflated expectations is kind of maybe where we were in 1516 or where we are today.

25:09.480 --> 25:11.480
Who knows.

25:11.480 --> 25:16.480
But at some point, you know, the hype kind of catches up to the market.

25:16.480 --> 25:17.480
Yeah.

25:17.480 --> 25:18.480
Right.

25:18.480 --> 25:20.480
And then, you know, there's a bit of a retrenchment, not necessarily a winter.

25:20.480 --> 25:22.480
But it's, you know, people have a contraction.

25:22.480 --> 25:23.480
A bit of a contraction.

25:23.480 --> 25:24.480
A bit of a contraction.

25:24.480 --> 25:26.480
People working hard to kind of create value.

25:26.480 --> 25:29.480
And then I always forget what the next one is.

25:29.480 --> 25:31.480
Plateau of productivity, I think.

25:31.480 --> 25:33.480
That's where you get value out of it.

25:33.480 --> 25:38.480
And I think we're kind of, you know, the different,

25:38.480 --> 25:43.480
the different sub technologies of ML&AR in different places on this curve.

25:43.480 --> 25:44.480
Yeah.

25:44.480 --> 25:49.480
But I don't think we should be too surprised that there is a trough, you know,

25:49.480 --> 25:54.480
and that we come out of that trough and, you know, ultimately give value out of the stuff.

25:54.480 --> 25:55.480
I hope so.

25:55.480 --> 25:56.480
I really hope so.

25:56.480 --> 25:57.480
Yeah.

25:57.480 --> 25:58.480
So that was the first presentation.

25:58.480 --> 25:59.480
That was the first presentation.

25:59.480 --> 26:01.480
And what was the second presentation?

26:01.480 --> 26:05.480
The second presentation is about machine learning as a product itself.

26:05.480 --> 26:06.480
Okay.

26:06.480 --> 26:10.480
One thing we've noticed is there's so many hobbyists and people really, really getting

26:10.480 --> 26:12.480
the feet wet into machine learning.

26:12.480 --> 26:14.480
And they don't have any path to production.

26:14.480 --> 26:16.480
They're not inside of me company.

26:16.480 --> 26:20.480
They're an individual contributor inside their home right in the model.

26:20.480 --> 26:21.480
And they want to move forward.

26:21.480 --> 26:28.480
And so we realize that we actually have a path to production within GitHub data app ecosystem.

26:28.480 --> 26:31.480
Because we have something called the GitHub marketplace.

26:31.480 --> 26:36.480
And in GitHub marketplace, you can put an unverified GitHub app on the marketplace.

26:36.480 --> 26:41.480
And so my colleague, how I'm all realize that, whoa, I could actually build an ML model

26:41.480 --> 26:44.480
and put it in a GitHub app and push it to marketplace.

26:44.480 --> 26:49.480
And people can actually use it to solve problems and get up itself, especially for open source.

26:49.480 --> 26:55.480
So independent of ML, what are the kinds of things that I might find in the GitHub marketplace?

26:55.480 --> 26:56.480
There are lots of apps.

26:56.480 --> 26:58.480
I think they can ban apps.

26:58.480 --> 27:00.480
But there are lots of app around software engineering.

27:00.480 --> 27:01.480
Yeah.

27:01.480 --> 27:03.480
Just the software engineering process workflows.

27:03.480 --> 27:04.480
There's all kinds of apps.

27:04.480 --> 27:05.480
Okay.

27:05.480 --> 27:09.480
Like maybe you open an issue or a new pull request and something says, hi, or something like that.

27:09.480 --> 27:13.480
They're just any kind of thing they can hook into a GitHub web hook.

27:13.480 --> 27:14.480
You can build an app around.

27:14.480 --> 27:17.480
So there are people who use a lot of stuff.

27:17.480 --> 27:18.480
Okay.

27:18.480 --> 27:19.480
Got it.

27:19.480 --> 27:22.480
And so we realize that we care a lot about open source.

27:22.480 --> 27:25.480
We also do a lot of work around natural language processing.

27:25.480 --> 27:31.480
The kinds of stuff that we are tinkering with, experimenting with within GitHub itself.

27:31.480 --> 27:36.480
One of the ways we can move our experiments forward is actually maybe something is not

27:36.480 --> 27:39.480
all the way quite ready to be a full-on product yet.

27:39.480 --> 27:42.480
You need to work out some of the kinks of it.

27:42.480 --> 27:49.480
One thing you can do, a look-a-metement way to get it continued to go, is to actually push it on the marketplace

27:49.480 --> 27:51.480
and have users use it.

27:51.480 --> 27:57.480
So you can learn the utility of it, you can iterate on it, and anybody can do that.

27:57.480 --> 28:01.480
Especially when it comes to machine learning itself as a community on GitHub.

28:01.480 --> 28:03.480
Like we've been talking about the hype cycles.

28:03.480 --> 28:07.480
What those things actually mean is people's weekends and weeknights.

28:07.480 --> 28:15.480
The maintainers of this of the same frameworks, spending inordinate amount of hours working for no pay

28:15.480 --> 28:21.480
often to build the things that we all use, we take for granted, somebody built pandas.

28:21.480 --> 28:23.480
Somebody built non-party.

28:23.480 --> 28:25.480
Was kidding in that guess.

28:25.480 --> 28:29.480
And sometimes they built this before they joined the corporation.

28:29.480 --> 28:34.480
We write a Python thing, you put your import pandas as NPT.

28:34.480 --> 28:39.480
Somebody's put time for free often to make that happen for you.

28:39.480 --> 28:44.480
And that person is one person having to deal with 600 contributors.

28:44.480 --> 28:50.480
So the amount of maintainers to contribute or flow, it's just not tractable.

28:50.480 --> 28:53.480
So sometimes you don't get the kind of response you want in open source,

28:53.480 --> 28:56.480
which affects the health of the open source community itself.

28:56.480 --> 29:02.480
One thing we realized very, very early on is that machine learning can actually automate a lot of those challenges away.

29:02.480 --> 29:08.480
Machine learning could actually triage some of your issues for you by putting levels that are pushing it to the right person.

29:08.480 --> 29:15.480
And you as a person in the ecosystem can get access to get up data to get up archive,

29:15.480 --> 29:19.480
which is actually inside of Google BigQuery.

29:19.480 --> 29:21.480
You can extract information.

29:21.480 --> 29:26.480
Meaning the code data or the lifecycle data or the behavioral data.

29:26.480 --> 29:27.480
Right.

29:27.480 --> 29:28.480
The behavioral data.

29:28.480 --> 29:30.480
You can use that data to tray models.

29:30.480 --> 29:32.480
We now have code data.

29:32.480 --> 29:35.480
We publish code data in something called code search net.

29:35.480 --> 29:42.480
We just did I think last month. So we have like six million snippets of functions that we've cleaned for you.

29:42.480 --> 29:44.480
We've parsed in multiple languages.

29:44.480 --> 29:45.480
We have JavaScript.

29:45.480 --> 29:46.480
We have PHP.

29:46.480 --> 29:47.480
We have Python.

29:47.480 --> 29:48.480
We have Java.

29:48.480 --> 29:52.480
So we have all these data sets that you can actually start using to build models.

29:52.480 --> 29:57.480
And then better yet we have get up apps that you can then push your app into production.

29:57.480 --> 30:00.480
And people can use it and give you feedback.

30:00.480 --> 30:06.480
And you can be a virtual circle cycle for helping keeping the health of our ecosystem alive.

30:06.480 --> 30:11.480
And we had our partner, Jeremy, who works at CUPLU, who's one of the lead developers of CUPLU,

30:11.480 --> 30:16.480
who is a customer of the issue level bot that, how my colleague wrote.

30:16.480 --> 30:19.480
And so we're talking about that entire virtual cycle.

30:19.480 --> 30:22.480
Like you want to really start contributing to machine learning.

30:22.480 --> 30:28.480
Start by building this apps to help keep the health of the machine learning communities themselves good.

30:28.480 --> 30:30.480
And we're using TensorFlow to do that.

30:30.480 --> 30:36.480
You've got these data sets that you make available both about code,

30:36.480 --> 30:43.480
not to mention the code that's on GitHub itself, but these data sets as well as the interaction information.

30:43.480 --> 30:55.480
And you provide the ability for folks to create applications that interfaces with or interacts with rather the GitHub users and repos,

30:55.480 --> 31:00.480
you know, things like, you know, tagging, uh, tagging issues and.

31:00.480 --> 31:03.480
Notifications. Any kind of event on GitHub.

31:03.480 --> 31:04.480
Yeah.

31:04.480 --> 31:05.480
Whatever it is.

31:05.480 --> 31:06.480
Somebody start a repo.

31:06.480 --> 31:09.480
They could write something to just interact with that.

31:09.480 --> 31:10.480
Somebody forked your repo.

31:10.480 --> 31:13.480
You could just say, oh, thank you. What do you want to use it for?

31:13.480 --> 31:14.480
You could write a bot to do that.

31:14.480 --> 31:16.480
Yeah, right. So it's, I was going to say it sounds a lot like a bot.

31:16.480 --> 31:19.480
Like do you think of them as bots essentially or are their bots?

31:19.480 --> 31:20.480
Yeah.

31:20.480 --> 31:22.480
Bots can have ML in them.

31:22.480 --> 31:23.480
Right.

31:23.480 --> 31:26.480
It's a way to get something to use this.

31:26.480 --> 31:28.480
It's a, it's a path to build their products.

31:28.480 --> 31:29.480
Yeah.

31:29.480 --> 31:36.480
So it's, so as opposed to, you know, if you, if you are playing around with machine learning and want to do something interesting,

31:36.480 --> 31:40.480
as opposed to building your own website or building a UI, something with a UI and having to deal with all that,

31:40.480 --> 31:45.480
you can build a GitHub bot and you've got this marketplace of people that you,

31:45.480 --> 31:48.480
that can connect to your GitHub bot and kind of take advantage of it.

31:48.480 --> 31:49.480
Yeah.

31:49.480 --> 31:53.480
And if you want to, you can get a verified, I don't want to make money.

31:53.480 --> 31:54.480
Yeah.

31:54.480 --> 31:57.480
Nothing stops you, but you can actually start adding value.

31:57.480 --> 32:00.480
You can understand that machine learning is not some delitant pursuit.

32:00.480 --> 32:01.480
Right.

32:01.480 --> 32:04.480
That it is a set of technologies to solve real human problems.

32:04.480 --> 32:07.480
And you can start doing that immediately.

32:07.480 --> 32:13.480
You don't have to wait to be part of a company and then do your ML within that company and then push it to users.

32:13.480 --> 32:16.480
You have the power now to do end to end.

32:16.480 --> 32:20.480
And so did you go into, like, how technical was the presentation?

32:20.480 --> 32:24.480
Did you go into some of the, you know, the details of how you would go about doing that?

32:24.480 --> 32:26.480
Not really, but we have lots.

32:26.480 --> 32:27.480
We're going to release the slides.

32:27.480 --> 32:32.480
We have, if you don't know how to write in flask, there's a course that we recommend.

32:32.480 --> 32:33.480
We put all the events there.

32:33.480 --> 32:36.480
We put snippets of the queries that you can use in BigQuery.

32:36.480 --> 32:38.480
So we get everything that you would need.

32:38.480 --> 32:43.480
We pointed to all the right sources and tutorials that you can actually recreate this.

32:43.480 --> 32:47.480
And they should labor about itself as open source. So you can see every single thing.

32:47.480 --> 32:50.480
So let's talk a little bit about the issue label bot is.

32:50.480 --> 32:51.480
It's a bot.

32:51.480 --> 32:56.480
It's responding to an issues created and it's, you know, has access to the content of that issue.

32:56.480 --> 33:00.480
Yeah. And it's liberated as a bug feature enhancement question.

33:00.480 --> 33:02.480
It's just adding labels to it.

33:02.480 --> 33:09.480
And something as simple as that is so powerful in giving maintenance back hours.

33:09.480 --> 33:17.480
And so the idea is, so GitHub has its own kind of automated issue labeling that it's doing.

33:17.480 --> 33:19.480
Correct or no?

33:19.480 --> 33:20.480
No, not really.

33:20.480 --> 33:22.480
We don't have the automated issue labeling just yet.

33:22.480 --> 33:23.480
Okay.

33:23.480 --> 33:24.480
We're starting to do the automated issue level.

33:24.480 --> 33:30.480
So you think your group, you mentioned earlier, your group is kind of thinking about how you might do that at the scale of GitHub.

33:30.480 --> 33:37.480
But if someone wants, you're not doing it because you can't do it.

33:37.480 --> 33:41.480
It's, you have to deal with the scale, but someone could take this issue label bot.

33:41.480 --> 33:45.480
And are they, what does that mean to take that?

33:45.480 --> 33:49.480
Did they have to take that and then plug their own model in or what are they doing?

33:49.480 --> 33:50.480
No, they don't plug their model.

33:50.480 --> 33:51.480
They just take it.

33:51.480 --> 33:52.480
It's a connection.

33:52.480 --> 33:55.480
They get a repo and the budget starts working.

33:55.480 --> 33:58.480
And what is the bot able to do?

33:58.480 --> 34:00.480
What labels is it able to, is it?

34:00.480 --> 34:01.480
Those three papers.

34:01.480 --> 34:02.480
Really labeling?

34:02.480 --> 34:03.480
Yes.

34:03.480 --> 34:08.480
The issue, it says, is this a bug, it labels it as a bug, if it's a bug, if it records nice, it predicts.

34:08.480 --> 34:09.480
Oh, this looks like a bug.

34:09.480 --> 34:10.480
Okay.

34:10.480 --> 34:11.480
Somebody said not working.

34:11.480 --> 34:12.480
Yeah.

34:12.480 --> 34:16.480
Then it opens it, it puts an issue, it puts another comment in the issue.

34:16.480 --> 34:17.480
This looks like a bug.

34:17.480 --> 34:21.480
If you think it's a bug, say thumbs, thumbs up, or thumbs down.

34:21.480 --> 34:24.480
If you say thumbs up, it adds the label bug to it.

34:24.480 --> 34:27.480
So it does its prediction and asks you to verify.

34:27.480 --> 34:29.480
And you can say, yes, it's a bug.

34:29.480 --> 34:31.480
And that just reinforces it learns.

34:31.480 --> 34:32.480
So it just helps to triage for you.

34:32.480 --> 34:33.480
Got it.

34:33.480 --> 34:35.480
With those simple labels.

34:35.480 --> 34:36.480
Something as simple as that.

34:36.480 --> 34:37.480
The use of the bug and whatever.

34:37.480 --> 34:39.480
The use of the bug, enhancements, or question.

34:39.480 --> 34:40.480
Got it.

34:40.480 --> 34:42.480
So maybe it's a feature request.

34:42.480 --> 34:44.480
I would like this to do that.

34:44.480 --> 34:47.480
Or how do I, whatever, question?

34:47.480 --> 34:49.480
Those three simple things.

34:49.480 --> 34:53.480
And that gives maintenance back hours.

34:53.480 --> 34:56.480
Because this is what humans have to read.

34:56.480 --> 34:59.480
And say, okay, I'm going to, somebody's job was just...

34:59.480 --> 35:00.480
Tagging news.

35:00.480 --> 35:02.480
Yeah, yeah.

35:02.480 --> 35:03.480
This is what everything that we do.

35:03.480 --> 35:04.480
This is how these things get done.

35:04.480 --> 35:05.480
Right.

35:05.480 --> 35:06.480
It's somebody doing all this kind of work.

35:06.480 --> 35:07.480
Right.

35:07.480 --> 35:10.480
But that person, if we can give them back their hours, it's great.

35:10.480 --> 35:11.480
Right.

35:11.480 --> 35:15.480
And especially for building a robust ecosystem of machine learning,

35:15.480 --> 35:19.480
GitHub is the home of all developers, including machine learning developers.

35:19.480 --> 35:25.480
The virtual cycle is you can actually do things to make the ecosystem more robust.

35:25.480 --> 35:26.480
Mm-hmm.

35:26.480 --> 35:28.480
And solve our own problems by leveraging.

35:28.480 --> 35:31.480
If you, by thinking of GitHub as a platform,

35:31.480 --> 35:33.480
instead of just could repository hosting,

35:33.480 --> 35:36.480
it's also a platform to plug and build things on top of.

35:36.480 --> 35:37.480
Got it.

35:37.480 --> 35:38.480
So we ourselves and the ML team,

35:38.480 --> 35:41.480
we build things on top of that platform as open source.

35:41.480 --> 35:45.480
And it's just a way to also just play with things they're experimenting with.

35:45.480 --> 35:47.480
Like, if you're writing a little experiment,

35:47.480 --> 35:49.480
why not open source it to see if it's actually useful?

35:49.480 --> 35:52.480
And maybe it's this useful, they add more time to it,

35:52.480 --> 35:54.480
and you actually build it all the way up.

35:54.480 --> 35:55.480
Yeah, yeah, yeah.

35:55.480 --> 35:59.480
With this issue label bought, it's something that you can immediately start using

35:59.480 --> 36:00.480
and get some value out of.

36:00.480 --> 36:02.480
And it sounds like the cube flow team is using that.

36:02.480 --> 36:03.480
The cube flow team is using it.

36:03.480 --> 36:04.480
Okay.

36:04.480 --> 36:06.480
And they're getting a lot of value out of it.

36:06.480 --> 36:08.480
The person that wrote the bot is downstairs, Hammer.

36:08.480 --> 36:09.480
Yeah.

36:09.480 --> 36:11.480
Here at the bot, Jeremy is also with us in the talk.

36:11.480 --> 36:13.480
He's using that bot to triage.

36:13.480 --> 36:14.480
Yeah.

36:14.480 --> 36:16.480
He's environment, he's a maintenance, he's project,

36:16.480 --> 36:19.480
because they want to keep the health of that project very high.

36:19.480 --> 36:20.480
Right.

36:20.480 --> 36:22.480
They want people to continue to contribute.

36:22.480 --> 36:24.480
And they want to turn around to actually getting things done.

36:24.480 --> 36:25.480
Right.

36:25.480 --> 36:28.480
Nobody wants to go to an issues, listen, see a bunch of issues

36:28.480 --> 36:29.480
that haven't been responded to.

36:29.480 --> 36:30.480
Exactly.

36:30.480 --> 36:31.480
And tagging is the first step in.

36:31.480 --> 36:34.480
That's the first step to figure out where should he go.

36:34.480 --> 36:35.480
Right.

36:35.480 --> 36:36.480
Right.

36:36.480 --> 36:39.480
And so, but this is not just a tool.

36:39.480 --> 36:43.480
It's also an example for other folks that might want to build their own tools.

36:43.480 --> 36:44.480
Absolutely.

36:44.480 --> 36:45.480
Using machine learning.

36:45.480 --> 36:46.480
Yes.

36:46.480 --> 36:48.480
That connect into the GitHub experience.

36:48.480 --> 36:49.480
Yeah.

36:49.480 --> 36:51.480
This was just saying, hey, you want to write code.

36:51.480 --> 36:55.480
You're doing ML and you care about developer productivity.

36:55.480 --> 36:59.480
Or you care about doing stuff around ML on code itself.

36:59.480 --> 37:04.480
Maybe you want to write that plan or have an idea of automated pull request review.

37:04.480 --> 37:08.480
Here's a code base for you that we've cleaned up.

37:08.480 --> 37:12.480
We've built some things ourselves wherever is baseline of what we think the model is.

37:12.480 --> 37:14.480
We've done something here is the baseline we got.

37:14.480 --> 37:17.480
Maybe you want to work on that and beat that baseline.

37:17.480 --> 37:18.480
Right.

37:18.480 --> 37:19.480
And then publish it.

37:19.480 --> 37:21.480
Like get the things down faster.

37:21.480 --> 37:24.480
So I'd be remiss if you just mentioned ML on code.

37:24.480 --> 37:25.480
I'm curious about.

37:25.480 --> 37:28.480
I'm sure others are curious about the generative side of this.

37:28.480 --> 37:31.480
Is that something that you're exploring in your group?

37:31.480 --> 37:33.480
So I am not exploring generative side of it.

37:33.480 --> 37:36.480
I think it's something that we've had ideas on.

37:36.480 --> 37:39.480
To me, that would be the ultimate moonshot.

37:39.480 --> 37:40.480
Yeah.

37:40.480 --> 37:43.480
And part of that code challenge was the GPT2 for things like that.

37:43.480 --> 37:44.480
Yeah.

37:44.480 --> 37:45.480
Exactly.

37:45.480 --> 37:46.480
That is the ultimate moonshot.

37:46.480 --> 37:48.480
So people have said I do work around that.

37:48.480 --> 37:51.480
The thing has to be good enough to be able to compile.

37:51.480 --> 37:54.480
So there's a version of this.

37:54.480 --> 37:56.480
I mean, but you've got that's like an adversarial thing.

37:56.480 --> 37:57.480
Yeah.

37:57.480 --> 37:58.480
But a version of this could just be.

37:58.480 --> 37:59.480
Could completion.

37:59.480 --> 38:00.480
Yeah.

38:00.480 --> 38:04.480
The challenge is so we are not necessarily an IDE.

38:04.480 --> 38:05.480
Right.

38:05.480 --> 38:09.480
From a get up perspective, if I put on a hat of like a get up product manager,

38:09.480 --> 38:11.480
we're not necessarily an IDE.

38:11.480 --> 38:12.480
Right.

38:12.480 --> 38:16.480
The person that would really, really rock and roll on that stuff is the person that is doing an IDE.

38:16.480 --> 38:18.480
Yeah.

38:18.480 --> 38:22.480
Because who is the, sometimes as technologists, we fall in love with the technology.

38:22.480 --> 38:25.480
And now we're trying to shoe horn it in.

38:25.480 --> 38:28.480
Who is the customer for that technology?

38:28.480 --> 38:30.480
Everybody ever sucks about.

38:30.480 --> 38:33.480
I would like to just say I want to do this and it writes the code for me.

38:33.480 --> 38:36.480
Even if that's where you want to get at, who's the customer for that?

38:36.480 --> 38:41.480
Is the person that has like an IDE or some environment where you write code?

38:41.480 --> 38:45.480
We don't necessarily, maybe in the future, we'll right now write code within GitHub.

38:45.480 --> 38:51.480
So from a generated perspective, I guess I can, I can see that from our managers.

38:51.480 --> 38:55.480
I'm not going to give us like the thumbs up to grab the chasing something that we can't,

38:55.480 --> 38:57.480
like that's not our job.

38:57.480 --> 39:00.480
We should be doing other things that are, we are not researchers.

39:00.480 --> 39:02.480
We are not a research.

39:02.480 --> 39:03.480
Right.

39:03.480 --> 39:09.480
Our shop is built something within a 12 month horizon to help our customers today.

39:09.480 --> 39:11.480
It's very, very quick.

39:11.480 --> 39:22.480
We have that those that you are in a position that not many organizations are in terms of the volume of code that you have access to.

39:22.480 --> 39:23.480
Indeed.

39:23.480 --> 39:26.480
Google also has code.

39:26.480 --> 39:31.480
But we don't have as much of all the different languages as GitHub does.

39:31.480 --> 39:32.480
Right.

39:32.480 --> 39:36.480
And structured metadata about the code.

39:36.480 --> 39:44.480
So there is, it does seem that there is a certain, part of this is, do you have the market?

39:44.480 --> 39:49.480
And maybe the IDE has the market for this feature.

39:49.480 --> 39:53.480
But they don't necessarily have the code, right?

39:53.480 --> 39:54.480
They couldn't.

39:54.480 --> 39:55.480
Yes.

39:55.480 --> 39:56.480
Right.

39:56.480 --> 39:58.480
We don't have the code.

39:58.480 --> 40:00.480
So where does GitHub fit?

40:00.480 --> 40:01.480
Right.

40:01.480 --> 40:03.480
I think this is the beginnings of code search net.

40:03.480 --> 40:08.480
If they don't have the code, could we provide some of the code for them?

40:08.480 --> 40:10.480
And so this is code search net is the.

40:10.480 --> 40:13.480
It's a code challenge.

40:13.480 --> 40:14.480
It's a code challenge.

40:14.480 --> 40:15.480
Okay.

40:15.480 --> 40:19.480
Replete with a data set filled with code itself.

40:19.480 --> 40:24.480
Past snippets of code and the sequences of code.

40:24.480 --> 40:27.480
And they're docks strings in natural language.

40:27.480 --> 40:32.480
Put out there to accelerate development on this issues.

40:32.480 --> 40:36.480
Understanding that we actually have customers today that we need to be building stuff for.

40:36.480 --> 40:37.480
Right.

40:37.480 --> 40:39.480
But we also want this long term horizon.

40:39.480 --> 40:40.480
So maybe we have this.

40:40.480 --> 40:44.480
Let's just see if anything interesting happens in this petri dish that we put out there.

40:44.480 --> 40:49.480
But I will make sure that when I get off this talk and I talk to my manager and our VP,

40:49.480 --> 40:54.480
I will tell them that our community might like us to start doing this.

40:54.480 --> 41:00.480
And so if they give us the thumbs up to chase that, then perhaps there's a GitHub research that is created.

41:00.480 --> 41:04.480
And get a research that is tossed with doing this kinds of work.

41:04.480 --> 41:05.480
Yeah.

41:05.480 --> 41:07.480
I mean, maybe this is the beginning of GitHub research.

41:07.480 --> 41:16.480
Yeah, maybe it does seem like it does seem like there's this asset available in open source code

41:16.480 --> 41:19.480
that you're uniquely positioned to take advantage of.

41:19.480 --> 41:24.480
And who knows what the, yeah, it's kind of classic innovators dilemma.

41:24.480 --> 41:26.480
Like this is our current business.

41:26.480 --> 41:28.480
So we kind of have the blinders on or focused on his current business.

41:28.480 --> 41:36.480
But you also are in this very unique position to kind of leapfrog that and do something potentially interesting.

41:36.480 --> 41:37.480
Yeah.

41:37.480 --> 41:41.480
And GitHub machine learning is all of almost three years old.

41:41.480 --> 41:42.480
Yeah.

41:42.480 --> 41:43.480
January 2017.

41:43.480 --> 41:44.480
Yeah.

41:44.480 --> 41:45.480
So that's also what you have to remember.

41:45.480 --> 41:46.480
Right.

41:46.480 --> 41:47.480
Right.

41:47.480 --> 41:48.480
So very different.

41:48.480 --> 41:49.480
I was just curious.

41:49.480 --> 41:50.480
Very different problem for sure.

41:50.480 --> 41:56.480
With the code challenge for those that don't have a team that does ASTs sitting right next to them.

41:56.480 --> 42:02.480
Are there kind of other kind of off the shelf tools that folks are using a play around with that kind of stuff?

42:02.480 --> 42:08.480
There are many parsers that are available that have their own version of ASTs that can parse ASTs for you.

42:08.480 --> 42:11.480
So I can mention any of them off the top of my cough, but they are available.

42:11.480 --> 42:12.480
But that's the thing.

42:12.480 --> 42:16.480
Like look for ASTs and parsers and kind of mashed up.

42:16.480 --> 42:17.480
But we don't know yet.

42:17.480 --> 42:20.480
We don't know is this is research.

42:20.480 --> 42:22.480
So get all the representations.

42:22.480 --> 42:27.480
If I were doing this, I'll get the code represented as an AST.

42:27.480 --> 42:29.480
I will represent the code as natural language.

42:29.480 --> 42:30.480
I'll just do everything.

42:30.480 --> 42:31.480
Yeah.

42:31.480 --> 42:34.480
And then do the science and see which one gets you further.

42:34.480 --> 42:35.480
Yeah.

42:35.480 --> 42:36.480
Yeah.

42:36.480 --> 42:38.480
And then, you know, put your.

42:38.480 --> 42:42.480
Join the leaderboard and submit your model and join the leaderboard.

42:42.480 --> 42:44.480
And I actually see how far you perform.

42:44.480 --> 42:47.480
Like a Netflix prize kind of thing where you've got a million bucks.

42:47.480 --> 42:49.480
I don't think there's a million bucks.

42:49.480 --> 42:51.480
I think there's just bracket rights of I did this.

42:51.480 --> 42:52.480
Okay.

42:52.480 --> 42:53.480
You're prizes.

42:53.480 --> 42:54.480
You're helping your community.

42:54.480 --> 42:55.480
Right.

42:55.480 --> 42:56.480
Awesome.

42:56.480 --> 42:57.480
Well, I'll mold you.

42:57.480 --> 43:01.480
It was so wonderful to finally get a chance to chat with you.

43:01.480 --> 43:03.480
Thanks so much for taking the time to be on the show.

43:03.480 --> 43:05.480
Thank you for having me.

43:05.480 --> 43:10.480
That's our show for today.

43:10.480 --> 43:15.480
To learn more about today's episode, visit twomalead.com slash shows.

43:15.480 --> 43:19.480
If you missed twomalcon or want to share what you learned with your team,

43:19.480 --> 43:24.480
be sure you visit twomalcon.com slash videos for more information about

43:24.480 --> 43:26.480
twomalcon video packages.

43:26.480 --> 43:52.480
Thanks so much for listening.

