1
00:00:00,000 --> 00:00:14,080
All right, everyone, I am here with Joseph Soriaga.

2
00:00:14,080 --> 00:00:17,680
Joseph is Senior Director of Technology at Qualcomm.

3
00:00:17,680 --> 00:00:20,340
Joseph, welcome to the Twinmore AI podcast.

4
00:00:20,340 --> 00:00:23,280
Great. Yeah. Thank you for having me. It's great to be here.

5
00:00:23,280 --> 00:00:25,800
Looking forward to jumping into our conversation.

6
00:00:25,800 --> 00:00:29,080
We'll be talking about a couple of very interesting papers that you and

7
00:00:29,080 --> 00:00:33,720
your team have that will be published later in the year at Globecom.

8
00:00:33,720 --> 00:00:37,560
Before we dig into those, though, I'd love to have you share a bit about your

9
00:00:37,560 --> 00:00:42,280
background. Tell us how you came to work in the field of machine learning.

10
00:00:42,280 --> 00:00:49,320
Yeah, sure. I'd be happy to. So I've actually been working for a while and

11
00:00:49,320 --> 00:00:54,360
wireless. And when I started, I actually started in coding and

12
00:00:54,360 --> 00:00:59,400
information theory a while ago, even and well before in the deep learning revolution.

13
00:00:59,400 --> 00:01:02,720
But there were some interesting parallels, I'd say, with machine learning.

14
00:01:02,720 --> 00:01:09,040
Because at the time, it was really exciting where belief propagation was

15
00:01:09,040 --> 00:01:13,960
very popular. And it was essentially being used to achieve shanty capacity

16
00:01:13,960 --> 00:01:21,160
and a lot of different use cases. And the trick was trying to find the right

17
00:01:21,160 --> 00:01:25,600
graphical model for the particular problem to achieve that.

18
00:01:25,600 --> 00:01:29,680
This is coming from TurboCodes and rediscovered LDPC.

19
00:01:29,680 --> 00:01:36,360
Another nice parallel was that our kind of community was getting used to

20
00:01:36,360 --> 00:01:39,920
and embracing a lot of like experiment-driven research.

21
00:01:39,920 --> 00:01:48,200
Like really extensive coding up of experiments to prove something could work.

22
00:01:48,200 --> 00:01:52,400
Because it was very difficult to prove rigorously and mathematically that

23
00:01:52,400 --> 00:01:54,600
this belief propagation would achieve shanty capacity.

24
00:01:54,600 --> 00:01:59,680
But through a lot of extensive experiments, you could go and simulate it and

25
00:01:59,680 --> 00:02:06,120
design things and then for all practical purposes show that you were achieving it.

26
00:02:06,120 --> 00:02:10,600
There were a lot of relationships to machine learning of belief propagation at

27
00:02:10,600 --> 00:02:15,560
the time, but I was really more on the communication side.

28
00:02:15,560 --> 00:02:22,240
And then coming out of school, my PhD, I joined a Qualcomm corporate R&D.

29
00:02:22,240 --> 00:02:30,440
And that was where I was really excited and exposed to this industrial

30
00:02:30,440 --> 00:02:34,920
research. And one of the great things about Qualcomm is that they not only

31
00:02:34,920 --> 00:02:39,200
invest substantially in research, but it's a very open, collaborative environment

32
00:02:39,200 --> 00:02:46,280
where we would really focus on taking a fundamental research idea

33
00:02:46,280 --> 00:02:48,280
and then proving it out.

34
00:02:48,280 --> 00:02:53,280
See how far you can go and making the system more complicated, more realistic.

35
00:02:53,280 --> 00:02:57,160
And to the point where you're actually going to build it and test it and

36
00:02:57,160 --> 00:02:58,880
demonstrate it.

37
00:02:58,880 --> 00:03:03,200
And that's been kind of a core philosophy that they've continued to do

38
00:03:03,200 --> 00:03:06,040
through, I don't know, my 15 plus years at the company.

39
00:03:06,040 --> 00:03:09,280
So that's kind of been a great thing.

40
00:03:09,280 --> 00:03:13,160
Through that course, I touched a lot of different things on the system,

41
00:03:13,160 --> 00:03:20,120
like the base station, the modem, the entire air interface system.

42
00:03:20,120 --> 00:03:24,240
And then most recently, at 5G, I worked closely with the

43
00:03:24,240 --> 00:03:26,800
research and then coming to participate in standards.

44
00:03:26,800 --> 00:03:29,880
So I did a lot of work in that.

45
00:03:29,880 --> 00:03:36,240
And through the course of that, I'd say, you know, it's 5G's, of course, very

46
00:03:36,240 --> 00:03:40,280
amazing things have opened up in this technology, new frequencies, new

47
00:03:40,280 --> 00:03:46,360
spectrums, new paradigms for how we do things, new services, of course.

48
00:03:46,360 --> 00:03:52,200
And through that, we started to see that we have this very large bandwidth.

49
00:03:52,200 --> 00:03:57,440
We have lots of directionality now with the millimeter wave.

50
00:03:57,440 --> 00:04:03,480
And the system itself, becoming lower latency more precise, it actually is

51
00:04:03,480 --> 00:04:07,000
very sophisticated for understanding the environment too.

52
00:04:07,000 --> 00:04:11,520
So positioning was one of the first, you know, interesting use cases of

53
00:04:11,520 --> 00:04:15,360
trying to understand the environment that the 5G system was able to

54
00:04:15,360 --> 00:04:20,120
demonstrate with these really large antenna rays and wide bandwidths.

55
00:04:20,120 --> 00:04:24,120
And so, you know, as the system gets more complicated and the capability

56
00:04:24,120 --> 00:04:29,520
of the system also grows, it just became more obvious that, like, there's a

57
00:04:29,520 --> 00:04:37,360
lot that can happen with AI and wireless and so, and so I kind of, over time,

58
00:04:37,360 --> 00:04:43,760
transition to doing much more AI in this space as opposed to being more

59
00:04:43,760 --> 00:04:45,640
wireless driven.

60
00:04:45,640 --> 00:04:50,440
And that was kind of one reason to moving more directly into Qualcomm AI

61
00:04:50,440 --> 00:04:52,640
research.

62
00:04:52,640 --> 00:04:58,520
Another, you know, important, you know, motivation I had was that this

63
00:04:58,520 --> 00:05:06,600
interface, it actually does help accelerate, you know, the developments in AI and

64
00:05:06,600 --> 00:05:09,640
the ability of certain applications.

65
00:05:09,640 --> 00:05:14,960
So, because, you know, at the start, it just is a better link to the cloud.

66
00:05:14,960 --> 00:05:17,960
Things can be more interactive and more direct.

67
00:05:17,960 --> 00:05:21,720
But then over time, as the devices also become more capable and we start

68
00:05:21,720 --> 00:05:26,760
moving more of the, you know, lower level perception tests, for instance, locally

69
00:05:26,760 --> 00:05:34,440
to the devices, then it enables, like, the next stage of AI, the cloud can

70
00:05:34,440 --> 00:05:41,760
concentrate on the more complicated and emerging research advances, like

71
00:05:41,760 --> 00:05:46,720
understanding reasoning and generalizing beyond what has been trained on.

72
00:05:46,720 --> 00:05:51,640
And so, it's very natural to think, okay, let's get

73
00:05:51,640 --> 00:05:56,640
more involved in this and write the kind of the next wave of where things are.

74
00:05:56,640 --> 00:06:03,520
Yeah, what I'm really looking forward to digging into in this discussion is what I

75
00:06:03,520 --> 00:06:10,720
think of as the other side of the AI 5G coin, specifically, I spoke not too

76
00:06:10,720 --> 00:06:17,520
long ago with your colleagues, he had about how 5G can be used to accelerate

77
00:06:17,520 --> 00:06:24,520
distributed AI applications that was episode 489 back in June.

78
00:06:24,520 --> 00:06:31,000
But we'll be talking about here, again, the flip side, the ability for machine

79
00:06:31,000 --> 00:06:38,840
learning and AI to help enable 5G and make it more efficient.

80
00:06:38,840 --> 00:06:44,920
You mentioned in your introductions, Shannon capacity, that's kind of a key

81
00:06:44,920 --> 00:06:49,720
concept that flows throughout your work, would you like to take a second to explain

82
00:06:49,720 --> 00:06:50,720
that?

83
00:06:50,720 --> 00:06:51,720
Yeah, sure.

84
00:06:51,720 --> 00:06:58,200
And the Shannon capacity is one of these amazing results from cloud Shannon is being

85
00:06:58,200 --> 00:07:03,640
able to characterize how well, for a particular channel, you know,

86
00:07:03,640 --> 00:07:08,760
conveying information from a transmitter receiver, how well can you hope to

87
00:07:08,760 --> 00:07:15,840
achieve, you know, throughput without actually, you know, building a system to do

88
00:07:15,840 --> 00:07:16,840
it.

89
00:07:16,840 --> 00:07:20,920
And then it becomes a question of like exactly what do we do to build a system to

90
00:07:20,920 --> 00:07:21,920
achieve that.

91
00:07:21,920 --> 00:07:27,760
And one of the really important advances from Shannon was that we know when to give

92
00:07:27,760 --> 00:07:32,000
up and to focus on different things, because if it's beyond the capacity, we

93
00:07:32,000 --> 00:07:35,080
shouldn't, you know, bother and move to the next problem.

94
00:07:35,080 --> 00:07:41,520
And if it's well within the capacity, then we know that we're what potential is

95
00:07:41,520 --> 00:07:43,920
there and what we have to realize.

96
00:07:43,920 --> 00:07:49,480
So yeah, so kind of the theoretical bandwidth limit, let's say between the

97
00:07:49,480 --> 00:07:56,280
between two communication devices or entities, I guess, exactly.

98
00:07:56,280 --> 00:08:02,960
As the channels become more complicated to characterize, some of these principles,

99
00:08:02,960 --> 00:08:07,400
you know, they could become more difficult to evaluate to some level.

100
00:08:07,400 --> 00:08:12,680
You start doing Monte Carlo integration and then some level, you know, this is

101
00:08:12,680 --> 00:08:16,400
where machine learning can start to come in and help us to understand what's the

102
00:08:16,400 --> 00:08:21,200
best representation for this particular system, which has now become so

103
00:08:21,200 --> 00:08:27,680
complicated to really get the right heuristic and the right abstraction.

104
00:08:27,680 --> 00:08:32,640
So that's, that's, yeah, that's how things have evolved.

105
00:08:32,640 --> 00:08:38,920
One of the papers that will dig into, or the first of the papers that will dig

106
00:08:38,920 --> 00:08:45,120
into is one on deep learning based network augmentation.

107
00:08:45,120 --> 00:08:47,960
Can you introduce that topic to us?

108
00:08:47,960 --> 00:08:53,560
We spoke to your former colleague, Max Walling, about that about a year ago.

109
00:08:53,560 --> 00:08:57,400
At the time, it was kind of this interesting idea that was being pursued in

110
00:08:57,400 --> 00:08:59,880
research.

111
00:08:59,880 --> 00:09:03,800
And it sounds like it's matured quite a bit in a year and now you've got a

112
00:09:03,800 --> 00:09:06,400
paper about some of the results you're seeing.

113
00:09:06,400 --> 00:09:08,800
Yeah, yeah, I'm glad you brought it up.

114
00:09:08,800 --> 00:09:16,040
So yeah, last year, Max did bring up this topic and the importance of it in

115
00:09:16,040 --> 00:09:22,600
communication is that, so the idea of neural augmentation is you want to,

116
00:09:22,600 --> 00:09:29,240
whenever a particular problem has some abstraction where we have a good

117
00:09:29,240 --> 00:09:34,680
algorithm that's perfectly matched to that abstraction, there's no reason to

118
00:09:34,680 --> 00:09:37,200
change that algorithm anymore.

119
00:09:37,200 --> 00:09:42,640
But if the abstraction itself is a little mismatched with reality, we can

120
00:09:42,640 --> 00:09:48,800
augment that algorithm with some neural networks so that we can make the

121
00:09:48,800 --> 00:09:53,200
right adaptation of the algorithm for the mismatch instead of kind of

122
00:09:53,200 --> 00:09:55,440
redesigning the whole thing.

123
00:09:55,440 --> 00:10:00,800
And there's still ways to make that say end to end trainable with the real world.

124
00:10:00,800 --> 00:10:06,280
So one really nice benefit of this that plays well with the

125
00:10:06,280 --> 00:10:11,000
communication, you know, academic community and industry is that there's a

126
00:10:11,000 --> 00:10:19,000
long history of abstracting different problems in wireless and domain where

127
00:10:19,000 --> 00:10:23,920
we know that we're doing exactly the right thing and it's just a matter of,

128
00:10:23,920 --> 00:10:27,520
how do we adapt our domain knowledge now that the channels are becoming even

129
00:10:27,520 --> 00:10:31,720
wider bandwidth or even higher frequency and there's more non-linearities

130
00:10:31,720 --> 00:10:38,480
being introduced or more more sophistication in the model itself that we

131
00:10:38,480 --> 00:10:43,640
weren't really able to capture properly in our abstraction.

132
00:10:43,640 --> 00:10:48,600
And so this is where that idea of the paper is coming in.

133
00:10:48,600 --> 00:10:54,520
And the idea there is that, you know, we often see in academic papers

134
00:10:54,520 --> 00:10:59,320
relative to kind of real world deployment in many fields is that the

135
00:10:59,320 --> 00:11:06,920
papers out of necessity in order to get clean mathematical results will

136
00:11:06,920 --> 00:11:11,560
simplify the real world ignoring any number of factors.

137
00:11:11,560 --> 00:11:17,040
And what this work is suggesting is that deep learning can be used to kind

138
00:11:17,040 --> 00:11:21,840
of map the simple models to what's seen in the real world to make them

139
00:11:21,840 --> 00:11:26,920
more, to make them match better and ultimately kind of more predictive.

140
00:11:26,920 --> 00:11:27,920
Is that the idea?

141
00:11:27,920 --> 00:11:29,040
Yeah, that's right.

142
00:11:29,040 --> 00:11:31,760
To make it more predictive.

143
00:11:31,760 --> 00:11:38,360
Actually, in the paper what's interesting is, you know, initially we were

144
00:11:38,360 --> 00:11:43,080
just naturally it's thinking that, okay, this is, so we were trying to track

145
00:11:43,080 --> 00:11:48,440
a channel and then the speed at which you move, you know, affects the

146
00:11:48,440 --> 00:11:53,320
Doppler of that channel, how fast it's changing.

147
00:11:53,320 --> 00:12:00,200
And if we know the Doppler, then the dynamics are well suited to the

148
00:12:00,200 --> 00:12:05,240
common filter in one particular example.

149
00:12:05,240 --> 00:12:08,800
So it's just a matter of making sure we have the right, you know,

150
00:12:08,800 --> 00:12:13,400
parameters for a common filter for that particular speed that we're at.

151
00:12:13,400 --> 00:12:18,920
And, and so when we're talking about Doppler, we're talking about the

152
00:12:18,920 --> 00:12:28,400
communication between like a fixed base station and a moving communicator

153
00:12:28,400 --> 00:12:31,880
like, you know, someone on a mobile device in a car and you're using the

154
00:12:31,880 --> 00:12:38,720
Doppler shift to, to kind of localize that, that device.

155
00:12:38,720 --> 00:12:39,720
Yeah, exactly.

156
00:12:39,720 --> 00:12:40,720
Is that the general idea?

157
00:12:40,720 --> 00:12:42,720
That's one, one example.

158
00:12:42,720 --> 00:12:44,440
Surprisingly, Doppler is everywhere.

159
00:12:44,440 --> 00:12:49,720
So wireless, a nice thing about wireless is you get great coverage because it

160
00:12:49,720 --> 00:12:54,080
bounces off a lot of things and sometimes transmitter and receiver aren't

161
00:12:54,080 --> 00:12:57,000
moving, but they're bouncing off of things that are moving.

162
00:12:57,000 --> 00:12:59,680
And so then we get Doppler again there.

163
00:12:59,680 --> 00:13:04,400
So, so it is a very ubiquitous problem that we do with even, even when I'm

164
00:13:04,400 --> 00:13:07,880
talking to you today, if we're on a, on a cellular system, we'd have to do

165
00:13:07,880 --> 00:13:10,880
with that to some degree.

166
00:13:10,880 --> 00:13:15,320
And so when you talk about channel tracking and Doppler and all that stuff,

167
00:13:15,320 --> 00:13:17,480
like why do, why do we care?

168
00:13:17,480 --> 00:13:19,480
Why do you care?

169
00:13:19,480 --> 00:13:24,400
As a, you know, someone who's building systems to help people communicate?

170
00:13:24,400 --> 00:13:25,800
Yeah, good question.

171
00:13:25,800 --> 00:13:31,640
So we always want to, like coming back to that shannan capacity, we always want to

172
00:13:31,640 --> 00:13:34,400
operate at that shannan capacity.

173
00:13:34,400 --> 00:13:40,920
And so it's evolved in our system to track this channel so that we know, don't

174
00:13:40,920 --> 00:13:43,920
put too much information if the channel is not very good.

175
00:13:43,920 --> 00:13:47,120
And then if the channel is really good, you know, let's put as much information as we

176
00:13:47,120 --> 00:13:52,840
can and opportunistically, you know, ride the wave of when it's good and when it's bad.

177
00:13:52,840 --> 00:13:53,840
And this is really.

178
00:13:53,840 --> 00:13:56,520
And how does that tie to Doppler?

179
00:13:56,520 --> 00:14:03,880
Doppler, the dynamic of the channel helps us to be able to predict how well.

180
00:14:03,880 --> 00:14:13,480
And then when we're actually trying to decode the signals themselves, we'll be able to

181
00:14:13,480 --> 00:14:19,320
resolve some of that signal better once we know how the channel has rotated through

182
00:14:19,320 --> 00:14:21,760
the course of time.

183
00:14:21,760 --> 00:14:25,160
And so those are the two aspects of it.

184
00:14:25,160 --> 00:14:31,160
And in this particular paper, we were deciding, we were looking more at the tracking the

185
00:14:31,160 --> 00:14:37,880
rotation so that we can resolve the signals that have been degraded.

186
00:14:37,880 --> 00:14:42,560
And when you say rotation in this instance, are you talking like phase shift or something

187
00:14:42,560 --> 00:14:43,560
like that?

188
00:14:43,560 --> 00:14:51,000
Yeah, probably using a lot of jargon, but you know, we'll send our communication signal

189
00:14:51,000 --> 00:15:02,080
usually, you know, your message that you want to convey goes through a very sophisticated

190
00:15:02,080 --> 00:15:11,520
remapping of bits into constellation and a MIMO transmission across antennas.

191
00:15:11,520 --> 00:15:15,000
And that's the signal that we're trying to get to the receiver.

192
00:15:15,000 --> 00:15:21,280
And then we want to be able to decode that original, you know, set of points that convey

193
00:15:21,280 --> 00:15:22,280
the message.

194
00:15:22,280 --> 00:15:25,920
And if that gets through, then we can always remap that back to the original information

195
00:15:25,920 --> 00:15:29,320
that was to convey it.

196
00:15:29,320 --> 00:15:38,680
Yeah, so maybe to kind of try to recap the setting here, going back to this Shannon model,

197
00:15:38,680 --> 00:15:43,880
you've got this transmitter, the transmitter is pumping information into this channel.

198
00:15:43,880 --> 00:15:48,200
There's a receiver that's trying to capture as much of that information as possible and

199
00:15:48,200 --> 00:15:51,920
kind of maximize the bandwidth or throughput in this channel.

200
00:15:51,920 --> 00:15:57,960
And there's inherently this assumption of a noise source that's like disrupting the communication

201
00:15:57,960 --> 00:15:59,600
between the two.

202
00:15:59,600 --> 00:16:09,120
I think we kind of think of, you know, as lay people, a straight line between the, you

203
00:16:09,120 --> 00:16:13,120
know, a cell tower and a mobile, but you know, as you've talked about the signals bouncing

204
00:16:13,120 --> 00:16:19,120
all over the place, you know, even if it wasn't bouncing, you just talked about MIMO and

205
00:16:19,120 --> 00:16:25,800
these other technologies, really the, there's multiple signals or channels kind of between

206
00:16:25,800 --> 00:16:31,440
the cell tower and the device and, you know, there's noise being inserted.

207
00:16:31,440 --> 00:16:36,000
The signals are all going different directions and the ideas that you have to figure all

208
00:16:36,000 --> 00:16:43,480
that you, the more you can kind of take the information you're getting about the network

209
00:16:43,480 --> 00:16:49,560
and the devices, Doppler and all this stuff, you can use that to ultimately kind of statistically

210
00:16:49,560 --> 00:16:54,640
predict what was sent at the device and vice versa.

211
00:16:54,640 --> 00:16:58,600
And that's how you, you maximize the, your bandwidth or throughput.

212
00:16:58,600 --> 00:16:59,600
Yes.

213
00:16:59,600 --> 00:17:00,600
I think you put it well.

214
00:17:00,600 --> 00:17:01,600
Yeah.

215
00:17:01,600 --> 00:17:02,600
Exactly.

216
00:17:02,600 --> 00:17:03,600
Got it.

217
00:17:03,600 --> 00:17:04,600
Got it.

218
00:17:04,600 --> 00:17:10,200
You know, common filter, where does common filter come into play in all this?

219
00:17:10,200 --> 00:17:11,200
Sure.

220
00:17:11,200 --> 00:17:19,320
So, the way the, the channel is evolving, this, you know, you fade up and you fade down,

221
00:17:19,320 --> 00:17:26,240
it's very well modeled in some cases, in a lot of cases, by an autoregressive model.

222
00:17:26,240 --> 00:17:34,560
And then common filters are very well studied and optimal way of tracking that dynamic

223
00:17:34,560 --> 00:17:36,320
system.

224
00:17:36,320 --> 00:17:42,320
And so, so that's, that's where kind of that solution is coming to play.

225
00:17:42,320 --> 00:17:44,160
Got it.

226
00:17:44,160 --> 00:17:52,200
And so, kind of going back to this idea of neural augmentation, talk about the kind of the gap

227
00:17:52,200 --> 00:17:56,400
between the common filter and what's observed in real world.

228
00:17:56,400 --> 00:17:57,400
Sure.

229
00:17:57,400 --> 00:17:58,400
Sure.

230
00:17:58,400 --> 00:18:02,280
So, in the real world, you're going to move, or things around, you're going to move at

231
00:18:02,280 --> 00:18:12,960
different speeds, which implies that your common filter should be using parameters for

232
00:18:12,960 --> 00:18:16,880
each speed, you know, nominally, that would be the best thing to do.

233
00:18:16,880 --> 00:18:23,160
And so, so like a very natural, you know, first attempt at this problem is you, you have

234
00:18:23,160 --> 00:18:27,200
a bank of common filters and you have a bank of speeds and then you, you have a two-part

235
00:18:27,200 --> 00:18:28,200
problem.

236
00:18:28,200 --> 00:18:29,200
What speed are you at?

237
00:18:29,200 --> 00:18:32,840
You figure that out, what common filter should you use.

238
00:18:32,840 --> 00:18:37,480
This is a, you know, it's a very simple, nice intuitive, but it's a bit, it's a two-part

239
00:18:37,480 --> 00:18:44,920
problem and it's also, doesn't necessarily scale as well because you have to go and train

240
00:18:44,920 --> 00:18:50,320
all this, this whole bank and, and then you have to figure out, exactly, you can't have

241
00:18:50,320 --> 00:18:55,840
an infinitely, you know, resume, resolve banks, so you, to figure out what kind of bins

242
00:18:55,840 --> 00:18:59,840
are you going to have to cover, what you need to cover.

243
00:18:59,840 --> 00:19:06,920
Then the other, so it's, it's very natural and, and you look at how people can just have

244
00:19:06,920 --> 00:19:12,000
deep learning, try to solve the system, so you can remove the common filter and say, okay,

245
00:19:12,000 --> 00:19:17,320
we have to deal with Doppler and common filter changing, why don't we just put an RNN

246
00:19:17,320 --> 00:19:23,320
in the system and then train it on all this data of the channel changing and then have

247
00:19:23,320 --> 00:19:26,200
it figure out what it should be doing.

248
00:19:26,200 --> 00:19:31,120
And it is a universal approximator, so if we give it the right amount of data, it should

249
00:19:31,120 --> 00:19:34,640
figure out to do what the common filter does, right?

250
00:19:34,640 --> 00:19:42,920
And specifically, would you be using the RNN to predict, to predict the, the channel characteristics

251
00:19:42,920 --> 00:19:47,160
or to predict the ultimate output bits, for example?

252
00:19:47,160 --> 00:19:53,280
So just the, just the channel itself, and then we would feed that into the rest of the,

253
00:19:53,280 --> 00:19:56,160
demodulator that would get the bits.

254
00:19:56,160 --> 00:19:57,160
Yeah.

255
00:19:57,160 --> 00:19:58,160
Okay.

256
00:19:58,160 --> 00:19:59,160
Got it.

257
00:19:59,160 --> 00:20:05,360
And so again, kind of universal approximator, given enough data and RNN should work, but,

258
00:20:05,360 --> 00:20:10,640
but, I think is where you were going.

259
00:20:10,640 --> 00:20:15,720
What, what we, the other thing we tried was let's just have an RNN to take the observations

260
00:20:15,720 --> 00:20:19,960
and then tell us what kind of common filter we should use.

261
00:20:19,960 --> 00:20:23,680
And then, you know, the nice thing now is we have somewhat of a continuum of parameters

262
00:20:23,680 --> 00:20:29,640
for the common filter and then we also can still have a nice way of making it end to

263
00:20:29,640 --> 00:20:30,640
end trainable.

264
00:20:30,640 --> 00:20:37,920
So unlike the two-stage approach where you have to go and have some kind of, you're sick

265
00:20:37,920 --> 00:20:42,720
of, of training things and building up different parts of the system, here we have one that

266
00:20:42,720 --> 00:20:48,440
we just give data to it and then give, you know, let it train.

267
00:20:48,440 --> 00:20:54,520
And, and so we, we tried all of these and, you know, the nice, there were some interesting

268
00:20:54,520 --> 00:20:56,200
things that actually came up.

269
00:20:56,200 --> 00:21:00,920
So, you know, naturally we, we want to see that we're doing better than everything.

270
00:21:00,920 --> 00:21:05,880
And, you know, we were able to show that this, what we're calling this neural augmented

271
00:21:05,880 --> 00:21:10,440
common filter, specifically we're calling it a hypernet common filter, since we have

272
00:21:10,440 --> 00:21:14,920
an RNN that's setting the parameters, it's kind of a hypernet.

273
00:21:14,920 --> 00:21:21,600
And then, you know, interestingly, so, so, you know, the benefit over the traditional

274
00:21:21,600 --> 00:21:26,320
approach is that it's end to end trainable, so it's much more straightforward.

275
00:21:26,320 --> 00:21:31,480
You can just expose it to data and then it learns and then, you know, it's ready to go.

276
00:21:31,480 --> 00:21:36,720
It makes the offline process much simpler.

277
00:21:36,720 --> 00:21:43,800
And it ends up being also, because there's a continuum of settings, you're not limited

278
00:21:43,800 --> 00:21:51,040
by the coarseness of binning that typically comes up from, you know, practical reduction

279
00:21:51,040 --> 00:21:55,080
of the problem of the solution.

280
00:21:55,080 --> 00:22:00,480
Now when we look at how it compares with the LSTM, which is what we used in this particular

281
00:22:00,480 --> 00:22:10,760
solution, one thing that was really interesting was that our hypernet common filter actually

282
00:22:10,760 --> 00:22:14,560
addressed unseen cases a lot better.

283
00:22:14,560 --> 00:22:22,040
And so, one important detail I didn't going to get to you earlier, but what happens when

284
00:22:22,040 --> 00:22:28,640
we're actually tracking the channel is that we don't, we don't get to, we usually use

285
00:22:28,640 --> 00:22:33,880
pilot symbols, so something that we know at the transmitter and the receiver, we send

286
00:22:33,880 --> 00:22:34,880
it.

287
00:22:34,880 --> 00:22:39,200
And then we use that pilot to figure out what the channel looks like, the fade and the

288
00:22:39,200 --> 00:22:41,760
phase shift and so forth.

289
00:22:41,760 --> 00:22:48,520
And that, you know, the frequency at which we send a pilot is a trade-off, we always have

290
00:22:48,520 --> 00:22:49,520
to deal with.

291
00:22:49,520 --> 00:22:53,680
Like if we send more, then we have a great look at the channel, but we don't have much

292
00:22:53,680 --> 00:22:58,560
information that we can send, and if we send less, the opposite.

293
00:22:58,560 --> 00:23:08,400
And so, one interesting thing was when we had the LSTM train on one particular pilot density

294
00:23:08,400 --> 00:23:13,760
or frequency at which we send these pilots, and we gave it a different density, one that

295
00:23:13,760 --> 00:23:18,520
was higher or one that was lower, it didn't just perform worse, it actually in some cases

296
00:23:18,520 --> 00:23:24,360
was somewhat significantly lower in performance.

297
00:23:24,360 --> 00:23:29,120
And so it was, you know, seemed like it was probably learning some things that would

298
00:23:29,120 --> 00:23:34,840
help it to track the particular case it was given for the training set.

299
00:23:34,840 --> 00:23:38,400
But yeah, but maybe you was using maybe the wrong features or is over-fitting in such

300
00:23:38,400 --> 00:23:41,560
a way that it was not good at generalizing.

301
00:23:41,560 --> 00:23:46,840
Whereas when we constrained it to be this hypernet common filter, it actually performed

302
00:23:46,840 --> 00:23:54,840
well, like it gracefully degraded when it went to actually did well when it went to this

303
00:23:54,840 --> 00:24:01,760
lower density or this higher density without having seen these in the training set.

304
00:24:01,760 --> 00:24:11,920
And so the two cases we're comparing here are the LSTM alone to predict the channel

305
00:24:11,920 --> 00:24:19,200
versus the model that's predicting the common filter characteristics.

306
00:24:19,200 --> 00:24:28,120
And the idea maybe is that in a sense, it kind of relates to this conversation I have

307
00:24:28,120 --> 00:24:29,120
in the podcast.

308
00:24:29,120 --> 00:24:34,280
A lot like we know a lot about the physical world and its behavior, and we've developed

309
00:24:34,280 --> 00:24:40,320
these models that, you know, are representative, that in this case, the common filter.

310
00:24:40,320 --> 00:24:46,680
So how do we couple kind of statistical approaches and physics-based approaches so that we're

311
00:24:46,680 --> 00:24:50,560
not, you know, kind of throwing out the baby with the bath water, right?

312
00:24:50,560 --> 00:24:57,480
And in this case, it sounds like the common filters providing some constraints or guardrails

313
00:24:57,480 --> 00:25:04,320
to the RNN that allow it to perform better even when it's or to generalize better.

314
00:25:04,320 --> 00:25:11,320
Yeah, exactly. I think it as well put exactly the point of what we're doing.

315
00:25:11,320 --> 00:25:18,120
And we tried other situations where not just the pilot density change, but even the strength

316
00:25:18,120 --> 00:25:20,560
of the signal to noise change.

317
00:25:20,560 --> 00:25:25,360
So we, you know, we could train it at one signal to noise ratio and then test it at a lower

318
00:25:25,360 --> 00:25:27,400
one or test it at a higher one.

319
00:25:27,400 --> 00:25:35,480
And we saw, again, a similar robustness from having a hypernet common filter versus just

320
00:25:35,480 --> 00:25:40,640
a pure neural network.

321
00:25:40,640 --> 00:25:49,480
And this idea of, you know, what you're calling neural augmentation or hypernet augmentation,

322
00:25:49,480 --> 00:25:56,400
are you applying it to, or have you applied it to other types of models or other problems?

323
00:25:56,400 --> 00:26:01,800
Yeah, I think that it's a great that you brought that up.

324
00:26:01,800 --> 00:26:07,960
I like to think of this particular paper and, you know, all the things also from the

325
00:26:07,960 --> 00:26:10,160
podcast a year ago with Max.

326
00:26:10,160 --> 00:26:17,120
This is kind of a seed idea and we wanted to really go deep in one particular problem

327
00:26:17,120 --> 00:26:21,040
so that people can see, you know, the different trade-offs that we were trying to understand

328
00:26:21,040 --> 00:26:24,680
and see how things were doing.

329
00:26:24,680 --> 00:26:28,160
But then it's not that a common filter is going to solve every problem, but there are

330
00:26:28,160 --> 00:26:31,840
going to be these other core algorithms in different problems.

331
00:26:31,840 --> 00:26:37,280
And we want this philosophy of, you know, don't forsake all the domain knowledge you've

332
00:26:37,280 --> 00:26:38,280
built at this point.

333
00:26:38,280 --> 00:26:40,280
It's really just a little bit of mismatch.

334
00:26:40,280 --> 00:26:45,440
You have to figure out what that is and put the neural network such that we give it,

335
00:26:45,440 --> 00:26:50,960
you know, the right amount of flexibility to learn how to adapt, but not too much that

336
00:26:50,960 --> 00:26:59,800
it might, you know, learn the wrong things and kind of adapt the solution the wrong way.

337
00:26:59,800 --> 00:27:05,560
Before we jump into the next paper, can you speak specifically to the results you saw

338
00:27:05,560 --> 00:27:06,560
with this?

339
00:27:06,560 --> 00:27:14,080
You kind of spoke generally to it, it performed better than the LSTM alone, but how did

340
00:27:14,080 --> 00:27:20,200
it perform relative to the original common filter implementation?

341
00:27:20,200 --> 00:27:27,780
The original, like the classical solution where you can classify it, that one, the short

342
00:27:27,780 --> 00:27:31,280
coming is more in how coarse the bins are.

343
00:27:31,280 --> 00:27:39,280
And so it's a very nice smooth degradation now, or I should say smooth interpolation across

344
00:27:39,280 --> 00:27:45,880
these bins, because we can't, in the classical approach, we can't quite just, you know, have

345
00:27:45,880 --> 00:27:52,760
a very fine resolution of speeds from 0 to, you know, 500 kilometers per hour.

346
00:27:52,760 --> 00:27:58,600
We have to somehow make that practical and do, you know, a dozen bins or less.

347
00:27:58,600 --> 00:28:03,960
And so there's no, there's a lot of trial and error or a lot of heuristic behind solving

348
00:28:03,960 --> 00:28:12,400
that, and the hypernet actually is able to give us a different way of having, like, almost

349
00:28:12,400 --> 00:28:14,680
a continuous interpolation there.

350
00:28:14,680 --> 00:28:17,920
That's really where we saw a nice, healthy gain over that.

351
00:28:17,920 --> 00:28:18,920
Got it.

352
00:28:18,920 --> 00:28:19,920
Got it.

353
00:28:19,920 --> 00:28:20,920
Awesome.

354
00:28:20,920 --> 00:28:21,920
Awesome.

355
00:28:21,920 --> 00:28:29,800
So the next paper we want to talk about is focused on RF sensing and communication.

356
00:28:29,800 --> 00:28:33,920
Introduce us to the setup here and the problem that you're trying to solve.

357
00:28:33,920 --> 00:28:34,920
Yeah, yeah.

358
00:28:34,920 --> 00:28:41,880
This is another, this is kind of a fun area, I would say, because, so we've, I kind of

359
00:28:41,880 --> 00:28:48,280
walked you through the idea that signals degrade environment, interacts with the signal

360
00:28:48,280 --> 00:28:55,120
going from the transmitter receiver, and we have to be able to track that well and deal

361
00:28:55,120 --> 00:29:00,280
with it so that we get the information through efficiently.

362
00:29:00,280 --> 00:29:07,880
One interesting, you know, the dual of this kind of is that, the environment interacts

363
00:29:07,880 --> 00:29:12,200
and it, you know, can degrade our signal, it hurts the information that we send.

364
00:29:12,200 --> 00:29:16,240
But at the same time, there's a lot of information about the environment when it's degraded

365
00:29:16,240 --> 00:29:17,640
the signal.

366
00:29:17,640 --> 00:29:23,800
And so, so then, oh, how much can we learn about the environment whenever it degrades the

367
00:29:23,800 --> 00:29:28,640
signal, becomes like a question that we want to get to.

368
00:29:28,640 --> 00:29:36,440
And now when we go to 5G, we have like a much larger antenna raise, much wider bandwidth.

369
00:29:36,440 --> 00:29:42,600
It's like a richer signal set now that we have to really understand how things are being

370
00:29:42,600 --> 00:29:46,280
interfered with from the environment to the communication system.

371
00:29:46,280 --> 00:29:49,920
And so we flip this around and we say, well, instead of trying to get the information

372
00:29:49,920 --> 00:29:56,920
through, let's try to learn what's in, what's in the environment as much as we can to see,

373
00:29:56,920 --> 00:30:01,840
you know, what, what can we, how far can we go at this, essentially?

374
00:30:01,840 --> 00:30:07,360
And so, you know, a very simple, you know, the very starting point where they both interact,

375
00:30:07,360 --> 00:30:13,160
you know, is that can we try to predict when the fate is going to come and go and then

376
00:30:13,160 --> 00:30:15,280
you know, very simply like that.

377
00:30:15,280 --> 00:30:22,920
But as you may have seen, even industries are like small companies are starting to introduce

378
00:30:22,920 --> 00:30:24,400
this.

379
00:30:24,400 --> 00:30:31,040
There are different other levels of more sophisticated inference that can be done, like understanding

380
00:30:31,040 --> 00:30:38,640
the presence of a person in a particular space or the activity of detecting an activity

381
00:30:38,640 --> 00:30:42,600
in a particular space.

382
00:30:42,600 --> 00:30:48,800
There has been gesture recognition, I believe that you've probably seen this on phones

383
00:30:48,800 --> 00:30:51,440
and other places.

384
00:30:51,440 --> 00:30:57,000
And then a location in position is another very interesting use case where it's, you know,

385
00:30:57,000 --> 00:31:02,120
called RF fingerprinting sometimes where you actually try to pinpoint where the activity

386
00:31:02,120 --> 00:31:06,000
is happening relative to the environment.

387
00:31:06,000 --> 00:31:13,000
I assume the gesture, all the gesture stuff was based on sensors in the phone, like,

388
00:31:13,000 --> 00:31:14,800
you know, camera or a light or something.

389
00:31:14,800 --> 00:31:22,040
It never occurred to me that they might be using RF interference to, to track gestures.

390
00:31:22,040 --> 00:31:31,600
Yeah, that's more recent, I would say, relatively speaking, but there's a technology.

391
00:31:31,600 --> 00:31:36,880
As you move higher in frequency, you can actually separate the transmitter from the receiver

392
00:31:36,880 --> 00:31:38,480
in a very small space.

393
00:31:38,480 --> 00:31:44,800
So a phone can transmit and receive without jamming it so too much.

394
00:31:44,800 --> 00:31:48,520
And that's the technology behind some of the recent gesture recognition.

395
00:31:48,520 --> 00:31:53,520
So a phone will transmit at a millimeter wave frequency and listen at the same time.

396
00:31:53,520 --> 00:31:58,640
And then from that, it can see signatures of things moving.

397
00:31:58,640 --> 00:32:02,640
And then, of course, by machine learning to figure out, is that signature, you know,

398
00:32:02,640 --> 00:32:05,640
a swipe left or a swipe right or?

399
00:32:05,640 --> 00:32:06,640
Oh, wow.

400
00:32:06,640 --> 00:32:07,640
Wow.

401
00:32:07,640 --> 00:32:08,640
Yeah.

402
00:32:08,640 --> 00:32:15,040
And you mentioned some other companies working on this a couple of years ago, back in February

403
00:32:15,040 --> 00:32:22,320
18, I did an interview with a company called Ariel that is in this space, like using Wi-Fi

404
00:32:22,320 --> 00:32:31,000
and home or commercial buildings to detect presence and motion and, you know, in an elder

405
00:32:31,000 --> 00:32:35,280
care scenario, if someone falls, that kind of thing.

406
00:32:35,280 --> 00:32:41,240
It sounds like that's the same kind of problem or same kind of result you're tackling.

407
00:32:41,240 --> 00:32:46,240
It's different about the work that you, that's in this paper.

408
00:32:46,240 --> 00:32:47,240
Yeah.

409
00:32:47,240 --> 00:32:49,240
Great point.

410
00:32:49,240 --> 00:32:50,240
Yeah.

411
00:32:50,240 --> 00:33:00,440
So a lot of really nice use cases, our knowledge are supervised and very densely labeled.

412
00:33:00,440 --> 00:33:07,680
And so, which is a great solution, but it's not necessarily something that scales.

413
00:33:07,680 --> 00:33:15,360
So what we did here was the team, it came back to the problem and they asked, is there

414
00:33:15,360 --> 00:33:19,360
any way we can reduce the requirement to labeling?

415
00:33:19,360 --> 00:33:24,280
If we can make it completely unsupervised with the proper loss function or if we can have

416
00:33:24,280 --> 00:33:27,040
some weak labeling.

417
00:33:27,040 --> 00:33:31,160
And that's, and we looked at, you know, instead of looking at, you know, all the problems

418
00:33:31,160 --> 00:33:32,800
in the space, we looked at positioning.

419
00:33:32,800 --> 00:33:40,360
So this seemed like a pretty challenging problem, but at the same time, a really nice one that

420
00:33:40,360 --> 00:33:48,440
has a lot of commonality with other applications at bar, since, and so, and so, you know, there

421
00:33:48,440 --> 00:33:56,000
was a prior result where, since you know that what you're tracking is moving in time, they

422
00:33:56,000 --> 00:34:02,760
looked at using a triplet loss to try to space things out so that in the latent space,

423
00:34:02,760 --> 00:34:08,880
so in, in the real space, we can kind of assume that samples are close together because

424
00:34:08,880 --> 00:34:10,040
they're close in time.

425
00:34:10,040 --> 00:34:15,360
And so in the latent space, we, it should be that they're also close in the latent space

426
00:34:15,360 --> 00:34:17,600
because they're close in time.

427
00:34:17,600 --> 00:34:22,640
And then, and then in these previous results, they had a, you know, a nice first step

428
00:34:22,640 --> 00:34:31,080
in showing that, okay, we can get a reasonably good similarity between the latent space

429
00:34:31,080 --> 00:34:35,800
distance and in the real distance in, in the real world.

430
00:34:35,800 --> 00:34:40,000
But it wasn't, you know, perfect because it wasn't geometrically consistent.

431
00:34:40,000 --> 00:34:46,720
So a floor plan may not look like a floor plan, even though you are moving around and close

432
00:34:46,720 --> 00:34:49,680
distances were close.

433
00:34:49,680 --> 00:34:55,920
The, the part that was missing is that, you know, sometimes you may be close in distance

434
00:34:55,920 --> 00:34:59,720
but not necessarily close in time because you may have walked in a circle or you may have

435
00:34:59,720 --> 00:35:03,640
come back somehow to the point that you were at.

436
00:35:03,640 --> 00:35:09,720
So our team looked at, um, clustering, a lot of deep cluster, you know, really interesting

437
00:35:09,720 --> 00:35:14,040
technology that's been used for other things and self-supervised learning.

438
00:35:14,040 --> 00:35:19,680
And, and looked and say, what if we put triplet loss together with this deep cluster so

439
00:35:19,680 --> 00:35:25,200
that we can address this problem when we do come back to the same space that we know

440
00:35:25,200 --> 00:35:29,680
that, okay, they actually should be close together and not for our part because of their,

441
00:35:29,680 --> 00:35:32,160
their cluster in another dimension.

442
00:35:32,160 --> 00:35:40,440
And so, uh, and so putting those two together, uh, now our latent space, which, um, uh, looks

443
00:35:40,440 --> 00:35:48,600
a lot better, a lot closer to reality of, of distance and position than, um, then before

444
00:35:48,600 --> 00:35:51,800
and then, you know, previous methods before.

445
00:35:51,800 --> 00:35:57,400
And so now you can go and just, in theory, you just walk around a room and then you're

446
00:35:57,400 --> 00:36:02,480
just listening to all the RF signals and with the loss functions and so forth training

447
00:36:02,480 --> 00:36:07,840
it, you come back and you see, okay, the latent space looks a lot like the room and where

448
00:36:07,840 --> 00:36:09,240
you were in the room.

449
00:36:09,240 --> 00:36:13,640
And it's not perfect, but it's a lot better than, than previous by doing this, both this

450
00:36:13,640 --> 00:36:16,720
triplet loss and then this clustering.

451
00:36:16,720 --> 00:36:21,680
And then our team won a, you know, one step further and they said, um, what if we just,

452
00:36:21,680 --> 00:36:26,680
what if we just coarsely told you, okay, you're in a room and the room has this shape and

453
00:36:26,680 --> 00:36:29,200
then you, you moved to another room and the room has this shape.

454
00:36:29,200 --> 00:36:34,320
So it's, it's much, it's still, it now becomes labeling, but it's a much lighter labeling

455
00:36:34,320 --> 00:36:40,760
instead of having, uh, some way of annotating exactly where this, um, person was moving around

456
00:36:40,760 --> 00:36:41,920
the room.

457
00:36:41,920 --> 00:36:45,880
You just tell it, okay, I'm in a room, I'm moving around, but the room has this boundary

458
00:36:45,880 --> 00:36:48,520
and that's all I'm going to know.

459
00:36:48,520 --> 00:36:55,640
And then, you know, the really cool thing was that now they actually could get to, um,

460
00:36:55,640 --> 00:37:00,320
you know, within one or two meters, which was as good as the supervised case where we

461
00:37:00,320 --> 00:37:06,400
did have a very precise tracking of the user and the labeling.

462
00:37:06,400 --> 00:37:11,400
And so by putting all these things together, then the idea is that, um, it's very simple

463
00:37:11,400 --> 00:37:18,720
to go in and, and build up, um, I know that they can infer where you are from the interference

464
00:37:18,720 --> 00:37:28,120
in the RF, uh, that it sees, um, and so the, the two parts of that are the, the triplet

465
00:37:28,120 --> 00:37:36,400
loss and the clustering, the deep clustering, that's fully unsupervised and then the, the,

466
00:37:36,400 --> 00:37:41,080
what you described there towards the end of, um, oh, that's like some labeling, localizing

467
00:37:41,080 --> 00:37:42,080
in the room.

468
00:37:42,080 --> 00:37:43,080
Yeah.

469
00:37:43,080 --> 00:37:44,080
It's done labeling.

470
00:37:44,080 --> 00:37:45,080
That's the weak labeling part.

471
00:37:45,080 --> 00:37:46,080
That's right.

472
00:37:46,080 --> 00:37:47,080
Yeah.

473
00:37:47,080 --> 00:37:49,080
Got it.

474
00:37:49,080 --> 00:37:57,080
And, uh, were those, uh, were those done successively or were those done, was the system

475
00:37:57,080 --> 00:38:05,000
trained with kind of two components to, to the, the training process, this unsupervised

476
00:38:05,000 --> 00:38:07,640
part and the weak supervised part.

477
00:38:07,640 --> 00:38:08,800
It was done together.

478
00:38:08,800 --> 00:38:12,720
So there, there is one, I should say, if you read the paper a little bit further, there

479
00:38:12,720 --> 00:38:17,040
are some things we do to initialize one other loss function that we put in.

480
00:38:17,040 --> 00:38:22,600
It's a jumpstart it, but overall those two key, key parts that we're doing together.

481
00:38:22,600 --> 00:38:31,080
I should mention that there's a, uh, a video of this system, um, that will post a link

482
00:38:31,080 --> 00:38:33,080
to in the show notes page.

483
00:38:33,080 --> 00:38:37,080
It was demonstrated at, uh, MWC, uh, Mobile World Congress.

484
00:38:37,080 --> 00:38:38,080
Is that right?

485
00:38:38,080 --> 00:38:39,080
Yeah, yeah.

486
00:38:39,080 --> 00:38:40,080
Thank you for reminding me.

487
00:38:40,080 --> 00:38:41,080
That's right.

488
00:38:41,080 --> 00:38:46,080
Um, you know, one of the really exciting things about this was, um, we had a whole team

489
00:38:46,080 --> 00:38:53,600
that could give us real world data and then different locations and, um, and we can really

490
00:38:53,600 --> 00:38:57,880
prove out these ideas is this, how robust is this an approach?

491
00:38:57,880 --> 00:39:04,840
And although the, the paper and the demo probably showed two particular types of layouts, um,

492
00:39:04,840 --> 00:39:09,720
we did test them on more and also the situations within each layout will also play around with

493
00:39:09,720 --> 00:39:15,200
like, you know, someone holding a, a metal sheet, for instance, and, and so if you go to

494
00:39:15,200 --> 00:39:22,200
that, uh, MWC demo, you can, you can get a nice, um, feel for, you know, what it, how does

495
00:39:22,200 --> 00:39:23,200
it look?

496
00:39:23,200 --> 00:39:27,720
You know, they have a nice animation of a person walking around, which is the ground truth

497
00:39:27,720 --> 00:39:31,920
and then you can see where, like, a dot to tell you where should you be?

498
00:39:31,920 --> 00:39:36,840
And, uh, it's pretty amazing thinking that, unfortunately, the MWC doesn't quite tell

499
00:39:36,840 --> 00:39:41,920
you that it's unsupervised or weekly supervised, which I personally feel like even more amazing

500
00:39:41,920 --> 00:39:47,360
than even the idea is, like, you're being able to be tracked with just RF signals is amazing

501
00:39:47,360 --> 00:39:48,720
in its own right, I think.

502
00:39:48,720 --> 00:39:53,560
But then when you go a little deeper and you realize, oh, this is something that they've

503
00:39:53,560 --> 00:40:00,400
gone and made it, you know, much more, um, scalable in a sense, um, that's, that's really

504
00:40:00,400 --> 00:40:03,400
a, uh, amazing that the team was able to do that.

505
00:40:03,400 --> 00:40:04,400
Yeah.

506
00:40:04,400 --> 00:40:13,000
I've wondered in thinking about these applications, like, do you, uh, to what degree do you need

507
00:40:13,000 --> 00:40:20,880
kind of inside access to the, to the devices or the, the Wi-Fi access point in the case

508
00:40:20,880 --> 00:40:26,160
if Wi-Fi is the, the signal that you're using in order to do the, or is there some, you

509
00:40:26,160 --> 00:40:32,680
know, net flow or logging or something, I can turn on in my, my unify system that will,

510
00:40:32,680 --> 00:40:37,040
uh, collect all the data and I could try to replicate what you're doing and build some

511
00:40:37,040 --> 00:40:41,080
system that tracks presence within, within my building here.

512
00:40:41,080 --> 00:40:46,160
There are some standards activities happening to, to make this somewhat, um, I guess like

513
00:40:46,160 --> 00:40:47,640
a standard that's accessible.

514
00:40:47,640 --> 00:40:50,280
I think we mentioned that a little bit in our paper.

515
00:40:50,280 --> 00:40:56,600
Um, I, I know that, uh, so I can't speak on, like, our product and other products in

516
00:40:56,600 --> 00:40:57,600
the field.

517
00:40:57,600 --> 00:41:01,240
It's, uh, I don't know that very well, but I do know that there are these capabilities

518
00:41:01,240 --> 00:41:06,680
and, you know, we've had the benefit of working with the, those, those, um, like we have counter

519
00:41:06,680 --> 00:41:11,600
parts on like a wireless research team and they really help us to enable us to get the

520
00:41:11,600 --> 00:41:14,920
right data and, and clean up the signal and make sure.

521
00:41:14,920 --> 00:41:19,680
So, um, you know, in theory, you should be able to do some of these, I, I think, but

522
00:41:19,680 --> 00:41:25,680
I, you know, the, the actual execution, uh, I have to have another show with some other

523
00:41:25,680 --> 00:41:26,680
experts.

524
00:41:26,680 --> 00:41:33,600
Maybe that's awesome, yeah, awesome, you know, maybe to kind of wrap, wrap things up, um,

525
00:41:33,600 --> 00:41:41,680
you know, these two papers are, again, kind of under this theme of, you know, how machine

526
00:41:41,680 --> 00:41:50,040
learning can be used to enable, you know, the more effective delivery of network services

527
00:41:50,040 --> 00:42:01,600
like 5G, um, and in some ways, a lot of that is enabled by increasing sophistication on,

528
00:42:01,600 --> 00:42:08,360
on the devices themselves, uh, and, um, machine learning capabilities on device.

529
00:42:08,360 --> 00:42:12,160
Uh, I'd love to hear you kind of riff on, you know, where you see all that going and what's

530
00:42:12,160 --> 00:42:13,160
possible.

531
00:42:13,160 --> 00:42:14,160
Yeah.

532
00:42:14,160 --> 00:42:23,000
Um, uh, I should say that, like, when, when you see this demo, MWC, it's part of, uh,

533
00:42:23,000 --> 00:42:29,200
I would say like a series of four or five demos in machine learning, uh, and 5G.

534
00:42:29,200 --> 00:42:35,760
And there's a lot of, uh, really, you know, cool applications, um, across, uh, like,

535
00:42:35,760 --> 00:42:40,800
for instance, like, there's outdoor positioning, there's, um, milling away beam forming.

536
00:42:40,800 --> 00:42:43,520
There's, um, you know, efficient channel state feedback.

537
00:42:43,520 --> 00:42:52,840
A lot of these have core designs enabled from deep learning and, um, they are also relying

538
00:42:52,840 --> 00:43:00,520
on, uh, the device having a very capable AI, um, and, you know, that's been, uh, a core

539
00:43:00,520 --> 00:43:06,280
you've probably seen on the show, uh, from, uh, many of our, um, you know, Qualcomm

540
00:43:06,280 --> 00:43:12,360
participants were focused on making sure that, uh, what AI can do, it becomes ubiquitous

541
00:43:12,360 --> 00:43:18,360
so we can bring it to mobile and, and have it in as many places as we can, and it, um,

542
00:43:18,360 --> 00:43:23,520
not only are the use cases that we come to associate with AI, like, you know, not language

543
00:43:23,520 --> 00:43:29,000
processing or computer vision, perception, but even making, you know, the wireless system

544
00:43:29,000 --> 00:43:35,840
better also is now benefiting, or potentially going to benefit from having, uh, a very capable

545
00:43:35,840 --> 00:43:45,760
device. And, um, and in this, um, this area of, say, you know, joint RF sensing are using

546
00:43:45,760 --> 00:43:53,080
the COM system for RF sensing, um, this is, uh, like, like, like other things I talk about,

547
00:43:53,080 --> 00:43:59,840
it's this very simple, um, example, and it's a seed idea, but there's certainly more things

548
00:43:59,840 --> 00:44:05,840
that can come from it, and we didn't demonstrate it on devices, mobile devices, we actually

549
00:44:05,840 --> 00:44:10,000
demonstrate on base stations, but you can imagine that, um, there are other things that

550
00:44:10,000 --> 00:44:14,960
you can have the mobile device get involved. And, you know, building up an awareness of

551
00:44:14,960 --> 00:44:19,320
the environment, here where we're showing that you can track people, uh, you can imagine

552
00:44:19,320 --> 00:44:25,760
over, uh, over the course of this that you can, you can start, um, understanding environment

553
00:44:25,760 --> 00:44:31,640
and, um, making the whole communication system more efficient, because now you don't have

554
00:44:31,640 --> 00:44:36,440
to serve, for instance, you don't have to blindly search for, whereas the best, um,

555
00:44:36,440 --> 00:44:40,040
where's the base station coming from, or where's the best direction to have a communication

556
00:44:40,040 --> 00:44:45,680
link, because, uh, you've established an awareness of where strong reflectors are, where blockers

557
00:44:45,680 --> 00:44:50,360
are, and, and where you're moving in the environment. So that's something we're really excited

558
00:44:50,360 --> 00:44:55,600
about moving forward to see, um, this, um, joint interaction between, you know, sensing

559
00:44:55,600 --> 00:45:00,160
helping to communicate AI, and sensing helping communication, and, you know, AI on device

560
00:45:00,160 --> 00:45:08,000
helping this, this, um, enable this, mm-hmm. Awesome, awesome. Well, Joseph, thanks so much

561
00:45:08,000 --> 00:45:13,680
for joining us and sharing a bit about what you're up to, uh, and walking through these

562
00:45:13,680 --> 00:45:19,360
two papers with us. Great, um, I hope, uh, hope you enjoyed it, and, uh, hope you look

563
00:45:19,360 --> 00:45:22,360
forward to seeing more stuff that we're going to do, because we have a lot more coming.

564
00:45:22,360 --> 00:45:50,360
Awesome. Thanks so much. I certainly did.

