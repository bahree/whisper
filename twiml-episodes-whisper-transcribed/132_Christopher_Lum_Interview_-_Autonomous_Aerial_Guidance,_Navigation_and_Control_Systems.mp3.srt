1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,240
I'm your host Sam Charrington.

4
00:00:31,240 --> 00:00:36,600
You've heard me mention my upcoming AI Summit previously and while I am just so excited

5
00:00:36,600 --> 00:00:39,520
because it's right around the corner.

6
00:00:39,520 --> 00:00:44,240
The event takes place April 30th and May 1st in Las Vegas in conjunction with the Interop

7
00:00:44,240 --> 00:00:46,600
ITX conference.

8
00:00:46,600 --> 00:00:51,160
If you're an IT technology or business leader who needs to get smart on the broad spectrum

9
00:00:51,160 --> 00:00:56,520
of machine learning and AI opportunities in the enterprise or someone in your organization

10
00:00:56,520 --> 00:01:01,480
fits that description and can benefit from a level up in this area, you should definitely

11
00:01:01,480 --> 00:01:04,320
make plans to join us in Vegas.

12
00:01:04,320 --> 00:01:09,280
I'll be presenting an introductory session on ML and AI fundamentals and we'll have deep

13
00:01:09,280 --> 00:01:15,520
dive sessions on AI for NLP and conversational applications, computer vision and Internet

14
00:01:15,520 --> 00:01:17,640
of things on Monday.

15
00:01:17,640 --> 00:01:22,400
And then on Tuesday we'll be discussing data collection and annotation, operationalizing

16
00:01:22,400 --> 00:01:25,880
and managing AI and building out your AI strategy.

17
00:01:25,880 --> 00:01:30,680
Then, you'll have a chance to discuss your organization's unique AI opportunities and

18
00:01:30,680 --> 00:01:34,320
challenges with our distinguished experts.

19
00:01:34,320 --> 00:01:40,800
To learn more about the event, head over to Twimbleai.com slash AI Summit for Details and be

20
00:01:40,800 --> 00:01:48,000
sure to use code CharringTin for 20% off of your registration.

21
00:01:48,000 --> 00:01:53,800
Okay, in this episode I'm joined by Christopher Lum, research assistant professor in the University

22
00:01:53,800 --> 00:01:58,080
of Washington's Department of Aeronautics and Astronautics.

23
00:01:58,080 --> 00:02:03,040
Chris also co-heads the University's Autonomous Flight Systems Lab, where he and his students

24
00:02:03,040 --> 00:02:08,160
are working on the guidance, navigation and control of unmanned systems.

25
00:02:08,160 --> 00:02:12,360
In our conversation, we discuss some of the technical and regulatory challenges of building

26
00:02:12,360 --> 00:02:15,920
and deploying unmanned autonomous systems.

27
00:02:15,920 --> 00:02:20,640
We also talk about some interesting work he's doing on evolutionary path planning systems,

28
00:02:20,640 --> 00:02:24,200
as well as a precision agriculture use case.

29
00:02:24,200 --> 00:02:28,800
Finally, Chris shares some great starting places for those looking to begin a journey

30
00:02:28,800 --> 00:02:30,800
into autonomous systems research.

31
00:02:30,800 --> 00:02:38,640
Alright, let's roll.

32
00:02:38,640 --> 00:02:41,840
Alright everyone, I am on the line with Chris Lum.

33
00:02:41,840 --> 00:02:48,520
Chris is a research assistant professor at the University of Washington in the Department

34
00:02:48,520 --> 00:02:51,640
of Aeronautics and Astronautics.

35
00:02:51,640 --> 00:02:57,240
And Chris has joined us today to talk about some of his work in autonomous vehicles.

36
00:02:57,240 --> 00:02:58,560
Chris, welcome to the podcast.

37
00:02:58,560 --> 00:03:01,200
Hi, well, thank you so much for having me, Sam.

38
00:03:01,200 --> 00:03:02,600
Thank you for joining us.

39
00:03:02,600 --> 00:03:07,040
I'm really looking forward to diving into the discussion here.

40
00:03:07,040 --> 00:03:10,520
Why don't we get started by having you tell us a little bit about your background and

41
00:03:10,520 --> 00:03:14,000
how you got involved in autonomous vehicles?

42
00:03:14,000 --> 00:03:20,280
Sure, actually, my background is fairly simple, basically, I've been at the University

43
00:03:20,280 --> 00:03:25,600
of Washington for around, I guess, what is this now, about the past 18 years.

44
00:03:25,600 --> 00:03:34,040
I started in 1999 as an undergrad and I finished my PhD there in 2009 in Aeronautics and Astronautics.

45
00:03:34,040 --> 00:03:37,680
And I've been in my current position as a research assistant professor for about the past

46
00:03:37,680 --> 00:03:39,440
two years or so.

47
00:03:39,440 --> 00:03:44,880
I think I've heard it referred to as being a lifer and I can't really tell if that's

48
00:03:44,880 --> 00:03:45,880
the end.

49
00:03:45,880 --> 00:03:49,600
If that's a term of endearment or maybe it's some sort of cautionary term of what happens

50
00:03:49,600 --> 00:03:54,680
if you get stuck in the same institution for too long and can't get a real job, but

51
00:03:54,680 --> 00:03:59,760
at any event, I've been interested in unmanned systems and aircraft probably since around

52
00:03:59,760 --> 00:04:02,320
the late 90s, early 2000s.

53
00:04:02,320 --> 00:04:06,680
So the University of Washington was actually part of the team that put the first robotic

54
00:04:06,680 --> 00:04:11,560
aircraft across the Atlantic Ocean around this time frame and pretty much ever since then

55
00:04:11,560 --> 00:04:15,160
I've been fascinated with applications of unmanned aerial systems.

56
00:04:15,160 --> 00:04:17,160
Oh, fantastic.

57
00:04:17,160 --> 00:04:23,840
You know, I've noted this in a previous podcast on this topic, but you've got to, I'm

58
00:04:23,840 --> 00:04:30,080
sure a unique perspective on this being so close to Boeing, but, you know, currently

59
00:04:30,080 --> 00:04:35,800
we think of autonomous vehicles largely in the context of self-driving cars, but there's

60
00:04:35,800 --> 00:04:40,880
a ton of work that has happened in this space around flying vehicles.

61
00:04:40,880 --> 00:04:45,840
Yeah, absolutely, and I know several of your recent guests have all been talking about

62
00:04:45,840 --> 00:04:46,840
self-driving cars.

63
00:04:46,840 --> 00:04:51,320
And as you mentioned, it's pretty much a very hot topic of research right now.

64
00:04:51,320 --> 00:04:56,000
But, you know, I'm not entirely versed on the history of self-driving cars, but I would

65
00:04:56,000 --> 00:05:01,400
probably guess that autonomous aircraft and some of the research in that realm has been

66
00:05:01,400 --> 00:05:04,240
going on quite a bit longer than that.

67
00:05:04,240 --> 00:05:09,400
It started to gain a lot of traction kind of in the early 90s here, a lot of some of

68
00:05:09,400 --> 00:05:16,240
the technology finally came to fruition to kind of enable a lot of the current iteration

69
00:05:16,240 --> 00:05:19,040
of what you might think of as an unmanned aerial system.

70
00:05:19,040 --> 00:05:23,200
But yeah, this research has been going on for quite a while in this space, and in some

71
00:05:23,200 --> 00:05:27,760
senses, I think it's an easier problem, and in some senses, it's definitely a more difficult

72
00:05:27,760 --> 00:05:28,760
one.

73
00:05:28,760 --> 00:05:35,720
I'm really looking forward to hearing you dig into those two areas, but for context, why

74
00:05:35,720 --> 00:05:40,960
don't we get started, or for context, why don't you tell us a little bit about your research

75
00:05:40,960 --> 00:05:41,960
focus?

76
00:05:41,960 --> 00:05:42,960
Sure.

77
00:05:42,960 --> 00:05:47,840
So, the lab that I direct up at the University of Washington is called the Autonomous

78
00:05:47,840 --> 00:05:53,320
Flight Systems Laboratory, and basically we're interested in pretty much researching any

79
00:05:53,320 --> 00:05:59,680
technology that's related to guidance, navigation, and control of unmanned systems or automation

80
00:05:59,680 --> 00:06:00,680
in general here.

81
00:06:00,680 --> 00:06:06,880
So, a lot of the times that has projects like looking at autonomous mapping here, or

82
00:06:06,880 --> 00:06:12,520
maybe performing risk assessment of an unmanned mission, or looking at maybe path planning.

83
00:06:12,520 --> 00:06:16,240
So, there's a couple of different projects we've looked at in the past, but the one

84
00:06:16,240 --> 00:06:21,640
flavor that unifies them all is they have some technology that's related to an aircraft

85
00:06:21,640 --> 00:06:23,960
or autonomy in general.

86
00:06:23,960 --> 00:06:24,960
Hmm.

87
00:06:24,960 --> 00:06:29,160
You say autonomy in general, meaning other types of vehicles beyond aircraft?

88
00:06:29,160 --> 00:06:30,160
Yeah.

89
00:06:30,160 --> 00:06:31,160
Yeah, absolutely.

90
00:06:31,160 --> 00:06:36,800
We've looked at some things like some obviously ground robots, some surface vehicles,

91
00:06:36,800 --> 00:06:42,120
like autonomous boats here, but in general, a lot of the times where we've historically

92
00:06:42,120 --> 00:06:47,600
been interested in the algorithms that are running on these systems here, and a lot

93
00:06:47,600 --> 00:06:52,200
of the times the autonomy aspect or the algorithm that you're running, you know, it doesn't

94
00:06:52,200 --> 00:06:56,400
have to be flying on an aircraft, you know, you're trying to do some path planning through

95
00:06:56,400 --> 00:07:02,440
a complicated environment, or you're trying to build a map of an environment, and you

96
00:07:02,440 --> 00:07:06,400
could do that using an aircraft, or if it's more pertinent, you could do that with

97
00:07:06,400 --> 00:07:08,400
a ground vehicle or a surface vehicle.

98
00:07:08,400 --> 00:07:14,320
So our major focus in the past has really been developing the algorithms that would drive

99
00:07:14,320 --> 00:07:18,320
these vehicles or enable some sort of functionality.

100
00:07:18,320 --> 00:07:24,760
And the fact that it flies is almost more of a historical trend with our group is, you

101
00:07:24,760 --> 00:07:28,040
know, we've just been more comfortable with the aircraft and have a little bit more experience

102
00:07:28,040 --> 00:07:32,480
with the aircraft, but as I'm sure you're well aware of, and many of your other guests

103
00:07:32,480 --> 00:07:37,840
have talked about autonomy spreads out and is much larger than a particular vehicle that

104
00:07:37,840 --> 00:07:39,920
you're happy to be using.

105
00:07:39,920 --> 00:07:47,800
You mentioned boats and, and I mentioned or we mentioned Boeing, Boeing, I think earlier

106
00:07:47,800 --> 00:07:54,840
this year purchased a company that was doing, like unmanned underwater vehicles for sea

107
00:07:54,840 --> 00:07:55,840
exploration.

108
00:07:55,840 --> 00:08:00,200
Did you ever come across that acquisition, or are you familiar with that company?

109
00:08:00,200 --> 00:08:06,720
I am not familiar with that particular company or application that you mentioned, but, you

110
00:08:06,720 --> 00:08:11,440
know, there are faculty here at the UW that have looked at underwater vehicles.

111
00:08:11,440 --> 00:08:15,840
In fact, that's, that's a major research focus here at UW.

112
00:08:15,840 --> 00:08:22,280
There's a vehicle called a sea glider and it's an underwater vehicle and basically it

113
00:08:22,280 --> 00:08:25,160
operates by changing its buoyancy.

114
00:08:25,160 --> 00:08:29,640
So sometimes if you're trying to dive, it is a little bit heavier than water and then

115
00:08:29,640 --> 00:08:33,280
it has an internal bladder which can change its buoyancy to be a little bit lighter than

116
00:08:33,280 --> 00:08:34,280
water.

117
00:08:34,280 --> 00:08:39,520
It's got wings on the outside of it and you can imagine as this thing is descending

118
00:08:39,520 --> 00:08:47,000
through the, the water column, it can effectively glide as it's descending and as it comes

119
00:08:47,000 --> 00:08:50,760
back up, you basically just change the buoyancy to be a little bit lighter than water and

120
00:08:50,760 --> 00:08:52,760
now it just glides in the opposite direction.

121
00:08:52,760 --> 00:08:56,200
So now you're gaining altitude or getting closer to the surface, but you're basically

122
00:08:56,200 --> 00:08:58,240
able to affect forward motion with this.

123
00:08:58,240 --> 00:09:01,920
So there's been a couple of groups of the University of Washington that have been very

124
00:09:01,920 --> 00:09:07,440
interested in the underwater robotic side of things, using things like the sea glider

125
00:09:07,440 --> 00:09:09,880
or custom made hardware as well.

126
00:09:09,880 --> 00:09:10,880
Okay.

127
00:09:10,880 --> 00:09:17,280
So what are some of the major challenges in the areas that you're focused on?

128
00:09:17,280 --> 00:09:20,960
You know, things you mentioned path planning and some others.

129
00:09:20,960 --> 00:09:25,960
Well, yeah, there, I guess that's really an interesting question because in this space

130
00:09:25,960 --> 00:09:30,440
there's, there's a lot of, as you mentioned, different challenges and right now I would

131
00:09:30,440 --> 00:09:33,360
almost bend these into two different buckets.

132
00:09:33,360 --> 00:09:37,200
There's obviously some of these technical challenges that people are interested in right

133
00:09:37,200 --> 00:09:42,200
now, like doing detect and avoid, right, where an aircraft would be able to find another

134
00:09:42,200 --> 00:09:47,400
aircraft and de-conflict and avoid a collision.

135
00:09:47,400 --> 00:09:52,160
There's technical challenges like that, but one of the almost bigger problems or obstacles,

136
00:09:52,160 --> 00:09:55,880
well, maybe obstacles are wrong or maybe we should just keep using the word challenge,

137
00:09:55,880 --> 00:10:03,400
but it is one of a regulatory one, the regulatory environment and the US right now is not the

138
00:10:03,400 --> 00:10:09,720
most conducive to conducting cutting edge research with unmanned aircraft, but it's definitely

139
00:10:09,720 --> 00:10:10,840
getting better here.

140
00:10:10,840 --> 00:10:17,080
So if you want to talk about challenges, interestingly, probably more of the issues that we deal with

141
00:10:17,080 --> 00:10:22,680
right now trying to conduct research with unmanned aircraft is almost, we spend more time trying

142
00:10:22,680 --> 00:10:26,520
to deal with some of the regulatory issues than we do with the technical challenges right

143
00:10:26,520 --> 00:10:27,520
now.

144
00:10:27,520 --> 00:10:32,760
And what's your approach to that, is it, are you taking a research oriented approach to

145
00:10:32,760 --> 00:10:41,480
that or is it more of a traditional kind of advocacy lobbying, whatever the right terminology

146
00:10:41,480 --> 00:10:42,480
is there?

147
00:10:42,480 --> 00:10:50,120
Yeah, we kind of do a little bit of both here, obviously being a research group here,

148
00:10:50,120 --> 00:10:58,040
we do try to push a lot of these technical projects forward here from a pure basic research

149
00:10:58,040 --> 00:10:59,240
standpoint.

150
00:10:59,240 --> 00:11:04,240
But as you mentioned, the lobbying and the advocacy and the public perception is almost

151
00:11:04,240 --> 00:11:05,240
just as important.

152
00:11:05,240 --> 00:11:10,480
You know, UAS right now seem to be this very polarizing topic right now.

153
00:11:10,480 --> 00:11:14,760
You know, a lot of people love them, you know, people like you and I and probably the majority

154
00:11:14,760 --> 00:11:19,440
of the audience of people that listen to this podcast are, you know, very technologically

155
00:11:19,440 --> 00:11:20,440
savvy.

156
00:11:20,440 --> 00:11:26,120
They see the potential benefits here of unmanned aircraft and unmanned aerial systems.

157
00:11:26,120 --> 00:11:30,440
And really think that it's probably one of the next major revolutions in the aerospace

158
00:11:30,440 --> 00:11:31,440
industry.

159
00:11:31,440 --> 00:11:34,760
So you got that side of the fence, but then on the other side of the fence, you have

160
00:11:34,760 --> 00:11:39,880
a large chunk of the public right now that, you know, don't think that they're a good

161
00:11:39,880 --> 00:11:45,280
tool and perceive UAS as, you know, something that the government is going to use to invade

162
00:11:45,280 --> 00:11:46,280
your privacy here.

163
00:11:46,280 --> 00:11:51,640
So you have this polarizing space where you've got some people love it, some people hate

164
00:11:51,640 --> 00:11:52,640
it.

165
00:11:52,640 --> 00:11:56,440
So I think one of the jobs here, obviously, the people that are working in this space is

166
00:11:56,440 --> 00:12:01,760
probably to try to change the perception of some of the people that are a little bit negative

167
00:12:01,760 --> 00:12:05,920
or on the fence on these systems and show them that, you know, there really are a lot of

168
00:12:05,920 --> 00:12:09,720
positive applications for this type of technology right now.

169
00:12:09,720 --> 00:12:14,720
So advocacy is is a large part of the work right now, I think, in order to try to change

170
00:12:14,720 --> 00:12:23,240
that perception, I'd like to get to some of the details of the research specifically

171
00:12:23,240 --> 00:12:29,160
on the technology side, but just for sake of completeness, when you think of the positive

172
00:12:29,160 --> 00:12:35,280
benefits or more specifically, the positive use cases or applications, what are the things

173
00:12:35,280 --> 00:12:39,760
that you tell people to try to win them over?

174
00:12:39,760 --> 00:12:45,440
Yeah, the great question, you know, for maybe a little bit of historical background, you

175
00:12:45,440 --> 00:12:51,880
know, as you probably know, UAS have there pretty much an established history kind of coming

176
00:12:51,880 --> 00:12:53,400
from a military perspective.

177
00:12:53,400 --> 00:12:59,920
So a lot of the times you hear about stories of, you know, the military using these to conduct

178
00:12:59,920 --> 00:13:05,840
intelligence surveillance and reconnaissance or other types of operations, but nowadays

179
00:13:05,840 --> 00:13:11,280
the commercial and the civilian applications of these are really opening up here.

180
00:13:11,280 --> 00:13:16,360
So for example, one of the technical applications that I think is has a lot of promise here

181
00:13:16,360 --> 00:13:21,520
in the U.S. in the next several years here is this concept of precision agriculture.

182
00:13:21,520 --> 00:13:29,800
So the idea here is, can you use unmanned aerial systems to augment or help effectively

183
00:13:29,800 --> 00:13:31,800
agriculture and farming here?

184
00:13:31,800 --> 00:13:37,680
So for example, one of the projects we're working on right now is, you can maybe call it

185
00:13:37,680 --> 00:13:40,120
just an aerial mapping project here.

186
00:13:40,120 --> 00:13:43,880
That's kind of the large umbrella term that it falls under.

187
00:13:43,880 --> 00:13:47,600
It's a very popular one, maybe I'll preface that, you know, it seems like right now everybody

188
00:13:47,600 --> 00:13:52,800
and their dog wants to use an aircraft to try to provide some type of aerial map.

189
00:13:52,800 --> 00:13:57,320
So you know, we kind of wanted to jump on that bandwagon a little bit as well and we've

190
00:13:57,320 --> 00:14:03,080
done a couple of projects where yeah, we would like to use a aircraft or some kind of imaging

191
00:14:03,080 --> 00:14:08,440
system to gather large data sets here over a farm here.

192
00:14:08,440 --> 00:14:11,800
And the data that you gather is very interesting.

193
00:14:11,800 --> 00:14:17,120
You could do something simple like using a normal electro-optical camera to get your, you

194
00:14:17,120 --> 00:14:23,880
know, red-green blue channels of what does a farm look like from the visual, you know, optical

195
00:14:23,880 --> 00:14:26,200
range of sensors.

196
00:14:26,200 --> 00:14:31,160
And provide that information to a farmer, that's maybe the first layer here is, you know,

197
00:14:31,160 --> 00:14:36,580
you would have to take all of these images and stitch them together here to generate

198
00:14:36,580 --> 00:14:40,680
a high resolution orthomozic of some kind of area.

199
00:14:40,680 --> 00:14:45,440
And then, you know, maybe taking that one step further, there are other applications where

200
00:14:45,440 --> 00:14:50,160
you can put on different types of sensors like a multispectral imager that might be able

201
00:14:50,160 --> 00:14:56,120
to get you some of maybe the red edge or the near IR bands of radiation on that same

202
00:14:56,120 --> 00:14:57,120
area.

203
00:14:57,120 --> 00:15:02,600
And what you can actually do with that is people have been looking at things like a normalized

204
00:15:02,600 --> 00:15:06,200
difference vegetation index or an NDVI image.

205
00:15:06,200 --> 00:15:10,760
What this is is it's basically a plant health map.

206
00:15:10,760 --> 00:15:14,560
So what it will do is not just show you what does the farm look like from the air, but

207
00:15:14,560 --> 00:15:19,920
it can show you in this other, another perspective of that same farm.

208
00:15:19,920 --> 00:15:25,440
You can kind of get an idea of which plants are vigorous or healthy and maybe which areas

209
00:15:25,440 --> 00:15:29,000
of the farm are, could use a little bit more attention.

210
00:15:29,000 --> 00:15:35,160
So that's, that's obviously has a lot of potential applications to helping agronomists and

211
00:15:35,160 --> 00:15:40,280
farmers learn a little bit more about their crops and their products.

212
00:15:40,280 --> 00:15:48,000
So when I think about that application area, there are, and try to decompose it into different

213
00:15:48,000 --> 00:15:55,200
problems that one might apply machine learning in AI to, you know, there are certainly the,

214
00:15:55,200 --> 00:16:02,040
you talked a little bit about the sensors and, you know, there may be some ML and like

215
00:16:02,040 --> 00:16:06,040
stitching together, you know, creating these ortho mosaics and doing it.

216
00:16:06,040 --> 00:16:08,600
And I know there's, I forget the term.

217
00:16:08,600 --> 00:16:14,080
It's like, you know, essentially rectification, like correcting for earth curvature and

218
00:16:14,080 --> 00:16:21,480
other anomalies, maybe removing cloud cover or things like that across the, the, you

219
00:16:21,480 --> 00:16:31,480
know, different things aside from the sensor load and the various things related to, you

220
00:16:31,480 --> 00:16:32,960
know, the center data.

221
00:16:32,960 --> 00:16:37,840
And I guess the other big one is obviously the processing of the data and applying it

222
00:16:37,840 --> 00:16:44,880
to the use case like what do these images tell us about the health of the underlying agricultural

223
00:16:44,880 --> 00:16:45,880
system?

224
00:16:45,880 --> 00:16:52,880
It's strange that the, you know, in some ways, like the autonomous flight aspect of this,

225
00:16:52,880 --> 00:16:55,720
you know, might even, might be one of the easiest problems, right?

226
00:16:55,720 --> 00:17:03,280
At least if you separate out the collision avoidance thing, like, you know, even consumer

227
00:17:03,280 --> 00:17:11,000
drones, you could do, you could kind of lay out like a waypoint, a GPS waypoint grid,

228
00:17:11,000 --> 00:17:15,840
and just have the, the UAS follow that waypoint grid.

229
00:17:15,840 --> 00:17:20,920
And I guess this is really all a setup for like, what are all of the things that, you

230
00:17:20,920 --> 00:17:25,080
know, someone like me who's distant from this doesn't even think about that make it way

231
00:17:25,080 --> 00:17:29,880
more, you know, nuanced and complex than one might think.

232
00:17:29,880 --> 00:17:34,520
No, you bring up a lot of really good points there Sam. And in fact, I kind of wanted to

233
00:17:34,520 --> 00:17:40,440
dig in a little bit more on that last statement you made where, you know, the path, the flight

234
00:17:40,440 --> 00:17:45,040
planning and the actual execution of saying autonomous flight, you're right, that is kind

235
00:17:45,040 --> 00:17:46,040
of the boring part.

236
00:17:46,040 --> 00:17:48,840
That's a, that's kind of a solved problem at this point.

237
00:17:48,840 --> 00:17:53,520
It's a fairly mature technology, you know, just automating an aircraft to do some kind

238
00:17:53,520 --> 00:17:54,520
of emission.

239
00:17:54,520 --> 00:17:58,080
Right now, you know, we've got undergraduates in our lab right now, they go out and they

240
00:17:58,080 --> 00:18:04,240
buy a $200 little avionics platform, which is this open source hardware and software

241
00:18:04,240 --> 00:18:05,240
package.

242
00:18:05,240 --> 00:18:09,520
And you can integrate that onto a pretty much vanilla radio controlled aircraft.

243
00:18:09,520 --> 00:18:14,560
And you have yourself a quote unquote drone right now that you can tell it where you

244
00:18:14,560 --> 00:18:15,560
want it to fly.

245
00:18:15,560 --> 00:18:18,240
You can tell it how high you can tell it when to land.

246
00:18:18,240 --> 00:18:20,720
All of that is, is great here, right?

247
00:18:20,720 --> 00:18:21,720
And autonomy.

248
00:18:21,720 --> 00:18:22,720
Oh, sorry.

249
00:18:22,720 --> 00:18:26,240
You have to know, happen to know the name of that package, I'm sure folks might want

250
00:18:26,240 --> 00:18:27,240
to check it out.

251
00:18:27,240 --> 00:18:28,240
Oh, yeah.

252
00:18:28,240 --> 00:18:29,240
Absolutely.

253
00:18:29,240 --> 00:18:33,480
I mean, there's, there's a bunch of different ones you can find right now, but I think probably

254
00:18:33,480 --> 00:18:40,480
the, the most popular package at least for the introductory level of getting into UAS

255
00:18:40,480 --> 00:18:41,480
here.

256
00:18:41,480 --> 00:18:43,200
It's a system called a Pixhawk.

257
00:18:43,200 --> 00:18:44,200
Okay.

258
00:18:44,200 --> 00:18:49,240
And it's basically an Arduino based system here where you would load on the open source

259
00:18:49,240 --> 00:18:54,560
firmware packages called the, it's the Ardu pilot family of software.

260
00:18:54,560 --> 00:19:00,400
And that can do things from flying a plane or flying a multirotor or doing a ground robot.

261
00:19:00,400 --> 00:19:02,160
So it's really a lot of fun.

262
00:19:02,160 --> 00:19:07,440
It's sort of the, yeah, the Arduino package for doing unmanned systems here, building your

263
00:19:07,440 --> 00:19:09,160
own unmanned vehicle.

264
00:19:09,160 --> 00:19:13,920
It's a pretty easy way to get introduced to these systems.

265
00:19:13,920 --> 00:19:18,240
But you know, like we were talking about earlier, that's, that's sort of the easy part of

266
00:19:18,240 --> 00:19:19,240
this, right?

267
00:19:19,240 --> 00:19:21,560
It's, that's the solve portion of the problem here.

268
00:19:21,560 --> 00:19:27,880
So nowadays, unmanned aircraft and UAS, they're, they're really a means to an end, right?

269
00:19:27,880 --> 00:19:33,480
All you're trying to do in a lot of the, the research topics now is carry a, some sort

270
00:19:33,480 --> 00:19:34,480
of sensor, right?

271
00:19:34,480 --> 00:19:39,080
All you need here is that unmanned aircraft to take sensor somewhere that you want and take

272
00:19:39,080 --> 00:19:44,720
the data that you want and then doing something with that data or extracting the relevant information.

273
00:19:44,720 --> 00:19:47,360
That's where a lot of the research is right now.

274
00:19:47,360 --> 00:19:50,840
And that's maybe where some of the, you know, the machine learning and the AI that, you

275
00:19:50,840 --> 00:19:55,280
know, I'm sure you're very familiar with comes into play here for doing things like you're,

276
00:19:55,280 --> 00:19:58,240
you're mentioning the, the stitching of the photos together here.

277
00:19:58,240 --> 00:20:03,080
So in that sense, you know, I don't think we're necessarily a cutting edge developer

278
00:20:03,080 --> 00:20:04,080
of AI.

279
00:20:04,080 --> 00:20:09,080
We more use a couple of packages that will do the structure from motion and the photogrammetry

280
00:20:09,080 --> 00:20:12,680
and matching all the key points up together and stitching it together.

281
00:20:12,680 --> 00:20:16,560
That's, that's something that you can almost purchase off the shelf right now.

282
00:20:16,560 --> 00:20:21,120
And extracting the information like you mentioned and, and doing something with that information

283
00:20:21,120 --> 00:20:25,720
and having some kind of policy that you can act upon based on what you perceive.

284
00:20:25,720 --> 00:20:28,160
That's where it's a, a little bit more interesting right now.

285
00:20:28,160 --> 00:20:32,240
And I think that's probably a little bit more where, where some of the, the strategic

286
00:20:32,240 --> 00:20:34,240
level of research is going on right now.

287
00:20:34,240 --> 00:20:35,240
Okay.

288
00:20:35,240 --> 00:20:43,840
And is that how, you know, with a, a research group focused on unmanned aerial systems?

289
00:20:43,840 --> 00:20:48,600
Do you, does your group get involved in, in kind of that level of the discussion or is

290
00:20:48,600 --> 00:20:55,640
it primarily the, you know, kind of the infrastructure for autonomy?

291
00:20:55,640 --> 00:20:57,280
Can you expand a little bit on that?

292
00:20:57,280 --> 00:20:59,120
What, what do you mean?

293
00:20:59,120 --> 00:21:03,880
I think I know the answer to this based on the example that you gave, but the, you know,

294
00:21:03,880 --> 00:21:08,960
getting down to the application of, you know, say in precision agriculture like it,

295
00:21:08,960 --> 00:21:16,360
is your research and your, your group's research interests going down to the application

296
00:21:16,360 --> 00:21:24,240
itself and some of the, those areas or is it more on the, you know, the platform and

297
00:21:24,240 --> 00:21:29,440
the autonomous flight, some of this, you know, given that the, you know, that there's

298
00:21:29,440 --> 00:21:34,240
a base level of capability that's well established and commoditized.

299
00:21:34,240 --> 00:21:40,440
There are also, I imagine, you know, kind of various, there's a frontier there somewhere

300
00:21:40,440 --> 00:21:48,360
that might be, you know, object to void ends or it might be, you know, maybe it's, you

301
00:21:48,360 --> 00:21:53,360
know, incorporating variability like, how do you update your, your mapping grid with,

302
00:21:53,360 --> 00:21:59,520
you know, with, if it's very windy or something like that and, you know, or, I saw on your

303
00:21:59,520 --> 00:22:04,200
website, you talk about like, swarming behaviors and things like that, do you tend to focus

304
00:22:04,200 --> 00:22:09,880
out at that, you know, these kind of infrastructural or platform kinds of things or, you know,

305
00:22:09,880 --> 00:22:15,200
as your group in particular, also kind of, you know, focusing on these application level

306
00:22:15,200 --> 00:22:16,200
questions.

307
00:22:16,200 --> 00:22:18,520
Yeah, I think I see what you're saying.

308
00:22:18,520 --> 00:22:22,520
And my answer might not be the most satisfying here.

309
00:22:22,520 --> 00:22:27,880
You know, our group, I don't want to say tends to be scattered here, but we do have multiple

310
00:22:27,880 --> 00:22:34,160
different projects looking at kind of different aspects of, of autonomy in general here.

311
00:22:34,160 --> 00:22:39,360
And I will preface all of this by a lot of it is driven by the student initiative here.

312
00:22:39,360 --> 00:22:43,520
So if some students have a project that they're very interested in, we do as much as we

313
00:22:43,520 --> 00:22:47,520
possibly can to support that and enable that type of research.

314
00:22:47,520 --> 00:22:53,720
So that might be one of the reasons why we, we do look at a kind of a wider spectrum,

315
00:22:53,720 --> 00:23:00,320
almost, almost a breadth for a search rather than a depth for search in some of these topics

316
00:23:00,320 --> 00:23:01,320
here.

317
00:23:01,320 --> 00:23:04,240
So we are very interested in some of the applications here.

318
00:23:04,240 --> 00:23:08,480
So going back to that precision agriculture discussion that we talked about, I think

319
00:23:08,480 --> 00:23:12,760
you put it exactly right when you said that some of these components are commoditized

320
00:23:12,760 --> 00:23:14,880
and readily available.

321
00:23:14,880 --> 00:23:20,760
So a lot of the workflow that we mentioned earlier about planning a flight plan, generating

322
00:23:20,760 --> 00:23:26,240
the, or obtaining all these pictures, stitching them together, that is also fairly mature.

323
00:23:26,240 --> 00:23:28,640
You can buy a lot of packages to do that.

324
00:23:28,640 --> 00:23:32,600
Now the question would be, what do you do with that information when you have it back?

325
00:23:32,600 --> 00:23:38,160
So that's where I think some of the, the frontier that you mentioned is happening right now.

326
00:23:38,160 --> 00:23:43,440
So it's, it's one thing to be able to tell a farmer, here's what your farm looks like

327
00:23:43,440 --> 00:23:46,800
from a NDBI or from a health perspective.

328
00:23:46,800 --> 00:23:48,520
What do you now do with that information?

329
00:23:48,520 --> 00:23:53,880
So one of the things that we've looked at in the past is what's been done historically?

330
00:23:53,880 --> 00:23:57,160
Well, what do farmers do if they have a problem in their farm?

331
00:23:57,160 --> 00:23:59,640
Well, they'll go higher, say a crop duster, right?

332
00:23:59,640 --> 00:24:05,200
And I'm sure you've seen crop dusting aircraft before, there are these biplanes or, you

333
00:24:05,200 --> 00:24:11,640
know, low wing aircraft, which have 500 gallons of effectively toxic chemicals, right?

334
00:24:11,640 --> 00:24:16,240
And then they would go carpet bomb the entire farm to make sure they got an even application

335
00:24:16,240 --> 00:24:18,160
of this everywhere, right?

336
00:24:18,160 --> 00:24:20,720
So that's one way to approach a problem, right?

337
00:24:20,720 --> 00:24:25,720
But if you had more information like say you were able to send out a, a surveying drone

338
00:24:25,720 --> 00:24:30,080
or a multiple surveying drones to get this information about where on your farm actually

339
00:24:30,080 --> 00:24:34,520
needs this, well, then you might be able to do a more surgical application of some of

340
00:24:34,520 --> 00:24:37,240
this pesticides, herbicides, what have you.

341
00:24:37,240 --> 00:24:42,240
So we've actually in the past, we've developed a automatic crop dusting aircraft here.

342
00:24:42,240 --> 00:24:48,080
So it's a small, you know, about six foot wingspan aircraft, which has about a liter of

343
00:24:48,080 --> 00:24:49,840
aerosolized payload.

344
00:24:49,840 --> 00:24:54,480
So some students were looking at would you be able to use this in conjunction with some

345
00:24:54,480 --> 00:25:00,360
of this data that you get from the mapping side of things to now touch up areas of your

346
00:25:00,360 --> 00:25:06,960
farm instead of using a carpet bomb, you know, policy, could you use one or more of these

347
00:25:06,960 --> 00:25:12,480
aircraft to deploy and just hit the areas that you need to in your farm?

348
00:25:12,480 --> 00:25:18,240
So that's maybe one of the application levels, but we also look at some of these, these,

349
00:25:18,240 --> 00:25:22,720
the regulatory and more of the larger platform issues because, you know, as we just talked

350
00:25:22,720 --> 00:25:26,920
about there, it's, you, you have to build some platform, you know, the off, you usually

351
00:25:26,920 --> 00:25:31,840
have to do some hardware to enable some of this, these ideas that you want to do.

352
00:25:31,840 --> 00:25:36,680
So that's one thing I think that makes our group a little bit unique here is that we

353
00:25:36,680 --> 00:25:42,080
do have a lot of people that are very interested in spending time, getting their hands dirty,

354
00:25:42,080 --> 00:25:47,080
building some specialized hardware, conducting flight tests, things like that, rather than

355
00:25:47,080 --> 00:25:51,120
just doing the simulation in the lab and making sure that it works.

356
00:25:51,120 --> 00:25:53,120
We actually want to go out and fly it.

357
00:25:53,120 --> 00:25:54,120
Hmm.

358
00:25:54,120 --> 00:26:01,120
The precision crop dusting application sounds really difficult, like I'm wondering, can

359
00:26:01,120 --> 00:26:09,400
you, can you share the, the specific results of the research, like when I think about the

360
00:26:09,400 --> 00:26:15,960
issues that go into that in particular that on the, you know, chemical delivery side,

361
00:26:15,960 --> 00:26:24,200
we've got this, you know, this, you know, targeted aerosol that you're trying to deliver.

362
00:26:24,200 --> 00:26:28,440
It sounds, yeah, I'm imagining that you'd have to fly pretty low in order to deliver it.

363
00:26:28,440 --> 00:26:32,960
And then you have all the turbulence and air effects off of your vehicle that's going

364
00:26:32,960 --> 00:26:34,440
to scatter your aerosol.

365
00:26:34,440 --> 00:26:36,800
Like, how does that even work?

366
00:26:36,800 --> 00:26:40,440
Or how well did it work?

367
00:26:40,440 --> 00:26:46,440
You, again, have a real knack for asking the exact questions that I think need to be

368
00:26:46,440 --> 00:26:47,680
asked here.

369
00:26:47,680 --> 00:26:51,600
So there are a lot of challenges associated with it.

370
00:26:51,600 --> 00:26:57,440
So one of them that you mentioned right away here is the fact that you need to be fairly

371
00:26:57,440 --> 00:27:01,160
low to have an effective dispersal of these systems here.

372
00:27:01,160 --> 00:27:07,760
So some of the students did have to look into some technologies like automatic terrain avoidance

373
00:27:07,760 --> 00:27:12,640
here, so you need to be able to maintain a very specific altitude above the ground level.

374
00:27:12,640 --> 00:27:15,520
We didn't get a chance to actually test that too extensively.

375
00:27:15,520 --> 00:27:20,240
We went out and the farm we flew this at luckily was fairly completely flat.

376
00:27:20,240 --> 00:27:23,880
And they actually had just mowed all the grass the day before.

377
00:27:23,880 --> 00:27:31,520
So it was, it worked in, but again, I don't think we stressed the system very much there.

378
00:27:31,520 --> 00:27:35,920
The other thing that was very difficult with this project and it maybe segues into some

379
00:27:35,920 --> 00:27:39,640
of the other research we've done here is if you think about it, when you have this farm

380
00:27:39,640 --> 00:27:46,640
where certain spots on your farm might have the need for application of the pesticide or

381
00:27:46,640 --> 00:27:51,160
the payload and others don't, you basically wind up with the large traveling salesman

382
00:27:51,160 --> 00:27:52,160
problem, right?

383
00:27:52,160 --> 00:27:56,360
You've got this spatial grid here, but then you have only certain locations you need to

384
00:27:56,360 --> 00:27:57,360
visit.

385
00:27:57,360 --> 00:28:01,760
And then you only have one vehicle with a certain amount of payload that has certain constraints.

386
00:28:01,760 --> 00:28:05,200
So effectively it turns into a traveling salesman problem.

387
00:28:05,200 --> 00:28:08,800
And then if you want to scale this up, you know, we were talking about the vehicle only

388
00:28:08,800 --> 00:28:10,480
has about a liter of payload.

389
00:28:10,480 --> 00:28:15,080
Well, I don't think a farmer wants to be out there all day, you know, shooting one liter

390
00:28:15,080 --> 00:28:19,480
of payload, having it land, refill it, exactly going back out again.

391
00:28:19,480 --> 00:28:26,080
So maybe scaling this up to a swarm of vehicles where you could have multiple of these aircraft

392
00:28:26,080 --> 00:28:29,840
going out and doing this might cut down on the amount of time necessary to do this.

393
00:28:29,840 --> 00:28:35,560
But now instead of a one dimensional traveling salesman person, you have like an agents that

394
00:28:35,560 --> 00:28:38,520
you want to do traveling salesman with effectively.

395
00:28:38,520 --> 00:28:41,480
And that's, that's can be kind of challenging.

396
00:28:41,480 --> 00:28:47,320
So some other projects in the past that our groups look that have been maybe trying to tackle

397
00:28:47,320 --> 00:28:53,160
some of these problems using evolutionary computation and algorithms, I believe you had a guest

398
00:28:53,160 --> 00:28:58,280
in the past from maybe from UT Austin talking a little bit about this, maybe from the financial

399
00:28:58,280 --> 00:29:02,880
website of things, but that was restore make a line in OK, right, right, right.

400
00:29:02,880 --> 00:29:06,800
I remember hearing one of them, that was a really good podcast.

401
00:29:06,800 --> 00:29:10,200
And I kept trying to think about what were some of the parallels to maybe some of the

402
00:29:10,200 --> 00:29:15,040
evolutionary, evolutionary algorithms that we would apply here for unmanned aircraft.

403
00:29:15,040 --> 00:29:18,600
And this is a, this is one of the places where it would work here.

404
00:29:18,600 --> 00:29:23,400
You know, you mentioned you have multiple aircraft or multiple agents and then you have environmental

405
00:29:23,400 --> 00:29:24,400
problems.

406
00:29:24,400 --> 00:29:27,600
I think earlier we were talking a little bit about what if you have wind, what if you

407
00:29:27,600 --> 00:29:34,080
have turbulence, if your environment is complicated, it's, it gets a little bit interesting.

408
00:29:34,080 --> 00:29:41,160
So one approach that I think has gained has yielded some reasonable results here is trying

409
00:29:41,160 --> 00:29:47,040
to do the path and the task planning using evolutionary computation rather than say traditional

410
00:29:47,040 --> 00:29:48,360
optimization techniques.

411
00:29:48,360 --> 00:29:49,360
OK.

412
00:29:49,360 --> 00:29:56,960
You mentioned swarms of vehicles, you know, this is also something that's been researched

413
00:29:56,960 --> 00:30:02,160
at least theoretically, I don't, I think we're a lot closer to application now with, you

414
00:30:02,160 --> 00:30:07,960
know, these small inexpensive vehicles than previously, but I, you know, I think some

415
00:30:07,960 --> 00:30:15,760
of this stuff goes back to the 70s, even maybe or what, what kind of things that you looked

416
00:30:15,760 --> 00:30:21,960
at or what had the research results been of the year, different forays and to this,

417
00:30:21,960 --> 00:30:26,000
like for the precision agriculture, like how far did you get with that?

418
00:30:26,000 --> 00:30:29,680
And, you know, what were, how did you formulate the problems?

419
00:30:29,680 --> 00:30:34,720
Well, you know, I definitely don't want to claim to be an expert in this arena by, by

420
00:30:34,720 --> 00:30:38,240
any means, but I mean, I'm happy to talk about some of the things that we've, we've done

421
00:30:38,240 --> 00:30:45,680
in the past, maybe going back to that evolutionary computation example, that was a project which

422
00:30:45,680 --> 00:30:50,520
had multiple vehicles involved in it and, and maybe you could call it a swarm.

423
00:30:50,520 --> 00:30:54,600
I guess the terminology swarm seems to have different contexts and different meetings

424
00:30:54,600 --> 00:30:58,320
depending on who you're talking about here, but from our perspective, maybe we would

425
00:30:58,320 --> 00:31:04,440
think about this as just multiple vehicles, trying to achieve some kind of common goal.

426
00:31:04,440 --> 00:31:10,560
So in the past, we've done things like searching with multiple vehicles.

427
00:31:10,560 --> 00:31:16,800
So we have a cooperative group of vehicles or in your team and you need to spread out

428
00:31:16,800 --> 00:31:22,320
and search a potentially spatially complex environment here, which might have obstacles

429
00:31:22,320 --> 00:31:27,200
from which might have danger zones or might have regions that you don't want to be in.

430
00:31:27,200 --> 00:31:32,800
So we looked at trying to apply multiple vehicles in these scenarios here rather than just

431
00:31:32,800 --> 00:31:39,560
a single vehicle and, you know, searching with multiple vehicles is by no means a new topic.

432
00:31:39,560 --> 00:31:42,880
As you mentioned, this has probably been from the 70s or earlier.

433
00:31:42,880 --> 00:31:49,680
I think a lot of the early work with, I believe Alberto Elves did a lot of work in occupancy

434
00:31:49,680 --> 00:31:53,640
grids and occupancy based maps back in the 80s here.

435
00:31:53,640 --> 00:31:58,480
And we sort of tried to extend some of that work here to using multiple aircraft to search

436
00:31:58,480 --> 00:32:00,680
an area cooperatively.

437
00:32:00,680 --> 00:32:06,280
So that might be one aspect where you might consider this to be a swarm application, although

438
00:32:06,280 --> 00:32:11,840
in that sense, the vehicles, they were not actually tightly coupled together.

439
00:32:11,840 --> 00:32:17,760
They were more cooperatively interacting with one another.

440
00:32:17,760 --> 00:32:20,760
So that was one application, I guess, where you have multiple vehicles.

441
00:32:20,760 --> 00:32:25,680
We've done other projects here where you tried to have a more rigidly structured swarm.

442
00:32:25,680 --> 00:32:30,920
So we did some work with Boeing a little while ago where we wanted to have a dynamically

443
00:32:30,920 --> 00:32:33,320
reconfigurable formation.

444
00:32:33,320 --> 00:32:38,600
So the idea would be you have a formation of vehicles either in a line or a diamond

445
00:32:38,600 --> 00:32:41,120
or some kind of configuration here.

446
00:32:41,120 --> 00:32:43,880
And for the most part, that's usually fine and dandy.

447
00:32:43,880 --> 00:32:48,520
You can go flying around in the atmosphere with this formation and maintain its structure

448
00:32:48,520 --> 00:32:49,520
no problem.

449
00:32:49,520 --> 00:32:56,360
But you've got people now talking about trying to do urban navigation like in cities.

450
00:32:56,360 --> 00:33:00,920
And you can imagine now you've got constraints, you've got obstacles.

451
00:33:00,920 --> 00:33:07,800
So this swarm needs to be able to reconfigure itself and adapt to moving around these obstacles

452
00:33:07,800 --> 00:33:14,080
or maybe going through choke points like trying to get through a window or a narrow intersection.

453
00:33:14,080 --> 00:33:20,600
So we looked at some of that work there with multiple vehicles and swarms here.

454
00:33:20,600 --> 00:33:25,920
When you're looking at these multi-vehicle problems, whether it's this formation flying

455
00:33:25,920 --> 00:33:36,040
problem or formation missions or the group search, what are some of the approaches or algorithms

456
00:33:36,040 --> 00:33:38,320
that come in the play?

457
00:33:38,320 --> 00:33:45,280
Yeah, that's a good one because right now it seems like a lot of the research is focused

458
00:33:45,280 --> 00:33:51,960
on sort of decentralized algorithms which are able to scale well.

459
00:33:51,960 --> 00:33:58,360
So the idea there would be you try to communicate with your nearest neighbors or using some type

460
00:33:58,360 --> 00:34:03,200
of graph topology to determine communication and how these vehicles interact.

461
00:34:03,200 --> 00:34:07,960
And I think one of the reasons that gained a lot of traction here is because it's somewhat

462
00:34:07,960 --> 00:34:09,200
scalable here, right?

463
00:34:09,200 --> 00:34:14,520
If you have a somewhat decentralized algorithm where you don't need information from everybody

464
00:34:14,520 --> 00:34:19,040
else in your team, you only need information from certain vehicles.

465
00:34:19,040 --> 00:34:24,400
That tends to be a little bit more scalable than say a centralized or some all-to-all communication

466
00:34:24,400 --> 00:34:30,440
topology where the communications costs and the scaling costs just exponentially increase

467
00:34:30,440 --> 00:34:31,640
with a number of vehicles.

468
00:34:31,640 --> 00:34:38,560
So if you want to do a large number of these, a decentralized approach might have a lot

469
00:34:38,560 --> 00:34:42,840
of interesting advantages here.

470
00:34:42,840 --> 00:34:48,040
That being said, some of the things that we've looked at particularly in the past here has

471
00:34:48,040 --> 00:34:52,840
actually been a little bit more heuristic or a little bit more rules-based.

472
00:34:52,840 --> 00:34:58,760
I think it's really great to be able to talk about scaling this to 50, 100, 200 vehicles,

473
00:34:58,760 --> 00:35:05,880
but in reality, the state of the technology is at such a level here that I think you'd

474
00:35:05,880 --> 00:35:10,760
be lucky if you can get five vehicles cooperating together simultaneously.

475
00:35:10,760 --> 00:35:19,840
So right now, we've personally been focusing a little bit more on the rule-based or the

476
00:35:19,840 --> 00:35:25,640
heuristics or the centralized type of algorithm to coordinate multiple vehicles.

477
00:35:25,640 --> 00:35:32,000
So that search work that we talked about earlier, it was basically you have this star topology

478
00:35:32,000 --> 00:35:36,160
where everybody communicates with a centralized coordinator.

479
00:35:36,160 --> 00:35:40,600
Not every single agent needs to talk to every other agent, but every agent needs to be connected

480
00:35:40,600 --> 00:35:48,040
to a centralized coordinator to allow each vehicle to compute what it thinks is the optimal

481
00:35:48,040 --> 00:35:50,120
path for it to take next.

482
00:35:50,120 --> 00:35:56,440
But that is the calculation of the optimal path to take next is done by the vehicle itself

483
00:35:56,440 --> 00:36:01,480
as opposed to the coordinator centrally determining that and just giving the vehicle a

484
00:36:01,480 --> 00:36:02,480
flight path.

485
00:36:02,480 --> 00:36:03,480
Correct.

486
00:36:03,480 --> 00:36:04,480
Correct.

487
00:36:04,480 --> 00:36:08,240
So the vehicles would be able to make their own decisions here, although it does rely

488
00:36:08,240 --> 00:36:12,520
on information or inputs from the centralized coordinator.

489
00:36:12,520 --> 00:36:14,800
And the coordinator rule can change.

490
00:36:14,800 --> 00:36:17,040
It doesn't necessarily need to be a ground station.

491
00:36:17,040 --> 00:36:21,840
It could be one of the vehicles, but as long as you have a central agent or some kind

492
00:36:21,840 --> 00:36:26,160
of clearinghouse that would have some information that all the other vehicles need, that's what

493
00:36:26,160 --> 00:36:30,880
we were using to make some of these systems like the searching or the evolutionary path

494
00:36:30,880 --> 00:36:32,080
planning work.

495
00:36:32,080 --> 00:36:36,960
And is that central coordinator or the central information?

496
00:36:36,960 --> 00:36:43,600
Is that just state or is there also, are there any elements that need to be centrally

497
00:36:43,600 --> 00:36:44,600
computed?

498
00:36:44,600 --> 00:36:47,240
I guess it would depend on the application.

499
00:36:47,240 --> 00:36:52,120
So for example, like the searching application where we had this environment and you wanted

500
00:36:52,120 --> 00:36:58,080
to send out a swarm of vehicles to find some kind of target, like a lost hiker or a boat,

501
00:36:58,080 --> 00:37:03,440
something like that, the information that the coordinator maintained would be a map

502
00:37:03,440 --> 00:37:04,760
or the state of the world.

503
00:37:04,760 --> 00:37:05,760
So you're right.

504
00:37:05,760 --> 00:37:09,920
In some sense, it would have some state here that the vehicles could that have access

505
00:37:09,920 --> 00:37:15,880
to to make their own independent decisions on what to do next here.

506
00:37:15,880 --> 00:37:20,480
In the case of the evolutionary path planning here, the idea with that was, you know, you

507
00:37:20,480 --> 00:37:26,880
would have multiple vehicles trying to achieve some type of team-based goal here.

508
00:37:26,880 --> 00:37:34,040
And to do that, each vehicle needed to compute its own flight path to achieve something.

509
00:37:34,040 --> 00:37:39,920
And what the centralized coordinator did would be able to look at every vehicle, effectively

510
00:37:39,920 --> 00:37:42,040
made a bid on a task here.

511
00:37:42,040 --> 00:37:47,920
They would say based on my tactics, based on my capabilities, based on my constraints,

512
00:37:47,920 --> 00:37:52,680
in order for me to execute a certain task, I think it's going to cost me X amount of

513
00:37:52,680 --> 00:37:56,080
whatever the metric is, fuel, time, money.

514
00:37:56,080 --> 00:38:01,600
And then the coordinator would then be able to effectively act as like an option, an open

515
00:38:01,600 --> 00:38:03,080
market, like a free market.

516
00:38:03,080 --> 00:38:04,080
Right.

517
00:38:04,080 --> 00:38:07,040
Now, the coordinator would be able to pick and assign tasks to the vehicle that could

518
00:38:07,040 --> 00:38:13,520
do that for not necessarily the cheapest individually, but the cheapest for the entire

519
00:38:13,520 --> 00:38:14,520
team, right?

520
00:38:14,520 --> 00:38:18,720
So the coordinator would be able to assess and evaluate who needs to do what so that the

521
00:38:18,720 --> 00:38:22,520
overall team could achieve the mission.

522
00:38:22,520 --> 00:38:23,520
Mm-hmm.

523
00:38:23,520 --> 00:38:31,880
It strikes me that in that case, you run into potential like local optima type problems

524
00:38:31,880 --> 00:38:40,160
or, you know, the cost is potentially highly dependent on like the time horizon and the

525
00:38:40,160 --> 00:38:45,560
sequence of tasks that each of the vehicles takes on, did you look into that aspect of

526
00:38:45,560 --> 00:38:46,560
it?

527
00:38:46,560 --> 00:38:47,560
Yes.

528
00:38:47,560 --> 00:38:48,560
You're absolutely right.

529
00:38:48,560 --> 00:38:54,000
And I think, again, I by no means want to claim to be an expert or even well versed

530
00:38:54,000 --> 00:39:00,160
in this, but evolution of algorithms and any kind of optimization in some of this very

531
00:39:00,160 --> 00:39:04,960
complicated problems here are always probably subject to some type of local minima here

532
00:39:04,960 --> 00:39:11,560
that in for a complicated system can be very difficult to assess, you know, yeah, is this

533
00:39:11,560 --> 00:39:12,560
a local minima?

534
00:39:12,560 --> 00:39:13,560
Is this a global minima?

535
00:39:13,560 --> 00:39:17,160
How are we doing relative to what else options are out there?

536
00:39:17,160 --> 00:39:20,720
So you definitely could fall into that trap.

537
00:39:20,720 --> 00:39:27,240
One thing that made this system unique here is, you know, you mentioned this idea of given

538
00:39:27,240 --> 00:39:32,200
the amount of time that you have to compute or whatever your horizon was, one feature

539
00:39:32,200 --> 00:39:37,200
that we really wanted to bake into this evolutionary path planning system that was developed

540
00:39:37,200 --> 00:39:42,000
here was the concept of feasibility here over optimality.

541
00:39:42,000 --> 00:39:47,640
So you can probably imagine if you have aircraft flying around, it's great if you were able

542
00:39:47,640 --> 00:39:51,200
to have some sort of what you would call a optimal flight path.

543
00:39:51,200 --> 00:39:52,200
That's great.

544
00:39:52,200 --> 00:39:56,160
But if it takes you three hours to compute an optimal flight path, that might not be so

545
00:39:56,160 --> 00:39:59,280
great if you have actual aircraft in the air, right?

546
00:39:59,280 --> 00:40:00,280
Right.

547
00:40:00,280 --> 00:40:03,880
It's kind of like having the space shuttle and you want to reboot the computer here and

548
00:40:03,880 --> 00:40:05,480
have everyone hold their breath, right?

549
00:40:05,480 --> 00:40:07,520
You probably don't want to do that.

550
00:40:07,520 --> 00:40:12,880
So instead, feasibility is almost more important than optimality, right?

551
00:40:12,880 --> 00:40:16,400
Each of these vehicles need to be able to have a feasible flight path and at least something

552
00:40:16,400 --> 00:40:19,720
they can do and execute at any given moment.

553
00:40:19,720 --> 00:40:24,720
So what we wanted to do is make sure that the evolutionary algorithm only sort of considered

554
00:40:24,720 --> 00:40:28,160
feasible trajectories or solutions at any given point.

555
00:40:28,160 --> 00:40:34,440
So you might think of this as some type of interior point method from a larger optimization

556
00:40:34,440 --> 00:40:35,440
standpoint.

557
00:40:35,440 --> 00:40:39,120
But that I think was something that made that a little bit interesting and unique here

558
00:40:39,120 --> 00:40:44,120
because optimality wasn't as highly prized as feasibility.

559
00:40:44,120 --> 00:40:49,360
And I guess if you think about it long enough, optimality is by definition it's subjective,

560
00:40:49,360 --> 00:40:50,360
right?

561
00:40:50,360 --> 00:40:54,160
It's whatever cost function or utility function, you decide it to cook up and decide

562
00:40:54,160 --> 00:40:59,200
to apply to the scenario, who's to say there isn't a better optimality function or cost

563
00:40:59,200 --> 00:41:01,240
function somewhere else.

564
00:41:01,240 --> 00:41:06,920
So in a lot of these cases, your constraints actually are more important than what you

565
00:41:06,920 --> 00:41:10,600
have decided as this utility function to apply.

566
00:41:10,600 --> 00:41:17,920
Oh, that's a really interesting way of thinking about it and something that something that

567
00:41:17,920 --> 00:41:21,720
probably gets lost in a lot of the conversations about optimizations.

568
00:41:21,720 --> 00:41:27,320
Did you look at, though, the feasibility cost, I guess, for lack of a better term?

569
00:41:27,320 --> 00:41:34,400
Like did you compare that to the optimal for a given cost function and try to get a sense

570
00:41:34,400 --> 00:41:41,200
for, you know, what was the cost of operating under fixed resource or time constraints?

571
00:41:41,200 --> 00:41:44,920
Gosh, you've got me in a corner there here.

572
00:41:44,920 --> 00:41:49,880
I don't recall the specific details here, but I'm going to have to punt a little bit

573
00:41:49,880 --> 00:41:51,680
on that and say, I don't believe that.

574
00:41:51,680 --> 00:41:57,640
If we actually did a law, an in-depth sensitivity study on that front.

575
00:41:57,640 --> 00:41:58,640
Okay.

576
00:41:58,640 --> 00:41:59,640
Great.

577
00:41:59,640 --> 00:42:05,920
So, for folks that are interested in learning more about this type of research, are there

578
00:42:05,920 --> 00:42:11,040
any particular, you've mentioned a couple of different projects that you've worked on

579
00:42:11,040 --> 00:42:16,840
are there specific papers that they can go and track down to learn more about the way

580
00:42:16,840 --> 00:42:18,680
you approach that problem?

581
00:42:18,680 --> 00:42:26,120
Yeah, absolutely. We have a couple of papers on our lab website here.

582
00:42:26,120 --> 00:42:29,600
Again, most of them are compartmentalized by these different projects that we're working

583
00:42:29,600 --> 00:42:30,600
on.

584
00:42:30,600 --> 00:42:35,680
So, yeah, please, or let me know, I'm happy to share projects or papers with anyone that's

585
00:42:35,680 --> 00:42:36,680
interested.

586
00:42:36,680 --> 00:42:42,560
Yeah, we'll definitely include links to the ones that we talked about.

587
00:42:42,560 --> 00:42:50,560
Hopefully, you can help us pull together a list of those as well as the website as a

588
00:42:50,560 --> 00:42:56,840
whole for folks that want to learn more about the field in general.

589
00:42:56,840 --> 00:43:02,040
Do you have any starting places that you tend to point people to?

590
00:43:02,040 --> 00:43:05,280
That's a really good question here.

591
00:43:05,280 --> 00:43:09,480
I guess it's even hard to define the field, right?

592
00:43:09,480 --> 00:43:14,480
That's exactly what I'm trying to think about right now is like we've had a really good

593
00:43:14,480 --> 00:43:20,280
discussion here about, there's the technical field for sure, things like the detective

594
00:43:20,280 --> 00:43:25,880
avoid or the path planning or the information processing on the data you return from these

595
00:43:25,880 --> 00:43:27,120
aircraft.

596
00:43:27,120 --> 00:43:33,080
That's definitely one exciting area of the field, but the ones that we're seeing a lot

597
00:43:33,080 --> 00:43:38,040
come out right now are there's a lot of interesting flight test and practical application

598
00:43:38,040 --> 00:43:42,360
and people actually going out and conducting experiments and gathering data with this.

599
00:43:42,360 --> 00:43:49,200
It's almost a branch of, I guess, the more mature sort of field robotics area, right?

600
00:43:49,200 --> 00:43:54,760
The aircraft I think in the US are now starting to be able to catch up to some of the field

601
00:43:54,760 --> 00:43:59,640
robotics that people have been conducting with ground robots and elsewhere for a long

602
00:43:59,640 --> 00:44:00,640
time.

603
00:44:00,640 --> 00:44:08,680
There's a lot of exciting details about that, so there's a couple of companies that we've

604
00:44:08,680 --> 00:44:13,680
worked with in the past that are actually conducting a lot of flight tests.

605
00:44:13,680 --> 00:44:20,640
You know, people in the University of Washington, over at UC Boulder, UT, or Texas A&M, there's

606
00:44:20,640 --> 00:44:24,240
a lot of different groups that are doing this type of work, so it's hard for me to point

607
00:44:24,240 --> 00:44:29,720
to one exact, I guess, paper that would be helpful.

608
00:44:29,720 --> 00:44:34,240
So yeah, I apologize, I probably don't have a specific reference to look at.

609
00:44:34,240 --> 00:44:40,000
And maybe let me ask like this, if you were talking to someone who was early in their

610
00:44:40,000 --> 00:44:47,560
research career and they asked you, you know, what are some specific kind of interesting

611
00:44:47,560 --> 00:44:53,280
problems that would be a good place to start to dig into, how would you advise them?

612
00:44:53,280 --> 00:44:55,720
Yeah, that's another good one.

613
00:44:55,720 --> 00:45:00,560
I guess at this point, where things are really interesting, at least from our perspective

614
00:45:00,560 --> 00:45:04,640
here, is we're doing a little bit of work right now.

615
00:45:04,640 --> 00:45:08,640
We're seeing a lot of interest in this idea of risk assessment of UAS.

616
00:45:08,640 --> 00:45:15,640
So if you're not sure on exactly what part of UAS you're interested in, risk assessment

617
00:45:15,640 --> 00:45:19,280
is actually an interesting way to take a look at this, because what's happening right

618
00:45:19,280 --> 00:45:26,800
now is a lot of people in order to gain waivers or the ability to conduct their operations

619
00:45:26,800 --> 00:45:32,000
with the under FAA jurisdiction need to provide some type of risk assessment showing that

620
00:45:32,000 --> 00:45:35,040
their operation is safe.

621
00:45:35,040 --> 00:45:39,080
And by doing that, by conducting this risk assessment, you're forced to sort of take

622
00:45:39,080 --> 00:45:45,640
an overall look at not just a specific technology on board and aircraft, but the entire flight

623
00:45:45,640 --> 00:45:48,960
operation envelope and operation in general.

624
00:45:48,960 --> 00:45:54,240
So you actually have to look at the end-to-end mission using a UAS.

625
00:45:54,240 --> 00:45:58,200
So that's your checklist, that's your area of operations.

626
00:45:58,200 --> 00:46:01,600
Then the technical aspects would be that's your platform and what kind of avionics you're

627
00:46:01,600 --> 00:46:03,360
running, what kind of control algorithms.

628
00:46:03,360 --> 00:46:09,440
So if you're able to understand the risk associated with the given UAS, that's a really

629
00:46:09,440 --> 00:46:15,040
good way to try to get a bird's eye view of what are some of the challenges and issues

630
00:46:15,040 --> 00:46:20,120
associated with UAS and the research that's going on with them right now.

631
00:46:20,120 --> 00:46:28,760
So we talked earlier about a software platform like Argypilot for a system like Argypilot,

632
00:46:28,760 --> 00:46:33,640
how would you go about conducting a risk assessment on that part of it?

633
00:46:33,640 --> 00:46:39,360
Does that involve detailed code path reviews?

634
00:46:39,360 --> 00:46:46,640
And are you trying to get to a, how do you even characterize the risk associated with

635
00:46:46,640 --> 00:46:48,080
that part of a system?

636
00:46:48,080 --> 00:46:50,440
Yeah, that's an excellent question here.

637
00:46:50,440 --> 00:46:55,760
And I think there might even be some parallels and some ways we can look at self-driving cars

638
00:46:55,760 --> 00:46:58,120
here as well.

639
00:46:58,120 --> 00:47:01,280
The risk assessment, there's multiple ways you can look at this.

640
00:47:01,280 --> 00:47:05,720
One is exactly like you mentioned here, you can look at a detailed low-level implementation

641
00:47:05,720 --> 00:47:11,320
of trying to characterize each component here associated with an aircraft, look at meantime

642
00:47:11,320 --> 00:47:18,200
between failures, try to calculate or estimate or some otherwise get a handle on the reliability

643
00:47:18,200 --> 00:47:19,440
of a given component, right?

644
00:47:19,440 --> 00:47:22,400
And you do that for one component, then you do it for another component, you do it for

645
00:47:22,400 --> 00:47:23,400
another component.

646
00:47:23,400 --> 00:47:28,600
And you can kind of see this also becomes, while it's very detailed, it's difficult to

647
00:47:28,600 --> 00:47:33,960
do this and scale this because I don't know if you just go into Google Images, right?

648
00:47:33,960 --> 00:47:38,840
You type a drone or unmanned aerial system and you look at the Images page, drones come

649
00:47:38,840 --> 00:47:45,280
in all sorts of different size, shapes, taxonomies, avionics, there's just so many different ways

650
00:47:45,280 --> 00:47:49,040
that you can configure an unmanned system that is really not standardized and trying to do

651
00:47:49,040 --> 00:47:54,040
that for any given system, pretty much becomes fairly intractable quickly.

652
00:47:54,040 --> 00:47:59,680
So the other way you can sort of look at assessing risk of a given UAS operation or emission

653
00:47:59,680 --> 00:48:06,480
is at a more macro level here, you can look at things like, how often do I expect this

654
00:48:06,480 --> 00:48:12,840
to collide with another vehicle here and try to do a larger level risk analysis?

655
00:48:12,840 --> 00:48:18,240
I mean, in fact, this is really interesting, we published a lot of technical papers here

656
00:48:18,240 --> 00:48:26,040
looking at things like path planning here or mapping or GPS to 9 navigation or things

657
00:48:26,040 --> 00:48:32,640
like that, but our most popular publication is actually looking at a model to assess the

658
00:48:32,640 --> 00:48:38,800
risk of a given UAS mission on a large level like what we were talking about just now.

659
00:48:38,800 --> 00:48:46,040
Because if you think about this, UAS are a very interesting new paradigm in terms of aviation

660
00:48:46,040 --> 00:48:47,040
safety.

661
00:48:47,040 --> 00:48:52,400
So historically, right, there's three parties or three entities you have to care about

662
00:48:52,400 --> 00:48:56,360
if you're flying an aircraft, right, you have to make sure that the A, the people on board

663
00:48:56,360 --> 00:49:00,840
your own aircraft are safe, B, you have to make sure people on board other aircraft are

664
00:49:00,840 --> 00:49:05,480
safe, and then C, you have to make sure that people on the ground, like these bystanders

665
00:49:05,480 --> 00:49:08,120
or pedestrians, that they're safe.

666
00:49:08,120 --> 00:49:13,080
And this is kind of very similar to self-driving car, right, self-driving car.

667
00:49:13,080 --> 00:49:14,080
It's the same thing.

668
00:49:14,080 --> 00:49:17,120
You've got to make sure that the person in the car is safe, people in other cars are safe,

669
00:49:17,120 --> 00:49:18,760
and pedestrians are safe.

670
00:49:18,760 --> 00:49:23,920
Now the unmanned aircraft, though, brings a interesting twist on this topic here, right,

671
00:49:23,920 --> 00:49:28,960
because historically, if you just make sure that your own people on board your own aircraft

672
00:49:28,960 --> 00:49:34,480
are safe, the other two categories follow directly, right, if my aircraft is safe, I probably

673
00:49:34,480 --> 00:49:37,400
won't hit other aircraft and I probably won't hit people on the ground here.

674
00:49:37,400 --> 00:49:43,800
So the implication of that is your aircraft needs to be extremely reliable and robust

675
00:49:43,800 --> 00:49:49,680
and safe, right, the airframe itself needs to be reliable, because if you ensure that,

676
00:49:49,680 --> 00:49:52,440
you ensure the other two parties are safe as well.

677
00:49:52,440 --> 00:49:56,040
And that's the exact same for a self-driving car, right, so I've heard of many of your guests

678
00:49:56,040 --> 00:50:01,080
previously talk about safety is important for self-driving cars, that really means, again,

679
00:50:01,080 --> 00:50:06,600
making sure that the vehicle itself, the self-driving car is safe and therefore won't

680
00:50:06,600 --> 00:50:08,240
endanger anyone else.

681
00:50:08,240 --> 00:50:13,200
Now with the aircraft, though, if you take out the person on board the first group, right,

682
00:50:13,200 --> 00:50:17,720
if you take off the people on board the aircraft, now you just have to worry about those other

683
00:50:17,720 --> 00:50:18,720
two categories.

684
00:50:18,720 --> 00:50:21,840
That's people and other aircraft and people on the ground.

685
00:50:21,840 --> 00:50:29,200
What that kind of does to you here is it means you can actually sort of have a semi-unreliable

686
00:50:29,200 --> 00:50:33,840
aircraft, as long as you make sure that it doesn't hit other aircraft and it doesn't

687
00:50:33,840 --> 00:50:39,200
hit other pedestrians on the ground here, right, so that's why I think you've seen a lot

688
00:50:39,200 --> 00:50:44,640
of these unmanned aircraft nowadays, they're not, they're nowhere near the level of reliability

689
00:50:44,640 --> 00:50:46,720
of a manned aircraft, right?

690
00:50:46,720 --> 00:50:53,840
Meantime between failures are fairly often, actually, you know, you have these lipopower,

691
00:50:53,840 --> 00:50:58,400
these battery powered, effectively souped up hobby aircraft, going out and doing these

692
00:50:58,400 --> 00:51:03,560
types of missions here and as long as you conduct them in, you know, like a remote enough

693
00:51:03,560 --> 00:51:08,120
area where you're not endangering those other two categories, you can probably conduct

694
00:51:08,120 --> 00:51:13,840
these type of operations in a perfectly safe manner here and still have the same level

695
00:51:13,840 --> 00:51:17,360
of reliability and safety as a manned operation.

696
00:51:17,360 --> 00:51:22,960
It just, it brings a slight paradigm shift to the idea of where these systems can be used.

697
00:51:22,960 --> 00:51:30,320
Which brings us full circle back to one of your opening points that regulation in particular

698
00:51:30,320 --> 00:51:41,200
and the overall perception of trustworthiness of these systems is a, you know, just as

699
00:51:41,200 --> 00:51:47,360
important as the technical bits and pieces in making, you know, making it all happen.

700
00:51:47,360 --> 00:51:48,360
Right.

701
00:51:48,360 --> 00:51:53,760
Yes, the regulatory compliance and making sure that the operation is safe, I think, is a

702
00:51:53,760 --> 00:51:58,800
huge portion of the research and the public perception associated with the UAS right

703
00:51:58,800 --> 00:51:59,800
now.

704
00:51:59,800 --> 00:52:01,960
Well, Chris, this has been a fascinating discussion.

705
00:52:01,960 --> 00:52:07,160
I appreciate you taking the time to share with us.

706
00:52:07,160 --> 00:52:09,760
Where can folks learn more about what you're up to?

707
00:52:09,760 --> 00:52:15,760
Oh, absolutely, we've, we've got a website and actually I'm almost kind of embarrassed

708
00:52:15,760 --> 00:52:18,760
to admit this here, but, you know, in this age of social media here, we've got a lot

709
00:52:18,760 --> 00:52:25,120
of very savvy students here in our lab who have set up a nice Facebook page as well for

710
00:52:25,120 --> 00:52:26,120
our group here.

711
00:52:26,120 --> 00:52:33,200
We've got, we've got those sort of environments in the, on the internet that people are absolutely

712
00:52:33,200 --> 00:52:38,080
welcome to check out and yeah, if anyone is near the University of Washington during this

713
00:52:38,080 --> 00:52:41,560
Seattle area, you know, I would invite them to swing by the lab, talk with us.

714
00:52:41,560 --> 00:52:47,000
We also have a flight testing facility near here where we fly every once in a while and

715
00:52:47,000 --> 00:52:51,960
we try to invite people that are interested to kind of come out and observe and maybe fly

716
00:52:51,960 --> 00:52:52,960
with us.

717
00:52:52,960 --> 00:52:57,880
Well, there's a, we would love to have any interaction with anybody in the area or else

718
00:52:57,880 --> 00:52:58,880
wise.

719
00:52:58,880 --> 00:52:59,880
Great.

720
00:52:59,880 --> 00:53:06,880
Well, I'll include a link to your page on the UW site and get with you about any other

721
00:53:06,880 --> 00:53:09,520
links that it would make sense to share.

722
00:53:09,520 --> 00:53:10,520
Oh, thank you.

723
00:53:10,520 --> 00:53:11,520
That would be great.

724
00:53:11,520 --> 00:53:12,520
Awesome.

725
00:53:12,520 --> 00:53:13,520
Well, thanks so much.

726
00:53:13,520 --> 00:53:14,520
I appreciate it.

727
00:53:14,520 --> 00:53:15,760
No, thank you so much for having us.

728
00:53:15,760 --> 00:53:17,520
It's been a real honor to be here.

729
00:53:17,520 --> 00:53:19,520
Thanks Chris.

730
00:53:19,520 --> 00:53:24,600
All right, everyone, that's our show for today.

731
00:53:24,600 --> 00:53:29,480
For more information on Christopher or any of the topics covered in this episode, you'll

732
00:53:29,480 --> 00:53:35,640
find the show notes at twomla.com slash talk slash 129.

733
00:53:35,640 --> 00:53:40,280
If you're not an ML or AI practitioner, but you want or need to increase your depth

734
00:53:40,280 --> 00:53:46,760
in these critical areas, remember to check out my upcoming AI summit at twomla.com slash

735
00:53:46,760 --> 00:53:49,280
AI summit.

736
00:53:49,280 --> 00:53:51,760
Thanks so much for listening and catch you next time.

