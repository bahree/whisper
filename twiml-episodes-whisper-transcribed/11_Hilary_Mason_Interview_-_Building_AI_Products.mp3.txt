Hello and welcome to another episode of Twimmel Talk, the podcast where I interview
interesting people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
I want to start out by wishing everyone a very happy and very belated new year.
I'm finding it really hard to believe just how quickly the last few weeks of last year
and the first few weeks of this year flew by.
Needless to say, I'm super pumped to bring you this new episode of the show.
Before we get going, I've got a bit of a holiday gift for some of you.
That's right, over the last few weeks I've received a few requests from listeners who've
wanted to listen to the podcast on their favorite home assistance.
Well, it's taken a bit of doing, but I'm happy to report that the podcast is now available
on both Amazon Alexa and Google Home.
Check this out.
Alexa, play the podcast this week in machine learning.
You'd like to play the program called this week in machine learning, right?
Yes.
This week in machine learning in AI, getting the latest episode.
Where it is from tune in, Hey, Google, play the podcast this week in machine learning.
Learning in AI podcast, twimmel talk number 10 Francisco Weber statistics versus semantics
for natural language processing.
Note that for whatever reason, Alexa doesn't like when you ask for the podcast using its
full name this week in machine learning and AI.
But this week in machine learning works fine on Google either works.
If you have any problems, just repeat the commands that I used in the demo.
Now, I like to think that at least some of you are listening at home on your phone speakers
and I've just commanded your device to play the podcast if that's the case.
Enjoy it.
Nice.
All right, moving along to our program.
This time around, our guest is Hillary Mason, who I interviewed last year at the O'Reilly
AI and strata conference in New York City.
I don't know that she'd refer to herself this way, but Hillary was really one of the
first quote unquote famous data scientists.
I remember the first opportunity I had to hear her speak was back in 2011 at the strange
loop conference in St. Louis.
At the time, she was chief scientist for Bittley, the company that popularized short links
on the web.
One of the days she's running fast forward labs, which helps organizations accelerate their
data science and machine intelligence capabilities through a variety of research and consulting offerings.
I tracked Hillary down at the AI conference after hearing from an attendee that her talk
on practical AI product development was their absolute favorite session.
Hillary and I had a wonderful, although somewhat brief chat, that I'm sure you're going
to enjoy and learn a lot from.
Of course, you can find this week's show notes at twimmelai.com slash talk slash 11.
And now on to the show.
All right.
Hey, everyone.
I'm here with Hillary Mason of fast forward labs.
And we're at day two of the O'Reilly AI conference, the first actual O'Reilly AI conference
as we were just discussing.
That's right.
And Hillary gave a talk yesterday that I didn't get a chance to see, but I heard great things
about it.
Oh, thank you.
Now we start by having you introduce yourself and then you can tell us what your talk was
about.
Sure.
So I'm Hillary Mason.
I'm the founder of an independent machine intelligence research company called fast forward
labs.
And we look into approaches and algorithms that are emerging in the machine learning AI
space, but that are not yet widely understood.
And we do our own independent research to make them useful to people.
So we write reports that are a survey of the techniques from a technical perspective
at a conceptual level, talking about where we think it's going to go, any ethical issues
that might come up, do a survey of the commercial landscape.
So what vendors are out there, what we think the interesting application opportunities are.
We also build working prototypes of these things.
And finally, we act as technical advisors to our clients, like their nerd friend and
help them actually build their AI machine learning products more effectively.
So yeah, that's what we do.
Everyone needs a nerd friend.
Yeah, I mean, we all have that friend.
Even if you are a nerd, you have your nerd friend on your music nerd friend and your
friend who's most likely sitting in front of a computer at 9 p.m., we all have those
people.
Right.
Right.
So your talk, what was the title of your talk?
So my talk was practical AI product development.
And what I was trying to accomplish with this talk was coming into this AI conference.
There's a lot of hype and a lot of lack of clarity around what it means to actually build
an AI product.
What an AI product is.
So what I was trying to talk through are some of the challenges we've seen going from
the idea and the algorithm, going from the press release, if you want to say it that way
to the product.
So being able to say, we have a data set, we have a business problem, we understand, and
we have some, you know, we're willing to invest in trying to make something, how do
we actually do that?
And how does it differ from data analytics and how does it differ from software product
development?
There's a lot of people today are trying to take a machine learning product and sort
of put it into the software development framework, and they tend to run into a few common
friction points when they do that.
Okay, and so I suppose those friction points were the body of your talk?
Yes, so things like how agile software development is really optimized for building a product
with commodity technology, but that isn't how you build a data product because you have
to understand that maybe, even if it's a good idea, sometimes the algorithm you've chosen
won't work, you have to make sure that the accuracy of the system is within sufficient
bounds.
There's a lot of work to do around how you productionize and operationalize these things,
how you monitor, not just that the server is up, but that the model continues to return
high quality results over time as the context and the data changes.
And so all of these details are something that you really have to learn right now by doing
it, and we have yet to really standardize on a common accepted practice.
And so in my talk, I was sharing what we've learned and what we do, and then hoping to
have conversations with people around what they do and what they're trying to do.
And so yes, that's what the talk was.
It seems like agile would be perfect for this environment where things like working closely
with your customer, the end user of your product, failing fast, at least the things we commonly
think about agile.
There's also a whole software development lifecycle thing, which may be what you're referring
to.
Right.
So on the surface, it's absolutely a compatible philosophy.
Which is why everyone falls into the trap.
Exactly.
Because when you go to implement the details is when you run into the problem, when you
have to say, you know, how long do I, how many points will do I think it's going to take
me to find an algorithm that can produce a useful result?
And it doesn't take into account the machine learning process of developing, really experimenting
and saying that, you know, I might try to solve problem A, but it turns out problem A is
really a lot harder than I thought it would be, but I can solve problem B that's also
useful in this product context, and it also doesn't deal with the, once you have something
that sort of works, doing the simplification and scalability work, which is just as hard
as the initial algorithmic work, but often gets overlooked in a, you know, AI conference
where everyone's excited about what's shining in me.
Okay.
So to me, that says that it's not that agile methodologies are fundamentally, you know,
placed in these types of problems, it's that our sensibilities for estimating and, you
know, understanding the development process that kind of feed into an agile methodology
are off.
Like we don't have.
We don't have a philosophy.
Right.
They agree.
But the, the mechanisms are second-class citizens.
So you can allocate a spike time to go figure out an algorithm that that's a hack and there's
no first-class mechanism for this sort of experimentation and iteration.
Okay.
Okay.
And so how did you, with that being kind of the premise for your talk, what were some of
the things that you, that you dove into?
So I love to tell stories.
So I talked about a couple of projects we've attempted that didn't work out.
So one was using a deep learning image classifier to let you take a picture of your plate and
get a calorie estimate, which, okay, that sounds, maybe that sounds like a good idea.
My team, we thought it was a good idea, at least worth trying.
We found a lot of data.
There's a lot of food photography out there.
And there's also a lot of data on, you know, a cheeseburger has this many calories.
Right.
It did not work because that data, a cheeseburger can have anywhere from 300 to 2,400 calories
and these data sets just simply don't agree.
And we did, you know, first we're like, okay, we want the actual calorie count from the
plate and then we decided on a more modest problem, which was, can you tell us if it's
very healthy, healthy or not at all healthy?
And eventually we decided that it was no longer worth the time and investment because
the quality of result we could get was not actually useful.
And of course, this is a fun story to tell because a couple months after we did this whole
process, Google announced that they had in fact solved this problem.
And you know, to me, that sort of validates that it was a good idea, but we didn't have
the resources to make it work.
So I talked about that story also went into depth on a brief, which is an extractive
summarization prototype we built using neural networks for articles.
So being able to take an article and pull sentences out of that article that are an effective
summary of the entire content of the article.
And that's something where there's a product design piece and there's an algorithm design
piece and they have to work together well in order to make a usable, useful, fun prototype.
And so I went through that whole example in the talk.
Can you talk about that one in a little bit more detail?
How did you go about that and what was the process like?
Yeah, so the work we do is always framed around an application.
And so as much fun as it might be to say, like, okay, we want to spend four months using
deep learning to analyze text, which is really what we did.
We decided to focus first on summarization and then under summarization or sort of two
major schools of system one is extractive.
So pulling words and sentences out of the body of text.
And there's abstractive, which is constructing a summary that may contain language that does
not appear in the underlying text that's new language.
We focused on extractive because again, in the product context, we could actually build
something with a high enough quality result to be useful.
Whereas on the abstractive side, we're still as a community very early.
And so the results are kind of variable.
So again, there was that focus.
And then within that, we looked at a couple formulations of the problem.
So one is, can I take any article and extract those sentences?
And that's the system we ended up building.
It's trained on about 18,000 human authored summaries with quotations of news articles.
And it works very effectively on those.
We also did a second formulation of the problem around multi-document summarizations.
So if you have 5,000 documents on the same topic, can you cluster them effectively and
then summarize each cluster?
And for that, we used LDA for that first step.
And actually, my colleague Mike Williams will be at strata tomorrow talking about all of
the technical fun stuff underneath it.
Yeah, if you're interested in that.
OK, and so for that example, the data set that you use, was that a public data set?
Yes, it's from a website called The Browser, which is the terrible website name.
Because of the ambiguity there.
But yeah, so it's a public data set.
And one that turned out to be quite effective.
Oh, interesting.
And LDA, latent, dearest lay allocation.
Absolutely.
And how does that, I've heard that come up a few times.
I don't really know how it works.
What's the 30,000 foot on that?
OK, so the quick conceptual overview is that it's a non-supervised or unsupervised algorithm,
meaning you take the stream of text, and it is able to infer related clusters in the
text fairly effectively.
One of the limitations is that you have to tell it how many clusters to look for, which
you may or may not have an intuition for going into an analysis.
Which again, means that practically the way people handle that on any given body of text
is to sort of try 10 clusters, 100 clusters, and then narrow their way intuitively.
And by clusters, are we talking like N-grams, or are we talking conceptual clusters?
We're talking groups of documents in this particular case.
So we applied it to Amazon product reviews.
And we found particularly great results in the pet product review category, because this
is a section where people are quite passionate about the items they, it's no surprise, I guess.
But we were, you know, a couple of examples we ran into were things like a dog toy that,
you know, 90% of the reviews were five-star and 10% were one-star.
And so when you look at the clusters of those reviews, you see that, you know, most of
them are things like, this is cheap, I can buy it in Amazon, it's great.
This is really good for my dog's emotional well-being, and yes, people are very concerned
with their dog's emotional well-being, and then the 10% were sort of like, yeah, my dog
ate part of this and had to have a $4,000 surgery.
And so that's the kind of structure you're able to pull out with LDA.
And the utility there, I think, is fairly obvious, or rather, one of the things I mentioned
in the talk is that we tend to see these algorithms applied to making things we already do more
efficient.
So if you can make that 20-page article down to two pages, that's making me more efficient.
But if you can make me able to read 5,000 documents, which I could not possibly, I could
not possibly ever stand to read 5,000 reviews of the same dog toy, I can tell you that.
But now I can get a similar amount of value.
That's sort of a really useful AI product.
When you say a similar amount of value, what was your optimization function?
How did you measure whether the value was similar?
So that's a really good question.
And in the case of our brief prototype, we had some human curated test data.
But to be honest, a lot of this is really intuition, which I know is a dirty word in this
context, the world of AI.
But I really do believe in the value of user testing feedback loops and human intuition
and guiding the product aspects of this sort of work.
So what were the, did you have kind of an enumerated list of takeaways from the talk?
Was it prescriptive or was it?
So it was more laying out a shared vocabulary and then sharing some experiences, but I'm
not going to presume to tell you how it's done, because I think that where we are in the
development of the practice of AI product building is still very early.
And this is, you know, I've been a data scientist since the very beginning, and it's very similar
to what happened with the evolution of the profession of data science, where a lot of
people are doing a lot of different interesting things that are all related.
But there's no one vocabulary, no one process that everyone has agreed on yet.
And so I shared my point of view.
I got to talk to people afterwards for an hour and a half out here hearing other people's
point of view.
And it's just, we're at one of those really exciting moments, I think.
Yeah.
Yeah.
Have you done, have you set in on anything else at the event?
Like what else do you think is cool and interesting kind of in this realm?
So at this particular conference, one thing I'm really impressed by is the different perspectives
in the room.
So most of the conferences I've been to are either technical or sort of business or sort
of product design.
Here we have everyone in the same room, which is great, you know, VCs, business folks start
up people, big company people, you know, software developers and machine learning professors
all here.
So that's really cool.
I've heard a couple of, you know, I always love the opening keynotes.
They were pretty great.
And then there have been talks on everything from, you know, TensorFlow for mobile poets,
which is Pete Wardens talk.
And he is a great blog post if you haven't seen it all the way over to the future of natural
language generation from the folks that automated insights.
So it's, you know, just a few of the things I've been enjoying.
Yeah.
Nice.
Nice.
So how long have you been doing fast forward labs?
So fast forward labs is going to be two and a half years old soon.
Okay.
And we are eight people plus two interns based in Brooklyn.
Oh, nice.
We are actually moving our office this week over to Atlantic Ave Barclays Center.
Oh, cool.
So yeah, you were any of your audience should let us know and come stop by if you're in
the new your head.
Nice.
Nice.
Awesome.
Well, I appreciate you taking the time.
I know you've got a meeting and run off too.
Well, thank you so much.
It's great to get an overview of your talk.
Oh, yes.
Great to have this conversation.
Thank you.
All right.
Thanks a lot.
All right, everyone.
That's it for today's show.
A quick note for you guys tomorrow.
I'm off to reworks deep learning summit in San Francisco.
If any twimmel listeners are attending or will be in the area, please reach out to me.
I would love, love, love to connect up with you.
Also, please do leave a comment on the show notes page at twimmelai.com slash talk slash
11 or tweet to me at at Sam Charrington or at twimmelai to discuss this show and let
me know how you liked it.
Thanks so much for listening.
Catch you next time.
