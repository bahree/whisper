WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:34.200
I'm your host, Sam Charrington, hey what's up everyone, we've got an amazing Twimble

00:34.200 --> 00:38.600
Con AI platform's event shaping up for you and I wanted to share a bit about it.

00:38.600 --> 00:41.920
The event is going to be anchored by what we're calling keynote interviews.

00:41.920 --> 00:46.800
These are live podcasts recorded right on the main stage and I'll be joined by some incredible

00:46.800 --> 00:52.680
guests, here are three that I'm really excited about.

00:52.680 --> 00:57.880
One, Andrew Eng, I could not be happier to have Andrew kicking off this event with me.

00:57.880 --> 01:02.640
Andrew is one of my AI heroes and no one has done more to bring new practitioners into machine

01:02.640 --> 01:05.240
learning and deep learning than he has.

01:05.240 --> 01:08.480
Andrew is going to be sharing a bit about what he's learned helping many businesses get

01:08.480 --> 01:12.640
productive with machine learning and AI and also speak with us about where he sees the

01:12.640 --> 01:13.960
field going.

01:13.960 --> 01:18.800
Number two, Hussein Mahana, Hussein is the head of AI and ML at Cruz, the self-driving

01:18.800 --> 01:20.160
car company.

01:20.160 --> 01:25.080
Before Cruz, Hussein helped build Google's cloud ML platform and Facebook's internal

01:25.080 --> 01:27.520
FB learner platform before that.

01:27.520 --> 01:31.480
Hussein is going to be sharing some of the lessons he's learned building ML platforms

01:31.480 --> 01:35.440
from scratch at some of the most advanced companies in the space.

01:35.440 --> 01:37.720
And number three, Fran Bell.

01:37.720 --> 01:41.560
Fran leads a team responsible for data science platforms at Uber.

01:41.560 --> 01:46.600
These are use case focused ML platform supporting application areas like forecasting, anomaly

01:46.600 --> 01:51.560
detection, NLP and conversational AI segmentation and more.

01:51.560 --> 01:56.480
Her platform sit on top of Uber's Michelangelo, putting here on a unique position to speak

01:56.480 --> 02:01.840
with us about how low level and higher level platforms come together to support data scientists

02:01.840 --> 02:04.040
and developer productivity.

02:04.040 --> 02:07.760
Beyond keynote interviews like this, we've got a bunch of outstanding speakers lined up

02:07.760 --> 02:12.200
to share their successes and failures, helping their organizations build and production

02:12.200 --> 02:15.120
lies, ML and deep learning models.

02:15.120 --> 02:21.240
If this lineup sounds interesting to you, visit twimmolcon.com today to register.

02:21.240 --> 02:27.320
Use the coupon code GreatContent through July 31st for an additional 10% off of our special

02:27.320 --> 02:28.840
early bird pricing.

02:28.840 --> 02:30.240
Hope to see you at Twimmolcon.

02:30.240 --> 02:36.040
Alright everyone, I am on the line with Theo Cariannis.

02:36.040 --> 02:42.080
Theo is an assistant professor at the Brain Research Institute of the University of Zurich.

02:42.080 --> 02:44.960
Theo, welcome to this Week in Machine Learning and AI.

02:44.960 --> 02:46.960
Thank you very much for having me.

02:46.960 --> 02:47.960
Absolutely, absolutely.

02:47.960 --> 02:52.320
Let's get started by having you share a little bit about your background.

02:52.320 --> 02:58.640
How did you come to work at the intersection of brain science and machine learning?

02:58.640 --> 03:08.600
Yes, so I would say that I haven't had sort of the most direct path in this sort of field.

03:08.600 --> 03:15.280
So I started off actually studying pharmacy of all things.

03:15.280 --> 03:21.640
So I had sort of my bachelor's degree in pharmaceutical sciences and pharmacy and then I was

03:21.640 --> 03:27.760
very, very much interested in sort of my final years in getting into brain science and understanding

03:27.760 --> 03:31.920
actually brain physiology and pathology.

03:31.920 --> 03:38.600
After that, I decided to pursue a career in neuroscience research, so brain science,

03:38.600 --> 03:42.920
through which I've had sort of a decent sort of long trajectory.

03:42.920 --> 03:48.160
And after I would say establishing my lab here at the University of Zurich about three

03:48.160 --> 03:57.080
years ago, so I came to appreciate and came more into sort of contact with the methods

03:57.080 --> 04:05.280
that were actually flooding, in fact, every almost field of science and also neuroscience

04:05.280 --> 04:07.360
that had to do with deep learning.

04:07.360 --> 04:14.560
So that was sort of my first kind of contact with deep learning was after I joined the

04:14.560 --> 04:20.600
brain research institute and I started working on my own kind of research projects after

04:20.600 --> 04:22.600
being a postdoctoral fellow.

04:22.600 --> 04:28.880
So I can elaborate more if you want on this or well, why don't you tell us a little bit

04:28.880 --> 04:31.080
about your research focus?

04:31.080 --> 04:32.080
Yeah.

04:32.080 --> 04:33.080
Okay.

04:33.080 --> 04:41.160
So what I have been working on and actually I'm very much interested in the lab as well.

04:41.160 --> 04:46.800
We're very much focused on understanding how the brain develops.

04:46.800 --> 04:57.600
So our primary focus is utilizing animal models, mammalian animal models, more specifically

04:57.600 --> 05:01.600
genetically tractable animal model, the mouse.

05:01.600 --> 05:07.240
And utilizing that in order to understand how the circuits in the brain get formed during

05:07.240 --> 05:12.720
development, especially postnatal development, so after birth, and how these circuits are

05:12.720 --> 05:21.600
modified by experience to allow us to really process information from our environment and

05:21.600 --> 05:28.000
ever increasing sort of complex and specific manner.

05:28.000 --> 05:35.040
So I would say that this is kind of the umbrella field that we were working towards understanding.

05:35.040 --> 05:44.920
So basically one of the sort of the more specific aspects of our work is aimed at understanding

05:44.920 --> 05:52.120
how the cortex gets built, so which is this outer surface of the brain, which is kind

05:52.120 --> 05:59.960
of supposed to be the most complex and evolutionary newer part of the nervous system.

05:59.960 --> 06:06.560
And to understand that, we focused on specific sort of sensory regions in the cortex of the

06:06.560 --> 06:11.760
mouse in order to understand how they process information as the animal grows.

06:11.760 --> 06:12.760
Okay.

06:12.760 --> 06:20.000
And so does the cortex have how are the different sensory regions in the cortex organized?

06:20.000 --> 06:26.040
So there's some sort of some a topic if you want in a way in the sense that they are

06:26.040 --> 06:28.880
separated in space.

06:28.880 --> 06:34.240
So there's, for example, regions that are devoted to processing visual information, other regions

06:34.240 --> 06:40.640
are devoted to processing so much of sensory information, so touch, events, and others

06:40.640 --> 06:46.920
for other sensory modalities that we have, such as hearing or smelling.

06:46.920 --> 06:52.560
So there's sort of a, of course, this aggregation of these areas, which at some point, of course,

06:52.560 --> 06:59.960
further down the information processing kind of convergent come together into a common

06:59.960 --> 07:05.480
sort of conscious, if you want, event that can lead to behavioral outcomes.

07:05.480 --> 07:12.080
Is your research focused on understanding how the kind of connections and pathways are

07:12.080 --> 07:13.080
made?

07:13.080 --> 07:18.880
Or do you see that the neurons kind of physically differentiate so that there are multiple

07:18.880 --> 07:25.440
types that kind of interact with one another to produce memory and behavior in these things?

07:25.440 --> 07:32.920
We basically focus quite a bit on understanding a population of cells, neurons in the brain,

07:32.920 --> 07:40.720
which are called inhibitory cells, or they have, sort of, used alternative names and maybe

07:40.720 --> 07:47.320
more so correct these gubergic cells that take their name from the molecule they used

07:47.320 --> 07:49.520
to communicate with one another.

07:49.520 --> 07:58.320
So we basically focus a lot on understanding how this second most populous neuronal sort

07:58.320 --> 08:07.320
of group in the cortex gets developed, so develops and integrates into the sort of circuit

08:07.320 --> 08:13.000
to start parsing out the information that the circuit receives.

08:13.000 --> 08:20.880
So I would say that, you know, the lab is sort of focused at multiple levels of analysis.

08:20.880 --> 08:29.560
One of which is now going to this a bit more to this sort of brain-wide level where things

08:29.560 --> 08:38.920
need to sort of be quantified at a sort of more complete if you want sort of level.

08:38.920 --> 08:45.640
So we try to understand a little bit how different areas sort of develop how inhibitory cells

08:45.640 --> 08:53.160
themselves that inhibit signals and regulate how information flows are positioned in different

08:53.160 --> 09:05.040
areas, how they start function during development and what that may do for signal propagation.

09:05.040 --> 09:08.880
So this is kind of something that we've been focused, of course, there's multiple different

09:08.880 --> 09:16.640
types of cells and the jury is still out as to how many, but our work is sort of a bit

09:16.640 --> 09:19.800
focused more on these cells.

09:19.800 --> 09:26.200
And so how is deep learning come into play in your research in this area?

09:26.200 --> 09:34.680
The way we kind of came about or turned our attention to deep learning is through a couple

09:34.680 --> 09:41.120
of projects that we had in mind where we in fact wanted to address what I was saying

09:41.120 --> 09:47.160
earlier, which has to do with a bit more comprehensive understanding of how these populations

09:47.160 --> 09:54.200
are, let's say, generated, how they populate different areas and how they may even sort

09:54.200 --> 10:00.520
of cease to exist by a phenomenon which is called cell death.

10:00.520 --> 10:07.560
And so in order to be able to achieve that, one needs to create or have the tools at hand

10:07.560 --> 10:16.120
that allow them to be able to perform an experiment or have some data at hand which have to

10:16.120 --> 10:23.320
do with actually, let's say, distribution of cells, let's say, based on a specific marker

10:23.320 --> 10:27.280
or something that marks the cells that one is interested in our case, let's say inhibitory

10:27.280 --> 10:31.040
cells in the whole brain, right?

10:31.040 --> 10:36.040
And that way you have sort of, let's say, a section, a tissue that allows you to sort

10:36.040 --> 10:38.800
of look at that and take a picture of it.

10:38.800 --> 10:44.240
Now, the key question here is how do you analyze that data and how do you analyze it across

10:44.240 --> 10:47.000
different developmental stages?

10:47.000 --> 10:54.000
This is actually how we came about wanting to look into these techniques that are very powerful

10:54.000 --> 11:01.760
and are created by multiple labs across the globe that would allow us to basically, first

11:01.760 --> 11:12.680
of all, have an atlas that tells us which region is which when we're looking at our tissue.

11:12.680 --> 11:18.000
And on top of that, try to extract the signal, which is a cellular signal.

11:18.000 --> 11:24.760
So it's a dotted sort of signal from each one of those brain areas.

11:24.760 --> 11:30.160
So this is actually, you know, the reason why we turned our attention to deep learning

11:30.160 --> 11:37.280
and machine learning methods that would allow us to basically segment, classify segment

11:37.280 --> 11:45.200
different regions and also be able to basically pick up detect the cellular signal that is found

11:45.200 --> 11:46.200
within them.

11:46.200 --> 11:47.200
Okay.

11:47.200 --> 11:53.480
And so a little bit more about the images that you're using, are they 3D scans?

11:53.480 --> 11:57.960
Are you looking at slices and you need to relate information between slices?

11:57.960 --> 12:01.080
Can you tell us a little bit more about the images themselves?

12:01.080 --> 12:02.080
Yes.

12:02.080 --> 12:10.320
Actually, we started off by doing sections, so slices, so tissue sections, brain sections.

12:10.320 --> 12:16.320
So where we have the whole brain, in fact, in view, and we just take images that can be

12:16.320 --> 12:17.320
also different modalities.

12:17.320 --> 12:23.440
It can be, for example, some bright field images where you detect some chromophore signal

12:23.440 --> 12:27.920
that has been created by a chemical reaction or by fluorescence.

12:27.920 --> 12:34.560
So by signal, which actually leads to fluorescent sort of protein signal that you can detect

12:34.560 --> 12:42.720
in cells, we have nevertheless also applied these kinds of methods now to different images

12:42.720 --> 12:50.320
from different modalities, imaging modalities, such as those taken by a fairly new method

12:50.320 --> 12:56.440
that is used in the biological field and also in the neurosciences, which is called clarity

12:56.440 --> 12:59.680
or brain clearing.

12:59.680 --> 13:05.680
These types of images are generated by the fact that what is done during the processing

13:05.680 --> 13:11.280
of the brain, which is after the animal has been sacrificed, is to basically get rid

13:11.280 --> 13:16.640
of the lipids and make the brain be transparent, the tissue.

13:16.640 --> 13:21.520
And that way you can actually just shine light through it and detect what is evoked in

13:21.520 --> 13:27.160
terms of light by means of, again, the fluorescence sort of signal.

13:27.160 --> 13:30.200
That way the light is not obstructed to go through, right?

13:30.200 --> 13:37.280
So this is another sort of imaging modality that we have used to apply our techniques on.

13:37.280 --> 13:43.160
In addition, in the paper, actually, that was sort of just published, we also tried to

13:43.160 --> 13:48.560
benchmark our methods, at least one of the methods we've used on some sort of MRI scans

13:48.560 --> 13:54.720
from human patients or rather individuals, I'm sorry, that are found on the web in the

13:54.720 --> 13:55.720
database.

13:55.720 --> 14:02.880
But so, although we apply these techniques mainly in mouse tissue, we hope that this method

14:02.880 --> 14:09.560
would also sort of start being applied in other types of tissues in this case or species

14:09.560 --> 14:11.240
like humans.

14:11.240 --> 14:18.240
And so the segmentation that you're trying to do with your method is, is it fair to say

14:18.240 --> 14:23.600
it's what I would, what one might call like a macro level segmentation like these large

14:23.600 --> 14:30.320
regions of the brain as opposed to clusters of cells within individual brain regions.

14:30.320 --> 14:31.320
Yes.

14:31.320 --> 14:38.280
So the initial part was to basically be able to, you're correct, yes, segment a few different

14:38.280 --> 14:44.640
brain regions such as, for example, the cortex, this outer surface that we care about.

14:44.640 --> 14:50.400
But the next level of analysis that we are actually aiming at and we have already implemented

14:50.400 --> 14:55.720
parts of, have to do with being able to at least use these deep learning methods to

14:55.720 --> 14:59.040
be able to detect all the cells.

14:59.040 --> 15:03.320
So in a way, create a, you know, bounding boxes around them and actually classify them

15:03.320 --> 15:10.640
and say with a specific sort of, you know, score that these are in fact neurons.

15:10.640 --> 15:21.360
And you mentioned something about seeing or segmenting connections or like signals in

15:21.360 --> 15:22.360
these images.

15:22.360 --> 15:24.160
Did I interpret that correctly?

15:24.160 --> 15:32.040
Are you able to through the imaging techniques, look at actual communication of neurons?

15:32.040 --> 15:38.880
And so we have not actually been sort of dealing with connections per se in the sense that,

15:38.880 --> 15:44.560
you know, these are usually smaller elements and quite complex in nature, depending on how

15:44.560 --> 15:50.560
you look at them, that we haven't really kind of dive into it yet.

15:50.560 --> 15:56.400
One of the things we have sort of done a little bit of is look at some really fine grain

15:56.400 --> 16:03.600
structures which are found on cells, which are the sites where connections happen and

16:03.600 --> 16:08.000
try to sort of, in fact, look at maybe how these change a little bit.

16:08.000 --> 16:13.520
These are called spines for excitatory cells for these other population of neurons.

16:13.520 --> 16:20.040
But in terms of actually looking at, you know, the elements of two, let's say, cells or

16:20.040 --> 16:26.840
two neurons connecting, we haven't sort of been looking at that too much.

16:26.840 --> 16:33.880
What we have done is utilize these methods in combination though with other genetic

16:33.880 --> 16:42.240
and viral and anatomically basically methods that allow us to look at which cells connect

16:42.240 --> 16:48.960
to which other cells in the brain, then performing a whole sort of brain mapping of those connections

16:48.960 --> 16:55.360
by doing this clarity method that I mentioned before, and then actually analyzing the signal

16:55.360 --> 16:56.960
using these deep learning methods.

16:56.960 --> 17:04.200
So basically analyzing the regions, maybe types of cells, but also the numbers and density

17:04.200 --> 17:09.040
of cells found in those regions using these deep learning algorithms.

17:09.040 --> 17:10.040
Okay.

17:10.040 --> 17:14.800
That may have been what I heard earlier that I was trying to tease apart.

17:14.800 --> 17:20.920
When you say the cells that are connected to one another, is that basically another way

17:20.920 --> 17:25.920
of saying cells that are in the same region, meaning the assumption is all of the cells

17:25.920 --> 17:30.120
in the cortex are connected or all the cells in the hippocampus are connected, that kind

17:30.120 --> 17:31.120
of thing.

17:31.120 --> 17:32.120
Yeah.

17:32.120 --> 17:38.640
It's actually sort of not the case in the sense that, you know, so the first assumptions

17:38.640 --> 17:45.840
that let's say the neurons in specific are all connected or maybe this is kind of the

17:45.840 --> 17:48.880
current view, which is, which is not the case.

17:48.880 --> 17:54.960
There's a lot of specificity actually in those connections between a variety of different

17:54.960 --> 17:56.800
types of cells.

17:56.800 --> 17:58.400
So that's not what you're saying.

17:58.400 --> 18:05.560
No, what I am actually saying is that through the use of a genetically tractable model,

18:05.560 --> 18:11.320
which is the mouse in this case, we end utilizing some complex methods that we can, in fact,

18:11.320 --> 18:13.320
go more into.

18:13.320 --> 18:20.440
We are able to, let's say, have a type of cell that we care about understanding what

18:20.440 --> 18:26.800
connects to it or revealing, and by tracing those connections in the cells that connect

18:26.800 --> 18:34.120
to that cell, not only in that area, but actually across the brain, that allows us to get a full

18:34.120 --> 18:41.560
sort of brain-wide view if you want of what kinds of areas and also what kinds of potentially

18:41.560 --> 18:49.920
cells actually connect with, let's say, the cells of interest in another given area.

18:49.920 --> 18:51.480
Does that make sense?

18:51.480 --> 18:52.480
It does.

18:52.480 --> 18:55.160
Let's definitely go a little bit deeper into that.

18:55.160 --> 19:02.880
But before we do, you've mentioned a couple of times the genetically tractable mouse.

19:02.880 --> 19:08.280
What's the significance of the genetic tractability to your research and what you're describing?

19:08.280 --> 19:16.200
So, it's, for us, it's actually very important, and it opens up sort of the door to a number

19:16.200 --> 19:23.200
of sort of approaches and questions that are not as easily addressable in different kinds

19:23.200 --> 19:29.680
of species, which you cannot, sort of, let's say, genetically modify or manipulate.

19:29.680 --> 19:42.280
So to give you an example, by modifying the genome of the mouse, you can label specific

19:42.280 --> 19:48.480
populations and even types of cells, maybe in specific areas of the brain.

19:48.480 --> 19:54.280
Of course, it's not always as clear-cut, and we can discuss why that is, but it allows

19:54.280 --> 20:01.600
us to basically be able to label these cells, track them across different ages, for example,

20:01.600 --> 20:04.520
and also manipulate them.

20:04.520 --> 20:12.080
And by manipulation, I mean that you can, for example, remove gene of interest, such as,

20:12.080 --> 20:17.720
let's say, a disease relevant gene that has been implicated in some sort of a neurodevelopmental

20:17.720 --> 20:25.640
disorder, where we know that its expression or its sort of function is reduced.

20:25.640 --> 20:32.880
You can basically remove that gene in specific populations and areas and time to understand

20:32.880 --> 20:37.000
what it does and how it affects specific circuits.

20:37.000 --> 20:44.560
So it is very powerful for us to be able to, sort of, really be able to track and also

20:44.560 --> 20:47.720
manipulate specific populations and cells.

20:47.720 --> 20:53.040
When you say label, you're talking about like inserting protein sequences that you can

20:53.040 --> 20:54.560
easily identify.

20:54.560 --> 20:55.560
Yes, you can.

20:55.560 --> 20:58.160
Kind of thing, or something else.

20:58.160 --> 21:00.800
Yes, you can do that.

21:00.800 --> 21:06.760
You can basically, exactly insert, let's say, something which was not present and is

21:06.760 --> 21:12.360
not present in the mouse, but which has been, in fact, shown after multiple sort of control

21:12.360 --> 21:18.320
experiments that doesn't have any negative effect on the cell.

21:18.320 --> 21:24.560
So this is, like, let's say, a small scissors, if you want, protein that acts as a scissors,

21:24.560 --> 21:29.520
and then you can combine that with, sort of, let's say, a receptive end, right?

21:29.520 --> 21:36.000
So you can, let's say, have the points where the scissors can work.

21:36.000 --> 21:42.520
You can add them in specific sort of genes in the genome and hence sort of cut them out.

21:42.520 --> 21:48.960
Or you can add something on top of it, again, external, which then you can cut out and

21:48.960 --> 21:55.040
actually, you can cut out one part and let it then fluoresce and let it sort of die, you

21:55.040 --> 22:00.200
know, die in a sense of, like, color the cells.

22:00.200 --> 22:06.160
So it's actually sort of, there's so many now, very sort of interesting tools that have

22:06.160 --> 22:12.160
been developed, which, by the way, there's also now, even cooler tools that have been developed,

22:12.160 --> 22:21.760
which allows us to now utilize methods that, in species that were not as easily sort of

22:21.760 --> 22:23.120
accessible before.

22:23.120 --> 22:28.400
One of those is this CRISPR-Cas method that has been very popular in biology.

22:28.400 --> 22:35.320
Okay, so with these tools in place, now can you talk a little bit more about this process

22:35.320 --> 22:42.160
of kind of mapping the connections from one cell around the brain?

22:42.160 --> 22:43.480
Yes.

22:43.480 --> 22:46.880
So let me sort of take a step back.

22:46.880 --> 22:51.240
So one of the things that, sort of, the way we've done it, I will try to explain the

22:51.240 --> 22:54.120
way we've done it.

22:54.120 --> 23:03.120
So we have, let's say, been utilizing some genetically modified animals or mice that,

23:03.120 --> 23:10.600
as I said, express these scissors in specific cell populations that we care to study.

23:10.600 --> 23:17.200
Specific, let's say, type, that a specific internal type or inhibitory type in the brain

23:17.200 --> 23:19.400
and the cortex.

23:19.400 --> 23:28.400
So by having these scissors cut out a stop signal, if you want, they allow something else

23:28.400 --> 23:30.200
to come online.

23:30.200 --> 23:36.160
And that something else that comes online, like a set of proteins, are, in fact, then expressed

23:36.160 --> 23:41.040
or presented in the cell types that we care to study.

23:41.040 --> 23:47.760
One of those things that is expressed is actually a receptor, so something which can go

23:47.760 --> 23:54.000
to the membrane of the cell, the outer sort of part of the cell, and that has specific

23:54.000 --> 23:56.000
things that it binds to.

23:56.000 --> 24:03.960
So this is a protein that is not found in mice, so it's actually found in birds.

24:03.960 --> 24:08.320
And hence, we know that then it should be specific for these cell types.

24:08.320 --> 24:14.120
Now what we do is we, at the same time, utilize genetically modified viruses.

24:14.120 --> 24:21.440
So in the neurosciences, viruses have been used quite some time now, in order to be able

24:21.440 --> 24:27.320
to, for example, express certain things, let's say a colorful thing, that once you put

24:27.320 --> 24:34.920
it in a specific area, then you can actually have these viruses be taken up by the cells,

24:34.920 --> 24:40.080
and then you actually see the cells and all their processes labeled.

24:40.080 --> 24:45.280
Therefore, you can follow them in different areas, in different brain regions.

24:45.280 --> 24:52.760
Now this has actually been even more modified, and even more sort of tools have been created

24:52.760 --> 24:57.880
to now be able to label specific populations of cells, such as the ones I was describing.

24:57.880 --> 25:03.720
So by putting a modified rabies virus in this case, the rabies virus, we can discuss

25:03.720 --> 25:08.960
what it is, but it's a different kind of, it's a specific type of virus, you're able to

25:08.960 --> 25:14.000
infect the cells that you want, and because the virus now is red, right, because you

25:14.000 --> 25:19.880
have expressed a dye in their colorful dye, it can actually label the cells that you care

25:19.880 --> 25:24.280
to label, and it can also label the cells that connect to that cell.

25:24.280 --> 25:33.480
And so I hope sort of I explained it simply enough, but not simplified, not I didn't simplify

25:33.480 --> 25:37.840
sort of too much, or it wasn't sort of too complex, but basically by utilizing different

25:37.840 --> 25:44.560
sets of tools, which have to do with the mouse lines and also the different viruses again,

25:44.560 --> 25:51.320
we're able to, in fact, look at connections on specific cell pipes.

25:51.320 --> 25:53.200
That is super fascinating.

25:53.200 --> 25:59.080
And now I've kind of pushed you down into the biology here, which is very, very interesting.

25:59.080 --> 26:05.080
With this particular problem of the connections, is this a place that you're applying deep learning

26:05.080 --> 26:06.080
as well?

26:06.080 --> 26:09.440
Yeah, so I'm really glad you said yes.

26:09.440 --> 26:18.480
Yes, yes, what we have sort of been applying deep learning methods for in this case is

26:18.480 --> 26:27.680
are to be able to again, to look at, for example, the distribution of the connections, right?

26:27.680 --> 26:37.840
So let's say you want to assess a brain area A, and what connects to cell type A.

26:37.840 --> 26:42.240
And so you utilize the methods I mentioned, and then you want to understand, because you

26:42.240 --> 26:44.120
almost go with an unbiased approach, right?

26:44.120 --> 26:49.360
So you say, okay, where do these cells receive information from, from which areas in which

26:49.360 --> 26:50.360
cell time?

26:50.360 --> 26:55.640
So in order to do that, again, in a brain wide manner, you need to put in place methods

26:55.640 --> 27:03.080
that don't force you to actually do typical stereology, that you start counting and extrapolating,

27:03.080 --> 27:09.320
or in fact, you know, make you count every single cell and try to eyeball the region that

27:09.320 --> 27:11.400
the cells sit in.

27:11.400 --> 27:17.840
So we try to utilize these deep learning methods to, first of all, identify brain regions

27:17.840 --> 27:23.200
in a whole brain sort of imaging set, as I said, with clarity and light sheet microscopy.

27:23.200 --> 27:27.440
And then once we have identified the region and segmented, let's say the region, then

27:27.440 --> 27:34.400
we actually use a different algorithm to actually detect all the cells in that region.

27:34.400 --> 27:39.880
And so can you talk about the specifics of the deep learning that you've used to accomplish

27:39.880 --> 27:41.240
these tasks?

27:41.240 --> 27:42.240
Yes.

27:42.240 --> 27:51.360
So in this case, I would say that we're kind of like the end user here and on the application

27:51.360 --> 27:52.360
side.

27:52.360 --> 27:59.960
So the kinds of networks we're utilizing are actually being currently developed by, so

27:59.960 --> 28:03.720
outside the lab, and they're being published by a number of labs.

28:03.720 --> 28:08.040
And in this case, by, for example, Facebook or Google.

28:08.040 --> 28:15.560
And we basically took inspiration from the excellent results that they have, in fact, seen

28:15.560 --> 28:25.480
in life basically, you know, images of humans or cars or any sort of, basically, external

28:25.480 --> 28:32.640
sort of scene that allows us to basically, again, segment and call an object, an object

28:32.640 --> 28:35.360
of a specific type and also count cells.

28:35.360 --> 28:41.960
So the two methods that we have utilized actually adapted, I would say, for our methods.

28:41.960 --> 28:48.000
Our two networks, which are called FastRcNN and MaskRcNN.

28:48.000 --> 28:53.720
And these sort of were developed by the MaskRcN, specifically, which we utilized in the

28:53.720 --> 28:58.200
published work was basically developed by Facebook AI research.

28:58.200 --> 29:00.240
Got it.

29:00.240 --> 29:10.760
And did you evaluate a broad array of different methods or algorithms or start there and

29:10.760 --> 29:13.520
it seemed to work well, so you moved on?

29:13.520 --> 29:14.520
Yeah.

29:14.520 --> 29:19.040
So our primary purpose, obviously, was not to kind of do like an end-to-end comparison with

29:19.040 --> 29:24.440
all the methods that are out there, because we're also not primarily allowed that develops

29:24.440 --> 29:32.920
these kinds of techniques or puts a significant effort in basically into this field.

29:32.920 --> 29:36.960
So I would say that we basically looked out there to see what's available, what's the

29:36.960 --> 29:43.040
most common sort of way that people do this kind of, in this case, image registration

29:43.040 --> 29:44.920
to Nathlas.

29:44.920 --> 29:50.880
And that we benchmarked our method against, which these are not deep learning algorithms.

29:50.880 --> 29:58.640
But of course, there's other sort of other efforts that have been also done by other labs,

29:58.640 --> 30:04.240
of course, that were sort of generating methods to do these kinds of things.

30:04.240 --> 30:11.040
But I would say these efforts have focused on mainly human brain images.

30:11.040 --> 30:17.960
What did you learn as you were applying these methods like mask our CNN to this problem?

30:17.960 --> 30:25.120
Any particular interesting challenge or observations in terms of applying it to the types of images

30:25.120 --> 30:28.040
and objects that you were looking for?

30:28.040 --> 30:35.040
Yeah, I mean, one of the sort of things that we, I at least came to appreciate is actually,

30:35.040 --> 30:41.320
of course, the power of these methods when you should have at least a large enough sort

30:41.320 --> 30:48.280
of training data set to be able them to look at the, you know, testing data set and actually

30:48.280 --> 30:50.000
perform the job.

30:50.000 --> 30:58.440
But in terms of our sort of method, I would say or our sort of questions, I would say that

30:58.440 --> 31:02.440
first of all, we didn't try to do this for all of the brain regions.

31:02.440 --> 31:08.960
We actually chose a few brain regions to kind of showcase the ability of the method to perform

31:08.960 --> 31:12.400
well and the usability of the method.

31:12.400 --> 31:20.880
But I would say that, of course, structures change in the brain when you move to different

31:20.880 --> 31:23.520
sort of, let's say, parts of the axis, right?

31:23.520 --> 31:29.880
So you may have the same brain region, let's say the cortex or the hippocampus.

31:29.880 --> 31:39.200
But as you go and take images of that region at different, basically, levels, right, closer,

31:39.200 --> 31:45.840
let's say to the middle, midline or farther away from it, then the network is having a

31:45.840 --> 31:52.960
challenge in basically being able to detect, of course, more complex types of imaging

31:52.960 --> 31:54.360
brain regions, right?

31:54.360 --> 31:59.720
And so I would say that the network has performed well enough for us to actually make use

31:59.720 --> 32:01.200
of it.

32:01.200 --> 32:07.840
But there's quite some way that we have to go in order to make sure that it's even

32:07.840 --> 32:14.920
more accurate and that it's actually able to segmental of this harder type of regions,

32:14.920 --> 32:21.120
which are maybe not as sort of easy and also expanded in other brain areas and even more

32:21.120 --> 32:24.400
specific parts of a given brain area.

32:24.400 --> 32:29.320
So I would say we're at the very beginning of this of these efforts.

32:29.320 --> 32:36.080
And what were some of the alternative or traditional techniques that you were benchmarking these

32:36.080 --> 32:37.960
methods against?

32:37.960 --> 32:44.240
So two of the most commonly used methods are elastics and MD-rich.

32:44.240 --> 32:52.960
So these are basically non-deep learning algorithms where they take minimum type of error

32:52.960 --> 33:04.360
approaches and utilize linear or non-linear sort of warping of the atlases onto images

33:04.360 --> 33:06.280
that you have collected.

33:06.280 --> 33:13.520
So these are the two sort of most commonly used and we kind of try to utilize those ones

33:13.520 --> 33:15.040
to just initially at least.

33:15.040 --> 33:20.600
And then we try to take it one step further and utilize or compare against some other

33:20.600 --> 33:31.240
methods, which were basically out there published on some human, in fact, tissue, again, was sort

33:31.240 --> 33:34.080
of the web, wasn't generated by us.

33:34.080 --> 33:41.880
So I would say that this is, you know, it is not, of course, clear whether at the moment

33:41.880 --> 33:47.880
this is the best deep learning algorithm to be able to segment different brain regions

33:47.880 --> 33:56.320
because, of course, this field is moving very fast and, you know, it is not unlikely

33:56.320 --> 34:01.800
that other algorithms are in the making or, in fact, we're just, let's say, published

34:01.800 --> 34:08.680
that could even sort of surpass this algorithm we've used.

34:08.680 --> 34:16.480
Were there any particular challenges that you faced in the kind of the data management

34:16.480 --> 34:21.280
and preparation side of this project?

34:21.280 --> 34:27.400
Yes, I would say that, of course, with any of these methods, again, as a sort of novice

34:27.400 --> 34:32.600
in the field, I've come to appreciate the amount of effort that needs to be put in terms

34:32.600 --> 34:35.680
of generating the ground truth data set.

34:35.680 --> 34:44.000
And so that has been sort of, of course, a bit of a bottleneck for us being able to

34:44.000 --> 34:49.640
really kind of create this data that we use to train the network.

34:49.640 --> 34:55.880
Yeah, I would say this has been sort of the biggest challenge for us if you want in

34:55.880 --> 35:04.760
sort of doing this, because we were, in fact, lucky enough, or maybe sort of inspired

35:04.760 --> 35:12.960
enough, I would say, to also have access or gain access to a big data set, which is

35:12.960 --> 35:19.480
available to us and actually the whole neuroscience or brain science community, provided by the

35:19.480 --> 35:23.520
Alan Institute based in Seattle.

35:23.520 --> 35:31.520
So this has been an institute that has been generating a lot of data at different levels

35:31.520 --> 35:40.920
of analysis, including a lot of sort of images of mouse brain for different types of proteins

35:40.920 --> 35:45.120
and markers and so on, so forth, that mark different areas, different sort of cell types

35:45.120 --> 35:46.800
and so on, so forth.

35:46.800 --> 35:50.240
So this was also sort of a great resource for us to have.

35:50.240 --> 35:57.000
And so we tried to utilize it, you know, abundantly in order to sort of get to our goal.

35:57.000 --> 36:03.440
And so what's next for you and your lab in terms of applications of machine learning and

36:03.440 --> 36:06.200
deep learning?

36:06.200 --> 36:13.280
So what's next for the lab is actually one of the things that we would like to try to

36:13.280 --> 36:23.880
do is to expand on on this approaches to both anatomical type of data, but also potentially

36:23.880 --> 36:33.560
sort of some functional data, meaning some activity type of data that we collect and others

36:33.560 --> 36:41.840
on live animals awake or freely behaving or basically that have undergone some sort

36:41.840 --> 36:45.040
of like external stimulus presentation.

36:45.040 --> 36:53.200
So I would say that for now we're aiming to expand some of these methods to potentially

36:53.200 --> 37:02.840
include other areas, but even more so to include hopefully different sub regions within regions,

37:02.840 --> 37:09.120
right, where we then need to create even sort of different types of ground truth, of course,

37:09.120 --> 37:15.000
that will give us quite a bit more specificity in terms of understanding actually this at

37:15.000 --> 37:18.200
the brain wide level or at least cortical wide level.

37:18.200 --> 37:25.480
So I would say that that would be sort of one direction that we're going towards and

37:25.480 --> 37:31.000
trying to also sort of utilize maybe these methods to look at connectivity that you

37:31.000 --> 37:39.920
asked me before, a bit more directly if possible, as well as try to implement these methods

37:39.920 --> 37:46.120
in functional data, as I said, that are collected by methods that look at activity of neurons

37:46.120 --> 37:47.280
in vivo.

37:47.280 --> 37:49.360
So in the live sort of animal.

37:49.360 --> 37:54.440
Well Theo, thanks so much for taking the time to share a bit of what you're working

37:54.440 --> 37:55.440
on.

37:55.440 --> 37:57.240
It has been a pleasure.

37:57.240 --> 37:58.240
Thank you.

37:58.240 --> 37:59.240
Thank you very much for the opportunity.

37:59.240 --> 38:01.720
Awesome, thank you.

38:01.720 --> 38:07.440
All right, everyone, that's our show for today.

38:07.440 --> 38:13.440
For more information on today's show, visit twomolai.com slash shows.

38:13.440 --> 38:19.280
Make sure you head over to twomolcon.com to learn more about the Twomolcon AI Platforms

38:19.280 --> 38:20.760
Conference.

38:20.760 --> 38:30.760
As always, thanks so much for listening and catch you next time.

