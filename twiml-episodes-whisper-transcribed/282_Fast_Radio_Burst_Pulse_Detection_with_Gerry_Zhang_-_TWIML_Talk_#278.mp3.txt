Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
You are invited to join us for the very first Twimblecon conference which will focus on the
tools, technologies and practices necessary to scale the delivery of machine learning
and AI in the enterprise.
The event will be held October 1st and 2nd in San Francisco and early bird registration
is open today at twimblecon.com, again that's t-w-i-m-l-c-o-n.com.
I can't wait to see you there.
Alright everyone, I am on the line with Yun Fan, Jerry Zhang.
Yun Fan is a PhD student in the Department of Astrophysics at the University of California
at Berkeley and is also affiliated with the SETI Research Center at Berkeley.
You're welcome to this week in machine learning and AI.
You spend your days searching for extraterrestrial intelligence.
Let's just start right there.
Tell us about that effort at Berkeley and how you got involved in applying machine learning
to that search.
Right, absolutely.
So SETI, which is short for the search for extraterrestrial intelligence, is about
the question are we alone in the universe?
So the search for extraterrestrial life comes in many different forms.
Many searches involve searching for simpler life by looking at the biosignatures or by
going inside of our solar system, doing insitial sampling in the soils on Mars, for example.
SETI takes a slightly different approach.
SETI is the main idea behind SETI is that a lot of technological signature or radio emissions
or whether intentional or non-intentional could potentially be detected from very far
away.
Therefore, if there are advanced civilizations within our galaxy, we could hope to detect
their technical signatures with or existing telescopes.
So these ideas have been proposed since the 1950s, and since then, we have greatly increased
the computational as well as the analog capabilities.
And in 2015, the breakthrough initiatives was funded by Yuri Milner.
The breakthrough listen project in particular is a $100 million project to conduct the
most comprehensive SETI to date.
And the main headquarters is here in Berkeley at a breakthrough SETI research center, where
we analyze the data that we collected from currently two main telescopes, the Greenbank
Telescope in West Virginia, the Parks Telescope in Australia, and most recently announced
the Miracat Telescope Array in South Africa, which is a precursor to the Square Kilometer
Array.
Interesting.
Now, I remember back in the early 2000s, I guess, there was a SETI at home project which
basically kind of distributed that there was this client you can download, and it would
the SETI at home project would kind of parcel out these mathematical equations, basically
analysis of some set of these signal to the, I don't know, millions of people who downloaded
this SETI at home.
I think it was a screensaver or something like that.
Right.
Right.
Does that thing still exist?
Yeah.
Yeah.
SETI at home is still operating, also based out of Berkeley.
Okay.
So SETI at home was actually one of the earlier deployments of distributed DECES.
Centralized computing.
And it employs a set of match filters that people use to, that people have engineered
a signal that could potentially be interesting, potentially be sources of ETI.
And that effort is still going on today.
Interesting, but your focus is on the application of machine learning to this.
How did you, you know, what sparked your interest in this area?
Absolutely.
So, so in, as machine learning applied to SETI, for example, SETI at home, as we just
discussed, employs a set of match filters.
And very few listen also mainly revolve, searching for particular types of signals, which
we can go into one more detail in a bit.
The idea is that using machine learning, we can potentially find signals where we don't
exactly know the type of signal that we're looking for.
So that's, that's one of the main reasons that a more flexible and versatile technique
like modern machine learning could potentially help.
For me personally, my background was actually originally in particle physics.
So the, my career track is sort of, I started very young, being interested in big
ideas, ideas that, that based on a set of principles, mathematics, we're able to derive highly
non-trivial understandings of the universe and really shape the course of human history.
So that really got me interested in the success stories of 20th century physics.
During my time at Berkeley, I started to realize that in the 21st century data has become
a new tool to solve these very complex problems more effectively, efficiently.
And that's how I got myself involved in machine learning and data science.
And I started by, I, I took some classes at Berkeley on seminars of deep learning where
we looked at most recent, some recent papers and we have invited talks from researchers
at Microsoft and Amazon and we design our own research projects.
And that's, that started my, my, my interest in passion for modern deep learning.
And within my department, the, one of the groups that was in need the most of these techniques
was breakthrough listen, the SETI project.
And that's how I started my involvement.
Okay.
And within the department just out of curiosity is deep learning, is it a, you know, a
still a rare skill or is it becoming a, to what degree is it becoming a standard piece
of the astrophysics toolkit?
Right.
Right.
Right.
To my understanding, I would say the, it's, I would not call deep learning a standard
toolkit in astronomy quite yet.
I would say the application in astronomy is just starting to take off.
The good thing is we have very nicely built algorithms from the computer vision community
from the voice recognition language processing community that we can tie in to the kind
of problems that astronomers are interested in.
So I think the progress will be very fast, however, I would describe the, the degree of
maturity to be still at early stages.
From my previous conversations with folks applying machine learning to astronomy, one of
the challenges that, of course, isn't unique to astronomy, but is accentuated in astronomy,
I believe, is the, you know, the issue of the data, the cleanliness of the data.
Can you talk a little bit about the data sources that you're working with and, you know,
what they look like, how you have to deal with them and the challenges that they create
for you?
Absolutely.
So, because, I think, because we, the algorithm side is so developed, well developed from
the computer vision folks, I think, for us, really forming, formalizing the problem and
putting the data in the form is, I think, the main effort in applying machine learning.
And so for us, in the radio frequency setting, the data are collected as complex raw voltages.
So these are time series, very high data rate time series that we collect from, from
the telescope.
So the raw data rate would be about half petabyte per day.
And we take these complex time series and we, we essentially take Fourier transforms
on these time series to form spectrograms.
So spectrograms are intensity as a function of frequency and time.
They are essentially two-dimensional data, sort of like images where we do a lot of, a
lot of our analysis.
So these two types of data products, the time series and the, the, the waterfall plot,
the spectrograms are the two main types of data that we work with.
The spectrogram is that a native output of the telescope, or is that a product that
you have to create through processing?
So it's a product that you create through processing.
It's, you can think of it as sort of a feature extraction.
So it's a Fourier transform to, to represent time series, essentially, by the type of
periodicities, the type of frequencies that's, that's present in the data.
It's a kind of feature extraction, but it's a very, it's a very efficient one because
of the way the, the, the, the, the Fourier nature of, of wave, wave physics, essentially.
And so you've got this, this half a petabyte of data per day that's coming off of these
telescopes that you're using.
Do you have to work with all of that?
Are you able to, are the, the telescopes themselves like the organizations that run those telescopes
producing products that are, you know, already processed and lower volume, or do you just
kind of work with raw data?
Right.
So the, the spectrograms I mentioned, that's already 100 times smaller in terms of data
volume than the raw data.
We do this simply by averaging once the spectrograms are formed.
So that makes the data storage problem a little more manageable.
So, and by, by doing so, you do destroy some information.
So, you know, the, the spectrograms that we work with, we designed them from the get go
for a particular type of observation in that we try to isolate the signals that are coming
from the sky, aside from the signal that are coming from the side lobes.
There's these signals, terrestrial signals from cell phones, satellites, from airplanes.
We try to isolate these interference away from, from signal that's actually coming from
space.
So we do this by a spatial filtering technique where we, to simply put, we look at multiple
patches of sky at the same time.
And if a signal shows up in all patches of sky, then we conclude that this signal is
actually not localized in the sky.
So, so the, the spectrograms are, are designed to look for these particular types of signals
and we have a set of match filters that operate on these spectrograms to look for them.
However, the nature of the problem is, is not so well defined because we don't exactly
know for sure that the type of signals that, that the event civilization could be sending
matches the, the match filter that we're deploying.
So we do store all of these spectrograms for later inspection with more events techniques
such as deep learning, even on supervised learning to, to look through them more exhaustively.
The, you mentioned that one of the big challenges besides from kind of just the data processing
piece is problem formulation and you alluded to that again and that you, you know, this
is something that will change as we get more sophisticated.
How do you approach that part of the problem though in your research?
Right, right. So the fact that the data comes very unstructured, so these are essentially
just images and images and images where you don't exactly know what to look for in the
image. It requires essentially different problems being formulated depending on what, what
the goal is.
One particular project that we recently did press release on was detection of a signal
known as a fast radio burst.
So these are a particular type of signals that astronomers have detected since 2007.
So these, what they look like is in the spectrogram that we just mentioned, these are roughly
a parabola.
So these are quadratic form signals.
So to look for these type of signals, we know what type of signal we're looking for.
So to use machine learning, we can simulate the type of signal and the reason we want
to do this is one that we know what to simulate and also because the signals are themselves
very rare.
So to date, they're only about 50 different fast radio bursts ever detected.
And from one of these sources, there have been about 200 to 300 detection.
So this is not a lot of samples to go off from a deep learning perspective.
And therefore, simulation would be needed to greatly expand the positive examples.
On the other hand, we do collect, in terms of spectrograms, we collect about petabyte
per year of spectrograms.
And there are many, many examples, there are terabytes and terabytes of interference, the
signals that we don't want to pick up in this data.
And by using the real background, the real interference background, and simulating
on top of the, simulating fake signals on top of the interference background, we train
the trained these networks to reject the signals that are actually interference and uninteresting.
So that's one particular example how to look for signal that are rare, but we know what
to look for.
Sometimes we detect certain signals, and we don't exactly know if this signal is interesting.
That requires a slightly different problem formulation.
And that way, we have to first design a match filter, or we can design a machine learning
algorithm to pick out these signals, then we do anomaly detection.
So we do a future prediction type of anomaly detection, where based on the past observation,
we try to predict the future observation, and then we compare against the real observation
to see if there's any significant discrepancies.
And if there is, then anomaly is triggered.
And we will look at the signal more closely.
There are also problems where we collected a great deal of signals, and we don't know exactly
how to characterize them, whether they can be classified, or some of them maybe we can
classify.
And that could be treated as more of a semi-supervised clustering type of problem, where we try to
characterize the signals and try to put them into different classes.
In the case of the fast radio bursts work, is the idea that you're able to train a detector
for these radio bursts, we then take that detector that you've trained and run it
against the petabytes and petabytes of historical data to identify instances where it occurred
before you started paying attention to it, or is it more just, you know, from now on we're
going to start looking at these things by running this detector against them.
This particular announcement was about, so a particular observation that we performed
about a year ago.
So for that observation, we collected about eight terabytes of spectrogram data that's now
all open to public from our website.
So in this observation, we previously had a match filtering technique that detected 21
signals.
And by training this network, we re-analyzed the same data and detected 72 more.
So all of these detections were from the same source.
So they have certain characteristics, they're all similar to each other, which made the
design of the, both in terms of the problem formulation, what kind of resolution should
I feed in the spectrogram in, you know, how many layers we should have to make the entire
design a little simpler.
We will also like to do both of those things that you suggested.
One is to search blindly in all the archival data for similar signals.
And another is to use this in the real-time serial for future service.
Both of those will be a little more challenging, for example, one difficulty is the problem
of scale.
When you don't know, essentially, the curvature of this parabola, the signal could be even
100 times longer than the signals we detected in this case, or it'd be much narrower, so
on and so forth.
And that requires sort of a multi-scale kind of input in order to have the same sensitivity
across all of the parameter spaces.
So that we haven't done yet.
So you formulate your problem into one of these broad categories of identifying the patterns
or doing anomaly detection, and then you have the two different types of data, the time
series data, and the spectrogram data.
Are there other things that you're doing?
What are also you doing on the data processing side to before you are putting data into kind
of, it sounds like you're using traditional, more or less, CNNs and those types of neural
networks?
Is that right?
Right, right, right.
So some of these require, so both in terms of the pre-processing, in terms of the future
extraction, and in terms of the deep learning, depending on the problem, they're different
uses.
So for the fast radio burst work, we used a typical CNN, it was a residual network.
For a anomaly detection, because there's a temporal component to it, we use a convolutional
LSTN, and it's also trained in an adversarial way, like again, because the loss function
when, so these spectrograms, they aren't image, there are two dimensional image data,
but they are very, very noisy.
So that makes direct comparison in terms of the pixel-wise L1 or L2 loss, that makes
that not very useful, because noise, you cannot predict noise, right?
So we use sort of adversarial loss to train these type of networks.
For the clustering type, depending on, we want to be a robust, for example, to a variety
of things, to how the signal was filtered on the analog side, and to how we processed
them, and what was the fractional bandwidth to be robust to a wide range of parameter there.
We do some feature space techniques, use some additional loss to regulate what the feature
space looks like.
We also try to use some of the adversarial techniques called domain transfers.
These are the same techniques that people use to do.
So if the training set, say, was rolled images taken during the day, how would you be able
to do inference for when you, how would you be able to inference when your camera is recording
at night, right?
So to be able to cross this domain, we try some of the techniques that people develop
in computer vision as well to do this, yeah.
Okay.
You mentioned GANS.
Can you elaborate on what you're doing with GANS?
So yeah, so the particular work I mentioned has an adversarial component to it.
So again, the original GANS is meant to generate new data that conforms to the distribution
of the data set.
It's not quite exactly what we're doing.
This is a future prediction type of network.
So what we're trying to do is to give in the past observation predict what a future observation
look like.
So you will still want to compare this prediction with the actual observations.
So in a way, this is a self-supervised type of technique.
We use an adversarial loss in that the generator that we have that generates this future prediction,
we also introduce a discriminator that looks at the real observation and the predicted observation
and try to tell which one is which.
And by having the generator trying to fool this discriminator, we essentially generate
more realistic looking future predictions.
And is this GAN operating like in the frequency domain, is it trying to predict spectrogram
samples or something else?
Right, right.
So this was a convolutional LSTM that was making the prediction.
So that's just the generator I is.
The GAN component of this is just an additional term in the loss function.
So the discriminator is a CNN that looks at the spectrogram that's predicted.
You talked about domain transfer, domain adaptation.
How are you approaching that in this use case?
So the main idea of domain transfer is that when your training data has certain characteristics
and your test set data is from a different distribution, you want to be able to correctly
do inference on this new, slightly differently distributed data sets.
I think this problem we face a lot in the radio frequency domain because the signals could
potentially look very different if you, if a different sensor was used, if a different
bandwidth was used, essentially the same signal can look completely different in the time
domain, which may be the original, the data that was, that was feed-in, that was fed
into the network.
So we use these techniques to essentially do the same thing as a computer vision to be
able to do inference more effectively in a domain that the training data was not collected
on.
And is this primarily happening at the kind of as feature pre-processing or adding, subtracting
gain from your signal or applying filters or things like that, or is this stuff that's
done in the training process?
So this is done in the in the training process when we, so also we, for example, we use a
lot of, we use a lot of simulated data because it's hard to collect ground truth labels for
real data. And to, when, when we train with this loss function that, that has knowledge
of what the, what the, the, the real data, the, essentially the target has looks like, but
we don't know the labels, you can add this additional loss to the, to the training process
so that the, the learned model is, is more aware of, of the target domain.
I guess I'm trying to get a sense for how many features these models tend to have.
Cute are they, you know, huge, very high dimension or not necessarily?
That's a very good question. So, the, in some of my experiments in these type of classification
and semi supervised clustering algorithms, we find that this type of domain adaptation
we typically use on the, on the last layer, essentially. We, we find that around 128 features
was probably was the most efficient in terms of using this technique. But that doesn't
mean that this is a general statement about all of these applications. It could simply
be the tackle signals that I was deploying this technique to classify, you know, roughly
had many dimensions. So, I think there's still a, still an open question to, to, to the,
the degree of variability in the number of features.
In the, the fast radio burst paper, there was a mention of new periodicity search technique
based on rally tests. Is that, is that related to machine learning or is that more kind of
domain specific?
I would say that's, that's more of a data mining technique that's not really machine learning.
However, it is a technique that's new to the astronomy community. So, this is, so we,
detected all these signals. And we would try to see one of the main questions we want
to see is, is there any regularity? Do you see periodically appearing signals? And,
because these signals come from very, very far away. So, the source, I should say for
this particular signal has been localized in the dwarf galaxy. That's three billion
liars away. So, and the signal, when they, when they come to us, many of them are very,
very weak. So, we don't exactly know how many of the signals that was emitted was actually
detected. And that makes searching for periodicity in, in the signal, relatively difficult. So,
we, we use this technique based on the railings test to see if we can detect any periodisties.
If not, if we can put a signal, significance level in terms of, they're not existing
a periodicity. And, in the end, we went with a later one. It does not look like any of
the periodicities that, in the range that physically was sensible, was a statistically
good match for the data that we collected.
So, what degree is the periodicity represented in the spectrograph? Like, I would have
imagined that the frequency component, you know, the stronger frequency components would
represent periodicity that is kind of readily apparent from the spectrograph. What does this
technique do for you kind of beyond what is available via your Fourier transform types
of techniques? Right, right, right. So, that's, that's a very bad question. So, in the, in the
spectrograph domain, if you see a very regular period, then it will show up very clearly.
So, in, in our case, these are very rare signals. So, in these six hours of observation around
a petabytes of data, we have about 100 detections. So, these are very rare on very weak signals.
So, similar techniques that have been applied to finding pulsars, which are radiobursts.
There are some differences. Well, pulsars are, are, their source are situated within our galaxy,
and most of them you can see clearly a regular period. And some of these techniques in spectrograph,
that works on spectrographs could work there. But for us, because of the amount of noise
as present, it's, it just was not nearly powerful enough to put a constraint. Got it, got it.
Yeah. And I imagine that there's, I don't have the, the words for it, but I imagine that there's
some notion of kind of a complex periodicity that's not, you know, just a regular time domain
frequency, but maybe has other components that might be harder to detect, but still interesting.
Is that something that you're able to detect in this data?
Right, right. So, I mean, essentially, if you have, if you have many parameters,
you can always fit the data, right? So, yeah, yeah. So, it's, that is one issue. And the way we,
so, so, I should just mention some factor that could potentially cost this type of complex
periodicity. One is, you know, the emission could not have been periodic, but maybe it was,
you know, the emission itself was, was some of, was pseudo periodic. There was a window in which,
through which the, the signal was emitted. And during the, during the propagation process,
there could have been processes that made some of these, that delayed some of these signals more
than the others. So, when they, by the time they arrive, they appear to, essentially, you smeared out
any, any periodicity that was in, in at the time of emission. So, we don't exactly know,
there are some physical, there are some models that are based on astrophysics, to model these
more complex type of periodicities. There hasn't been enough evidence to support any of them. And
even though we have the most amount of detections from a single observation, it still would not be
able to constrain these models. So, what, what we did is to essentially put all the complexities
in the same parameter. In, in our case, is the uncertainty is the uncertainty in the arrival times
that we picked up. And, you know, all of these different models, they would map onto this
uncertainty in a way. And we constrained, we, we derive a final constraint as a function of
this uncertainty. And that way, this measurement could contribute to, to, to putting limits on
these individual complex periodicity models. So, you see kind of in parallel to the application
of machine learning and deep learning to astronomy, the application happening in domains like
computer vision that's moving very quickly are there. Technique, and your, your, sounds like
you're staying very well current to some of those techniques by applying gans and domain,
transfer and things like that. Are there things that you're excited about happening outside of
particular things that you're excited about happening outside of astronomy? Did you think we'll
have big impacts on this field? Yeah, absolutely. So, I should say the, the radio frequency
AI applied to radio frequency data is not only something that's done in astronomy.
In recent years, there's, there's so a lot of interest in the defense sector as well as
in telecommunications. And there are, there are a few companies that I know, mostly in Washington,
DC area that, that specialize in this type of signal recognition. And for them,
they want to be able to classify all the signals that they detect and see if there are any anomalies.
For, for, for, for us in, in, in radial setting, we will also like to do that. They may not be
the signals that we're looking for, but we, we typically, we will describe this as a, as a
needle in a haystack, kind of a problem. And by classifying all of the signals,
there are terrestrial signal communication signals. We're able to, we will be able to understand
the hay in the problem very well. And this would help us narrow down or surge greatly in terms
of understanding, you know, potentially interesting signals in our data. And are there
things, are there techniques that are emerging or evolving in the broader, or out of the broader
deep learning community that you see having a big impact in this area?
Outside of deep learning. No, inside of, you know, within deep learning, but outside of
the astronomy in particular. So, so, for example, these applications I mentioned are,
our works that are in, they're engineering, more from engineering signal processing point of view.
So, they are a bit outside of astronomy themselves. And in fact, we, we, we try to pay close attention
to, to some of the recent progresses. It's, usually, I think, we're late enough to the game that
they're still enough cherries to pick from well-established ideas. I think, you know, it could be,
it's both a good thing and a bad thing. A good thing is that, you know, we do have a lot of
established techniques that we can apply effectively by designing the problem appropriately.
A difficult part is that, you know, the data was not collected with machine learning in mind.
So, you know, the, first of all, there's not any labels and things have vastly different scales
compared to one another. I think the, the putting the data in a form that's, that's suitable for,
for these, you know, by this point, well-established ideas is, it's still a very fruitful effort, I think.
Well, Jerry, thanks so much for taking the time to chat with us about what you're up to.
It's very cool stuff. Great, yeah, thanks a lot for having me.
All right, everyone, that's our show for today. For more information about today's show,
visit twimmolai.com. Be sure to visit twimmolcan.com for information or to register for
Twimmolcan AI platforms. Thanks again to C3 for their sponsorship of today's episode.
To check out what they're up to, visit c3.ai. As always, thanks so much for listening and catch you next time.
