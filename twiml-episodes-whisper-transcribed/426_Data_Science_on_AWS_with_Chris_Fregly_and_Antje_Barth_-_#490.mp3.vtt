WEBVTT

00:00.000 --> 00:13.960
All right, everyone, I am here with Anshia Bart and Chris

00:13.960 --> 00:18.960
Freggly. Anshia is a senior developer advocate at AWS and Chris is a

00:18.960 --> 00:24.280
principal developer advocate at AWS. Anshia and Chris, welcome to

00:24.280 --> 00:25.680
the Twomo AI podcast.

00:25.680 --> 00:29.680
Thanks so much, Sam. It's great to be here.

00:29.680 --> 00:35.680
I am really looking forward to digging into our conversation. I've

00:35.680 --> 00:41.680
known the two of you for quite some time now. I'd say let's

00:41.680 --> 00:45.680
put it like this before Anshia's hair was blue and before Chris

00:45.680 --> 00:47.680
was wearing button-down shirts.

00:47.680 --> 00:51.680
Oh my God. That is true.

00:51.680 --> 00:52.680
Indeed.

00:52.680 --> 00:57.680
And, you know, in fact, we'll talk a little bit about, you know,

00:57.680 --> 01:02.680
the work that you have both done kind of building communities

01:02.680 --> 01:04.680
around data science.

01:04.680 --> 01:09.680
But to maybe get us there, I'd love to have both of you walk us through

01:09.680 --> 01:14.680
a little bit of your background and bios and just how you came to work in

01:14.680 --> 01:17.680
ML. Anshia, want to get us started?

01:17.680 --> 01:19.680
Sure. Happy to.

01:19.680 --> 01:23.680
So, yeah, I had a quite traditional start. So I studied computer

01:23.680 --> 01:26.680
science here in Germany, actually at the University of

01:26.680 --> 01:31.680
Tupingen. And after that, I really got excited to start right away in

01:31.680 --> 01:35.680
the tech industry. I joined Cisco, worked many years in the data

01:35.680 --> 01:40.680
center space. And then the next big thing that I always was interested

01:40.680 --> 01:45.680
in is data. So I also worked a couple of years in the big data space

01:45.680 --> 01:49.680
at MEPR. And, you know, how it goes, right? I mean, the technology

01:49.680 --> 01:54.680
innovation keeps going. And after big data, I really got super, super

01:54.680 --> 01:58.680
interested in learning more about data science, AI and machine

01:58.680 --> 02:03.680
learning. So I started to do more talks and that space to take

02:03.680 --> 02:10.680
courses, to build fun demos and got excited. And then I joined AWS

02:10.680 --> 02:13.680
as a developer advocate for AI and machine learning.

02:13.680 --> 02:17.680
And I'm super excited right now on this role to be able to help

02:17.680 --> 02:22.680
developers build on AWS and show them how they can use the services

02:22.680 --> 02:26.680
and also enjoy writing books.

02:26.680 --> 02:29.680
Nice. Nice. Chris, how about you?

02:29.680 --> 02:33.680
Yeah, similar type of thing. You know, I moved to the Bay

02:33.680 --> 02:37.680
area about 10 years ago and started working for Netflix.

02:37.680 --> 02:42.680
And they do so much machine learning, so much AI for, you know,

02:42.680 --> 02:47.680
foundations and even, you know, some of the script writing and

02:47.680 --> 02:51.680
script analysis and really caught the bug there, caught the

02:51.680 --> 02:55.680
machine learning bug there. And then moved on to Databricks

02:55.680 --> 03:01.680
to really scale out and, you know, learn all of the, like, depth

03:01.680 --> 03:06.680
and breadth of Spark, of Apache Spark. And then the two came

03:06.680 --> 03:10.680
together. And so coming from Netflix where we use AWS very,

03:10.680 --> 03:15.680
very heavily from day one, my first day, I spun up, like,

03:15.680 --> 03:20.680
EC2 instance, I actually deployed some code.

03:20.680 --> 03:24.680
What's super fun to do that. And then I've kind of come full

03:24.680 --> 03:27.680
circle almost. And now that I'm working for AWS and I'm

03:27.680 --> 03:31.680
specifically focused on big data AI and machine learning.

03:31.680 --> 03:33.680
So that's why I'm here.

03:33.680 --> 03:37.680
That's awesome. And I think you are one of the first people

03:37.680 --> 03:42.680
that I knew that was out kind of evangelizing Kubernetes for

03:42.680 --> 03:45.680
ML and AI. That's right.

03:45.680 --> 03:49.680
You had a course. I think both you and Anjah were working on

03:49.680 --> 03:53.680
the, that's right together.

03:53.680 --> 03:58.680
Talk about some of that work that you have done the community

03:58.680 --> 04:02.680
building and the courses. You have a had or have a meetup

04:02.680 --> 04:07.680
that you have hosted for quite some time in SF.

04:07.680 --> 04:12.680
Yeah, exactly. So right after Databricks, I actually started

04:12.680 --> 04:17.680
what was back then the advanced TensorFlow and Spark meetup.

04:17.680 --> 04:20.680
So TensorFlow had just hit the scene. It was 2016.

04:20.680 --> 04:23.680
And I focused on the advanced part of it because there were

04:23.680 --> 04:26.680
plenty of Spark meetups, there were plenty of, you know,

04:26.680 --> 04:30.680
TensorFlow meetups. But, you know, I would go to lots of

04:30.680 --> 04:33.680
these meetups. And I would come away not really knowing

04:33.680 --> 04:36.680
anything more than I, you know, could have gotten, for example,

04:36.680 --> 04:40.680
from just simple documentation. So because I had so much

04:40.680 --> 04:44.680
Spark knowledge, I actually set up, I think the first,

04:44.680 --> 04:48.680
I think eight or nine meetups was just me speaking.

04:48.680 --> 04:51.680
And because, right, like no one really knew me.

04:51.680 --> 04:54.680
I didn't have that large of a network back then.

04:54.680 --> 04:59.680
So I was able to explain what was going on within Spark.

04:59.680 --> 05:04.680
And each event, which like we ran monthly, we would dive into

05:04.680 --> 05:07.680
the details of this code of the TensorFlow source code itself.

05:07.680 --> 05:09.680
You know, fortunately these projects are open source,

05:09.680 --> 05:12.680
Kubernetes open source. And so once Kubernetes came out,

05:12.680 --> 05:16.680
there was a lot of interest from my community to say,

05:16.680 --> 05:20.680
hey, how do I get Spark running on, on like Kubernetes?

05:20.680 --> 05:23.680
And then also how do I scale out TensorFlow? And then eventually

05:23.680 --> 05:29.680
Kubeflow came out and we sort of pivoted to that. And now that I'm

05:29.680 --> 05:32.680
with AWS, I cover all of those open source and SageMaker.

05:32.680 --> 05:38.680
And yeah, so all of those technologies pie towards TensorFlow.

05:38.680 --> 05:42.680
And until you cover the same set of technologies.

05:42.680 --> 05:46.680
Yeah, exactly. And it's actually fun. So in parallel to Chris

05:46.680 --> 05:49.680
efforts, I was also starting to build up the community here

05:49.680 --> 05:54.680
across Europe. And while I was working in the big data space,

05:54.680 --> 05:58.680
it also started to containerize big data workloads.

05:58.680 --> 06:02.680
Right. So I was also being invited to give presentations and talks

06:02.680 --> 06:06.680
at events, conferences to talk about how to containerize big data

06:06.680 --> 06:10.680
environments. So I was also starting to get into the Kubernetes

06:10.680 --> 06:14.680
and cloud native ecosystem. And yeah, and from there it was

06:14.680 --> 06:17.680
literally a few more steps and then into the machine learning space.

06:17.680 --> 06:22.680
And yeah, Chris and I have been developing a couple of workshops

06:22.680 --> 06:27.680
and courses to help developers really grasp the idea and the

06:27.680 --> 06:31.680
technology, how to be successful working with those open source

06:31.680 --> 06:35.680
technologies, but also now in the role at AWS, how to successfully

06:35.680 --> 06:38.680
build with the services and sometimes even in combination,

06:38.680 --> 06:41.680
right, to leverage both the innovation of the cloud, but also

06:41.680 --> 06:45.680
maybe some exciting open source technologies.

06:45.680 --> 06:50.680
Nice. And are your roles primarily working one to many

06:50.680 --> 06:55.680
with producing materials like workshops and courses or do you

06:55.680 --> 07:00.680
work with individual customers? What's the specific role

07:00.680 --> 07:06.680
that you're or what are the specific focus areas of the role?

07:06.680 --> 07:10.680
Yeah, I think primarily we are community focused.

07:10.680 --> 07:15.680
Yeah, so obviously AWS is very, very customer focused.

07:15.680 --> 07:19.680
And so we do get lots of requests to work with specific

07:19.680 --> 07:24.680
customers. We're super happy to do that. Fortunately, we can reuse

07:24.680 --> 07:28.680
the same like workshop. And so that's even better because we can

07:28.680 --> 07:33.680
present something that's like totally open to both the customer

07:33.680 --> 07:38.680
internally for their like training or just sort of educational

07:38.680 --> 07:41.680
needs, but then they can also go away with it and share it with

07:41.680 --> 07:44.680
the rest of the group or their friends at like other companies.

07:44.680 --> 07:49.680
So yeah, it's a mix of both our, you know, sort of primary

07:49.680 --> 07:56.680
goal is, is, you know, reach and spreading this knowledge and

07:56.680 --> 07:59.680
write like really diving deep into these things. That's why

07:59.680 --> 08:03.680
Auncha and I really focus on sort of end to end type use cases,

08:03.680 --> 08:06.680
where we're not really focused on a single product or a single

08:06.680 --> 08:10.680
service or a single open source tool, we show how to use

08:10.680 --> 08:14.680
them all together and then provide different options.

08:14.680 --> 08:18.680
And so we've been talking kind of generally about workshops

08:18.680 --> 08:23.680
and you've been doing a end to end ML workshop for quite

08:23.680 --> 08:29.680
some time, but recently, in fact, with this yesterday, the

08:29.680 --> 08:34.680
ML summit, you announced your latest effort.

08:34.680 --> 08:38.680
Auncha, do you want to do the grand unveil?

08:38.680 --> 08:43.680
Sure, I'm happy to. So yeah, we've been working for a lot

08:43.680 --> 08:46.680
of different formats. So we've been doing workshops.

08:46.680 --> 08:48.680
We just recently published the book.

08:48.680 --> 08:51.680
And another project, Chris and I have been working on over

08:51.680 --> 08:54.680
the last couple of months, which we launched yesterday during

08:54.680 --> 08:59.680
the ML summit keynote AWS is a project in collaboration with

08:59.680 --> 09:01.680
Deep Learning AI and Coursera.

09:01.680 --> 09:06.680
We worked on a new Coursera course, practical data science,

09:06.680 --> 09:09.680
which is open for enrollments right now.

09:09.680 --> 09:12.680
And the idea was really kind of the same thing.

09:12.680 --> 09:17.680
We wanted to help democratize data science, machine learning

09:17.680 --> 09:20.680
and give people also really this hands-on part, right?

09:20.680 --> 09:23.680
Both Chris and I are very passionate when we develop content to

09:23.680 --> 09:25.680
make it really a hands-on experience.

09:25.680 --> 09:29.680
So developers and builders can really work with the tools

09:29.680 --> 09:32.680
and get this learning right away.

09:32.680 --> 09:36.680
So this is a three course, 10 weeks specialization for Deep

09:36.680 --> 09:37.680
Learning AI.

09:37.680 --> 09:40.680
And we're going to show the learners really kind of how to get

09:40.680 --> 09:45.680
started the easy way that is doing exploratory data analysis

09:45.680 --> 09:50.680
and then also how to analyze the data for statistical

09:50.680 --> 09:54.680
imbalances and to leverage also automated machine learning.

09:54.680 --> 09:57.680
And this is kind of the first course, the easy start.

09:57.680 --> 10:01.680
And then we kind of build up a little bit the knowledge

10:01.680 --> 10:02.680
and the depth.

10:02.680 --> 10:06.680
So in the second course, we're diving deeper into building

10:06.680 --> 10:07.680
your custom models.

10:07.680 --> 10:11.680
So for example, running the feature engineering model training,

10:11.680 --> 10:15.680
tuning, and also starting building your pipelines.

10:15.680 --> 10:18.680
And then the third course, which is about to be released soon,

10:18.680 --> 10:22.680
will then talk about and show the advanced concepts

10:22.680 --> 10:25.680
of model training, distributed training, advanced model

10:25.680 --> 10:28.680
deployments, strategies, monitoring.

10:28.680 --> 10:32.680
And then also wrapping it up with how to build human

10:32.680 --> 10:33.680
in the loop pipelines.

10:33.680 --> 10:35.680
And we're super excited for this course.

10:35.680 --> 10:39.680
And also hope there's a lot of interest out there.

10:39.680 --> 10:40.680
Awesome.

10:40.680 --> 10:43.680
And Chris, who's the target audience for it?

10:43.680 --> 10:46.680
Is it someone who's just getting started or someone

10:46.680 --> 10:51.680
who's more advanced on their journey with building these pipelines?

10:51.680 --> 10:56.680
Yeah, the specialization, the prerex, really, you know,

10:56.680 --> 11:01.680
people who have been doing maybe local machine learning, right?

11:01.680 --> 11:06.680
Like local exploratory data analytics on their laptop.

11:06.680 --> 11:09.680
And now have reached a point where they need to scale out

11:09.680 --> 11:13.680
or they are starting to collect more and more data that either

11:13.680 --> 11:16.680
can't fit on their laptop or they're shared,

11:16.680 --> 11:18.680
like development server.

11:18.680 --> 11:20.680
And now they need to scale it out to the cloud.

11:20.680 --> 11:25.680
So really, it's, it is designed to show the benefits

11:25.680 --> 11:27.680
of doing machine learning in the cloud.

11:27.680 --> 11:30.680
And of course, there's a heavy focus on SageMaker pipelines,

11:30.680 --> 11:34.680
which was released December 2020 reinvents.

11:34.680 --> 11:37.680
We cover all the latest features up till now.

11:37.680 --> 11:41.680
And yeah, so really, you know,

11:41.680 --> 11:45.680
it's really sort of emphasizing scale and then ML ops automation.

11:45.680 --> 11:49.680
And what you'll find is if you're doing your own pipelines,

11:49.680 --> 11:52.680
there's quite a lot of Python scripts and bash scripts

11:52.680 --> 11:53.680
and a lot of things.

11:53.680 --> 11:58.680
And so the ability to really centralize that and to like integrate

11:58.680 --> 12:03.680
with the experiments part of SageMaker as well.

12:03.680 --> 12:07.680
All those pieces come together, lineage tracking, artifact tracking.

12:07.680 --> 12:10.680
And so that's really what it's for is, you know, people wanting

12:10.680 --> 12:15.680
to sort of leave the laptop or leave the sort of local environment.

12:15.680 --> 12:19.680
Yes, I'd love to hear from both of you.

12:19.680 --> 12:24.680
A bit on just how your perspective went into the course,

12:24.680 --> 12:28.680
or they are there specific, you know, things that you can think of

12:28.680 --> 12:32.680
or point to that were like hard one lessons out in the field

12:32.680 --> 12:36.680
that you're trying to give people a head start on

12:36.680 --> 12:38.680
by building them into the course.

12:38.680 --> 12:43.680
Does anything like that come to mind?

12:43.680 --> 12:46.680
Yeah, so I think a personal learning was,

12:46.680 --> 12:51.680
it's quite different to develop like a massive online course

12:51.680 --> 12:55.680
compared to, you know, just running a workshop for developers.

12:55.680 --> 12:58.680
So that was a personal learning for me, but really exciting,

12:58.680 --> 13:00.680
same with writing a book.

13:00.680 --> 13:04.680
It's just those experiences that you tap into and learn

13:04.680 --> 13:07.680
how to do things in a completely different way.

13:07.680 --> 13:11.680
I think for all the learners and machine learning practitioners

13:11.680 --> 13:15.680
out there, we really wanted to give them perspectives

13:15.680 --> 13:19.680
on the different ways to achieve the same goal.

13:19.680 --> 13:23.680
So what we're doing, for example, is we picked a use case,

13:23.680 --> 13:28.680
natural language processing and classifying product reviews,

13:28.680 --> 13:32.680
for example, into sentiment classes.

13:32.680 --> 13:35.680
And we've seen a lot of interest for our communities

13:35.680 --> 13:38.680
in natural language processing, in particular.

13:38.680 --> 13:41.680
So we decided to go for that use case

13:41.680 --> 13:44.680
and sticking to the same use case and then showing them

13:44.680 --> 13:47.680
how they can use the different tools.

13:47.680 --> 13:50.680
It doesn't always have to be the most complicated custom

13:50.680 --> 13:52.680
developed and trained model, right?

13:52.680 --> 13:54.680
Sometimes if it's a problem, you're trying to solve

13:54.680 --> 13:56.680
that has already been solved.

13:56.680 --> 14:00.680
There's probably easier ways you could use a pre-trained model

14:00.680 --> 14:02.680
for example, then just find you in it

14:02.680 --> 14:05.680
or even use pre-built algorithms to do it.

14:05.680 --> 14:10.680
And our goal was to really show the different options

14:10.680 --> 14:14.680
so people can build up this intuition

14:14.680 --> 14:18.680
how easy it can be to do AI and ML these days.

14:18.680 --> 14:20.680
And then also if you need to customize

14:20.680 --> 14:22.680
and go deeper and build your custom code,

14:22.680 --> 14:24.680
that there's also tooling available

14:24.680 --> 14:27.680
that helps you perform the tasks.

14:27.680 --> 14:30.680
That was a little bit what we hoped to get across

14:30.680 --> 14:32.680
and which was also fun in building the content

14:32.680 --> 14:36.680
to see how easy it is sometimes to achieve

14:36.680 --> 14:38.680
what you're trying to build.

14:38.680 --> 14:39.680
Nice.

14:39.680 --> 14:44.680
Yeah, I learned, I sort of have a new appreciation

14:44.680 --> 14:46.680
for these MOOCs, right?

14:46.680 --> 14:48.680
The massive online courses.

14:48.680 --> 14:51.680
I had actually built one back at Databricks.

14:51.680 --> 14:53.680
I was part of that effort.

14:53.680 --> 14:55.680
And I remember thinking back then

14:55.680 --> 14:57.680
that we completely underestimated

14:57.680 --> 14:59.680
how much time these things take, right?

14:59.680 --> 15:02.680
And so working with someone like deep learning, by the way,

15:02.680 --> 15:07.680
they completely raised the bar on this sort of overarching

15:07.680 --> 15:10.680
from course one to course two to course three

15:10.680 --> 15:13.680
and making sure that it's coherent

15:13.680 --> 15:19.680
and trying to make the slides and the script

15:19.680 --> 15:24.680
and the videos and the labs,

15:24.680 --> 15:29.680
all like coherence and down to,

15:29.680 --> 15:32.680
we had cases where some of our slides

15:32.680 --> 15:36.680
actually gave the solution that was being used in the lab.

15:36.680 --> 15:39.680
And so just all these little details have to be worked out.

15:39.680 --> 15:43.680
And we actually had two other people

15:43.680 --> 15:47.680
that were solution architects with AWS still there,

15:47.680 --> 15:50.680
of course, that were part of the launch.

15:50.680 --> 15:53.680
And so coordinating across just four of us,

15:53.680 --> 15:56.680
but then also a few curriculum developers on the deep learning

15:56.680 --> 15:59.680
AI side and some of the folks,

15:59.680 --> 16:02.680
like alpha testers beta testers from Coursera,

16:02.680 --> 16:03.680
it's a massive effort.

16:03.680 --> 16:06.680
And if you ever do decide to do one

16:06.680 --> 16:08.680
and want to do it with very high quality,

16:08.680 --> 16:10.680
you know, it takes a lot longer.

16:10.680 --> 16:13.680
I'd say probably three to four times longer

16:13.680 --> 16:15.680
than you might think.

16:15.680 --> 16:16.680
Oh, wow.

16:16.680 --> 16:19.680
Wow.

16:19.680 --> 16:22.680
We mentioned the book a few times as well.

16:22.680 --> 16:25.680
Chris, can you talk us through the book

16:25.680 --> 16:27.680
and how that came about in the relationship

16:27.680 --> 16:29.680
between the course and the book

16:29.680 --> 16:31.680
and some of the other things you're doing?

16:31.680 --> 16:32.680
Yeah.

16:32.680 --> 16:36.680
We call it the flywheel content strategy, you know?

16:36.680 --> 16:40.680
So we basically started with a GitHub repo.

16:40.680 --> 16:43.680
Yeah, Anchanai were, you know,

16:43.680 --> 16:47.680
like really trying to sort of start off

16:47.680 --> 16:49.680
with an end-to-end example.

16:49.680 --> 16:54.680
We then got the book deal, which, you know,

16:54.680 --> 16:57.680
so I've been trying to get a book deal

16:57.680 --> 17:00.680
with O'Reilly for about seven years, right?

17:00.680 --> 17:02.680
And yeah, finally got it.

17:02.680 --> 17:04.680
Yeah, so thanks to Anchan, right?

17:04.680 --> 17:06.680
And one thing that was really interesting

17:06.680 --> 17:10.680
about the book proposal process I found was

17:10.680 --> 17:14.680
it's very similar to a startup

17:14.680 --> 17:16.680
and to pitching your startup, right?

17:16.680 --> 17:19.680
Because keep in mind that when you approach a publisher,

17:19.680 --> 17:21.680
they're basically the investor.

17:21.680 --> 17:26.680
And they are, so they're actually putting up money

17:26.680 --> 17:28.680
because they have to pay for the editors

17:28.680 --> 17:31.680
and the, you know, figure drawers and all that.

17:31.680 --> 17:33.680
So they make the investment and then

17:33.680 --> 17:36.680
were the founders or the co-authors.

17:36.680 --> 17:39.680
And so, and so, fortunately,

17:39.680 --> 17:43.680
I had just had a startup right like before joining AWS.

17:43.680 --> 17:46.680
So I had already gone through the pitch process

17:46.680 --> 17:48.680
and fundraising process.

17:48.680 --> 17:51.680
And I literally used the 13, you know,

17:51.680 --> 17:54.680
slide deck like template and,

17:54.680 --> 17:58.680
and, you know, converted that into our proposal.

17:58.680 --> 18:00.680
Yeah, so it had total addressable market,

18:00.680 --> 18:02.680
which we had to look at, you know,

18:02.680 --> 18:04.680
SageMaker users and projected users

18:04.680 --> 18:07.680
and AI, ML in general.

18:07.680 --> 18:09.680
We had to look at like competitors,

18:09.680 --> 18:11.680
which in this case was competing books

18:11.680 --> 18:14.680
that were, were either written recently or, you know,

18:14.680 --> 18:17.680
being written that we knew about.

18:17.680 --> 18:20.680
We had to talk about us, the founders slash,

18:20.680 --> 18:23.680
like co-authors, you know, how we're backgrounds.

18:23.680 --> 18:26.680
So what is that competitive positioning of this book

18:26.680 --> 18:29.680
versus the others that are available out there?

18:29.680 --> 18:33.680
There are a lot of books on data science and AI out there.

18:33.680 --> 18:34.680
Sure.

18:34.680 --> 18:35.680
Sure.

18:35.680 --> 18:36.680
Yes.

18:36.680 --> 18:38.680
Aren't you do want to talk about that?

18:38.680 --> 18:41.680
Sure.

18:41.680 --> 18:43.680
So, yeah, we, and we thought a lot about rights.

18:43.680 --> 18:45.680
So, so where does, does the book fit in?

18:45.680 --> 18:47.680
And, and where do we want it to fit in?

18:47.680 --> 18:51.680
And what, what Chris mentioned is we wanted to show.

18:51.680 --> 18:54.680
Practitioners really this end to end approach right there.

18:54.680 --> 18:57.680
There's a lot of books that focus maybe on a specific implementation,

18:57.680 --> 19:00.680
a specific use case, a specific tool.

19:00.680 --> 19:04.680
And we wanted to give the ML practitioners kind of this end to end guidance.

19:04.680 --> 19:07.680
Really starting with discussions about in general,

19:07.680 --> 19:11.680
about use cases, how data science AI could maybe, you know,

19:11.680 --> 19:13.680
spark innovation and companies,

19:13.680 --> 19:17.680
sharing a couple of the use cases we see across the industry.

19:17.680 --> 19:20.680
And then where we're diving into this, how to get started, right?

19:20.680 --> 19:24.680
And again, kind of the easy way, maybe using available AI services

19:24.680 --> 19:27.680
that you can literally choose with it with an API call,

19:27.680 --> 19:29.680
integrate in your applications.

19:29.680 --> 19:32.680
And then, but if you need to build something custom,

19:32.680 --> 19:35.680
walking everyone through the individual steps.

19:35.680 --> 19:40.680
So we're starting with a discussion how to get the data into your environment,

19:40.680 --> 19:43.680
right into the AWS cloud in this example.

19:43.680 --> 19:47.680
And how to build maybe a data lake, what are the considerations?

19:47.680 --> 19:50.680
And then how to explore the data, prepare the data.

19:50.680 --> 19:52.680
And really this end the end approach.

19:52.680 --> 19:56.680
And we didn't really stop with deploying the model or building the pipelines.

19:56.680 --> 20:01.680
So we also decided to add another chapter specifically on how to work with streaming data.

20:01.680 --> 20:06.680
We got a lot of feedback from the developers in our communities,

20:06.680 --> 20:10.680
always asking us in the workshops, how do I do this with streaming data, right?

20:10.680 --> 20:12.680
Real-time data coming into my systems.

20:12.680 --> 20:14.680
What do I have to keep in mind there?

20:14.680 --> 20:17.680
So we decided to actually add another chapter on this.

20:17.680 --> 20:21.680
And then obviously we all have to build secure applications.

20:21.680 --> 20:26.680
So we also decided to add another chapter on how to build secure data science project.

20:26.680 --> 20:31.680
So I think back to your point, what sets this book apart is really this.

20:31.680 --> 20:37.680
And to end approach to showing how to get started discussing ideas, use cases,

20:37.680 --> 20:42.680
and then going into the how to and also discussing the concepts, right?

20:42.680 --> 20:46.680
So it's not just important to know how to to work with the tools,

20:46.680 --> 20:51.680
but obviously to to give it understanding of the overall concepts.

20:51.680 --> 20:58.680
For example, in the feature engineering section, we also talk about the idea of a feature store,

20:58.680 --> 21:03.680
which maybe some people haven't heard of yet or thought about implementing it.

21:03.680 --> 21:06.680
And then also as we evolve through the individual chapters,

21:06.680 --> 21:11.680
we talk about those great new concepts that are available and then show the practitioners

21:11.680 --> 21:15.680
how they can actually use the tools and implement them.

21:15.680 --> 21:26.680
Nice. And is the scenario that you discuss in the book, the same NLP scenario that you discuss in the course?

21:26.680 --> 21:29.680
Yeah, yeah, yeah.

21:29.680 --> 21:30.680
It's similar.

21:30.680 --> 21:36.680
We use a different data set and we used a slightly different NLP task.

21:36.680 --> 21:40.680
And we use a different variant of birth, I think, too, right?

21:40.680 --> 21:45.680
Yeah, yeah. And we use PyTorch instead of TensorFlow.

21:45.680 --> 21:56.680
So there's plenty of differences to if you have both that will cover quite a lot of ground.

21:56.680 --> 22:01.680
We don't cover streaming in the in the MOOC.

22:01.680 --> 22:04.680
So there's some differences there.

22:04.680 --> 22:07.680
We were able to go deeper with 500 pages.

22:07.680 --> 22:11.680
There's been a book, yes, versus just 10 weeks.

22:11.680 --> 22:20.680
But yeah, I should also, yes, I should also mention to that we actually ran a survey while we were writing the book.

22:20.680 --> 22:27.680
This is something else that like me and Anisha decided to do because like AWS is very customer focused.

22:27.680 --> 22:34.680
We actually wanted to hear, you know, from customers, what would you want to see in a book called Data Science on AWS?

22:34.680 --> 22:38.680
And we had, you know, six or seven questions.

22:38.680 --> 22:49.680
And it was everything from, you know, which technologies, which AI frameworks do, you know, like TensorFlow, PyTorch and MaxNet to streaming.

22:49.680 --> 22:54.680
Do you want use cases, which type of use cases? Do you want recommendations? Do you want time series?

22:54.680 --> 23:05.680
And that literally drove our outline. And so the original proposal actually that we gave to the O'Reilly folks changed quite a bit.

23:05.680 --> 23:08.680
And yeah, so they were great working with this trying to slot it in.

23:08.680 --> 23:12.680
But there's chapter two is like all about use cases.

23:12.680 --> 23:19.680
And that came directly from the community, right? They said, okay, that's great that you're doing this like NLP use case.

23:19.680 --> 23:27.680
But I want to learn more about computer vision. I want to learn more about recommendations. And so there's a whole chapter dedicated to.

23:27.680 --> 23:30.680
Yeah, it's all those top like use cases.

23:30.680 --> 23:37.680
Anisha, for the main scenario, talk us through a little bit more of the details there. Like what is the data set?

23:37.680 --> 23:44.680
What is the kind of the process that you're using the models that you're working with?

23:44.680 --> 23:50.680
Sure. So for the book, we decided as a framework to go with TensorFlow.

23:50.680 --> 23:59.680
And for the NLP use case, we use the product reviews data set to classify into into rating classes.

23:59.680 --> 24:05.680
And what we decided also is showing the practitioners different ways as I mentioned before.

24:05.680 --> 24:13.680
So we're using tools like automated machine learning to give practitioners like a way to get an easy start.

24:13.680 --> 24:19.680
And show them. You can just provide the data set and you know automated machine learning.

24:19.680 --> 24:26.680
We'll run analysis on the data, decide for framework and the model to use, train the model.

24:26.680 --> 24:31.680
And then percent with you, send you the best model candidates right away.

24:31.680 --> 24:36.680
So we found that is really, really interesting to see how to use those technologies.

24:36.680 --> 24:43.680
And then we're walking everyone through the custom step-by-step process.

24:43.680 --> 24:49.680
And for the custom model building, we actually decided to also include hacking space.

24:49.680 --> 24:58.680
Having space is a very popular open source NLP library, specifically built around the transformer based models.

24:58.680 --> 25:05.680
And this was actually one of the feedbacks also coming from the community being interested in the end of the space.

25:05.680 --> 25:09.680
So we decided to use a variant of the bird model.

25:09.680 --> 25:15.680
And in the book, we're using that is still bird variant that is optimized on this field.

25:15.680 --> 25:25.680
And we're showing everyone how to start working with that pretty trained model also to show them how powerful business in the meantime.

25:25.680 --> 25:28.680
And then we find unit to our data set.

25:28.680 --> 25:34.680
We also talk them obviously through the whole feature engineering process, how to create bird embeddings.

25:34.680 --> 25:53.680
We also learned quite a lot background on NLP models, bird specifically, how that got to the popularity in the industry really with the attention mechanisms and then show how to prepare the data around the feature engineering, create the embeddings, then find unit.

25:53.680 --> 26:13.680
We also show people how they can profile the model training in that process. So that's another exciting new concept and tooling that is available where you're able to monitor and profile while the training job is running and see how the underlying resources are utilized.

26:13.680 --> 26:25.680
For example, if you're running into any bottlenecks, it might be CPU bottlenecks or GPU bottlenecks. And this can help you right to to right size your infrastructure as well, specifically in the training process.

26:25.680 --> 26:36.680
And also you can capture tensors during the model training and do further analysis. You could visualize, for example, the attention that is building up through the model.

26:36.680 --> 26:52.680
I'm optimizing. So we're showing hyperparameter tuning how to optimize the model to you in the model. And then also we discuss a couple of different deployment strategies in the book. And yeah, this is one of my favorite ones, a Chris worked on the multi on band it on strategy.

26:52.680 --> 27:16.680
And I'm always excited every time I hear a talk about multi on bandits. I always learn something new. So that's a really exciting topic. I think personally. And then we wrap it up in the pipeline section where we show how to orchestrate all of those individual steps and and help to implement automation, whether it's get ups automation or other techniques.

27:16.680 --> 27:24.680
Chris, can you talk a little bit about that multi on band it piece as well as the ML ops chapter in the book.

27:24.680 --> 27:38.680
Yeah. So, so yeah, chapter nine was was all about deployment. And we cover AB tests, cover multi on band it. So, yeah, the ability to dynamically shift traffic.

27:38.680 --> 27:54.680
And so there's a reference architecture that is proposed in the book that is used by customers. There's a blog post on this as well, where we're using dynamo DB very, very lightweight to sort of track the

27:54.680 --> 28:12.680
the band it experiment results. And so as we're shifting traffic, we are figuring out which model is performing better live. That data is also being streamed with kinesis. And yes, all these pieces can be replaced with like Kafka manage Kafka anything.

28:12.680 --> 28:32.680
But a nice simple clean like architecture to do these multi on band it tests. The use case there was we had a model, a birth model that was trained one way to predict the class or the like multi class classification.

28:32.680 --> 28:50.680
If the review was positive neutral negative something like that. And then we use different hyper parameters for a slightly different model for the same use case and sort of pin them up against each other. And why you would want to use multi on band it's of course is you don't want to

28:50.680 --> 29:06.680
use a lot everybody into the lay a bucket. And so you'll find the sort of early winner. And then if that one's winning, you can send more traffic to that model variant.

29:06.680 --> 29:35.680
And then, but you're still exploring other options right like other models. And just in case there is a variant that is better than the like early variants we can actually continue to explore. And then if suddenly B is better than we could shift traffic over to B. So it's sort of an optimization for your AB test that minimizes any negative aspects of this overall test that you're doing in live production.

29:35.680 --> 29:38.680
Nice.

29:38.680 --> 29:57.680
You've mentioned a lot of technologies, a lot of AWS services. I've seen some of the architecture diagrams associated with your your previous workshop and you've got a lot of those services involved that you're orchestrating the build out, you know, one of these and pipelines.

29:57.680 --> 30:19.680
I'm wondering if, you know, how do you recommend folks manage the, you know, the complexity that comes with building real world projects and all of the different parts that you might want to use anything in particular that you've learned about doing that.

30:19.680 --> 30:37.680
You want to get to start it? Sure. So what I always recommend people is to think about what's the easiest way to achieve the goal. Right. And at AWS, we believe to let builders decide the right tool for the right job. Right.

30:37.680 --> 30:58.680
So depending on really your use case, your experience, you might go one path or the other. And I would recommend always using the easiest one, right. So as I explained earlier, if you're working on the problem that has been solved before, you might just need to translate language right from maybe English to German to Spanish.

30:58.680 --> 31:14.680
There are services available and models built that can do this. So the easiest way is maybe to look at is, is there any service that I can literally embed into my application with an API call, then I would definitely recommend starting there.

31:14.680 --> 31:38.680
If you need to build a little bit more custom models and you need a little bit more freedom, then I would definitely recommend looking at the Amazon Sage maker family of services and functionalities. So there have been a lot of additions to this managed service that is giving you basically the tools to build to train and to deploy models easily.

31:38.680 --> 31:53.680
And at the same time, it's taking care of the infrastructure for you. So it does the heavy lifting of managing individual instances, right. So you can really focus on on your tasks to to build models to train the models and to deploy them.

31:53.680 --> 32:08.680
And then for all of the expert practitioners that really want you to build neural networks themselves and have all of the freedom and flexibility. There's a lot of options also available on an infrastructure on framework basis.

32:08.680 --> 32:32.680
They could pick and choose, you know, maybe the latest GPU instances, if they need CPU architectures and then start building as they need. But again, depending on your use case and experience, always start looking for the easiest way to achieve it, because you want to focus on the business problem and normally less on on spending hours of hours of training and model, right.

32:32.680 --> 32:42.680
And as you go and customize, you can leverage additional services and additional tooling that is available.

32:42.680 --> 33:01.680
Anything you'd add to that, Chris. Yeah, Sam, you know, we work with a lot of customers and more recently, where, so back to the sort of a B testing multi-armed and a testing, you know, putting out one model, two models.

33:01.680 --> 33:19.680
You don't have a good automation strategy in place. That actually takes quite a while. And what you want to get to is the ability to try out, you know, many models, like hundreds of models, right. So typically we see people go from one single model to two and that's a big, big step.

33:19.680 --> 33:39.680
And then two to five. And what we're really trying to get people to try out is, you know, five to 10 and then 10 to 100. And people have enough variations, you know, for example, geo variations for your recommendations.

33:39.680 --> 33:52.680
Or, you know, different product categories will have different models. And so right now, people seem to be limited by the ability to get these models out there in an automated way and to auto scale.

33:52.680 --> 34:06.680
And like shift traffic dynamically. So seeing, seeing more and more models going out per customer is super exciting to us. We love that. And then seeing all of this automated and all the experiments being tracked.

34:06.680 --> 34:24.680
And I think I hear you saying that one of the things that you do is encourage customers to build multiple models because it's kind of a forcing function to building that automation that will, it's kind of a virtuous loop or cycle or something like that.

34:24.680 --> 34:37.680
And it kind of forces them to build the automation that will allow them to build more models.

34:37.680 --> 34:47.680
Right. Because it's often not easy to, or to value that automation when you just have one or two, which is why getting to five is kind of a big deal. And then, you know, trying to get from five to 50 and, you know, 50 to 500.

34:47.680 --> 35:04.680
Yeah. So trying to make that investment, which is something we've been trying to do with Sage maker pipelines, making that, that like investment much smaller, much easier, taking the exact same scripts that you're using Python script, C scripts, psychic learn, TensorFlow, PyTorch, whatever.

35:04.680 --> 35:21.680
And then getting those into production quickly, because you, you can't, or yes, oftentimes it's difficult to just evaluate the model in the research lab or, or on a single, you know, sort of enclosed environment.

35:21.680 --> 35:42.680
So like one thing we did at Netflix quite a bit was push these models into production live and that was our platform for experimentation was actually on live traffic, because you could do all the experimentation in with like historical data and get, you know, really, really close, but not until that models in production and you can look at the

35:42.680 --> 35:57.680
like prediction latencies and, you know, real real live traffic as data is changing, right, because the world's always changing. So the ability to just keep putting out new models and, you know, trying different experiments is very, very powerful.

35:57.680 --> 36:00.680
Nice, nice.

36:00.680 --> 36:21.680
We've also mentioned the ML summit recently, it was just yesterday as we're recording this, the videos will be available. I'm wondering if you have any recommendations for folks that are hearing this and want to dig in a little bit deeper into the summit content.

36:21.680 --> 36:41.680
Any any favorites from you? Yeah, I don't want to play favorites right. We had an action fact agenda yesterday. So we had a track dedicated to the signs of machine learning that is super, super interesting with a lot of very bright and smart people

36:41.680 --> 36:55.680
understanding on the different research science topics. And we also had a track that is focused more on how machine learning is done. And actually a couple of our colleagues also presented there.

36:55.680 --> 37:11.680
So if people want to learn more what I mentioned earlier, how to, for example, profile and debug your models. There was a great talk going into details how you can achieve this with a Sage maker debugger, for example.

37:11.680 --> 37:30.680
Also had a talk around NLP specifically. So how do I celebrate NLP training with Sage maker. And yeah, those are think the topics that I found very interesting. And then again, also the research trick, I think, had a lot of great insight.

37:30.680 --> 37:35.680
And yeah, Chris, what are your favorite topics?

37:35.680 --> 37:49.680
I'm trying to learn more and more about football, the soccer version of football. So there was a good talk on Bundesliga. So I pay very close attention to like the NFL talks because that's what I grew up with.

37:49.680 --> 37:58.680
But trying to keep an open mind, trying to be global, trying to learn why everyone likes soccer, still still haven't quite gotten there yet.

37:58.680 --> 38:15.680
And then my favorite track actually is called the how machine learning is done. So to me, this was a more, more on the, the like practical side.

38:15.680 --> 38:22.680
So talking about Jupiter notebooks and Sage maker studio and you know, some of the advancements happening there.

38:22.680 --> 38:44.680
The right algorithm for your use case. There's a really good talk about automated model tuning. And also one of our colleagues has this really good talk about computer vision and how to visualize what's happening.

38:44.680 --> 39:02.680
And you know, the attention that's happening and the like convolutional, like characteristics and what which kernels are being learned. And so using Sage maker debugger in more of a visual way, you know, versus just looking at the actual GPU metrics.

39:02.680 --> 39:22.680
Yes, I should also mention to Sage maker debugger has this, this new feature that is used for profiling. And so this falls under the like debugger service, but it's a feature that does really make recommendations and say, we think you should use a smaller instance type.

39:22.680 --> 39:40.680
Right. And like this blows my mind, right, that that we AWS would be suggesting to use a smaller instance, right. And really earns a lot of trust, I think with, with our customers, when you see those kind of recommendations, or saying that you are using too big of a GPU.

39:40.680 --> 39:52.680
Either, yes, increase batch size, maybe change the algorithm, make some small adjustments, because you're not fully utilizing the hardware that you've chosen. So yeah, really good talks.

39:52.680 --> 39:54.680
Nice, nice.

39:54.680 --> 40:16.680
Yeah, maybe kind of taking a step back from the books and the courses and the conference and all that stuff and thinking, you know, a little bit more broadly about kind of what you're seeing in the space with the customers you're working with and the communities you're involved in.

40:16.680 --> 40:26.680
I'm really curious, like, just what you're finding, you know, most interesting and exciting and where you think things are headed, aren't you anything jump out of you.

40:26.680 --> 40:45.680
Definitely, yeah. So I think I see two really exciting areas right now. So one is definitely the whole orchestration and automation piece. So how can I, you know, get from manually training, tuning, deploying the models to this more of an ML ops strategy, orchestration strategy automation.

40:45.680 --> 40:51.680
I think that's a very exciting field where many companies will will build their solutions.

40:51.680 --> 40:59.680
And the other area I think is also super exciting is how to make AI and ML even more accessible.

40:59.680 --> 41:03.680
And with that, I mean through and to end solutions, right.

41:03.680 --> 41:09.680
So, I mean, I'm a person I always get excited when there's a new tool I want to try out the tool.

41:09.680 --> 41:20.680
But ultimately, we need to solve, you know, our businesses use cases. And I think with AI services and ML services that are more targeted at a solution.

41:20.680 --> 41:35.680
Like, for example, AWS launched the new industrial machine learning services that are helping customers to implement, let's say predictive maintenance as a solution right instead of you have to go and train your individual model to recognize maybe product effects.

41:35.680 --> 41:54.680
And I think as SAI and data science evolves over the next years, it will be more and more of those solutions, hopefully coming and helping customers to even have a faster start to implement their own business use cases. So I'm super excited to see how that space evolves over the next years.

41:54.680 --> 41:58.680
What about you Chris?

41:58.680 --> 42:09.680
Yeah, I like the hardware aspects with with lookouts and I think it's called monotron.

42:09.680 --> 42:18.680
Some of the industrial stuff, like you mentioned, we cover some of that in the book that that came from the community.

42:18.680 --> 42:37.680
Other areas I've been looking at, you know, just more, more on the massive scale and just being able to point something to your data and, you know, this is something I really like about auto pilot our, like auto, our, like auto ML solution.

42:37.680 --> 42:54.680
You can really derive quite a lot and, you know, get pretty far right by just pointing to your data. So seeing some of that working closer with, like natural language data and some of the pre train models for computer vision.

42:54.680 --> 43:10.680
Just, you know, really not even thinking about like machine learning much anymore, you know, just like we don't really think much when we're building microservices, there's like tons of frameworks and very, very easy to do these days, you know, versus 10 years ago.

43:10.680 --> 43:28.680
At like Netflix 20 years ago at like Amazon, right, like 20, 25 years ago. So really just these things being, if you think of it like a drag and drop kind of widget or just, just like a right click and, you know, add recommendations here kind of thing.

43:28.680 --> 43:42.680
Awesome. Awesome. Well, Ancha and Chris, thanks so much for taking the time to share a bit about what you're up to. You've both been really busy.

43:42.680 --> 43:51.680
Looking forward to checking out the course and the book and more detail, but thanks so much for jumping on and sharing.

43:51.680 --> 44:02.680
It's really a pleasure. Yeah, this has been a lifelong dream for me was to be on this podcast. And yeah, there is a signed book that will be, I think it's going to arrive today.

44:02.680 --> 44:05.680
Awesome. Awesome. Thanks so much.

44:05.680 --> 44:21.680
Take care.

