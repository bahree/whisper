1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,720
I'm your host Sam Charrington.

4
00:00:31,720 --> 00:00:37,740
Today we're joined by Vladimir Bichovsky, engineering manager at Facebook to discuss Spiral,

5
00:00:37,740 --> 00:00:43,440
a system they've developed for self-tuning high-performance infrastructure services at scale,

6
00:00:43,440 --> 00:00:46,160
using real-time machine learning.

7
00:00:46,160 --> 00:00:51,520
In our conversation, we explore the ins and outs of Spiral, including how the system works,

8
00:00:51,520 --> 00:00:55,840
how it was developed, and how infrastructure teams at Facebook can use it to replace

9
00:00:55,840 --> 00:01:02,200
hand-tuned parameters set using heuristics with services that automatically optimize themselves

10
00:01:02,200 --> 00:01:04,960
in minutes rather than weeks.

11
00:01:04,960 --> 00:01:09,440
We also discussed the challenges of implementing these kinds of systems, how to overcome

12
00:01:09,440 --> 00:01:15,120
user skepticism, and how to achieve an appropriate level of explainability.

13
00:01:15,120 --> 00:01:17,360
Now on to the show.

14
00:01:17,360 --> 00:01:18,360
All right, everyone.

15
00:01:18,360 --> 00:01:21,400
I am on the line with Vlad Bichovsky.

16
00:01:21,400 --> 00:01:26,360
Vlad is an engineering manager with Facebook based out of the Boston office.

17
00:01:26,360 --> 00:01:28,960
Vlad, welcome to this week in machine learning and AI.

18
00:01:28,960 --> 00:01:29,960
Thank you.

19
00:01:29,960 --> 00:01:30,960
Thank you very much.

20
00:01:30,960 --> 00:01:32,360
It's very exciting to be here.

21
00:01:32,360 --> 00:01:37,520
So today we're going to be talking about a project that you have worked on called Spiral,

22
00:01:37,520 --> 00:01:42,160
but before we do that, I'd like to explore a little bit of your background.

23
00:01:42,160 --> 00:01:46,000
You did your graduate work on Image Enhancement.

24
00:01:46,000 --> 00:01:47,880
Tell us a little bit about that.

25
00:01:47,880 --> 00:01:48,880
That's correct.

26
00:01:48,880 --> 00:01:56,080
Actually, before that, I did a little bit of systems work as well, so I worked in wireless

27
00:01:56,080 --> 00:02:02,280
networking and then transitioned into computational photography primarily because I really enjoyed

28
00:02:02,280 --> 00:02:05,840
photography, and I wanted to learn more about it.

29
00:02:05,840 --> 00:02:12,840
So for my thesis, I worked on automatic image enhancement, which is the magic button that

30
00:02:12,840 --> 00:02:18,680
people have on their phones, or actually, the algorithm I developed is now in Adobe Photoshop.

31
00:02:18,680 --> 00:02:23,960
If you dig deep into the menus, you could automatically set curves, and that's the algorithm

32
00:02:23,960 --> 00:02:27,200
that I built during my thesis.

33
00:02:27,200 --> 00:02:30,960
So yeah, and then after I finished my PhD, I joined Facebook.

34
00:02:30,960 --> 00:02:31,960
Nice.

35
00:02:31,960 --> 00:02:34,240
And what group are you in in Facebook?

36
00:02:34,240 --> 00:02:40,480
The group is called Machine Learning Experience, and it's the goal of our group is to basically

37
00:02:40,480 --> 00:02:44,320
deliver the benefits of machine learning for everybody.

38
00:02:44,320 --> 00:02:49,320
Generally, machine learning is kind of thought of as kind of this elite field for only people

39
00:02:49,320 --> 00:02:54,920
with incredibly strong backgrounds can contribute or even use, whereas what we're trying to do

40
00:02:54,920 --> 00:02:59,840
is kind of democratize machine learning so that every engineer can Facebook can benefit

41
00:02:59,840 --> 00:03:01,160
from it.

42
00:03:01,160 --> 00:03:10,240
Okay, and the specific project that you're working on is one called spiral that your group

43
00:03:10,240 --> 00:03:12,080
disclosed recently.

44
00:03:12,080 --> 00:03:13,920
Tell us a little bit about that project.

45
00:03:13,920 --> 00:03:14,920
Sure.

46
00:03:14,920 --> 00:03:16,960
Yeah, this is actually, I think it's a very exciting project.

47
00:03:16,960 --> 00:03:19,600
I'm glad to be part of it.

48
00:03:19,600 --> 00:03:24,040
So I think I thought it for a while about how to describe what we do, just the people who

49
00:03:24,040 --> 00:03:28,800
are not necessarily deep in computer science, and I think the best analogy is the following.

50
00:03:28,800 --> 00:03:35,880
So if you think about, for example, like coffee drinking habits, so we all want to sleep

51
00:03:35,880 --> 00:03:39,800
at night at the same time people do enjoy their coffee.

52
00:03:39,800 --> 00:03:45,400
And if you have to make a decision, do I drink coffee at 3 p.m. or not, right?

53
00:03:45,400 --> 00:03:49,880
You can do a bunch of experience where you drink coffee at 3 and then see if you can

54
00:03:49,880 --> 00:03:52,560
fall asleep at night, right?

55
00:03:52,560 --> 00:03:56,520
And based on the result, you kind of adjust what was the right call, like for example,

56
00:03:56,520 --> 00:04:01,600
I drink my coffee, then I can't fall asleep, okay, I record the outcome.

57
00:04:01,600 --> 00:04:07,560
And then the same thing next day, maybe I don't drink coffee after 3 p.m. and I fall asleep

58
00:04:07,560 --> 00:04:08,560
fine, right?

59
00:04:08,560 --> 00:04:13,440
And so if you kind of build up the data set and you kind of define a policy for yourself,

60
00:04:13,440 --> 00:04:18,080
you learn a policy which is I shouldn't be drinking coffee after 3, right?

61
00:04:18,080 --> 00:04:23,720
So the same kind of thing can be done for machines where you can literally in sort of

62
00:04:23,720 --> 00:04:27,760
in this environment where everything around you is changing all the time, you could kind

63
00:04:27,760 --> 00:04:30,520
of see the results of your actions.

64
00:04:30,520 --> 00:04:34,120
And you could see in retrospect whether or not the actions the machine has taken were

65
00:04:34,120 --> 00:04:39,200
good or bad and informed future decisions, does that make sense?

66
00:04:39,200 --> 00:04:44,720
So that is a really, really good explanation and example.

67
00:04:44,720 --> 00:04:48,600
And I think you may have just derailed the interview because the thing you just described,

68
00:04:48,600 --> 00:04:50,640
I really think it needs to exist.

69
00:04:50,640 --> 00:04:55,040
I've wanted the quantified self movement, I don't know if people even talk about this

70
00:04:55,040 --> 00:05:02,560
anymore, quantified self, but I've wanted this thing that just like tracks your, you

71
00:05:02,560 --> 00:05:08,040
can set up some metrics and track data points and then it applies machine learning to figure

72
00:05:08,040 --> 00:05:16,960
out the correlation between your actions and these other experiences you have, whether

73
00:05:16,960 --> 00:05:22,240
it's health or happiness or what have you.

74
00:05:22,240 --> 00:05:27,920
It automatically uses this data that you collect to make predictions as opposed to what

75
00:05:27,920 --> 00:05:34,600
quantified self really ever amounted to is providing like pretty pictures of the past,

76
00:05:34,600 --> 00:05:39,920
like the rear view mirror as opposed to the dashboard.

77
00:05:39,920 --> 00:05:44,760
And I can tell you more about why it's so important for Facebook or generally I think

78
00:05:44,760 --> 00:05:49,760
any company of that scale or any company wants to scale if you're interested.

79
00:05:49,760 --> 00:05:54,760
Well, so it sounds like you're not going to let me derail the interview by talking about

80
00:05:54,760 --> 00:06:03,320
applying this to quantified self, which is good, which is good, but it sounds like a set

81
00:06:03,320 --> 00:06:12,440
of problems that you can maybe loosely or roughly refer to as, I don't think there

82
00:06:12,440 --> 00:06:20,800
is low level as infrastructure management, but you're kind of using them to manage the

83
00:06:20,800 --> 00:06:24,360
way you configure.

84
00:06:24,360 --> 00:06:30,160
You have not low level infrastructure like high level software and kind of the deployment

85
00:06:30,160 --> 00:06:36,640
architecture of actually, I don't think deployment architecture is the right term either,

86
00:06:36,640 --> 00:06:43,160
but the configuration of software components that are driving various Facebook applications.

87
00:06:43,160 --> 00:06:45,200
Yeah, yeah, that's right.

88
00:06:45,200 --> 00:06:51,360
So another way, with the way I call it internally, it's more formally, it's automatic, adaptive

89
00:06:51,360 --> 00:06:52,680
policy, right?

90
00:06:52,680 --> 00:06:59,200
So it's automatic policy learning where instead of usually people define policies like coffee

91
00:06:59,200 --> 00:07:05,480
drinking policy or cash admission policy in terms of some sort of heuristic, right?

92
00:07:05,480 --> 00:07:09,840
They sort of look at like, oh, well, let's look at arrival times, let's look at something

93
00:07:09,840 --> 00:07:15,200
else and let's have a bunch of if else statements where we define the behavior.

94
00:07:15,200 --> 00:07:17,400
And that's generally, it generally works pretty well.

95
00:07:17,400 --> 00:07:22,040
There's nothing wrong with that approach in normal circumstances.

96
00:07:22,040 --> 00:07:27,320
I think the biggest challenge for the list comes up when you actually start going sort

97
00:07:27,320 --> 00:07:33,120
of at a much higher speed, specifically think about Facebook and this was published on

98
00:07:33,120 --> 00:07:42,520
their engineering blog, while back, Facebook is releasing a new version of web source code

99
00:07:42,520 --> 00:07:43,520
every hour.

100
00:07:43,520 --> 00:07:48,840
So literally, the version of Facebook you see is different from an hour to hour.

101
00:07:48,840 --> 00:07:54,480
So the code that runs it is changing and any system that depends on the code and makes

102
00:07:54,480 --> 00:07:58,920
assumptions about this code can potentially be outdated within hours.

103
00:07:58,920 --> 00:08:05,480
So if you think about sort of dub, dub, dub, or the web of Facebook being a dependency,

104
00:08:05,480 --> 00:08:10,520
it's something you kind of think it should behave a certain way if you if your service depends

105
00:08:10,520 --> 00:08:11,680
on it.

106
00:08:11,680 --> 00:08:13,880
And then every hour, it's actually changing.

107
00:08:13,880 --> 00:08:18,480
So whatever assumptions you made about how behaves may be completely invalid and not

108
00:08:18,480 --> 00:08:24,080
just invalid at sort of some sort of slow rate, literally every hour, it could be different.

109
00:08:24,080 --> 00:08:30,240
And so in that environment, it's very, very hard to sort of keep pace and update your code,

110
00:08:30,240 --> 00:08:33,440
update your logic of your service to stay optimal.

111
00:08:33,440 --> 00:08:37,760
So it's literally, this is not like some mechanism that we're just implemented because

112
00:08:37,760 --> 00:08:39,920
it's cool and we wanted to do it.

113
00:08:39,920 --> 00:08:45,280
It's literally a necessity to be able to run something at this scale and run it efficiently.

114
00:08:45,280 --> 00:08:48,720
So I'll give you an example of over cash, for example.

115
00:08:48,720 --> 00:08:54,160
If you have cash that's caching images, it could be movies, it could be anything else.

116
00:08:54,160 --> 00:09:00,440
And let's say that in the past, people have uploaded mostly PNG files and we cashed them

117
00:09:00,440 --> 00:09:03,240
and for PNG files, we may choose a certain limit.

118
00:09:03,240 --> 00:09:07,960
If the file is PNG file and is less than certain size, let's cash it.

119
00:09:07,960 --> 00:09:11,840
If it's too big, let's not cash it, vice versa, et cetera, they could sort of find a policy

120
00:09:11,840 --> 00:09:14,040
by hand with their statements.

121
00:09:14,040 --> 00:09:18,960
And then a little bit later, users are not uploading PGs anymore, they're mostly uploading

122
00:09:18,960 --> 00:09:19,960
JPEGs.

123
00:09:19,960 --> 00:09:20,960
Right?

124
00:09:20,960 --> 00:09:25,280
The policy you have written is completely useless because you're not caching any JPEG files

125
00:09:25,280 --> 00:09:28,400
and your system performs very poorly, right?

126
00:09:28,400 --> 00:09:32,240
So somebody has to go in and manually recode this.

127
00:09:32,240 --> 00:09:36,640
Somebody has to notice that metrics are out of auto-wack and has to recode it by hand,

128
00:09:36,640 --> 00:09:37,880
which is not sustainable.

129
00:09:37,880 --> 00:09:38,880
Right?

130
00:09:38,880 --> 00:09:40,920
Giving her things, how fast things are changing.

131
00:09:40,920 --> 00:09:44,400
And so what we do instead, something that spiraling can actually learn the optimal policy

132
00:09:44,400 --> 00:09:49,520
on the fly as the changes are occurring, as the changes in load are happening.

133
00:09:49,520 --> 00:09:58,200
So you're talking about learning the policy on the fly and that makes me think about techniques

134
00:09:58,200 --> 00:09:59,960
like active learning.

135
00:09:59,960 --> 00:10:07,600
Is that formally something that you've employed here or is it an adjacent area?

136
00:10:07,600 --> 00:10:08,600
It's related.

137
00:10:08,600 --> 00:10:12,840
If you say active learning is something we can do, it's something that we do in some

138
00:10:12,840 --> 00:10:18,600
other contexts, currently we don't do active learning inside spiral, that's not really

139
00:10:18,600 --> 00:10:19,600
necessary.

140
00:10:19,600 --> 00:10:23,480
So active learning is more about choosing examples to train on, right?

141
00:10:23,480 --> 00:10:27,640
So to be more specific, imagine if you're doing medical experiments, right?

142
00:10:27,640 --> 00:10:31,400
And you're doing some sort of experiments using new drugs or something like that.

143
00:10:31,400 --> 00:10:36,520
If you, and you're trying to figure out which combination of drugs works better, right?

144
00:10:36,520 --> 00:10:41,200
And each experiment costs you a lot of money to run, like it's literally not free, right?

145
00:10:41,200 --> 00:10:44,640
In this case, you can just say, okay, let me take a bunch of combinations and see which

146
00:10:44,640 --> 00:10:49,760
one works out, what you want to do is you want to take all previous experiments into account

147
00:10:49,760 --> 00:10:55,120
and figure out which combination to try next that gives you the most information, right?

148
00:10:55,120 --> 00:10:57,600
To kind of gains you the most information.

149
00:10:57,600 --> 00:11:03,200
In our case, it's, that's not the setup we have, but this applies in some other situations

150
00:11:03,200 --> 00:11:06,560
such as automatic configuration of services.

151
00:11:06,560 --> 00:11:10,800
So this is kind of looking a little bit forward, but something we're looking into sort of in

152
00:11:10,800 --> 00:11:18,440
the same vein of self maintaining services or self optimizing services is self tuning fleets.

153
00:11:18,440 --> 00:11:23,400
So if you think about a number of parameters that a given service has, it's actually very

154
00:11:23,400 --> 00:11:28,000
large and it's actually often not clear how to set them, especially if the environment

155
00:11:28,000 --> 00:11:29,000
is changing.

156
00:11:29,000 --> 00:11:34,800
It could be numbers such as number threads or sizes of queues, et cetera, right?

157
00:11:34,800 --> 00:11:39,480
And what is the optimal setting today, maybe different from the optimal setting tomorrow?

158
00:11:39,480 --> 00:11:45,120
And so what you want to do is you could use some of the machines in your fleet for experimentation,

159
00:11:45,120 --> 00:11:50,800
figure out which of them results in a better QPS, like the number of requests per second,

160
00:11:50,800 --> 00:11:51,800
right?

161
00:11:51,800 --> 00:11:53,880
And pick those parameters.

162
00:11:53,880 --> 00:11:57,840
And ideally you do this continuously and so this is exactly where active learning is

163
00:11:57,840 --> 00:12:03,120
very useful because you don't want to use lots of machines, sort of waste resources.

164
00:12:03,120 --> 00:12:07,800
You want to focus on the next combination of parameters that's more likely to be better

165
00:12:07,800 --> 00:12:09,040
than the current one.

166
00:12:09,040 --> 00:12:10,040
Does that make sense?

167
00:12:10,040 --> 00:12:15,520
Now, that does make sense and there's definitely this kind of sense or definition of active

168
00:12:15,520 --> 00:12:24,400
learning that's focused on trying to identify the training data, for example, that increase

169
00:12:24,400 --> 00:12:29,520
information gain so that you can reduce your overall costs of training.

170
00:12:29,520 --> 00:12:36,400
But there's also this sense, or I could be just, you know, I could be confusing ideas,

171
00:12:36,400 --> 00:12:40,920
but I also get the sense of active learning or think of it in the context of like incremental

172
00:12:40,920 --> 00:12:45,360
learning, meaning you get a piece of, you've got a trained model.

173
00:12:45,360 --> 00:12:50,880
And then you get a piece of data, you know, labeled data incrementally without going

174
00:12:50,880 --> 00:12:54,000
through an entire retraining, you're using that to enhance your model.

175
00:12:54,000 --> 00:12:56,480
Was there a better name for that than active learning?

176
00:12:56,480 --> 00:12:59,400
Yeah, the better name for that is online learning.

177
00:12:59,400 --> 00:13:00,400
Okay.

178
00:13:00,400 --> 00:13:01,400
So it's kind of like streaming.

179
00:13:01,400 --> 00:13:06,400
So if you think of streaming databases, so online learning is the form of kind of learning

180
00:13:06,400 --> 00:13:08,240
that's streaming, right?

181
00:13:08,240 --> 00:13:11,800
And that's actually exactly what we use for our system.

182
00:13:11,800 --> 00:13:15,240
And the main benefit of it in practice is feedback loops.

183
00:13:15,240 --> 00:13:21,160
So it's something actually machine learning researchers rarely think about, but as an engineer

184
00:13:21,160 --> 00:13:27,520
trying to just let's say enable adaptive policy in my service, I don't really want to spend

185
00:13:27,520 --> 00:13:32,160
time setting up a pipeline and finding out to more than I made some sort of mistake,

186
00:13:32,160 --> 00:13:33,160
right?

187
00:13:33,160 --> 00:13:37,760
Because it takes a while to do the training and then to shift the data and to get me back

188
00:13:37,760 --> 00:13:38,760
the model.

189
00:13:38,760 --> 00:13:41,160
It's, it's a very difficult feedback loop.

190
00:13:41,160 --> 00:13:45,520
So if I'm debugging something, it's, it's just not really acceptable, right?

191
00:13:45,520 --> 00:13:50,280
So if I'm training a huge neural network somewhere on the back end, it's, it's just difficult.

192
00:13:50,280 --> 00:13:54,960
So literally, imagine if you were trying to write a program and every time you compile,

193
00:13:54,960 --> 00:13:56,640
you have to wait a day, right?

194
00:13:56,640 --> 00:13:58,160
Realistically, we would not get anywhere.

195
00:13:58,160 --> 00:13:59,160
So, right.

196
00:13:59,160 --> 00:14:03,600
So the online model is actually really helping this case because with, with our system,

197
00:14:03,600 --> 00:14:08,160
one of the modes of operation is that when it's fully embedded and online, which means

198
00:14:08,160 --> 00:14:13,920
you literally plug it in, there's, it's actually two call sites and you plug in the data

199
00:14:13,920 --> 00:14:16,720
and you literally run your service.

200
00:14:16,720 --> 00:14:20,240
And as soon as your service starts running and providing feedback, you can start running

201
00:14:20,240 --> 00:14:21,240
and start seeing the results.

202
00:14:21,240 --> 00:14:24,800
You can start seeing the results improve, but you could see, oh, maybe I'm missing an

203
00:14:24,800 --> 00:14:25,800
important feature.

204
00:14:25,800 --> 00:14:29,760
Maybe it's, I'm misclassifying something, immediately change it, run it again and you're

205
00:14:29,760 --> 00:14:30,760
good to go.

206
00:14:30,760 --> 00:14:32,360
You can see the results immediately.

207
00:14:32,360 --> 00:14:38,000
So that's, that is exactly where online learning is very, very beneficial in practice,

208
00:14:38,000 --> 00:14:39,000
right?

209
00:14:39,000 --> 00:14:42,600
So in theory, people often talk about, oh, well, maybe you can't do quite as well online

210
00:14:42,600 --> 00:14:43,600
as you can do offline.

211
00:14:43,600 --> 00:14:47,960
Well, when you have all the data, something we're doing is we're kind of combining the

212
00:14:47,960 --> 00:14:53,880
best of both worlds, online learning is used to enable really, really tight feedback loops

213
00:14:53,880 --> 00:14:57,680
because it's, to me, this is probably the most important thing in engineering.

214
00:14:57,680 --> 00:15:01,800
If you're building something, you want to know how well it's doing, right?

215
00:15:01,800 --> 00:15:05,560
You want to know how well it's doing right now, not, not three days from now because

216
00:15:05,560 --> 00:15:09,280
you may lose context, you'll forget what you're doing, what you're trying to do, et cetera,

217
00:15:09,280 --> 00:15:10,280
et cetera.

218
00:15:10,280 --> 00:15:12,760
And this is something our system enables.

219
00:15:12,760 --> 00:15:16,360
When you're in the steady state, when you really figured out your features, you debunked

220
00:15:16,360 --> 00:15:20,320
your system, everything is good, now it's more about, okay, and then get a better, higher

221
00:15:20,320 --> 00:15:22,680
accuracy for my predictions.

222
00:15:22,680 --> 00:15:26,400
Then you can switch the offline learning mode and sort of, because the system was already

223
00:15:26,400 --> 00:15:27,400
debunked.

224
00:15:27,400 --> 00:15:31,640
And then you just improve your accuracy by using potentially larger model and more models

225
00:15:31,640 --> 00:15:33,200
and more complicated models.

226
00:15:33,200 --> 00:15:35,040
Does that make sense?

227
00:15:35,040 --> 00:15:42,680
The curse of me that I tend to think of the, that transition is being the opposite direction,

228
00:15:42,680 --> 00:15:51,160
meaning that you start with an offline train model and you use online learning to keep

229
00:15:51,160 --> 00:15:53,040
that model updated.

230
00:15:53,040 --> 00:15:57,240
But what you've done is you've kind of flipped that and you're using offline or rather

231
00:15:57,240 --> 00:16:07,320
online learning as a way to bootstrap very quickly and without requiring the model creators

232
00:16:07,320 --> 00:16:15,640
to understand the environment as well, collect the data, do all the feature engineering

233
00:16:15,640 --> 00:16:21,040
that they can do when they have that data and understand the environment.

234
00:16:21,040 --> 00:16:31,800
And then use the information from the online learning models that you've created to create

235
00:16:31,800 --> 00:16:36,000
incrementally better models by doing batch training.

236
00:16:36,000 --> 00:16:38,920
Yeah, that's exactly right, yeah.

237
00:16:38,920 --> 00:16:44,840
And so the challenge is always, so unlike traditional data sets, when you actually know what

238
00:16:44,840 --> 00:16:51,080
your features are or have complete data set, when we're talking about system generalists

239
00:16:51,080 --> 00:16:57,200
trying to optimize the system using machine learning, they don't necessarily know the features

240
00:16:57,200 --> 00:16:58,360
ahead of time, right?

241
00:16:58,360 --> 00:16:59,360
There's no data set.

242
00:16:59,360 --> 00:17:04,760
They're still trying to figure out, okay, is file size important for my caching policy?

243
00:17:04,760 --> 00:17:09,400
Maybe not, is the name of the data center from which this data comes in from?

244
00:17:09,400 --> 00:17:10,400
Is that important?

245
00:17:10,400 --> 00:17:11,400
Should I add that?

246
00:17:11,400 --> 00:17:12,400
Should I not add that?

247
00:17:12,400 --> 00:17:17,320
And in some respect, there is no, there's no, there's no data set before you start collecting

248
00:17:17,320 --> 00:17:18,320
it, right?

249
00:17:18,320 --> 00:17:22,320
It sort of assumes you say, oh, I should probably add file size, I should probably add

250
00:17:22,320 --> 00:17:23,320
something.

251
00:17:23,320 --> 00:17:27,360
Then then you create the data set, but it's really up to the engineer to plug it in, right?

252
00:17:27,360 --> 00:17:31,920
It doesn't come prepackaged as a set of benchmark of like, okay, here's a bunch of images

253
00:17:31,920 --> 00:17:35,880
and here's a bunch of labels, here's a cat and here's a dog, right?

254
00:17:35,880 --> 00:17:40,120
It's sort of part of the problem is that people are trying to understand their problem and

255
00:17:40,120 --> 00:17:44,400
trying to define it as they're solving it, right?

256
00:17:44,400 --> 00:17:49,600
And this is actually one of the probably biggest challenges for us in sort of something I find

257
00:17:49,600 --> 00:17:56,120
really, really exciting about this field is that we get to change how people think, literally.

258
00:17:56,120 --> 00:18:00,880
So when engineers, traditional engineers come to us with problems, they sort of, they

259
00:18:00,880 --> 00:18:05,560
always sort of think in terms of those fixed policies or sort of heuristics and picking

260
00:18:05,560 --> 00:18:10,880
some sort of thresholds for things and when we start working with them, their mind opens

261
00:18:10,880 --> 00:18:15,200
up and they realize that they can apply this whole slew of statistical methods to a problem

262
00:18:15,200 --> 00:18:18,560
which they considered very, very rigid.

263
00:18:18,560 --> 00:18:23,400
And so to me, that's just like one of those seeing those aha moments is really exciting.

264
00:18:23,400 --> 00:18:27,720
And oftentimes what happens next is that people realize that there's a whole bunch of new

265
00:18:27,720 --> 00:18:32,960
features that they could enable by switching to using a statistical approach from sort of

266
00:18:32,960 --> 00:18:33,960
a rigid heuristic.

267
00:18:33,960 --> 00:18:39,040
So there's kind of a bunch of really cool side benefits that come from learning more about

268
00:18:39,040 --> 00:18:41,800
how to apply systems like that.

269
00:18:41,800 --> 00:18:48,800
And so practically speaking, if I'm developing a system, say a caching system, one of the

270
00:18:48,800 --> 00:18:54,440
first things I might do in my system is pull a bunch of configuration information from,

271
00:18:54,440 --> 00:19:02,960
you know, environment variables or configuration files or what have you instead using spiral

272
00:19:02,960 --> 00:19:10,640
I'm calling an API to give me the kind of current best version of those configuration

273
00:19:10,640 --> 00:19:11,640
parameters.

274
00:19:11,640 --> 00:19:12,640
Is that correct?

275
00:19:12,640 --> 00:19:14,640
Yeah, almost.

276
00:19:14,640 --> 00:19:17,080
So in some respect, there's two ways to think about it.

277
00:19:17,080 --> 00:19:22,000
So if you think of a complete clean slate where your system puts up for the first time

278
00:19:22,000 --> 00:19:27,480
and we've never, spiral never has seen any data, so something that, and then you ask

279
00:19:27,480 --> 00:19:31,960
spiral for predictions for a given, for a given item that comes in, like do I cache

280
00:19:31,960 --> 00:19:36,200
this, do I not cache this, the spiral will just return the default value that you assigned

281
00:19:36,200 --> 00:19:39,280
because it has no information at this point.

282
00:19:39,280 --> 00:19:42,880
But as soon as your system starts providing feedback, as soon as you say, oh, I should

283
00:19:42,880 --> 00:19:46,720
have cache this item, oh, I should not have cache this item, and as soon as you start

284
00:19:46,720 --> 00:19:51,880
putting this information in, the next prediction that you ask will be better.

285
00:19:51,880 --> 00:19:58,880
And so all you need to do is just pull the information at the time when you know what

286
00:19:58,880 --> 00:20:00,840
decision should have been made, right?

287
00:20:00,840 --> 00:20:04,520
So when you're sort of on, for cache, it may be at eviction time when you're evicting

288
00:20:04,520 --> 00:20:10,280
an item and nobody has ever requested their item, you could say, well, I probably shouldn't

289
00:20:10,280 --> 00:20:11,840
have cache this, right?

290
00:20:11,840 --> 00:20:15,960
If it's like it wasn't necessary, like nobody asked for it, and vice versa, if you see

291
00:20:15,960 --> 00:20:19,920
an item that's been hit many, many times, you're like, okay, definitely next time I see something

292
00:20:19,920 --> 00:20:21,840
like this, I should cache it.

293
00:20:21,840 --> 00:20:22,840
Yeah.

294
00:20:22,840 --> 00:20:28,960
I think you just pointed out an important distinction, and that is spiral is not predicting

295
00:20:28,960 --> 00:20:36,960
for me the underlying configuration parameters that I might use to make a decision.

296
00:20:36,960 --> 00:20:43,000
It's predicting the decision, meaning it's not predicting, I'm not using it to tell

297
00:20:43,000 --> 00:20:48,760
me, you know, what queue length or, you know, how much JVM memory I might need or something

298
00:20:48,760 --> 00:20:56,440
like that, it's operating at a higher level and it is managing all those parameters under

299
00:20:56,440 --> 00:20:57,440
the covers.

300
00:20:57,440 --> 00:20:58,440
Is that correct?

301
00:20:58,440 --> 00:21:02,720
Indirectly, yes, it's managing the parameters of your policy, right?

302
00:21:02,720 --> 00:21:07,920
So for example, if you had a threshold before, if I should not cache images that are larger

303
00:21:07,920 --> 00:21:09,600
than 100 kilobytes, right?

304
00:21:09,600 --> 00:21:13,560
So you kind of had this 100 kilobyte parameter, and then you're like, well, maybe it should

305
00:21:13,560 --> 00:21:16,400
change it to 70 or 120, right?

306
00:21:16,400 --> 00:21:20,880
So and then you look at the quality of decisions, say, oh, yeah, 120 is way better, looks

307
00:21:20,880 --> 00:21:25,080
like I get a better cache hit rate or something, right?

308
00:21:25,080 --> 00:21:27,000
So that's taken away.

309
00:21:27,000 --> 00:21:31,080
So if you were trying to configure a policy, you no longer have to do that.

310
00:21:31,080 --> 00:21:37,800
You just provide examples of correct decisions, and spiral, spiral learns the rest of it.

311
00:21:37,800 --> 00:21:41,840
The tuning of parameters of a service is sort of a different project we're doing, which

312
00:21:41,840 --> 00:21:46,680
is kind of moving, looking forward at the things we're interested in.

313
00:21:46,680 --> 00:21:51,960
So we could tune the number of threads, but the setup is a little bit different than spiral.

314
00:21:51,960 --> 00:21:57,920
So in that setup, what you would do is you would provide statistics of how well the services

315
00:21:57,920 --> 00:22:02,920
operating as a whole with a set of parameters, and we would look at those statistics and

316
00:22:02,920 --> 00:22:08,440
let's say the number of requests per second that the service is providing with a given

317
00:22:08,440 --> 00:22:09,960
configuration.

318
00:22:09,960 --> 00:22:14,120
And we would compare it to other experience we have ran, and then using active learning

319
00:22:14,120 --> 00:22:16,040
would pick the next experiment.

320
00:22:16,040 --> 00:22:22,320
Okay, sounds like the queue size of 100 looks better than 110, let's try 90, right?

321
00:22:22,320 --> 00:22:26,960
And that all happens behind the covers, so under the covers and the engineer never has

322
00:22:26,960 --> 00:22:27,960
to see it.

323
00:22:27,960 --> 00:22:32,280
In the end, what they get is, oh, it looks like currently you get the highest number of

324
00:22:32,280 --> 00:22:38,960
requests per second if you use the queue length of 35 and the number of threads 15, right?

325
00:22:38,960 --> 00:22:43,160
And now you just set the two service and all of a sudden your utilization drops.

326
00:22:43,160 --> 00:22:46,520
You consume much less energy and you're serving many more requests.

327
00:22:46,520 --> 00:22:47,520
Got it.

328
00:22:47,520 --> 00:22:48,520
Got it.

329
00:22:48,520 --> 00:22:50,440
But that's a separate future project.

330
00:22:50,440 --> 00:22:51,440
That's correct.

331
00:22:51,440 --> 00:22:52,440
Yes.

332
00:22:52,440 --> 00:23:01,560
So then with spiral, imagining that, and you alluded to this, that engineers might have

333
00:23:01,560 --> 00:23:09,920
previously envisioned very simple policies for different aspects of their systems, for

334
00:23:09,920 --> 00:23:15,880
example, you know, cash based on file size or cash based on file type.

335
00:23:15,880 --> 00:23:25,920
And now by being able to specify these policies more declaratively, they, there's also a tendency

336
00:23:25,920 --> 00:23:28,200
to make the policies richer.

337
00:23:28,200 --> 00:23:29,200
Is that the case?

338
00:23:29,200 --> 00:23:33,280
Yes, it's sort of a very easy way.

339
00:23:33,280 --> 00:23:35,040
It's formalizing the problem, right?

340
00:23:35,040 --> 00:23:36,760
So you use exactly the right language.

341
00:23:36,760 --> 00:23:41,480
So it's, you kind of do more declarative programming than imperative programming.

342
00:23:41,480 --> 00:23:43,960
You declare what it is that you want.

343
00:23:43,960 --> 00:23:47,760
One interesting thing that happens when you start working with different engineer teams

344
00:23:47,760 --> 00:23:53,240
that want to try sort of using automatic policies is that they realize that their problem

345
00:23:53,240 --> 00:23:54,920
is not well defined, right?

346
00:23:54,920 --> 00:23:57,600
They say, oh, we really want to just optimize this metric.

347
00:23:57,600 --> 00:24:00,680
So this is our, that's what we want.

348
00:24:00,680 --> 00:24:05,080
And then we, when we try to formalize the problem because they have to code up that declarative

349
00:24:05,080 --> 00:24:09,120
solution to, okay, this is the right answer, this is what the right answer looks like,

350
00:24:09,120 --> 00:24:13,280
they realize, oh, that, that conflicts with, with this other objective, no, that's not

351
00:24:13,280 --> 00:24:14,640
what we want to do.

352
00:24:14,640 --> 00:24:17,520
And so that's change in mindset that happens.

353
00:24:17,520 --> 00:24:21,680
It's also beneficial in sense that people figure out problems that they've always had,

354
00:24:21,680 --> 00:24:26,080
but previously just had some sort of hard-quoted solution that made some sort of implicit

355
00:24:26,080 --> 00:24:27,080
trade-off, right?

356
00:24:27,080 --> 00:24:32,440
That's sort of the trade-off was hidden and fixed and they just lived with it.

357
00:24:32,440 --> 00:24:38,360
And switching to this higher level programming model effectively forces them to be more explicit

358
00:24:38,360 --> 00:24:42,520
about the trade-offs they're making, understand the trade-offs they're making the system.

359
00:24:42,520 --> 00:24:46,800
So again, I think this is one of the super exciting aspects of working in this field.

360
00:24:46,800 --> 00:24:52,760
Can you walk through an example that illustrates that both the specific changes that they

361
00:24:52,760 --> 00:25:00,360
need to make to implement these policies and to integrate with Spiral, but also where

362
00:25:00,360 --> 00:25:04,120
these types of trade-offs have come into play?

363
00:25:04,120 --> 00:25:09,360
So, I mean, it's difficult to do sort of an abstract sort of an example that would be

364
00:25:09,360 --> 00:25:13,960
easy to discuss on sort of an already without a Blackboard.

365
00:25:13,960 --> 00:25:19,080
But if you think about, again, something like cash admission policy, right?

366
00:25:19,080 --> 00:25:24,560
You sort of want, as soon as you previously could just say, oh, well, I think we should

367
00:25:24,560 --> 00:25:28,200
cash this type of files and if they're not bigger than this, right?

368
00:25:28,200 --> 00:25:30,240
And just roll with it.

369
00:25:30,240 --> 00:25:34,520
And then you look at some metric and see, oh, well, the cash rate, the cash hit rate looks

370
00:25:34,520 --> 00:25:35,520
good.

371
00:25:35,520 --> 00:25:38,960
All right, let's find, let's keep it as this, right?

372
00:25:38,960 --> 00:25:42,800
So you don't know what the opportunity cost is, right?

373
00:25:42,800 --> 00:25:49,760
So maybe you could have had a much better cash hit rate or maybe you're burning through

374
00:25:49,760 --> 00:25:50,760
flash, right?

375
00:25:50,760 --> 00:25:55,920
Let's say it's a bigger cash, not only use memory, but those use flash, right?

376
00:25:55,920 --> 00:26:03,120
And so now you start looking at the rates of how much flash you're running through.

377
00:26:03,120 --> 00:26:07,920
And you're like, oh, no, well, it looks like we're writing over flash a lot.

378
00:26:07,920 --> 00:26:13,160
Let me go back and maybe tune my policy or do something about it, right?

379
00:26:13,160 --> 00:26:16,600
And then that has an effect on your cash hit rate, right?

380
00:26:16,600 --> 00:26:21,360
So if you're storing your, maybe saving few items, you have lower cash hit rate.

381
00:26:21,360 --> 00:26:24,480
So and then maybe different engineers are working the two problems, right?

382
00:26:24,480 --> 00:26:29,040
So you have this issue where one team is working to improve the cash hit rate and the

383
00:26:29,040 --> 00:26:32,760
other team is trying to improve the rate of burnout of flash, right?

384
00:26:32,760 --> 00:26:37,240
And sort of you have people who are adjusting different parts of the system, which indirectly

385
00:26:37,240 --> 00:26:42,200
impact the other team without sort of realizing that explicit dependency.

386
00:26:42,200 --> 00:26:46,440
I mean, this is a really simple example and most people would probably figure out that

387
00:26:46,440 --> 00:26:50,960
like, okay, if I were changing this, we're going to affect the cash hit rate.

388
00:26:50,960 --> 00:26:54,280
But this is, this should give you a flavor of the types of trade-offs.

389
00:26:54,280 --> 00:26:59,720
Now if you have a single policy controlling the two, then, then you can set recall on

390
00:26:59,720 --> 00:27:03,720
your classifier and sort of make the trade-off very explicit, okay, I'll get this much cash

391
00:27:03,720 --> 00:27:08,280
rate, cash hit rate at this burnout rate, right?

392
00:27:08,280 --> 00:27:11,800
And sort of then you can say, okay, well, this is the classifier I have.

393
00:27:11,800 --> 00:27:14,000
And it looks like I can't have both, right?

394
00:27:14,000 --> 00:27:21,080
I can't have really high cash hit rate with the current policy and low burn rate.

395
00:27:21,080 --> 00:27:25,760
So then what you look at is, okay, maybe we can add additional features and sort of improve

396
00:27:25,760 --> 00:27:27,480
both at the same time.

397
00:27:27,480 --> 00:27:29,200
Does that make sense?

398
00:27:29,200 --> 00:27:34,560
Is it sort of using adaptive policy tools like Spiral allows you to make this trade-offs

399
00:27:34,560 --> 00:27:37,920
explicit and then sort of see them all in one place?

400
00:27:37,920 --> 00:27:47,440
And so you started talking about starting with these policies and then looking at optimization

401
00:27:47,440 --> 00:27:55,000
metrics and performance and features and feature engineering, that kind of thing.

402
00:27:55,000 --> 00:28:00,640
Can you talk a little bit about the data science element of this or the modeling element

403
00:28:00,640 --> 00:28:06,960
of this and specifically, is that abstracted away from the presumably, it's abstracted

404
00:28:06,960 --> 00:28:12,080
away to some extent from the engineers that are using Spiral or are they involved in developing

405
00:28:12,080 --> 00:28:17,200
statistical models for the specific policies that they want to implement?

406
00:28:17,200 --> 00:28:21,520
So that's a great question in a sense that this is something we're still trying to figure

407
00:28:21,520 --> 00:28:23,760
out kind of the best way to do.

408
00:28:23,760 --> 00:28:30,200
So initially when we started building Spiral, our view was that we have a lot of domain

409
00:28:30,200 --> 00:28:35,840
expertise, meaning that if people who are building caches and have built in caches for many

410
00:28:35,840 --> 00:28:42,120
years decide to use adaptive policy, they actually already have all the domain expertise

411
00:28:42,120 --> 00:28:43,120
we need, right?

412
00:28:43,120 --> 00:28:46,240
So in some respect, they really know what matters or what doesn't.

413
00:28:46,240 --> 00:28:51,560
In other words, if I have written a heuristic manually by hand that checks file sizes and

414
00:28:51,560 --> 00:28:57,080
file types and compression types as something that's important to my policy, that is my

415
00:28:57,080 --> 00:28:58,080
feature set, right?

416
00:28:58,080 --> 00:29:03,840
And sort of I already have experience and I already know what features matter.

417
00:29:03,840 --> 00:29:09,800
And that's partially what enables us to do what we do because the methods, as I said,

418
00:29:09,800 --> 00:29:14,760
we use our online methods and sort of their meant to be high performance, right?

419
00:29:14,760 --> 00:29:20,800
Because the cache is making lots and lots of decisions per second and you can't really

420
00:29:20,800 --> 00:29:23,920
have very heavy models to make those decisions.

421
00:29:23,920 --> 00:29:29,880
And so currently we partner with teams and help them do the data science.

422
00:29:29,880 --> 00:29:34,640
But moving forward, we're trying to template those solutions and sort of every team can

423
00:29:34,640 --> 00:29:40,840
do their own data science fairly easily with the tools that we built for them.

424
00:29:40,840 --> 00:29:45,120
And then they would know how well their system would perform if they were to plug Spiral

425
00:29:45,120 --> 00:29:46,120
in.

426
00:29:46,120 --> 00:29:47,600
Does that make sense?

427
00:29:47,600 --> 00:29:51,880
So in other words, we're transitioning from doing a lot of the data science ourselves

428
00:29:51,880 --> 00:29:55,920
and sort of jointly with the team with a sort of high-touch environment into more of a

429
00:29:55,920 --> 00:30:02,560
self-service environment where teams have an easy way to sort of plug in their data and

430
00:30:02,560 --> 00:30:08,120
get the insights and make a decision how to use that data.

431
00:30:08,120 --> 00:30:12,880
And this is sort of done through education, through documentation and through potentially

432
00:30:12,880 --> 00:30:17,520
shifting some of the work we do to data scientists on those teams or affiliated data

433
00:30:17,520 --> 00:30:18,520
scientists.

434
00:30:18,520 --> 00:30:22,160
So that's our path forward to sort of scaling this, right?

435
00:30:22,160 --> 00:30:24,040
Because we're not a very large team.

436
00:30:24,040 --> 00:30:26,120
We don't have hundreds of people working on this, right?

437
00:30:26,120 --> 00:30:30,080
So it's been noted to have impact on Facebook scale.

438
00:30:30,080 --> 00:30:34,160
It's if we just were to meet with every potential customer, we would burn out of hours

439
00:30:34,160 --> 00:30:35,160
in the day.

440
00:30:35,160 --> 00:30:36,160
Sure.

441
00:30:36,160 --> 00:30:37,160
Sure.

442
00:30:37,160 --> 00:30:44,080
Can you talk through the data science process as it exists today and in particular elements

443
00:30:44,080 --> 00:30:53,000
of the modeling that are unique to the way you've formulated this problem in system?

444
00:30:53,000 --> 00:30:54,000
Sure.

445
00:30:54,000 --> 00:30:59,080
So the most difficult data science, in this case, ends up being the part where we are

446
00:30:59,080 --> 00:31:01,160
formally defining the problem, right?

447
00:31:01,160 --> 00:31:04,440
So effectively, what we do is it's structured learning, right?

448
00:31:04,440 --> 00:31:09,120
So it's really you need features and you need labels.

449
00:31:09,120 --> 00:31:14,280
And part of the process to work with what teams to figure out, what are the features,

450
00:31:14,280 --> 00:31:17,360
which is something they usually know, and then what are the labels?

451
00:31:17,360 --> 00:31:22,000
And this is something I referred to earlier, which is people don't necessarily agree

452
00:31:22,000 --> 00:31:24,720
on what the labels should be and which labels are right.

453
00:31:24,720 --> 00:31:29,480
And that's sort of where we bring up some sort of contradictions in the objectives

454
00:31:29,480 --> 00:31:31,160
they're trying to achieve.

455
00:31:31,160 --> 00:31:36,440
So a lot of it is just talking through the problem and taking the main specific problems

456
00:31:36,440 --> 00:31:42,520
sort of a systems problem and bring it into machine learning terms and sort of to sort

457
00:31:42,520 --> 00:31:47,720
of figure out what is our data set, what are the right answers, what are the right labels?

458
00:31:47,720 --> 00:31:52,840
Can one of the big requirements of spiralist ability to generate the labels automatically,

459
00:31:52,840 --> 00:31:53,840
right?

460
00:31:53,840 --> 00:31:57,760
Because in order for system to stay adaptive, you need to be able to continuously

461
00:31:57,760 --> 00:32:00,720
feedback the new labels, right?

462
00:32:00,720 --> 00:32:03,920
To sort of continue to adopt the environment, you need to fit in the new data set, the

463
00:32:03,920 --> 00:32:07,000
fresh, the fresh correct answers.

464
00:32:07,000 --> 00:32:10,680
So a lot of it is number one, figure out if that can be done.

465
00:32:10,680 --> 00:32:14,320
And if it can be done, then the spiralist is not the right system for a particular use

466
00:32:14,320 --> 00:32:15,320
case.

467
00:32:15,320 --> 00:32:20,960
And if it can be done, then figure out what are those labels taking them and then just

468
00:32:20,960 --> 00:32:26,160
applying the basic machine learning methods to see if we can achieve desired accuracy,

469
00:32:26,160 --> 00:32:27,160
desired quality.

470
00:32:27,160 --> 00:32:34,840
And are there specific methods or techniques that are used particular to the online learning

471
00:32:34,840 --> 00:32:35,840
aspect of this?

472
00:32:35,840 --> 00:32:43,120
So one of the very old and very kind of battle-tested methods is something we also use, it's

473
00:32:43,120 --> 00:32:45,360
called multinomial-nave-base.

474
00:32:45,360 --> 00:32:50,680
It comes from a family of nave-base methods and it's sort of very simple that effectively

475
00:32:50,680 --> 00:32:52,160
is counting.

476
00:32:52,160 --> 00:32:59,240
So if you have, let's say one place where this is also used is spam detection, right?

477
00:32:59,240 --> 00:33:03,560
So that's actually what makes spam detection practical on desktop when you get an email

478
00:33:03,560 --> 00:33:08,920
and it says it has words like Viagra and something else, something else, okay, that's spam,

479
00:33:08,920 --> 00:33:09,920
right?

480
00:33:09,920 --> 00:33:14,680
Because your other email, your good email probably doesn't have words like Viagra in

481
00:33:14,680 --> 00:33:15,680
it, right?

482
00:33:15,680 --> 00:33:16,880
That's probably not something you can verse about.

483
00:33:16,880 --> 00:33:22,680
So if you count the number of times Viagra occurs in your email, it's very low in sort

484
00:33:22,680 --> 00:33:27,520
of a good email and if you count the number of times Viagra occurs in bad email, that's

485
00:33:27,520 --> 00:33:28,520
very high.

486
00:33:28,520 --> 00:33:34,400
So that's effectively what multinomial-nave-base and generate nave-base methods do.

487
00:33:34,400 --> 00:33:38,440
And the big benefit of those methods is that they're incredibly fast, right?

488
00:33:38,440 --> 00:33:40,680
Because you literally just do counting.

489
00:33:40,680 --> 00:33:45,240
There is no grading descent, there's none of that needs to be done and as soon as you

490
00:33:45,240 --> 00:33:50,920
updated your counters, your model has updated and you're now ready to make predictions with

491
00:33:50,920 --> 00:33:53,680
higher certainty or not a larger data set.

492
00:33:53,680 --> 00:33:59,880
You say as soon as you've updated your counters, what are those counters represent?

493
00:33:59,880 --> 00:34:05,840
Are those counters features from the input data or are they kind of internal state that's

494
00:34:05,840 --> 00:34:09,240
keeping track of thresholds or things like that?

495
00:34:09,240 --> 00:34:11,760
It's the internal state that keeps track of thresholds.

496
00:34:11,760 --> 00:34:18,760
Literally, like one counter is sort of the prior counter, empirical prior, which is how

497
00:34:18,760 --> 00:34:21,680
many good emails have you gotten versus bad emails, right?

498
00:34:21,680 --> 00:34:28,640
So if you just count that and if 99% of your emails are good and if you ask me to predict

499
00:34:28,640 --> 00:34:32,120
that for a new email, is that likely to be good or bad?

500
00:34:32,120 --> 00:34:35,720
Based on that single counter, I'll say, well, it's most like the good because really most

501
00:34:35,720 --> 00:34:40,400
of the emails you get are good without even looking at the content, right?

502
00:34:40,400 --> 00:34:46,400
And on top of that, I can look at word occurrences in the email and which words occur in that.

503
00:34:46,400 --> 00:34:51,920
And if that's, if that email says hello Sam and it says sort of how are you, let's get

504
00:34:51,920 --> 00:34:53,720
together this weekend.

505
00:34:53,720 --> 00:34:57,280
That's one set of words that are being hit right and like weekend and hello and everything

506
00:34:57,280 --> 00:34:58,280
else.

507
00:34:58,280 --> 00:35:02,360
Those are, all those counts are usually high for good emails.

508
00:35:02,360 --> 00:35:07,200
And then if it says, you know, Pills, Viagra, something, something, something else, those

509
00:35:07,200 --> 00:35:10,720
counts are very low when you're regular email, right?

510
00:35:10,720 --> 00:35:12,840
So does that, does that make sense?

511
00:35:12,840 --> 00:35:16,040
You're basically conditionals in your feature space.

512
00:35:16,040 --> 00:35:17,040
That's exactly right.

513
00:35:17,040 --> 00:35:21,760
So you're keeping kind of class conditional probabilities, you're keeping those scores

514
00:35:21,760 --> 00:35:26,120
and you're applying them to as soon as soon as you updated the counters, you have new conditional

515
00:35:26,120 --> 00:35:29,480
probabilities and you could use them to classify the next item.

516
00:35:29,480 --> 00:35:34,360
We've talked about the caching example multiple times.

517
00:35:34,360 --> 00:35:37,080
You've mentioned spam a couple of times.

518
00:35:37,080 --> 00:35:42,920
Is this used for content filtering types of applications at Facebook or is that more

519
00:35:42,920 --> 00:35:43,920
an example?

520
00:35:43,920 --> 00:35:45,440
That's definitely an example.

521
00:35:45,440 --> 00:35:50,360
Just anytime you see multi-nevenly based, like if you go into Wikipedia, they'll literally

522
00:35:50,360 --> 00:35:54,160
give you a spam as an example of how this method works.

523
00:35:54,160 --> 00:36:00,440
Are there other areas beyond the cache example that this is being used at?

524
00:36:00,440 --> 00:36:01,440
Yeah.

525
00:36:01,440 --> 00:36:02,440
So one other area.

526
00:36:02,440 --> 00:36:07,600
I mean, this literally can be used in any area where the examples can be generated automatically.

527
00:36:07,600 --> 00:36:11,840
Caches just one of them in a sense, like you, you know and retrospect which items you

528
00:36:11,840 --> 00:36:13,880
should or should not have cashed.

529
00:36:13,880 --> 00:36:20,360
Anytime you can retrospectively check a decision, the system applies and one other specific

530
00:36:20,360 --> 00:36:23,760
example is something like retribility.

531
00:36:23,760 --> 00:36:29,200
So imagine that you were many, so many companies run batch jobs, right?

532
00:36:29,200 --> 00:36:33,240
So Facebook has a lot of large system that runs batch jobs.

533
00:36:33,240 --> 00:36:37,240
And batch jobs often can fail for various reasons, right?

534
00:36:37,240 --> 00:36:42,680
Sometimes it could be there's a syntax error that I checked in bad code because I'm a

535
00:36:42,680 --> 00:36:44,920
irresponsible developer, right?

536
00:36:44,920 --> 00:36:49,680
And there's syntax error in it and after four hours of computing something, it hits my

537
00:36:49,680 --> 00:36:52,640
incorrect statement and breaks, right?

538
00:36:52,640 --> 00:36:54,240
Literally the job fails.

539
00:36:54,240 --> 00:36:57,240
The results have not been delivered.

540
00:36:57,240 --> 00:36:59,480
Or there may be instructions failure.

541
00:36:59,480 --> 00:37:02,680
Let's say there's network connectivity issues with a particular data center and the

542
00:37:02,680 --> 00:37:06,920
job is trying to get the data and it fails because it couldn't get the data, right?

543
00:37:06,920 --> 00:37:09,240
And maybe those does this be very quickly.

544
00:37:09,240 --> 00:37:13,440
So in the first case, you actually don't want to retry the job, right?

545
00:37:13,440 --> 00:37:16,640
But particularly because it could be very expensive to rerun it, right?

546
00:37:16,640 --> 00:37:20,880
So you sort of you run for a bunch of phases, you run it for hours, spend on hundreds of

547
00:37:20,880 --> 00:37:24,320
computers and then you fail because there is a syntax error.

548
00:37:24,320 --> 00:37:26,800
Well, if I and you're going to run it again the next time.

549
00:37:26,800 --> 00:37:27,800
Exactly.

550
00:37:27,800 --> 00:37:28,800
Exactly.

551
00:37:28,800 --> 00:37:29,800
So I'm going to fail again next time.

552
00:37:29,800 --> 00:37:31,600
I can retry it three times or four times or five times.

553
00:37:31,600 --> 00:37:34,480
I will still fail and I will waste resources.

554
00:37:34,480 --> 00:37:39,280
On the other hand, if the job is, if the failure was intermittent, you actually do want to

555
00:37:39,280 --> 00:37:41,360
retry, right?

556
00:37:41,360 --> 00:37:48,280
And this is exactly the same setup as with the cache because retroactively, you know what

557
00:37:48,280 --> 00:37:51,000
the right answer answer should have been, right?

558
00:37:51,000 --> 00:37:54,520
And certain types of jobs, no matter how many times you retry them, they fail.

559
00:37:54,520 --> 00:37:57,160
Other jobs succeed on retries.

560
00:37:57,160 --> 00:38:03,320
So learning to classify which, what to retry and what not to retry is again a type of scenario

561
00:38:03,320 --> 00:38:04,800
where we use spiral.

562
00:38:04,800 --> 00:38:11,360
So features here might be job, return codes and infrastructure metrics and things like

563
00:38:11,360 --> 00:38:12,360
that.

564
00:38:12,360 --> 00:38:17,600
Yeah, this feature features in this example that are literally logs, right?

565
00:38:17,600 --> 00:38:21,080
So to return codes, press the log that this job produced.

566
00:38:21,080 --> 00:38:26,320
So it's kind of just literally the text that was out, the last, at last, say, 100 lines

567
00:38:26,320 --> 00:38:32,320
of text that were produced and that's fed into the classifier, along with the kind of

568
00:38:32,320 --> 00:38:37,920
number of retries that happened, meaning, okay, this message was produced and we retried

569
00:38:37,920 --> 00:38:40,360
it three times and nothing good happened, right?

570
00:38:40,360 --> 00:38:41,920
We've never succeeded.

571
00:38:41,920 --> 00:38:46,160
So next time we get the similar message, well, that means we probably shouldn't retry it.

572
00:38:46,160 --> 00:38:55,960
So you've got these, these logs, I'm imagining a typical log is, you know, has some significant

573
00:38:55,960 --> 00:38:56,960
depth to it.

574
00:38:56,960 --> 00:39:02,400
It's not kind of abstracted down to a particular, you know, word or error code or something,

575
00:39:02,400 --> 00:39:03,760
but it's in there.

576
00:39:03,760 --> 00:39:10,600
How are you narrowing in on the, you know, the specific signal within a big log file?

577
00:39:10,600 --> 00:39:15,080
Well, then it's down through the magic of machine learning.

578
00:39:15,080 --> 00:39:21,600
I guess in the context of, of this, this online learning where you're, you're basically

579
00:39:21,600 --> 00:39:27,200
doing counting, right, you've, you've got to tell it what to count, right?

580
00:39:27,200 --> 00:39:31,120
You're not, yeah, I'm not, I'm not hearing that you're doing, you know, deep learning

581
00:39:31,120 --> 00:39:36,920
or something like that and you're training a model to figure out what to count.

582
00:39:36,920 --> 00:39:41,960
Well, we are, we are trying to, so there's, I mean, it's fundamental to deep learning

583
00:39:41,960 --> 00:39:45,240
or any kind of other learning, they're all similar, right?

584
00:39:45,240 --> 00:39:49,920
They're all, there is a, there is a theorem called no free lunch theorem.

585
00:39:49,920 --> 00:39:54,680
You can look it up on Wikipedia, but it, it's fairly, it's fairly complicated, but in

586
00:39:54,680 --> 00:39:59,000
a nutshell, it says that no classifier is superior to another classifier.

587
00:39:59,000 --> 00:40:04,360
In other words, if, if I can, with the right set of transformations on the input data,

588
00:40:04,360 --> 00:40:10,720
I can get results that are as good with a simple classifier as I would on raw data with

589
00:40:10,720 --> 00:40:13,800
a more sophisticated classifier, does that make sense?

590
00:40:13,800 --> 00:40:14,800
Sure.

591
00:40:14,800 --> 00:40:15,800
Yeah.

592
00:40:15,800 --> 00:40:20,600
Effectively, if I pre-process the logs using some sort of vectorization, using something

593
00:40:20,600 --> 00:40:25,320
else and then plug them into a very simple classifier, I'll get the results that are almost

594
00:40:25,320 --> 00:40:32,600
as good or, or as good as sort of a sophisticated neural, natural language processing method

595
00:40:32,600 --> 00:40:35,640
with, you know, recurring neural networks or something like that.

596
00:40:35,640 --> 00:40:36,640
Right.

597
00:40:36,640 --> 00:40:37,640
Well, that's what I was asking about.

598
00:40:37,640 --> 00:40:41,440
Even processing the logs and vectorizing them or creating an embedding or something like

599
00:40:41,440 --> 00:40:42,440
that.

600
00:40:42,440 --> 00:40:43,440
That's correct.

601
00:40:43,440 --> 00:40:44,440
Exactly.

602
00:40:44,440 --> 00:40:45,440
Yeah, that's what I was getting at.

603
00:40:45,440 --> 00:40:46,440
Okay.

604
00:40:46,440 --> 00:40:47,440
Cool.

605
00:40:47,440 --> 00:40:48,440
Interesting.

606
00:40:48,440 --> 00:40:49,440
Interesting.

607
00:40:49,440 --> 00:40:55,160
And so, you know, one of my initial thoughts and I alluded to this earlier in the discussion

608
00:40:55,160 --> 00:41:03,200
was, you know, kind of broad implications of this kind of technique in infrastructure

609
00:41:03,200 --> 00:41:08,240
management, for example, Google has kind of famously talked about some of their results

610
00:41:08,240 --> 00:41:13,760
in applying machine learning to managing, you know, HVAC systems within the data center.

611
00:41:13,760 --> 00:41:17,440
It seems like this kind of approach could have similar applicability.

612
00:41:17,440 --> 00:41:18,440
Correct.

613
00:41:18,440 --> 00:41:19,440
Yes.

614
00:41:19,440 --> 00:41:21,640
And that's what we're trying to do as well.

615
00:41:21,640 --> 00:41:27,880
I mean, if you weren't going to a large company, so a company that with as much infrastructure

616
00:41:27,880 --> 00:41:32,680
as Facebook or Google, at some point you want to take people out of the loop, right?

617
00:41:32,680 --> 00:41:35,200
And that's exactly what we're doing with our methods.

618
00:41:35,200 --> 00:41:40,160
We're trying to make sure people aren't doing kind of routine maintenance or mundane

619
00:41:40,160 --> 00:41:46,160
work and are actually focused on creative tasks by automating the routine work and sort

620
00:41:46,160 --> 00:41:47,960
of maintenance work.

621
00:41:47,960 --> 00:41:52,480
And so, have you done anything to try to apply this to kind of management of physical

622
00:41:52,480 --> 00:41:53,480
infrastructure?

623
00:41:53,480 --> 00:41:57,880
Our team in particular hasn't, but I don't know if other teams have.

624
00:41:57,880 --> 00:42:00,800
There's many other teams that are doing very interesting things.

625
00:42:00,800 --> 00:42:04,440
So we haven't, but I can't speak for all of Facebook.

626
00:42:04,440 --> 00:42:10,480
What were some of the main things that your team has learned in building the system and

627
00:42:10,480 --> 00:42:13,560
getting it in the hands of some users?

628
00:42:13,560 --> 00:42:18,240
I think the main thing that we've learned is that it's, you do have to change the mindset

629
00:42:18,240 --> 00:42:22,760
of people before they're comfortable using our system because initially when they start

630
00:42:22,760 --> 00:42:26,840
using it, the sort of just see it as magic, it's like, oh, this magical thing just makes

631
00:42:26,840 --> 00:42:27,840
decisions.

632
00:42:27,840 --> 00:42:30,840
It's like, why did it make that decision?

633
00:42:30,840 --> 00:42:34,520
And sort of, there's a price for an activity.

634
00:42:34,520 --> 00:42:36,200
There's a price for optimality, right?

635
00:42:36,200 --> 00:42:39,560
In this case, it's maybe somewhat reduced transparency.

636
00:42:39,560 --> 00:42:45,040
So if you think about the example I gave earlier, which is a sort of an EFELS tree of statements

637
00:42:45,040 --> 00:42:50,160
for you, where your policies encoded, you could look at any decision and you can trace

638
00:42:50,160 --> 00:42:55,200
it back through that tree and say, well, that image was not cashed because it was just

639
00:42:55,200 --> 00:42:57,960
over the file size limit, right?

640
00:42:57,960 --> 00:43:04,200
As soon as you start using statistical methods, that observability goes away, right?

641
00:43:04,200 --> 00:43:05,560
It's not, there were changes.

642
00:43:05,560 --> 00:43:07,560
It requires you to think in different terms, right?

643
00:43:07,560 --> 00:43:11,600
It would, it requires you to think in terms of larger data set and sort of statistical

644
00:43:11,600 --> 00:43:15,040
averages, not EFELS statements.

645
00:43:15,040 --> 00:43:16,680
I think that's the biggest challenge for us.

646
00:43:16,680 --> 00:43:23,120
It's sort of getting people to let go of control and trusting a machine learning system.

647
00:43:23,120 --> 00:43:27,760
And it's very much on us to prove to them that it's actually better than what they had

648
00:43:27,760 --> 00:43:28,760
before.

649
00:43:28,760 --> 00:43:34,200
We've been lucky in a sense that we've enabled our customers to do things they didn't

650
00:43:34,200 --> 00:43:35,680
think were possible.

651
00:43:35,680 --> 00:43:39,000
And so they, they're kind of embraced us and they said, this is great.

652
00:43:39,000 --> 00:43:41,160
This really saves me many hours in a day.

653
00:43:41,160 --> 00:43:44,360
And now we can do this thing that I didn't think we could.

654
00:43:44,360 --> 00:43:45,680
So that helps.

655
00:43:45,680 --> 00:43:50,000
But generally, when you start talking to people, they're a little bit skeptical like, well,

656
00:43:50,000 --> 00:43:51,360
is this going to do the right thing?

657
00:43:51,360 --> 00:43:52,360
How am I going to debug it?

658
00:43:52,360 --> 00:43:53,360
Right.

659
00:43:53,360 --> 00:43:59,280
So that's kind of our next challenge in terms of scaling this to sort of literally every

660
00:43:59,280 --> 00:44:03,800
engineer at Facebook and potentially after that, you know, every engineer in the world

661
00:44:03,800 --> 00:44:05,640
who wants to benefit from this.

662
00:44:05,640 --> 00:44:14,160
Have you started exploring approaches to creating some degree of observability, explainability,

663
00:44:14,160 --> 00:44:15,160
that kind of thing?

664
00:44:15,160 --> 00:44:16,160
Yes.

665
00:44:16,160 --> 00:44:19,200
And so that's a kind of an ongoing process.

666
00:44:19,200 --> 00:44:24,480
Traditionally, so this is something I actually learned during my, during the time of work

667
00:44:24,480 --> 00:44:30,880
to my dissertation, methods such as nearest neighbor methods tend to be easier to explain

668
00:44:30,880 --> 00:44:36,360
because whatever person says, why was this decision made, you could provide examples and

669
00:44:36,360 --> 00:44:42,480
say, well, because this example looks very similar to those two examples, which you said

670
00:44:42,480 --> 00:44:43,920
were positive.

671
00:44:43,920 --> 00:44:46,600
That's why this example is positive.

672
00:44:46,600 --> 00:44:47,600
Does that make sense?

673
00:44:47,600 --> 00:44:54,720
It's because nearest neighbors, family methods, they work by literally through examples.

674
00:44:54,720 --> 00:44:56,840
Like, here's a prototype examples.

675
00:44:56,840 --> 00:45:00,520
Now, tell me what this new, never seen before example.

676
00:45:00,520 --> 00:45:02,360
What is the label for this example?

677
00:45:02,360 --> 00:45:06,920
We can literally use that as an interface and say, well, it's because you provided us

678
00:45:06,920 --> 00:45:08,480
with this data.

679
00:45:08,480 --> 00:45:13,480
And so that's the direction we're kind of thinking about and sort of that's those methods we

680
00:45:13,480 --> 00:45:18,200
want to try to see if we can exploit and sort of run effectively online.

681
00:45:18,200 --> 00:45:19,200
Awesome.

682
00:45:19,200 --> 00:45:22,480
Well, Vlad, thanks so much for taking the time to chat with us about this.

683
00:45:22,480 --> 00:45:24,640
This is a really interesting project.

684
00:45:24,640 --> 00:45:25,640
Thank you very much.

685
00:45:25,640 --> 00:45:27,880
I'm, thank you for having me on the show.

686
00:45:27,880 --> 00:45:28,880
Awesome.

687
00:45:28,880 --> 00:45:29,880
Take care.

688
00:45:29,880 --> 00:45:30,880
Bye-bye.

689
00:45:30,880 --> 00:45:34,840
All right, everyone.

690
00:45:34,840 --> 00:45:39,920
That's our show for today for more information on Vlad or any of the topics covered in the

691
00:45:39,920 --> 00:45:45,800
show, visit twomla.com slash talk slash 221.

692
00:45:45,800 --> 00:46:12,560
As always, thanks so much for listening and catch you next time.

