1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,560
I'm your host Sam Charrington.

4
00:00:23,560 --> 00:00:26,720
A few updates before we jump into our show.

5
00:00:26,720 --> 00:00:31,360
This week, October 10th through 11th, I'll be in Montreal for the rework deep learning

6
00:00:31,360 --> 00:00:32,560
summit.

7
00:00:32,560 --> 00:00:37,400
We held a flash giveaway last week for one lucky listener to get a chance to join me

8
00:00:37,400 --> 00:00:38,880
at the conference.

9
00:00:38,880 --> 00:00:42,280
And that winner is Matt Stone, a listener from Toronto.

10
00:00:42,280 --> 00:00:46,760
Thanks to everyone who entered and be on the lookout for more giveaways to close out

11
00:00:46,760 --> 00:00:47,760
the year.

12
00:00:47,760 --> 00:00:51,220
Hey, if you're in the Montreal area, I'd love to connect.

13
00:00:51,220 --> 00:00:56,040
Reach out to me via Twitter or the contact page at twimlai.com if you'd like to meet

14
00:00:56,040 --> 00:00:57,040
up.

15
00:00:57,040 --> 00:01:01,520
The show you're about to hear is the first of a series of shows recorded in San Francisco

16
00:01:01,520 --> 00:01:06,120
at the Artificial Intelligence Conference, which was hosted by our friends at O'Reilly

17
00:01:06,120 --> 00:01:07,800
and Intel Nirvana.

18
00:01:07,800 --> 00:01:12,640
In addition to their support for the event itself, Intel Nirvana is also our sponsor for this

19
00:01:12,640 --> 00:01:15,040
series of podcasts from the event.

20
00:01:15,040 --> 00:01:19,080
A huge thanks to them for their continued support of the show.

21
00:01:19,080 --> 00:01:24,120
In this episode, I speak with Navine Rao, Vice President and General Manager of Intel's

22
00:01:24,120 --> 00:01:28,840
AI Products Group and Scott Appland, Director of Intel's Developer Network.

23
00:01:28,840 --> 00:01:33,400
It's been a few months since we last spoke with Navine, so he gives us a quick update on

24
00:01:33,400 --> 00:01:38,040
what Intel has been up to and we discuss his perspective on some recent events in the

25
00:01:38,040 --> 00:01:39,560
AI ecosystem.

26
00:01:39,560 --> 00:01:45,280
Then, Scott and I dig into Intel Nirvana's new dev cloud offering, which was announced

27
00:01:45,280 --> 00:01:46,600
at the conference.

28
00:01:46,600 --> 00:01:52,000
We also discussed the Intel Nirvana AI Academy, a new portal offering hands-on learning

29
00:01:52,000 --> 00:01:57,080
tools and other resources for various aspects of machine learning and AI.

30
00:01:57,080 --> 00:02:02,080
In addition to my conversations with Navine and Scott, this show is packed with more interviews

31
00:02:02,080 --> 00:02:08,520
that I know you'll love, including Paul Tepper of Nuance, on conversational interfaces,

32
00:02:08,520 --> 00:02:16,120
Gunner Carlson of Stanford and IASD on topological data analysis, Laura Freilich and Mo Patel

33
00:02:16,120 --> 00:02:21,800
of Think Big Analytics on some interesting machine learning use cases they've implemented,

34
00:02:21,800 --> 00:02:27,760
and Ian Steuiger of UC Berkeley on his work at the Ryze Lab and Ray, a new platform for

35
00:02:27,760 --> 00:02:29,520
reinforcement learning.

36
00:02:29,520 --> 00:02:34,360
Finally, a quick reminder about the upcoming Twimble Online Meetup.

37
00:02:34,360 --> 00:02:40,680
On Wednesday, October 18th, at 3pm Pacific time, we'll be discussing the paper visual

38
00:02:40,680 --> 00:02:47,640
attribute transfer through deep image analogy by Jing Li Yao and others from Microsoft Research.

39
00:02:47,640 --> 00:02:50,400
The discussion will be led by Duncan Stothers.

40
00:02:50,400 --> 00:02:54,720
To join the meetup, or to catch up on what you missed from the first two meetups, visit

41
00:02:54,720 --> 00:03:00,400
twimbleai.com slash meetup, and now on to the show.

42
00:03:00,400 --> 00:03:08,520
All right, everyone.

43
00:03:08,520 --> 00:03:14,600
I am here at the AI conference brought to you by O'Reilly and Intel Nirvana and I'm here

44
00:03:14,600 --> 00:03:20,920
with Naveen Rao, who is the general manager of Intel's Artificial Intelligence products

45
00:03:20,920 --> 00:03:21,920
group.

46
00:03:21,920 --> 00:03:22,920
Welcome, Naveen.

47
00:03:22,920 --> 00:03:23,920
Thanks, Sam.

48
00:03:23,920 --> 00:03:24,920
Great to be here.

49
00:03:24,920 --> 00:03:25,920
It's great to have you here.

50
00:03:25,920 --> 00:03:30,520
We're going to spend a few minutes this morning just catching up on what Intel Nirvana

51
00:03:30,520 --> 00:03:35,120
has been up to, and then we've got a really interesting interview schedule to talk about

52
00:03:35,120 --> 00:03:38,760
one of the products that you guys are announcing here at the event.

53
00:03:38,760 --> 00:03:40,560
Sounds great.

54
00:03:40,560 --> 00:03:41,560
What's new?

55
00:03:41,560 --> 00:03:44,760
Well, it's been a very eventful few months.

56
00:03:44,760 --> 00:03:49,200
We started the Artificial Intelligence products group about five months ago now, and really

57
00:03:49,200 --> 00:03:53,960
getting resources around Intel aligned around this focus area now.

58
00:03:53,960 --> 00:03:58,200
The company has been super supportive from the top down to make this happen, and I think

59
00:03:58,200 --> 00:04:02,320
it's a reflection of the importance of AI to Intel.

60
00:04:02,320 --> 00:04:05,840
We want to be at the forefront of it, not just from the product standpoint, but also

61
00:04:05,840 --> 00:04:08,800
from the research standpoint.

62
00:04:08,800 --> 00:04:11,880
And so you made some announcements at the event today.

63
00:04:11,880 --> 00:04:13,400
Tell us a little bit about those.

64
00:04:13,400 --> 00:04:15,760
A lot of it is around our connection with developers.

65
00:04:15,760 --> 00:04:21,280
The Dev Cloud was one where we can connect with developers, get them working on our tools,

66
00:04:21,280 --> 00:04:22,920
but also training people.

67
00:04:22,920 --> 00:04:28,280
There's a big appetite right now for knowledge and understanding how to build AI solutions

68
00:04:28,280 --> 00:04:31,080
and how to actually solve industry problems.

69
00:04:31,080 --> 00:04:36,920
We put together a very nice set of tutorials in Tel Nirvana Academy, and also having computational

70
00:04:36,920 --> 00:04:41,280
support for those tools and actually computational resources available is what the Dev Cloud is

71
00:04:41,280 --> 00:04:42,280
about.

72
00:04:42,280 --> 00:04:46,480
And you know, that'll actually go hand in hand with Intel Nirvana Cloud coming up in the

73
00:04:46,480 --> 00:04:49,720
future where you can get access to the latest and greatest technologies.

74
00:04:49,720 --> 00:04:50,720
Okay.

75
00:04:50,720 --> 00:04:55,160
So where can folks find the tools that you, the documentation and tools that you released

76
00:04:55,160 --> 00:04:58,960
from Intel Nirvana.com or just Google Intel Nirvana Academy?

77
00:04:58,960 --> 00:04:59,960
Okay.

78
00:04:59,960 --> 00:05:00,960
Awesome.

79
00:05:00,960 --> 00:05:02,920
And so is the Dev Cloud?

80
00:05:02,920 --> 00:05:06,880
What's the relationship between the Dev Cloud and Intel Nirvana Cloud that's forthcoming

81
00:05:06,880 --> 00:05:07,880
to the Dev Cloud?

82
00:05:07,880 --> 00:05:11,840
The Dev Cloud is really meant for developers and education, whereas the Intel Nirvana

83
00:05:11,840 --> 00:05:16,000
Cloud is actually the enterprise grade solution for companies.

84
00:05:16,000 --> 00:05:20,480
So you know, one is more, here's access to our tools and a package format.

85
00:05:20,480 --> 00:05:24,920
The other thing is the Intel Nirvana Cloud is really our latest technology and a very kind

86
00:05:24,920 --> 00:05:26,960
of low cost way of getting access to it.

87
00:05:26,960 --> 00:05:27,960
Okay.

88
00:05:27,960 --> 00:05:32,640
And then you've got a keynote tomorrow that you're doing with Steve Jarvison.

89
00:05:32,640 --> 00:05:34,360
What are you going to be talking about there?

90
00:05:34,360 --> 00:05:38,760
Well, as you know, Steve may have been, as you may know, Steve was one of our early investors

91
00:05:38,760 --> 00:05:43,800
at Nirvana and has really become an industry expert in this area.

92
00:05:43,800 --> 00:05:47,800
And you know, I find it very fortunate to have him involved with us from the start guiding

93
00:05:47,800 --> 00:05:48,800
some of our direction.

94
00:05:48,800 --> 00:05:52,360
And it'll really just be a conversation between us talking about some of the things that

95
00:05:52,360 --> 00:05:57,640
are exciting coming up, you know, how hardware is going to evolve for the future of AI and

96
00:05:57,640 --> 00:05:59,400
drive the future of AI.

97
00:05:59,400 --> 00:06:00,400
What is the future of AI?

98
00:06:00,400 --> 00:06:01,760
What kind of problems will you be solving?

99
00:06:01,760 --> 00:06:02,760
Why is it important?

100
00:06:02,760 --> 00:06:05,480
It's really going to be a conversation and I think it should be entertaining.

101
00:06:05,480 --> 00:06:07,080
Oh, what is the future of AI?

102
00:06:07,080 --> 00:06:09,280
I'm going to save that for tomorrow.

103
00:06:09,280 --> 00:06:13,120
Well, I promise you no one will hear this before tomorrow.

104
00:06:13,120 --> 00:06:14,120
Okay.

105
00:06:14,120 --> 00:06:19,440
I think one of the main messages from my perspective is AI is really a set of techniques

106
00:06:19,440 --> 00:06:21,920
that allow us to scale intelligence.

107
00:06:21,920 --> 00:06:27,200
We can now take in more resources that we could possibly do as individual humans, you

108
00:06:27,200 --> 00:06:30,920
know, loosely coupled by language that we're hitting that fundamental limitation now

109
00:06:30,920 --> 00:06:33,760
because we've gotten really good at gathering data.

110
00:06:33,760 --> 00:06:37,960
And now we have too much data and we actually can't do much with it as individuals.

111
00:06:37,960 --> 00:06:39,360
Humans can't scale that level.

112
00:06:39,360 --> 00:06:41,560
So we need to build technologies to allow us to do it.

113
00:06:41,560 --> 00:06:46,000
And it's really kind of continuing along the evolution of the scientific method.

114
00:06:46,000 --> 00:06:51,520
Humans forms this procedure to really make testable, repeatable results and try to get

115
00:06:51,520 --> 00:06:53,080
to the ground truth of the world.

116
00:06:53,080 --> 00:06:54,320
And I think this is part of that, right?

117
00:06:54,320 --> 00:06:56,000
We just want to do it on a bigger scale.

118
00:06:56,000 --> 00:06:59,520
You know, one human can only experience so much, but we can actually now put devices

119
00:06:59,520 --> 00:07:02,400
out in the world that can experience a lot and bring it all together.

120
00:07:02,400 --> 00:07:06,640
So that's really what I think AI is about and why it's important.

121
00:07:06,640 --> 00:07:10,440
It's really allowing us to continue along the evolution of what it means to be human.

122
00:07:10,440 --> 00:07:11,440
Mm-hmm.

123
00:07:11,440 --> 00:07:15,400
And one of the things that came up in the key notes this morning was, it's related

124
00:07:15,400 --> 00:07:16,840
to a comment you just made.

125
00:07:16,840 --> 00:07:22,200
We've become really good at gathering and collecting data, but not necessarily so good at collecting

126
00:07:22,200 --> 00:07:28,280
label data sets that are trainable to create machine learning models and AI models, is

127
00:07:28,280 --> 00:07:30,440
Intel doing anything in that space at all?

128
00:07:30,440 --> 00:07:31,440
Yeah.

129
00:07:31,440 --> 00:07:34,080
So, I mean, there are three fundamental types of learning.

130
00:07:34,080 --> 00:07:36,360
There's what you just described would be called supervised learning.

131
00:07:36,360 --> 00:07:40,480
This is really about taking data that's already been annotated by human and saying this

132
00:07:40,480 --> 00:07:43,240
is what we want to get out of a model.

133
00:07:43,240 --> 00:07:46,000
Reinforcement learning is more like kind of how you train your dog.

134
00:07:46,000 --> 00:07:49,520
Dog gets something good, you give him a treat, and he does that good thing more often.

135
00:07:49,520 --> 00:07:53,520
The other, I would say, the big frontier right now is unsupervised learning.

136
00:07:53,520 --> 00:07:54,520
Right.

137
00:07:54,520 --> 00:07:57,600
And that's really about finding potentially useful structure and data before you know

138
00:07:57,600 --> 00:07:59,280
what you want to do with it.

139
00:07:59,280 --> 00:08:04,880
And that's really what needs to be cracked to enable this kind of scalability, because

140
00:08:04,880 --> 00:08:07,720
actually going through and labeling all the data in the world is not possible.

141
00:08:07,720 --> 00:08:08,720
Right.

142
00:08:08,720 --> 00:08:12,480
Just if there's too much already, if we froze the world today and handed out 100 megabytes

143
00:08:12,480 --> 00:08:16,480
to every man, woman, and child on the planet, we would take us 30 years to get through

144
00:08:16,480 --> 00:08:17,480
all of it.

145
00:08:17,480 --> 00:08:19,200
So, you know, that's not something we can, that's possible.

146
00:08:19,200 --> 00:08:22,760
The only way to do it is to crack it from an algorithmic standpoint and then throw

147
00:08:22,760 --> 00:08:25,600
the computational horsepower at it that we're building.

148
00:08:25,600 --> 00:08:29,000
So that's, I think, one of the big, big things we're going to see in the next couple of

149
00:08:29,000 --> 00:08:31,920
years is research into the unsupervised training world.

150
00:08:31,920 --> 00:08:36,120
And we are doing that as well and providing tools, so our researchers do move this field

151
00:08:36,120 --> 00:08:37,120
forward.

152
00:08:37,120 --> 00:08:42,280
Are there any particular examples of progress in that space that comes to mind for you,

153
00:08:42,280 --> 00:08:45,480
or that you've helped, your tools are helping facilitate?

154
00:08:45,480 --> 00:08:49,280
I think GANs, generative adversarial networks are a big, big one.

155
00:08:49,280 --> 00:08:53,120
This is something that started becoming popular about a year, year and a half ago, showing

156
00:08:53,120 --> 00:08:55,040
some really promising results now.

157
00:08:55,040 --> 00:08:59,320
And this is towards more unsupervised kind of method.

158
00:08:59,320 --> 00:09:01,800
What our tools have helped there is really the speed.

159
00:09:01,800 --> 00:09:03,400
GANs are computationally intensive.

160
00:09:03,400 --> 00:09:09,720
They take a lot of horsepower, and a lot of time, and, you know, four years ago, you

161
00:09:09,720 --> 00:09:10,720
simply couldn't do it.

162
00:09:10,720 --> 00:09:16,880
You just didn't have the tools and computational capabilities that we have today by providing

163
00:09:16,880 --> 00:09:21,720
better tools faster, more scalable, larger parameter memories, these kinds of things.

164
00:09:21,720 --> 00:09:23,600
We can actually drive these fields forward.

165
00:09:23,600 --> 00:09:27,720
And that's the way I see it as, like, when we put out a new architecture that has fundamental

166
00:09:27,720 --> 00:09:31,840
and new capabilities, smart researchers are going to do things with it that we had never

167
00:09:31,840 --> 00:09:32,840
even thought of.

168
00:09:32,840 --> 00:09:33,840
And that's what I think is really cool.

169
00:09:33,840 --> 00:09:37,840
It's not the stuff that we're thinking about, that should work, but it's other stuff

170
00:09:37,840 --> 00:09:38,840
that's going to happen.

171
00:09:38,840 --> 00:09:39,840
Yeah.

172
00:09:39,840 --> 00:09:40,840
Very interesting.

173
00:09:40,840 --> 00:09:45,240
One of the things I remember from our last conversation was we were talking about Intel

174
00:09:45,240 --> 00:09:49,720
and Intel's role in the space, and you made a comment to the effect that, hey, you

175
00:09:49,720 --> 00:09:52,520
know, we're in the first inning, is that, right?

176
00:09:52,520 --> 00:09:58,880
And in the context of tools, I think last time we talked a little bit about the support

177
00:09:58,880 --> 00:10:05,640
for Nervonograph and some of the products projects that were announced last time at the AI

178
00:10:05,640 --> 00:10:07,640
conference in New York.

179
00:10:07,640 --> 00:10:12,000
And a lot of the conversation was around support for TensorFlow as kind of one of these

180
00:10:12,000 --> 00:10:13,680
back-end frameworks.

181
00:10:13,680 --> 00:10:17,440
And interestingly enough, like, I think, you know, a few months ago, everyone thought

182
00:10:17,440 --> 00:10:21,520
everyone thought that TensorFlow was like the Crown King and the game was over.

183
00:10:21,520 --> 00:10:25,200
And now, like, out of nowhere, we're talking about PyTorch all over the place.

184
00:10:25,200 --> 00:10:28,400
And I'm just going to go there.

185
00:10:28,400 --> 00:10:31,960
I'm just wondering if you have any, you know, thoughts or perspective on, you know, the

186
00:10:31,960 --> 00:10:36,280
market and how it will evolve and what we should expect to see.

187
00:10:36,280 --> 00:10:38,400
You know, you can look at the past.

188
00:10:38,400 --> 00:10:40,560
We saw the same thing happen with web technologies, right?

189
00:10:40,560 --> 00:10:42,160
Or the same thing happening.

190
00:10:42,160 --> 00:10:47,160
There's a new web technology to do responsive dynamic web pages out every year.

191
00:10:47,160 --> 00:10:50,800
I can't keep up because I don't do that stuff anymore.

192
00:10:50,800 --> 00:10:54,440
So I think you're going to see a very similar thing happening here when there's, you know,

193
00:10:54,440 --> 00:10:59,640
a new set of capabilities that kind of catapult some set of researchers, everyone was going

194
00:10:59,640 --> 00:11:00,640
to want to use it.

195
00:11:00,640 --> 00:11:01,640
Right.

196
00:11:01,640 --> 00:11:06,040
TensorFlow was kind of favored for the last eight months, nine months.

197
00:11:06,040 --> 00:11:07,040
We'll see what happens in the future.

198
00:11:07,040 --> 00:11:09,560
I think there's plenty of room for innovation here.

199
00:11:09,560 --> 00:11:11,280
It's not a done deal by any means.

200
00:11:11,280 --> 00:11:12,440
I think I even said that then.

201
00:11:12,440 --> 00:11:13,960
It's like, yeah, I've seen this happen.

202
00:11:13,960 --> 00:11:15,680
I've seen this game before.

203
00:11:15,680 --> 00:11:17,720
And, you know, we'll support what's out there, of course.

204
00:11:17,720 --> 00:11:22,600
You know, we want to provide innovations through our own software stack that we own and open

205
00:11:22,600 --> 00:11:27,040
source neon on top of end graph, but we obviously want to support what the community is using

206
00:11:27,040 --> 00:11:28,040
more broadly.

207
00:11:28,040 --> 00:11:31,880
And if that's pie towards great, if it's TensorFlow, great too, we have no problem with

208
00:11:31,880 --> 00:11:32,880
it.

209
00:11:32,880 --> 00:11:36,360
I think, you know, we're providing that computational substrate under the hood.

210
00:11:36,360 --> 00:11:40,640
And so we want to make sure that researchers have access to what they need.

211
00:11:40,640 --> 00:11:47,680
More broadly, what is the role of ecosystems and enabling AI solutions and AI tools?

212
00:11:47,680 --> 00:11:51,520
To evolve ecosystems are absolutely key, right?

213
00:11:51,520 --> 00:11:53,640
There's not one person who can do this on their own, right?

214
00:11:53,640 --> 00:11:55,120
It's just not going to happen.

215
00:11:55,120 --> 00:11:57,280
Not even one single big company, I think.

216
00:11:57,280 --> 00:12:01,600
There's too many smart people working on this problem to not work together in a common

217
00:12:01,600 --> 00:12:03,920
set of tools in a common language, right?

218
00:12:03,920 --> 00:12:06,840
So the way the big problems are going to solve, like, some supervised problems, things

219
00:12:06,840 --> 00:12:11,480
like that, is really through this openness of publishing, you know, people putting stuff

220
00:12:11,480 --> 00:12:12,480
on archive is great.

221
00:12:12,480 --> 00:12:16,640
But then having peer review and, you know, papers accepted by NIPs and ICML, these big

222
00:12:16,640 --> 00:12:20,520
conferences, and then providing the code to actually show the implementation.

223
00:12:20,520 --> 00:12:23,640
That's been a very virtuous cycle, I think.

224
00:12:23,640 --> 00:12:25,080
We've seen a lot of innovation happen quickly.

225
00:12:25,080 --> 00:12:29,360
You get something out there, the codes out there, you can download it, play with it, modify

226
00:12:29,360 --> 00:12:32,320
it, and then put out the next thing on top of it, right?

227
00:12:32,320 --> 00:12:35,880
I think it's actually a great paradigm for any kind of innovation.

228
00:12:35,880 --> 00:12:38,320
Yeah, absolutely, absolutely.

229
00:12:38,320 --> 00:12:39,920
Anything else you'd like to share with us?

230
00:12:39,920 --> 00:12:43,200
Yeah, I think, you know, it's going to be very exciting in the next year or so.

231
00:12:43,200 --> 00:12:46,440
We're going to be making a lot of announcements about some of the things coming to fruition.

232
00:12:46,440 --> 00:12:49,120
I mean, we're making a lot of bets right now.

233
00:12:49,120 --> 00:12:54,720
You know, we've come from a place where Intel is a CPU manufacturer, and that's how people

234
00:12:54,720 --> 00:12:58,600
are perceiving it a year ago, and now we're going to be providing leadership in AI.

235
00:12:58,600 --> 00:13:01,680
I think it's very exciting to see that transition and be part of it.

236
00:13:01,680 --> 00:13:04,240
So stay tuned for some cool things coming up.

237
00:13:04,240 --> 00:13:08,360
Along the line of some of those bets, you recently, or Brian recently published a blog

238
00:13:08,360 --> 00:13:13,280
post that talked about the billion dollars that the company is investing across the AI

239
00:13:13,280 --> 00:13:14,280
spectrum.

240
00:13:14,280 --> 00:13:15,280
Any comments on that?

241
00:13:15,280 --> 00:13:18,120
Yeah, there were a number of startups mentioned and some other things.

242
00:13:18,120 --> 00:13:23,000
Yeah, I mean, Intel is a huge, if not the biggest VC in the valley.

243
00:13:23,000 --> 00:13:25,400
So we invest in a lot of different kinds of companies.

244
00:13:25,400 --> 00:13:30,560
I mean, obviously, we look at it from strategic value standpoint, but also just from a, you

245
00:13:30,560 --> 00:13:33,000
know, like a monetary return, just like a VC.

246
00:13:33,000 --> 00:13:37,320
So we've placed a lot of bets there, and, you know, we want to see the ecosystem to build

247
00:13:37,320 --> 00:13:40,080
and innovate, and startups will wear a lot of that happens.

248
00:13:40,080 --> 00:13:43,720
Then beyond that, some of that investment is also internally what we're doing in aligning

249
00:13:43,720 --> 00:13:45,480
our resources around.

250
00:13:45,480 --> 00:13:51,160
So I think it's, again, it's a really good readout of the emphasis and focus we're putting

251
00:13:51,160 --> 00:13:52,160
on AI at Intel.

252
00:13:52,160 --> 00:13:53,160
Yeah.

253
00:13:53,160 --> 00:13:54,160
Absolutely.

254
00:13:54,160 --> 00:13:55,160
Well, great.

255
00:13:55,160 --> 00:13:58,160
Thanks so much, Naveen, for joining us and looking forward to catching up with you next

256
00:13:58,160 --> 00:13:59,160
time.

257
00:13:59,160 --> 00:14:00,160
Absolutely.

258
00:14:00,160 --> 00:14:01,160
Great talking with you.

259
00:14:01,160 --> 00:14:02,160
Great.

260
00:14:02,160 --> 00:14:03,160
All right.

261
00:14:03,160 --> 00:14:12,840
Everyone, I'm here at the AI conference with Scott Appland, who is the director of developer

262
00:14:12,840 --> 00:14:19,040
programs with Intel Nirvana, and we're here to talk about the dev cloud that was launched

263
00:14:19,040 --> 00:14:20,040
today.

264
00:14:20,040 --> 00:14:21,040
Welcome, Scott.

265
00:14:21,040 --> 00:14:22,040
Well, thank you.

266
00:14:22,040 --> 00:14:23,040
Good to be here.

267
00:14:23,040 --> 00:14:24,040
Great to have you.

268
00:14:24,040 --> 00:14:27,200
So it sounds like you had a big launch last night.

269
00:14:27,200 --> 00:14:28,440
How did it go?

270
00:14:28,440 --> 00:14:29,440
Really went well.

271
00:14:29,440 --> 00:14:35,120
So back about 10 months ago in November last year, we announced our AI Academy.

272
00:14:35,120 --> 00:14:42,000
So this was our program for helping students, developers, teachers really have more, learn

273
00:14:42,000 --> 00:14:45,600
more about AI, how to use it, get access to the technology and the tools.

274
00:14:45,600 --> 00:14:46,960
So we kicked that off.

275
00:14:46,960 --> 00:14:53,000
Today, we really announced the next stage of that, which is making cloud compute accessible

276
00:14:53,000 --> 00:14:57,240
to broad set of developers and students with our new Nirvana dev cloud.

277
00:14:57,240 --> 00:14:58,240
Okay.

278
00:14:58,240 --> 00:15:02,440
So tell us a little bit about the dev cloud and what the focus is there.

279
00:15:02,440 --> 00:15:07,720
And in particular, you know, compute, unlike a few years ago, compute is much more readily

280
00:15:07,720 --> 00:15:13,040
available on various public facing consumer clouds.

281
00:15:13,040 --> 00:15:14,840
What's different about dev cloud?

282
00:15:14,840 --> 00:15:15,840
Yeah.

283
00:15:15,840 --> 00:15:21,360
Well, you know, one of the challenges for folks getting started in AI is actually having

284
00:15:21,360 --> 00:15:27,080
access and being able to get started with compute in a way that's economical for them

285
00:15:27,080 --> 00:15:28,960
without having to invest in it.

286
00:15:28,960 --> 00:15:33,760
So for all of our Academy members, they'll have free access to the dev cloud.

287
00:15:33,760 --> 00:15:40,200
And this is a, yeah, this is a very large scale cluster and will have the latest Xeon scalable

288
00:15:40,200 --> 00:15:42,320
processors on there.

289
00:15:42,320 --> 00:15:47,160
And developers can sign up, they'll be, they can use it to sandbox, new projects they're

290
00:15:47,160 --> 00:15:51,080
working on, they can use it for their homework exercises they're doing in class.

291
00:15:51,080 --> 00:15:55,200
They can do just test out things or if they have a compelling project, they really want

292
00:15:55,200 --> 00:16:00,560
to get started and use it as Academy members, they sign up, they'll be given access.

293
00:16:00,560 --> 00:16:05,160
They can start for four weeks and use it for four weeks and then at the end of the four

294
00:16:05,160 --> 00:16:08,400
weeks, if they need it longer, then post the project they're working on.

295
00:16:08,400 --> 00:16:11,160
We'd like to see what they're working on and let other developers see what they're

296
00:16:11,160 --> 00:16:16,360
working on and they can get extended for another four weeks or even longer if it's necessary.

297
00:16:16,360 --> 00:16:22,200
So in this way, they're getting access to as much cloud compute as they're going to need

298
00:16:22,200 --> 00:16:24,840
for quite a while to get them up and started.

299
00:16:24,840 --> 00:16:29,520
It's not for commercial production type of applications, but a great way to get started.

300
00:16:29,520 --> 00:16:36,080
Oh, great, is there use of the dev cloud limited to, it doesn't sound like it's limited

301
00:16:36,080 --> 00:16:41,720
to just exercises that are part of the Academy, they can do any project that they come up

302
00:16:41,720 --> 00:16:42,720
with.

303
00:16:42,720 --> 00:16:43,720
Yeah.

304
00:16:43,720 --> 00:16:46,920
Let me just spend a few more minutes talking about the Academy what it is and you can

305
00:16:46,920 --> 00:16:49,400
understand how they use the dev cloud.

306
00:16:49,400 --> 00:16:53,200
So the Academy includes a lot of learning resources.

307
00:16:53,200 --> 00:16:59,760
So tutorials, online classes, webinars, webcasts, from basic getting started, machine learning

308
00:16:59,760 --> 00:17:04,280
101, deep learning 101, and intermediate to advanced.

309
00:17:04,280 --> 00:17:07,960
So a really good curriculum to learn about AI.

310
00:17:07,960 --> 00:17:12,520
But if you're already a professional developer and you just want to say, let's use the latest

311
00:17:12,520 --> 00:17:17,920
software that's optimized, let's maybe use neon framework or some other new Intel

312
00:17:17,920 --> 00:17:22,320
technology, you'll have access to that in the Academy and then you'll have technical

313
00:17:22,320 --> 00:17:23,600
support.

314
00:17:23,600 --> 00:17:29,920
So we have a real mix of professional developers, students are getting started, graduate students

315
00:17:29,920 --> 00:17:34,800
are working on research projects and they can all use the dev cloud.

316
00:17:34,800 --> 00:17:42,000
For example, some of, so just last night we had a dev jam and here in San Francisco is

317
00:17:42,000 --> 00:17:49,680
kind of a day zero of the O'Reilly conference and we had about 500 developers, students,

318
00:17:49,680 --> 00:17:56,480
startups attend this and on the stage I did a fireside chat with six of our students

319
00:17:56,480 --> 00:17:58,720
who are working on projects.

320
00:17:58,720 --> 00:18:02,440
And the types of projects that we're going on were just amazing, especially when you look

321
00:18:02,440 --> 00:18:03,960
at the variety.

322
00:18:03,960 --> 00:18:11,280
So one of them was doing a project on epilepsy and he was doing EG scans and connectivity

323
00:18:11,280 --> 00:18:17,960
analysis of the brain and using that to help patients manage epilepsy and predict seizures

324
00:18:17,960 --> 00:18:19,320
and things like that.

325
00:18:19,320 --> 00:18:21,960
So he's working on just a fascinating project there.

326
00:18:21,960 --> 00:18:26,160
Another student was doing a trail cam project.

327
00:18:26,160 --> 00:18:32,000
So if you're out in the wild and you have a trail cam, not only does it turn on record

328
00:18:32,000 --> 00:18:36,800
when a wildlife passed by, but it will try to recognize what type of wildlife that is

329
00:18:36,800 --> 00:18:38,120
and a lurch.

330
00:18:38,120 --> 00:18:43,040
So if it's a day they're run, yes it's a dangerous one and tell the campers nearby time to

331
00:18:43,040 --> 00:18:44,320
get out of there.

332
00:18:44,320 --> 00:18:51,040
Another student is working on mosquito detection and identification because mosquitoes there's

333
00:18:51,040 --> 00:18:55,480
thousands of varieties, but there's only a small number that are real dangerous that

334
00:18:55,480 --> 00:18:58,360
maybe carry malaria or Zika.

335
00:18:58,360 --> 00:19:04,200
So with his phone, he does create an application where it would take a photo, recognize what

336
00:19:04,200 --> 00:19:06,560
type of mosquitoes and tell if it's a dangerous type.

337
00:19:06,560 --> 00:19:07,560
Interesting.

338
00:19:07,560 --> 00:19:14,200
So that's just a sample, oh another fun one that I liked was a student from Rutgers who

339
00:19:14,200 --> 00:19:21,160
has developed an application where it will scan your head, look at your facial structure,

340
00:19:21,160 --> 00:19:28,440
your head structure and then based on popular hairstyles that you have similar facial structures

341
00:19:28,440 --> 00:19:33,360
recommend hairstyles for you and maybe a beard style as well.

342
00:19:33,360 --> 00:19:37,160
So you never have to worry anymore about what you should get to haircut, just have this

343
00:19:37,160 --> 00:19:40,400
app tell you exactly what your hair should look like and go get a cut like that.

344
00:19:40,400 --> 00:19:41,400
Oh wow.

345
00:19:41,400 --> 00:19:46,000
Quite a variety of things that they're working on and they have access to the dev cloud

346
00:19:46,000 --> 00:19:51,400
and can and to our technical support as well because we announced also today that we have

347
00:19:51,400 --> 00:19:58,360
a partnership with Tata Consulting Services to put in place an AI center of excellence.

348
00:19:58,360 --> 00:20:04,280
And we're going to leverage TCS's expertise in AI and use that to help to support the

349
00:20:04,280 --> 00:20:05,560
Academy members.

350
00:20:05,560 --> 00:20:10,160
So when they need to get stuck on a project or using the dev cloud, we'll have special

351
00:20:10,160 --> 00:20:14,720
engineers who can support them and provide the support to help them and they'll be located

352
00:20:14,720 --> 00:20:18,400
around the world because TCS is a worldwide organization.

353
00:20:18,400 --> 00:20:22,600
Now TCS is a consulting company it's hard to get a consulting company to do anything

354
00:20:22,600 --> 00:20:30,280
without dollars changing hands like if I'm an Academy member and I run into something

355
00:20:30,280 --> 00:20:35,440
and I need some help like how does that do I raise my hand and yeah.

356
00:20:35,440 --> 00:20:38,840
So the beauty of this is for the Academy members it's free.

357
00:20:38,840 --> 00:20:43,680
Of course there's a business model for Tata Consultancy in this as well but for Academy

358
00:20:43,680 --> 00:20:50,760
members, both the dev cloud and the support and the tutorials and training it's all free.

359
00:20:50,760 --> 00:20:58,160
And our desire is to help as many students, developers get smart, learning and discover new

360
00:20:58,160 --> 00:21:01,280
ways of using it as possible.

361
00:21:01,280 --> 00:21:07,880
And then is there a mechanism whereby if I say I'm working on something it starts out

362
00:21:07,880 --> 00:21:12,280
as a little project, side project in the corner of the office or something like that and

363
00:21:12,280 --> 00:21:18,600
then it grows into something that's more important for my company, like to get more help.

364
00:21:18,600 --> 00:21:20,360
Yeah, we do look for that.

365
00:21:20,360 --> 00:21:25,280
So we're always kind of monitoring and watching for those really cool things to emerge and

366
00:21:25,280 --> 00:21:27,560
see how we can help them be more successful.

367
00:21:27,560 --> 00:21:32,880
A lot of times they'll start to attract all kinds of support and interest in general but

368
00:21:32,880 --> 00:21:37,680
early on it's really helpful that we can say hey, this guy's got something going here.

369
00:21:37,680 --> 00:21:42,520
Let's give him a little extra boost so we're looking for that constantly and on my team

370
00:21:42,520 --> 00:21:47,800
what we've developed to do this is a program called Student Ambassadors.

371
00:21:47,800 --> 00:21:53,000
So since we rolled out the Academy, we've been going out to universities worldwide and

372
00:21:53,000 --> 00:21:57,880
run workshops, AI workshops and we'll introduce technology to give them the basics and then

373
00:21:57,880 --> 00:22:02,520
we'll hear what the students are working on and those students are really passionate

374
00:22:02,520 --> 00:22:07,560
doing something really cool, we'll see if they want to become ambassadors for Intel.

375
00:22:07,560 --> 00:22:12,960
And if they're interested then we'll give them even more training, more access to technology

376
00:22:12,960 --> 00:22:18,480
and in return just ask them to go tell other students about what they're doing and share

377
00:22:18,480 --> 00:22:19,800
their knowledge.

378
00:22:19,800 --> 00:22:25,320
So these six that were on the stage with me last night were ambassadors, one from UC Santa

379
00:22:25,320 --> 00:22:32,520
Barbara, one from MIT, one from Rutgers, one from let's see ASU and that's just the US.

380
00:22:32,520 --> 00:22:36,960
We started to have ambassadors all across the world from India, China, lots of them in

381
00:22:36,960 --> 00:22:42,680
Europe as well and I'd say those are the cream of the crop that we're really monitoring

382
00:22:42,680 --> 00:22:45,880
to see what cool things are they going to come up with.

383
00:22:45,880 --> 00:22:51,160
And if someone's listening and wants to get involved in the ambassador program, is there

384
00:22:51,160 --> 00:22:55,680
a mechanism for signaling their interests or do they just get involved in the Academy

385
00:22:55,680 --> 00:22:58,400
and do cool things and you'll figure you'll find them?

386
00:22:58,400 --> 00:22:59,960
No, they actually can apply.

387
00:22:59,960 --> 00:23:06,160
So online at the Academy you can just search on Intel Nirvana Academy online and you'll

388
00:23:06,160 --> 00:23:11,840
find it and then there's a apply to become a student ambassador.

389
00:23:11,840 --> 00:23:15,920
And you can fill out what you're working on, why you want to be an ambassador and then

390
00:23:15,920 --> 00:23:20,640
we'll have someone follow up to do an interview and see if you're ready for that.

391
00:23:20,640 --> 00:23:25,800
Okay, so interesting, sounds like the DevCloud is supported by some pretty interesting programs.

392
00:23:25,800 --> 00:23:33,680
In terms of the DevCloud itself, if I'm an AI developer and I'm coming to, I discover

393
00:23:33,680 --> 00:23:43,160
the Academy and DevCloud and have an existing tool chain instead of tools that I'm using,

394
00:23:43,160 --> 00:23:48,960
will those work on the DevCloud or do I need to port what I'm doing to the Intel Nirvana

395
00:23:48,960 --> 00:23:52,400
tool stack in order to use the DevCloud?

396
00:23:52,400 --> 00:23:56,880
There's a really good chance that they will already be preloaded on the DevCloud.

397
00:23:56,880 --> 00:24:01,440
So the DevCloud is not just for specific frameworks.

398
00:24:01,440 --> 00:24:07,680
It's really for, first of all, the Intel Xeon scalable processor is our hardware platform

399
00:24:07,680 --> 00:24:13,120
and that will extend that when we have the new flavors of Nirvana technology come out.

400
00:24:13,120 --> 00:24:15,240
So we'll keep building that hardware.

401
00:24:15,240 --> 00:24:22,200
But on the software side, it's whatever software that will run great and that developers

402
00:24:22,200 --> 00:24:23,160
and students want to use.

403
00:24:23,160 --> 00:24:29,040
So today, the DevCloud supports Neon, Spudges, TensorFlow, Spudges, Cafe, Spudges,

404
00:24:29,040 --> 00:24:33,960
Deano, Keras, most all the popular frameworks.

405
00:24:33,960 --> 00:24:37,800
And then Intel spent a lot of time optimizing them to run well on CPU.

406
00:24:37,800 --> 00:24:45,600
If you go back a couple of years ago, the frameworks ran great on GPUs but not so well on CPUs.

407
00:24:45,600 --> 00:24:51,080
We put a lot of investment over the last nine months or so and seen the performance improve

408
00:24:51,080 --> 00:24:56,040
up to 100X on running those frameworks on CPUs.

409
00:24:56,040 --> 00:25:03,040
So now we have optimized frameworks, pretty much the choice of the user gets to pick that

410
00:25:03,040 --> 00:25:11,360
and then he'll get 200GB of secure storage area for his files and load up his, you know,

411
00:25:11,360 --> 00:25:17,000
queue up his project and then we'll run it in the batch mode and then he gets notified

412
00:25:17,000 --> 00:25:19,800
when it's ready and can do it again.

413
00:25:19,800 --> 00:25:24,480
And so I suppose there are no GPUs in the DevCloud.

414
00:25:24,480 --> 00:25:27,360
No, they were not necessary.

415
00:25:27,360 --> 00:25:32,720
And so you talked about some of the performance metrics that you've seen recently.

416
00:25:32,720 --> 00:25:36,560
These are for this 100X this improvement over time.

417
00:25:36,560 --> 00:25:40,600
This is for training or inference or both.

418
00:25:40,600 --> 00:25:42,280
That's for training really.

419
00:25:42,280 --> 00:25:47,880
And you know, deep learning, first of all, machine learning, the vast majority of the

420
00:25:47,880 --> 00:25:53,960
servers that are running machine learning workloads are powered by Xeon platforms, Xeon servers.

421
00:25:53,960 --> 00:25:59,200
Deep learning is a subset and a fairly small but important subset of machine learning.

422
00:25:59,200 --> 00:26:04,320
And that's an area where we've seen the software optimizations make a huge difference on

423
00:26:04,320 --> 00:26:05,920
the time to train.

424
00:26:05,920 --> 00:26:13,400
And so developers now are seeing, you know, what used to take months down to minutes to

425
00:26:13,400 --> 00:26:16,400
do training on Xeon scalable processor.

426
00:26:16,400 --> 00:26:19,600
So the DevCloud will give you access to that.

427
00:26:19,600 --> 00:26:23,720
If developers have it tried it lately, they should try it now and see really, you know,

428
00:26:23,720 --> 00:26:25,920
the great performance will get.

429
00:26:25,920 --> 00:26:32,680
And so the 100X performance in the months down to minutes, that's relative to past performance

430
00:26:32,680 --> 00:26:36,440
on the Xeon with CPUs.

431
00:26:36,440 --> 00:26:41,480
Do you have any published comparisons relative to GPUs?

432
00:26:41,480 --> 00:26:46,440
And I'll just note that a lot of it is really based on the software optimization more

433
00:26:46,440 --> 00:26:47,440
than anything.

434
00:26:47,440 --> 00:26:49,360
It's made seem the huge difference.

435
00:26:49,360 --> 00:26:55,880
And we're seeing folks in the industry now start to publish really good results on the

436
00:26:55,880 --> 00:26:59,440
training site as well, compared to other alternatives in the market.

437
00:26:59,440 --> 00:27:04,320
So I don't know that we have any yet published on our site, but in general, we're seeing

438
00:27:04,320 --> 00:27:06,520
some really good results in the industry.

439
00:27:06,520 --> 00:27:10,160
And then we're seeing really good results on cloud service providers and what they're

440
00:27:10,160 --> 00:27:12,200
using as well for the technology.

441
00:27:12,200 --> 00:27:19,280
You mentioned cloud service providers is DevCloud hosted by Intel Nirvana, or have you

442
00:27:19,280 --> 00:27:23,360
partnered with one or more of the cloud service providers to make it available?

443
00:27:23,360 --> 00:27:29,160
It's really a part of our Nirvana cloud and really aligning those together.

444
00:27:29,160 --> 00:27:35,000
For the service providers, AWS or Google Cloud, they have great services today.

445
00:27:35,000 --> 00:27:39,240
They're using Xeon scalable and developer students can use those too.

446
00:27:39,240 --> 00:27:43,120
However, it can become costly for a student just getting started.

447
00:27:43,120 --> 00:27:48,680
So this is a way for them to stand bucks and get started and then move into a CSP model

448
00:27:48,680 --> 00:27:51,240
when they have a business that can support that.

449
00:27:51,240 --> 00:27:52,240
Okay.

450
00:27:52,240 --> 00:27:53,240
Okay.

451
00:27:53,240 --> 00:28:00,960
So then the Intel Nirvana cloud is, that's something that you're building and built and

452
00:28:00,960 --> 00:28:07,320
are building and host in your own data centers and manage independent of the large cloud

453
00:28:07,320 --> 00:28:08,320
providers.

454
00:28:08,320 --> 00:28:09,320
That's correct.

455
00:28:09,320 --> 00:28:10,320
That's correct.

456
00:28:10,320 --> 00:28:11,320
Right.

457
00:28:11,320 --> 00:28:17,240
And another thing I'll mention too is that Intel, one of the differentiators from Intel

458
00:28:17,240 --> 00:28:23,680
is we have such a broad portfolio of offerings and from the data center to the edge.

459
00:28:23,680 --> 00:28:28,040
And in the data center, of course, there's a training, there's inference on the Xeon,

460
00:28:28,040 --> 00:28:32,640
but we also have the FPGA product line and recently Microsoft announced that they're going

461
00:28:32,640 --> 00:28:39,000
to use the Stratics 10 FPGA for their brainwave project to really power all of the inference

462
00:28:39,000 --> 00:28:42,640
in their DL platform and brainwave.

463
00:28:42,640 --> 00:28:47,880
And we see a lot of opportunity with FPGAs as well, both in the data center and also at

464
00:28:47,880 --> 00:28:49,840
the edge for the inference piece.

465
00:28:49,840 --> 00:28:53,600
Can you tell us a little bit about brainwave or folks that missed that announcement?

466
00:28:53,600 --> 00:29:00,080
Well, I'm not the necessarily expert on brainwave, but it is Microsoft's deep learning platform

467
00:29:00,080 --> 00:29:07,200
and they announced it's going to use FPGA and Stratics 10 for it because of the low latency,

468
00:29:07,200 --> 00:29:09,160
low power, high throughput.

469
00:29:09,160 --> 00:29:14,760
It provides and the flexibility, FPGA is great in the flexibility it provides as AI evolves

470
00:29:14,760 --> 00:29:15,760
and changes.

471
00:29:15,760 --> 00:29:16,760
Right.

472
00:29:16,760 --> 00:29:17,760
Okay.

473
00:29:17,760 --> 00:29:18,760
All right, great.

474
00:29:18,760 --> 00:29:22,400
And then the last thing I'll mention too is if we talk about the portfolio is we also

475
00:29:22,400 --> 00:29:28,200
have at the edge, we have people developing solutions at the edge for deep learning that

476
00:29:28,200 --> 00:29:36,440
use Adam, core processor, Movidius for the video processing and whole host of this.

477
00:29:36,440 --> 00:29:39,960
All of this is going to be part of the academy too, so developers can not only learn about

478
00:29:39,960 --> 00:29:44,240
okay, I want to do the training, the inference in the data center, but at the edge too and

479
00:29:44,240 --> 00:29:46,440
put full end to end solution.

480
00:29:46,440 --> 00:29:47,440
Okay.

481
00:29:47,440 --> 00:29:48,440
Awesome.

482
00:29:48,440 --> 00:29:49,440
Awesome.

483
00:29:49,440 --> 00:29:55,160
One question I've got for you is in your role as overseeing developer programs, there

484
00:29:55,160 --> 00:30:02,160
are some interesting differences between the needs of traditional enterprise developers

485
00:30:02,160 --> 00:30:09,160
and more data science users, you know, data scientists that, you know, may also probably

486
00:30:09,160 --> 00:30:12,640
also fall under developer programs for you.

487
00:30:12,640 --> 00:30:17,400
Can you talk a little bit about how, you know, the different offerings you have that, you

488
00:30:17,400 --> 00:30:21,520
know, target these different communities and more generally, like how you're looking

489
00:30:21,520 --> 00:30:27,680
at these communities and how you plan, you know, evolve your offerings to serve both

490
00:30:27,680 --> 00:30:29,440
of them and give them what they need?

491
00:30:29,440 --> 00:30:30,440
Sure.

492
00:30:30,440 --> 00:30:31,440
And that is a great point.

493
00:30:31,440 --> 00:30:38,640
AI really introduced us to new types of an audience for us because I run developer programs

494
00:30:38,640 --> 00:30:46,120
for Intel and we cover the gamut from server to mobile and game developers and IOT developers

495
00:30:46,120 --> 00:30:51,520
across the board and we jumped into AI, yeah, all of a sudden there's this data scientist

496
00:30:51,520 --> 00:30:57,520
and they're like, okay, we're used to maybe dealing more with C++ developers and helping

497
00:30:57,520 --> 00:31:03,680
them optimize their code for the latest hardware that we had and for data scientists, it's

498
00:31:03,680 --> 00:31:08,320
a different ball game and first of all, most of them are using Python.

499
00:31:08,320 --> 00:31:11,760
What we've had to do is, okay, let's focus on how do we help them?

500
00:31:11,760 --> 00:31:15,720
They're going to be using frameworks, they need optimized frameworks, they need optimized

501
00:31:15,720 --> 00:31:21,600
versions of Python, they need really to understand the basics of machine learning and how to

502
00:31:21,600 --> 00:31:29,200
manage the data, how to apply machine learning versus how to really code in many cases.

503
00:31:29,200 --> 00:31:34,960
So we really had to look at this differently and start to say, okay, for these guys, let's

504
00:31:34,960 --> 00:31:37,640
teach them the basics on how to get started.

505
00:31:37,640 --> 00:31:42,640
Let's look at the tools that they will need from, like Python, for example.

506
00:31:42,640 --> 00:31:47,080
We have an Intel distribution of Python that is really good for performance and really

507
00:31:47,080 --> 00:31:48,920
good for AI and developer.

508
00:31:48,920 --> 00:31:51,760
And Intel distribution of Python?

509
00:31:51,760 --> 00:31:53,760
Yes, it's a parallel Python.

510
00:31:53,760 --> 00:31:54,760
Really?

511
00:31:54,760 --> 00:31:58,680
Oh yeah, so when we tell data scientists about this too, they're actually really excited

512
00:31:58,680 --> 00:32:01,560
as well because it can really help the performance of their application.

513
00:32:01,560 --> 00:32:04,480
Where do you find this Intel distribution of Python?

514
00:32:04,480 --> 00:32:09,080
It's easy to find, you just search on exactly that, you'll find it, you'll find it on our

515
00:32:09,080 --> 00:32:12,240
Academy, we have lots of information about it there and the benefits.

516
00:32:12,240 --> 00:32:16,240
And is it new kind of as part of the Academy or has it been around for?

517
00:32:16,240 --> 00:32:21,240
It's been around a little while, but it's not that long, I'd say, yeah, last year, I believe

518
00:32:21,240 --> 00:32:24,560
it was when we rolled it out in 2016.

519
00:32:24,560 --> 00:32:28,920
And you said it's optimized around parallel and distributed?

520
00:32:28,920 --> 00:32:35,120
Yeah, particularly for parallel, running really well in a parallel environment and giving

521
00:32:35,120 --> 00:32:37,320
the best performance out of Python applications.

522
00:32:37,320 --> 00:32:42,920
And what's an example of a parallel environment and a workload that you might use this Python

523
00:32:42,920 --> 00:32:44,800
distribution with?

524
00:32:44,800 --> 00:32:51,240
Well, I don't know if I have a real good example right there, but let me tell you about an example

525
00:32:51,240 --> 00:32:56,120
that something we did just recently, we just wrapped up as we did a contest with Kaggle.com.

526
00:32:56,120 --> 00:32:58,720
You heard it from other Kaggle.

527
00:32:58,720 --> 00:33:04,560
And we said, let's find a partner in the industry who wants to solve a real world AI problem

528
00:33:04,560 --> 00:33:05,560
and then eat some help.

529
00:33:05,560 --> 00:33:11,360
And so we partnered with mobile ODT and they're all about early detection of cancer and

530
00:33:11,360 --> 00:33:16,440
how do they do, how do they provide low cost devices to early deduct cancer?

531
00:33:16,440 --> 00:33:21,200
And so we, they provided a data set of 10,000 images, okay?

532
00:33:21,200 --> 00:33:26,160
And we provided the developers with parallel Python with access.

533
00:33:26,160 --> 00:33:29,320
This was an early version of our dev cloud, we were kind of in the pilot mode.

534
00:33:29,320 --> 00:33:33,400
So they got parallel Python, they got a dev cloud, they got, in this case, it was optimized

535
00:33:33,400 --> 00:33:40,520
cafe and we said, all right, whoever can provide the best algorithms and become the best

536
00:33:40,520 --> 00:33:45,360
at the detection of the images that are cancerous will win lots of good prizes.

537
00:33:45,360 --> 00:33:47,360
And the response was great.

538
00:33:47,360 --> 00:33:54,760
We had up to 1,000 data scientists and developers competing on this and accessing the dev cloud

539
00:33:54,760 --> 00:33:56,320
on a daily basis.

540
00:33:56,320 --> 00:34:01,080
So it was a great test of this, it was a great test of the tool set and the whole model

541
00:34:01,080 --> 00:34:02,080
here.

542
00:34:02,080 --> 00:34:07,400
And at the end of the day, mobile ODT was really excited about what they learned and are

543
00:34:07,400 --> 00:34:11,640
now falling out with the winners to say, okay, how do we productize what you've done

544
00:34:11,640 --> 00:34:13,640
here together?

545
00:34:13,640 --> 00:34:14,640
Interesting.

546
00:34:14,640 --> 00:34:19,480
I think a lot of folks use Python from, you know, they'll use like condos or some of these

547
00:34:19,480 --> 00:34:26,680
other Python distributions like does, do you envision, you know, partnerships to, how

548
00:34:26,680 --> 00:34:29,160
do you get this distribution of Python out there, right?

549
00:34:29,160 --> 00:34:34,560
To have people aren't, a lot of, I imagine to not know about it that a lot of people don't

550
00:34:34,560 --> 00:34:35,560
know about it.

551
00:34:35,560 --> 00:34:43,000
And I mean, I've seen this, this, yeah, I think just based on other things that I've seen

552
00:34:43,000 --> 00:34:47,040
Intel do in the past like, for example, in the Hadoop space, right?

553
00:34:47,040 --> 00:34:52,800
So there's a ton of interesting innovations that have happened in taking, you know, Intel's

554
00:34:52,800 --> 00:34:58,960
deep knowledge of the hardware and like kind of driving that into, you know, the mainstream

555
00:34:58,960 --> 00:35:05,240
Hadoop distributions and making them, you know, just making them out of the box more

556
00:35:05,240 --> 00:35:10,360
performant based on or more secure, like there's some security and encryption stuff in

557
00:35:10,360 --> 00:35:16,840
the Hadoop example, you know, I know of examples where, you know, folks from Intel have partnered

558
00:35:16,840 --> 00:35:21,920
with, you know, vendors like Docker and, you know, other, you know, lots of, lots of open

559
00:35:21,920 --> 00:35:23,760
source engagement.

560
00:35:23,760 --> 00:35:27,280
But in this Python case, like, how do you get this, how do you get this out into the

561
00:35:27,280 --> 00:35:28,280
wild?

562
00:35:28,280 --> 00:35:33,720
Well, a lot of that happens organically if you have a, you know, good product and there's

563
00:35:33,720 --> 00:35:38,040
a Python community out there, which is quite active and they start to hear about the word

564
00:35:38,040 --> 00:35:39,760
will spread organically.

565
00:35:39,760 --> 00:35:46,620
But to help that, we're becoming pretty proactive on awareness, thriving just social media

566
00:35:46,620 --> 00:35:53,560
outreach, some digital online marketing and other academy awareness in general where Python

567
00:35:53,560 --> 00:35:58,320
is becoming a bigger message there that, hey, did you know this distribution is available

568
00:35:58,320 --> 00:35:59,960
and with these benefits?

569
00:35:59,960 --> 00:36:04,280
So I think it's a combination of those and it won't be long when it's before it's pretty

570
00:36:04,280 --> 00:36:06,800
well known within that community.

571
00:36:06,800 --> 00:36:08,600
Oh, interesting.

572
00:36:08,600 --> 00:36:11,640
Any other cool stuff to tell me about that I didn't know about it?

573
00:36:11,640 --> 00:36:14,160
I don't think so.

574
00:36:14,160 --> 00:36:15,600
I think we hit on the main ones.

575
00:36:15,600 --> 00:36:19,760
I think the mention is that the academy is growing fast.

576
00:36:19,760 --> 00:36:27,040
We already have, coming up on a 50,000 members and we're, we've been running workshops

577
00:36:27,040 --> 00:36:32,200
around the world at universities, we'll have probably 200 universities that will be participating

578
00:36:32,200 --> 00:36:39,600
by the end of this year and trained about, I think we're on 25,000 developers and students

579
00:36:39,600 --> 00:36:41,120
so far this year.

580
00:36:41,120 --> 00:36:46,040
So it's really ramping up fast and we have some big aggressive goals, really helping to

581
00:36:46,040 --> 00:36:51,760
bring AI to the masses and through this dev cloud make compute available, through the

582
00:36:51,760 --> 00:36:56,840
training, help them learn about it, the technical support with TCS, we're pretty serious

583
00:36:56,840 --> 00:37:02,640
about helping people learn and grow and use AI to do really cool things.

584
00:37:02,640 --> 00:37:08,600
Well, it's a huge growth opportunity so I think it's a smart move and makes sense.

585
00:37:08,600 --> 00:37:14,120
It makes me think a little bit of Apple's strategy back in the day to get into colleges

586
00:37:14,120 --> 00:37:19,600
and universities with the Macintosh which help propel them later on.

587
00:37:19,600 --> 00:37:24,680
So congrats on that and congrats on the success of the academy so far.

588
00:37:24,680 --> 00:37:26,120
Thank you very much.

589
00:37:26,120 --> 00:37:27,120
Yeah.

590
00:37:27,120 --> 00:37:28,120
Thanks so much.

591
00:37:28,120 --> 00:37:29,120
God.

592
00:37:29,120 --> 00:37:35,200
All right, everyone, that's our show for today.

593
00:37:35,200 --> 00:37:40,120
Thank you so much for listening and for your ongoing feedback and support.

594
00:37:40,120 --> 00:37:45,320
For more information on Naveen and Scott, for links to dev cloud or the AI Academy and

595
00:37:45,320 --> 00:37:51,360
any of the other topics covered in this episode, head on over to twimaleigh.com slash talk slash

596
00:37:51,360 --> 00:37:53,360
51.

597
00:37:53,360 --> 00:38:00,520
For the rest of this series, visit twimaleigh.com slash AISF 2017.

598
00:38:00,520 --> 00:38:05,520
And please, please, please send us any questions or comments that you may have for us or for

599
00:38:05,520 --> 00:38:11,880
our guests via Twitter at twimaleigh or at Sam Charrington or leave a comment on the

600
00:38:11,880 --> 00:38:13,600
show notes page.

601
00:38:13,600 --> 00:38:17,440
There are a ton of great conferences coming up through the end of the year.

602
00:38:17,440 --> 00:38:21,960
To keep up to date on which events will be attending and hopefully meet us there, check

603
00:38:21,960 --> 00:38:31,560
out our new events page at twimaleigh.com slash events, twimaleigh.com slash events.

604
00:38:31,560 --> 00:39:00,080
Thanks again for listening and catch you next time.

