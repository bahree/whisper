1
00:00:00,000 --> 00:00:15,360
Welcome to the Twimal AI Podcast. I'm your host, Sam Charrington.

2
00:00:15,360 --> 00:00:28,160
Before we get going, I'd like to send a huge thanks to LinkedIn for sponsoring today's show.

3
00:00:29,840 --> 00:00:33,760
LinkedIn Engineering solves complex challenges at scale to create economic

4
00:00:33,760 --> 00:00:40,160
opportunity for every member of the global workforce. AI and ML are integral aspects of almost

5
00:00:40,160 --> 00:00:45,520
every product the company builds for its members and customers. LinkedIn's highly structured

6
00:00:45,520 --> 00:00:50,800
dataset gives their data scientists and researchers the ability to conduct applied research to

7
00:00:50,800 --> 00:00:56,160
improve member experiences. To learn more about the work of LinkedIn Engineering, visit

8
00:00:56,160 --> 00:01:01,360
engineering.linkedin.com slash blog and now on to the show.

9
00:01:01,360 --> 00:01:11,760
All right, everybody. I am here in Santa Clara at the first O'Reilly TensorFlow World conference.

10
00:01:12,320 --> 00:01:16,400
And I've got the pleasure of being seated with Jonathan Hong. Jonathan is a senior software

11
00:01:16,400 --> 00:01:21,840
engineer at LinkedIn and he is presenting here at the conference tomorrow. Is that right, Jonathan?

12
00:01:21,840 --> 00:01:25,760
Oh, yep. That's correct. On your experiences, scale,

13
00:01:25,760 --> 00:01:33,360
link TensorFlow at LinkedIn. Welcome to the Twimal AI Podcast. Thank you. Before we jump into

14
00:01:33,360 --> 00:01:39,440
your talk and your project, I'd love to learn a little bit about your background and how you came

15
00:01:39,440 --> 00:01:49,120
to work on machine learning infrastructure at LinkedIn. Yeah. So back in 2014, I joined LinkedIn

16
00:01:49,120 --> 00:01:56,960
as an intern on what was then called the Hadoop development team. So we handled the Hadoop

17
00:01:56,960 --> 00:02:08,560
infrastructure at LinkedIn for storage and compute and compute orchestration. So I rejoined LinkedIn

18
00:02:08,560 --> 00:02:16,960
the next year in 2015 on the same team. When I joined, I was working on the compute

19
00:02:16,960 --> 00:02:24,560
infrastructure at LinkedIn, which is yarn in the Hadoop project. So we were building some

20
00:02:24,560 --> 00:02:32,000
enhancements around compute efficiency, making sure we were getting good ROI on the hardware

21
00:02:32,000 --> 00:02:39,040
that our jobs were running on. So I worked on that for a few years. Was this the Tony project or

22
00:02:39,040 --> 00:02:45,920
was that separate? No, so this is separate. This was yarn specific. So nothing related to machine

23
00:02:45,920 --> 00:02:54,640
learning yet. Just making sure we have Hadoop clusters at LinkedIn that we manage a couple

24
00:02:54,640 --> 00:03:02,480
of thousands of nodes and making sure that things are running efficiently. So I worked on that

25
00:03:02,480 --> 00:03:13,680
for a few years. And then in late 2017, I'd say there was a lot of interest in using deep learning

26
00:03:13,680 --> 00:03:21,360
to improve the insights that we were giving our members. So we started exploring using

27
00:03:21,360 --> 00:03:29,360
TensorFlow as our deep learning framework. And so we were kind of experimenting with various

28
00:03:29,360 --> 00:03:36,240
existing frameworks in the open source world for running TensorFlow on Hadoop cluster.

29
00:03:36,240 --> 00:03:45,600
So we explored some projects and none of them really fit our needs exactly. So that's when we

30
00:03:45,600 --> 00:03:52,480
started to build this project called Tony, which stands for TensorFlow on yarn. And so this is our

31
00:03:52,480 --> 00:03:57,760
in-house solution for running distributed TensorFlow on our Hadoop clusters. I'm curious,

32
00:03:57,760 --> 00:04:02,720
what were some of the things that you looked at that didn't quite work for you? Yeah, so we looked

33
00:04:02,720 --> 00:04:10,400
at a few options. The first one was a project called TensorFlow on Spark. So this was open-sourced

34
00:04:10,400 --> 00:04:19,360
by Yahoo. I don't know the exact date. So the concept there is pretty similar. Instead of running your

35
00:04:19,360 --> 00:04:25,840
TensorFlow training and modeling code directly on your yarn cluster, you would run it on a

36
00:04:25,840 --> 00:04:34,400
Spark cluster, which usually runs on a yarn cluster. And so that worked reasonably well, but there

37
00:04:34,400 --> 00:04:43,200
were some feature gaps that we couldn't overcome. So at the time, there wasn't great support for

38
00:04:43,200 --> 00:04:50,400
fault tolerance in that project. I know since then it's improved. But at the time, this was a

39
00:04:50,400 --> 00:04:58,160
big blocker for us. And then a couple of other things that are related to kind of the

40
00:04:58,960 --> 00:05:05,040
Spark execution model. So one of them was that Spark didn't have support for

41
00:05:06,080 --> 00:05:13,840
GPU requesting and scheduling. And so a lot of our AI engineers, they were interested in running

42
00:05:13,840 --> 00:05:21,040
their distributed TensorFlow training on GPU hardware to accelerate the speed at which they can

43
00:05:21,040 --> 00:05:29,120
iterate. And so since Spark didn't have support for this, this was one of the big reasons we

44
00:05:29,120 --> 00:05:35,680
decided to build something else that we could integrate that GPU support with. And then the last

45
00:05:35,680 --> 00:05:44,560
thing was more related to Spark itself. So kind of the Spark execution model is, you know, you have

46
00:05:45,120 --> 00:05:54,240
a driver and a bunch of executors in your job. And the problem here is that all of your executors

47
00:05:54,240 --> 00:06:01,760
need to share the same resource profile, essentially. And this didn't really mix well with the

48
00:06:01,760 --> 00:06:09,120
TensorFlow execution model where you have various job types such as your like your perimeter servers

49
00:06:09,120 --> 00:06:16,480
or your workers and things like that. And each of these job types may require different resource

50
00:06:16,480 --> 00:06:22,880
profiles. And so if you're running TensorFlow on Spark, this won't really work. And then you end

51
00:06:22,880 --> 00:06:30,560
up with a lot of resource wastage. Yeah. And so maybe taking a step back, what's the overarching

52
00:06:30,560 --> 00:06:37,040
motivation for running TensorFlow on the Hadoop clusters? Is it that you have them in there there?

53
00:06:37,040 --> 00:06:46,160
And you want to use the machines? Is it that, you know, you like yarn as a general kind of workload

54
00:06:46,160 --> 00:06:53,600
orchestration system? And maybe kind of an adjacent question, you know, if you didn't have that

55
00:06:53,600 --> 00:06:57,360
existing investment, would you do the same thing? Would you stand up with the Hadoop cluster and

56
00:06:57,360 --> 00:07:02,000
then run TensorFlow on it? Or would you be going in a totally different direction? Yeah. So

57
00:07:02,960 --> 00:07:07,840
I think our biggest motivation for building Tony was because we had these Hadoop clusters.

58
00:07:08,480 --> 00:07:15,360
So LinkedIn has invested in Hadoop as our de facto data processing platform for many years now.

59
00:07:17,040 --> 00:07:23,840
You know, even before I joined the company. Sure. And so, you know, teams across our company are

60
00:07:23,840 --> 00:07:33,600
running very diverse workloads at scale on our Hadoop clusters. And so the Hadoop ecosystem at

61
00:07:33,600 --> 00:07:40,480
LinkedIn is very mature. And so we're running these clusters with thousands of nodes, you know,

62
00:07:40,480 --> 00:07:50,880
petabytes of compute. And so we wanted to use our infrastructure and our expertise in Hadoop and

63
00:07:50,880 --> 00:07:59,600
build a way to run TensorFlow on this infrastructure. And historically, you know, Hadoop offered

64
00:07:59,600 --> 00:08:05,360
this advantage of, you know, in the context of MapReduce, this kind of locality between your

65
00:08:05,360 --> 00:08:12,480
compute and your data. Does that have any relevance in the machine learning model training world?

66
00:08:12,480 --> 00:08:23,200
Yeah. So ideally, the model training would be bounded by your compute speed. And so hopefully,

67
00:08:23,200 --> 00:08:32,000
IO doesn't become a concern. Yeah. We have found in the past that IO was a big limiter for us. But

68
00:08:33,360 --> 00:08:39,440
we don't think it was related to locality reasons. You're just a bad model or training or something

69
00:08:39,440 --> 00:08:45,600
like that. Okay. Okay. I've had Beechan on the show before talking about ProML. What's the

70
00:08:45,600 --> 00:08:56,000
relationship between Tony and ProML? Yeah. So the idea behind ProML was to give our AI engineers a

71
00:08:56,000 --> 00:09:03,360
better experience for building and machine learning pipelines. So you know, you have your data

72
00:09:03,360 --> 00:09:09,840
pre-processing phase. You may be doing some feature extraction, things like that. And then

73
00:09:09,840 --> 00:09:16,160
you have your model training and then you can save your model and then go onto the serving phase.

74
00:09:17,440 --> 00:09:26,640
And so the Tony part is kind of fills the model training part of this pipeline. And then we have

75
00:09:26,640 --> 00:09:34,800
some internal libraries to link all these systems together. Okay. So ProML is kind of a layer of

76
00:09:34,800 --> 00:09:39,840
abstraction that sits on top of a bunch of things. Tony being one of those on the training side.

77
00:09:39,840 --> 00:09:46,320
Yeah, exactly. Cool. So tell us about your presentation. How's your presentation structured?

78
00:09:47,040 --> 00:09:53,280
Yeah. So it's kind of a mix of the things that we've talked about kind of the

79
00:09:53,280 --> 00:10:00,160
hoodie ecosystem at LinkedIn, what that looks like. And then kind of going into the story of

80
00:10:01,200 --> 00:10:07,760
why we were looking at TensorFlow as our deep learning framework and kind of what the experience

81
00:10:07,760 --> 00:10:17,600
was like for our AI engineers in running either single node or distributed TensorFlow back in 2017

82
00:10:17,600 --> 00:10:24,880
when our deep learning infrastructure was not very mature. So talking about what that experience

83
00:10:24,880 --> 00:10:30,640
was like some of the gaps that we saw. But maybe pause here. It sounds like you have some interesting

84
00:10:30,640 --> 00:10:36,480
stories there. What's the kind of what what what what did that world look like and how does that

85
00:10:36,480 --> 00:10:43,280
contrast to how it looks today? Yeah. So I think the biggest gaps there were

86
00:10:43,280 --> 00:10:52,960
users would have to like AI engineers would have to set up their own training environment either

87
00:10:52,960 --> 00:11:00,880
locally or on machines that we provided them. And so there wasn't really like a set of managed

88
00:11:00,880 --> 00:11:06,320
compute hardware that people could run on. So it was it was kind of like a free for all wild west

89
00:11:06,320 --> 00:11:11,360
situation. You know, you have all this compute hardware sitting there, but there's nothing to

90
00:11:11,360 --> 00:11:19,600
manage it. So it kind of ends up being the user who has to figure out which machines are available

91
00:11:20,800 --> 00:11:25,200
when you run into like race conditions where I see this machine is available, but so on

92
00:11:25,200 --> 00:11:31,840
else does and then you end up kind of butting heads. Yeah. So that was the biggest issue. And you

93
00:11:31,840 --> 00:11:38,000
know, especially with like GPU hardware, this becomes an even bigger issue because you only have

94
00:11:38,000 --> 00:11:46,400
so many GPUs on a single machine. And you end up running into, you know, multi-tenancy issues

95
00:11:46,400 --> 00:11:52,800
a lot, which is what we experienced. Yeah, the race condition, race condition issue is that's

96
00:11:52,800 --> 00:11:58,400
an interesting one I hadn't thought about that particular example of you've got some shared

97
00:11:58,400 --> 00:12:03,040
resource and two people see it and want to take advantage of it and then they spend something

98
00:12:03,040 --> 00:12:08,080
up and now they're colliding. Yeah, exactly. The ones wins, but you know, the other person loses.

99
00:12:08,080 --> 00:12:16,000
Right. That's the really bad experience. Yeah. And so today, obviously, it's more of a you've

100
00:12:16,000 --> 00:12:21,520
got a set of shared services that developers can take advantage of and TensorFlow is a big part of

101
00:12:21,520 --> 00:12:29,840
of that. And why TensorFlow? Any, you know, particular thoughts on why TensorFlow is a framework,

102
00:12:29,840 --> 00:12:37,120
you know, was the right direction for you? I can't really speak to why we decided to make

103
00:12:37,120 --> 00:12:43,360
TensorFlow the official deep learning platform. But maybe the more interesting question is,

104
00:12:43,360 --> 00:12:48,560
you know, one of the big decisions that folks that are trying to provide platform services need

105
00:12:48,560 --> 00:12:55,920
to face is whether they are offering, you know, whether they're trying to be framework agnostic

106
00:12:55,920 --> 00:13:02,320
and support everything or whether they're focusing on a particular thing. Is it correct to infer

107
00:13:02,320 --> 00:13:08,240
that there's a strong focus on TensorFlow for LinkedIn to the exclusion of other frameworks? So do

108
00:13:08,240 --> 00:13:15,280
you also have ways of supporting, you know, you're just here talking about TensorFlow, but you also have,

109
00:13:15,280 --> 00:13:23,200
you know, PyTorch on yarn or something. Yeah. Yeah. Yeah. So this is actually something.

110
00:13:23,200 --> 00:13:30,320
It's kind of interesting. When we first developed Tony, it was for TensorFlow specific support.

111
00:13:30,320 --> 00:13:36,720
Okay. And this was mostly guided by our AI teams who were most interested in using TensorFlow.

112
00:13:36,720 --> 00:13:40,640
There was certainly a period in time in which TensorFlow was the only choice that made sense.

113
00:13:40,640 --> 00:13:49,760
Right. Right. Yeah. And so, you know, I think right now we are not really platform agnostic.

114
00:13:49,760 --> 00:13:58,320
We, as a policy, I'd say, we only support certain frameworks. And I think that's maybe

115
00:13:59,760 --> 00:14:05,440
an easier way to scale our deep learning infrastructure. You know, we only have so many

116
00:14:05,440 --> 00:14:11,280
infra engineers on our team that can support these frameworks. So we kind of need to

117
00:14:12,320 --> 00:14:18,880
limit what kind of the support we provide to the engineers at our company. Yeah. Yeah.

118
00:14:18,880 --> 00:14:27,440
It's interesting. We earlier this month had a conference, Twomelcon focused on Twomelcon AI

119
00:14:27,440 --> 00:14:34,080
platforms to be precise focused on the platforms and technologies that folks are standing up to

120
00:14:34,080 --> 00:14:41,680
accelerate machine learning. And you hear a lot of people kind of advocating for you got to support,

121
00:14:41,680 --> 00:14:45,280
you know, in platform roles, you have to support everything that the engineers want to use.

122
00:14:45,280 --> 00:14:55,360
And it's, I think, worthy of pointing out that if an organization, you know, with an engineering

123
00:14:55,360 --> 00:15:00,480
culture like a LinkedIn and, you know, the size and scale of LinkedIn, both in terms of

124
00:15:01,520 --> 00:15:06,880
engineering team and problem, you know, can say, well, you know, we're going to focus on this.

125
00:15:07,600 --> 00:15:14,400
Yeah. Then there are probably a lot of other organizations that are smaller that can also do

126
00:15:14,400 --> 00:15:19,520
that and probably get as much advantage, you know, of focusing on something, whether it's

127
00:15:19,520 --> 00:15:27,280
TensorFlow or PyTorch or whatever. Yeah. Exactly. I feel like, you know, if you have a team of

128
00:15:27,280 --> 00:15:31,440
hundreds of engineers that are working just for deep learning at your company, that might be

129
00:15:31,440 --> 00:15:36,880
something that's possible. Maybe just on your platform team. Yeah. Yeah. Not developing. No,

130
00:15:36,880 --> 00:15:42,560
you know, right. Yeah. But, you know, we only have so many people on our team that can only do so

131
00:15:42,560 --> 00:15:49,040
much. Right. And so I think this is the best way for us to do it. Yeah. Okay. So you were talking

132
00:15:49,040 --> 00:15:57,360
about the motivation for this investment and the experience that engineers had before this project.

133
00:15:58,240 --> 00:16:02,960
What's next in your kind of agenda or your story on this with the presentation?

134
00:16:04,240 --> 00:16:10,960
Yeah. So, you know, after we go into kind of the gaps that we saw in distributed

135
00:16:10,960 --> 00:16:16,960
TensorFlow training, we'll talk a little bit about how Tony works behind the hood.

136
00:16:18,480 --> 00:16:23,280
So kind of what features we support, how it's implemented on top of yarn,

137
00:16:24,800 --> 00:16:28,400
and then kind of how AI engineers at LinkedIn would use it.

138
00:16:30,240 --> 00:16:36,000
Yeah. And so that part will kind of go into like coming back to the pitfalls that we saw,

139
00:16:36,000 --> 00:16:43,760
how Tony addresses them, basically, to walk us through that. Yeah. So do you want like a walk

140
00:16:43,760 --> 00:16:50,960
through of how Tony works? Yeah. Yeah. Absolutely. Absolutely. Yeah. So sort of for any yarn

141
00:16:50,960 --> 00:16:58,800
application, there's a few main components. There is a client component that is submitting jobs

142
00:16:58,800 --> 00:17:05,120
to your hudu cluster. And then there's what yarn calls an application master. So you can think of

143
00:17:05,120 --> 00:17:12,160
this as essentially a driver that handles all of the subtasks in your hudu job.

144
00:17:12,800 --> 00:17:18,240
And then you have what Tony calls a task executor. These are essentially the tasks that are doing

145
00:17:18,240 --> 00:17:24,640
the heavy lifting in your job. And so for us, we have implementations of all three of these

146
00:17:24,640 --> 00:17:33,680
components. And then we package them all into this Tony library. And so some of the things that

147
00:17:33,680 --> 00:17:39,760
we've built into the design of Tony, most of this is happening in the application master of the

148
00:17:39,760 --> 00:17:45,280
driver. So some of the things that we need to support are like fall tolerance, which we talked

149
00:17:45,280 --> 00:17:52,080
a little bit about earlier. So you know, as our engineers are running on more and more training

150
00:17:52,080 --> 00:18:01,280
data, their training may be running on more workers running for longer. You know, there's this idea

151
00:18:01,280 --> 00:18:07,600
that any machine can fail at any time, which will cause the tasks running on that machine to fail.

152
00:18:08,560 --> 00:18:15,760
And so we needed good support for fall tolerance in the Tony framework to make sure that if we run

153
00:18:15,760 --> 00:18:26,800
into these transient issues such as hardware failure, that Tony can transparently continue training

154
00:18:26,800 --> 00:18:32,640
and make sure that the job succeeds to completion. Yeah. In the Hadoop world, there's,

155
00:18:33,600 --> 00:18:37,600
you know, people will say fault tolerance and mean lots of different things, right? They can

156
00:18:37,600 --> 00:18:43,760
mean that they can mean that a node fails, but there's been checkpointing happening during the,

157
00:18:43,760 --> 00:18:48,960
you know, the training or the job. And so some other node is able to access that state and start

158
00:18:49,600 --> 00:18:56,400
or continue and not have to start back to the beginning, you know, or you said kind of

159
00:18:56,400 --> 00:19:03,120
continuous, you know, fault tolerance. Whereas, or such that there's no interruption at all.

160
00:19:03,120 --> 00:19:09,120
There's no checkpointing that needs to happen. Those are maybe the spectra of different, you know,

161
00:19:09,120 --> 00:19:14,320
ways that people use fault tolerance. You know, what level of fault tolerance are you providing?

162
00:19:14,320 --> 00:19:20,560
And how are you providing that? Yeah. So I think for, you know, for frameworks like MapReduce

163
00:19:20,560 --> 00:19:26,880
or Spark, it will follow this model of you, you may need to recompute some things. And then the

164
00:19:26,880 --> 00:19:32,960
framework will handle exactly what you need to recompute. Yeah. So in Tony's case, it's a little

165
00:19:32,960 --> 00:19:42,080
different. So since TensorFlow already has this capability of checkpointing, checkpointing status

166
00:19:42,080 --> 00:19:50,480
to some durable storage essentially. In our case, we're using HDFS since it's running on our

167
00:19:50,480 --> 00:19:58,240
HD cluster. Yeah. So for us, we're like checkpointing the status of our Tony jobs every, every few

168
00:19:58,240 --> 00:20:07,040
minutes to our HDFS clusters. And then in Tony's case, if it detects that some worker has failed

169
00:20:07,040 --> 00:20:14,160
for whatever reason, it can tear down the the Tony application of all the workers associated

170
00:20:14,160 --> 00:20:21,360
with it and then re-request resources from the HD cluster, spin up the same job, but read from

171
00:20:22,000 --> 00:20:29,040
the checkpoints that were saved from the previous attempt. We spoke earlier about this race condition

172
00:20:29,040 --> 00:20:37,760
issue. Does Tony kind of inherently solve that race condition problem, or is it just that it

173
00:20:37,760 --> 00:20:43,440
organizes everything in some higher level abstraction like ProML, like a scheduler of some sort with

174
00:20:43,440 --> 00:20:52,320
the user interface can handle, can better handle that race condition. Yeah. So the, I think the core

175
00:20:52,960 --> 00:20:57,920
problem with having these unmanaged machines and, you know, that's the race condition. Yeah.

176
00:20:57,920 --> 00:21:06,800
Is that there is no layer that is that is aware of which machines have how many resources and

177
00:21:06,800 --> 00:21:14,400
how many are being used. Right. And so we kind of got this for free, so to say, when we move to

178
00:21:14,960 --> 00:21:25,840
manage infrastructure like yarn. So, you know, when we want to build end-to-end GPU support for

179
00:21:25,840 --> 00:21:32,240
our users, we need to make sure that every layer in our stack is aware of these GPU resources,

180
00:21:32,240 --> 00:21:38,480
so that we don't have this race condition. So for us, that meant, you know, in the yarn layer,

181
00:21:39,200 --> 00:21:44,400
yarn needs to know, you know, you have all of these machines in your cluster. How many GPUs are on

182
00:21:44,400 --> 00:21:51,520
each machine? When a user runs a task on one of these machines, how many GPUs is it using? And so

183
00:21:51,520 --> 00:21:57,360
yarn is aware of all of these things. And then so we can leverage that in Tony. And Tony can say,

184
00:21:57,360 --> 00:22:04,800
you know, this user requested 2GPUs. I'm going to ask the yarn cluster for 2GPUs. And then the yarn

185
00:22:04,800 --> 00:22:10,240
layer can handle the scheduling part for that. And so that was the kind of how it works

186
00:22:10,880 --> 00:22:15,760
element. And we covered some of the problems that it fixes are there others that you highlight in

187
00:22:15,760 --> 00:22:26,960
presentation. So the fault tolerance issue and the GPU issue, those are the two that we cover.

188
00:22:26,960 --> 00:22:34,160
There are a few that we decided not to get into. So after that, we kind of start to go into,

189
00:22:35,360 --> 00:22:42,240
you know, this is useful for scaling up TensorFlow training at LinkedIn. But we also have this

190
00:22:42,240 --> 00:22:50,640
orthogonal issue of if AI engineers want to experiment on new libraries that came out in the

191
00:22:50,640 --> 00:22:57,920
open source world, how can they easily experiment on that? And, you know, if you've ever worked with

192
00:22:57,920 --> 00:23:07,280
Hadoop, it doesn't lend itself very well to experimentation, I think. And so one thing that we were

193
00:23:07,280 --> 00:23:16,640
exploring was building a Kubernetes research cluster that our engineers could use to do various

194
00:23:16,640 --> 00:23:22,480
experimentation. And so one of the powerful things about Kubernetes is that there's very good

195
00:23:22,480 --> 00:23:29,280
support for containerization. So if our engineers want to use some library, they can easily

196
00:23:30,000 --> 00:23:35,840
build the image themselves and run it on the Kubernetes cluster. And so the later part of the talk

197
00:23:35,840 --> 00:23:42,400
we'll get into kind of how we built that out. Some of the gaps that we saw when we were building

198
00:23:42,400 --> 00:23:50,320
out our Kubernetes cluster and some use cases. Okay. And just to be clear, the Kubernetes cluster is

199
00:23:50,320 --> 00:23:56,240
independent of the Hadoop cluster, or you somehow running Kubernetes on top of Hadoop?

200
00:23:56,240 --> 00:24:05,600
Yeah. Yeah, I know there have been some attempts to do. Yeah. We decided not to go that

201
00:24:05,600 --> 00:24:13,360
route. So essentially the Kubernetes compute part is a separate cluster. And this is something

202
00:24:13,360 --> 00:24:20,160
we'll get into in the talk as well. We already have this vast data lake on HDFS with all of our

203
00:24:20,160 --> 00:24:27,200
training data. And so even while we have this separate compute cluster for Kubernetes, we want

204
00:24:27,200 --> 00:24:32,880
a way to access this data lake. So this is one of the gaps that we saw when building out this

205
00:24:32,880 --> 00:24:40,560
Kubernetes cluster, how if people run these Kubernetes jobs in this cluster, how do they access

206
00:24:40,560 --> 00:24:48,880
this data? You know, since we're running a secure Hadoop, it's kind of non-trivial to instrument

207
00:24:48,880 --> 00:24:57,840
this. So that's something we also get into in the talk. And so the main challenges there are

208
00:24:57,840 --> 00:25:04,560
kind of integrating in with the kind of your access controls and entitlements on the Hadoop side

209
00:25:04,560 --> 00:25:09,600
between the kind of the file system driver infrastructure on the Kubernetes side, or is it

210
00:25:09,600 --> 00:25:14,960
something else? Yeah, that's basically what it does. Okay. You know, there's built-in support

211
00:25:14,960 --> 00:25:20,400
for accessing a secure cluster. How do you like authenticate things like that when you're running

212
00:25:20,400 --> 00:25:25,840
your tests on the Hadoop cluster. But then when you have some external cluster on Kubernetes,

213
00:25:25,840 --> 00:25:29,360
how do you do the same thing? And so that gap is something we have to bridge.

214
00:25:29,360 --> 00:25:32,640
Well, before we dive a little bit deeper into the Kubernetes side of things,

215
00:25:33,840 --> 00:25:42,400
does Tony take advantage of or draw from any of the other distributed training

216
00:25:43,120 --> 00:25:50,560
approaches for TensorFlow, the, you know, the built-in distributed training, or a horrified,

217
00:25:50,560 --> 00:25:55,440
or any of those kinds of things, or is it, you know, as part of what you did kind of build your own

218
00:25:55,440 --> 00:26:04,400
version of that stuff? Yeah. So the layer at which Tony operates that is kind of on top of the

219
00:26:05,440 --> 00:26:13,920
TensorFlow distributed training part. So when the AI, when an AI engineer wants to run distributed

220
00:26:13,920 --> 00:26:21,440
training, they are writing like the model creation and the training logic themselves. So if they

221
00:26:21,440 --> 00:26:30,400
are interested in running some distributed training strategy, they can do that. And then Tony is

222
00:26:30,400 --> 00:26:38,160
kind of a thin layer on top of that, which will handle the resource acquisition and task launch

223
00:26:38,160 --> 00:26:44,160
essentially. And then once that part is complete, then the user, the AI engineers distributed

224
00:26:44,160 --> 00:26:53,840
TensorFlow job will proceed as it normally would. Got it. Yeah. And so some portion of your user

225
00:26:53,840 --> 00:27:00,320
community is coming in, you know, their jobs are being submitted via ProML. But I'm imagining

226
00:27:00,320 --> 00:27:05,760
some are using Tony directly. And if that's the case, I'm curious what the user experience is.

227
00:27:05,760 --> 00:27:15,360
Are they creating Tony Yamal files? Yeah. Yeah. So kind of the bare bones Tony experience is

228
00:27:15,360 --> 00:27:22,000
you need to create your configuration files. Yeah. And then package all of your source code

229
00:27:22,000 --> 00:27:27,280
and everything yourself. Like jar files or something. Right. Exactly. So if you're running Tony

230
00:27:27,280 --> 00:27:33,440
from like the command line, for example, that's something we would expect the user to do. But

231
00:27:33,440 --> 00:27:40,720
at LinkedIn, we have this this ProML ecosystem. And the objective there is to provide a higher

232
00:27:40,720 --> 00:27:48,720
level abstraction to our engineers. And so a lot of these nuts and bolts are kind of handled

233
00:27:49,280 --> 00:27:54,560
for them. Cool. Well, maybe let's take a few minutes and talk about how you're approaching

234
00:27:54,560 --> 00:28:02,240
Kubernetes. I guess first of all, are you, you know, is there an official position? Like, you

235
00:28:02,240 --> 00:28:09,200
know, this is the future of the future direction for, you know, distributed compute for ML and AI

236
00:28:09,200 --> 00:28:20,080
at LinkedIn? Or do you see Kubernetes and Tony coexisting long term? Yeah. That's a difficult

237
00:28:20,080 --> 00:28:27,920
question for me to answer. I don't think we I think we are the Kubernetes work we're doing is

238
00:28:27,920 --> 00:28:35,760
still pretty early phase. And so I think as we onboard more and more use cases, we'll see

239
00:28:37,040 --> 00:28:44,720
what the gaps there are. And then I think at that point, we'll have a better idea of what the

240
00:28:44,720 --> 00:28:52,720
long term distributed TensorFlow story will be at LinkedIn. But as of now, the state of Kubernetes

241
00:28:52,720 --> 00:29:00,160
at LinkedIn is, you know, we're we're still building out the infrastructure. And we don't really

242
00:29:00,160 --> 00:29:11,280
have a solid idea of how that plays into our long term solution. Beyond the challenge of

243
00:29:12,480 --> 00:29:17,280
the security challenges that we talked about integrating at that level, these two

244
00:29:17,280 --> 00:29:26,320
disparate systems, what are some of the other challenges that, well, challenges are what are some

245
00:29:26,320 --> 00:29:35,360
of the other, you know, focus areas that you're doing to kind of make the Kubernetes cluster accessible

246
00:29:35,360 --> 00:29:43,120
to folks? Yeah. So I think that the HDFS access thing is was the biggest thing for us.

247
00:29:43,120 --> 00:29:52,640
And then for experimentation, we're still kind of experimenting with it within the infrastructure

248
00:29:52,640 --> 00:30:02,400
team. And so a lot of the issues are related to building out the actual cluster and making sure

249
00:30:02,400 --> 00:30:12,640
that it operates as a production cluster should. So for example, making sure that the nodes in

250
00:30:12,640 --> 00:30:20,080
our cluster are up most of the time and making sure that we have appropriate metrics and monitoring

251
00:30:20,080 --> 00:30:26,720
to accurately assess the state of our cluster. Yeah. So it's kind of core

252
00:30:28,480 --> 00:30:36,640
Kubernetes operability stage that a lot of people, frankly, are at as opposed to how do we build

253
00:30:36,640 --> 00:30:44,160
some higher level abstraction on top of Kubernetes that is ML focused or creates the user experience.

254
00:30:44,160 --> 00:30:50,800
You're trying to offer to your ML engineers. Right. Exactly. Yeah. I think once we solidify

255
00:30:50,800 --> 00:30:57,120
the Kubernetes infrastructure, then we can start onboarding more and more users and then

256
00:30:58,320 --> 00:31:05,280
hopefully it will take off from there. And it's not like you have a few research focused teams

257
00:31:05,280 --> 00:31:14,320
running on Kubernetes now, are they doing, are they kind of experimenting? Well, I guess they're,

258
00:31:14,320 --> 00:31:19,440
yeah, experimenting is overloaded, but are they like running real use cases and workloads on this?

259
00:31:20,640 --> 00:31:25,280
But maybe not time-critical ones or like what's how do you characterize how you've started,

260
00:31:25,280 --> 00:31:28,720
you know, in terms of a workload perspective on the Kubernetes side?

261
00:31:28,720 --> 00:31:35,680
Yeah. For now, it's mostly kind of on an ad hoc basis. So people aren't really running

262
00:31:37,520 --> 00:31:43,840
critical jobs there. Yeah. And we've kind of played with some use cases such as running

263
00:31:43,840 --> 00:31:53,680
horrified on Kubernetes or running Qflow, for example. But yeah, those are still very experimental.

264
00:31:53,680 --> 00:31:58,960
So did you cover anything beyond the Kubernetes stuff? Or is that where you left it?

265
00:31:58,960 --> 00:32:05,440
I think that's the last thing that we cover. Yeah. Okay. You know, I asked a little bit about the

266
00:32:05,440 --> 00:32:15,680
kind of the feature of all this at LinkedIn with respect to Kubernetes and Hadoop. But more broadly,

267
00:32:15,680 --> 00:32:19,920
you know, what are some of the things that your group is looking at going forward?

268
00:32:19,920 --> 00:32:29,120
Yeah. I think right now, it's really important for us to give our engineers a really good user

269
00:32:29,120 --> 00:32:37,040
experience. A lot of our work so far has been making sure our clusters can scale well as we add

270
00:32:37,040 --> 00:32:43,440
more machines and, you know, hundreds of users are onboarding their deep learning jobs. But

271
00:32:43,440 --> 00:32:49,520
we're all just trying to improve our user experience. And so that's something we'll be addressing in the

272
00:32:49,520 --> 00:32:56,800
next few months. And other specific aspects of that that you can talk about? I'm not sure how much

273
00:32:56,800 --> 00:33:06,000
I can say. A lot of it is related to, for example, like internal tooling or the way our clusters are

274
00:33:06,000 --> 00:33:15,600
built out, for example. So even if you could say it wouldn't mean much to anyone. Yeah. Cool. And

275
00:33:15,600 --> 00:33:24,800
I'm curious if you have any kind of going back to kind of core TensorFlow, any kind of interesting

276
00:33:24,800 --> 00:33:29,680
lessons learned or, you know, things that you would share with folks that are, you know, starting to

277
00:33:29,680 --> 00:33:37,040
think about, you know, building out platform support around TensorFlow key, key things that it

278
00:33:37,040 --> 00:33:46,880
was important for your team to learn. Yeah. So far, I think just using what the open source

279
00:33:46,880 --> 00:33:55,840
TensorFlow community has provided has worked reasonably well for us. And I think when we cover,

280
00:33:55,840 --> 00:34:04,960
for example, Tony and talk, it kind of sits on a different layer from TensorFlow. So up to now,

281
00:34:04,960 --> 00:34:12,960
we haven't really had to delve into the TensorFlow internals. But in the future, I think as we optimize

282
00:34:12,960 --> 00:34:19,040
model training more and more, that's something we're going to look into, you know, how can we

283
00:34:19,040 --> 00:34:23,920
better optimize the actual TensorFlow layer rather than the layers that sit on top of it?

284
00:34:23,920 --> 00:34:29,360
Well, Jonathan, thanks so much for taking the time to chat with me. Yeah. Thank you. It was a pleasure.

285
00:34:32,960 --> 00:34:38,400
All right, everyone. That's our show for today. To learn more about today's show, including our

286
00:34:38,400 --> 00:34:45,200
guests, visit twomalai.com. If you missed Twomalcon or want to share what you learned with your team,

287
00:34:45,200 --> 00:34:52,240
be sure to visit twomalcon.com slash videos for more information about Twomalcon video packages.

288
00:34:52,240 --> 00:35:02,240
Thanks so much for listening and catch you next time.

