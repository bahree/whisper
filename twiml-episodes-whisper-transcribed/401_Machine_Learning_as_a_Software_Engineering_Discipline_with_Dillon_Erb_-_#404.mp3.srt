1
00:00:00,000 --> 00:00:12,080
All right, everyone. I am here with Dylan Herb. Dylan is the co-founder and CEO of PaperSpace.

2
00:00:12,080 --> 00:00:16,800
Dylan, welcome to the Twomble AI podcast. Awesome. Exciting to be here.

3
00:00:16,800 --> 00:00:22,240
It's great to have you on the show. I was thinking back to when we first met and you introduced me

4
00:00:22,240 --> 00:00:28,000
to this great coffee shop across the the street, I guess, or around the corner from your old offices

5
00:00:28,000 --> 00:00:33,920
in Brooklyn. Looks like you've got a new space now where you've got lots of cool plants.

6
00:00:34,800 --> 00:00:40,400
Yep, still in Brooklyn, just down the street, but yeah, I guess it's been a while. Glad to be here.

7
00:00:41,120 --> 00:00:50,960
Awesome. So we are going to be focusing in on the general topic of machine learning as a software

8
00:00:50,960 --> 00:00:58,640
engineering discipline, touching on ideas like ML ops and CICD and what all that means for folks

9
00:00:58,640 --> 00:01:04,480
that are trying to get ML into production. But before we do that, let's start with a little bit

10
00:01:04,480 --> 00:01:11,920
of your background and how you came to, you know, found a company that is, you know, in the center

11
00:01:11,920 --> 00:01:19,440
of helping folks, you know, work on machine learning problems. Yeah. So time flies, but we've

12
00:01:19,440 --> 00:01:24,640
actually been at this for about five years now. My background and this will kind of inform some

13
00:01:24,640 --> 00:01:28,960
of the, probably the conversation today, but my background is a little bit nontraditional. I

14
00:01:29,920 --> 00:01:33,360
studied building architecture and kind of on the architecture engineering side.

15
00:01:34,640 --> 00:01:40,560
And what used to be probably more in like the HPC world, so working more with like genetic algorithms

16
00:01:40,560 --> 00:01:46,320
and I was doing things around topology optimization, that led to an interest in parallel compute

17
00:01:46,320 --> 00:01:52,000
and GPUs were really the name of the game and have continued to be so. And so I started paper space

18
00:01:52,000 --> 00:01:59,680
with my co-founder and good buddy Dan, Dan Cobran. And yeah, so we, you know, our general premise

19
00:01:59,680 --> 00:02:05,920
and it's definitely evolved was that, you know, GPUs as sort of a kind of parallel compute device

20
00:02:05,920 --> 00:02:09,520
would make its way into the cloud and there would be all sorts of, you know, new applications that

21
00:02:09,520 --> 00:02:14,480
would emerge from that. And I think what we, you know, weren't aware of at the time was that the

22
00:02:14,480 --> 00:02:19,360
big driver of that was going to be this, you know, shift from like visual compute into just,

23
00:02:19,360 --> 00:02:24,080
you know, massive data processing and the emergence of like deep learning as kind of a practical

24
00:02:24,080 --> 00:02:30,960
discipline as well. So yeah, that's how I got into it. And now I primarily just think about that,

25
00:02:30,960 --> 00:02:36,320
which is sort of how do these, you know, new tools evolve and support kind of emerging workflows,

26
00:02:36,320 --> 00:02:42,160
tools, products, things like that. Yeah, I think you and Nvidia maybe have that in common,

27
00:02:42,160 --> 00:02:49,280
you know, we're going after a totally different use case for GPUs, one that was graphics focused

28
00:02:49,280 --> 00:02:56,160
and were quick to recognize the activity or the shift that was happening around ML and AI.

29
00:02:56,800 --> 00:03:02,800
What were, what were some of the first use cases that you, you saw that kind of clued you into

30
00:03:02,800 --> 00:03:08,240
interesting activity in this space? Yeah, I mean, it was, when you're an early stage company,

31
00:03:08,240 --> 00:03:12,240
you kind of, you know, I was manning support as well as doing everything else to company. And so

32
00:03:12,240 --> 00:03:16,880
you email everyone who signs up and you're just like, hey, what are you up to? And we started,

33
00:03:16,880 --> 00:03:20,960
you know, this was new to me, but we started getting more requests for people saying, hey, I'm

34
00:03:20,960 --> 00:03:26,480
trying this thing out called TensorFlow. You guys have GPUs. This was before really the big cloud

35
00:03:26,480 --> 00:03:31,840
providers had offered GPUs as just like a, you know, a native compute device. Obviously today,

36
00:03:31,840 --> 00:03:37,360
they're, they're pervasive. And so we're like, tell us more, you know, what are you building? And

37
00:03:37,360 --> 00:03:43,840
so that's kind of been the format of the conversation for, you know, the last four years. And so,

38
00:03:43,840 --> 00:03:48,320
you know, in that time, we've seen, well, actually two things interestingly. One, you know,

39
00:03:48,320 --> 00:03:53,920
the emergence of like this deep learning practice where you need a lot of compute. So you need a

40
00:03:53,920 --> 00:03:57,600
lot of things. You need data, you need compute, you need expertise, but compute is a big part of it.

41
00:03:57,600 --> 00:04:01,520
You know, you can, you know, you're, you're not going to make a driverless car algorithm on a

42
00:04:01,520 --> 00:04:06,400
Chromebook. So there is a compute requirement. And the kind of the interesting thing is even today,

43
00:04:06,400 --> 00:04:10,560
and I'm sure this is, you know, bumped up in, in your universe as well, which is sort of the,

44
00:04:11,920 --> 00:04:19,040
the blending of the visual compute kind of side of things or everything from like image generation,

45
00:04:19,040 --> 00:04:24,320
deep fakes being sort of the big example, or now we're seeing things like synthetic data. So the

46
00:04:24,320 --> 00:04:28,720
compute pipeline and the visualization pipeline, I think, are collapsing in a really interesting way,

47
00:04:29,760 --> 00:04:35,520
where, you know, visual effects are, are, you know, just as interested in deep learning as like a,

48
00:04:35,520 --> 00:04:39,760
you know, thing in their tool belt. So, so it is a, it's been a weird few years where,

49
00:04:40,560 --> 00:04:43,600
you know, the first pitch deck, I remember the first slide was, what's a GPU?

50
00:04:44,800 --> 00:04:48,720
Which luckily, we don't, we don't have to bring that one up anymore, people kind of get it.

51
00:04:48,720 --> 00:04:57,920
Nice, nice, nice. And paper space has been popular in our community for quite a while. We

52
00:04:57,920 --> 00:05:04,560
do a bunch of study groups around courses like Fast AI and others. And, you know, for years now,

53
00:05:04,560 --> 00:05:10,800
folks, in trying to do those courses, you look for infrastructure in which to run it on and paper

54
00:05:10,800 --> 00:05:18,320
space has always been one of those options. But the company is doing more now than just, you know,

55
00:05:18,320 --> 00:05:25,760
a server instance with the GPU, kind of going up the stack. Can you talk a little bit about that

56
00:05:25,760 --> 00:05:30,560
and the motivation there? Yeah, definitely. So, paper space is the name of the company and our kind

57
00:05:30,560 --> 00:05:35,840
of main product or kind of collection of products is called Gradient. And that encompasses

58
00:05:36,880 --> 00:05:41,680
really a handful of components around what, you know, we'd probably call an ML ops platform.

59
00:05:41,680 --> 00:05:46,720
And, you know, we definitely should dive in to what exactly that comprises. But, yeah,

60
00:05:46,720 --> 00:05:52,800
today we, you know, provide tools for pretty much every step of the kind of building the machine

61
00:05:52,800 --> 00:05:58,640
learning model process. But really with an emphasis, again, coming from our kind of background in

62
00:05:58,640 --> 00:06:04,560
the infrastructure side of things, like a focus on where the kind of machine learning world intersects

63
00:06:04,560 --> 00:06:09,600
with the, you know, infrastructure or networking issues or more broadly, just how does it interface

64
00:06:09,600 --> 00:06:14,400
with, you know, traditional software development and application development that, you know, has also

65
00:06:14,400 --> 00:06:19,440
been changing quite quickly, but has, you know, become a relatively established pattern for, you know,

66
00:06:19,440 --> 00:06:25,680
all sorts of companies to build on top of. Yeah, and as you mentioned, this has been a quickly

67
00:06:25,680 --> 00:06:33,520
evolving space in terms of the, you know, your perspective on, you know, slash takes,

68
00:06:33,520 --> 00:06:40,320
slash interest in the ML ops and infrastructure side, or, you know, to what degree are,

69
00:06:42,640 --> 00:06:50,000
are you, I guess, productizing or, or, you know, drawing learnings from the experiences that you

70
00:06:50,000 --> 00:06:57,520
had, you know, standing up these, you know, these data centers with GPUs versus, you know, stuff

71
00:06:57,520 --> 00:07:02,080
that you're seeing evolve elsewhere outside of the company. Like, what's kind of the core,

72
00:07:04,080 --> 00:07:10,080
the core around which you're, you know, building out an approach to ML ops?

73
00:07:10,800 --> 00:07:14,640
Yeah, so I think there's kind of two levels of it. The first level is just like, you know,

74
00:07:14,640 --> 00:07:20,880
what does the thing do? And to date, you know, we offer, you know, one click sign up any developer

75
00:07:20,880 --> 00:07:24,800
and one of the most popular ways of onboarding is, you know, through a course like Fast AI,

76
00:07:25,520 --> 00:07:29,360
which will be, you know, partnering with them the next version as well. This sort of the entry

77
00:07:29,360 --> 00:07:33,680
point and the question is, you know, how can you kind of get right into the media, the problem,

78
00:07:33,680 --> 00:07:38,480
start looking at some pie torches or TensorFlow or, you know, try out GPT-2 or something like that,

79
00:07:38,480 --> 00:07:42,320
without even thinking about infrastructure. So there, you know, there's kind of the practical

80
00:07:42,320 --> 00:07:48,880
piece of that, just onboarding to it. And then on top of that, the question is, you know, what are,

81
00:07:48,880 --> 00:07:53,680
I think, across the industry, there's this a lot of interest in creating purpose-built tools

82
00:07:53,680 --> 00:07:57,600
for machine learning because we can all agree or people that, you know, spend some time with it will

83
00:07:57,600 --> 00:08:02,480
say will acknowledge that, you know, it does have some fundamental differences from traditional

84
00:08:02,480 --> 00:08:06,320
software development. You know, we can talk about the programming languages. Some folks are coming

85
00:08:06,320 --> 00:08:12,800
from R or their backgrounds in stats or math. The hardware itself, obviously, you know,

86
00:08:12,800 --> 00:08:18,480
GPUs are not required for building out a web app. And within machine learning, there's obviously

87
00:08:18,480 --> 00:08:25,200
a whole host of types of machines. So there is a particular need to think about the hardware as

88
00:08:25,200 --> 00:08:31,280
a primitive in your system. So, you know, so when you zoom out kind of collectively, I think the

89
00:08:31,280 --> 00:08:38,240
bigger problem in the way we talk about, you know, the way we evangelize it is to say, we believe

90
00:08:38,240 --> 00:08:43,360
machine learning is a part of a traditional software engineering practice. And the good thing about

91
00:08:43,360 --> 00:08:48,640
that is when you start diving into something like an ML ops platform, you have a lot to draw on,

92
00:08:48,640 --> 00:08:54,640
which is, you know, a whole 10 years of, at least, of, you know, modern software development practices.

93
00:08:54,640 --> 00:08:59,520
So that encompasses things like continuous integration, continuous deployment, obviously,

94
00:08:59,520 --> 00:09:02,560
tight integrations with source control management, and in the case of machine learning, you know,

95
00:09:02,560 --> 00:09:08,160
data management, and, and provenance. And, and you start thinking about it in a different way. So,

96
00:09:09,440 --> 00:09:14,880
the benefit of a traditional software development practice that might be like agile or, you know,

97
00:09:14,880 --> 00:09:20,400
based around CICD is that you can, you know, we're a software company that builds a web application,

98
00:09:20,400 --> 00:09:25,360
a web console, a lot of tools. And we can, you know, bring new people into that collaborative effort,

99
00:09:25,360 --> 00:09:30,640
and they can work in sort of guidelines that means that they can very quickly start, you know,

100
00:09:30,640 --> 00:09:35,120
shipping production code. So machine learning is newer in the sense that, you know,

101
00:09:35,120 --> 00:09:38,880
not every company is in the, like, we need to ship this into production. But if you look at the

102
00:09:38,880 --> 00:09:42,960
process of, like, testing some assumptions, building a little model out, and then trying to get into

103
00:09:42,960 --> 00:09:49,280
production, the, the kind of, the framework that you need to think about it in is just like any

104
00:09:49,280 --> 00:09:53,840
other software, you know, development paradigm. And we feel strongly that, you know, this,

105
00:09:53,840 --> 00:09:59,600
the closest analogy is probably something like mobile app development, where, you know, historically,

106
00:09:59,600 --> 00:10:03,520
it was like, you have your iOS team when the iPhone came out and you have your, you know,

107
00:10:03,520 --> 00:10:07,280
regular software team or your website team, and eventually those two merged, and the,

108
00:10:07,280 --> 00:10:11,760
the baseline practices are the same. And we think that's the, you know, the case for machine learning

109
00:10:11,760 --> 00:10:17,680
as well. We're just at the beginning of that curve. Now, a lot of folks pushed back on that and

110
00:10:17,680 --> 00:10:24,000
say that there are fundamental differences in the way that machine learning and data science more

111
00:10:24,000 --> 00:10:34,080
broadly should be practiced. And it's not, you know, it's not as predictable that as software

112
00:10:34,080 --> 00:10:41,120
engineering. You know, what's your, you know, how do you respond to that kind of? Do you,

113
00:10:41,120 --> 00:10:45,760
well, first of all, do you even encounter that? Like the, the, yeah, I kind of push back and what's

114
00:10:45,760 --> 00:10:52,000
your, what's your take on that? Well, I think it's an emerging discipline that has, that has moved

115
00:10:52,000 --> 00:10:56,000
quite quickly. And it's also happened at the same time that we've, you know, it's, it's happening

116
00:10:56,000 --> 00:11:00,240
the same time that we're also seeing pretty large, large shifts in how software is developed. And

117
00:11:00,240 --> 00:11:05,040
I think the biggest trends here we can talk about are, you know, containerization, the idea that

118
00:11:05,040 --> 00:11:09,680
you can have kind of reproducibility at the, at the, as like a primitive in your pipeline.

119
00:11:10,400 --> 00:11:14,800
The emergence of these kind of more complex tools like Kubernetes, which is still, you know,

120
00:11:14,800 --> 00:11:20,320
a complex thing to set up and to manage. And you have companies that are seeing the benefits

121
00:11:20,320 --> 00:11:26,560
of this. But fundamentally, we're starting to, you know, software development is shifting. And

122
00:11:26,560 --> 00:11:30,400
that's happening right as machine learning is trying to figure out sort of what its relationship is.

123
00:11:30,400 --> 00:11:35,520
So I think there is a lot to that. And I think it, in the sense that there are people that would

124
00:11:35,520 --> 00:11:40,320
argue that maybe the foundational part of machine learning is more exploratory. It doesn't quite

125
00:11:40,320 --> 00:11:46,480
have, you know, one-to-one mappings into, you know, software development. But I don't think that is

126
00:11:47,840 --> 00:11:52,160
true across the board. And by that, I mean, you know, there are a lot of really useful analogies

127
00:11:52,160 --> 00:11:58,400
we can draw from. You know, we, we think a lot about, you know, if you think of Git or GitHub as

128
00:11:58,400 --> 00:12:04,480
sort of a standard in collaboration on software projects today, there's some fundamental act,

129
00:12:04,480 --> 00:12:08,480
you know, things you can do, you know, you can fork, you can, you have pull requests, you have

130
00:12:08,480 --> 00:12:13,600
branches, they don't map perfectly to the machine learning model. You know, your iteration

131
00:12:13,600 --> 00:12:17,040
could be very quick on a machine learning model or it could be really slow if it takes a long time

132
00:12:17,040 --> 00:12:23,440
to train. But in either case, there are useful things to draw on, you know, development staging

133
00:12:23,440 --> 00:12:27,840
and production environments, you know, being able to promote things. And that's, that's a traditional

134
00:12:27,840 --> 00:12:31,840
software engineering practice largely. So the question is how do they interface? And that's what we,

135
00:12:31,840 --> 00:12:36,880
you know, spent a lot of time on gradient trying to tease out where, where you can get the best

136
00:12:36,880 --> 00:12:41,600
to both worlds. Like, where can you draw on those kind of best practices? And, and where does it

137
00:12:41,600 --> 00:12:45,760
diverge? Like the reality is, if, if it were just a software development practice, you could use,

138
00:12:45,760 --> 00:12:52,000
you know, Jenkins or, you know, a traditional kind of CICD pipeline runner for machine learning.

139
00:12:52,000 --> 00:12:55,680
And you really can't do that. There are, you know, the artifacts are different. The machine learning

140
00:12:55,680 --> 00:13:00,800
model is a very important artifact at the center of this. Data is a, is a, you know, as important as

141
00:13:00,800 --> 00:13:07,040
code as a primitive, as an input to the pipeline. So, maybe dig into that a little bit, in a little

142
00:13:07,040 --> 00:13:14,640
bit more detail. I am imagining that folks that are coming at things from the more traditional data

143
00:13:14,640 --> 00:13:23,040
science perspective don't really have any idea what a Jenkins is or CICD pipeline. You know,

144
00:13:23,040 --> 00:13:28,240
maybe talk through, you know, kind of your take on that traditional world from a software

145
00:13:28,240 --> 00:13:34,240
engineering perspective. And then, you know, we can talk through like how it maps to, you know,

146
00:13:34,240 --> 00:13:41,040
the way you see the ML ops world. Yeah, definitely. I mean, I think at, at the foundational level,

147
00:13:41,040 --> 00:13:47,360
the idea is, you, you commit to, you know, you, certain things get committed into your development

148
00:13:47,360 --> 00:13:52,160
process. Even, you know, literally as part of like a config file that goes into your repo or

149
00:13:52,160 --> 00:13:58,800
something that says like here are the steps of the process, meaning, you know, we transform some

150
00:13:58,800 --> 00:14:05,280
data. We send it to this machine type with this, you know, container and this framework tenser

151
00:14:05,280 --> 00:14:10,400
flow 2.1 or whatever. And this has an artifact that we then deploy. So, there's kind of a pipeline.

152
00:14:10,400 --> 00:14:15,120
And so the foundation of CICD and there are a lot of, you know, components to it is that if you

153
00:14:15,120 --> 00:14:20,080
can make those more reproducible and deterministic, then ultimately is a software developer or an

154
00:14:20,080 --> 00:14:24,640
organization trying to, you know, build an impactful machine learning model that you can do that

155
00:14:24,640 --> 00:14:29,360
more quickly and, you know, more safely because you can sort of see what every step of the process

156
00:14:29,360 --> 00:14:34,240
was. So, you know, when you talk about machine or folks talk about machine learning is sort of a

157
00:14:34,240 --> 00:14:39,760
black box like you put in data and you get out some predictive model that's like hard to interrogate.

158
00:14:39,760 --> 00:14:45,120
I think part of it is that this is really powerful, powerful algorithms that are still hard to

159
00:14:45,120 --> 00:14:49,200
fully understand. But the other part of it is the normal way of developing them at least, you

160
00:14:49,200 --> 00:14:56,400
know, we work with everyone from, you know, university students to, you know, organizations like

161
00:14:56,400 --> 00:15:00,960
that are very much coming at it from like a business intelligence perspective. And in both cases,

162
00:15:00,960 --> 00:15:06,480
you know, because it's a new practice, there aren't patterns fully established yet. So people

163
00:15:06,480 --> 00:15:12,000
are frantically looking for the, you know, the tool stack to make it happen. And I think that ML

164
00:15:12,000 --> 00:15:17,040
ops has kind of done itself a bit of a disservice in that it presents itself as such a totalizing

165
00:15:17,040 --> 00:15:20,800
thing, which is really not if you're thinking about it from a software development perspective.

166
00:15:20,800 --> 00:15:26,800
It's not the, that's really, there aren't good parallels for that. Like in traditional software

167
00:15:26,800 --> 00:15:30,720
development or if we're making our web application today or your iOS app or whatever, you're using

168
00:15:30,720 --> 00:15:35,040
30 different tools. But you're doing it in your structuring it in a way that is, you know,

169
00:15:35,040 --> 00:15:39,120
roll an agreement on it. You know, you commit sort of the important parts of the pipeline,

170
00:15:39,120 --> 00:15:42,640
you add tests, you add checks so that someone can come in. They can, you know, everything is

171
00:15:42,640 --> 00:15:47,600
tied to source control. So, you know, you can, you can experiment in a branch and then come back

172
00:15:47,600 --> 00:15:52,000
in. And I think a lot of those are really useful for thinking about, you know, machine learning,

173
00:15:52,000 --> 00:15:55,680
not, not, you know, in its entirety, but certainly a lot of the components that people struggle

174
00:15:55,680 --> 00:15:59,360
with today and taking this from R&D into production, which is really the name of the game.

175
00:16:00,880 --> 00:16:07,920
You know, I think my, my guess is that folks who know paper space and, and gradient in particular

176
00:16:07,920 --> 00:16:14,080
from a user perspective, think of it as, you know, primarily what the interface that it's

177
00:16:14,080 --> 00:16:20,160
providing, kind of a notebook like experience and, you know, maybe notebooks as a service we could

178
00:16:20,160 --> 00:16:29,840
call it. And when you think of ML ops platform, you know, you think of all this enterprise-y stuff,

179
00:16:29,840 --> 00:16:37,840
containers and Kubernetes and things like that. How do you get from one to, to the

180
00:16:37,840 --> 00:16:42,640
next is all that stuff, just the stuff that you're using to allow folks to spin up these notebooks

181
00:16:42,640 --> 00:16:48,080
or what's the relationship? Yeah, so, so we call it kind of like the gradient notebook lab,

182
00:16:48,080 --> 00:16:53,200
which is, you know, the wrapper around Jupyter. You actually use other kind of IDE-like

183
00:16:53,200 --> 00:16:57,280
environments, but Jupyter has certainly become the de facto standard. That's really only one

184
00:16:57,280 --> 00:17:02,800
part of gradient, but it's all built on the same foundation. And that foundation is committed to

185
00:17:02,800 --> 00:17:08,320
the idea of reproducibility adding UUIDs to every step of the process. So even if someone comes in,

186
00:17:08,320 --> 00:17:13,120
and the most popular kind of product we have is certainly notebooks. Anyone can come in, we have

187
00:17:14,240 --> 00:17:18,560
a tool called the ML Showcase where they can one click, run it on a free instance in the cloud and

188
00:17:18,560 --> 00:17:24,560
kind of, you know, get their feet wet with the machine learning tooling. And that's important

189
00:17:24,560 --> 00:17:29,520
because our general view is that for every thousand software developers, you have maybe one

190
00:17:29,520 --> 00:17:33,280
who's a machine learning expert. So the question is, how do you onboard the machine learning technology

191
00:17:33,280 --> 00:17:37,120
for everyone else? And they have to try it out. So notebooks are certainly one part of it,

192
00:17:38,000 --> 00:17:43,840
but as folks kind of get more advanced within gradient, we offer a lot of like kind of

193
00:17:44,800 --> 00:17:49,680
ways of making the pipeline sort of building on top of it. So the notebook is always running

194
00:17:49,680 --> 00:17:54,000
in a container. When you shut it down, we do a Docker commit to make sure that you have sort of

195
00:17:54,000 --> 00:17:59,040
the reproducibility in the history. And then you can go a step further and then connect that to a

196
00:17:59,040 --> 00:18:04,320
GitHub repo. You can actually, we have like a job run or architecture, very similar to how

197
00:18:04,320 --> 00:18:09,200
kind of the paradigm has been established where you can use a CLI or Python SDK and then just

198
00:18:09,200 --> 00:18:15,120
send a task and have it get scheduled across a single node or a large scale distributed set of

199
00:18:15,120 --> 00:18:22,080
nodes. And then tools like we have one called gradient CI, which is just a GitHub bot or application

200
00:18:22,080 --> 00:18:28,560
where we give you rich pull request information back. So notebooks are the entry point, but they're

201
00:18:28,560 --> 00:18:33,040
not exclusive or they're certainly not the end of it. It's really the question of, where are you on

202
00:18:33,040 --> 00:18:37,520
the kind of data processing or development, machine learning development lifecycle?

203
00:18:40,000 --> 00:18:47,040
As you've built this out, where the areas that, you know, what areas presented the most

204
00:18:47,040 --> 00:18:53,760
challenges? And, you know, we can kind of take this from different levels. One thing that I'm

205
00:18:53,760 --> 00:18:59,280
thinking about you mentioned, like you're transparently committing stuff to get like, are you

206
00:19:00,480 --> 00:19:07,120
are you doing that? You know, whenever I close out of a notebook or every time I, you know, run a

207
00:19:07,120 --> 00:19:12,160
new cell or like, how do you? Yeah, that's the connection between, you know, challenges and that

208
00:19:12,160 --> 00:19:17,280
question is like, you know, there's all this questions about granularity and I imagine that,

209
00:19:17,280 --> 00:19:22,320
you know, you've had to figure out a lot of that stuff along the way. Yeah, so I would say to

210
00:19:22,320 --> 00:19:27,520
that particular one, I think that is still unresolved in the sense that I don't think there's

211
00:19:27,520 --> 00:19:31,680
the best version of it that will exist in a year or two that exists today and I think it's been a

212
00:19:31,680 --> 00:19:38,080
lot of back and forth. You know, you know, Jupiter notebooks are formatted JSON objects with

213
00:19:38,080 --> 00:19:41,840
sort of a special cell type and everything else and they don't really map super well to the code

214
00:19:41,840 --> 00:19:45,440
that's actually running in it, at least from like a code differing or source control management

215
00:19:45,440 --> 00:19:53,120
perspective. And you got folks like interact coming out of Netflix that are trying to, you know,

216
00:19:53,120 --> 00:19:57,760
do interesting things with notebooks to make them more runnable. You have folks that are trying to

217
00:19:57,760 --> 00:20:02,640
take notebooks and turn them into executable objects. There's this whole ecosystem of innovation

218
00:20:02,640 --> 00:20:07,120
happening around the notebook itself, not to mention stuff that Jupiter is doing. So it's a

219
00:20:07,120 --> 00:20:11,440
good moving target from that perspective. Totally. And from our perspective, it's just a container

220
00:20:11,440 --> 00:20:16,240
and I think that's the important part. You know, we actually, big fans of Interact, I think that's

221
00:20:16,240 --> 00:20:21,920
a really important step in the, you know, basically they've created a TypeScript and JavaScript,

222
00:20:21,920 --> 00:20:27,200
like React Library, a web framework kind of interface for Jupiter. And I think that's doing a

223
00:20:27,200 --> 00:20:31,840
lot to move this as, you know, another kind of traditional primitive that can be used in the

224
00:20:31,840 --> 00:20:37,920
Webstack. But from our perspective, it's a container that has to be scheduled on a node somewhere

225
00:20:37,920 --> 00:20:44,400
and even within that kind of part of the process, there's a lot of complexity. You know, there

226
00:20:44,400 --> 00:20:49,680
are a million types of instances you can run on. There are a million ways of, you know,

227
00:20:49,680 --> 00:20:53,840
setting up how you do storage and artifact management and things like that. And our perspective is,

228
00:20:55,120 --> 00:21:00,000
you know, you should, there are sort of like best practices of like, hey, we can, you know,

229
00:21:00,640 --> 00:21:05,360
one example here, we, within gradient, there are experiments that you can run, which are just,

230
00:21:05,360 --> 00:21:09,840
you give us a container in some code and we're going to execute that as well as notebooks. And

231
00:21:09,840 --> 00:21:14,080
both of them, you know, at the fundamental level of gradient, which is actually built on top of

232
00:21:14,080 --> 00:21:19,760
Kubernetes, is that we're thinking about these as containers with a lot of nice kind of glue

233
00:21:19,760 --> 00:21:25,360
in between. So, for example, providing a single persistent high performance directory that's

234
00:21:25,360 --> 00:21:30,320
available across notebooks, experiments, and ultimately your deployments as well. And so,

235
00:21:30,320 --> 00:21:36,480
thinking about as like an infrastructural problem where you want to, you know, deploy a model,

236
00:21:36,480 --> 00:21:41,440
be able to see what, you know, what experiment created it, who, what line of code generated that,

237
00:21:41,440 --> 00:21:45,760
and then also use the feedback from that, you know, in the kind of holy grail here, which is to

238
00:21:45,760 --> 00:21:51,360
create a kind of continuous life cycle. And, you know, I think that's also an unsolved problem,

239
00:21:51,360 --> 00:21:56,640
but the way to solve it is, you know, I strongly believe is one that is looks more like a traditional

240
00:21:56,640 --> 00:22:02,800
software, you know, engineering stack issue. And so, you know, we, you've seen a lot of like,

241
00:22:02,800 --> 00:22:07,280
a lot of the dialogue in the, in this ecosystem is around like build versus buy or, you know,

242
00:22:07,280 --> 00:22:12,240
what's the one true platform? Is it this, you know, is it the SageMaker or Qflow or gradient?

243
00:22:12,240 --> 00:22:17,600
I think that the, the, the way this will resolve itself is that it'll be just like everything,

244
00:22:17,600 --> 00:22:22,080
everything else. Your every software team will build certain components by certain components,

245
00:22:22,080 --> 00:22:26,400
and mix and match them in a way that looks probably a lot like how, you know, software gets developed

246
00:22:26,400 --> 00:22:32,000
today. You know, when we send our website out, we have like every release, we, we use tools like,

247
00:22:32,000 --> 00:22:37,440
you know, code coverage, regression testing libraries, visual testing libraries. You know,

248
00:22:37,440 --> 00:22:43,360
we use CircleCI for our CICD engine. We use a lot of ARGO. There's a whole host of tools,

249
00:22:43,360 --> 00:22:47,760
and within this organization, we have our own practices. Like, you know, we've defined among

250
00:22:47,760 --> 00:22:54,480
the engineers here, myself definitely less now, but, you know, how the, you know, what's the,

251
00:22:54,480 --> 00:22:58,000
how, when do you make a branch? When do you make a pull request? When is it okay to make a release

252
00:22:58,000 --> 00:23:01,680
on something? So a lot of that, you still have to build a lot of your own methodology around software

253
00:23:01,680 --> 00:23:05,920
development. That's what makes a, you know, an organization effective. But the tooling itself, you

254
00:23:05,920 --> 00:23:10,080
know, you will need purpose-built tools, and we're, we're kind of making the case that we're offering

255
00:23:10,080 --> 00:23:15,200
a version of this that we think is, you know, built to, you know, grow into the next iteration,

256
00:23:15,200 --> 00:23:19,600
where, you know, machine learning becomes more prolific, not as, you know, as a domain, but as just

257
00:23:19,600 --> 00:23:25,120
to software engineering practice, kind of more fundamentally. Do you think that the, at a given

258
00:23:25,120 --> 00:23:32,160
organization, the tooling is best provided by folks that are familiar with the, this

259
00:23:32,160 --> 00:23:39,680
soft existing software engineering, you know, practices, or, you know, folks that are more

260
00:23:40,320 --> 00:23:47,120
coming at it from the, the data science side. And, and, you know, curious what you've seen in

261
00:23:47,120 --> 00:23:53,760
that regard? Yeah, I mean, I guess I'll add to the controversy. I do think this is something that,

262
00:23:53,760 --> 00:23:59,760
you know, at least at the very least has to engage the kind of CISOPS DevOps person, or the,

263
00:23:59,760 --> 00:24:04,320
or the team that's responsible for shipping production grade code, you know, whatever that looks like.

264
00:24:05,120 --> 00:24:09,200
You know, I don't think it's the domain of the data scientists or machine learning engineer

265
00:24:09,200 --> 00:24:14,800
necessarily. But I also think that the interface needs to be better defined, meaning, you know,

266
00:24:14,800 --> 00:24:21,840
we have to find a way that people can easily integrate with source control management and,

267
00:24:21,840 --> 00:24:25,840
you know, the primitive artifact that gets deployed. Like, for example, you know, you've heard stories,

268
00:24:25,840 --> 00:24:30,080
I'm sure of, you know, a model gets developed and then it gets rewritten in Java by somebody else

269
00:24:30,080 --> 00:24:34,480
so that they can actually deploy into their system. I think the Kubernetes, you know, containerized

270
00:24:34,480 --> 00:24:38,800
future and that in the world we're living in presents a nice kind of in-between model,

271
00:24:38,800 --> 00:24:42,400
which is that if you can containerize this thing and sort of define its inputs and outputs,

272
00:24:42,400 --> 00:24:46,720
then the artifact that comes out is something that you can hand off to the DevOps team and they

273
00:24:46,720 --> 00:24:50,160
can they can deploy effectively, you know, and they can deploy tools like, you know,

274
00:24:50,160 --> 00:24:54,560
Prometheus or, you know, metrics and logging and things that really are not within the scope of the

275
00:24:55,600 --> 00:24:59,920
machine learning kind of domain. And I think that's it's the separation of concerns that I think

276
00:24:59,920 --> 00:25:04,240
isn't really well defined. And so the outcome of that is that really sophisticated companies,

277
00:25:04,240 --> 00:25:08,080
you know, Facebook, Spotify, et cetera, you know, they have to build their own tools because they

278
00:25:08,080 --> 00:25:12,720
need to push this discipline forward. That's not going to be the case for most companies in the

279
00:25:12,720 --> 00:25:17,200
world and then the question is sort of what does that tool stack look like, you know, in ours as a

280
00:25:17,200 --> 00:25:22,880
proposal that is very much designed for, you know, a company that wants to produce production

281
00:25:22,880 --> 00:25:26,400
grade software and how machine learning integrates inside, you know, into that process.

282
00:25:27,040 --> 00:25:33,360
Yeah, that's a really interesting example you gave. Like everything or like many things in tech

283
00:25:33,360 --> 00:25:38,640
maybe it's there's a bit of a pendulum going back and forth. When I first started tracking this

284
00:25:38,640 --> 00:25:46,640
space eight something years ago or more, a lot of the early folks, a lot of the early

285
00:25:48,400 --> 00:25:54,480
goals and messaging of these early tool vendors, most of which are not still around was,

286
00:25:54,480 --> 00:26:00,800
you know, your data scientists are developing software or developing models in R and SAS and things

287
00:26:00,800 --> 00:26:05,840
like that and you have no way to put them in a production. And so you have to hand them over to

288
00:26:05,840 --> 00:26:10,240
folks that are, you know, like you said, building them in Java or building them in C, C++, whatever.

289
00:26:11,440 --> 00:26:17,600
And the, you know, the whole idea of a lot of these early tools was that you can, you know,

290
00:26:17,600 --> 00:26:25,760
develop and deploy and Python, right? And a lot of the argument was that you wouldn't have to pull

291
00:26:25,760 --> 00:26:33,840
in a separate person. The data scientists could just do that. And then the, the next wave of that

292
00:26:33,840 --> 00:26:37,920
was, well, you know, ah, maybe that's not going to work. We've got our data scientists. Let's

293
00:26:37,920 --> 00:26:42,320
hire a bunch of machine learning engineers and, you know, they'll be part of this process. And

294
00:26:43,040 --> 00:26:49,840
as opposed to kind of letting the tooling handle the productionalization, we've got people that

295
00:26:49,840 --> 00:26:56,400
come from more software engineering background. Um, and it sounds like you're talking about a further

296
00:26:56,400 --> 00:27:02,400
evolution of this pendulum, which is, well, containers will just do it for us. Yeah, I mean, I think

297
00:27:02,400 --> 00:27:08,560
that, I don't know how much I'll commit to that particular version. I, I agree it's a pendulum.

298
00:27:08,560 --> 00:27:12,880
I, I do think that, um, you know, like I've said, I think this is a software engineering practice

299
00:27:12,880 --> 00:27:17,200
or at least there are a lot of, you know, pieces we can pull from that. Yeah. I do think it's made

300
00:27:17,200 --> 00:27:22,080
leaps and bounds forward on in the sense that, you know, containers are really, really helpful for,

301
00:27:22,080 --> 00:27:25,600
you know, building out web applications. They're portable, they're reproducible, you know,

302
00:27:25,600 --> 00:27:30,080
my dev environment is similar to yours. It's, you can't map that perfectly to, um,

303
00:27:30,720 --> 00:27:34,800
uh, you know, the machine learning development process. But there's, there's also, you know,

304
00:27:34,800 --> 00:27:39,280
newer concepts like there's, uh, in the Kubernetes world, there's a lot of talk about, you know,

305
00:27:39,280 --> 00:27:44,480
solving the inner loop of development, which is, um, basically saying, you know, we, we have the,

306
00:27:44,480 --> 00:27:48,800
as a software software engineering problem, we have these complicated systems, you know,

307
00:27:48,800 --> 00:27:52,640
uh, paper space and gradient is a whole lot of services at a bunch of microservices,

308
00:27:52,640 --> 00:27:58,160
a bunch of big services. Um, how do, how do you, uh, basically keep a fidelity between your

309
00:27:58,160 --> 00:28:01,200
production environment and your development environment in the, you know, because maybe your

310
00:28:01,200 --> 00:28:05,280
laptop isn't going to run the whole host of production environments. So, you know, a lot of

311
00:28:05,280 --> 00:28:09,280
interest in, or a lot of software development from coming out from Google, we have,

312
00:28:09,280 --> 00:28:13,600
got tools like scaffold and the idea here is that, you know, you want to, uh, they call the inner

313
00:28:13,600 --> 00:28:16,960
loop of development, which is like, before it goes into production, someone's just iterating

314
00:28:16,960 --> 00:28:20,480
on it, which I think actually is what a lot of the data scientists who push back on the machine

315
00:28:20,480 --> 00:28:26,240
learning or the ML ops kind of paradigm that is totalizing is, you know, uh, they're like, oh,

316
00:28:26,240 --> 00:28:29,280
well, I'm going to, I'm going to work in a notebook here locally and I just, you know, I don't think

317
00:28:29,280 --> 00:28:32,960
every line of code here needs to be committed to source control. And that's, and that's true,

318
00:28:32,960 --> 00:28:37,040
you know, you don't need to, you don't need to get, you know, heavy handed with it. Um, but it is

319
00:28:37,040 --> 00:28:42,960
an open problem and open discussion in even the Kubernetes world way, you know, uh, totally distinct

320
00:28:42,960 --> 00:28:46,800
from machine learning world. Um, and I, you know, I think that the conversations are most productive

321
00:28:46,800 --> 00:28:53,120
when the two, you know, engage in that way. Um, but yeah, I mean, I, like, people that are interested

322
00:28:53,120 --> 00:28:57,680
in the kind of deriving insight from a machine learning model, uh, you know, they want to be working

323
00:28:57,680 --> 00:29:02,240
in these amazing tools like TensorFlow and PyTorch. But at the same time, if you look at like PyTorch's

324
00:29:02,240 --> 00:29:09,200
evolution, um, is like another kind of, uh, proxy of this, you know, um, they have native C++

325
00:29:09,200 --> 00:29:14,560
bindings and there's a lot of, there's a lot of, um, uh, push to make this a regular software

326
00:29:14,560 --> 00:29:18,640
development thing because PyTorch has all sorts of limitations. It's a, it's a very expressive

327
00:29:18,640 --> 00:29:23,280
language, um, very powerful in machine learning, uh, but isn't maybe the best one for, you know,

328
00:29:24,000 --> 00:29:28,160
squeezing out the performance from your incredibly expensive cloud GB resources or something like

329
00:29:28,160 --> 00:29:31,920
that. Um, so I think it's coming from both dimensions, you know, if you've got like the software

330
00:29:31,920 --> 00:29:35,040
engineers trying to be more machine learning stuff, you've got the ML folks that are like, yeah,

331
00:29:35,040 --> 00:29:39,760
we want to, you know, become more, uh, kind of pervasive in an organization or have higher impact

332
00:29:39,760 --> 00:29:44,640
in what gets shipped, um, and it's an evolving practice. But I, I do think that, you know, uh,

333
00:29:44,640 --> 00:29:50,320
uh, I, I, or sorry, I would say I don't believe that there's one ML ops platform to rule them all

334
00:29:50,320 --> 00:29:55,840
and it has to do the best training, you know, uh, model aggregation, quantizing, and, uh, you know,

335
00:29:56,480 --> 00:30:01,520
AB testing and like the full end end. But I do think that there's a lot of value in tools,

336
00:30:01,520 --> 00:30:05,920
you know, like cube flow, which I would say is probably the closest analogy to, to gradient, um,

337
00:30:05,920 --> 00:30:08,720
where, you know, you're setting up something that's kind of foundational and there's,

338
00:30:08,720 --> 00:30:11,840
you know, in the case of cube led, and there's a lot of setup that's required. It is a complicated

339
00:30:11,840 --> 00:30:15,680
tool stack and in the case of gradient, it's kind of like, you know, we're going to manage it for

340
00:30:15,680 --> 00:30:22,080
you a bit more. Um, but yeah, I think that enlisting the, you know, DevOps systems people who

341
00:30:22,080 --> 00:30:26,800
have to manage the same, keep it running early on the process sets you up for success and allows

342
00:30:26,800 --> 00:30:30,400
you to ultimately get all the things we always talk about, you know, more models faster, you know,

343
00:30:30,400 --> 00:30:36,960
higher impact, all that kind. Right. Right. And is there a relationship between gradient and,

344
00:30:36,960 --> 00:30:42,880
and cube flow is gradient, you know, does gradient use parts of cube flow or is, uh,

345
00:30:42,880 --> 00:30:50,720
do we think of gradient as a paper space analogy to cube flow, but one that, you know, has features

346
00:30:50,720 --> 00:30:55,920
that are specific to the way you view the world? Yeah. Um, so it's an interesting question.

347
00:30:55,920 --> 00:30:59,520
I think it's evolving as well. I think cube flow is a really interesting project. It's still

348
00:30:59,520 --> 00:31:04,640
relatively early. And I think, um, you know, Kubernetes is also something that, you know, not a lot

349
00:31:04,640 --> 00:31:08,960
of organizations have expertise in yet. So it is something that is a little bit harder to get going,

350
00:31:08,960 --> 00:31:14,400
but very powerful. Um, where we overlap is we are also based on Kubernetes. I mean, Kubernetes is

351
00:31:14,400 --> 00:31:18,880
just container orchestration, some networking stuff, and some nice best practices. And I'm

352
00:31:18,880 --> 00:31:24,480
privilizing Kubernetes, but it doesn't do anything really around machine learning or auto scaling

353
00:31:24,480 --> 00:31:29,840
is in particular to GPUs and things like that. Cube flow does a lot in that way, but the best

354
00:31:29,840 --> 00:31:35,520
part of cube flow, um, at least what we've seen work really well are, uh, is, is it's,

355
00:31:35,520 --> 00:31:40,560
is the fact that it's based on top of Argo as the, um, kind of pipeline tool. So Argo CD.

356
00:31:41,360 --> 00:31:47,360
So we also use Argo. Uh, the difference is, you know, cube flow, uh, compiles down to Argo YAML,

357
00:31:47,360 --> 00:31:52,560
ultimately. Um, we have our own syntax that also compiles down. And so the newest iteration of

358
00:31:52,560 --> 00:31:57,680
this is that they are compatible at a kind of fundamental level, but, um, you know, we buy a certain

359
00:31:57,680 --> 00:32:01,920
things. Um, we also, I mean, the most important differentiator between those two projects is that

360
00:32:01,920 --> 00:32:07,200
we have a, um, very sophisticated like GUI console where you can do most things through, you know,

361
00:32:07,200 --> 00:32:11,040
again, because most data science, you know, data science and kind of statisticians and,

362
00:32:11,040 --> 00:32:16,000
and mathematicians are not the same people that, um, can, can string up very complex, uh, you know,

363
00:32:16,000 --> 00:32:22,240
Kubernetes tooling. Mm hmm. And for those that don't know, Argo is the underlying workflow

364
00:32:22,960 --> 00:32:30,240
engine. How is that workflow engine used in, uh, gradient or, uh, cube flow for that matter?

365
00:32:30,240 --> 00:32:35,360
Yeah. So the, I mean, the, the, the kind of underlying piece is this, uh, continuous integration,

366
00:32:35,360 --> 00:32:41,200
continuous deployment, uh, engine, which basically says, you know, um, here are the steps in the

367
00:32:41,200 --> 00:32:45,600
process. Like this thing happens, then this thing happens. Uh, I need to build a container, I need to

368
00:32:45,600 --> 00:32:49,680
pull my data in, I need to process that data and each thing is sort of a step in that process.

369
00:32:50,400 --> 00:32:53,360
Um, and then you start thinking about like what the triggers to that. So this is another area

370
00:32:53,360 --> 00:32:58,880
where the, the kind of CICD paradigm doesn't map fully between machine learning and, you know,

371
00:32:58,880 --> 00:33:04,960
web app development or containerized, you know, um, no JS apps, which is, uh, the,

372
00:33:06,640 --> 00:33:11,440
the types of triggers can be very different. Like normally the trigger in a, in a, in a, in a,

373
00:33:11,440 --> 00:33:16,000
when you make a web app or an iOS app is, you, you push new code, you have a code commit, and that

374
00:33:16,000 --> 00:33:20,720
causes, you know, that's the primary trigger. Um, in the case of machine learning, there are some

375
00:33:20,720 --> 00:33:25,920
interesting ones that I think still, you know, early, you know, early days, but, um, you know,

376
00:33:25,920 --> 00:33:31,040
there are concepts like model drift and data drift. Um, you know, we joke around, it's like,

377
00:33:31,040 --> 00:33:34,960
code is just, or a code commit is just code drift. It's just like something has changed. So let's,

378
00:33:34,960 --> 00:33:38,560
let's kick off this pipeline again. And Argo is a really nice one, which gives you,

379
00:33:38,560 --> 00:33:42,640
it's a Kubernetes native CI CD engine, and there are a bunch of components to it. And, and that is

380
00:33:42,640 --> 00:33:49,840
the, um, a big part of, of cube flow. Um, and we also use that as, as, uh, this sort of our

381
00:33:49,840 --> 00:33:54,160
underlying engine. Um, but on top of that, there are a lot of other things with just like the UI,

382
00:33:54,160 --> 00:33:58,880
how you expose it, the command line interface, the, the way you expose the syntax and semantics.

383
00:33:58,880 --> 00:34:03,360
And I think it's a race you talked earlier about the, um, you know, the right level of granularity.

384
00:34:03,360 --> 00:34:08,000
And I think that is the big question. I think that's where, you know, any startup in this space or

385
00:34:08,000 --> 00:34:12,960
any, you know, software coming to space really has to keep an eye on how it's moving because, um,

386
00:34:12,960 --> 00:34:17,760
best practices change every day and, you know, uh, new frameworks come alive. But I think we've

387
00:34:17,760 --> 00:34:21,760
seen some stabilization. I do think that the machine learning landscape from like a fundamental

388
00:34:21,760 --> 00:34:26,080
framework and tooling perspective is, is somewhat stabilized. Whereas, you know, two years ago,

389
00:34:26,080 --> 00:34:30,480
it was the pre-cambering explosion, whereas like every day something new came up. So I don't know

390
00:34:30,480 --> 00:34:33,920
your thoughts on that. If that's like something you're, you also would agree with or if it's, uh,

391
00:34:33,920 --> 00:34:40,080
we're still in the wild west. Now, I definitely agree with, with that statement, um,

392
00:34:40,080 --> 00:34:44,880
I've written quite a bit about it. We've got an ebook, the definitive guide to machine learning

393
00:34:44,880 --> 00:34:51,600
platforms that try to map out the early phases of this Cambrian explosion. Uh, and then, uh,

394
00:34:51,600 --> 00:34:57,680
another one, Kubernetes for ML ops, uh, which, you know, for anyone who's still listening who,

395
00:34:57,680 --> 00:35:01,760
you know, has alphabet soup in their head and wants to know what all these terms are and

396
00:35:01,760 --> 00:35:07,600
how they fit together. That will be a good one to check out. But I certainly agree that we're

397
00:35:08,320 --> 00:35:20,320
starting to see more, um, more kind of coalescing of the major components. There are well-defined

398
00:35:20,320 --> 00:35:28,000
subcategories now within kind of this tooling and platform landscape. And it is continuing to be

399
00:35:28,000 --> 00:35:36,800
interesting. Uh, I'm curious from your perspective for, you know, folks that are coming at this

400
00:35:36,800 --> 00:35:46,240
from the data science machine learning side, haven't done much with, uh, ML ops or processes,

401
00:35:46,240 --> 00:35:51,920
you know, do the usual, you know, I've got a notebook on a server somewhere, write some code,

402
00:35:51,920 --> 00:35:57,840
you know, pull that code out of the notebook and, uh, you know, somehow get it into production. Like,

403
00:35:57,840 --> 00:36:05,680
what, what's the first thing to do or, or the first three things to, to think about, to be more,

404
00:36:06,720 --> 00:36:10,880
as discipline the right word, uh, to advance your, your, your process.

405
00:36:11,680 --> 00:36:17,360
Yeah, I, I think that, um, I would, I would encourage the use of A tool, you know, obviously

406
00:36:17,360 --> 00:36:22,800
on bias. I think we, you know, we were, uh, we are approaches to onboard people into all this,

407
00:36:22,800 --> 00:36:26,400
these complicated tools that we're talking about, you know, the alphabet soup of Kubernetes and

408
00:36:26,400 --> 00:36:30,240
Argo and everything else. Um, the interface for gradient is actually quite simple, you know,

409
00:36:30,240 --> 00:36:35,280
the notebook is the starting point. Um, and, you know, it, it rewards closer inspections. So

410
00:36:35,280 --> 00:36:39,520
the deeper you go into it, the more you'll see where it adds value. Um, but I should have said,

411
00:36:39,520 --> 00:36:45,840
one of the first three steps besides use gradient. Yeah. Um, you know, I think I, I, the, the,

412
00:36:45,840 --> 00:36:49,760
they're really the ones that I think probably most people with space would agree on. It's like, um,

413
00:36:49,760 --> 00:36:53,760
find a, a problem that you want to solve that's relatively narrowly scoped because that,

414
00:36:53,760 --> 00:36:57,840
you know, we've worked on, we internally, we have a lot of machine learning projects and the ones

415
00:36:57,840 --> 00:37:01,440
that do really well are the ones that have a very clean sort of scope and we know what we're trying

416
00:37:01,440 --> 00:37:06,160
to solve. Um, I think when it becomes unbounded, like find something interesting in the data,

417
00:37:06,160 --> 00:37:10,400
it, it gets really hard because not only are you having tooling issues, you're trying to figure out

418
00:37:10,400 --> 00:37:16,240
what the, the question is. Um, and that's it, that's very attractive given that, you know, um,

419
00:37:16,240 --> 00:37:19,840
you can download TensorFlow and you kind of get superpowers like it's in, it's a, it's a,

420
00:37:19,840 --> 00:37:24,160
it is a fundamentally transformative thing that can do things that you, you know, can't do otherwise.

421
00:37:24,160 --> 00:37:29,680
But, um, the fundamentals are still there, which are, you know, you, you should commit to a process

422
00:37:29,680 --> 00:37:33,760
of, or sorry, define the problem that you want to solve. Any organization trying to onboard

423
00:37:33,760 --> 00:37:38,560
to machine learning broadly today, um, if they haven't already, would have to locate where they

424
00:37:38,560 --> 00:37:43,760
want to apply it. In our case, the first thing we ever did was, um, just, uh, uh, kind of like

425
00:37:43,760 --> 00:37:47,760
fraud detection and lead scoring. We get people to sign up every day, um, you know, at this point,

426
00:37:47,760 --> 00:37:52,960
we've had, I think over 350,000 people sign up. This is during the Bitcoin boom as well, so we

427
00:37:52,960 --> 00:37:56,720
want to make sure that, you know, who's a, who's a real actor, who's not. And we had a very narrow

428
00:37:56,720 --> 00:38:01,680
sense of that. And that's, that's a production, um, thing that we use today. But when you, when

429
00:38:01,680 --> 00:38:07,680
it's more unbounded, it becomes much harder. Um, I think, you know, developing the practice around

430
00:38:07,680 --> 00:38:12,720
it in software development, it is the collection of the, you know, GitHub readmys and the,

431
00:38:12,720 --> 00:38:16,480
whether you do standups, you know, it's like, there is a software development practice way beyond

432
00:38:16,480 --> 00:38:21,600
the tooling. Um, and, you know, I think that's important. Uh, also source control management is

433
00:38:21,600 --> 00:38:26,480
great. You know, uh, you don't, you don't want to be, you know, naming your files, um, you know,

434
00:38:26,480 --> 00:38:31,920
final, final, final three dot ipinb, uh, because it's just, you know, you're, you're going to put

435
00:38:31,920 --> 00:38:37,760
get yourself in, uh, in, uh, you know, complicated mess over time. So I think source control management

436
00:38:37,760 --> 00:38:42,160
is, is key. But, um, yeah, I don't know if that was two or three, but I, you know, I think the

437
00:38:42,160 --> 00:38:46,320
fundamentals are true. Regardless of, and again, this goes back to like, I think this is, uh, you

438
00:38:46,320 --> 00:38:51,600
know, more well understood problem than maybe we all have, uh, realized. And so that's coming at

439
00:38:51,600 --> 00:38:57,040
things from the data science perspective. What about coming at things from the engineering

440
00:38:57,040 --> 00:39:05,440
perspective, you know, say you've been working on, on these kinds of problems, uh, at a relatively

441
00:39:05,440 --> 00:39:10,560
modest scale, you know, what are the kinds of what are the gnarliest, you know, technical issues

442
00:39:10,560 --> 00:39:18,000
you run at trying to run this at, um, you know, provider scale. Yeah, that's a really good one. Um,

443
00:39:19,360 --> 00:39:24,080
open AI actually outlined a lot of them, which are when you start doing this a lot. So for example,

444
00:39:24,080 --> 00:39:29,840
we run kind of a public gradient instance, which is where we run all the free notebooks. Um,

445
00:39:29,840 --> 00:39:34,560
and so it's basically like one big managed instance, uh, you know, there are some issues of scale

446
00:39:34,560 --> 00:39:38,720
for sure. Uh, you know, you're going to hit issues of pulling containers down, caching them

447
00:39:38,720 --> 00:39:42,640
at CD, which is the tool that kind of, you know, an essential tool for communication within the

448
00:39:42,640 --> 00:39:47,040
process. It does break down at a certain level. Um, you start have to, you know, look, you have to

449
00:39:47,040 --> 00:39:51,760
look for things like where, you know, your bottlenecks are. And so we've spent, you know, many years now

450
00:39:51,760 --> 00:39:57,760
optimizing this, um, you know, the way the pieces connect to one another because it's very likely

451
00:39:57,760 --> 00:40:02,320
in your first app at it, you will have an expensive GPU and an expensive CPU and a lot of memory,

452
00:40:02,320 --> 00:40:06,880
but you're actually using not of it due to something totally outside of the, uh, you know, of that

453
00:40:06,880 --> 00:40:12,240
thing. Um, and figuring that out is hard. I think big teams, you know, it pays off to invest in that.

454
00:40:12,240 --> 00:40:16,720
I think Uber, you know, does great in that they have an expertise here. And this is a, you know,

455
00:40:16,720 --> 00:40:23,040
an internal effort, but I think a lot of companies would benefit from this tooling as well, um,

456
00:40:23,040 --> 00:40:27,680
without having to go down that path of building custom, you know, or entirely purpose-built tooling.

457
00:40:27,680 --> 00:40:30,560
There will always be something that gets built internally. We have all sorts of, you know,

458
00:40:30,560 --> 00:40:35,440
admin tools that we build, but, um, fundamentally, we committed to a containerized process. We've

459
00:40:35,440 --> 00:40:40,880
adopted newer practices. Um, uh, and I think that pays off and, you know, it allows us to ship,

460
00:40:40,880 --> 00:40:44,960
ship a new version of the software every two weeks, you know, or whatever the release cadence is.

461
00:40:44,960 --> 00:40:49,360
Um, and that's, that, that's the holy grail. It's like you want to be able, you know,

462
00:40:49,360 --> 00:40:53,840
machine intelligence broadly is like, can you build out a model that is predictive and powerful?

463
00:40:53,840 --> 00:41:00,240
And also, um, is in a system that can then be fine-tuned or, or modified as it reacts to the

464
00:41:00,240 --> 00:41:05,280
environment. So it's like we built these predictive models that are incredible. Um, how do you,

465
00:41:05,280 --> 00:41:09,840
you know, now work that into, to everything else? And I think that's the open question around,

466
00:41:10,480 --> 00:41:13,360
uh, how software development, you know, and maybe there's something to learn there,

467
00:41:13,360 --> 00:41:16,960
and, and some of it has to be redefined. You know, like we didn't talk a lot about hardware,

468
00:41:16,960 --> 00:41:20,720
but that's, that's a, you know, I think we might have had a conversation about that in the past,

469
00:41:20,720 --> 00:41:26,320
but, um, accelerator, you know, GPUs were, were video game cards, and now they're, uh, you know,

470
00:41:26,320 --> 00:41:30,960
ML processing cards. And so there's a whole host of new things coming out. And I think that's

471
00:41:30,960 --> 00:41:35,680
going to lead to a lot of interesting developments in the space that we're in, which is largely

472
00:41:35,680 --> 00:41:40,560
involved with like the interface between hardware and physical infrastructure and, you know,

473
00:41:40,560 --> 00:41:46,080
uh, sending, uh, software into production, and then the actual media, the problem of like,

474
00:41:46,080 --> 00:41:51,040
I want to build a model and do something amazing. Anything you're particularly excited about,

475
00:41:51,040 --> 00:41:59,040
and can talk about on that front? Um, yeah, I, I think broadly actually gets back to one of the

476
00:41:59,040 --> 00:42:03,840
things I kind of earlier in the conversation. I, I am particularly interested in, uh,

477
00:42:03,840 --> 00:42:09,520
uh, where the visualization pipeline and the compute pipeline collapse. Uh, we actually,

478
00:42:09,520 --> 00:42:14,880
I was at, uh, SIGGRAPH, the big visual effects conference, um, in LA, maybe three, three,

479
00:42:14,880 --> 00:42:19,920
three years ago or so. Uh, and it was clear that AI was sort of making its way in there,

480
00:42:19,920 --> 00:42:25,920
but everything from, you know, better rendering to bots in games, um, and then on the other end,

481
00:42:25,920 --> 00:42:31,040
you have, you know, uh, driverless cars, simulators that can simulate environments. And I think the

482
00:42:31,040 --> 00:42:35,520
newest iteration of that is this, um, you know, a lot of talk around synthetic data, you know,

483
00:42:35,520 --> 00:42:39,200
if one of the limitations of building powerful machine learning models is generating data,

484
00:42:39,200 --> 00:42:43,680
how can that be done more quickly? Um, you know, can you use Unity? And I think the,

485
00:42:43,680 --> 00:42:47,840
the blend of those gets really interesting and I don't know exactly where it goes, but it is an

486
00:42:47,840 --> 00:42:52,320
area that I think is fascinating right now, um, which is now you're roping in the, you know,

487
00:42:52,320 --> 00:42:56,560
the content creators as well into this, this tool and it speaks to the power of it, you know,

488
00:42:56,560 --> 00:43:01,040
it speaks to you of this, this tool, you know, machine learning and its current, you know, iteration,

489
00:43:01,040 --> 00:43:05,280
it's so powerful, it can do things that are, you know, mind-boggling and complex and, you know,

490
00:43:05,280 --> 00:43:11,600
we need to regulate in probably lots of ways, but, um, uh, you know, it's making its way into, uh,

491
00:43:11,600 --> 00:43:17,520
you know, the universe way beyond sort of traditional ML stats and, you know, data science. And so,

492
00:43:18,560 --> 00:43:22,160
there will be a lot of dimensions that emerge. Software development is the one I'm thinking a lot

493
00:43:22,160 --> 00:43:27,680
about, but I think they're, you know, yeah, it's an interesting time for sure. Yeah, over the years,

494
00:43:29,280 --> 00:43:38,800
Jensen's visualization demos at NVIDIA's GPU conference have gotten extremely impressive,

495
00:43:38,800 --> 00:43:44,640
like all the ray tracing stuff and some of the simulation stuff that they're doing. And again,

496
00:43:44,640 --> 00:43:50,400
to your points, the same hardware. Yeah, I, yeah, to me, that's where it gets really, really,

497
00:43:50,400 --> 00:43:54,160
really interesting. It looked like those were two totally diversion paths, and now it looks like,

498
00:43:55,600 --> 00:44:00,400
you know, we had, we had one point, it might still be live. We had a guy who was, um,

499
00:44:00,400 --> 00:44:06,080
training a model to, to drive his, uh, grand theft auto car on Twitch, and people could pay into his

500
00:44:06,080 --> 00:44:09,840
account, and it would, you know, pay for his paper space credit so we could run the whole thing.

501
00:44:10,880 --> 00:44:15,120
And this, this car was like, you know, it was not, I wouldn't, I wouldn't get in the car, but it was

502
00:44:15,120 --> 00:44:18,560
a funny, you know, experience for us. Like, we're going to train this thing using, you know,

503
00:44:18,560 --> 00:44:22,000
grand theft auto. And it's like, those are interesting to me. Like, it's just like,

504
00:44:22,000 --> 00:44:26,320
a totally emerging use case and, and, you know, something as possible that was never possible before.

505
00:44:26,960 --> 00:44:33,040
That's awesome. That's awesome. Uh, so one last question for you. I'm curious if, you know, given that you,

506
00:44:34,000 --> 00:44:43,520
uh, you, you've got all these users doing machine learning stuff, uh, on, on gradient, any unique insights

507
00:44:43,520 --> 00:44:49,280
into what's coming based on what folks are doing. Do you get that kind of visibility?

508
00:44:50,240 --> 00:44:55,200
Yeah. I mean, I think, candidly, I think a lot of people are still at the beginning of understanding

509
00:44:55,200 --> 00:44:59,440
this technology. And, and I don't mean the, the folks that, you know, we hang out with at NERIPS.

510
00:44:59,440 --> 00:45:03,600
I mean, the, the, you know, the software engineers that are, you know, building, building every

511
00:45:03,600 --> 00:45:08,960
other software tool we use, I think within that universe, machine learning is still exotic, new,

512
00:45:08,960 --> 00:45:14,880
um, it, you know, it speaks to why, you know, Jeremy, uh, you know, can, can get so much interest in

513
00:45:14,880 --> 00:45:19,120
fast AI, you know, he present, he presents fast AI is like the pragmatic way of getting started with

514
00:45:19,120 --> 00:45:25,760
machine learning. Yeah. Exactly. And I think that that resonates a lot because it's still new. So,

515
00:45:25,760 --> 00:45:31,120
from, you know, at this point, we've run something like 60 million hours of compute, you know,

516
00:45:31,120 --> 00:45:35,520
through the platform. And most of that is probably training, you know, or, you know, a lot of it is

517
00:45:35,520 --> 00:45:39,280
probably the first model that you train and trying to swap the data set out to see like what, what

518
00:45:39,280 --> 00:45:44,960
you can do. Um, I think it gets more interesting as that you're like, you know, wow, this actually

519
00:45:44,960 --> 00:45:50,640
worked in some way. Now how do I blend it and, uh, you know, or, or do something with it? Um,

520
00:45:50,640 --> 00:45:55,040
in most cases, like, it's like, how do I take this model and turn it, you know, make it on an iPhone

521
00:45:55,040 --> 00:46:00,400
or, you know, deploy it? I think those are still really hard things. Um, so where's it going? I,

522
00:46:00,400 --> 00:46:05,920
I think that generally you will see more regular software engineers, whatever the, you know, whatever

523
00:46:05,920 --> 00:46:10,640
that encompasses, you know, using these tools and understanding them more because it's sort of

524
00:46:10,640 --> 00:46:18,080
moving past academia. Um, academia is still mind-blowing in how, you know, how fast it can move ahead.

525
00:46:18,080 --> 00:46:22,640
Every conference, it's like, wow, this is something that was totally unfathomable even a,

526
00:46:22,640 --> 00:46:26,400
you know, a couple of years ago. But there's still a lot of catch up to do in the kind of, um,

527
00:46:26,400 --> 00:46:33,120
machine learning as a professional practice, I would say. Yeah. Awesome. It's been amazing

528
00:46:33,120 --> 00:46:38,320
catching up with you. Uh, too bad we work. We, uh, it's been a while since we've seen each other

529
00:46:38,320 --> 00:46:44,560
in person, uh, due to circumstances. Yep. We're controlled. But, uh, maybe one of these days,

530
00:46:44,560 --> 00:46:47,600
we'll be able to grab a coffee or something at a conference.

531
00:46:47,600 --> 00:46:57,920
Yeah. Cheer with. Thank you. Thank you.

