Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington, hey what's up everyone, we've got an amazing Twimble
Con AI platform's event shaping up for you and I wanted to share a bit about it.
The event is going to be anchored by what we're calling keynote interviews.
These are live podcasts recorded right on the main stage and I'll be joined by some incredible
guests, here are three that I'm really excited about.
One, Andrew Eng, I could not be happier to have Andrew kicking off this event with me.
Andrew is one of my AI heroes and no one has done more to bring new practitioners into machine
learning and deep learning than he has.
Andrew is going to be sharing a bit about what he's learned helping many businesses get
productive with machine learning and AI and also speak with us about where he sees the
field going.
Number two, Hussein Mahana, Hussein is the head of AI and ML at Cruz, the self-driving
car company.
Before Cruz, Hussein helped build Google's cloud ML platform and Facebook's internal
FB learner platform before that.
Hussein is going to be sharing some of the lessons he's learned building ML platforms
from scratch at some of the most advanced companies in the space.
And number three, Fran Bell.
Fran leads a team responsible for data science platforms at Uber.
These are use case focused ML platform supporting application areas like forecasting, anomaly
detection, NLP and conversational AI segmentation and more.
Her platform sit on top of Uber's Michelangelo, putting here on a unique position to speak
with us about how low level and higher level platforms come together to support data scientists
and developer productivity.
Beyond keynote interviews like this, we've got a bunch of outstanding speakers lined up
to share their successes and failures, helping their organizations build and production
lies, ML and deep learning models.
If this lineup sounds interesting to you, visit twimmolcon.com today to register.
Use the coupon code GreatContent through July 31st for an additional 10% off of our special
early bird pricing.
Hope to see you at Twimmolcon.
Alright everyone, I am on the line with Theo Cariannis.
Theo is an assistant professor at the Brain Research Institute of the University of Zurich.
Theo, welcome to this Week in Machine Learning and AI.
Thank you very much for having me.
Absolutely, absolutely.
Let's get started by having you share a little bit about your background.
How did you come to work at the intersection of brain science and machine learning?
Yes, so I would say that I haven't had sort of the most direct path in this sort of field.
So I started off actually studying pharmacy of all things.
So I had sort of my bachelor's degree in pharmaceutical sciences and pharmacy and then I was
very, very much interested in sort of my final years in getting into brain science and understanding
actually brain physiology and pathology.
After that, I decided to pursue a career in neuroscience research, so brain science,
through which I've had sort of a decent sort of long trajectory.
And after I would say establishing my lab here at the University of Zurich about three
years ago, so I came to appreciate and came more into sort of contact with the methods
that were actually flooding, in fact, every almost field of science and also neuroscience
that had to do with deep learning.
So that was sort of my first kind of contact with deep learning was after I joined the
brain research institute and I started working on my own kind of research projects after
being a postdoctoral fellow.
So I can elaborate more if you want on this or well, why don't you tell us a little bit
about your research focus?
Yeah.
Okay.
So what I have been working on and actually I'm very much interested in the lab as well.
We're very much focused on understanding how the brain develops.
So our primary focus is utilizing animal models, mammalian animal models, more specifically
genetically tractable animal model, the mouse.
And utilizing that in order to understand how the circuits in the brain get formed during
development, especially postnatal development, so after birth, and how these circuits are
modified by experience to allow us to really process information from our environment and
ever increasing sort of complex and specific manner.
So I would say that this is kind of the umbrella field that we were working towards understanding.
So basically one of the sort of the more specific aspects of our work is aimed at understanding
how the cortex gets built, so which is this outer surface of the brain, which is kind
of supposed to be the most complex and evolutionary newer part of the nervous system.
And to understand that, we focused on specific sort of sensory regions in the cortex of the
mouse in order to understand how they process information as the animal grows.
Okay.
And so does the cortex have how are the different sensory regions in the cortex organized?
So there's some sort of some a topic if you want in a way in the sense that they are
separated in space.
So there's, for example, regions that are devoted to processing visual information, other regions
are devoted to processing so much of sensory information, so touch, events, and others
for other sensory modalities that we have, such as hearing or smelling.
So there's sort of a, of course, this aggregation of these areas, which at some point, of course,
further down the information processing kind of convergent come together into a common
sort of conscious, if you want, event that can lead to behavioral outcomes.
Is your research focused on understanding how the kind of connections and pathways are
made?
Or do you see that the neurons kind of physically differentiate so that there are multiple
types that kind of interact with one another to produce memory and behavior in these things?
We basically focus quite a bit on understanding a population of cells, neurons in the brain,
which are called inhibitory cells, or they have, sort of, used alternative names and maybe
more so correct these gubergic cells that take their name from the molecule they used
to communicate with one another.
So we basically focus a lot on understanding how this second most populous neuronal sort
of group in the cortex gets developed, so develops and integrates into the sort of circuit
to start parsing out the information that the circuit receives.
So I would say that, you know, the lab is sort of focused at multiple levels of analysis.
One of which is now going to this a bit more to this sort of brain-wide level where things
need to sort of be quantified at a sort of more complete if you want sort of level.
So we try to understand a little bit how different areas sort of develop how inhibitory cells
themselves that inhibit signals and regulate how information flows are positioned in different
areas, how they start function during development and what that may do for signal propagation.
So this is kind of something that we've been focused, of course, there's multiple different
types of cells and the jury is still out as to how many, but our work is sort of a bit
focused more on these cells.
And so how is deep learning come into play in your research in this area?
The way we kind of came about or turned our attention to deep learning is through a couple
of projects that we had in mind where we in fact wanted to address what I was saying
earlier, which has to do with a bit more comprehensive understanding of how these populations
are, let's say, generated, how they populate different areas and how they may even sort
of cease to exist by a phenomenon which is called cell death.
And so in order to be able to achieve that, one needs to create or have the tools at hand
that allow them to be able to perform an experiment or have some data at hand which have to
do with actually, let's say, distribution of cells, let's say, based on a specific marker
or something that marks the cells that one is interested in our case, let's say inhibitory
cells in the whole brain, right?
And that way you have sort of, let's say, a section, a tissue that allows you to sort
of look at that and take a picture of it.
Now, the key question here is how do you analyze that data and how do you analyze it across
different developmental stages?
This is actually how we came about wanting to look into these techniques that are very powerful
and are created by multiple labs across the globe that would allow us to basically, first
of all, have an atlas that tells us which region is which when we're looking at our tissue.
And on top of that, try to extract the signal, which is a cellular signal.
So it's a dotted sort of signal from each one of those brain areas.
So this is actually, you know, the reason why we turned our attention to deep learning
and machine learning methods that would allow us to basically segment, classify segment
different regions and also be able to basically pick up detect the cellular signal that is found
within them.
Okay.
And so a little bit more about the images that you're using, are they 3D scans?
Are you looking at slices and you need to relate information between slices?
Can you tell us a little bit more about the images themselves?
Yes.
Actually, we started off by doing sections, so slices, so tissue sections, brain sections.
So where we have the whole brain, in fact, in view, and we just take images that can be
also different modalities.
It can be, for example, some bright field images where you detect some chromophore signal
that has been created by a chemical reaction or by fluorescence.
So by signal, which actually leads to fluorescent sort of protein signal that you can detect
in cells, we have nevertheless also applied these kinds of methods now to different images
from different modalities, imaging modalities, such as those taken by a fairly new method
that is used in the biological field and also in the neurosciences, which is called clarity
or brain clearing.
These types of images are generated by the fact that what is done during the processing
of the brain, which is after the animal has been sacrificed, is to basically get rid
of the lipids and make the brain be transparent, the tissue.
And that way you can actually just shine light through it and detect what is evoked in
terms of light by means of, again, the fluorescence sort of signal.
That way the light is not obstructed to go through, right?
So this is another sort of imaging modality that we have used to apply our techniques on.
In addition, in the paper, actually, that was sort of just published, we also tried to
benchmark our methods, at least one of the methods we've used on some sort of MRI scans
from human patients or rather individuals, I'm sorry, that are found on the web in the
database.
But so, although we apply these techniques mainly in mouse tissue, we hope that this method
would also sort of start being applied in other types of tissues in this case or species
like humans.
And so the segmentation that you're trying to do with your method is, is it fair to say
it's what I would, what one might call like a macro level segmentation like these large
regions of the brain as opposed to clusters of cells within individual brain regions.
Yes.
So the initial part was to basically be able to, you're correct, yes, segment a few different
brain regions such as, for example, the cortex, this outer surface that we care about.
But the next level of analysis that we are actually aiming at and we have already implemented
parts of, have to do with being able to at least use these deep learning methods to
be able to detect all the cells.
So in a way, create a, you know, bounding boxes around them and actually classify them
and say with a specific sort of, you know, score that these are in fact neurons.
And you mentioned something about seeing or segmenting connections or like signals in
these images.
Did I interpret that correctly?
Are you able to through the imaging techniques, look at actual communication of neurons?
And so we have not actually been sort of dealing with connections per se in the sense that,
you know, these are usually smaller elements and quite complex in nature, depending on how
you look at them, that we haven't really kind of dive into it yet.
One of the things we have sort of done a little bit of is look at some really fine grain
structures which are found on cells, which are the sites where connections happen and
try to sort of, in fact, look at maybe how these change a little bit.
These are called spines for excitatory cells for these other population of neurons.
But in terms of actually looking at, you know, the elements of two, let's say, cells or
two neurons connecting, we haven't sort of been looking at that too much.
What we have done is utilize these methods in combination though with other genetic
and viral and anatomically basically methods that allow us to look at which cells connect
to which other cells in the brain, then performing a whole sort of brain mapping of those connections
by doing this clarity method that I mentioned before, and then actually analyzing the signal
using these deep learning methods.
So basically analyzing the regions, maybe types of cells, but also the numbers and density
of cells found in those regions using these deep learning algorithms.
Okay.
That may have been what I heard earlier that I was trying to tease apart.
When you say the cells that are connected to one another, is that basically another way
of saying cells that are in the same region, meaning the assumption is all of the cells
in the cortex are connected or all the cells in the hippocampus are connected, that kind
of thing.
Yeah.
It's actually sort of not the case in the sense that, you know, so the first assumptions
that let's say the neurons in specific are all connected or maybe this is kind of the
current view, which is, which is not the case.
There's a lot of specificity actually in those connections between a variety of different
types of cells.
So that's not what you're saying.
No, what I am actually saying is that through the use of a genetically tractable model,
which is the mouse in this case, we end utilizing some complex methods that we can, in fact,
go more into.
We are able to, let's say, have a type of cell that we care about understanding what
connects to it or revealing, and by tracing those connections in the cells that connect
to that cell, not only in that area, but actually across the brain, that allows us to get a full
sort of brain-wide view if you want of what kinds of areas and also what kinds of potentially
cells actually connect with, let's say, the cells of interest in another given area.
Does that make sense?
It does.
Let's definitely go a little bit deeper into that.
But before we do, you've mentioned a couple of times the genetically tractable mouse.
What's the significance of the genetic tractability to your research and what you're describing?
So, it's, for us, it's actually very important, and it opens up sort of the door to a number
of sort of approaches and questions that are not as easily addressable in different kinds
of species, which you cannot, sort of, let's say, genetically modify or manipulate.
So to give you an example, by modifying the genome of the mouse, you can label specific
populations and even types of cells, maybe in specific areas of the brain.
Of course, it's not always as clear-cut, and we can discuss why that is, but it allows
us to basically be able to label these cells, track them across different ages, for example,
and also manipulate them.
And by manipulation, I mean that you can, for example, remove gene of interest, such as,
let's say, a disease relevant gene that has been implicated in some sort of a neurodevelopmental
disorder, where we know that its expression or its sort of function is reduced.
You can basically remove that gene in specific populations and areas and time to understand
what it does and how it affects specific circuits.
So it is very powerful for us to be able to, sort of, really be able to track and also
manipulate specific populations and cells.
When you say label, you're talking about like inserting protein sequences that you can
easily identify.
Yes, you can.
Kind of thing, or something else.
Yes, you can do that.
You can basically, exactly insert, let's say, something which was not present and is
not present in the mouse, but which has been, in fact, shown after multiple sort of control
experiments that doesn't have any negative effect on the cell.
So this is, like, let's say, a small scissors, if you want, protein that acts as a scissors,
and then you can combine that with, sort of, let's say, a receptive end, right?
So you can, let's say, have the points where the scissors can work.
You can add them in specific sort of genes in the genome and hence sort of cut them out.
Or you can add something on top of it, again, external, which then you can cut out and
actually, you can cut out one part and let it then fluoresce and let it sort of die, you
know, die in a sense of, like, color the cells.
So it's actually sort of, there's so many now, very sort of interesting tools that have
been developed, which, by the way, there's also now, even cooler tools that have been developed,
which allows us to now utilize methods that, in species that were not as easily sort of
accessible before.
One of those is this CRISPR-Cas method that has been very popular in biology.
Okay, so with these tools in place, now can you talk a little bit more about this process
of kind of mapping the connections from one cell around the brain?
Yes.
So let me sort of take a step back.
So one of the things that, sort of, the way we've done it, I will try to explain the
way we've done it.
So we have, let's say, been utilizing some genetically modified animals or mice that,
as I said, express these scissors in specific cell populations that we care to study.
Specific, let's say, type, that a specific internal type or inhibitory type in the brain
and the cortex.
So by having these scissors cut out a stop signal, if you want, they allow something else
to come online.
And that something else that comes online, like a set of proteins, are, in fact, then expressed
or presented in the cell types that we care to study.
One of those things that is expressed is actually a receptor, so something which can go
to the membrane of the cell, the outer sort of part of the cell, and that has specific
things that it binds to.
So this is a protein that is not found in mice, so it's actually found in birds.
And hence, we know that then it should be specific for these cell types.
Now what we do is we, at the same time, utilize genetically modified viruses.
So in the neurosciences, viruses have been used quite some time now, in order to be able
to, for example, express certain things, let's say a colorful thing, that once you put
it in a specific area, then you can actually have these viruses be taken up by the cells,
and then you actually see the cells and all their processes labeled.
Therefore, you can follow them in different areas, in different brain regions.
Now this has actually been even more modified, and even more sort of tools have been created
to now be able to label specific populations of cells, such as the ones I was describing.
So by putting a modified rabies virus in this case, the rabies virus, we can discuss
what it is, but it's a different kind of, it's a specific type of virus, you're able to
infect the cells that you want, and because the virus now is red, right, because you
have expressed a dye in their colorful dye, it can actually label the cells that you care
to label, and it can also label the cells that connect to that cell.
And so I hope sort of I explained it simply enough, but not simplified, not I didn't simplify
sort of too much, or it wasn't sort of too complex, but basically by utilizing different
sets of tools, which have to do with the mouse lines and also the different viruses again,
we're able to, in fact, look at connections on specific cell pipes.
That is super fascinating.
And now I've kind of pushed you down into the biology here, which is very, very interesting.
With this particular problem of the connections, is this a place that you're applying deep learning
as well?
Yeah, so I'm really glad you said yes.
Yes, yes, what we have sort of been applying deep learning methods for in this case is
are to be able to again, to look at, for example, the distribution of the connections, right?
So let's say you want to assess a brain area A, and what connects to cell type A.
And so you utilize the methods I mentioned, and then you want to understand, because you
almost go with an unbiased approach, right?
So you say, okay, where do these cells receive information from, from which areas in which
cell time?
So in order to do that, again, in a brain wide manner, you need to put in place methods
that don't force you to actually do typical stereology, that you start counting and extrapolating,
or in fact, you know, make you count every single cell and try to eyeball the region that
the cells sit in.
So we try to utilize these deep learning methods to, first of all, identify brain regions
in a whole brain sort of imaging set, as I said, with clarity and light sheet microscopy.
And then once we have identified the region and segmented, let's say the region, then
we actually use a different algorithm to actually detect all the cells in that region.
And so can you talk about the specifics of the deep learning that you've used to accomplish
these tasks?
Yes.
So in this case, I would say that we're kind of like the end user here and on the application
side.
So the kinds of networks we're utilizing are actually being currently developed by, so
outside the lab, and they're being published by a number of labs.
And in this case, by, for example, Facebook or Google.
And we basically took inspiration from the excellent results that they have, in fact, seen
in life basically, you know, images of humans or cars or any sort of, basically, external
sort of scene that allows us to basically, again, segment and call an object, an object
of a specific type and also count cells.
So the two methods that we have utilized actually adapted, I would say, for our methods.
Our two networks, which are called FastRcNN and MaskRcNN.
And these sort of were developed by the MaskRcN, specifically, which we utilized in the
published work was basically developed by Facebook AI research.
Got it.
And did you evaluate a broad array of different methods or algorithms or start there and
it seemed to work well, so you moved on?
Yeah.
So our primary purpose, obviously, was not to kind of do like an end-to-end comparison with
all the methods that are out there, because we're also not primarily allowed that develops
these kinds of techniques or puts a significant effort in basically into this field.
So I would say that we basically looked out there to see what's available, what's the
most common sort of way that people do this kind of, in this case, image registration
to Nathlas.
And that we benchmarked our method against, which these are not deep learning algorithms.
But of course, there's other sort of other efforts that have been also done by other labs,
of course, that were sort of generating methods to do these kinds of things.
But I would say these efforts have focused on mainly human brain images.
What did you learn as you were applying these methods like mask our CNN to this problem?
Any particular interesting challenge or observations in terms of applying it to the types of images
and objects that you were looking for?
Yeah, I mean, one of the sort of things that we, I at least came to appreciate is actually,
of course, the power of these methods when you should have at least a large enough sort
of training data set to be able them to look at the, you know, testing data set and actually
perform the job.
But in terms of our sort of method, I would say or our sort of questions, I would say that
first of all, we didn't try to do this for all of the brain regions.
We actually chose a few brain regions to kind of showcase the ability of the method to perform
well and the usability of the method.
But I would say that, of course, structures change in the brain when you move to different
sort of, let's say, parts of the axis, right?
So you may have the same brain region, let's say the cortex or the hippocampus.
But as you go and take images of that region at different, basically, levels, right, closer,
let's say to the middle, midline or farther away from it, then the network is having a
challenge in basically being able to detect, of course, more complex types of imaging
brain regions, right?
And so I would say that the network has performed well enough for us to actually make use
of it.
But there's quite some way that we have to go in order to make sure that it's even
more accurate and that it's actually able to segmental of this harder type of regions,
which are maybe not as sort of easy and also expanded in other brain areas and even more
specific parts of a given brain area.
So I would say we're at the very beginning of this of these efforts.
And what were some of the alternative or traditional techniques that you were benchmarking these
methods against?
So two of the most commonly used methods are elastics and MD-rich.
So these are basically non-deep learning algorithms where they take minimum type of error
approaches and utilize linear or non-linear sort of warping of the atlases onto images
that you have collected.
So these are the two sort of most commonly used and we kind of try to utilize those ones
to just initially at least.
And then we try to take it one step further and utilize or compare against some other
methods, which were basically out there published on some human, in fact, tissue, again, was sort
of the web, wasn't generated by us.
So I would say that this is, you know, it is not, of course, clear whether at the moment
this is the best deep learning algorithm to be able to segment different brain regions
because, of course, this field is moving very fast and, you know, it is not unlikely
that other algorithms are in the making or, in fact, we're just, let's say, published
that could even sort of surpass this algorithm we've used.
Were there any particular challenges that you faced in the kind of the data management
and preparation side of this project?
Yes, I would say that, of course, with any of these methods, again, as a sort of novice
in the field, I've come to appreciate the amount of effort that needs to be put in terms
of generating the ground truth data set.
And so that has been sort of, of course, a bit of a bottleneck for us being able to
really kind of create this data that we use to train the network.
Yeah, I would say this has been sort of the biggest challenge for us if you want in
sort of doing this, because we were, in fact, lucky enough, or maybe sort of inspired
enough, I would say, to also have access or gain access to a big data set, which is
available to us and actually the whole neuroscience or brain science community, provided by the
Alan Institute based in Seattle.
So this has been an institute that has been generating a lot of data at different levels
of analysis, including a lot of sort of images of mouse brain for different types of proteins
and markers and so on, so forth, that mark different areas, different sort of cell types
and so on, so forth.
So this was also sort of a great resource for us to have.
And so we tried to utilize it, you know, abundantly in order to sort of get to our goal.
And so what's next for you and your lab in terms of applications of machine learning and
deep learning?
So what's next for the lab is actually one of the things that we would like to try to
do is to expand on on this approaches to both anatomical type of data, but also potentially
sort of some functional data, meaning some activity type of data that we collect and others
on live animals awake or freely behaving or basically that have undergone some sort
of like external stimulus presentation.
So I would say that for now we're aiming to expand some of these methods to potentially
include other areas, but even more so to include hopefully different sub regions within regions,
right, where we then need to create even sort of different types of ground truth, of course,
that will give us quite a bit more specificity in terms of understanding actually this at
the brain wide level or at least cortical wide level.
So I would say that that would be sort of one direction that we're going towards and
trying to also sort of utilize maybe these methods to look at connectivity that you
asked me before, a bit more directly if possible, as well as try to implement these methods
in functional data, as I said, that are collected by methods that look at activity of neurons
in vivo.
So in the live sort of animal.
Well Theo, thanks so much for taking the time to share a bit of what you're working
on.
It has been a pleasure.
Thank you.
Thank you very much for the opportunity.
Awesome, thank you.
All right, everyone, that's our show for today.
For more information on today's show, visit twomolai.com slash shows.
Make sure you head over to twomolcon.com to learn more about the Twomolcon AI Platforms
Conference.
As always, thanks so much for listening and catch you next time.
