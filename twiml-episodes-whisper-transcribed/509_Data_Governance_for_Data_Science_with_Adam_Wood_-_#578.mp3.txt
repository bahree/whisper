All right, everyone. Welcome to another episode of the Twemal AI podcast. I am your host,
Sam Charrington. Today, I'm joined by Adam Wood, Director of Data Governance and Data Quality
at MasterCard. Of course, before we get going, be sure to take a moment to hit that subscribe
button wherever you're listening to today's show. I had the pleasure of meeting Adam at a
recent event I hosted with Claudeira, a data leader's round table back in February.
And it is a pleasure to welcome him to the show to talk a little bit about data governance
for machine learning. Adam, welcome to the podcast. Thank you for having me, Sam. It's good to see you
again. It's great to see you and looking forward to digging into our chat. Of course, I love to have
you introduce yourself to our audience and share a bit about how you how you came to work in data.
Yeah, absolutely. So a lot of people don't know this by by education. I've got a doctorate
in biochemistry and through several twists and turns of career moved into IT at Monsanto and
didn't want to do anything else. So I've spent roughly 12 years, the last 12 years of my career
in the data governance and data strategy space and that has spanned Monsanto healthcare companies,
the financial industry and picked up a lot of knowledge. How data science has grown,
how governance has been applied within those different industries, how data is treated
within those different industries and the different sensitive information and regulations that
get applied across the board. So with my current job, I've tried to bring all of that industry
knowledge forward and see how it can help MasterCard progress in their initiatives.
Awesome, awesome. You know, let's maybe start by talking about the various use cases
for the data and data platforms that you're working with at MasterCard. Both machine learning
and beyond. How's data being used there? Yeah, so MasterCard obviously being a global company,
we bring in a lot of information and you can guess what that information is related to. We
process a lot of credit card information for banks in different merchants globally.
The governance needs there have really grown with the volume of data that we process.
And even, you know, the growth of data science as a function is driven more of the need
for governance across the board. So is data privacy regulations have grown?
As the volume of information has grown, the need for us to regulate and do more with it from
a governance standpoint has definitely grown as well. But downside is governance as a classical
initiative tended to get in the way. And so our data needs are for more open use of the information
and putting guardrails on the information rather than being this blocker to data access and use.
So the majority of what we work on right now are ways to automatically detect and catalog sensitive
information across the company and across the borders, the different countries that we do business
in and to make sure every single security and privacy regulation is being followed down to the
letter. And doing so, what we've been able to do is bring solutions forward that enable the
data science community to understand where information lives, what it means, how to access it and
how to do so responsibly using privacy, privacy management and consent management to make sure
anything that we're using the information for is always in line with regulations that we're
facing up to. Now, governance used to be very inflexible. The regulations are changing more and
more. New ones are being added to the table all the time and the data science world has become
incredibly flexible and needs to be moving fast. So everything that we do from a data science
standpoint at MasterCard and actually at several other companies has had two flex with cloud
adoption with machine learning and AI, the scale of data that's needed, the performance needs that
are available. And I would tell you the number one thing that we're focused on right now is heavy
reuse, helping people understand that there is information out there that other data science teams
have curated and put together. And the quality rules that have been applied don't have to be the
spoke. They can be shared across teams. So helping connect data science teams through our governance
platforms and helping them move faster through shared components and reuse has been one of the
largest undertakings that we brought forward. When we think about governance, well, you mentioned
one of the things that is often thought about is this barrier, maybe internal bureaucracy that you
have to overcome to use your data. But more broadly, I guess you can kind of think of it as they're
being like carrots and sticks in terms of why you might invest in data governance and build out
those kinds of processes. And before we started recording, you shared an example of a significant
stick that was passed down by a regulatory body. Can you talk a little bit about this example
that you shared and what it means for folks that are using data on a global scale?
Yeah, absolutely. So the stick that I was referring to has to do with GDPR and the newest
regulations around Shrems. So Amazon was slapped with an $898 million fine. And it was because they
were using data for some of their data science projects that users had consented to them collecting
but they had not consented to the way it was being used. And so privacy regulations have gone
well beyond. I need to know where my data is, how you're tracking it and making sure it's encrypted
and that you're being responsible as you store it. Now, it's if you're going to take my information,
you can only use it in the way that I stated you could. So consent management alongside
the information for people to consume has to be available. People have to have the understanding
that this information that we've collected in this particular place can only be used for these
purposes. And that's where a lot of governance tooling has moved to. So, you know, regulations
and the growth of data science have driven a lot of the governance discipline. You're right,
it used to be a massive blocker. It used to be very prohibitive. Now, it's become much more agile,
a lot more automated and light touch so that we are bringing as many tools forward as possible to
track metadata, policies, consent, and map that side by side with the information on what the
data is and where it's stored. So that is any data science consumer comes forward.
Once to use it, they know the guardrails that they have to to follow. Yeah, I was very surprised to
hear about this, this Amazon fine. For many years, we've kind of operated in this gray area where,
you know, there are all kinds of open questions with regard to, you know, what happens if you take
data and incorporate it into a model, you know, privacy, you know, it wasn't really, you know,
it was indeterminate, you know, there were legal and IP issues that were kind of indeterminate.
Sounds like, you know, some of these things are getting clearer and at least in the case that you
mentioned, the, you know, it's falling back on, you know, if explicit consent wasn't given for
that use, then it can't be used there. And I think, you know, I wonder how many organizations are
operating, you know, with that kind of constraint in place. You know, it has gotten clearer,
but it's also gotten more difficult to manage because the variety of data that people are bringing
in, it gets scattered very quickly. So making sure that you have governance processes highly
automated and scalable processes to make sure that consent and privacy standards are being
adhered to, making sure that data is encrypted at rest and the different types of things that
regulators are asking for. That's all built into these data cataloging tools, which have taken,
taken huge indicators from the data science community as a whole. So the management of privacy
and consent has been incredibly difficult to start because the, the traditional BI, if I go back
10 years, there was no such thing as serving up raw information to an end consumer, right? It
was all going through something that had already been curated, something that had already been
deemed safe. Exactly. It was only exposed through a handful of BI tools. Or there was an army of
data architects and engineers that handled a handful of databases. So they knew what all the
information represented and how to be careful with it. So now data science needs access to the raw.
They don't need the curated layer because they want to be able to build features off of the
raw information and they want to be exposed to all of the variables there to be able to create a
true model of the raw information that they'll encounter instead of trying to build an AI model
on top of a business intelligence layer. It's kind of a no-brainer. So but looking at rather than
going through these highly curated views where, where consent and policy assignment or
everything else would be so much easier, the difficulty has, has become going to all of the
underlying product databases and operational databases and figuring out how to merge consent
and privacy with the underlying data stores. And I'll keep this entire conversation. I'll keep
coming back to data catalogs that are really providing that opportunity. And even you'll see
some of the services being stood up in the public cloud providers right now that are helping
facilitate this. And Amazon just published, I want to say it was a month and half the two months
ago that they've released crawlers for their cloud environments to help identify sensitive
and personal information in all of their cloud environments that can also be fed into their data
catalog. So even the public cloud providers are starting to release these capabilities that
enable governance but do it in a very scalable and automated way. One of the other things that
came up that is just a level of complexity that never really occurred to me. This was something
we discussed that the data leaders roundtable was, you know, you have kind of introduced this
issue of governance and, you know, the requirement to track user consent. But then when you
talk about it at kind of a global scale, you know, that global scale implies not just, you know,
more, more records, more, you know, access. But also this requirement to federate in a sense
because it's not just one regulatory regime. You have all these different regulatory regimes.
You've got requirements that data, you know, stay local to a particular
locale. You know, of course, you can articulate this better than me. You kind of walk through some
of the complexity that you run into there. Yeah. So some of the newest standards that have come
out of, you know, India, China, Germany, South Africa. It's this concept of nationalism.
And each one of these countries brings forth a different set of rules to where
where data is created. And if it carries certain attributes, it can't leave that country.
And when you look at a lot of global companies, their information is processed centrally,
data warehouses are built centrally. And so a lot of AI models and a lot of machine learning
models are grabbing training sets centrally. But what happens now when you can't centralize
that information and everything has to be federated? I know this is certainly, certainly impacted
governance on the data science side as well. I think a lot of companies are struggling with how to
train locally and then build the model centrally. But I can tell you one of the things that's
that's another area of governance that's gaining a lot of momentum and has been for the last three
to four years is the concept of data lineage, which helps us understand where all of the same
data sets are occurring from even in a federated model and how they can be matched and merged and
flow together. This is incredibly beneficial too as we're exchanging information across
different boundaries between different countries to make sure that we stand compliance with
regulations. But at the same time, data scientists as long as I've known any mature data scientists
initiatives, they want to know where their information is sourced from, how it was constructed,
and now is there anything that's limiting its use regionally or consent or privacy related?
The nationalism is bringing in a new area of complexity where you can only use information
or a certain location in that location. So data lineage is really helping us uncover exactly
where that information is being sourced from so that data scientists can make sure that they're
only using it for a specific purpose in that region now. So it's given us a different layer of
granularity to try and protect people from using information in a way it wasn't intended or
moving outside of the boundaries of a country with it. Now I know a kind of fast moving data science
world in which you've got folks, you know, building all kinds of different pipelines and doing
different kinds of transformations, pulling this information into models, sometimes hierarchical,
you know, models, how are folks keeping track of lineage?
Yeah, so some of the newest initiatives that I've been part of, there's some brilliant people
in the data science community of MasterCard that really have a good handle on this.
But as we're building feature stores, we can build in as new feature sets are being created,
we can build in the metadata around how, what types of, how is each feature constructed,
what types of cleansing logic was used, and all of that information is going to be published
back to our data catalog so that the data science community not only understands that these
feature sets are out there and available for use, they understand how they were built.
And so at the intention here, you're right, data science is moving faster and faster.
One of the things that we want to do to enable people is make sure that they have a shared
set of components to use. Rather than 30 or 40 people going after the exact same data set and
taking the time to create their own feature set from it, now we can use data lineage.
We can use the metadata that's been gathered around other curated feature sets that have been
built. Combine that with the information from the feature store to help people locate that
information and move towards it and start using it very quickly. So the agility of data science,
they're going to keep coming up with new use cases, but as people build new feature sets,
we want to make sure that that's immediately understood and available for other people to consume.
As chances are, if there's some new wonderful initiative, a new data science program coming
forward, a lot of people are going to be going after the same data. And whoever reaches the end
goal first and build something that's really valuable, we want other people to start consuming that
right away. With regard to the feature store and metadata management in particular,
talk a little bit more about how you've attacked that problem, what you've built,
and kind of where that's going. So this all started off of the ability to just
curate data. Not even moving towards a feature site yet. It was just how do we build the data sets
from the raw information? How do we aggregate from multiple databases or denormalize something
from multiple data warehouse sources to build something that we could use to train a particular model?
So all of our metadata management, our data catalog was already consuming that information,
meaning we had tracked every single database and every table and every column and every shred of
business metadata that we could get for that information. So that as data scientists were starting
to build curated data sets, they understood what they were bringing in. And then as they built
their data sets, we've got some very, very incredible partners that are publishing back metadata
for what they've done to construct these sets. So we now know that in these tables,
this is information that was sourced from x, y, and z. We're intending to use it for
these additional problems. It's a training set for this set of models.
The discipline that I would love to see going forward is that within any sort of data science
platform, they make sure to relate back to how that particular feature set was constructed to
make sure all of these components are fully understood. We do see gaps here and there. So I look
at it as let's say I cooked a wonderful dinner and I didn't write down any of the recipe.
And now I've got to go do it again. I've got to start from scratch. We don't want people to have
to do that. So what we do with the feature store is very similar to that. So every set that's
being created, you know, it's how was this feature normalized, you know, how was it clandes,
how was any sort of back fills done to make sure that this was a complete feature set for someone
to be able to consume and use and for what purposes were people consuming it. So again, if I'm
working under a particular set of consent assumptions and I'm able to see other data sets or
feature sets that were built from that same set of assumptions and that same consent. I'm off to
the races. I don't have to spend any time trying to construct it myself. I may have some tweaks
that I want to make to it, but I've got a huge leg up. Historically, when we've talked about feature
stores, you know, one aspect of the feature store is kind of making the features available and
kind of ensuring consistency of features and things like that. And another aspect of it is more
kind of the store part of this, not as in storage, but as in a place that you, you know, a marketplace
almost or really focusing on feature reuse and enabling, yeah, teams of void kind of reinventing
the wheel. And there's been this historical kind of, you know, I guess it depends a lot on the
organization. Sometimes you find folks push back on that because they don't want to, you know,
create something that they need for their project and then have to, you know, own and support it,
you know, and have it be used in ways that it wasn't intended. You mentioned reuse earlier.
I'd love for you to share a bit about how you see reuse playing out in org as big as mastercard.
Yeah, so I can tell you some other companies in the way they've addressed it and some of the things
that we're thinking about as well. If you look at some of the companies that have really published a
lot of their governance process and their data catalogs, Lyft, Uber, Spotify, they have all gone and
built their own and they've built their own with data science in mind. So how do you get to reuse?
Whenever you search for particular information, it actually brings back sample queries that have
been run, the people that that have been most frequently accessing that information samples of the
data sets. So, you know, it drives reuse by helping you build a community of people that are
after the exact same information. The way we've approached it is we work with the data science
community who is the larger teams that are building these data sets, bring them into our data
catalog and then there's a way to certify them as top quality assets. And so we also add additional
metadata so that any data science coming in can look for these are the certified assets that are
available for the data science community, see them immediately and then be able to access them.
We do also take some approaches running analytics on our data science environments to look at
query behaviors. Very similar to what these other companies were doing, but looking at behaviors of
individual users within individual teams to see what data they're going after and can we connect
that to a data set that's already been curated and is available to use and then we can actually
drive those users towards those those curated feature sets. So right now we can't guarantee reuse,
but we can do we can strongly promote reusable feature sets that are out there and by including
the logic that was used to build them, we make sure that we can iterate on top of those and
continue to build new ones from a base component rather than trying to, like I said, reinvent the
wheel every single time. In the broader context of ensuring the responsible use of machine learning
and dealing with issues like bias, the ideas of like data cards and data sheets for data sets
have been proposed and are increasingly popular. Are you doing anything like that to kind of
profile the data and the the way it's been sourced and the various biases so that folks
that are trying to use it have more visibility into that? So I would say I'm not as familiar with
any bias that's gone into the data. We do source a lot of external information as many companies do.
We also have several third-party acquisitions that we've made. So whenever we don't have the
information or the capability internally, master card's been making a lot of acquisitions and the
open banking space and fraud detection and identity management. And so we do and every single one of
those instances when we start looking at the information that those companies bring forward, we're
always thinking about new analytics that can be built. And the first the first issue that's always
tackled is what is underrepresented? What do they have that's new to us? What do we have that's
probably new to them? And are there any gaps remaining? Is there anything if we're going to build a
comprehensive model over this information? What type of information do we need to make to or bring
in so that the end result is not skewed? Trying to eliminate as much bias as possible because a lot
of these smaller acquisitions, they cater to one class of user, one class of customer.
So when we're bringing in acquisitions, of course, there's going to be some level of bias,
but master card has the advantage of being a very large global company with an absolutely
massive customer base. And so those types of evaluations help us understand bias pretty quickly.
Now in terms of data profiling, this is also a space that we're spending considerable efforts
and considerable time in going into really understanding across the board, value distributions,
what is the use of the information? Is it reference data? Is it sensitive information?
And we're doing all of this to make sure that we manage encryption. We're making sure that we
manage lineage and flow of sensitive information appropriately. And it's also tied to consent
management. I would say that particular information though, we're still working on ways to really tie
it to the data science community and make it usable. I think the first foray into that is really
going to be around the consent and privacy management, but then figuring out ways to make that give
additional value to data science teams from our data profiling results is something we're exploring
right now. How does data quality plan into all of this? Yeah, so it's always been a really special
relationship between data quality and data science. Mostly because most of the data science teams
that I've worked with, the first words out of their mouth are don't touch the data. Don't try to
sanitize anything before it hits my hands because I want to have influence over the way that it's
cleansed. So some of the things that we really try to do, we know when there is something that's
that's very error prone. For instance, credit card numbers that come in with special characters
and letters in them. Okay, there might be something in that transaction that is valuable to a data
science team, but chances are it's going to have other errors in it and we don't want people to
start to use that type of information. So data quality is really used more from a product development
standpoint. Is it recommended that this data is fit for use or fit for purpose? But in terms of
data quality for data science, a lot of those measures are actually coming from the data science
teams themselves rather than these dedicated data quality organizations that exist and almost every
enterprise organization right now. So data quality for data science has really taken on a life of
its own. It's become a very interesting space in terms of cleansing and future creation.
And so the big level of encouragement that I give to these data science groups is great.
You know, the tools that we have for regular operational data quality, they track what we're
running. We know exactly what we're running it against. If you're building a brand new pipeline,
you have to do the same thing. And you also, my big recommendation is take the data quality
measures and and cleansing measures that you're building and make them some form of reusable component.
If you're going through the effort of doing it, almost like a feature store, there needs to be
some form of feature cleansing store. And that way when you're providing metadata around how you've
created everything, you can cleanly reference the processes that you used to get there or at least
some logic around what's been done from your personal data quality standpoint to let other people
understand how things were created. But data quality is an interesting space in data science.
It's taking shape a lot more than it was. You know, it was sort of go at it alone, cleanse the
information, however you see fit. And you know, the normal data quality measures that organizations
would run don't touch my data. Stay out of it. Let me do what I need to do. Those two are going
to have to meet in the middle somewhere. I think we're on the way to doing that. Just because the
the level of effort it takes to keep reinventing feature sets and features and everyone applying
the same logic over and over with no way to reference it centrally. I think that's about to
change very soon. When we spoke earlier, you also reference data domain discovery. How does that
play into all of this? Yeah. So data domain discovery is a term that's used specifically by
Informatica. Informatica is governance suite. But the domain discovery relates down to what is the
logic that I can run as part of data profiling that lets me understand the type of information that's
in each particular column or what each particular key in a document represents.
And so what companies are starting to do with that information is as you have a series of what are
just loosely called tags or data domains or some form of label for each document, each table,
each column, each key, you can build additional logic on top of that to figure out what governance
policies you have to assign. And so data domains are another one of these ways that can be fully
automated, that can be fully scalable and is one of the newer governance processes that's really
taken hold. There is no manual intervention in these processes. It's something to where you can
scale across as many databases, hybrid cloud environment on premise, fully cloud environment,
and come away with your data sets being labeled with what they contain. And that type of logic
can immediately help you understand if there are different types of security needs, if there are
different types of policy and privacy implications. So is the general idea here that
you know we've got some new database maybe it comes in for being an acquisition or a third party
source and it hasn't been previously curated and this these data discovery data domain discovery
tools can identify columns that represent PII like addresses or phone numbers names. Yeah that's
exactly the point. So the scale of information that every company is bringing in is absolutely
gotten massive logarithmic growth. And not only that data brokers have started to become I mean
those are in the news all the time people selling information whether whether that's appreciated
or not a lot of companies are using information that they didn't generate that someone else did
and now they have to take ownership of it. And so what data domain discovery or data tagging does
is it looks at that information and tries to determine for many patterns in it is it an email address
phone number IP address anything that could be used to reverse engineer your identity or the
identity of your financial information. So obviously fraud has become a very very big deal in
recent years the sophistication of identity theft and people that are stealing credit cards and
making transactions in your name matter of fact two years ago someone filed my my IRS tax return
in my name. So people are getting really creative and so making sure that we understand all
information that we're taking in and processing making sure that any sensitive information around
a customer or bank or any sort of financial transaction is well understood and protected.
This is where the entire governance industry is headed. So these are definitely initiatives
that we've taken on and it also helps us in terms of R&D or POC methods to know which
information needs to be anonymized encrypted we apply that same thing to our operations making
sure that we understand which information needs to be encrypted or even hashed make sure it's
secured at all times. And so this is this is akin to data profiling it's an additional step that
results in labeling of each individual element in a database but that makes sure in an automated
way across the board globally we have the right controls in place to understand what our data
represents and to make sure our customers stay safe. So we've talked a lot about the tooling
around data management data catalog even feature stores a lot of organizations are also investing
in building out platforms for the the data science parts of the workflow is that something that
master card is doing as well. Yeah absolutely so within within our data warehousing environments
we're big users of cladera we have roughly a 20 petabyte Hadoop environment right now very
large contains a ton of information and one of the native components there is the data science
workbench. And so along with that the majority of our data science workflows the data pulls a
lot of the aggregations a lot of the the testing file and training file storage is all happened
with happening within that singular platform. That's also where a lot of our governance activities
have focused to understand we're we're using cladera manager to be able to pull logs how people
are accessing the information how they're interrogating the information and being able to build
different types of analytics to help connect different members of our user community.
So it's it's been a decentralized platform for data science at master cards so far and we're
exploring other ones as well but but Hadoop and cladera have played a very large part for us and
even within the newest releases Apache Atlas as a data catalog component of the cladera platform
has come forward and we're looking forward to building out some additional integrations with
that to strengthen our global governance footprint. Got it and historically one of their pitches
for the data science workbench is kind of this integration between the governance capability
and their like historical data management tooling and the data science workflows and now
you know even emphasizing the ability to deploy on different clad environments which you
mentioned earlier. So even some of the newer things that we've done within data cataloging and
this is happening everywhere it's not a standalone platform. We're building a bunch of API
services that can be accessed and called directly from within data science workbench to be able to
both pull out metadata and push back metadata. So I was referencing you know how to share
how you've built different feature sets or different trainings sets. We want people to be able to
do that natively from within the platform that they're working in so they can search our catalog
natively from within data science workbench and then turn around and at the end of the day when
they when they've built their data set publish that metadata back in so that we'd get a record of
not only how it was built but also where it's stored now so that other people can have access to it.
So Adam a lot of what we've talked about thus far has been you know from your perspective as the
the governance and data management person informed by the work you've done with data scientists
is there a set of things that you wish data scientists knew about the space beyond what we've
talked about or things that you wish that they would do that would make them more effective in
thinking about working with governance. Absolutely so I mentioned I've been in this space for
10 to 12 years right nobody cared about governance when I started it was pure overhead nobody wanted
to do it but then data science became a discipline and it had to get more flexible and now what you'll
find is a lot of these governance platforms take their opportunities from data science.
I think we've all made peace with this is where innovation comes from this is where profitability
is going to come from for a lot of companies and our products have to be able to support that
governance used to get in the way it can't do that anymore when you're chopping at the revenue
stream of your company you've got to make changes so my my biggest advice to data scientists
first and foremost get acquainted with what the platform does get acquainted with how to
contribute information to and consume information from a data catalog because I guarantee your
company has one a lot of people just don't know of its existence in most cases. Beyond that figure
out how you become a contributor and I don't just mean a contributor to the data catalog or your
governance program what I mean is if you're building feature sets figure out what metadata you can
do to improve the work of everyone else around you if you're building data quality logic if you're
building cleansing logic if you're building up feature sets make sure that you're tracking how
that information was constructed and that you're putting it into a central repository so that people
can access it at a later date when you do that when it hits that central repository that's where data
tagging and data profiling is happening so you get the added benefit of letting us do the
automated processes to protect your information for you. We can now let you and everybody else know
if there's sensitive information in it is a data set that's open for use and can be used by anybody
internally. Now a lot of the processes that we run are enablers we try incredibly hard not to
get in the way anymore. What we want to do is make sure data science gets served the information
that they need to be more effective and like you were talking about earlier we are here to promote
reuse and direct people to the right information and how to use it responsibly and so the final
thing that I'll say is I want every data scientist to focus on reuse. Heavy reuse I mean feature
stores came about because the industry was saying we can't keep going at this alone.
Well the data catalog is helping you not have to but in order to do that you have to focus on the
ways that you're constructing data sets and the way that you're tracking that information. You can
contain some of that in your feature store. I'd ask from a governance standpoint that you've pushed
the rest of that metadata into the data catalog so that privacy compliance cyber security everyone
else has the privilege to see your work and make sure that is protected for you. We're not here to
cause roadblocks we're here to be an uplift and help you get to your angle faster but we want to
make sure that we have you set for success through making sure you're adhering to privacy consent
all these other risks that are out there so that you can move very quickly in a de-risked environment.
Awesome awesome well Adam thanks so much for joining us and sharing a bit about your experience
with data governance as great to chat once again. Yeah absolutely thank you so much Sam.
Thanks Adam.
