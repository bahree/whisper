1
00:00:00,000 --> 00:00:16,200
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,200 --> 00:00:21,320
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,320 --> 00:00:34,240
I'm your host Sam Charrington. In this episode of our Strada Data Conference series, we're

4
00:00:34,240 --> 00:00:40,960
joined by Essen Ashrough, data scientist at Pinterest. In our conversation, Essen and I discuss

5
00:00:40,960 --> 00:00:46,880
his presentation from the conference, diversification and recommender systems, using topical variety

6
00:00:46,880 --> 00:00:52,840
to increase user satisfaction. We cover the various experiments his team ran to explore

7
00:00:52,840 --> 00:00:58,480
the impact of diversification in user boards. The methodology is team used to incorporate

8
00:00:58,480 --> 00:01:03,520
variety into the Pinterest recommendation system, the metrics they monitored throughout the

9
00:01:03,520 --> 00:01:07,880
process, and how they performed sensitivity and sanity testing.

10
00:01:07,880 --> 00:01:13,320
Before we move on, I'd like to send a huge shout out to our friends at Capital One and

11
00:01:13,320 --> 00:01:18,800
Cloud era for their continued support of the podcast and their sponsorship of this series.

12
00:01:18,800 --> 00:01:23,720
At the NIPPS conference in Montreal in December, Capital One will be co-hosting a workshop

13
00:01:23,720 --> 00:01:29,040
focused on challenges and opportunities for AI and financial services, and the impact

14
00:01:29,040 --> 00:01:35,240
of fairness, explainability, accuracy and privacy. A call for papers is open now through

15
00:01:35,240 --> 00:01:43,000
October 25th. For more information or submissions, visit twimbleai.com slash C1 NIPPS. That's

16
00:01:43,000 --> 00:01:46,840
the letter C, the number one NIPS.

17
00:01:46,840 --> 00:01:51,920
Cloud era is a modern platform for machine learning and analytics optimized for the cloud

18
00:01:51,920 --> 00:01:59,600
that you build and deploy AI solutions at scale efficiently and securely anywhere you want.

19
00:01:59,600 --> 00:02:05,360
In addition, Cloud era Fast Forward Labs expert guidance helps you realize your AI future

20
00:02:05,360 --> 00:02:11,840
faster. To learn more, visit Cloud era's machine learning resource center at cladera.com

21
00:02:11,840 --> 00:02:17,880
slash ML. Now, if you're a fan of this show, you've got to love our sponsors because they

22
00:02:17,880 --> 00:02:22,640
help make it possible. So, please take a look at what they're up to and be sure to let

23
00:02:22,640 --> 00:02:29,520
them know that twimble sends you. And now, onto the show.

24
00:02:29,520 --> 00:02:36,640
I am here in New York City with SN Ashraf. SN is a data scientist with Pinterest. SN

25
00:02:36,640 --> 00:02:42,920
welcome to this week in machine learning and AI. Thanks, Sam. So, you gave a talk yesterday

26
00:02:42,920 --> 00:02:48,440
on the way you do recommendation systems at Pinterest. What was the specific title of

27
00:02:48,440 --> 00:02:53,840
the talk? So, the talk was called diversification and recommender systems and how we can use

28
00:02:53,840 --> 00:02:59,200
content diversity to try and increase user satisfaction. Awesome. Before we get into that,

29
00:02:59,200 --> 00:03:04,880
a little bit about your background, you have a PhD in physics. PhDs in physics are not

30
00:03:04,880 --> 00:03:11,360
unfamiliar to this podcast. There are a lot of physics PhDs in ML and AI. How did you get

31
00:03:11,360 --> 00:03:17,560
from physics to machine learning? Yeah. So, my background, as he said, is in physics.

32
00:03:17,560 --> 00:03:22,640
I used to study condensed matter physics and the physics of complex systems. So, complex

33
00:03:22,640 --> 00:03:28,880
systems are often systems that are kind of hard to define using simple equations and physicists,

34
00:03:28,880 --> 00:03:33,880
as you might know, I really love to put an equation to everything. We like to say, hey,

35
00:03:33,880 --> 00:03:41,080
this is how the world works. I can put that on a t-shirt. So, complex systems are often

36
00:03:41,080 --> 00:03:46,840
systems that have a lot of interacting, a lot of moving parts essentially. I've always

37
00:03:46,840 --> 00:03:53,160
been interested in those kinds of systems. A system like Pinterest is similar to that.

38
00:03:53,160 --> 00:03:59,620
Before that, I also studied a little bit in neural networks and worked in sort of soft

39
00:03:59,620 --> 00:04:04,600
matter physics, which is polymer physics, and anything, any other materials that don't

40
00:04:04,600 --> 00:04:09,200
behave as we might expect. And you also were an insight fellow. I know

41
00:04:09,200 --> 00:04:17,080
Ross and Emmanuel and some of the other folks that have gone through that program. How

42
00:04:17,080 --> 00:04:22,640
you made the transition into machine learning and AI? Yeah, absolutely. So, towards the end

43
00:04:22,640 --> 00:04:26,480
of my PhD, I started realizing that a lot of the work that I was doing was quite relevant

44
00:04:26,480 --> 00:04:32,800
to the stuff that people were doing out in the Bay Area. It was a great way for me to

45
00:04:32,800 --> 00:04:39,280
be able to transition into data science. Awesome. So, what's your focus at Pinterest?

46
00:04:39,280 --> 00:04:45,480
Yeah. So, at Pinterest, we have a sort of small data science team. I worked very closely

47
00:04:45,480 --> 00:04:52,560
with the ranking and blending team, and they essentially build what we call our main

48
00:04:52,560 --> 00:04:57,480
home feed. And so, when you land at Pinterest, you kind of see a set of bins, and that feed

49
00:04:57,480 --> 00:05:02,480
is what we call the home feed. So, what powers that feed is a set of interacting machine

50
00:05:02,480 --> 00:05:08,200
learning technologies. And one of our teams is responsible for kind of the ranking and

51
00:05:08,200 --> 00:05:12,880
the blending of a lot of that content, and I work really closely with those engineers.

52
00:05:12,880 --> 00:05:20,880
Okay. And so, the project that you described in your talk was on introducing diversification

53
00:05:20,880 --> 00:05:25,000
into that feed. What motivated you to start looking at that?

54
00:05:25,000 --> 00:05:32,360
Yeah. So, that's a great question. So, machine learning systems often are a burping system.

55
00:05:32,360 --> 00:05:38,280
Recommender systems try to say, I have this user and app, this item, and how likely is this

56
00:05:38,280 --> 00:05:45,960
user to engage with or to click on or to whatever your system might be with this specific

57
00:05:45,960 --> 00:05:50,200
item. And the interesting thing is that they don't often are at least naive or simple

58
00:05:50,200 --> 00:05:57,560
the recommender systems don't often think about looking at things as a set of bins.

59
00:05:57,560 --> 00:06:02,480
Most recommender systems try to think of stuff as a burping or a burping item basis.

60
00:06:02,480 --> 00:06:08,320
But we obviously as human beings can feel that if, so the example that I gave in my talk

61
00:06:08,320 --> 00:06:14,080
was that personally, I love using Pinterest for street art. And, you know, one of my favorite

62
00:06:14,080 --> 00:06:19,780
street artists is Banksy. And the recommender system can learn that I like Banksy, but what

63
00:06:19,780 --> 00:06:24,520
ends up happening is that rather than just giving me one Banksy pin, it ends up giving me

64
00:06:24,520 --> 00:06:30,800
a hundred of them. And so recommender systems say, hey, if I know what this person likes,

65
00:06:30,800 --> 00:06:35,760
I'm going to give you a thousand of these things. But obviously, we have the notion of

66
00:06:35,760 --> 00:06:40,000
diminishing returns, right? So, this is a pretty standard thing in economics where if

67
00:06:40,000 --> 00:06:44,160
you give me one of something, I might really like it, but by the hundred one, the additive

68
00:06:44,160 --> 00:06:49,680
value that you're giving me by showing me that piece of content is actually pretty low.

69
00:06:49,680 --> 00:06:54,680
And so that's kind of the primary motivation behind thinking about entropy or thinking

70
00:06:54,680 --> 00:07:00,640
about randomness and sort of diverse content diversification within recommender systems.

71
00:07:00,640 --> 00:07:06,300
And to maybe jump to the punchline a little bit and I'll elaborate on why, did you in

72
00:07:06,300 --> 00:07:11,640
fact find that diversification provided some additional lift or engagement?

73
00:07:11,640 --> 00:07:18,040
Yeah, absolutely. So, that's actually, I like to do that as well where I try to give

74
00:07:18,040 --> 00:07:24,360
away the punchline. And so, yeah, the punchline is the diversity makes users happy, right?

75
00:07:24,360 --> 00:07:31,400
And the reason why is that Pinterest specifically is a visual search engine, right? People come

76
00:07:31,400 --> 00:07:35,600
into Pinterest to discover and do what the things that they love. And so they want to be

77
00:07:35,600 --> 00:07:40,800
able to, they want to be introduced to a bunch of content that they can explore and browse

78
00:07:40,800 --> 00:07:45,960
and then kind of dive deep into the things that they really enjoy. And sometimes the things

79
00:07:45,960 --> 00:07:49,920
that you really find, I mean, if you think about the last time someone recommended a good

80
00:07:49,920 --> 00:07:56,440
book to you or a good art show to you, it often happens by chance. And the word for

81
00:07:56,440 --> 00:08:01,160
it is serendipity, right? And so what we want to do is we want to create serendipitous

82
00:08:01,160 --> 00:08:06,720
experiences on Pinterest where people come on and they're able to define those things.

83
00:08:06,720 --> 00:08:10,040
And when there's more diversity, that is more likely to happen.

84
00:08:10,040 --> 00:08:18,120
So what prompted the question was, in fact, another interview that I had with the speaker

85
00:08:18,120 --> 00:08:25,520
at Stratta from Reuters who looked at essentially recommendations, they were trying to determine

86
00:08:25,520 --> 00:08:33,560
the best articles to surface to a user in their infinite scroll redesign. So you go to

87
00:08:33,560 --> 00:08:39,640
an article and when you're finished with that article, you see the next article automatically.

88
00:08:39,640 --> 00:08:45,640
And they looked at a couple of different experiments. One was surfacing similar articles, another

89
00:08:45,640 --> 00:08:51,920
was surfacing dissimilar articles. And the third was surfacing articles, just top world

90
00:08:51,920 --> 00:08:58,840
news articles. And they found that, in fact, in their case, similar articles had the greatest

91
00:08:58,840 --> 00:09:05,880
performance as opposed to dissimilar, which is kind of analogous to the diversification

92
00:09:05,880 --> 00:09:10,240
that you're describing. But I think I guess all this speaks to the fact that it's really

93
00:09:10,240 --> 00:09:13,480
about your users and the way they want to use your site.

94
00:09:13,480 --> 00:09:17,240
Yeah, absolutely. I mean, that's a really interesting point. So the interesting thing about

95
00:09:17,240 --> 00:09:23,480
Reuters, are any news, or most news agencies, I should say, is that they're not personalized

96
00:09:23,480 --> 00:09:27,000
usually, right? Like Reuters is just trying to, and they are not exactly.

97
00:09:27,000 --> 00:09:31,640
So they're trying to give you content. Most of the content that they serve the users will

98
00:09:31,640 --> 00:09:37,680
probably be homogenous. However, for us, if you look at a specific user's home feed,

99
00:09:37,680 --> 00:09:44,840
it's entirely personalized to that specific user. From the language that that user speaks

100
00:09:44,840 --> 00:09:48,280
to the type of content that they've engaged with in the past, to the users that they follow

101
00:09:48,280 --> 00:09:54,840
to all these different things. And therefore, for us, diversification is actually a really

102
00:09:54,840 --> 00:10:02,160
important part of that. And I should also caveat that I don't think that the extreme end

103
00:10:02,160 --> 00:10:06,000
of this, like if you could take it to the, to the, you know, an infinitive, it would

104
00:10:06,000 --> 00:10:10,000
be that everything should be random. And that's not what I'm saying either, right? There's

105
00:10:10,000 --> 00:10:15,200
some sweet spots. So in machine learning, we use the term explore versus exploit. And

106
00:10:15,200 --> 00:10:20,160
the idea is that if you really personalize, if you really say, hey, this user really likes

107
00:10:20,160 --> 00:10:23,700
Banksy Street art, all I'm going to show this user is Banksy Street art, that's like

108
00:10:23,700 --> 00:10:29,480
extreme exploitation. And extreme exploration is randomness. And there's some sweet spot

109
00:10:29,480 --> 00:10:33,480
between those two, which allows for this kind of discovery experience that we want to

110
00:10:33,480 --> 00:10:39,040
try and give our users. And so how did you organize the presentation?

111
00:10:39,040 --> 00:10:45,800
Yeah. So basically, I start off by talking generally about the motivation. And then I

112
00:10:45,800 --> 00:10:52,040
sort of give a few examples of how do we actually measure this diversity. So one of the really

113
00:10:52,040 --> 00:10:58,600
important problems within, like in the past and literature as well as now is we can intuitively

114
00:10:58,600 --> 00:11:03,360
feel that, like I can tell you that this was a Banksy Street art pen. But how do you actually

115
00:11:03,360 --> 00:11:08,600
give that information to a machine learning algorithm as a number or as something that

116
00:11:08,600 --> 00:11:15,520
could be an input to your, to your system? And so I primarily focused like more than half

117
00:11:15,520 --> 00:11:19,320
my talk was trying to focus on how do we measure that? And what are the kinds of tests

118
00:11:19,320 --> 00:11:26,360
that we can do to be able to understand that this measure is actually working for us?

119
00:11:26,360 --> 00:11:32,920
And so these things are things like is my metrics stable, which means that how, as I

120
00:11:32,920 --> 00:11:39,000
give it more information, does it actually kind of converge to a specific value? And how

121
00:11:39,000 --> 00:11:42,920
quickly does it converge? Because that's an important thing as well. Like I don't, I want

122
00:11:42,920 --> 00:11:50,120
to be able to give it, you know, 10 pins or a few pins, pins here are just our basic

123
00:11:50,120 --> 00:11:56,720
unit of content on Pinterest. And it should be able to give me a pretty good value. So

124
00:11:56,720 --> 00:12:01,320
that's stability. The second thing is giving it 10 pins and it's giving you a pretty good

125
00:12:01,320 --> 00:12:09,320
value of what? Of diversity. Okay. Yeah. So you can imagine that with one image, so let's

126
00:12:09,320 --> 00:12:15,240
imagine we have a thousand pins, right? There's some value of diversity that I can give

127
00:12:15,240 --> 00:12:20,840
that set of pins. And so you can, for example, if all those thousand pins were related to

128
00:12:20,840 --> 00:12:25,240
street art, the diversity of that would be pretty low because they're all street art.

129
00:12:25,240 --> 00:12:29,320
If they were entirely random, the diversity should be pretty high. So the number that I

130
00:12:29,320 --> 00:12:34,760
give it should be pretty high. Now, if I sub sample, let's say one pin from that thousand

131
00:12:34,760 --> 00:12:41,240
set of pins, maybe it's randomly happens to be not a street art pin, right? And then now

132
00:12:41,240 --> 00:12:47,400
I take two samples and now I can maybe get a better value of diversity. Now I take three

133
00:12:47,400 --> 00:12:52,680
and so on and so forth. And so how many pins do I need in order to be able to get to that number

134
00:12:52,680 --> 00:12:59,000
pretty quickly? This is what I mean, my stability. Okay. And then the second important aspect of it

135
00:12:59,000 --> 00:13:05,960
is sensitivity, which means that does it behave the way we wanted to behave? So the example here

136
00:13:05,960 --> 00:13:10,920
would be again, like let's say I have a set of pins and a hundred percent of them are

137
00:13:10,920 --> 00:13:17,560
taxi street art, right? And so the diversity value here should be pretty low. Now let's say we

138
00:13:17,560 --> 00:13:22,920
start introducing a completely orthogonal topic into this set of pins. So imagine something like

139
00:13:23,640 --> 00:13:28,920
scooters or cars or whatever. Something that we think is like different. And then

140
00:13:28,920 --> 00:13:33,240
we introduce some of these pins into this system. And we should see this diversity value kind of

141
00:13:33,240 --> 00:13:39,960
go up. When we're at 50, 50 where we have 50 percent like scooters, 50 percent street art,

142
00:13:39,960 --> 00:13:44,440
then this diversity value should be at its max. And then as you keep introducing more and more

143
00:13:44,440 --> 00:13:48,760
scooters into it until we have a hundred percent scooters, then this diversity value should come

144
00:13:48,760 --> 00:13:54,120
down again. And so if this measure doesn't move very much or it doesn't move the way we actually

145
00:13:54,120 --> 00:14:00,520
be expected to behave, then it's not working. And so this kind of a study of trying to understand

146
00:14:00,520 --> 00:14:06,440
if the measure is working is a sensitivity analysis. And so I talk a little bit about this.

147
00:14:06,440 --> 00:14:13,560
One quick question on that. So you said that when you have this 50, 50 distribution of

148
00:14:14,520 --> 00:14:21,800
pin topics, assuming we know how to find those, that this diversity measure should be at its max,

149
00:14:21,800 --> 00:14:27,720
that's like one, that's a design decision, right? You could also argue that the diversity

150
00:14:27,720 --> 00:14:32,760
metric should be at its max when every pin is of a different topic. Yeah, absolutely. Yeah,

151
00:14:32,760 --> 00:14:40,200
so what I mean by saying max is max in this spectrum of mixing these two topics. So you're

152
00:14:40,200 --> 00:14:45,160
absolutely right that if I introduced a third topic into this, now that value should be even higher

153
00:14:45,160 --> 00:14:50,360
than if I only have two topics. So that's actually another analysis that I didn't talk about in my

154
00:14:50,360 --> 00:14:56,600
talk, but we did do, which is that let's say I have 50, 50, two topics, and now we have 30, 30,

155
00:14:56,600 --> 00:15:03,000
33 topics. And then let's say we keep going with like 25, 25, 25, like four topics and so on.

156
00:15:03,000 --> 00:15:08,360
We actually keep seeing that this value increases until some max point where it flatens out.

157
00:15:08,360 --> 00:15:13,320
And so that's also another aspect of sensitivity, which we also checked.

158
00:15:13,320 --> 00:15:16,120
Okay. Yeah, but that's a great, that's a great question.

159
00:15:16,120 --> 00:15:22,200
Okay. And so that's a word. Yeah. And so the last thing is basically, in physics, we just call

160
00:15:22,200 --> 00:15:27,000
the sanity checking, right? So we want to make sure that this metric is sensible for the system

161
00:15:27,000 --> 00:15:32,920
that we have now constructed. So in Pinterest, we have something called boards. Boards are collections

162
00:15:32,920 --> 00:15:39,640
of bins or collections of these units of images that people that our users have kind of put together.

163
00:15:40,600 --> 00:15:45,960
And these are thematically often quite similar. So users create boards, for example, for

164
00:15:45,960 --> 00:15:51,240
you know, flowers for their wedding. And so all of the, depends on that, on that board,

165
00:15:51,240 --> 00:15:55,960
will be like purple flowers or something of that sort. People will create a board for scooters.

166
00:15:55,960 --> 00:16:00,040
People, I have a board, for example, for street art, you know, and so on and so forth.

167
00:16:00,040 --> 00:16:05,160
And we, we generally know that these boards should be thematically quite consistent and quite

168
00:16:05,160 --> 00:16:12,920
similar. So one of the things that I did was I sampled lots of users boards and tried to give

169
00:16:12,920 --> 00:16:20,040
those set of bins a value for diversity. And that creates a distribution. And this distribution now

170
00:16:21,000 --> 00:16:28,520
should be lower than the lower in diversity from the distribution, if I just randomly sample bins

171
00:16:28,520 --> 00:16:34,680
from our corpus, from our system. And so we basically created multiple distributions like this,

172
00:16:34,680 --> 00:16:39,640
just to make sure that the distribution for boards is actually like the mean and everything is

173
00:16:39,640 --> 00:16:45,320
much lower than the distribution for random bins. And then the distribution for sessions,

174
00:16:45,320 --> 00:16:50,280
or when users come on, what does this see on Pinterest? It's actually kind of overlapping

175
00:16:50,280 --> 00:16:55,000
between those two things, because sometimes users come on to see pretty random content,

176
00:16:55,000 --> 00:16:59,640
but sometimes users may come on just to see something very specific. And so we see that the sessions,

177
00:17:00,280 --> 00:17:05,400
not only is the, the mean kind of that distribution making sense, but the standard deviations a

178
00:17:05,400 --> 00:17:10,040
lot bigger too. And so we know that it's more spread out. And that generally kind of makes sense as

179
00:17:10,040 --> 00:17:17,000
well. And so given those three checks of stability, sensitivity and sanity, we can then become

180
00:17:17,000 --> 00:17:23,560
quite confident that this measure is something that we can use. We're able to look for boards that

181
00:17:23,560 --> 00:17:30,920
were titled miscellaneous or random and compare them to compare them in diversity to other types of

182
00:17:30,920 --> 00:17:37,400
boards. Yeah, that's a good question. I tried doing some stuff where I looked at specific topics and

183
00:17:37,400 --> 00:17:46,200
saw that within, within boards, topics of, you know, one, boards of one topic can be different in

184
00:17:46,200 --> 00:17:52,680
diversity than boards of a different topic. Okay. I think the meaning consistently. Yeah, exactly.

185
00:17:52,680 --> 00:17:57,560
Or in general, like if you create those distributions, they often are non-overlapping,

186
00:17:57,560 --> 00:18:05,000
one being greater than the other. I can't remember right now what a specific example, but like one

187
00:18:05,000 --> 00:18:10,520
of the, one of the things I think was that crockpot recipes, which much lower in diversity,

188
00:18:10,520 --> 00:18:16,440
than a board title, it's like wedding or a board title, you know, something like that. And I guess

189
00:18:16,440 --> 00:18:20,920
the thing is that wedding is a much broader category like you could have, you know, anything from

190
00:18:20,920 --> 00:18:25,240
dresses to flowers to all sorts of stuff in wedding. Whereas if you're, if you have crockpot

191
00:18:25,240 --> 00:18:31,560
recipes, they're quite specific. I guess. So things like that we definitely saw.

192
00:18:31,560 --> 00:18:36,120
But that's a good point about boards type being titled random. And if they were, in fact,

193
00:18:36,120 --> 00:18:42,920
random or not. Yeah. Yeah. You may be coming to this, but I'm curious how you got at what the

194
00:18:42,920 --> 00:18:48,680
pin's content was. Did you, you know, we're looking at metadata? Are we doing deep learning on

195
00:18:48,680 --> 00:18:55,000
the images? Yeah. So that's a great question. So when we, when users put a pin onto our

196
00:18:55,000 --> 00:19:00,520
system, they generally put it on a specific board, which has a title and a description and stuff.

197
00:19:00,520 --> 00:19:05,720
And, and then the pin itself has a description to where users can write some stuff about,

198
00:19:05,720 --> 00:19:11,400
about the images that they've uploaded. And then often, pins actually have a web page is associated

199
00:19:11,400 --> 00:19:17,800
with the content, right? And so when you, when you try to, what, when we have all this information

200
00:19:17,800 --> 00:19:25,240
about the pin, we can actually associate certain words with these pins. And so the example that I

201
00:19:25,240 --> 00:19:31,000
gave was, if you have a street art pin, the words that are associated with this are things like art

202
00:19:31,000 --> 00:19:37,080
and graffiti or a bank see and so on and so forth. And we call these words associated with

203
00:19:37,080 --> 00:19:44,600
pins pin annotations. And so that's kind of step one, which is that try to get to the key topics

204
00:19:44,600 --> 00:19:50,280
of the pin. And we do this by, by, by this kind of tokenization off of these words that we can

205
00:19:50,280 --> 00:19:55,400
get from the descriptions, the board titles, the web age of sounds of worth. Once we have these

206
00:19:55,400 --> 00:20:01,320
annotations, we can actually use, so I walked in my, in my talk, I walk through several measures of

207
00:20:01,320 --> 00:20:06,760
diversity that they, that you can use. One of the problems with words, though, is that there's

208
00:20:06,760 --> 00:20:13,160
synonyms. And so when, when, when you say like art versus street art versus graffiti or something

209
00:20:13,160 --> 00:20:20,200
of that sort, these have overlapping meanings. And because of that, we actually couldn't get very

210
00:20:20,200 --> 00:20:27,000
stable measures of diversity using purely words, using purely annotations. So there's a lot of

211
00:20:28,520 --> 00:20:33,880
work on lexical diversity in linguistics literature. And then so you can use some of those

212
00:20:33,880 --> 00:20:38,680
standard techniques. We also tried using some techniques like entropy or the gene coefficient,

213
00:20:38,680 --> 00:20:44,920
which are from like physics or economics. And then, but at the core of it, the issue is that

214
00:20:44,920 --> 00:20:50,520
annotations or words can often have synonyms. And there's, there's the inherent instability in that.

215
00:20:50,520 --> 00:20:56,200
And so what we ended up doing was creating these embeddings using a matrix factorization. And so

216
00:20:56,200 --> 00:21:02,120
what embeddings try to do is that they try to map these words onto vectors, right? And not just

217
00:21:02,120 --> 00:21:06,840
any vectors, but something quite special vectors in the sense that you can add and subtract these

218
00:21:06,840 --> 00:21:11,560
vectors and they still have meaning. So the very standard example that people give is that if you

219
00:21:11,560 --> 00:21:18,040
have the vector for king, you can subtract man and add a woman and then get queen out of that.

220
00:21:18,040 --> 00:21:22,920
And the fact that that works actually still blows my mind because it's quite incredible that we

221
00:21:22,920 --> 00:21:29,240
can do that in such a such a such a way that that we can still interpret it makes a lot of sense.

222
00:21:30,200 --> 00:21:36,040
And so we actually do exactly that where we take these annotations and we know that annotations

223
00:21:36,040 --> 00:21:41,960
on a specific border related to each other. And so we use that matrix of annotations as columns

224
00:21:41,960 --> 00:21:48,680
and boards as rows and factorize that to be able to get annotation embeddings. And so once we

225
00:21:48,680 --> 00:21:54,520
have these annotation embeddings and we know that the the each pin has associated like let's say we

226
00:21:54,520 --> 00:22:00,440
take the top 10 annotations for each pin. Now, because of the fact that these these embeddings

227
00:22:00,440 --> 00:22:04,600
can be added and subtracted and stuff, we can actually just take the average of it and that

228
00:22:04,600 --> 00:22:10,280
average still has meaning. And that embedding we call the pin embedding. And so once we have that

229
00:22:10,280 --> 00:22:16,040
pin embedding, now we can actually do simple things like calculate the similarity or dissimilarity

230
00:22:16,040 --> 00:22:24,360
in this case of different pins and be able to give that kind of get that embedding diversity value

231
00:22:24,360 --> 00:22:29,000
out of that. Is there a single pin embedding at Pinterest or do you have multiple different types

232
00:22:29,000 --> 00:22:33,320
of pin embeddings that use like is that a pin annotation embedding and there are other types of

233
00:22:33,320 --> 00:22:37,400
pin embeddings? Yeah, that's a great question. I mean, we definitely have a lot of embeddings

234
00:22:37,400 --> 00:22:42,680
and we're trying to converge to a single unified embedding which encapsulates everything. And so a

235
00:22:42,680 --> 00:22:48,200
lot of the stuff that I've talked about so far has been about the words that are on the pin,

236
00:22:48,200 --> 00:22:52,840
but you can imagine that there's there's a visual embedding right embedding that's purely based on

237
00:22:53,720 --> 00:22:58,360
the image itself. And we definitely have a team that entirely focuses in trying to create a

238
00:22:58,360 --> 00:23:04,040
visual embedding. And we actually recently launched something which tries to combine the two

239
00:23:05,000 --> 00:23:09,720
and there's a block post about that that I can link at some point.

240
00:23:10,920 --> 00:23:21,400
So you talk for the properties of the metric and then you're using embeddings to develop the

241
00:23:21,400 --> 00:23:27,160
metric. What else did you talk about? Or what was next in your talk? I mean, so the final step

242
00:23:27,160 --> 00:23:34,680
obviously is that we have the problem, we've kind of motivated it. We have sort of the solution

243
00:23:34,680 --> 00:23:39,240
which is how do we measure the diversity? But then the final step is how do we actually implement

244
00:23:39,240 --> 00:23:46,040
this into our system? How do we use it? And actually before you jump into that, you mentioned

245
00:23:47,480 --> 00:23:55,000
a couple of alternatives, some lexical work from the linguistic space and entropy and things from

246
00:23:55,000 --> 00:23:59,400
physics. How far did you go down those paths? What did you kind of look down those paths and say,

247
00:23:59,400 --> 00:24:05,480
hey, we don't want to go down there? Well, we definitely, we went far enough where we were able to

248
00:24:05,480 --> 00:24:09,480
understand what the pros and cons of those approaches are and whether it works for us.

249
00:24:10,120 --> 00:24:14,280
And when we found that something doesn't work for us, we kind of moved on from there. And so

250
00:24:15,080 --> 00:24:19,320
the very first example, you know, there's something called the type token ratio, which just takes

251
00:24:19,320 --> 00:24:23,800
the unique number of annotations and divides the total. And so this is something that's like very

252
00:24:23,800 --> 00:24:29,560
easy to understand. And that's, I think, there are, that is the pro of some of these approaches,

253
00:24:29,560 --> 00:24:34,600
which is that, you know, interpredability is in a really important aspect in machine learning,

254
00:24:34,600 --> 00:24:40,680
which people sometimes ignore these days. But that does have its value and merits. And so,

255
00:24:41,240 --> 00:24:48,280
I think the point is being that like, you kind of have to try it out, see what the pros and cons

256
00:24:48,280 --> 00:24:53,400
are, see if it, you know, matches the three conditions that I mentioned of like stability, sensitivity,

257
00:24:53,400 --> 00:24:58,120
and sanity. And if it doesn't, then you kind of move on to the next approach and stop where you

258
00:24:58,120 --> 00:25:05,000
find something that works. So this type token, for example, pretty simple, but it really trips up

259
00:25:05,000 --> 00:25:12,520
with the synonyms. Exactly. Yeah. And so you can imagine that if I have some two pins that are

260
00:25:12,520 --> 00:25:18,120
there that are quite different, but then, you know, might have overlapping annotations, it'll, it just

261
00:25:18,120 --> 00:25:24,040
won't understand. Or if they're quite similar, like imagine slow cooker and crock bot, which are

262
00:25:24,040 --> 00:25:28,840
two separate words, but, you know, I have quite the same meaning. It'll actually think that

263
00:25:28,840 --> 00:25:32,840
they're very different. And so it just doesn't behave the way that we wanted to behave. Right.

264
00:25:32,840 --> 00:25:38,440
Right. So the implementation of the system, for where some of the big challenges there. Yeah.

265
00:25:38,440 --> 00:25:43,800
So before jumping into the implementation, I'll just quickly describe what our recommendations

266
00:25:43,800 --> 00:25:49,160
stack looks like. Okay. And so we start off with, you know, our pin corpus, which is sort of

267
00:25:49,160 --> 00:25:56,120
billions and billions of pins. We narrow that down to a state called Canada generation, where we

268
00:25:56,120 --> 00:26:01,560
have a bunch of different ways of generating candidates for, you know, recommendations. And so

269
00:26:01,560 --> 00:26:06,120
some of these involve purely content to content type recommendations, but some of them involve

270
00:26:06,120 --> 00:26:10,840
more like collaborative filtering type approaches, and so on and so forth. Like we have a lot of

271
00:26:10,840 --> 00:26:15,720
these different approaches. And at this stage, we kind of get about off the order of thousands of

272
00:26:15,720 --> 00:26:25,720
pins for users. The next step is pure ranking. Meaning for a given user's home feed, you'll get

273
00:26:25,720 --> 00:26:31,320
thousands of candidate pins. Exactly. Okay. So when a user comes onto Pinterest, we're doing all

274
00:26:31,320 --> 00:26:36,040
of this stuff in the background before they even land on the on the home feed. So the next

275
00:26:36,040 --> 00:26:41,240
step is ranking where we just blend all of the, or put all of these things together and try to say,

276
00:26:41,240 --> 00:26:46,520
well, how do they actually perform against each other? What is the probability that this user

277
00:26:46,520 --> 00:26:52,280
will in fact engage with this specific thing or not? And then the final step is actually blending.

278
00:26:52,280 --> 00:26:59,880
And at this stage, where we're taking content from the users followers, from the users, from the

279
00:26:59,880 --> 00:27:07,480
the user that the viewer follows, from the topics that they're interested in, and finally from their

280
00:27:07,480 --> 00:27:11,640
recommendations, which are these machine learning systems. And we're putting them all together

281
00:27:11,640 --> 00:27:19,800
into a single feed or creating a chunk as we call it. And so at this final step, you can imagine

282
00:27:19,800 --> 00:27:26,120
that there's a lot more control in trying to tune this explore exploit balance of, do we want to

283
00:27:26,120 --> 00:27:31,880
try and show users 100% things that we know that they will engage with? Or do we want to sneak in

284
00:27:31,880 --> 00:27:39,080
some more exploratory stuff? And so this is the stage at where we started adding this diversification.

285
00:27:39,720 --> 00:27:44,280
And the way that we essentially did it was that we would calculate this embedding

286
00:27:44,280 --> 00:27:49,880
dissimilarity metric for all the pins that we were about to show the user. And we said,

287
00:27:49,880 --> 00:27:55,400
is it too similar? Is it the first few pins that this user's going to see? Are they all very,

288
00:27:55,400 --> 00:28:01,080
very similar? And if they are, then we push some of the pins down and we actually introduce more

289
00:28:01,080 --> 00:28:06,840
sort of randomness and more entropy into the system. Do you consider this at all a personalization

290
00:28:06,840 --> 00:28:13,000
parameter? Like user A wants more diversification in their field than user B? Yeah, that's a great

291
00:28:13,000 --> 00:28:19,880
question. So we did, we are also trying other approaches of introducing diversity. And so one of

292
00:28:19,880 --> 00:28:27,160
the ways of doing that is actually adding it into our ranking function essentially. And these

293
00:28:27,160 --> 00:28:32,440
things are often called submodular functions. And so there is an approach of doing something like

294
00:28:32,440 --> 00:28:38,520
that as well. We specifically found that this approach of just kind of looking at the final product

295
00:28:38,520 --> 00:28:43,400
and then seeing if it's too similar and just, you know, penalizing at that step works slightly

296
00:28:43,400 --> 00:28:48,840
better than actually trying to do it the other way. That's not to say that it won't work for anyone

297
00:28:48,840 --> 00:28:54,200
else. I think it's just a matter of the system and how it behaves. But that's definitely one of

298
00:28:54,200 --> 00:29:02,120
the options as well. So the pin embeddings did that pre-exist this particular project? Was it

299
00:29:02,120 --> 00:29:07,080
already available for you? Did you have to create that as part of building out this system?

300
00:29:07,080 --> 00:29:12,280
So we actually had to create new pin embeddings for this. And the reason why often is again,

301
00:29:12,280 --> 00:29:18,760
the characteristics of the embeddings that you want can often differ from different use cases,

302
00:29:18,760 --> 00:29:24,440
from use case to use case. And so the given pin embedding, the embeddings that we already had

303
00:29:25,000 --> 00:29:30,520
just didn't behave the way that we wanted them to behave. And this is again the thing of

304
00:29:31,720 --> 00:29:40,040
any, for a lot of these systems, the technologies are often already out there. You kind of just have

305
00:29:40,040 --> 00:29:44,840
to pick and choose like what works for me and what is the problem that I'm really trying to solve.

306
00:29:44,840 --> 00:29:51,720
At the end of the day, you know, it is great to try and build at something new, but at the same time,

307
00:29:51,720 --> 00:29:56,840
if something already works, you just use that. And in this case, we just realized that, you know,

308
00:29:56,840 --> 00:30:01,400
we had to create something new to be able to solve this problem.

309
00:30:01,400 --> 00:30:09,560
So you haven't talked much about kind of the operating characteristics,

310
00:30:09,560 --> 00:30:14,120
scalability requirements. I mean, clearly, you talked about how many pins there are and

311
00:30:15,080 --> 00:30:21,640
the number of candidates did the solution that you, the direction you started going,

312
00:30:21,640 --> 00:30:28,760
did it just kind of work fine or did it have to be massaged in order to get it to perform

313
00:30:28,760 --> 00:30:35,560
it to meet the requirements of the site? Yeah, that's actually a great question. So when we think

314
00:30:35,560 --> 00:30:39,560
about the pros and cons between, let's say like the annotation diversity that I talked about in

315
00:30:39,560 --> 00:30:44,840
the embedding diversity, that was actually a big thing that we took into account when deciding

316
00:30:44,840 --> 00:30:50,200
on which approach to choose. And so the reason why, and so in this case, embedding diversity actually

317
00:30:50,200 --> 00:30:56,520
does, it is better in terms of scalability. And the reason why is because embeddings are numbers.

318
00:30:56,520 --> 00:31:01,080
And numbers are easier to, you know, store and add and subtract and do all these things to,

319
00:31:01,080 --> 00:31:05,480
instead of actual words, which are the annotations. So each pin has, you know,

320
00:31:05,480 --> 00:31:09,720
hundreds of annotations associated with it and we're trying to find what's the overlap between

321
00:31:09,720 --> 00:31:14,280
two things. You literally have to go through every single one and kind of, you know, see which

322
00:31:14,280 --> 00:31:18,120
one's overlap. And then that's actually a very expensive process if you want to do it at scale.

323
00:31:18,920 --> 00:31:24,120
And so for embeddings, which are just vectors, we can actually add and subtract them fairly easily.

324
00:31:24,120 --> 00:31:28,280
And there's libraries that do matrix factorization and stuff like that pretty, pretty fairly.

325
00:31:29,720 --> 00:31:35,640
Having said that, matrix factorization is actually something that's very hard to do at scale.

326
00:31:35,640 --> 00:31:42,040
And in that case, what comes into play is sampling, but sampling in the correct way,

327
00:31:42,760 --> 00:31:47,160
in the sense of like, sampling in a way that doesn't introduce biases into your system.

328
00:31:47,160 --> 00:31:51,880
And that in itself is a topic that's really hard to do. We ended up using reservoir sampling.

329
00:31:51,880 --> 00:31:58,120
But can you elaborate on this whole area? What are you using sampling in place of

330
00:31:58,760 --> 00:32:01,880
creating embeddings for every pin? Is that what you're suggesting?

331
00:32:01,880 --> 00:32:06,760
No, so what I'm, I guess, if you come back to the matrix that we're factorizing, we're essentially

332
00:32:06,760 --> 00:32:13,880
looking at annotations as the columns and the rows being boards here. And so the reason why we're

333
00:32:13,880 --> 00:32:19,560
using boards is because we think boards are more thematically similar. And if we do it on boards,

334
00:32:19,560 --> 00:32:24,360
we're able to actually get at the meaning of that annotation a little bit better,

335
00:32:24,360 --> 00:32:28,920
or the vector that we're going to associate with this annotation a little bit better.

336
00:32:28,920 --> 00:32:31,880
And so the sampling that I'm talking about is actually at that board level,

337
00:32:32,680 --> 00:32:37,320
which is that how many boards do we sample? What are the topics that we sample these boards from?

338
00:32:37,320 --> 00:32:41,560
And you can imagine that if I just do it randomly, I might create biases for

339
00:32:42,600 --> 00:32:46,280
things that people create, a lot of boards for versus things that people don't create,

340
00:32:46,280 --> 00:32:51,240
all right, and so we have to be quite smart about that when we're when we're trying to do this.

341
00:32:51,240 --> 00:32:54,600
Makes sense. And how did you approach that?

342
00:32:55,480 --> 00:33:01,240
Yeah, so I mean, obviously we started simple, we started with the, you know, trying to do it the

343
00:33:01,240 --> 00:33:08,120
very simple way where we just did a random sample, recognize what is a granularity at which we

344
00:33:08,120 --> 00:33:13,880
want to be able to find differences between these boards, and then try to skew it in the opposite

345
00:33:13,880 --> 00:33:20,040
way of that. So if we have a lot of boards from a specific piece of content, we try to sample less

346
00:33:20,040 --> 00:33:24,120
from there and then we over sample places where we don't have enough content.

347
00:33:24,120 --> 00:33:30,520
If you have a lot of boards from, meaning a lot of boards that a specific piece of content belongs to,

348
00:33:32,520 --> 00:33:39,320
a lot of boards that are thematically quite similar. And so the idea here is that let's say,

349
00:33:39,320 --> 00:33:46,200
we have a lot of users creating wedding boards. And so it could be that if I just sample randomly,

350
00:33:46,200 --> 00:33:53,320
I end up getting just a lot of wedding boards. But, you know, we also want to make sure that we have

351
00:33:53,320 --> 00:33:58,520
boards for scooters or boards for street art and all this other stuff. And then if there's not

352
00:33:58,520 --> 00:34:03,560
enough boards that are just being created for that type of content, we actually have to over sample

353
00:34:03,560 --> 00:34:09,480
there and under sample boards that are being created just, just in volume a lot more.

354
00:34:11,000 --> 00:34:16,760
Is there, would it be a reasonable approach to look at creating an embedding space for boards

355
00:34:16,760 --> 00:34:21,800
and then using that embedding space for boards to try to determine diverse boards and then using

356
00:34:21,800 --> 00:34:29,320
that to feed into your pin embedding? Yeah, I mean, so at Pinterest we are actually by lucky where

357
00:34:29,320 --> 00:34:35,960
we have this really nice graph of, you know, a user creating a board and that board having a bunch

358
00:34:35,960 --> 00:34:43,320
of pins on it and then often these pins overlap with other boards. The most smallest unit in this

359
00:34:43,320 --> 00:34:49,080
obviously is the pin. And so we can roll up to the boards if we want. But, but you're right in

360
00:34:49,080 --> 00:34:53,240
the sense that we could we could do it at the board level and then roll it up to the user or something

361
00:34:53,240 --> 00:34:58,920
of that sort. But given that we have the pin embeddings, we can actually just roll it up to the user,

362
00:34:58,920 --> 00:35:05,640
roll it up to the board and then be able to get that value for the board as well. And so it's often

363
00:35:05,640 --> 00:35:11,320
good to be able to start at the most basic unit and kind of roll it up if needed because then you

364
00:35:11,320 --> 00:35:17,720
have the granularity, right? Yeah, I guess that makes sense. And so implementation.

365
00:35:17,720 --> 00:35:25,400
Yeah, so as I said, at the blending level, we're able to kind of tune this Explorer exploit balance.

366
00:35:26,440 --> 00:35:33,960
And the idea here simply is that we take this out of pins and what's basically known as first

367
00:35:33,960 --> 00:35:40,040
page optimization. And so the idea is that one of the things that we'd found with these embeddings

368
00:35:40,040 --> 00:35:45,880
is that the top of user's feeds are often the least diverse in the sense that

369
00:35:45,880 --> 00:35:51,640
recommender systems often try to shove everything that they think that the user will really engage with

370
00:35:51,640 --> 00:35:55,800
right at the top of the feed, which kind of makes sense because again, recommender systems are

371
00:35:55,800 --> 00:36:00,920
trying to do this at a per item or a per pin basis. They're not really thinking too much about

372
00:36:00,920 --> 00:36:06,120
like what does the page look like? How does this pin look like in association with the pins that

373
00:36:06,120 --> 00:36:12,280
it's surrounded by? And so that's the reason why this is actually quite effective at that

374
00:36:12,280 --> 00:36:17,800
blender level because now we have a set of pins. Now we have this page that before we show the

375
00:36:17,800 --> 00:36:21,960
user, we can kind of take a look at and be like, hey, does this kind of look good together?

376
00:36:22,840 --> 00:36:29,640
And so the lower diversity of the top of the feed actually often makes users feel that,

377
00:36:29,640 --> 00:36:34,120
you know, this is all the stuff that I'm going to see. But if you actually scroll a little bit lower,

378
00:36:34,120 --> 00:36:38,200
there is a lot of content that's more diverse. We're just not showing it right at the top.

379
00:36:38,200 --> 00:36:42,760
And so if you actually push some of that content further up the feed, you know, you can kind of

380
00:36:42,760 --> 00:36:48,280
users are able to be exposed to more diversity right at the top, which kind of encourages them to

381
00:36:48,280 --> 00:36:57,000
explore more. And so when you talk about this, the focus being this first page diversity, does that

382
00:36:57,000 --> 00:37:03,160
mean that after the first page of recommendations, you're not going through this same process and

383
00:37:03,160 --> 00:37:09,800
assuming that the recommended is already going to produce a more diverse feed? So we do go through

384
00:37:09,800 --> 00:37:15,160
the process even after the first page, but it becomes more crucial right at the top right because

385
00:37:15,160 --> 00:37:22,440
that's where the issue that we found was. We also found that the issue was actually more severe in

386
00:37:22,440 --> 00:37:28,520
users that are the most active. So the more active that you are, the more we know about you and the

387
00:37:28,520 --> 00:37:33,880
more we're able to kind of overoptimized on the interests that we know you have as opposed to

388
00:37:33,880 --> 00:37:40,920
the interests that you may or may not have. Right. And so there's a bunch of things here that

389
00:37:41,480 --> 00:37:46,760
the quantitative measure of diversity allowed us to do. And so the first thing as I mentioned is

390
00:37:46,760 --> 00:37:51,560
the fact that we understood and recognized that the problem was more severe at the top of the

391
00:37:51,560 --> 00:37:58,040
feed versus lower down. The problem was more severe, for example, for users that was the most active.

392
00:37:58,040 --> 00:38:02,920
And then we can also do things like try to understand, well, is this problem more severe for

393
00:38:04,040 --> 00:38:11,800
users that speak a different language or users that there's a lot of other properties of this

394
00:38:11,800 --> 00:38:16,520
that we can now kind of understand a little bit more and tackle those problems head on as opposed

395
00:38:16,520 --> 00:38:22,120
to just kind of thinking about diversity as a more qualitative problem. We can try to focus on

396
00:38:22,120 --> 00:38:29,080
specific quantitative approaches of doing that. All of this is based on understanding what

397
00:38:29,080 --> 00:38:35,960
engagement means for these pins. And there are kind of the obvious things like

398
00:38:36,760 --> 00:38:46,520
likes, thumbs ups, those kinds of things, comments. But when thinking about the board and diversity

399
00:38:46,520 --> 00:38:52,360
on the board, you know, a lot of times it's just, you know, what you see when the board comes up

400
00:38:52,360 --> 00:38:57,480
and that having a qualitative, making a qualitative impression on the user.

401
00:38:57,480 --> 00:39:03,720
Did you do user studies or things like that outside of just kind of the pure click engagement metrics?

402
00:39:04,280 --> 00:39:11,240
Yeah, absolutely. So this issue actually was, so we have a entire team that's devoted to try

403
00:39:11,240 --> 00:39:15,240
and talk to users. There is do a lot of qualitative research to be able to understand what are the

404
00:39:15,240 --> 00:39:19,560
problems that users are facing. And then we obviously listened to a lot of the comments and stuff

405
00:39:19,560 --> 00:39:25,960
that users give us as well. And so this problem actually we studied quite in depth where we got a

406
00:39:25,960 --> 00:39:31,880
bunch of users to come in from varying backgrounds and we tried to understand what are the problems

407
00:39:31,880 --> 00:39:38,120
that you're facing? How, you know, and so that in my talk, I actually give a few quotes from some

408
00:39:38,120 --> 00:39:42,840
of our users that specifically talk about this problem where users say, oh, I see the same stuff

409
00:39:42,840 --> 00:39:49,320
all the time or I want to more diversity and I want to more type new type of new content or new

410
00:39:49,320 --> 00:39:54,600
topics and, you know, I want Pinterest to kind of broaden the types of things that it shows me and

411
00:39:54,600 --> 00:40:00,840
stuff like that. And so we kind of approach it from a bunch of different ways like we, you know,

412
00:40:00,840 --> 00:40:06,120
we have very like in-depth studies where we sit down and talk to users for an hour. We have,

413
00:40:06,120 --> 00:40:10,680
you know, a way for users to write to us and do all sorts of stuff like that. And then we have

414
00:40:10,680 --> 00:40:15,000
user surveys, which are sort of quick responses. And then finally, we have the experiments that we

415
00:40:15,000 --> 00:40:21,800
run where we try something out. And in this case, we tried this specific approach that I described

416
00:40:22,440 --> 00:40:28,680
at an actual experiment. And then we try to see, do one users come back more often? And two,

417
00:40:28,680 --> 00:40:34,440
when they do come back, do they spend more time? And do they actually like feel like they're engaging

418
00:40:34,440 --> 00:40:41,560
more? And so we saw a lot of these approaches kind of converging on the same thing, which kind

419
00:40:41,560 --> 00:40:50,760
of tells us that we're doing something right. So another way to come at that is that for this

420
00:40:50,760 --> 00:40:59,320
type of problem, you're optimizing more on site engagement and then cart, then pin engagement,

421
00:40:59,320 --> 00:41:05,800
per se. Is that fair? Yeah, I think that's fair. I think often those two things correlate

422
00:41:06,840 --> 00:41:12,120
where site engagement often correlates with how often people engage more with content.

423
00:41:12,840 --> 00:41:17,640
But, you know, users come on for a bunch of various reasons. And users have different ways

424
00:41:17,640 --> 00:41:22,440
of engaging. So some users may come in and, you know, check a lot or what we call repending,

425
00:41:22,440 --> 00:41:27,160
which is that they take pins that they see and put them on their own boards. But then some

426
00:41:27,160 --> 00:41:32,760
users just come on to explore, right? Like, users are coming on to like, you know, design things and

427
00:41:32,760 --> 00:41:37,160
actually take actions on those things. But they're also just coming to, you know, for entertainment.

428
00:41:37,160 --> 00:41:41,320
They just want to see a bunch of content. They want to try and explore new new ideas or explore

429
00:41:41,320 --> 00:41:47,640
new aspects of themselves. And we kind of want to we don't want to over optimize on one specific

430
00:41:47,640 --> 00:41:52,520
type of user base. We try want to try and do it more holistically. And site engagement is a good

431
00:41:52,520 --> 00:42:00,120
proxy for that. So you've inserted this into your pipeline. You've got it up and running on the

432
00:42:00,120 --> 00:42:07,400
site. You didn't done some experiments. You know, we know that you found that increased diversity

433
00:42:07,400 --> 00:42:15,880
worked. But, you know, how well, how exactly did you measure that? Yeah. So finally we did an

434
00:42:15,880 --> 00:42:20,440
experiment. We actually did a bunch of series of experiments. And the final one that we decided

435
00:42:20,440 --> 00:42:28,120
to launch was was one where, as I mentioned, a users are coming back more often to the site.

436
00:42:28,120 --> 00:42:33,640
And so that's one of that that basically tells us inherently that users did find value when the

437
00:42:33,640 --> 00:42:38,200
when they came once and therefore they've decided to come back. And that's a really important

438
00:42:38,200 --> 00:42:43,800
measure for us. And then the second thing is when they do come on, do do they engage more to

439
00:42:43,800 --> 00:42:50,360
the reap and more do they spend more time. And so we actually saw that we increased time spent

440
00:42:50,360 --> 00:42:55,240
by about 1%, which is quite huge. And then we were also able to increase the number of pin

441
00:42:55,240 --> 00:42:59,800
impressions that that users were seeing. So that just meant that every time they came in,

442
00:42:59,800 --> 00:43:04,920
they actually scrolled deeper and had longer and hopefully more meaningful sessions.

443
00:43:05,560 --> 00:43:09,960
And that was finally our sort of proxy for saying that this is this is something that's actually

444
00:43:09,960 --> 00:43:17,080
providing the idea to users. But to kind of start to wrap up any, what were the key takeaways

445
00:43:17,080 --> 00:43:25,640
that you left the audience with? Yeah. So sort of the main thing that I think that this shows is

446
00:43:25,640 --> 00:43:33,000
that measuring content diversity, a measuring diversity in any recommender system is incredibly

447
00:43:33,000 --> 00:43:39,720
important. And the reason why it's important is because it's not just a tack on that you can

448
00:43:39,720 --> 00:43:45,080
put right at the end of your system. It's actually something that's inherently fixing a pretty

449
00:43:45,080 --> 00:43:51,240
common flaw that recommender systems have, which is that recommendations are often per bin or per

450
00:43:51,240 --> 00:43:57,720
item. And they're not taking into account things like, you know, diminishing returns or how do people

451
00:43:57,720 --> 00:44:03,400
look at something when they see lots of stuff at the same page, which is how we as human beings

452
00:44:03,400 --> 00:44:07,400
actually interact with the content. We don't see things like, hey, look at this one thing and

453
00:44:07,400 --> 00:44:13,160
then looks at something and so on and so forth. We actually often see things in a holistic view.

454
00:44:13,160 --> 00:44:19,080
So it's incredibly important. It's non-trivial in the sense that it has, you can't just use the

455
00:44:19,080 --> 00:44:23,800
first thing that comes to mind. You often have to do a lot of analysis and a lot of like kind of

456
00:44:23,800 --> 00:44:29,560
deep studies in terms of stability, sensitivity, and things like that to be able to understand

457
00:44:29,560 --> 00:44:36,040
is this measure right for the system that I'm working with. And then finally, it's important,

458
00:44:36,040 --> 00:44:41,080
it's non-trivial. And then when it's actually done well, it can have a lot of real user impact.

459
00:44:41,080 --> 00:44:46,120
It can make your users much happier. And this is something that we finally showed through these

460
00:44:46,120 --> 00:44:52,280
experiments and this implementation that we had. But the final takeaway just is that measuring

461
00:44:52,280 --> 00:44:57,880
diversity in recommender systems is actually important, non-trivial, and can have real user impact.

462
00:44:58,520 --> 00:45:03,720
Awesome. Awesome. Well, as in, thank you so much for taking the time to share this with us.

463
00:45:03,720 --> 00:45:11,640
Yeah, thank you so much. All right, everyone, that's our show for today.

464
00:45:11,640 --> 00:45:15,880
For more information on Essen or any of the topics covered in this show,

465
00:45:15,880 --> 00:45:22,360
visit twimlai.com slash talk slash 187. For more information on the entire

466
00:45:22,360 --> 00:45:28,440
Stratidata podcast series, visit twimlai.com slash strata and y 2018.

467
00:45:28,440 --> 00:45:34,280
Thanks again to our sponsors Capital One and Cladera for their sponsorship of this series.

468
00:45:34,280 --> 00:46:04,120
As always, thanks so much for listening and catch you next time.

