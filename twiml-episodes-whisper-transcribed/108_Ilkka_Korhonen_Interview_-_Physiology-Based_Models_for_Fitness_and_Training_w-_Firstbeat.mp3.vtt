WEBVTT

00:00.000 --> 00:16.120
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:16.120 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:32.440
I'm your host Sam Charrington.

00:32.440 --> 00:33.840
Contest alert.

00:33.840 --> 00:38.960
This week we have a jam-packed intro, including a new contest we're launching.

00:38.960 --> 00:43.040
So please bear with me, you don't want to miss this one.

00:43.040 --> 00:46.720
First, a bit about this week's shows.

00:46.720 --> 00:51.440
As you may know, I spent a few days at CES earlier this month.

00:51.440 --> 00:56.400
While there, I spoke with a bunch of folks applying AI in the consumer electronics industry,

00:56.400 --> 01:01.040
and I'm including you in those conversations via this series of shows.

01:01.040 --> 01:05.440
Stay tuned as we explore some of the very cool ways that machine learning and AI are being

01:05.440 --> 01:08.600
used to enhance our everyday lives.

01:08.600 --> 01:13.680
This includes work being done at Anki, who built Cosmo, the cutest little computer vision-powered

01:13.680 --> 01:15.280
robot.

01:15.280 --> 01:22.120
Nighthouse, whose smart home security camera combines 3D sensing with deep learning and NLP.

01:22.120 --> 01:28.120
Intel, who's using the single-shot multi-box image detection algorithm to personalize video

01:28.120 --> 01:31.680
fees for the Ferrari Challenge North America.

01:31.680 --> 01:36.480
First beat, a company whose machine learning algorithms analyzed your heartbeat data to

01:36.480 --> 01:42.360
provide personalized insights into stress, exercise, and sleep patterns.

01:42.360 --> 01:48.400
3AI and Koito, who have partnered to bring machine learning-based adaptive driving beams

01:48.400 --> 01:52.280
or automatically adjusting high beams to the US.

01:52.280 --> 01:59.360
And last but not least, aerial.ai, who applies sophisticated analytics to Wi-Fi signals

01:59.360 --> 02:05.600
to enable some really interesting home automation and healthcare applications.

02:05.600 --> 02:11.000
Now, as if six amazing interviews wasn't enough, a few of these companies have been so

02:11.000 --> 02:15.520
kind as to provide us with products for you, the Twimmel community.

02:15.520 --> 02:19.360
And keeping with the theme of this series, our contest will be a little different this

02:19.360 --> 02:20.360
time.

02:20.360 --> 02:25.400
To enter, we want to hear from you about the role AI is playing in your home and personal

02:25.400 --> 02:28.640
life, and where you see it going.

02:28.640 --> 02:36.200
Just head on over to twimmelai.com slash myaicontest, fire up your webcam or smartphone camera,

02:36.200 --> 02:39.120
and tell us your story in two minutes or less.

02:39.120 --> 02:43.600
Go post the videos to YouTube, and the video with the most likes wins their choice of

02:43.600 --> 02:50.480
great prizes, including an Anki Cosmo, a lighthouse smart home camera, and more.

02:50.480 --> 02:55.040
Submissions will be taken until February 11th, and voting will remain open until February

02:55.040 --> 02:56.040
18th.

02:56.040 --> 03:02.360
Good luck.

03:02.360 --> 03:06.560
Before we dive into today's show, I'd like to thank our friends at Intel AI for their

03:06.560 --> 03:09.520
continued support of this podcast.

03:09.520 --> 03:14.760
Intel was extremely active at this year's CES, with a bunch of AI autonomous driving

03:14.760 --> 03:17.200
and VR related announcements.

03:17.200 --> 03:21.440
One of the more interesting partnerships they announced was a collaboration with the Ferrari

03:21.440 --> 03:24.720
Challenge North America race series.

03:24.720 --> 03:29.440
Along with the folks at Ferrari Challenge, Intel AI aspires to make the race viewing experience

03:29.440 --> 03:35.360
more personalized by using deep computer vision to detect and monitor individual race

03:35.360 --> 03:40.680
cars via camera feeds, and allow viewers to choose the specific cars feeds that they'd

03:40.680 --> 03:42.200
like to watch.

03:42.200 --> 03:46.960
Look for my conversation with Intel's Andy Keller and Emil Chindicki earlier in this series

03:46.960 --> 03:52.920
for an in-depth discussion about this project, and be sure to visit ai.intel.com where you'll

03:52.920 --> 03:56.200
find Andy's technical blog post on the topic.

03:56.200 --> 03:58.320
Now about today's show.

03:58.320 --> 04:02.640
In this episode, I'm joined by Oka Koronen, Vice President of Technology at First

04:02.640 --> 04:07.200
Speed, a company whose algorithms are embedded in fitness watches from companies like Garmin

04:07.200 --> 04:12.960
and Sunto, and which use your heartbeat data to offer personalized insights into stress,

04:12.960 --> 04:15.520
fitness, recovery, and sleep patterns.

04:15.520 --> 04:20.600
We cover a ton about first beat in the conversation, including how they transform the center readings

04:20.600 --> 04:26.360
into more actionable data, their use of a digital physiological model of the human body,

04:26.360 --> 04:31.480
how they use center data to identify and predict physiological changes within the body,

04:31.480 --> 04:35.440
and some of the opportunities that first beat has to further apply machine learning in

04:35.440 --> 04:36.680
the future.

04:36.680 --> 04:38.920
And now on to the show.

04:38.920 --> 04:46.120
Alright everyone, I am on the line with Oka Koronen, Oka is Vice President of Technology

04:46.120 --> 04:53.520
at First Beat, a company that I first met with at CES, in fact I met Oka at CES, and

04:53.520 --> 04:58.760
he was kind enough to agree to jump on the line for an interview.

04:58.760 --> 05:02.240
Oka, welcome to this week in machine learning in AI.

05:02.240 --> 05:04.120
Thank you very much.

05:04.120 --> 05:08.280
So why don't we get started by having you tell us a little bit about your background?

05:08.280 --> 05:14.080
Yeah, so my background is that I've been doing biomedical engineering for basically

05:14.080 --> 05:21.200
in time, my professional career I did on 90s, I was working on biomedical engineering

05:21.200 --> 05:27.480
and ambulatory heart rate variability monitoring, believe it or not, and activity tracking,

05:27.480 --> 05:31.040
but the technologies were quite different at that time.

05:31.040 --> 05:40.560
So gradually I moved in, I did research at that time, but then gradually moving towards

05:40.560 --> 05:49.040
wellness and preventative care, while finally later in 2009 I decided to take a career

05:49.040 --> 05:59.640
move and went to industry first for Nokia and later I spent some colleagues, a company

05:59.640 --> 06:05.280
called Pulse on which is an optical, one of the pioneers in optical heart rate tracking

06:05.280 --> 06:14.360
and later on about a year ago I quit that and now I'm with First Beat on doing the next

06:14.360 --> 06:21.400
level of the, in the stack, so to say the heart rate analysis rather than measurements.

06:21.400 --> 06:26.000
So that's in brief my background.

06:26.000 --> 06:30.840
And for those who aren't familiar with First Beat maybe a little bit more about what that

06:30.840 --> 06:38.080
company does, I happen to know a teeny bit about it because First Beat's embedded in the

06:38.080 --> 06:42.040
fitness watch that I use the Garmin Vivo Active 3.

06:42.040 --> 06:43.360
Yeah, that's correct.

06:43.360 --> 06:50.000
So our core business is that we are doing heart rate analytics, so we transform the heart

06:50.000 --> 06:54.640
rate reading into something actionable and meaningful for the user.

06:54.640 --> 07:01.600
We were established in 2002 as a spin of the University of Yvescola and we first looked

07:01.600 --> 07:12.640
at heart rate variability as a pramder or method for controlling the athletes overtraining

07:12.640 --> 07:18.760
but soon we realized that actually while we try to detect and prevent overtraining with

07:18.760 --> 07:24.800
heart rate variability based methods, those are also applicable for regular people who

07:24.800 --> 07:28.560
are struggling with stress and recovery.

07:28.560 --> 07:35.080
So that's where we started and gradually we have been moving into other domains from

07:35.080 --> 07:36.360
elite sports.

07:36.360 --> 07:46.960
We still do have this elite sport, so we are serving elite teams like NHL, NBA, etc kind

07:46.960 --> 07:54.080
of teams and their coaches for optimizing the training and recovery of the athletes.

07:54.080 --> 08:01.360
But more I think better known area where we are is that we do develop and license the

08:01.360 --> 08:05.360
heart rate analytics algorithms for wearables.

08:05.360 --> 08:13.160
So for example, Garmin, Huawei, Sunt and some other brands they are using our analytics

08:13.160 --> 08:19.720
to transform the sensor reading into more actionable information like fitness level,

08:19.720 --> 08:26.440
color consumption, stress and recovery metrics, etc.

08:26.440 --> 08:33.320
Now I've had a couple of conversations on the podcast about IoT and some of the challenges

08:33.320 --> 08:39.680
of analytics in an IoT environment and I guess when I think about this device on my

08:39.680 --> 08:44.920
wrist it's kind of like an IoT in the small and all of the challenges, well not all of

08:44.920 --> 08:52.640
them, but some of the challenges that are typical for IoT in particular, the noisiness

08:52.640 --> 08:56.360
of the sensor readings and things like that, I get the impression that there's a lot

08:56.360 --> 09:03.960
of that going on in the with regards to kind of the heart rate sensor in the wearables.

09:03.960 --> 09:07.720
That's very correct, so that's absolutely true.

09:07.720 --> 09:17.600
So the typical limitations or requirements of the IoT are that the sensor is very power

09:17.600 --> 09:25.480
limited or resource limited environment in that sense that you don't have the supercomputer

09:25.480 --> 09:32.240
power there, you have limited amount of battery you want to use as efficiently as possible

09:32.240 --> 09:39.120
to have the battery lifetime as long as possible, still you want to have a reach information

09:39.120 --> 09:40.440
from multiple of sensors.

09:40.440 --> 09:48.000
So for example, typical Garmin sports, what has a motion sensor and barometer in addition

09:48.000 --> 09:52.600
to heart rate, monitor and GPS and then of course all these radios.

09:52.600 --> 09:59.320
So it's quite interesting from 80s or 90s perspective, in fact it would be a supercomputer

09:59.320 --> 10:07.480
but it's not and things with what are being done there are quite fascinating.

10:07.480 --> 10:15.040
The other thing I think which is very different from for example, as I told I started with

10:15.040 --> 10:19.840
biomedical engineering on 90s when we were working with hospital systems and monitoring

10:19.840 --> 10:27.960
of who patient in a hospital, the monitoring was continuous and controlled in a way but

10:27.960 --> 10:35.960
here it's very liberal or there are a lot of decrease of freedom in the sensor use also

10:35.960 --> 10:45.240
that it's people are wearing the sensor not continuously but sometimes they are wearing

10:45.240 --> 10:50.720
sometimes they are not and also the way how they wear it how they attach the sensor to

10:50.720 --> 11:00.320
their wrist and how snug it fits to the wrist and so on they are not so well controlled

11:00.320 --> 11:07.240
and that causes a lot of variation in the single quality also ambient prongers like

11:07.240 --> 11:15.040
temperature ambient light and motion and so on they affect a lot the sensor reading.

11:15.040 --> 11:21.840
So it's quite challenging data what is measured by the sensors and there's quite sophisticated

11:21.840 --> 11:30.160
algorithms and detection technologies which are required to make sense out of that.

11:30.160 --> 11:39.720
And so for the devices that first beat is embedded in are you pulling data directly off

11:39.720 --> 11:45.520
of the sensors and kind of responsible for giving the watch kind of everything from the

11:45.520 --> 11:51.960
ground up the the heart rate itself plus the higher level metrics that you're providing

11:51.960 --> 11:59.000
or does the watch or the sensor provide some of those metrics in year doing higher level

11:59.000 --> 12:01.400
analytics on top of that.

12:01.400 --> 12:08.280
It's rather the latter so our interface to the sensor is typically the heart rate

12:08.280 --> 12:14.760
and there be to beat heart rate and also we use motion and GPS speed and things like

12:14.760 --> 12:22.760
that but we don't do the heart rate detection but we do the as I said we transform the

12:22.760 --> 12:28.760
heart rate and heart rate variability data into actionable information so it's a little

12:28.760 --> 12:38.800
bit higher level analytics based on the physiological model of how the human physiology works

12:38.800 --> 12:45.280
and how the autonomic nervous system controls the heart rate and heart rate variability

12:45.280 --> 12:55.240
and how this kind of data can be interpreted in terms of physiology and behavior.

12:55.240 --> 13:02.720
Okay so before we get into the company's approach to the analytics maybe take a moment

13:02.720 --> 13:11.080
to talk about heart rate variability and how that's calculated and why that number is

13:11.080 --> 13:12.760
important.

13:12.760 --> 13:19.280
Yeah so heart rate variability refers to beat to beat variation in the in the interval

13:19.280 --> 13:27.720
between the heart beats so each successive heart beat is having certain time instant

13:27.720 --> 13:34.200
in between them and this time difference between successive heart beats is varying as a

13:34.200 --> 13:42.000
function of time so and this variation is related to the functioning of the so-called

13:42.000 --> 13:50.840
autonomic nervous system which controls all our autonomic body functions like respiration,

13:50.840 --> 13:59.120
perspiration and blood pressure and heart rate among others so this autonomic nervous system

13:59.120 --> 14:05.640
is usually divided into two branches which are sympathetic and parasympathetic branch

14:05.640 --> 14:15.840
so this sympathetic branch is responsible for so-called fight-of-flight response so whenever

14:15.840 --> 14:23.840
our physiological resources are needed the sympathetic nervous system activates and prepares

14:23.840 --> 14:31.240
the body for the for the new requirements like increased energy expenditure or increased

14:31.240 --> 14:37.120
physical activity or increased mental activity and that is actually what happens when we

14:37.120 --> 14:45.800
have a body physical activity or when we have mental activity or in elevated stress for

14:45.800 --> 14:51.560
example it's the sympathetic nervous system which is activated which activates and that

14:51.560 --> 14:57.600
can be seen as an elevated heart rate and in broad terms reduced amount of heart rate

14:57.600 --> 15:04.960
variability the parasympathetic part is the other other nervous branch and that is responsible

15:04.960 --> 15:13.680
for cooling down the body after the requirements or immediate requirements of the situation are

15:13.680 --> 15:21.200
over so to basically recover the resources and reduce the heart rate, increase the heart rate

15:21.200 --> 15:31.040
variability rate and so on and I said this is in broad terms the functioning of these autonomic

15:31.040 --> 15:37.120
nervous system branches are seen in the heart rate and heart rate variability it sounds simple

15:37.120 --> 15:43.440
and the principle is quite simple but the challenge is that of course there's huge inter individual

15:43.440 --> 15:50.880
and also inter individual variants between in this especially heart rate variability they are affected

15:50.880 --> 16:00.960
by several factors like different substances and in addition to stress and physical or mental

16:00.960 --> 16:07.680
requirements also also our metabolism and and so on play a role there and people are different

16:07.680 --> 16:17.520
so their interpretation is quite challenging in fact this phenomena was identified years ago

16:17.520 --> 16:23.840
and there's been active research in the heart rate variability since early 70s but only

16:23.840 --> 16:31.920
quite recently during last last ten years so we have learned how to how to truly manage all

16:31.920 --> 16:39.040
these different factors which affect the phenomenon and how we can transform the information into

16:39.040 --> 16:46.400
something which is useful and in order to do that it requires an approach analytics that

16:47.200 --> 16:53.360
takes into account not just the you know not just kind of the raw data that you're pulling off

16:53.360 --> 17:02.400
of the sensors but also a model of how the body works is that right yeah that's right so for example

17:02.400 --> 17:08.560
our app wrote for the for the heart rate variability analytics is that we have constructed a digital

17:08.560 --> 17:18.800
physiological model of the human human body or body functions so we we have have figured out

17:18.800 --> 17:27.840
the physiological mechanisms for example how respiration physical activity heart rate mental activity

17:27.840 --> 17:34.480
how they affect each other how they are related and and and how heart rate variability reflects

17:34.480 --> 17:42.080
these activities and and based on this physiological model we can we can interpret the data

17:42.080 --> 17:49.360
we that's that's the that's the physiology part but then we use the data and data driven driven

17:49.360 --> 17:56.480
machine learning basically to tune the data in to be physiology or to be relevant for for its

17:56.480 --> 18:06.880
individual and and we have in fact a database of 250,000 individuals where where we have white

18:06.880 --> 18:16.480
reigns of people with different age both chambers different physical fitness and different BMI

18:16.480 --> 18:23.520
or weight and weight and and by using that data measured in in in daily during daily life in

18:23.520 --> 18:31.440
different conditions we can we can numerically adapt this model for it so that it fits for its

18:31.440 --> 18:44.320
individual and and produces kind of a personalized but yet standardized outputs can you talk a

18:44.320 --> 18:50.640
little bit about the physiological model to get us started what's the how is that expressed

18:50.640 --> 18:56.640
I'm imagining it's a mathematical model of some sort what's its kind of size shape level of

18:56.640 --> 19:04.720
complexity and is this something that ultimately lives in the device that that the and users

19:04.720 --> 19:13.200
wearing yeah if I start from from from the end of a question so yes yes it relies in it we have

19:13.200 --> 19:20.240
implemented this model into into software library and it indeed it is embedded into the

19:20.240 --> 19:32.160
these wearable devices these these two days super computers in a way and and and how it works is

19:32.160 --> 19:41.920
basically that that for each time instant we have a first first level is that we have a active

19:41.920 --> 19:49.680
segmentation of the data that that that we segment the data and and after that we classify

19:51.120 --> 19:56.880
calculate certain certain features of the data and and these physiological motivated features

19:56.880 --> 20:02.400
based on the physiological model like for example we transform the hard rate and hard rate

20:02.400 --> 20:11.840
rivalry data into into oxygen consumption or momentary oxygen consumption v02 or v02 and then we

20:11.840 --> 20:19.280
detect based on the hard rate rivalry we detect respiratory rate and and based on these these

20:19.920 --> 20:27.360
basically these two parameters described the level of of physical activity and and also

20:27.360 --> 20:34.960
respiratory rate is related to the also the physical activity and based on that we can classify

20:34.960 --> 20:43.840
whether a certain time instant is physical activity or or mental activity and after that we can also

20:43.840 --> 20:48.960
by looking at the hard rate variability and and whether they're very sympathetic or

20:48.960 --> 20:54.800
very sympathetic dominance we can classify its time instant whether that is more of physical

20:54.800 --> 21:03.440
mental stress or or physiological recovery and and accumulating from that we can calculate

21:03.440 --> 21:11.200
different kind of things like like a level of stress in during the day and amount of recovery

21:12.160 --> 21:21.120
from the from the v02 levels we also can calculate energy expenditure etc and when we combine

21:21.120 --> 21:28.880
issues like speed or or physical effort which is measured by the motion sensor we can also

21:28.880 --> 21:37.200
calculate what and and using the information like personal hard rate maximum and agent

21:37.200 --> 21:43.200
gender and so on we can we can calculate estimate the v02 max which is the fitness level of the

21:43.200 --> 21:49.440
individuals and things like that so it's it is there is actually we have certain white papers

21:49.440 --> 21:54.640
describing that but there is actually a multitude of different physiological mechanisms embedded

21:55.600 --> 22:01.280
I don't I think it doesn't make sense to go to details but just just to take as an example is

22:01.280 --> 22:06.560
that that we we have modeled that when you start a physical activity there is certain

22:07.280 --> 22:12.960
the hard rate increase is not immediate but gradual and it also depends on your previous

22:12.960 --> 22:20.880
physiological state for example in interval training we know that that the previous interval

22:20.880 --> 22:27.680
affects to the next one and we can have this kind of a on of kind of of mechanisms in the model

22:28.800 --> 22:35.520
and and those are taken into account so it's it's it's kind of a state state compartment model

22:35.520 --> 22:45.120
heavily heavily based on the physiology which is behind there and so you mentioned that there's

22:45.120 --> 22:51.840
a the physiological model and then more of a data driven model all of the metrics that you

22:52.560 --> 22:57.200
just mentioned are those all coming out of the physiological model before you even get to the

22:57.200 --> 23:06.080
data driven piece how it works it's basically that we have the principles are physiological but

23:06.080 --> 23:16.160
but the parameters or how it really works how you how the input data is processed and how the

23:16.160 --> 23:23.680
classification and and quantification of the different physiological parameters goes that's

23:23.680 --> 23:30.080
that's heavily data driven so we have used the big amount of data what we have to tune the

23:30.080 --> 23:38.080
parameters of the model and tune it also or to adapt it to its individual so that let's say that

23:38.080 --> 23:48.160
it data driven personalization of the model which is done there I don't know if you if that makes

23:48.160 --> 23:55.840
sense but well in in what way is it how personalized like is this

23:57.760 --> 24:05.680
machine learning type of a model that is running you know on the device itself or is it you know

24:05.680 --> 24:13.360
you're doing analytics using some type of machine learning that that spits out some number of

24:13.360 --> 24:19.040
different models and the you can choose between models on the watch how personalized are you

24:19.040 --> 24:27.600
able to to go with it we are using both approaches so when you take a new device into use you are

24:27.600 --> 24:34.560
asked to provide your background parameters like gender weight age hate and activity level and

24:34.560 --> 24:42.240
those are used to to put you broadly to the scale that what is typical for for an individual

24:42.240 --> 24:48.160
of your age and gender and fitness level but then when and that is kind of a

24:50.000 --> 24:56.480
machine learning or or database driven learning with what what we continuously update based on

24:56.480 --> 25:04.640
the data what we we accumulate from from our users but then then it's also adaptive model in the

25:04.640 --> 25:15.280
sense that that we use the we have algorithms which adapt the computation to your daily physiological

25:15.280 --> 25:24.000
or your normal physiological and and physical activity levels and and heart rate variability

25:24.000 --> 25:32.080
levels and so and so basically the devices get more accurate after couple of days of use when they

25:32.080 --> 25:38.160
have the algorithms have learned what is your typical level of heart rate variability and what is

25:38.160 --> 25:46.160
your your typical responses and your your real true heart rate minimums and maximums during

25:46.160 --> 25:53.920
different daily activities so so the model adapts to the user and that is why also these these

25:53.920 --> 26:00.800
devices are are typically designed for personal use if you would use for example share that

26:00.800 --> 26:06.960
these wearable devices with with some of your colleagues or your wife that would be suboptimal

26:06.960 --> 26:15.200
in the sense that that the the learning would not converge. The the learning that we're talking

26:15.200 --> 26:22.320
about here it's um I don't put sorry we asked this question we're not talking about like training

26:22.320 --> 26:27.600
in the sense of training a machine learning model that's certainly not happening on the on the

26:27.600 --> 26:36.720
wearable device it's more like tracking the the individuals data and adapting the model to the

26:36.720 --> 26:43.840
data over time. Yeah that is that's probably more accurate description of that yes so so they are

26:43.840 --> 26:52.800
there's in in the physiological model and which is being being broadly optimized for for your

26:52.800 --> 26:59.680
age and gender and weight and etc so so that is being more fine tuned to do their

27:00.480 --> 27:08.400
your exact characteristics based based on the adaptation there but it is correct it's more like

27:09.280 --> 27:15.920
adaptation. And you mentioned classifying a few times are you ending up having to do things like

27:15.920 --> 27:25.040
like uh like uh outlier detection and things like that where you're getting rid of noisy data

27:25.040 --> 27:32.320
from the sensor itself or does that happen at a lower level. We hope that most most of that happens

27:32.320 --> 27:39.040
in a lower level but in fact we we have a lot of that happening in the analytics layer as well

27:39.040 --> 27:47.280
so especially with optical sensors there is a lot of a lot of noise a lot of poor data and in fact

27:47.280 --> 27:56.160
we can we have we have built quite a lot of intelligence into into the separation or detection of

27:56.160 --> 28:05.280
poor and good appropriate quality data and what we actually do in the model is that when we detect

28:05.280 --> 28:14.720
that the input data is is not valid we we have a serum mechanisms to to bridge those gaps or

28:14.720 --> 28:24.880
or survive without without providing false outputs in in fact to an extent that for example our stress

28:24.880 --> 28:32.960
and recovery analysis is still still providing a quite valid outputs up to the error level of 50

28:32.960 --> 28:40.720
percent which is quite high so so as long as as more data which is coming in is is reflecting

28:40.720 --> 28:46.400
the real heart rate then we can we can provide reasonable analytics of course when when there is more

28:46.400 --> 28:54.160
false data than than real data then there's little one to do but right right right and so we've

28:54.160 --> 29:00.720
talked about primarily about the things that are happening on the device itself but you've also got

29:00.720 --> 29:12.240
this warehouse so to speak of data from individuals what are you you know in addition to kind of the

29:12.240 --> 29:18.240
work you're doing to develop the models for the device are there other things that the company is

29:18.240 --> 29:25.440
doing to you know with machine learning and analytics to take advantage of that data

29:25.440 --> 29:35.200
yeah so we have we have two other businesses and one is we provide corporate wellness service

29:35.200 --> 29:44.160
called a lifestyle assessment and there the idea is is that we basically sell for cooperates

29:44.160 --> 29:50.320
why interested to improve or promote their employer well being an assessment service where

29:50.320 --> 29:58.000
employers employees get a heart rate monitor special heart rate monitor for three days it's

29:58.000 --> 30:05.360
based on easy chisel it's very accurate to one millisecond time resolution and they do three

30:05.360 --> 30:13.040
day heart rate variability recording together with the diary and by using those those heart rate

30:13.040 --> 30:20.320
data and the diary data we construct a report and and give feedback to individuals about their

30:20.320 --> 30:28.000
physical activity sleep stress and recovery and fitness level and things like that and that

30:28.000 --> 30:34.560
those are also compared to the recommendations like physical activity recommendations sleep

30:34.560 --> 30:44.800
recommendations and what is normal at their age and gender and that is used very often in this

30:44.800 --> 30:52.640
kind of wellness campaigns where where people are are motivated to improve their lifestyles

30:53.440 --> 31:00.880
and improve their stress management skills so it can be used as an initial initial

31:00.880 --> 31:09.760
measure to to assess the starting point and identify the exact activities they should they

31:09.760 --> 31:16.720
should do to improve their lifestyles and and that is something as we sell as a service and that

31:16.720 --> 31:23.200
is actually a one source where we get a lot of data we we do we did last year about 50,000 such

31:23.200 --> 31:31.760
assessments of both in in Europe in Finland UK Germany Sweden now in Singapore as well not so

31:31.760 --> 31:38.240
much in US yet but that is actually a good source for data for us so because we we get this kind

31:38.240 --> 31:45.760
of a last year we got like 150,000 new datasets with with documentation and background information

31:45.760 --> 31:53.040
and diary and that is actually what we learn used for for the optimization and further further

31:53.040 --> 32:00.560
development of our our technologies which we use then for for consumer devices so yeah that is

32:00.560 --> 32:06.560
that is an interesting area but that that's not to say that that is just this this service is

32:06.560 --> 32:14.160
actually used and developed on its own it's not just for data collection but it's really just

32:14.160 --> 32:20.880
just to for corporate wellness business and and we we see that actually there are there's a lot

32:20.880 --> 32:29.840
of a lot of interest there about 95% of the people who who make the assessment are find it very

32:29.840 --> 32:36.640
very useful and and they recommend it for the others so so it's we looking at the at how to how

32:36.640 --> 32:44.320
to scale it up and how to bring make it more broadly available at the moment. How does the company

32:44.320 --> 32:54.080
organize to tackle analytics types of problems or challenges given the the strong domain expertise

32:54.080 --> 33:03.040
required but also the you know the analytical requirements to for machine learning and in

33:03.040 --> 33:11.680
traditional analytics. Yeah so we have a here in Finland we have a team of of data analytics

33:11.680 --> 33:18.640
analysis experts and and then we have a team of physiologists and in fact we have organized it

33:18.640 --> 33:26.560
so that these two teams are working as a single single bigger team so they work on a daily basis

33:26.560 --> 33:34.160
with each other so they are people who are who are from data science and and they are sports

33:34.160 --> 33:42.320
physiologists and and physiologists who are expert in the physiology and and and that's the big

33:42.320 --> 33:48.720
big thing what we are doing doing that that they are they are not they are basically never doing

33:48.720 --> 33:55.600
a single project that that only only one one size of that expertise would be present then of

33:55.600 --> 34:02.640
course we have engineers with software software background and I'm so on to transform all of that

34:02.640 --> 34:09.280
into into something which can be delivered to customers and or or implemented into our

34:09.280 --> 34:15.600
services but but the core thing there is that the maturity of that R&D or intellectual work is done

34:15.600 --> 34:28.160
by by the this data scientists or physiologists. I guess I'm curious about the opportunities that are

34:28.160 --> 34:38.560
created as you know we advance you continue to advance in our knowledge of applying machine

34:38.560 --> 34:43.520
learning and you know even some of the newer techniques like deep learning that you know might

34:43.520 --> 34:51.280
not necessarily be applicable to running on a watch but do you have any perspectives on what

34:51.280 --> 34:59.040
opportunities these technologies and the increased focus on these technologies creates for first

34:59.040 --> 35:10.000
beat. Yeah certainly I think we are we are just getting there that even though we have data from

35:10.000 --> 35:20.640
roughly to 250,000 individuals in our databases and so on it's still it's it's it's it's only today

35:20.640 --> 35:26.000
I think it starts to be in the scale where I would really truly call it as a big data. Also I

35:26.000 --> 35:34.240
do recognize that it's probably quite unique resource that very few few organizations would have

35:34.240 --> 35:40.240
or if if not if anybody would have have that amount of hard rate variability and background data

35:40.240 --> 35:46.320
available. So we are actually applying at the moment we're looking at things like how we could

35:46.320 --> 35:52.800
apply more more machine learning type of things and we have done some experimentation but

35:52.800 --> 35:58.640
but I have to say that to to date our perspective is very much that there are

35:58.640 --> 36:06.960
challenges with applying just pure machine learning without having having some kind of a domain

36:06.960 --> 36:15.680
knowledge to to constrain the this kind of a machine learning methods. There is a risk that you

36:15.680 --> 36:22.480
over over optimize to certain data sets and data on generalize and I think one of the one of the

36:22.480 --> 36:28.960
learnings what we have done and how why why our methods also work in the wearable environment and

36:28.960 --> 36:36.480
why they work in in almost all the individuals is that that they are based on this kind of a

36:36.480 --> 36:46.480
physiological principles and we use only only data to to kind of optimize those principles and

36:46.480 --> 36:53.520
make them numerically work and and in that sense we are not very heavily using using for our hard

36:53.520 --> 36:59.760
rate data we are not using this kind of pure machine learning like deep learning kind of methods.

36:59.760 --> 37:05.680
We have it and we are experimenting on that but I'm actually not the great believer that that

37:05.680 --> 37:12.560
would be the optimal way to go great great well okay this is a really fascinating conversation and I

37:12.560 --> 37:21.360
I appreciate the way that you're combining the physiological models with the the data driven

37:21.360 --> 37:28.400
models and I think clearly the domain knowledge is important here as is the case in in you know

37:28.400 --> 37:35.360
many if not all of the the use cases that folks are having success with so thanks for taking the

37:35.360 --> 37:44.320
time out thank you very much it was good for me as well all right everyone that's our show

37:44.320 --> 37:50.960
for today thanks so much for listening and for your continued feedback and support remember

37:50.960 --> 37:58.400
for your chance to win in our AI at home giveaway head on over to twimmolayi.com slash my AI

37:58.400 --> 38:04.720
contest for complete details for more information on ilka first beat or any of the topics covered

38:04.720 --> 38:12.160
in this episode head on over to twimmolayi.com slash talk slash 106 thanks once again to intel AI

38:12.160 --> 38:16.880
for their sponsorship of this series to learn more about their partnership with Ferrari North

38:16.880 --> 38:24.160
America Challenge and the other things they've been up to visit ai.intel.com of course we'd be

38:24.160 --> 38:29.840
delighted to hear from you either via a comment on the show notes page or via twitter directly to

38:29.840 --> 38:36.400
me at at sam sharrington or to the show at at twimmolayi. thanks once again for listening

38:36.400 --> 39:01.680
and catch you next time

