1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,920
I'm your host Sam Charrington.

4
00:00:31,920 --> 00:00:36,760
You are invited to join us for the very first Twimblecon conference which will focus on the

5
00:00:36,760 --> 00:00:41,200
tools, technologies and practices necessary to scale the delivery of machine learning

6
00:00:41,200 --> 00:00:43,720
and AI in the enterprise.

7
00:00:43,720 --> 00:00:48,600
The event will be held October 1st and 2nd in San Francisco and early bird registration

8
00:00:48,600 --> 00:00:58,720
is open today at twimblecon.com, again that's twimblecon.com, I can't wait to see you there.

9
00:00:58,720 --> 00:01:01,680
All right everyone, I am on the line with Lawrence Watson.

10
00:01:01,680 --> 00:01:04,960
Lawrence is a data scientist at Carbon Tracker.

11
00:01:04,960 --> 00:01:08,360
Lawrence, welcome to this week in machine learning and AI.

12
00:01:08,360 --> 00:01:10,640
Hi Sam, great to be on the show.

13
00:01:10,640 --> 00:01:13,520
It is great to have you on the show.

14
00:01:13,520 --> 00:01:19,640
Let's get started by exploring a bit of your background, you started out in physics,

15
00:01:19,640 --> 00:01:25,120
made your way over to climate change policy and now you're working in data science in

16
00:01:25,120 --> 00:01:26,280
that field.

17
00:01:26,280 --> 00:01:30,040
Tell us a little bit more about that path for you.

18
00:01:30,040 --> 00:01:34,640
Sure, so when I was small I always wanted to be a physicist.

19
00:01:34,640 --> 00:01:38,960
I just love to ask why and to get down to the root of the question and when you got

20
00:01:38,960 --> 00:01:43,560
to the fundamental laws of the universe, I thought there was far enough.

21
00:01:43,560 --> 00:01:47,920
When I finished my degree, I really wanted to have a positive impact or to address some

22
00:01:47,920 --> 00:01:51,520
of the issues that needed addressing in the world so I decided to try and work on clean

23
00:01:51,520 --> 00:01:53,400
energy and energy policy.

24
00:01:53,400 --> 00:01:58,480
I worked with a think tank that campaigned to reform the European carbon markets and that

25
00:01:58,480 --> 00:02:01,560
was when I got started into programming.

26
00:02:01,560 --> 00:02:06,040
They had a Python and Django stack in fact and I sort of took over looking after their

27
00:02:06,040 --> 00:02:11,040
database, scraping the European Commission's website where they released all of the data

28
00:02:11,040 --> 00:02:17,960
about who was buying and selling these emissions permits and then went from there really and

29
00:02:17,960 --> 00:02:22,480
I've been at carbon tracker almost two years trying to convince the financial markets

30
00:02:22,480 --> 00:02:24,160
about climate risk.

31
00:02:24,160 --> 00:02:27,760
When you say trying to convince the financial markets about climate risk, what is that

32
00:02:27,760 --> 00:02:28,760
intel?

33
00:02:28,760 --> 00:02:29,760
Sure.

34
00:02:29,760 --> 00:02:37,040
So we, carbon tracker popularized this idea of a carbon bubble that if the valuations

35
00:02:37,040 --> 00:02:41,160
of fossil fuel companies that are some extent based on the amount of fossil fuels they're

36
00:02:41,160 --> 00:02:46,000
going to sell in the future, if they're wrong in their predictions and those valuations

37
00:02:46,000 --> 00:02:52,160
are in fact going to be constrained by climate change either by economic factors or by governments

38
00:02:52,160 --> 00:02:57,200
saying you're not going to be allowed to continue in this way that has a financial implication.

39
00:02:57,200 --> 00:03:02,960
So it's all been about quantifying the extent to which they're going to face those risks.

40
00:03:02,960 --> 00:03:04,520
Practically what does that mean?

41
00:03:04,520 --> 00:03:14,640
What is the carbon tracker product or service that works on what this qualification?

42
00:03:14,640 --> 00:03:21,320
So we've done a lot of work on oil and gas and then I've been working on coal power.

43
00:03:21,320 --> 00:03:25,480
For oil and gas we put all the oil projects on a cost curve.

44
00:03:25,480 --> 00:03:30,880
So we say how much does it cost for the company X in this region to produce a barrel of oil?

45
00:03:30,880 --> 00:03:36,600
And then we say how much oil could we burn in a climate compatible scenario?

46
00:03:36,600 --> 00:03:41,120
And the projects that are above the line don't make it in.

47
00:03:41,120 --> 00:03:45,840
And so we say, you know, some companies are better positioned for this energy transition

48
00:03:45,840 --> 00:03:47,800
in the climate compatible way and some aren't.

49
00:03:47,800 --> 00:03:51,360
And then we started doing the same for coal power, saying if there's going to be a coal

50
00:03:51,360 --> 00:03:55,600
power phase out in a given country, how should that be done if it's done on the least cost

51
00:03:55,600 --> 00:03:56,600
basis?

52
00:03:56,600 --> 00:04:02,080
Which company has the highest cost units and should therefore be closed down first?

53
00:04:02,080 --> 00:04:08,240
And that is about the market as well, because I'm saying close down, but it may be that

54
00:04:08,240 --> 00:04:12,960
the market sends a signal such that the coal plant is no longer economically viable and

55
00:04:12,960 --> 00:04:16,080
that phase out would happen in the same way.

56
00:04:16,080 --> 00:04:24,160
And so who are the users of this intelligence, is it the policymaker or the companies themselves?

57
00:04:24,160 --> 00:04:28,440
We think that we have some appeal to a lot of different audiences, definitely policymakers,

58
00:04:28,440 --> 00:04:32,240
because they need to be aware of these forces that are going on in the end to transition

59
00:04:32,240 --> 00:04:35,560
and make sure the policies are there to support it.

60
00:04:35,560 --> 00:04:41,400
But investors certainly, because we think there's a lot of shareholder value at risk for

61
00:04:41,400 --> 00:04:44,800
companies that aren't prepared for the changes that are happening.

62
00:04:44,800 --> 00:04:49,080
We've seen that a lot in Europe in the utility sector, where European utilities lost a lot

63
00:04:49,080 --> 00:04:53,840
of money because they didn't see renewables coming, essentially.

64
00:04:53,840 --> 00:04:57,320
But also to campaigners and journalists as well.

65
00:04:57,320 --> 00:05:00,440
And so where does data science fit into all of this?

66
00:05:00,440 --> 00:05:07,240
So we take a lot of different databases from all sorts of different sources and try and

67
00:05:07,240 --> 00:05:09,760
join them up.

68
00:05:09,760 --> 00:05:14,280
But the project that we've done more recently was really about looking at places where

69
00:05:14,280 --> 00:05:20,560
the databases weren't so good, where it's very hard to get publicly available data about

70
00:05:20,560 --> 00:05:25,040
the kinds of operations that we're trying to find out about.

71
00:05:25,040 --> 00:05:31,200
So trying to find coal production data, trying to find it out about how plants in India

72
00:05:31,200 --> 00:05:36,200
have running their pollution technologies, all of which has impacts on how much they cost

73
00:05:36,200 --> 00:05:38,560
to run and the profitability of the companies.

74
00:05:38,560 --> 00:05:44,000
So it's about joining up different data sources, making them talk to each other and about

75
00:05:44,000 --> 00:05:47,720
filling in the gaps, where we don't have good data.

76
00:05:47,720 --> 00:05:49,400
So walk us through the process.

77
00:05:49,400 --> 00:05:55,440
How did you go about pulling together all of these data sources?

78
00:05:55,440 --> 00:06:02,920
So firstly, I have to give thanks to all of the data providers all around the world doing

79
00:06:02,920 --> 00:06:09,200
a huge amount of good work in terms of making, I mean, we buy a lot of data sets, but

80
00:06:09,200 --> 00:06:14,800
there are also some really good freely available public data sets, including coal swarm, which

81
00:06:14,800 --> 00:06:21,720
have a global database about operating coal plants, which I know is a lot of work and

82
00:06:21,720 --> 00:06:26,960
really a testament as well to open source, because they have a website where a wiki site

83
00:06:26,960 --> 00:06:31,280
where people can upload information, so they aggregate them, do a lot of work themselves

84
00:06:31,280 --> 00:06:33,320
to put it all together.

85
00:06:33,320 --> 00:06:40,760
Of course, there's no uniform naming as often the case, so we have to do a lot of string

86
00:06:40,760 --> 00:06:47,080
matching and patent matching in order to sync up where we think these projects are and

87
00:06:47,080 --> 00:06:51,680
bring together these different qualities that we're looking for basically in terms of capacity

88
00:06:51,680 --> 00:06:56,960
in terms of ownership, and these things are often some organization may be really interested

89
00:06:56,960 --> 00:07:01,040
in what is there, but a different organization may be really interested in who owns it and

90
00:07:01,040 --> 00:07:06,040
how that ownership structure has changed over time, so gluing those things together, and

91
00:07:06,040 --> 00:07:13,080
in terms of how we do it, because carbon track has a lot of X city analysts, so we do a

92
00:07:13,080 --> 00:07:19,240
lot of analysis in Excel, and so my first task in the beginning was to interface with

93
00:07:19,240 --> 00:07:26,200
a lot of existing Excel databases and put them into SQL, which is usually what I would

94
00:07:26,200 --> 00:07:34,520
use, and then just a lot of string matching, they're not terribly exciting at the base layer,

95
00:07:34,520 --> 00:07:36,840
but essential for everything we did on top.

96
00:07:36,840 --> 00:07:41,760
Okay, and are you doing some work with satellite imagery as well, is that right?

97
00:07:41,760 --> 00:07:48,600
Yeah, yeah, so why don't I just jump in and tell you a little bit about that project?

98
00:07:48,600 --> 00:07:54,960
And so what we wanted to find out was the capacity factor of coal plants, and the capacity

99
00:07:54,960 --> 00:08:00,400
factor is simply how much of the time, more proportion of the time they're running compared

100
00:08:00,400 --> 00:08:06,960
to their maximum theoretical maximum output, and that's a key part of the financial evaluation

101
00:08:06,960 --> 00:08:15,280
of any plant, because the profits that they can make are a balance between the revenues

102
00:08:15,280 --> 00:08:19,960
they can earn when they run, and the ongoing costs, and the fixed costs that they have

103
00:08:19,960 --> 00:08:25,640
to pay every year in terms of maintenance costs, in terms of lifetime extensions, and

104
00:08:25,640 --> 00:08:27,360
other fixed costs.

105
00:08:27,360 --> 00:08:33,080
So working out how often these things are running is a really important part of our modeling.

106
00:08:33,080 --> 00:08:38,480
Now for various parts of the world, that data is public, though sometimes it's a few years

107
00:08:38,480 --> 00:08:45,400
out of date, so in the US and in Europe, you can find that data through the EPA and in Europe

108
00:08:45,400 --> 00:08:52,560
through, it's called a NSOE, which is about electricity transparency, but the data is

109
00:08:52,560 --> 00:08:57,280
out there, but for other parts of the world, particularly sort of Southeast Asia and across

110
00:08:57,280 --> 00:09:03,320
Asia, that data was not available, or if it is available it's about four years out of date.

111
00:09:03,320 --> 00:09:09,840
So we wanted to investigate whether we could use remote monitoring that is satellite imagery

112
00:09:09,840 --> 00:09:14,440
to answer that question and work out how often these plants are running, and we thought

113
00:09:14,440 --> 00:09:23,280
we had a good shot at it because at the same time, the proliferation of this, of competitors

114
00:09:23,280 --> 00:09:29,080
in the satellite imagery space, and the availability of the data has just increased hugely in the

115
00:09:29,080 --> 00:09:30,080
last few years.

116
00:09:30,080 --> 00:09:36,160
Partly that's to do with these nano-sats and cube-sats, which are very small, but still

117
00:09:36,160 --> 00:09:43,480
give reasonable quality outputs, and some companies like a planet who we worked with put up

118
00:09:43,480 --> 00:09:48,360
a sort of over a hundred of the, I think 150 now, these cubes-sats, and I know a lot

119
00:09:48,360 --> 00:09:53,360
of other providers, I think you're doing the same or certainly thinking of if they're

120
00:09:53,360 --> 00:09:54,600
not already.

121
00:09:54,600 --> 00:10:04,840
The goal then is to look at areas where you've got known coal production facilities and

122
00:10:04,840 --> 00:10:13,440
try to predict their output, their capacity at any given point in time, and it sounds

123
00:10:13,440 --> 00:10:20,280
like one of the things you're doing is you've got the, you've got some known facilities

124
00:10:20,280 --> 00:10:29,400
and their output via the NSoE and EPN you're using these as labels to then train a model.

125
00:10:29,400 --> 00:10:34,640
Exactly, that was our starting point that we would have all this label data, and thus

126
00:10:34,640 --> 00:10:41,840
we would have a strong base to do some proper supervised learning.

127
00:10:41,840 --> 00:10:47,160
And so without too much further scoping, we then set off to try and do them.

128
00:10:47,160 --> 00:10:51,920
And possibly as with all things, perhaps we should have spent longer scoping out or thinking

129
00:10:51,920 --> 00:11:00,760
about other kinds of solutions, but we just dove straight in and I started writing scripts

130
00:11:00,760 --> 00:11:07,000
to interface with satellite providers, APIs, where you can query for images and things.

131
00:11:07,000 --> 00:11:13,480
So the first step was to create GeoJson objects specifying the areas where it's called areas

132
00:11:13,480 --> 00:11:17,640
of interest or AOIs, what's referred to by these satellite image providers.

133
00:11:17,640 --> 00:11:22,040
So we had to make shape files or GeoJson files for each one of these coal parts that we

134
00:11:22,040 --> 00:11:23,360
wanted to get the data.

135
00:11:23,360 --> 00:11:30,960
Often we just drew a square, a sort of 1.5 kilometer squared size shape file around each

136
00:11:30,960 --> 00:11:38,880
plant and sent that off to the image provider's API and said, give me all the images you

137
00:11:38,880 --> 00:11:45,680
have in the last two years that meet a threshold of cloud cover of, say, less than 10% cloud

138
00:11:45,680 --> 00:11:49,680
cover and let me download it.

139
00:11:49,680 --> 00:11:55,520
And that was amazing in the first instance because that sort of capability, again, is very

140
00:11:55,520 --> 00:12:00,880
new because usually or what has historically been the case was if you want to work with

141
00:12:00,880 --> 00:12:07,560
satellite data, you get image tiles and the tiles are like the photograph, the image

142
00:12:07,560 --> 00:12:13,560
that the satellite sensor takes and it covers a large area and it's a big file.

143
00:12:13,560 --> 00:12:18,080
So if I wanted to do that, historically, I would have had to download sort of terabytes

144
00:12:18,080 --> 00:12:21,400
of data and then sort of click it myself.

145
00:12:21,400 --> 00:12:29,120
Thankfully, I didn't have to do that. I could create a labeled small, well, set of small

146
00:12:29,120 --> 00:12:33,800
images where images were a few hundred kilobytes each or something because they had been pre-clipped

147
00:12:33,800 --> 00:12:34,800
out.

148
00:12:34,800 --> 00:12:39,160
I think a digital globe called these image chips.

149
00:12:39,160 --> 00:12:50,080
And so reasonably quickly, we had a data set of around sort of 80,000 images for the

150
00:12:50,080 --> 00:12:54,280
rest of the labelled.

151
00:12:54,280 --> 00:12:56,680
So we were sort of ready to go relatively quickly though.

152
00:12:56,680 --> 00:13:01,760
There were some challenges there in terms of making sure that the time zones were right

153
00:13:01,760 --> 00:13:06,240
for the labels and the satellite images and sinking that up correctly.

154
00:13:06,240 --> 00:13:11,280
That was a minor headache.

155
00:13:11,280 --> 00:13:17,080
And I mean, another challenge that we saw straight away was that we didn't have any sort

156
00:13:17,080 --> 00:13:20,280
of balance in terms of the training classes.

157
00:13:20,280 --> 00:13:24,920
If we were going to look at whether plants were running very hard or they were running

158
00:13:24,920 --> 00:13:28,960
somewhat or they were off, or if we just, as we ended up just looking at whether plants

159
00:13:28,960 --> 00:13:35,760
were on or off, it was a very imbalanced class and part of that is because satellites

160
00:13:35,760 --> 00:13:43,840
take images in the daytime when it and it plants also happen to run more in the daytime.

161
00:13:43,840 --> 00:13:47,280
So there's no images in the night when plants were running less and more likely to be off.

162
00:13:47,280 --> 00:13:51,840
So we had very imbalanced class, training classes straight away that we had to deal with

163
00:13:51,840 --> 00:13:59,320
them, which we counted just by sampling the imbalanced class multiple times and then

164
00:13:59,320 --> 00:14:04,120
doing lots of manipulations to it.

165
00:14:04,120 --> 00:14:07,600
And that worked out okay, but not fantastic, I would say.

166
00:14:07,600 --> 00:14:10,840
So that was one limitation that we saw straight away.

167
00:14:10,840 --> 00:14:17,680
And were you primarily looking at this binary status, whether the plant was on or off as

168
00:14:17,680 --> 00:14:26,680
opposed to trying to measure the plume area and try to determine the output in some way?

169
00:14:26,680 --> 00:14:31,960
Initially, we absolutely wanted to be hopes, we had high hopes that our model would just

170
00:14:31,960 --> 00:14:37,440
spit out a reasonable output number for each plant and that had to be calibrated on the

171
00:14:37,440 --> 00:14:44,360
actual capacity, the size of each plant, which we had, we had that information.

172
00:14:44,360 --> 00:14:50,400
But unfortunately, we tried to just do a make a regressor, but it didn't turn out terribly

173
00:14:50,400 --> 00:14:51,400
well.

174
00:14:51,400 --> 00:14:57,080
The results it gave didn't seem to reflect reality particularly.

175
00:14:57,080 --> 00:15:05,240
And part of that, we found by doing some manual analysis, was just looking at the classification

176
00:15:05,240 --> 00:15:10,680
that it was doing in terms of the actual pixels that it was counting up.

177
00:15:10,680 --> 00:15:19,440
And this is where perhaps an early weakness that was, I think, I made a decision early

178
00:15:19,440 --> 00:15:29,400
on to take visual images from the API, which is author-rectified sort of our RGB images

179
00:15:29,400 --> 00:15:35,440
because visual images are what's needed, of course, to do an image processing machine

180
00:15:35,440 --> 00:15:37,160
learning technique.

181
00:15:37,160 --> 00:15:45,600
What's also available is 13 band analytic images, which contain a lot, a lot more information.

182
00:15:45,600 --> 00:15:52,720
And we ended up using that to do the counting up rather than doing a visual classifier because

183
00:15:52,720 --> 00:15:59,320
any kind of very light pixels, which could have been to do with a wish-lectivity of metal,

184
00:15:59,320 --> 00:16:04,520
other kinds of sort of smoke plumes and things coming off the ground, that was all getting

185
00:16:04,520 --> 00:16:11,520
counted up and sort of adding to the plants output, which wasn't a good reflection of

186
00:16:11,520 --> 00:16:13,280
what was actually going on.

187
00:16:13,280 --> 00:16:19,800
So fairly quickly, we decided that we weren't going to be able to get the output using this

188
00:16:19,800 --> 00:16:20,800
method.

189
00:16:20,800 --> 00:16:26,640
And so we ended up doing, on Google Earth Engine, we made an algorithm that would count

190
00:16:26,640 --> 00:16:32,120
up the pixels in each image and just say, using the analytical images, because it could

191
00:16:32,120 --> 00:16:39,520
do a spectral linear mixing of the information in those analytic image chips.

192
00:16:39,520 --> 00:16:45,160
And that gave us a better estimate of an instantaneous output.

193
00:16:45,160 --> 00:16:50,920
So our idea then was to combine these two different techniques to say, here's when we think

194
00:16:50,920 --> 00:16:55,080
the plants are often, here's what we think is an average of the plants output over that

195
00:16:55,080 --> 00:16:56,840
given time.

196
00:16:56,840 --> 00:17:01,400
And by combining them, we got to a reasonable results in the end.

197
00:17:01,400 --> 00:17:07,280
You mentioned earlier that a lot of your challenges could be traced back to kind of the way

198
00:17:07,280 --> 00:17:11,200
you scope the problem or problem definition.

199
00:17:11,200 --> 00:17:17,400
And this is one example of where you need it to pivot in the way you approach the problem

200
00:17:17,400 --> 00:17:21,040
or are there others that we can talk for?

201
00:17:21,040 --> 00:17:30,320
Yeah, certainly. I mean, one thing that became clear to us over time as we got more into

202
00:17:30,320 --> 00:17:33,960
the problem was we started out really wanting to understand China and what's happening in

203
00:17:33,960 --> 00:17:34,960
China.

204
00:17:34,960 --> 00:17:41,080
And of course, from a climate change perspective, China is a huge global emitter.

205
00:17:41,080 --> 00:17:44,000
And it has a huge amount of cold capacity.

206
00:17:44,000 --> 00:17:47,360
It has sort of 1100 gigawatts of cold capacity.

207
00:17:47,360 --> 00:17:51,240
So from a climate perspective, it's very important to know what's going on.

208
00:17:51,240 --> 00:17:56,400
And historically, the data has been very poor and China has been criticized for publishing

209
00:17:56,400 --> 00:17:59,360
statistics that perhaps don't really reflect what's going on.

210
00:17:59,360 --> 00:18:03,720
And that sort of thing, or the data is only available years later.

211
00:18:03,720 --> 00:18:08,720
And what we found as we started working more and more closely on this and talking to

212
00:18:08,720 --> 00:18:15,680
more and more people who are closer to the ground was that more in recent times.

213
00:18:15,680 --> 00:18:21,120
In fact, there is a real-time monitoring effort in five Chinese provinces.

214
00:18:21,120 --> 00:18:28,240
So we were actually able to obtain very good high quality granular data for coal emissions

215
00:18:28,240 --> 00:18:32,920
in some of these places, which was brilliant because we could then calibrate the predictions

216
00:18:32,920 --> 00:18:36,160
we'd made for China in those regions.

217
00:18:36,160 --> 00:18:44,640
But then, of course, to some extent reduce the need for the methodology we had developed.

218
00:18:44,640 --> 00:18:49,920
So we were sort of happy pleased and frustrated at the same time with that.

219
00:18:49,920 --> 00:18:51,760
But then, of course, that was only for five regions.

220
00:18:51,760 --> 00:18:55,440
It was only a mandatory in certain places.

221
00:18:55,440 --> 00:19:01,440
So for other places, of course, we can still use our methodology and be even more certain

222
00:19:01,440 --> 00:19:04,000
or confident in the results that it gave us.

223
00:19:04,000 --> 00:19:09,520
Did you find that the models that you created translated well from one region of the world

224
00:19:09,520 --> 00:19:13,720
to another, or did they not?

225
00:19:13,720 --> 00:19:16,200
Yeah, we did.

226
00:19:16,200 --> 00:19:24,440
And I think the interesting variation, in fact, was to do with the ground state of the plants.

227
00:19:24,440 --> 00:19:27,720
Oh, and yeah, here's another good challenge that I'd forgotten about.

228
00:19:27,720 --> 00:19:31,640
Or maybe my mind tried to push it down into my surface.

229
00:19:31,640 --> 00:19:34,440
So annoying.

230
00:19:34,440 --> 00:19:37,000
So just to make it very clear about how we were trying to do this,

231
00:19:37,000 --> 00:19:43,000
we were looking at the visual plumes, the smoke and water vapor that come out of the flu stack

232
00:19:43,000 --> 00:19:47,080
and the cooling towers from a coal plant.

233
00:19:47,080 --> 00:19:54,120
And we were testing and sort of sub-setting on various sort of samples to try and improve

234
00:19:54,120 --> 00:19:54,920
our results.

235
00:19:54,920 --> 00:20:00,760
And I forget how exactly we stumbled upon it, but as soon as we did, it became so obvious

236
00:20:00,760 --> 00:20:05,640
that there are various kinds of cooling technologies that coal plants have.

237
00:20:05,640 --> 00:20:10,680
There's what's called once through, which is if the plant is located in a body of water,

238
00:20:10,680 --> 00:20:18,280
it'll suck in water from, say, a lake or a river, use that to cool its equipment and then

239
00:20:18,280 --> 00:20:23,280
pass it out a slightly warm stream of water.

240
00:20:23,280 --> 00:20:27,720
And there's also active and passive cooling towers, which is draft cooling towers, where

241
00:20:27,720 --> 00:20:31,760
evaporation is used and produces these huge steam plants.

242
00:20:31,760 --> 00:20:37,360
Now those two cooling types produce very different cooling plumes.

243
00:20:37,360 --> 00:20:42,400
And the once through method, in fact, did not behave very well in our models at all.

244
00:20:42,400 --> 00:20:47,920
So once we were able to slice that out and only examine plants with active and natural

245
00:20:47,920 --> 00:20:51,240
draft cooling, we saw much better results.

246
00:20:51,240 --> 00:20:59,760
So that was a real sort of step change that perhaps if we had had a deeper understanding

247
00:20:59,760 --> 00:21:03,960
of the physical characteristics of coal plants at the beginning, we could have seen coming

248
00:21:03,960 --> 00:21:09,680
as it happened, and we were able to infer it by looking at the results as we went along.

249
00:21:09,680 --> 00:21:15,280
It also strikes me that, for example, when would make a big difference if there's no

250
00:21:15,280 --> 00:21:19,400
wind, you're going to have this plume that kind of goes straight up and doesn't spread

251
00:21:19,400 --> 00:21:20,960
horizontally in your image.

252
00:21:20,960 --> 00:21:26,360
But if it's very windy, it'll kind of disperse in one direction, and your model would

253
00:21:26,360 --> 00:21:31,280
need to be able to figure that out to perform more.

254
00:21:31,280 --> 00:21:37,560
Absolutely, we did do a reasonable amount of investigation against environmental data.

255
00:21:37,560 --> 00:21:45,520
And what really enabled us to do this was Google Earth Engine, which had a lot of our environmental

256
00:21:45,520 --> 00:21:49,840
data layers that we could just bring in very easily.

257
00:21:49,840 --> 00:21:52,720
It would have been much more difficult if we weren't using Google Earth Engine, I must

258
00:21:52,720 --> 00:21:53,720
say.

259
00:21:53,720 --> 00:21:57,560
There were other platforms off of similar things, but we were able to, so we were able

260
00:21:57,560 --> 00:22:08,040
to use that to get per image a wind speed, a wind direction, temperature, atmospheric

261
00:22:08,040 --> 00:22:10,040
pressure, and humidity.

262
00:22:10,040 --> 00:22:15,200
And so we did some analysis against all of those variables to see if there was significant

263
00:22:15,200 --> 00:22:20,200
correlation with plume size, and with wind, we did find if the wind isn't blowing the

264
00:22:20,200 --> 00:22:24,560
plume goes straight up and doesn't disperse so much, which when you're looking over vertically.

265
00:22:24,560 --> 00:22:30,000
And some satellites, in fact, do offer an angle offset so that you can try and do volumetric

266
00:22:30,000 --> 00:22:31,480
estimations.

267
00:22:31,480 --> 00:22:36,280
That was something that we'd left on the side and didn't end up trying to investigate.

268
00:22:36,280 --> 00:22:41,760
That was sort of beyond the amount of time we had, but if the wind is very low, you

269
00:22:41,760 --> 00:22:42,760
get the straight up plume.

270
00:22:42,760 --> 00:22:46,160
If the wind is going somewhat, you get more of a dispersal, and if it's a very strong

271
00:22:46,160 --> 00:22:51,080
wind, then you get more of a straight line, so actually the plume area looking from above

272
00:22:51,080 --> 00:22:57,000
isn't as great as sort of medium wind. But overall, we didn't find that it was hugely

273
00:22:57,000 --> 00:23:04,600
significant, saying with the other estimates, because we hoped that by bringing those variables

274
00:23:04,600 --> 00:23:11,280
into the model, we were able to get a really good accuracy, but they didn't actually help

275
00:23:11,280 --> 00:23:14,960
as much as we had hoped, unfortunately.

276
00:23:14,960 --> 00:23:19,320
And I think that was when I talked about the scoping, I mean, we didn't know how hard

277
00:23:19,320 --> 00:23:25,360
this problem was. I think it's the real truth of the matter.

278
00:23:25,360 --> 00:23:36,120
When you just look at the noise and the variation of generation output compared to the plumes

279
00:23:36,120 --> 00:23:42,000
emitted by a plant, you just find that there's a huge variation. It's just very noisy to

280
00:23:42,000 --> 00:23:43,000
start with.

281
00:23:43,000 --> 00:23:49,280
So the accuracy of what we could end up with was always going to be limited by that natural

282
00:23:49,280 --> 00:23:55,160
variation. Whereas if, for example, we were just trying to quantify what kind of equipment

283
00:23:55,160 --> 00:23:58,720
or what kind of cooling technologies, or say we were doing something different and just

284
00:23:58,720 --> 00:24:04,040
looking at whether solar panels are built in a certain area, static stuff that it, rather

285
00:24:04,040 --> 00:24:09,680
than time series data, that's a lot more, I think you can get a much finer degree of

286
00:24:09,680 --> 00:24:13,280
accuracy than trying to get something dynamic like this.

287
00:24:13,280 --> 00:24:14,280
Right.

288
00:24:14,280 --> 00:24:18,160
So we lived and learned.

289
00:24:18,160 --> 00:24:27,800
And so the availability of these image chips helped quite a bit, but did that totally alleviate

290
00:24:27,800 --> 00:24:33,160
the data preparation challenges, or did you have other areas where data prep was really

291
00:24:33,160 --> 00:24:35,640
a big challenge for you?

292
00:24:35,640 --> 00:24:41,840
Doing everything together at the beginning was some challenge.

293
00:24:41,840 --> 00:24:46,400
But beyond that, I mean that just the amount of cloud architecture and cloud solutions

294
00:24:46,400 --> 00:24:50,360
that are being offered really does a lot of the work for you.

295
00:24:50,360 --> 00:24:59,440
And for example, AWS now hosts a lot of archived satellite image data sets that anyone can

296
00:24:59,440 --> 00:25:02,440
access, which we investigated.

297
00:25:02,440 --> 00:25:08,160
We didn't end up using a lot of these satellite image providers now have their own platforms.

298
00:25:08,160 --> 00:25:11,800
And they really try and take as much out of your hands as possible so you can really get

299
00:25:11,800 --> 00:25:14,960
to the implementation phase as quickly as possible.

300
00:25:14,960 --> 00:25:22,280
And it's entirely possible to do extremely rapid prototyping now with new kinds of image

301
00:25:22,280 --> 00:25:27,440
classifiers on satellite data, whether that's through Google Earth Engine, which you can

302
00:25:27,440 --> 00:25:32,480
just pull in all sorts of different sources, or through one of these, mostly I must say,

303
00:25:32,480 --> 00:25:36,640
they're proprietary, but a lot of them have sort of quite low barriers, especially for

304
00:25:36,640 --> 00:25:40,960
academic institutions, and a lot of them have not profit elements as well.

305
00:25:40,960 --> 00:25:45,480
Of course, they have huge fixed costs because they put satellites into the air and they

306
00:25:45,480 --> 00:25:51,360
need to make a return on it, but they are very keen for people to try new things and

307
00:25:51,360 --> 00:25:58,120
to, well, they hope, make commercializable solutions.

308
00:25:58,120 --> 00:26:02,720
For example, Planet has had a Kaggle Challenger while ago about classifying bits of the Amazon

309
00:26:02,720 --> 00:26:08,000
rainforest to try and get people working on these different challenges.

310
00:26:08,000 --> 00:26:12,760
And I know that there's a huge amount being done across this sort of NGO and energy, climate

311
00:26:12,760 --> 00:26:19,000
change space on all sorts of things around water, around coal mining, forest cover, a forest

312
00:26:19,000 --> 00:26:23,480
station, or all those sorts of questions, which can, as I say, I mean, we are a carbon

313
00:26:23,480 --> 00:26:24,480
tracker.

314
00:26:24,480 --> 00:26:29,200
And people that work with this project, it was only sort of maybe three of us.

315
00:26:29,200 --> 00:26:33,480
And the fact that, you know, we could even pull together a sort of machine-learning project

316
00:26:33,480 --> 00:26:38,320
with satellite images, I think, says a lot about how quickly you can get up and running

317
00:26:38,320 --> 00:26:40,160
with modern tooling.

318
00:26:40,160 --> 00:26:47,520
For the classifier that was looking to predict the status of the plants, what model did

319
00:26:47,520 --> 00:26:48,520
you use?

320
00:26:48,520 --> 00:26:50,960
Visual classifier, so it looks like a CNN.

321
00:26:50,960 --> 00:26:51,960
Yeah, exactly.

322
00:26:51,960 --> 00:26:52,960
It was a CNN.

323
00:26:52,960 --> 00:26:56,840
We used Inception V3.

324
00:26:56,840 --> 00:27:05,280
And we just wanted an image-pressing model that knew edges and knew its way around an

325
00:27:05,280 --> 00:27:06,280
image.

326
00:27:06,280 --> 00:27:11,840
We ended up stripping off some of the last final layers.

327
00:27:11,840 --> 00:27:15,520
And I think we added a dense layer.

328
00:27:15,520 --> 00:27:21,360
But, you know, we didn't have to do a huge amount of tweaking.

329
00:27:21,360 --> 00:27:27,760
Maybe we should have done, but that was what we ended up doing, and it worked pretty

330
00:27:27,760 --> 00:27:28,760
well.

331
00:27:28,760 --> 00:27:29,920
Pretty okay, I would say.

332
00:27:29,920 --> 00:27:36,240
You were evaluating your model performance based on, again, this kind of, these known US

333
00:27:36,240 --> 00:27:41,960
and Europe plants, or did you end up with something different?

334
00:27:41,960 --> 00:27:46,120
No, we just used the label data for the US and the EU.

335
00:27:46,120 --> 00:27:50,560
And later, when we found out about this source in China, we were able to do some training

336
00:27:50,560 --> 00:27:53,800
using the label China data as well.

337
00:27:53,800 --> 00:28:00,880
And so we just looked at precision and recoil for the plants that were on and the plants

338
00:28:00,880 --> 00:28:01,880
that were off.

339
00:28:01,880 --> 00:28:05,680
And again, because of this very imbalanced data set, most of the images were of plants

340
00:28:05,680 --> 00:28:09,680
with some sort of smoke vapor bloom.

341
00:28:09,680 --> 00:28:14,480
We had very good accuracy or very good precision for plants that were on.

342
00:28:14,480 --> 00:28:21,040
And then much worse, in fact, for plants that were off, which dragged the accuracy down

343
00:28:21,040 --> 00:28:27,760
overall, which is quite understandable with a very balanced training set.

344
00:28:27,760 --> 00:28:34,320
Head of curiosity, what's the typical kind of cycle time for these plants being on or

345
00:28:34,320 --> 00:28:35,320
off?

346
00:28:35,320 --> 00:28:37,960
Are they cycling several times a day?

347
00:28:37,960 --> 00:28:43,160
Or is it, you know, they're cycling for, you know, days or weeks on end?

348
00:28:43,160 --> 00:28:50,600
So there's a cost if you're a coal plant operator to go down to zero is if you have to start

349
00:28:50,600 --> 00:28:55,680
up against what's called a cold start, and it's much easier to just lower your output.

350
00:28:55,680 --> 00:29:00,920
So plants are sort of ramping their outputs up and down quite a lot.

351
00:29:00,920 --> 00:29:03,840
But then they might turn off for, you know, a period of days.

352
00:29:03,840 --> 00:29:08,960
But most of the time, it's more, more useful for them to try and keep running as much

353
00:29:08,960 --> 00:29:13,880
as possible and to keep some inertia going.

354
00:29:13,880 --> 00:29:17,800
And for the classifies point of view, that isn't very helpful because it's just saying

355
00:29:17,800 --> 00:29:20,720
oh, it's still on, it's still on.

356
00:29:20,720 --> 00:29:27,880
And that was why the results that we got were initially we thought we could do have a

357
00:29:27,880 --> 00:29:32,320
really fine grain time series and be able to see, you know, every day or every time

358
00:29:32,320 --> 00:29:36,640
we got an image whether it's on or off and draw a very nice time series chart.

359
00:29:36,640 --> 00:29:42,720
And what we ended up deciding was that we could get reasonable accuracy over a time period

360
00:29:42,720 --> 00:29:45,920
because we could take these averages.

361
00:29:45,920 --> 00:29:51,400
But we weren't able to get, you know, to say in this week what's happening.

362
00:29:51,400 --> 00:29:54,360
That was just a limitation that we found.

363
00:29:54,360 --> 00:30:00,760
Though as plants in some areas, I know in the UK where the economic conditions are much

364
00:30:00,760 --> 00:30:05,240
more competitive for coal and they're really struggling, they are trying to innovate which

365
00:30:05,240 --> 00:30:10,960
does mean cycling more often because they'll be trying to make sure that they hit the spikes

366
00:30:10,960 --> 00:30:15,760
in our prices and then just sort of lay low the rest of the time.

367
00:30:15,760 --> 00:30:21,600
So I mean, in theory, or I mean, running these models hopefully will be able to identify

368
00:30:21,600 --> 00:30:26,240
some of these changing operating characteristics or I mean certainly spotting plant down times

369
00:30:26,240 --> 00:30:29,880
and things will be something that we would we would love to do in terms of just setting

370
00:30:29,880 --> 00:30:34,120
this running and then automatically flagging when things are changing.

371
00:30:34,120 --> 00:30:38,920
And did you define off with regard to some kind of threshold to account for this, you

372
00:30:38,920 --> 00:30:45,880
know, cycling down very low or was it hard off was the only off that you were considering?

373
00:30:45,880 --> 00:30:50,360
It's a good question because we came up with two things there, whether the pixel count

374
00:30:50,360 --> 00:30:56,200
would give a value at all, but then there was sort of generic noise in the images.

375
00:30:56,200 --> 00:31:01,040
And when you said before about how did the algorithm fare in different regions of the

376
00:31:01,040 --> 00:31:02,040
world?

377
00:31:02,040 --> 00:31:06,560
Of course, the image is a square around the power plant.

378
00:31:06,560 --> 00:31:11,040
So it is getting some of the landscape, of course the landscape is differing all around

379
00:31:11,040 --> 00:31:17,920
the world and we didn't know to what extent the CNN would pick up various bits of this

380
00:31:17,920 --> 00:31:23,800
landscape and other parts of the coal plant and try and include those and including of

381
00:31:23,800 --> 00:31:26,560
course there's some sighted on rivers and on coastal regions and things.

382
00:31:26,560 --> 00:31:30,680
So we really wanted to try and delve into it to ensure that that wasn't happening and

383
00:31:30,680 --> 00:31:34,000
it would be repeatable.

384
00:31:34,000 --> 00:31:41,040
And so even when it was off there was a base level of reflectivity.

385
00:31:41,040 --> 00:31:48,680
So in short, yes, there was some sort of threshold.

386
00:31:48,680 --> 00:31:55,760
And so that's the classifier on the regressor side was that did you use the same sources

387
00:31:55,760 --> 00:32:03,120
and so we and EPA for your training data or for your labels or did that come from someplace

388
00:32:03,120 --> 00:32:04,120
else?

389
00:32:04,120 --> 00:32:11,640
No, we started off with the regress and we did try to use exact same training data, but

390
00:32:11,640 --> 00:32:16,840
we found that it just wouldn't converge, which was very frustrating.

391
00:32:16,840 --> 00:32:22,320
So we switched that pretty quickly and we just thought this isn't going to, this isn't

392
00:32:22,320 --> 00:32:25,040
going to produce good results.

393
00:32:25,040 --> 00:32:30,280
You didn't get anywhere with the regressor at all or you switched to a different approach.

394
00:32:30,280 --> 00:32:37,880
Yeah, we just switched out and and and said let's just do this with a pixel counting method

395
00:32:37,880 --> 00:32:38,880
basically.

396
00:32:38,880 --> 00:32:41,600
Ah, got it, got it.

397
00:32:41,600 --> 00:32:44,720
So this wasn't a machine learning, there was no training data, just counting the pixels

398
00:32:44,720 --> 00:32:51,440
kind of correlating that to an output based on, you know, understanding of the, you

399
00:32:51,440 --> 00:32:55,400
know, the underlying principles precisely, precisely.

400
00:32:55,400 --> 00:32:59,280
And, you know, so of course, you know, we like to use, love to use machine learning

401
00:32:59,280 --> 00:33:03,440
where we can, but in this case, we just thought, okay, we just need to get a, we just need

402
00:33:03,440 --> 00:33:07,520
to get some number outputs here and the simplest way looks to be best.

403
00:33:07,520 --> 00:33:12,880
I mean, of course, a huge challenge in terms of doing the pixel counting is that, you

404
00:33:12,880 --> 00:33:17,680
know, a, a white pixel and a smoke plume for a plant looks indistinguishable from, from

405
00:33:17,680 --> 00:33:23,720
cloud cover, though there is some, some stuff about sort of height and, and some reflectance

406
00:33:23,720 --> 00:33:29,240
and those sorts of things, but essentially for various parts of the world and in Southeast

407
00:33:29,240 --> 00:33:34,560
Asia, certainly very difficult, you're never going to get optical images frequently enough

408
00:33:34,560 --> 00:33:37,840
that aren't obscured by clouds.

409
00:33:37,840 --> 00:33:42,720
The reason why you could set a limit like 10%, that doesn't mean that there's 10% clouds

410
00:33:42,720 --> 00:33:43,720
evenly distributed.

411
00:33:43,720 --> 00:33:48,600
It means in a, in an image, a large image tile, there will be some clouds somewhere.

412
00:33:48,600 --> 00:33:52,280
And so you just hope that that doesn't intersect with the area of interest you're trying to

413
00:33:52,280 --> 00:33:53,280
look at.

414
00:33:53,280 --> 00:33:55,400
And most of the time it didn't, but some of the time it did.

415
00:33:55,400 --> 00:34:00,720
So that was another source of, of error with, with cloud cover.

416
00:34:00,720 --> 00:34:04,920
And there are some senses that are less affected by this.

417
00:34:04,920 --> 00:34:10,440
And there's a whole lot of senses, including from the European Space Agency's Copernicus

418
00:34:10,440 --> 00:34:17,440
platform that, that look at ozone, self-adarkside, nitrogen dioxide, and there's also some radar,

419
00:34:17,440 --> 00:34:21,360
short synthetic aperture radar that will pick up on metals.

420
00:34:21,360 --> 00:34:25,120
And that's very good for looking about where things are being built or if there's industrial

421
00:34:25,120 --> 00:34:26,120
operations happening.

422
00:34:26,120 --> 00:34:30,640
And I know there's some, some very exciting analytics companies that are, that are using

423
00:34:30,640 --> 00:34:39,400
that approach to regularly check on, on industrial applications or economic activity automatically.

424
00:34:39,400 --> 00:34:44,560
So they, their algorithms will just run every day and say, you know, his, his, what we

425
00:34:44,560 --> 00:34:51,400
think, the economic activity in this sector is based on this, this radar data.

426
00:34:51,400 --> 00:34:54,120
How long did you spend on this project?

427
00:34:54,120 --> 00:34:59,400
All told, I think we, we, we got the data at around Christmas last year or that's when

428
00:34:59,400 --> 00:35:03,560
I was writing the, the scripts to get the first training set.

429
00:35:03,560 --> 00:35:07,400
And it took us, I mean, we did other projects in the interim, so it probably took us about

430
00:35:07,400 --> 00:35:13,840
half, half, half two of our time for about nine months, something like that.

431
00:35:13,840 --> 00:35:17,240
Maybe, maybe a little more, actually, you know, I shouldn't, I shouldn't really undersell

432
00:35:17,240 --> 00:35:22,880
the amount of effort it does, but it was, it, you know, it does no one any favours to

433
00:35:22,880 --> 00:35:23,880
do that.

434
00:35:23,880 --> 00:35:28,160
And it was really to fill in the gaps in, in a, in a global coal economics platform that

435
00:35:28,160 --> 00:35:29,560
we have just been developing.

436
00:35:29,560 --> 00:35:35,960
We're going to launch, we're launching just at the start of December, which is going

437
00:35:35,960 --> 00:35:41,000
to showcase the cost and the profitability for every coal plant worldwide, as well as

438
00:35:41,000 --> 00:35:46,520
contrast it when renewables are going to be cheaper, or it'll be cheaper to build new renewables

439
00:35:46,520 --> 00:35:49,400
than to even run existing coal plants.

440
00:35:49,400 --> 00:35:51,560
So that's the, the data we wanted to make available.

441
00:35:51,560 --> 00:35:55,080
And that was why we were doing this project such that we could fill in the gaps of places

442
00:35:55,080 --> 00:35:58,560
that we, we really couldn't find any data at all.

443
00:35:58,560 --> 00:36:03,840
So this project did feed into that portal for China, but over the year, we also tried

444
00:36:03,840 --> 00:36:07,280
to develop a lot of local partners, and so it turned out that they're talking to people

445
00:36:07,280 --> 00:36:11,160
and getting, getting local expertise in all parts of the world was also a very useful

446
00:36:11,160 --> 00:36:12,160
way as well.

447
00:36:12,160 --> 00:36:13,160
That's, is that machine learning?

448
00:36:13,160 --> 00:36:14,160
I don't know.

449
00:36:14,160 --> 00:36:16,000
Review machine at work.

450
00:36:16,000 --> 00:36:19,000
Interesting, interesting.

451
00:36:19,000 --> 00:36:26,200
And so are these models, are they kind of, in an ongoing production, production state feeding

452
00:36:26,200 --> 00:36:34,280
into this portal, or have you, did you kind of do a survey and then collect the data and

453
00:36:34,280 --> 00:36:38,560
then is the portal, was any more static data?

454
00:36:38,560 --> 00:36:44,840
Yeah, it's, our aim is to update it every, every three months, while I had the ambition that

455
00:36:44,840 --> 00:36:49,320
I was sort of productionized everything and just keep all the scripts running.

456
00:36:49,320 --> 00:36:54,320
We didn't, ultimately didn't have the, the need to do that, you know, we're, we're

457
00:36:54,320 --> 00:36:58,240
not from profits, so we're not selling, we don't have customers in that, in that sense.

458
00:36:58,240 --> 00:37:03,600
So it never seemed like it was, it was, it was really necessary to do that.

459
00:37:03,600 --> 00:37:07,760
However, because there is, it is really interesting for a lot of different groups to have this

460
00:37:07,760 --> 00:37:13,440
information, and this is where in the, the not profit sector, you know, it's, it's, it's

461
00:37:13,440 --> 00:37:16,600
very hard to get these sort of partnerships set up where someone builds it and everyone

462
00:37:16,600 --> 00:37:20,960
else uses it, but I have some hopes that, that that will happen.

463
00:37:20,960 --> 00:37:27,360
And there is a lot of very exciting information sharing and technical methodology sharing across

464
00:37:27,360 --> 00:37:31,120
these, these different sort of technologies around the energy transition, and it's, it's

465
00:37:31,120 --> 00:37:32,720
only going to improve over time.

466
00:37:32,720 --> 00:37:37,960
So, so hopefully our work will, we'll be a part of that in some way.

467
00:37:37,960 --> 00:37:46,400
It strikes me that this is, you know, just one really interesting use case around how

468
00:37:46,400 --> 00:37:53,280
machine learning AI data science can be applied in the sphere of climate change, climate

469
00:37:53,280 --> 00:37:54,760
change policy.

470
00:37:54,760 --> 00:37:57,160
Are there others that jump out for you?

471
00:37:57,160 --> 00:37:59,200
Yeah, well, absolutely.

472
00:37:59,200 --> 00:38:04,840
I mean, the, the, the Paris climate agreement and the international agreements, one big

473
00:38:04,840 --> 00:38:10,120
part of that is about countries, inventories, and, and holding every, every signatory to

474
00:38:10,120 --> 00:38:15,880
those agreements to, to account in terms of what they say they're going to be doing.

475
00:38:15,880 --> 00:38:19,920
And, and that means, and that's a whole industry in terms of monitoring compliance, monitoring

476
00:38:19,920 --> 00:38:24,720
CO2 emissions, because what falls out straight away just, just on our coal work is, if you

477
00:38:24,720 --> 00:38:27,520
know how often the plants are running and you know some other characteristics, you can

478
00:38:27,520 --> 00:38:31,800
estimate how much CO2 is, is being emitted.

479
00:38:31,800 --> 00:38:35,280
And there's a lot of satellites now that have, that are just for CO2 monitoring as well

480
00:38:35,280 --> 00:38:36,840
as other air pollutants.

481
00:38:36,840 --> 00:38:45,240
So using, using, using AI, you can, and, and data science, you can run automated algorithms

482
00:38:45,240 --> 00:38:48,160
to just continuously measure these things.

483
00:38:48,160 --> 00:38:53,480
And again, a lot of this data is, is available, it's just a question of gluing and all together.

484
00:38:53,480 --> 00:39:01,320
So I do see a, a future where everyone or civil society is able to, to keep tabs on all

485
00:39:01,320 --> 00:39:06,320
large polluters and, and nation states to say, you know, are you really doing, are you

486
00:39:06,320 --> 00:39:09,720
staying true to the commitments you've made on, on climate?

487
00:39:09,720 --> 00:39:15,840
Is this large polluter staying true to its commitments to, uh, run its air pollution scrubbers

488
00:39:15,840 --> 00:39:20,720
or is it in fact, you know, just, just pumping out pollution into the atmosphere, um, and

489
00:39:20,720 --> 00:39:22,280
thinking it can get away with it.

490
00:39:22,280 --> 00:39:26,880
So I see that really starting to change in, in real time, and the other part of it is

491
00:39:26,880 --> 00:39:31,720
making arguments about the speed of growth of, of the positive side of the, the speed of

492
00:39:31,720 --> 00:39:37,600
uptake of renewables of solar deployment and also smarter, uh, predictive capabilities

493
00:39:37,600 --> 00:39:39,800
in terms of power systems.

494
00:39:39,800 --> 00:39:46,160
So being able to, uh, more accurately predict our solar and wind output, um, shifting

495
00:39:46,160 --> 00:39:52,000
demand, uh, and smart grid, so smoothing out the peaks in NG demand, um, which reduces

496
00:39:52,000 --> 00:39:57,120
the system cost for every on and, and further erodes the case for, for fossil fuels.

497
00:39:57,120 --> 00:40:02,240
Um, so, uh, and across, I, I mainly look at the power sector, but there's, you know, power

498
00:40:02,240 --> 00:40:06,320
also has a water stress and water impacts, which is, which is extremely important, that's

499
00:40:06,320 --> 00:40:10,640
something that can very easily be seen and changes over time can very easily be seen,

500
00:40:10,640 --> 00:40:16,200
um, from space or in automated ways, uh, deforestation can, can now be tracked again in,

501
00:40:16,200 --> 00:40:18,040
sort of, near real time.

502
00:40:18,040 --> 00:40:23,200
Um, so yeah, a huge amount of applications, and I think, um, the, the more, the more people

503
00:40:23,200 --> 00:40:26,600
that, that we in the non-profit sector can sort of mobilise to, to walk in those, the

504
00:40:26,600 --> 00:40:31,120
more data scientists we can, we can attract to, to come and work on those projects, the,

505
00:40:31,120 --> 00:40:33,320
better able will be to, to address them.

506
00:40:33,320 --> 00:40:37,000
Lawrence, thank you so much for taking the time to chat with me.

507
00:40:37,000 --> 00:40:38,000
I really enjoyed it.

508
00:40:38,000 --> 00:40:40,800
Right, Sam, thanks so much for having me on.

509
00:40:40,800 --> 00:40:46,800
All right, everyone, that's our show for today.

510
00:40:46,800 --> 00:40:51,040
For more information about today's show, visit twimmolai.com.

511
00:40:51,040 --> 00:40:57,320
Be sure to visit twimmolcan.com for information or to register for Twimmolcan AI platforms.

512
00:40:57,320 --> 00:41:01,160
Thanks again to C3 for their sponsorship of today's episode.

513
00:41:01,160 --> 00:41:04,840
And to check out what they're up to, visit c3.ai.

514
00:41:04,840 --> 00:41:33,360
As always, thanks so much for listening and catch you next time.

