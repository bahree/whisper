Welcome to the Twomo AI Podcast.
I'm your host Sam Charrington.
Hey, what's up Twomo listeners?
I've got a super busy few weeks ahead of me as I head back out on the road to close out
the 2019 conference season.
Next week I'll be at CUBEcon, hanging out with my Kubanot friends and getting caught
up on how the open source Kuban80's project is evolving to support machine learning at
scale.
Then the week of December 2nd, I'll be turning my attention to machine learning and AI
in the cloud at the AWS re-invent conference.
In the following week, the week of the 9th, I'll be hanging out with the AI research
community at NURRIPS.
Definitely reach out if you'll be at any of these events I'd really love to meet you.
Before we get to today's show, a quick plug for the TwomoCon AI Platforms video packages
that we've currently got available for pre-order.
If you're working in an organization where productivity, efficiency, or scale of your machine
learning efforts matters, please hit the pause button and check out twomocon.com slash
videos where you can take a look at what we've got on offer.
While I could list a ton of reasons why you should get these for yourself or your team,
instead I thought I'd share a few of my favorite attendee quotes.
Very, very relevant for my day-to-day work.
Practical information for those trying to scale AI in their organization.
If you were to plot out quality versus density, this is up and to the right.
More pricing goes away as soon as we get the videos posted, which is likely within
a week.
So don't miss this opportunity to get a great deal on this amazing resource and of course
to support your favorite ML&AI podcast.
Once again, visit twomocon.com slash videos for more information on individual and team
pricing.
All right, on to the show.
All right, everyone, I am on the line with Terry Stenobsky.
Terry is the Frances Crick Chair and Head of the Computational Neurobiology Lab at Salk
Institute for Biological Studies, as well as he's on the faculty at UC San Diego.
Terry, welcome to the Twomo AI podcast.
Wonderful to be here.
I'm really excited about jumping into our conversation.
Why don't we start by having you share a little bit about your background.
You are one of the founders of the field of computational neuroscience.
How did that come to be?
Yes, it is a combination of my training first in physics.
My PhD is from Princeton University and then postdoctoral work afterwards at Harvard Department
of Neurobiology.
And it was at a time when neuroscience was really heavily dominated by empirical studies
and it still is, but I felt that with my training in physics and developing models that this
could be another part of enhanced neuroscience and help go from the biological substrate
to a more computational perspective on the function of the neural circuits that we were
trying to study.
And so are you fundamentally trying to apply computation to better understand the neurons
and how they operate within a biological context or to use neurological function as we understand
it to improve computation?
You know, it's really both.
It's a two-way street.
And Richard Feynman once said that how do you know whether you really understand something
is when you can build it based on the principles that you've uncovered and it works and it has
the same functionality.
And so we've been trying to do that with building, you know, very detailed models of neurons,
but also synapses, but also developing larger-scale, neural, spiking neural models, which help
the experimental people interpret their data.
And at the same time, because we have computational applications, we can use that to develop much
more powerful systems for being able to do things like control robots, vision systems,
and all of the recent advances that have been occurring in deep learning have basically
come from that direction.
Interesting.
Interesting.
A few chats about spiking neural nets on the show before, most recently, the podcast
I did with Jeff Gellhar from Qualcomm and it came up in a very tangential ways.
So this would be the first time that I've had an opportunity to really, really dig into
the topic.
My understanding of the general idea of spiking neural nets as it applies to machine learning
is that in a lot of ways deep learning and artificial neural nets are inspired by biological
systems, but one key difference is that biological systems exhibit the spiking behavior.
And so the field of spiking neural nets is trying to come up with computational analogs
for the spiking system that can do, that can act or perform like artificial, or that
can perform as artificial neural nets and hopefully lead us to more performing and
more efficient artificial neural net systems.
Is that kind of a good, super high level synopsis of the general direction of research in
this area?
Yes, I think you've set up the issues, which really are based on efficiency.
So let's just make a few comparisons.
So your brain runs on about 20 watts of power, and that should be compared to the enormous
amount of power right now that's going into deep learning in the cloud.
There's an article in today's paper that it's increasing at a phenomenal rate.
I mean, it's not just it's a lot, but it keeps growing and it's been an effort to create
special purpose machine learning chips, which of course are more efficient.
But it doesn't even come close to the efficiency that nature has achieved with regard to how
the brain is able to accomplish all it does in real time with so little power.
And the real secret turns out to be to use signaling, electrical signaling very sparingly.
So it's very sparse.
But they able to encode information in a way that is highly able to represent the information
but also to compute with spikes.
And with the spike, a spike is an all-in-one event.
It's technically called an action potential.
And we know a lot about it.
We know the biophysical mechanisms underlying it last for about a millisecond.
It travels down nerves at variable speed depending on the diameter of the axon, the nerve,
bundle.
And it's relatively slow by computer standards.
So you have signaling within chips at something close to the speed of light.
But if you look at a nerve, the typical speeds are on the order of meters per second.
So you might say, gee, can't neurons do better?
Well, in fact, one of the fastest nerves that's been studied is that the giant axon of
the squid that's used for when the squid has to flee is an escape response.
And this nerve is a millimeter in diameter.
And in fact, when the anonymous looked at it, they mistook it for a blood vessel.
But later, the neurophysiologist, Alan Hodgkin and Huxley, Hugh Huxley, were able to use
this as a model system for understanding the mechanisms.
And they wrote down a set of equations, how are the Hodgkin Huxley equations, which have
served as the foundation for all of signaling, electrical signaling, many other types of
channels and pathways that have been built on top of that.
So that really was foundational.
But now the question is, how do you compute with those spikes?
And that's really an interesting problem.
Let me jump in with a quick question.
When we're talking about these spikes, are they fundamentally digital in nature, a spike
occurred, or a spike didn't occur?
Or are there other characteristics that may be important, at least biologically, such
as the amplitude of the spike or the duration of the spike?
Or I can imagine there might be others, some intensity.
How do we characterize these spikes, and what do we think might be part of the information
that's transmitted with them?
Right.
Well, all of the above, certainly, they're all or none, that's the characteristic of
a spike.
However, they come in many different sizes and shapes.
In fact, the fast sodium spike I was talking about on the millisecond time scale has
variable width, also a calcium spike, which is much broader, and in fact, your heart uses
the calcium spike hundreds of milliseconds long in order to maintain a heartbeat.
But the first approximation that you should think of it, yes, it is a digital signal.
There's either a signal there or not.
But it occurs at an analog time, because the spiking is asynchronous.
There is no clock, master clock in the brain.
There may be local synchronization that takes place in small circuits.
But the idea, though, is that, and this is something that's actually a very powerful way
to think about computing, which now that, for example, machine learning chips are being
developed.
There's 100 startup companies out there right now that are all vying for this big market
that people see.
And once you've gone to an asynchronous system, it just makes designing chips much more easy
in a sense that you no longer have to have a signal that is transmitted all over the
chip that allows you to get the transistor on and off.
But there are other things, too, which are very important.
It's not just the spike itself, but what happens to the spike when it reaches the synapse.
And there, there's an even more complex dynamical system that controls the release of neurotransmitter.
And depending on the rate of firing of these spikes and depending on the signaling to
the postsynaptic cell, you have a very wide range of not just strengths, but temporal modulation
of that signal.
So, you know, you elaborate on that bit a bit?
Yeah, okay, so, you know, in neural network models, we have learning algorithms, and the
idea here is that these are slow changes in the weights and they're permanent, but that
is to say they'll last for, you know, many days.
But there are the short-term synaptic plasticity mechanisms that occur on less than a second
scale.
For example, if you have a burst of firing of a bunch of spikes at a high rate, then the
strength of the synapse facilitates, you know, it could double in size, which means that
a burst of spikes has actually has much more impact than an isolated spike or a same number
of spikes that are spaced in time.
And this is an example of a mechanism which is very important for timing and also for regulating
the flow of information, which isn't incorporated right now in traditional neural network models
that use graded activity rather than spiking activity.
So just to try to capture that, it sounds like one first order difference between the way
the biological systems work and the neural network, artificial neural networks are work
is that in the latter, there's no notion of kind of this, even a dual time scale, kind
of a short-term accumulation effect in changes to inputs versus kind of a long-term adjustment
of weights.
Right.
Actually, Jeff Hinton has a paper, very old paper, probably going back more than 20 years,
where he showed that the short-term changes actually could be helpful for networks that
have dynamical outputs.
By the way, there's another very important degree of freedom here that we, as we know,
is used at various places in the brain, and I actually think it adds a computational,
a very powerful computational dimension.
So that has to do with the relative timing of spikes.
So what's known, this is a mechanism for synaptic plasticity, which depends on spike timing.
It's known that if the spike coming into a neuron occurs within a very brief 10 millisecond
window before the output neuron spikes, pre-before post, and if that's repeated at 10 hertz or
above, that that will increase the strength of the synapse, long-term potentiation.
That means that it will increase in strength and will stay elevated for many hours.
However, if you reverse the order of the two spikes so that the output neuron spikes
before the synaptic input spikes, and you pair that at 10 hertz with a time window here
from 10 to 50 milliseconds depending on the neuron, then that will decrease the strength
of the synapse, and that's a long-term depression.
So it means that the brain is able to use these relative times to regulate the neuron,
the house of strength of a synapse is either increasing or decreasing it, and it can
do that very, very rapidly.
And if you think about it, having, there must be a discriminator sitting in the synapse
that can, is literally able to tell the order of the pre-imposed synaptic activity within
a few milliseconds, which is pretty good for biology, that's a very fast timescale.
The conclusion that you just mentioned suggests that what we're talking about with these spikes
and whether they're pre-imposed isn't kind of the result of, again, kind of some kind
of internal accumulator, like some chemical thing where the spikes are coming in faster
than they're going out, there's a build-up of something.
It's more about the proximity of input and output timings relative to one another that
isn't related to just thinking about the input and output of a bucket like a drain or something
like that.
Well, those are all good analogies, but the reality is that the synapse is a very complex
biochemical machine that has components in small numbers, like there's, in the post-ynaptic
site, for example, there's an area of very dense structure that shows up in the EM as it's
kind of a black surface, the EM block with proteins, electron microscopy.
This is a very high-resolution way of looking inside of cells, nanometer scale, and there's
like 300 different proteins in that post-ynaptic density.
They're all there to work, as you say, doing all of the functions that accumulating information,
that's an integration step, but also keeping track of what's been happening over a longer
time scale and through a downstream pathways can increase the size of the synapse through
this potentiation mechanism that I was telling you about.
People think of, in networks, as a weight, a single connection strength is one number,
but the reality is, as I said, the synapse is a dynamical system with probably dozens
of degrees of freedom, different timescales, and those are all there for a variety of reasons
which have to do with being able to have what's called traces.
You want to keep traces of something without permanently changing the strength.
You want to keep track of things that have happened maybe over the last 10 minutes, and
this actually comes up in reinforcement learning algorithms.
This is Andy Bartow and Rich Sutton, developed a whole series of reinforcement algorithms
that use trace conditioning, these mechanisms for keeping track of information within the
synapse itself, so that you can make decisions later.
Again, to kind of summarize thus far, there's work happening on the biological side to
understand these neurons, and we've identified a whole set of phenomena, our characteristic
of the way these systems work, including the timing of spikes and the duration of spikes
and frequency of spikes, and we have some sense of how they translate into behavior within
the biological system, and then there's this whole other set of work and activity to
try to replicate that on the computational side, and I say, and then there's this not
to artificially separate the two, but let's maybe talk a little bit about the state of
the R and major research directions on that other side, the replication or modeling of
the biological systems on the computational side.
Well, this is an area that is very active right now, that has to say there's a number
of groups around the world who have recognized that if we can build deep learning networks
of spiking units rather than these graded ones, then not only would there be a tremendous
energy savings, but now you could use these deep networks in edge devices like your watch
or sensors directly at the point where the information is coming in, and that would
allow a tremendous amount of compression to occur, and as much more efficient in terms
of just how to get the bandwidth, reduce the bandwidth that you're going to need to get
the information into the internet.
So my own group, over the last few years, has put some effort into being able to do
stochastic gradient descent, which is the algorithm that's used for most deep learning
networks for being able to adjust the weights, but to do that with spiking units rather
than graded units, and we've had some success.
This is Ben Ha, who is a former graduate student of mine who's now working at IBM, but that
looked very promising in a sense that we were able to generalize the algorithm so that
it would be able to work near thresholds.
See, the neurons have these very sharp thresholds where if you're below it, nothing happens,
and as soon as you go above it, you get a spike, all in non-spike, but we showed that if
you have a blurry region, a window in between those two states, that you could use it in
an analog way in order to be able to compute gradients.
So that was very exciting.
To have that, it was a Neurip's paper a few years ago.
If I can pause there with a few questions about that work, is that work, or even today,
are we talking about a handful of, I guess I'm curious about the complexity of the
systems that we're establishing, is this a couple of layers, a couple of neurons?
Are we experimenting with deep systems?
So that's kind of A, and then B, I'm assuming you're not doing this on new hardware by one
of the hundred or so startups that's working in this area, but that you're using traditional
clocked computing, are we talking about simulation-based experiments, or are you building custom
hardware, or what's the kind of hardware at side of this?
Right, well, my lab isn't a hardware lab, but we do collaborate with others, and the
work I was talking about was all done with simulations with fully recurrent networks
having sizes in the several hundred spiking units that were trained to do simple tasks.
Simple in the sense that it's certainly not at the level of deep learning, but these
are benchmark tasks that have been just to show that for one of the issues, and a very
important one with recurrent network is whether you can take input and store it over some
length of time, and then use that to make a decision when another input comes in, say
a second or two later, and that's, we demonstrated that, so it's, it has a lot of the strengths
of these recurrent neural networks that are used right now for language translation.
Now that having been said, we still haven't scaled it up yet, in principle, it should
be possible to have layers, multiple layers of these recurrent networks, but that's not
something unfortunately been left before he could get to that point, but that's not
the only approach.
We have also recently with a graduate student taken another attack, and the idea here
is that, hey, we already have ways of training up these recurrent networks with back propagation
and time.
Why not take one of them that already exists and convert it into a spiking network?
And that's a difficult problem.
Many people have tried to do this, and one typical approach was to say, okay, we'll just
replace every graded unit with 100 spiking units, which then will have stochastic variability,
but it will get the same message through with some degree of variability or noise.
And yeah, if you have enough units, you can do that, but it's very, very expensive because
you're just throwing away a tremendous number of units.
So Robert Kim, who's a graduate student in my lab, came up with a really efficient and
elegant solution to the problem.
So here's what he did, and this is a paper that will be out very soon in the proceedings
of the National Academy of Sciences, before you dive into the approach he took, I want
to make sure that we understand the context so that we understand how important it is.
This kind of assumption that for each of a traditional kind of artificial neuron, we
would need hundreds of spiking units.
Does that come from the idea, roughly, that if you've
got a system that, let's say it's an eight-bit, it can handle eight-bit weights or inputs
or is quantized in some way, and we need to represent that with a system that is essentially
binary.
We'll need many of those binary kind of spiking neurons or spiking units to achieve the
same amount of information storage or flow as in the traditional graded neuron.
Well, that would be a very direct digital solution, just to have each unit representing
a different unit, to represent, for example, eight bits, you need eight units being on
or off.
But if you have spiking units that are asynchronous, you need a lot more because you're averaging
over spikes, and you might need for eight bits, you may need, I'd have to calculate it,
but something like maybe 25 or 50 in order to get, you reduce the noise by square to
Venn.
I'll elaborate on this a little bit more because there's a piece that I think is important
here and not obvious, the averaging over spikes and that kind of driving this fan out
and the number of spiking units.
Why does that come about?
Well, in fact, it's called a population code, and a lot of it was one of the early ideas
in the neural modeling going back to Jack Cohen, which is that we have a lot of neurons,
right?
We have 100 billion, so you might think that you have a lot of units to spare, so it's
redundancy.
You can have the same signal being carried by 100 neurons.
And then if you want to get an accurate estimate for an output, like for a motor neuron, then
you just average over all those spikes, and one of the drawbacks of that approach is that
if you look at how good the variance is, the variability in the estimate for the average,
it goes down as 1 over n, and that means that if you want to reduce it by 10%, you've got
to have 100 units.
Got it.
That's the problem that we're trying to overcome.
By the way, I don't believe for a minute that the brain uses units so profilically.
It just doesn't make any sense to me.
It's just like throwing away tremendous amount of machinery.
And so that's why Robert's solution to the problem, I think, is so elegant.
What he showed was that you don't need to throw in a bunch of spiking units.
You can get by with one spiking unit per one analog graded unit.
But now here's the simple solution, which is that you have to decrease the strength of
the weight, and typically by factor of 10.
And what you find is that if you do this right and tune it up a little bit, you can get
performance which is good, in some cases, a little better than the original network.
And that is truly, from my perspective, it's revealing because it means that it is possible
for the brain to compute with spikes.
It can actually replace the very, the eight-bit kind of, and the throughput that it would
need if you were just averaging.
So in common deep learning, neural nets, you've mentioned gradient descent.
You mentioned back prop, the core problem that we've overcome that allowed us to have
the success we've seen with deep learning is this idea of diminishing and exploding
gradients in these neural networks is do you get the same problem in when you've got networks
of spiking units or is there an analogous kind of definitional problem that we need to
figure out?
Right.
Well, you know, there have been mech ways to overcome the diminishing gradient.
So we have various ways of being able to get the gradient using skip connections back
down to the early layers and also by starting out with the right set of connections so that
it has favorable properties for transmitting information back down.
So we have the same things kind of work?
We haven't done it yet, but that will certainly be our starting point too.
We think that the same principles should apply.
I think what we have already is a good indication that there's a great future ahead for spiking
networks and this feeds into the hardware side, which is analog vealous eye chips that
are now becoming very efficient.
And there are many companies now that are beginning to explore this.
You may know that Intel has a whole group which are neuromorphic engineering group that
is built a chip that is of use of spiking units and also has implemented a lot of the
other details I was telling you about, like short term plasticity, spiked time dependent
plasticity.
And so, you know, we have, we do have a platform now that we could take our simulations
to and demonstrate that we get this great advantage in terms of energy and efficiency.
And so, what would you say are the, is there a way to kind of characterize the major research
problems or directions that folks are currently working on in the space?
Right, I think that the, you know, the problem that we're facing now is architectural
and systems.
In other words, we can put together densely connect small, densely connected networks.
And this is a problem that's faced by deep learning as well as the spiking version,
which has to do with the fact that the biggest deep learning networks today have on the order
of a billion weights, you know, thinking of as parameters, a billion parameters.
Well, in a cubic millimeter of the cerebral cortex, which is what the deep learning emulates,
in a single cubic millimeter, there's a billion synapses.
And what that tells me is that the cortex has the capacity to create, you know, many thousands,
maybe, you know, hundreds of thousands of deep learning networks.
And now the question that hasn't yet been solved or confronted even is, how do you control
the flow of information through a hundred thousand deep learning networks?
Right, right.
And that's a systems level problem.
And, you know, that's a problem that nature solved a long time ago.
And it's one that we're just beginning to come to grips with.
Yeah, I mean, when you think about the kind of, you know, even the most basic kind of picture
of neurons, you know, that you might, might see in a book or article for lay people, you
know, it becomes clear that, or at least it, that system seems a lot less orderly than
the things that we've put in place for deep learning, right?
We've got these neurons that have many connections by directional.
What do we know about the architecture of these neurons with regard to, I'm not articulating
this question, but it feels like it, it feels like those systems are a lot more chaotic
than the things that we're doing.
And, you know, what kind of directions are, you know, do we think will allow us to build
and manage systems with those many, that many degrees of freedom?
Does that question make any sense?
Yes, makes a lot of sense.
In fact, you know, if you look at an electron microscopic image of the cortex, it looks
like spaghetti.
In other words, there's axons and dendrites and synapses all kind of mishmash together.
But as we develop tools and techniques that allow us to dissect out the actual circuits,
you know, the wiring.
Also, not just local, but the long range connections.
What we're discovering is that what looked like it was a mishmash is actually incredibly
precisely put together.
It's all done with molecular systems that are like lock and keys that allow one neuron
to find another.
And that can be over, you know, centimeters, you know, you have this little axon that's
traveling over many centimeters and has to, it's like finding, it's, you know, going from
San Diego and having a little string going up to L.A. and finding a particular address
up in L.A.
I mean, that, that's the level of precision with which the brain is put together.
This is an incredible device we have.
And we will know very soon, sometime next year, Clay Reed, who's at the Allen Institute
for Brain Science, is going to,
you know, announce a connectomic reconstruction.
This is a tour de force because this is something that requires like a petabyte of data
to be computationally stitched together.
But he'll be able to have the entire wiring diagram for a cubic millimeter of cortex.
And as I said before, this contains about a billion synapses and about a hundred thousand
pieces of a hundred thousand neurons.
So we're, you know, we're reaching at a point now where we will have real detailed ideas
for what's the real complexity of these neural circuits.
What makes it, you know, the brain, I think, powerful is that it's not, it's not the case
like they are in deep learning networks where the units are more or less the same, you
know, with different parameters, but more or less the same input output and so forth.
But the, there's hundreds, in fact, thousands of different types of neurons, specialized
neurons.
There's just within inhibitory neurons, there's about 20 different types that have separate
functions and are integrated into a circuit with a great precision.
And so nature has had much more time to evolve and optimize the circuit for the particular
function that it has.
And that's different, different parts of the brain.
The cortex has a different circuit from the, for example, another visual area called
the superior colloculus, which is used in lower vertebrates for their visual system.
And there are hundreds of brain areas, each of which has a different type of neuron and
type of circuit.
So this is a very highly evolved system.
Right now we're at the very beginning.
In fact, I think you could compare where we are now, you know, the deep learning networks
where the right brothers were back in 1903 when they had their first flight, right?
It was a proof of principle, but it was far, far away from where we end up today.
There are a couple of papers that I wanted to make sure that we covered.
One of those was, it's called a simple framework for constructing functional spiking RNNs.
I feel like we talked about some of that stuff, but did we talk about this paper, the key
results of this paper?
Is this one of the ones that you mentioned?
It's a foundational paper for this new method for replacing graded units with spiking units,
but we went through a very millions and millions of simulations in order to pin down the robustness.
I mean, how many networks, you know, when you put them together will work as advertised
and it turns out to be a very high percentage, but also varying a lot of the parameters.
And so this is something you do when you just get something, you know, you have to prove
that it actually works.
But now what we've done is to a paper that we're just preparing is to apply that to much
more complex problems and also compare it to recordings from neurons in different parts
of the cortex.
And what we're finding is something that is happening not just in our lab, but many other places
in the world like Jim DeCarlo at MIT is that when you train up one of these networks,
either deep learning for the visual system or recurrent networks, which is what we're
studying here, which is relevant for the prefrontal cortex, what you find is that the properties
of the units in these networks are phenomenally similar, statistically similar to the recordings
that are made from the brains of monkeys and other species that are solving specific
problems, visual recognition problems or memory problems.
So this is really exciting because it means that there's this is very close conversions
that's occurring between neuroscience on one hand and machine learning and deep learning
on the other hand, which I think is really going to be very, you know, the interaction
the synergies, the fantastic opportunities that are opening up now for the first time in
AI that are going to be sending, you know, information and talent back and forth.
And this is, there's been a couple dozen AI and neuroscience meetings that I've been
to a few of them, but there are many others, you know, I think that there's going to be
a career path here for other people who have an interest in this convergence that's going
on.
And then you've got another couple of collaborations that are focused on this idea of the
application of spiking neural networks to sensory motor control and kind of this, what
you call a sweet spot.
And I guess there's a tradeoff between speed and accuracy.
Can you talk a little bit about that work?
Yes, this is a collaboration with John Doyle, who's a control theorist at Caltech.
And we're looking at the problem of how animals are able to be both fast and accurate, despite
the fact that as I was saying earlier, axons are very limited either they're very fast
but very inaccurate because they take up a lot of space and you can only pump so many spikes
down them or if you have very thin axons like in the alfactory bulb where receptors coming
in have very, very small caliber.
So you have, but you have a hundred million of them and they're very, very, very slow.
So they're very accurate but very, very, very slow.
And the visual system itself, there's a time to leave about a hundred milliseconds.
So you have these built-in limitations in the hardware.
But how is it that you can, for example, mountain bike down a mountain side where you're getting
jostled on a very fast timescale and you have to maintain your balance and at the same
time, you have to navigate down a very winding and perhaps dangerous trail that, and you
know, keep the plant, you have to plan ahead as well as respond to things that are happening.
So in any case, we've developed a theoretical model that can accomplish that and we have
a game.
It's a driving game but it has a lot of the elements of mountain biking in terms of the fast
timescales with jitter of the wheel and also planning ahead the path.
And what we've uncovered in developing the model is something that we call the diversity
enabled sweet spot.
So what does that mean?
First of all, diversity is something we're all familiar with.
You have a very wide range of axon diameters that you see in the brain.
And the question is, can you, if you have the right combination, can you incorporate
them into a control model that takes into account two things, signaling right and speed
and optimize that?
And that's the speed accuracy trade-off.
And what we showed is that once you set up that system, you can reproduce one of the most
celebrated speed accuracy trade-offs in the motor control literature called, this is
something that goes back, you know, 50 years, called FIT's law, if ITTS fits law.
And it's a logarithmic law and it's very, very, a general trade-off between the accuracy
and the speed.
And we've shown now that mathematically and politically, we can achieve that with the
kind of diversity of hardware that's seen in the brain.
Now this is a general principle.
In fact, these logarithmic laws that, like FIT's law, are found throughout sensory and
motor systems.
You know, this is a FECKNERS law and vision, for example, sensory systems.
And we think that not just biology, but we think that a lot of engineered control systems
can benefit from this principle.
Interesting.
Interesting.
So this idea of a speed accuracy trade-off is something that's been well studied in
biology and has resulted in a number of laws, like FIT's laws, that kind of govern the
way we see this trade-off in biological systems.
And you've been able to kind of recreate that using diversity as your control parameter,
if you will.
Exactly.
Exactly.
This optimizing, the sweet spot, is optimizing those two different constraints.
One of the constraints has to do with speed and the other one with accuracy, you know,
the signaling, the accuracy.
And, and by the way, one of the, for me, one of the satisfying parts was that this was
a marriage of two important parts in engineering that are separate from each other.
One of them is control theory, which is all about time delays.
Very rarely do they worry about the signaling pathways because they're using digital logic
and so forth.
And then on the other hand, there's information theory, which is all about information and
how much information you can get through a channel.
But they never worry about time delay.
This is not interesting.
So you have to do extremes and we put the two together and we find this beautiful sweet
spot.
Awesome.
Awesome.
So before we go, one of the things that you mentioned, as we were chatting before we
started the interview was that you are one of the founders of what sounds like a really
interesting workshop focused on neuromorphic engineering.
Can you talk a little bit about the field and the workshop and what you're up to there?
Right.
So I was a visiting professor at Caltech back in the 80s or actually it was a fair trial
this thing was scholar and was actually in the 90s, early 90s.
And I used to go to a Carver Meads lab meetings and I was fascinated.
This is an error when he created the first, you know, vision chip that was able to replicate
some of the things that happened in the retina with asynchronous spiking coming out.
And a cochlear chip for auditory processing.
And this turned out to be a kind of a seed.
He published a book around that era on analog VLSI neural systems, which really started
a whole new branch of analog VLSI design.
And that his students went off to the four corners of the world, but wanted to continue
meeting. So I helped organize an NSF sponsored workshop at Telluride.
It has been meeting for the last 25 years during the first three weeks of July.
And it's a real workshop.
People go there, they bring equipment, they bring robots, they bring all sorts of devices
and oscilloscopes and so forth.
And they work on projects.
We have about 50 students and about 50 faculty who give lectures.
And it's just a wonderful atmosphere because if you've been to Telluride, you're up there
in the mountains and you're kind of it's isolated, but it's a beautiful place outdoors
in the summer.
Now I know where your mountain biking references are coming from.
Yes.
Well, we do a lot of, I don't do personally a lot of biking, but I do a lot of hiking.
But the spirit there is very intense and the students are basically there.
They're not just learning, they're collaborating, they're creating new projects, they take
them home with them, and it's created an international community, which I think is very vibrant
and very, very exciting right now because it's become clear that Moore's law has come
to an end in terms of how being able to reduce the line widths any further is already reaching
the point where you have leakage and so forth that is becoming an energy problem.
But this is having these chips which are incredibly power efficient because you're working not
at saturation, but right at the beginning of the non-linear activation and you're dealing
with microwatts rather than watts to be able to do a decision down at the level of a spike.
So this is really, I think, ultimately this is going to be the technology that's going
to be out there in robots someday because as you know, robots are also have to worry about
power.
They can't take a super computer around with them if you want them to perform properly.
Awesome.
Well, we will include a link to that workshop as well as the papers that we've discussed
here in our show notes.
Terri, thanks so much for taking the time to chat really, really interesting conversation.
Well, thank you very much, I really enjoyed it.
All right everyone, that's our show for today to learn more about this episode visit Twomolaii.com.
Once again, if you missed Twomolcan or want to share what you learned with your team, be
sure to visit twomolcan.com slash videos for more information about our video packages.
As always, thanks so much for listening and catch you next time.
