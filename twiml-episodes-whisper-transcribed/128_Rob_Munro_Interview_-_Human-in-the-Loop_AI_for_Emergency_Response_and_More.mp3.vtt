WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.920
I'm your host, Sam Charrington.

00:31.920 --> 00:37.960
In this episode, I chat with Rob Monroe, CTO of the newly rebranded Figure 8, formerly

00:37.960 --> 00:40.560
known as Crowdflower.

00:40.560 --> 00:45.640
Figure 8's human and aloof AI platform supports data science and machine learning teams, working

00:45.640 --> 00:51.960
on autonomous vehicles, consumer product identification, natural language processing, search relevance,

00:51.960 --> 00:54.680
intelligent chat bots, and more.

00:54.680 --> 00:59.000
Rob and I had a really interesting discussion, covering some of the work he's previously

00:59.000 --> 01:04.280
done applying machine learning to disaster response and epidemiology, including a use case

01:04.280 --> 01:10.000
involving text translation in the wake of the catastrophic 2010 Haiti earthquake.

01:10.000 --> 01:14.040
We also dig into some of the technical challenges that he's encountered in trying to scale

01:14.040 --> 01:18.720
the human and aloof side of machine learning, since joining Figure 8, including identifying

01:18.720 --> 01:23.480
more efficient approaches to image annotation, as well as the use of zero-shot machine learning

01:23.480 --> 01:26.160
to minimize training data requirements.

01:26.160 --> 01:31.680
Finally, we briefly discuss Figure 8's upcoming train AI conference, which takes place

01:31.680 --> 01:34.440
on May 9th and 10th in San Francisco.

01:34.440 --> 01:39.840
At train AI, you can join me and Rob, along with a host of amazing speakers like Gary

01:39.840 --> 01:46.840
Casparov, Andre Carpathi, Marty Hurst, and many more, and receive hands-on AI, machine

01:46.840 --> 01:51.480
learning, and deep learning training through real world case studies on practical machine

01:51.480 --> 01:53.600
learning applications.

01:53.600 --> 02:01.600
For more information on train AI, head over to figure-8.com slash train-AI, and be sure

02:01.600 --> 02:09.600
to use the code TwimmelAI, that's TWIMLAI, for 30% off of your registration.

02:09.600 --> 02:14.560
For those of you listening to this on or before Friday, April 6th, Figure 8 is offering an

02:14.560 --> 02:17.400
even better deal on event registration.

02:17.400 --> 02:22.720
Use the code Figure-8 to register for only $88.

02:22.720 --> 02:27.040
A huge thanks to Figure 8 for sponsoring this episode of the podcast.

02:27.040 --> 02:40.120
And now on to the show.

02:40.120 --> 02:41.120
All right, everyone.

02:41.120 --> 02:43.440
I am on the line with Rob and Rob.

02:43.440 --> 02:49.200
Rob is CTO of Figure 8, the company that you may know as Crowdflower.

02:49.200 --> 02:51.400
They recently changed their name.

02:51.400 --> 02:54.400
Rob, welcome to this weekend machine learning and AI.

02:54.400 --> 02:55.400
Thank you.

02:55.400 --> 02:56.400
It's great to be here.

02:56.400 --> 02:58.480
It's great to have you on the show.

02:58.480 --> 03:03.120
We usually start by having our guests give us a little bit of an introduction to their

03:03.120 --> 03:07.680
backgrounds and how they got interested and involved in machine learning and AI.

03:07.680 --> 03:10.480
Why don't you introduce yourself to the audience?

03:10.480 --> 03:11.480
I'd be delighted to.

03:11.480 --> 03:15.360
My introduction to AI was a little bit circular.

03:15.360 --> 03:21.480
So I was working as a software developer for a number of years, not really focused on

03:21.480 --> 03:23.480
artificial intelligence.

03:23.480 --> 03:28.080
And that had taken me to work for the United Nations Eye Commission for Refugees.

03:28.080 --> 03:35.280
I was working in refugee camps in Liberia while I was living in Sierra Leone.

03:35.280 --> 03:40.960
And there was one particular moment when I was in rural Liberia in a refugee camp there.

03:40.960 --> 03:46.080
And we were installing solar power systems at a clinic supporting the camp.

03:46.080 --> 03:51.440
And we heard all these rumors about refugees coming over the border from Cottovoire.

03:51.440 --> 03:54.840
But we didn't know whether there were 10 refugees or 10,000.

03:54.840 --> 03:59.000
They're in just the next valley, but we couldn't reach them.

03:59.000 --> 04:05.360
And ultimately, after a day of doing work at this clinic, we had to move on without establishing

04:05.360 --> 04:06.520
work condition.

04:06.520 --> 04:09.040
These refugees were in and how many they were.

04:09.040 --> 04:14.520
And what really stood out for me was that I had five bars of cell phone reception at

04:14.520 --> 04:15.520
that time.

04:15.520 --> 04:20.360
And I'm lucky to get a full reception here in Silicon Valley.

04:20.360 --> 04:27.640
And so there's no doubt that this refugee community also had cell phones with them.

04:27.640 --> 04:31.560
Those cell phones were probably bouncing signals off the same tower as mine, but I'd

04:31.560 --> 04:33.360
know where to connect with them.

04:33.360 --> 04:38.640
And even if we did, we probably didn't share any languages.

04:38.640 --> 04:43.600
And the languages for which they did speak, even basic things that we took for granted

04:43.600 --> 04:49.320
and AI 10 years ago, like spam filtering or search engines, wouldn't have worked well

04:49.320 --> 04:51.880
or at all for their languages.

04:51.880 --> 04:54.000
So there really just wasn't anything out there.

04:54.000 --> 04:59.960
And in terms of the supporting technology, which would allow us to understand or translate

04:59.960 --> 05:00.960
between the languages.

05:00.960 --> 05:05.360
And so it was clear to me at that time that we really solved the problem of connect in

05:05.360 --> 05:06.360
the world.

05:06.360 --> 05:10.880
Now, but we had an imbalance in how we're bringing services.

05:10.880 --> 05:15.920
And so I thought, well, anyone can be out drilling solar panels into the roof of a clinic

05:15.920 --> 05:18.760
that doesn't really require specialized skills.

05:18.760 --> 05:22.400
I studied artificial intelligence as an undergraduate or something that I'd remain interested

05:22.400 --> 05:23.400
in.

05:23.400 --> 05:26.840
And so it was at that point that I decided that I really wanted to pursue a career in

05:26.840 --> 05:33.240
artificial intelligence and make sure that we could bring it to everybody in the world.

05:33.240 --> 05:36.880
And so that's what ultimately took me back to graduate school.

05:36.880 --> 05:44.160
So I completed my PhD at Stanford focused on how we can apply natural language processing

05:44.160 --> 05:50.000
to low resource languages, both in health and disaster response context.

05:50.000 --> 05:57.360
And since then, I've worked in a combination of social impact companies and also, you know,

05:57.360 --> 06:02.280
right through to very large, you know, 4 to 500 tech companies like Amazon.

06:02.280 --> 06:08.320
And that brought me to working at Figure 8 just six months ago where I'm really excited

06:08.320 --> 06:11.360
to be the new CTO here.

06:11.360 --> 06:12.360
Awesome.

06:12.360 --> 06:15.040
What did you do your PhD on?

06:15.040 --> 06:16.040
Sure.

06:16.040 --> 06:23.560
So I was looking at ways where we could go from very little initial training data to adapted

06:23.560 --> 06:30.080
models in health and disaster response contexts, especially looking at text messages.

06:30.080 --> 06:35.280
So when people were sending text messages to a hospital clinic in Malawi in a language

06:35.280 --> 06:42.400
district with Chichoa, and then also looking at two disaster response communication data

06:42.400 --> 06:50.840
sets in Haiti and Pakistan from an earthquake in 2010 and floods later that year in Pakistan.

06:50.840 --> 06:55.520
These are actual disasters that as a disaster response professional I worked in.

06:55.520 --> 07:00.320
And so I was very much answering that question for myself, okay, if we don't have any initial

07:00.320 --> 07:08.280
training data in these languages, what's the minimum amount of human interaction and labeling

07:08.280 --> 07:14.160
and categorization and mapping of these messages that is required until we can start building

07:14.160 --> 07:19.920
out automated services in these languages in a way that's language independent.

07:19.920 --> 07:20.920
Oh, interesting.

07:20.920 --> 07:21.960
And how far did you get?

07:21.960 --> 07:27.880
Did you clearly not have completely solved problem, but what did you, what conclusion did

07:27.880 --> 07:29.400
you arrive at?

07:29.400 --> 07:34.240
The broad conclusion was that you could do a lot of so word modeling, which would mean

07:34.240 --> 07:40.080
that you could take one technique and get very similar accuracies across these different

07:40.080 --> 07:41.080
languages.

07:41.080 --> 07:45.920
But what an important observation was that the techniques that worked in English would

07:45.920 --> 07:48.760
not necessarily carry over to other languages.

07:48.760 --> 07:54.640
So linguistically, English tends to be an outlier language in that the spelling is extremely

07:54.640 --> 08:00.200
standardized, even with like the US and the UK variants.

08:00.200 --> 08:06.240
People are highly literate and we have very few affixes in English, very few prefixes

08:06.240 --> 08:09.600
and suffixes compared to most languages.

08:09.600 --> 08:15.920
And what that means is that a lot of approaches to data language processing that views a single

08:15.920 --> 08:23.120
word as a fundamental unit won't apply, won't be very accurate in other languages.

08:23.120 --> 08:30.280
So for example, in the text messages between health workers in Chichoa, in 600 messages,

08:30.280 --> 08:36.480
there were more than 50 different spellings for the word patient due to variations in literacy,

08:36.480 --> 08:40.920
but also just due to the large number of different suffixes and combinations of suffixes and

08:40.920 --> 08:44.600
prefixes that you get in that language.

08:44.600 --> 08:50.920
And so it was positive in terms of being able to find techniques that we've now deployed

08:50.920 --> 08:58.480
in disaster response situations globally, but it also raised some questions about a lot

08:58.480 --> 09:03.520
of research in natural language process, and there's just focused on English as to how

09:03.520 --> 09:10.560
much it really could make an impact if you were taking it to the 7000 other languages

09:10.560 --> 09:11.560
in the world.

09:11.560 --> 09:12.560
Right, right.

09:12.560 --> 09:20.640
Because your sense that the techniques broadly apply but the tooling and the dictionaries

09:20.640 --> 09:27.920
and all of that, you know, haven't, you know, need to be kind of ported over to these

09:27.920 --> 09:34.160
other languages or that there's, you know, a whole set of different research that has

09:34.160 --> 09:38.240
to happen to support languages with different structures.

09:38.240 --> 09:45.400
And part of the question is prompted by at least on the, you know, with deep learning

09:45.400 --> 09:53.120
and neural networks, a lot of what I hear in the conversations that I'm thinking back

09:53.120 --> 10:01.320
to a specific interview where the, I think this was Shubus and Gupta at Baidu at the time

10:01.320 --> 10:05.360
was talking about how they did their, you know, English to Mandarin translation without

10:05.360 --> 10:11.600
any Mandarin speakers, you know, on staff at the time because the deep neural networks

10:11.600 --> 10:17.800
were able to figure out the meaning and the ability to translate without having specific

10:17.800 --> 10:23.440
knowledge, structural knowledge of really either of the languages.

10:23.440 --> 10:27.920
So how do you think that that kind of translates to, you know, this issue that you're pointing

10:27.920 --> 10:32.360
out the disparity in kind of tools and research across languages?

10:32.360 --> 10:38.040
I think a lot of that research is being really exciting in terms of being able to get up

10:38.040 --> 10:44.880
to speed a lot faster without resources like dictionaries or the sources or other resources

10:44.880 --> 10:46.640
in those languages.

10:46.640 --> 10:52.080
So for most languages in the world, we don't have a dictionary, so we're not an online

10:52.080 --> 10:57.000
dictionary that is easily available for, for natural language tools, for the majority

10:57.000 --> 11:03.360
of the world's languages, the only real scientific resource we have is probably a PhD written

11:03.360 --> 11:08.800
by a hippy linguist 40 years ago, and so that doesn't, doesn't give you much of a, much

11:08.800 --> 11:10.760
of a starting point.

11:10.760 --> 11:16.640
And so a lot of the techniques that I was looking at in my PhD and then I've seen taken

11:16.640 --> 11:21.680
much further in exciting ways in more recent deep learning approaches has really focused

11:21.680 --> 11:26.400
on making no assumptions about the structure going in and still being able to get these

11:26.400 --> 11:33.200
really accurate results, and I think a lot of work in machine translation has shown

11:33.200 --> 11:34.200
that.

11:34.200 --> 11:40.880
The only caveat is that a lot of the neural-based techniques typically require a lot more

11:40.880 --> 11:48.280
in the way of labeled data, and so there are particular use cases where the first time

11:48.280 --> 11:52.920
you work in a language is following a sudden onset disaster, then you're coming up against

11:52.920 --> 11:57.960
other problems of, you need some kind of model to start working with a very small amount

11:57.960 --> 12:03.320
of data, and certainly you can't be waiting days, which is typical for training some

12:03.320 --> 12:06.400
of these large machine-limited models.

12:06.400 --> 12:12.560
So it's certainly been net positive, moved towards language independence, but it has been

12:12.560 --> 12:15.520
bringing up some new problems associated with it.

12:15.520 --> 12:21.360
Yeah, so this experience on the research side and running into the need to have these

12:21.360 --> 12:26.520
labeled data sets in place in order to really make progress and create the kind of tools

12:26.520 --> 12:32.840
that you're looking to create really set you up for, I guess, a deep and personal experience

12:32.840 --> 12:41.200
for the need for organizations to be able to amass these labeled training data sets, and

12:41.200 --> 12:50.040
you spent quite a bit of time working on that from the time you spent at the UNHCR and

12:50.040 --> 12:52.800
then in grad school.

12:52.800 --> 12:53.800
That's right.

12:53.800 --> 13:00.800
Yeah, I was a client of figure eights, maybe five or six different times before joining

13:00.800 --> 13:06.680
the company, and fully appreciated the value in being able to build up training data

13:06.680 --> 13:09.240
sets for a number of different use cases.

13:09.240 --> 13:16.280
The first time I used figure eight was during grad school in 2010, so at that point I was

13:16.280 --> 13:21.880
tasked with running their first step in a 911 service, following earthquake in Haiti in

13:21.880 --> 13:24.200
January 2010.

13:24.200 --> 13:29.200
And at the time, more than 100,000 people killed immediately, and while a lot of local

13:29.200 --> 13:34.480
services collapsed, as in buildings, physically collapsed, housing, and to respond services,

13:34.480 --> 13:37.440
most of the cell phone towers remained active.

13:37.440 --> 13:41.560
And so working with a number of people, and including the US State Department, we set

13:41.560 --> 13:45.760
up a free phone number that anyone in Haiti gets in a text message to.

13:45.760 --> 13:50.880
So the lines were overloaded for phone calls, but text messages were still getting through.

13:50.880 --> 13:56.520
But it showed this problem where everyone in Haiti, almost everyone in Haiti, only spoke

13:56.520 --> 14:00.760
Haitian Creole, a language that is not widely spoken.

14:00.760 --> 14:04.960
But everyone come in into Haiti, only had English as a common language.

14:04.960 --> 14:12.520
So I was tasked with finding people who could translate a text message sent in Haitian

14:12.520 --> 14:17.760
Creole, categorize that, plot the location on a map based on the written location and

14:17.760 --> 14:18.840
the message.

14:18.840 --> 14:23.280
And so then you would have a structured English report with a longitude and latitude streamed

14:23.280 --> 14:25.000
back to the men's seat responders.

14:25.000 --> 14:31.040
So people like the US Coast Guard, who could go in and respond to those actual messages.

14:31.040 --> 14:36.520
And that was my first experience with figure eight is something we launched in just 48 hours

14:36.520 --> 14:43.120
and then ultimately found about 2,000 members of the Haitian diaspora worldwide from

14:43.120 --> 14:46.400
across 49 different countries.

14:46.400 --> 14:47.880
And they were the workforce.

14:47.880 --> 14:52.480
So they were the ones who were reading the messages, translating them, categorizing.

14:52.480 --> 14:57.800
Using their local knowledge to know where villages were, which villages would not appear

14:57.800 --> 15:02.520
on any map, but they could at least know from the satellite view where they were.

15:02.520 --> 15:07.200
And then they were able to do this for 80,000 messages.

15:07.200 --> 15:12.960
So an incredibly large amount of data, like several novels with a data in more or less

15:12.960 --> 15:16.040
real time in about four and a half minutes.

15:16.040 --> 15:22.520
So that was a really important moment for me in realizing with distributed human computing

15:22.520 --> 15:29.360
how quickly you can structure data and how you can do this across a really large number

15:29.360 --> 15:30.880
of people.

15:30.880 --> 15:35.680
And so it was certainly a positive experience for as much as it could be for the members

15:35.680 --> 15:40.720
of the Haitian diaspora to be able to help their country from so far away.

15:40.720 --> 15:46.400
Obviously, I really appreciated being able to get that scale of information to the disaster

15:46.400 --> 15:49.200
responders on the ground as well.

15:49.200 --> 15:52.600
And that's ended up also being something that I, like I mentioned, I then studied from

15:52.600 --> 15:58.360
my PhD, looking at ways that we could extend that process with natural language processing

15:58.360 --> 16:03.720
so that we could scale it to even large data sets, larger than even very large numbers

16:03.720 --> 16:05.880
of humans I could process.

16:05.880 --> 16:08.600
And that's where a lot of my work has been used inside the time.

16:08.600 --> 16:15.960
It sounds like you have been involved in a number of, or were involved in a number of

16:15.960 --> 16:24.400
different uses of figure eight and as you, as you described it, distributed human computing,

16:24.400 --> 16:27.680
prior to actually joining the company, what were some of the others?

16:27.680 --> 16:33.520
Yeah, so I use case that extends from from that one very closely is in epidemic tracking.

16:33.520 --> 16:39.920
So just these outbreaks are still the largest large cause of mortality in the world.

16:39.920 --> 16:41.800
And no one is really tracking them all.

16:41.800 --> 16:46.560
So you see a lot of movies where there's a wall room and a big map of the world and

16:46.560 --> 16:51.040
like a heat map it flares up every time there's an outbreak that only exists in the movies

16:51.040 --> 16:52.840
unfortunately.

16:52.840 --> 16:58.040
And I think that the budget for those movies might be bigger than the actual budget for tracking

16:58.040 --> 17:00.040
epidemic globally.

17:00.040 --> 17:04.560
Maybe the closest thing is the Google trends or Google predict.

17:04.560 --> 17:09.160
I forget the specific thing but Google and blue trends, yeah, flu trends, right?

17:09.160 --> 17:14.880
Is it still only flu or is it, do they, are they able to predict a broader set of things

17:14.880 --> 17:15.880
now?

17:15.880 --> 17:20.160
They were able to predict a broader set of things that, that group which was in Google

17:20.160 --> 17:24.720
or at the time were actually one of the funders of the company that I was working in doing

17:24.720 --> 17:25.720
epidemic tracking.

17:25.720 --> 17:27.640
So we're within closely with them.

17:27.640 --> 17:32.560
And this was also a problem which was very linguistic.

17:32.560 --> 17:40.040
So like I mentioned, English only makes up about 5% of the world's conversations daily.

17:40.040 --> 17:47.440
And most of the world's diseases come in the thin band of the tropics where you just

17:47.440 --> 17:50.280
correlates with ecological diversity.

17:50.280 --> 17:55.280
So most of the world's ecological diversity is in the tropics therefore most of the pathogens

17:55.280 --> 17:57.280
come from there too.

17:57.280 --> 18:02.600
That also happens to correlate with more than 90% of the world's linguistic diversity.

18:02.600 --> 18:10.320
So the first time that a language is mentioned, it's really, really unlikely to be in English

18:10.320 --> 18:13.840
or even any other dominant language.

18:13.840 --> 18:20.280
And so we can go back in time and find examples of disease outbreaks well before they were

18:20.280 --> 18:26.000
finally identified by virologists and epidemiologists as being new strains of a potential disease

18:26.000 --> 18:27.000
outbreak.

18:27.000 --> 18:28.000
Okay.

18:28.000 --> 18:32.680
So for swine flu, there are open reports in a local spanish language newspaper written

18:32.680 --> 18:36.880
in Mexico about months before it was identified as new virus.

18:36.880 --> 18:42.880
In the case of bird flu coming out of areas just outside of Hong Kong, there were reports

18:42.880 --> 18:47.960
weeks before it was identified as being a stranger of the flu.

18:47.960 --> 18:53.840
And so this is another example using crowd flower to collect information about potential

18:53.840 --> 18:58.520
disease outbreaks worldwide, you know, make sure they're real feverers, not Justin Bieber

18:58.520 --> 19:05.440
feverers, and then filter from millions of reports across 15 different languages, use

19:05.440 --> 19:10.840
a machine learning and a small number of human experts as well.

19:10.840 --> 19:16.040
So that the turnout breaks each day that mattered, whether only reports seen by the virologists

19:16.040 --> 19:20.360
out of the millies of potential reports out there.

19:20.360 --> 19:25.600
I'm wondering if you're aware of any efforts to kind of bring together a network of, you

19:25.600 --> 19:35.240
know, data scientists and machine learning AI experts to be able to help respond to emergencies

19:35.240 --> 19:36.240
as they happen.

19:36.240 --> 19:40.800
Like the, I'm not sure the specifics of how you got pulled into the, well, you got pulled

19:40.800 --> 19:48.120
into the Haiti situation based on the company you were at after, yeah, I forget how you

19:48.120 --> 19:54.720
say you got pulled into the, it was a connection at the U.S. State Department.

19:54.720 --> 20:00.600
So at that time, I was doing work on a text messages between health workers in Africa

20:00.600 --> 20:03.920
in the general language of Malawi.

20:03.920 --> 20:09.680
And when it became clear that that text messages were the only formal communication, those

20:09.680 --> 20:16.120
widely available in Haiti, I got dragged into it as really just as the only person working

20:16.120 --> 20:17.120
in this field.

20:17.120 --> 20:22.800
So unfortunately, no one has, as far as I know, tried to complete a PhD in text messages

20:22.800 --> 20:26.920
and low resource languages and health and disaster response context since.

20:26.920 --> 20:33.080
So I was, I remain the expert on that area, unfortunately, by being the only person who

20:33.080 --> 20:36.440
has looked into that kind of research.

20:36.440 --> 20:42.760
What's been very encouraging is that since that time, more than 10 years later, a lot of

20:42.760 --> 20:48.240
large companies have been moving in the direction of providing better tooling and support.

20:48.240 --> 20:54.200
So immediately before I joined, figure eight, I was running product for natural language

20:54.200 --> 21:00.760
processing and translation at AWS, so emeralds, web services, Amazon AI.

21:00.760 --> 21:07.080
And so as the product lead there, I was able to have a lot of influence and found a lot

21:07.080 --> 21:14.240
of internal support for making sure that Amazon's first suite of native NLP technology on

21:14.240 --> 21:21.600
AWS is language independent where they a clear roadmap to supporting as wide a variety

21:21.600 --> 21:23.360
of languages as possible.

21:23.360 --> 21:28.080
And I think that this is where we can see a lot of the biggest impact while I appreciated

21:28.080 --> 21:33.800
my time working for the UN and with charity organizations.

21:33.800 --> 21:39.560
I found that it's in many ways more important to make sure that you get this diversity in

21:39.560 --> 21:41.480
people's everyday tools.

21:41.480 --> 21:46.640
So the analogy I like to use is that if you go into an area after a disaster, the disaster

21:46.640 --> 21:52.640
response community are all driving turtle land rivers, right, because a turtle is a well

21:52.640 --> 21:53.640
known car.

21:53.640 --> 21:57.840
It's been tested for millions of miles before you took it into a critical situation.

21:57.840 --> 22:02.360
And there's plenty of people who know how to operate one or to repair one.

22:02.360 --> 22:05.520
And I take a similar view with software.

22:05.520 --> 22:13.520
And so software, which is specifically made for low resource health and disaster response

22:13.520 --> 22:17.600
environments, I can tend to be buggy, not well supported.

22:17.600 --> 22:24.440
And so while it's not as easy to immediately measure the impact, I think some of the greatest

22:24.440 --> 22:29.480
ways to improve the world have been in making sure that the most popular cloud platform

22:29.480 --> 22:34.680
AWS as a view to be language independent so that people can build out these tools in

22:34.680 --> 22:40.560
a well known environment, along with other work that I've done both here at Figure 8 and

22:40.560 --> 22:41.560
previously.

22:41.560 --> 22:49.640
So for example, working with a lot of manufacturers of cell phones to ensure that they give

22:49.640 --> 22:54.560
as much linguistic diversity as possible in their speech recognition systems.

22:54.560 --> 23:04.160
I think a lot of people associate Figure 8 slash crowd flower with this idea of human and

23:04.160 --> 23:05.160
loop.

23:05.160 --> 23:14.640
And I think one of the themes that has been part of our conversation around machine learning

23:14.640 --> 23:22.280
and AI is this idea that often people will put it as AI versus humans.

23:22.280 --> 23:31.200
And there has been, I think a consistent and growing set of voices that it's not AI versus

23:31.200 --> 23:34.880
humans or AI or humans is AI and humans.

23:34.880 --> 23:40.200
How is your perspective on that evolve since doing this early work?

23:40.200 --> 23:48.200
I imagine you get involved in a lot of customer activity at Figure 8.

23:48.200 --> 23:56.800
What's your take on the importance of humans in delivering machine learning and AI products

23:56.800 --> 24:01.200
and solutions and how do you see that evolving over time?

24:01.200 --> 24:06.360
Yeah, I think one of the most important problems we're solving in technology right now is

24:06.360 --> 24:11.560
working out what it looks like for humans and AI to work together on problems.

24:11.560 --> 24:17.200
This is something that we're seeing across our client base, whether it's a self-driving

24:17.200 --> 24:25.200
car company looking to get the right human feedback on the hours and hours of videos taken

24:25.200 --> 24:31.920
from their cars collecting data right through to medical imaging, what's the right way for

24:31.920 --> 24:41.040
a predictive service to identify, for example, breast cancer cells to either replace or advise

24:41.040 --> 24:46.880
the doctor right through to the use cases that I've been looking at in text where your

24:46.880 --> 24:52.920
letting humans make a decision based on large volumes of reports and the AI component

24:52.920 --> 24:55.520
is prioritizing that for a person.

24:55.520 --> 25:00.560
And so I think we're really just scratching the surface right now in the ways in which

25:00.560 --> 25:05.160
AI and humans can work together, and there's a lot more excited work.

25:05.160 --> 25:11.640
When you say more exciting work is that work to be identified or work that is being done

25:11.640 --> 25:15.120
in different places that you're specifically aware of?

25:15.120 --> 25:19.120
Yeah, I mean, we're doing a lot of exciting work right now with companies.

25:19.120 --> 25:24.440
So for example, I imagine you're a self-driving car company and you're looking to identify

25:24.440 --> 25:28.400
pedestrians on the street.

25:28.400 --> 25:33.360
If you don't have any AI systems in an incredible training data, there's going to be a pretty

25:33.360 --> 25:34.880
tedious experience.

25:34.880 --> 25:39.400
So a person might have to draw a manually draw a bounding box around every single pedestrian

25:39.400 --> 25:42.640
and every frame in hours and hours of video.

25:42.640 --> 25:44.920
And that's incredibly tedious.

25:44.920 --> 25:50.280
And most of that video is going to be empty, it's going to be people driving down freeways

25:50.280 --> 25:51.720
and then highways.

25:51.720 --> 25:58.600
And so there's at least four different ways where we're commonly introducing AI into

25:58.600 --> 26:01.360
that human annotation process at the moment.

26:01.360 --> 26:06.920
So the first is selecting what's interesting, so what's the car at the intersection and

26:06.920 --> 26:12.400
having some highway driving, but not having that be 90% of what the car is learning.

26:12.400 --> 26:18.880
And then with those bounding boxes around the pedestrians, to what extent can we pre-populate

26:18.880 --> 26:25.520
using the machine learning model and have the humans' edits accept or reject those boxes.

26:25.520 --> 26:32.520
And then automatically track those objects between frames against allowing humans to edit

26:32.520 --> 26:34.280
except then reject.

26:34.280 --> 26:39.200
And then finally, taking advantage of a lot of craft class quality control methods, how

26:39.200 --> 26:42.560
can we give the same task to multiple people to make sure that they agree with each other

26:42.560 --> 26:50.040
and errors don't propagate and then combine those different, maybe slightly overlapping

26:50.040 --> 26:52.560
boxes in the most optimal way.

26:52.560 --> 26:57.280
And so every piece of that step, selecting the right data, using predictive bounding

26:57.280 --> 27:01.800
boxes rather than having somebody manually draw them, semi-automating the tracking in

27:01.800 --> 27:06.520
videos and then combining in different human judgments into one final judgment for the

27:06.520 --> 27:11.400
training data or four of those steps using machine learning in different ways.

27:11.400 --> 27:17.320
So I think that's already incredibly exciting in terms of the ways that the humans and

27:17.320 --> 27:22.520
machines are collaborating, but at the end of the day, that's just putting a box around

27:22.520 --> 27:23.520
objects.

27:23.520 --> 27:30.520
I think the kinds of interfaces that we can develop, not even at R&D stage yet.

27:30.520 --> 27:35.200
I think this is going to be some of the most exciting advances at the intersection of human

27:35.200 --> 27:38.600
computer interaction in AI in the coming decades.

27:38.600 --> 27:44.880
And do you have any ideas around what those might look like or do you know places where

27:44.880 --> 27:47.760
folks are working on that kind of thing that you can point us to?

27:47.760 --> 27:53.400
You know what, there's no one really working on this anymore than we are right now.

27:53.400 --> 28:00.640
We're going to this out with a lot of our customers and just starting to see some research

28:00.640 --> 28:08.000
papers coming out of AI labs and human computer interaction labs, but it's really new.

28:08.000 --> 28:14.800
There's not even conferences in academia dedicated to the intersection of human computer

28:14.800 --> 28:17.440
interaction and artificial intelligence at the moment.

28:17.440 --> 28:20.960
So this is really nice and I think incredibly important.

28:20.960 --> 28:21.960
Yeah, I agree.

28:21.960 --> 28:28.320
It's something that I've been kind of mentioning and asking about and for on the podcast

28:28.320 --> 28:30.200
probably for over a year now.

28:30.200 --> 28:37.200
I think there's a book that's kind of classic in the design, the design field, the design

28:37.200 --> 28:38.200
of everyday things.

28:38.200 --> 28:41.160
I forget the name of the author.

28:41.160 --> 28:50.080
But we've built up a huge body of expertise and approaches, methodologies, senses for

28:50.080 --> 28:57.280
what works and what doesn't around design minus intelligence, just kind of design of

28:57.280 --> 28:59.280
stuff.

28:59.280 --> 29:09.200
And it strikes me that designing with intelligence, designing for devices and systems that have

29:09.200 --> 29:15.240
intelligence is its own field and we need to have people that are thinking about this

29:15.240 --> 29:23.440
stuff and researching it and kind of pushing the frontiers of our knowledge about it.

29:23.440 --> 29:29.640
I think so too and when you add in the complexity of people approaching technology on very different

29:29.640 --> 29:34.840
devices in very different cultures, speaking very different languages, there is so much

29:34.840 --> 29:42.800
out there that we are yet to even look at from an academic viewpoint that I can't wait

29:42.800 --> 29:45.280
to see more people get involved with.

29:45.280 --> 29:53.640
Yes, when you look at these, the four ways that you're looking to evolve the kind of

29:53.640 --> 30:00.440
the human AI interface from a training perspective, can you talk a little bit about what some

30:00.440 --> 30:05.720
of the most interesting technical challenges have been and how you've approached them?

30:05.720 --> 30:08.080
Yeah, yeah, absolutely.

30:08.080 --> 30:12.400
Some of them are things which we haven't seen at all before, which is somewhat surprising.

30:12.400 --> 30:20.960
So for example, combining the different people's judgments, so taking those say three different

30:20.960 --> 30:24.280
bounding boxes around a pedestrian which don't quite overlap with each other from three

30:24.280 --> 30:28.520
different workers and making sure that that final bounding box which would then become

30:28.520 --> 30:30.960
the training data is the correct one.

30:30.960 --> 30:33.240
So it turns out there's no simple heuristic.

30:33.240 --> 30:35.800
You can't take the average of those boxes.

30:35.800 --> 30:40.600
You can't take the weighted average given the past accuracy of each of those workers on

30:40.600 --> 30:48.680
the task, but you can make this a machine learning task in itself, where you have the

30:48.680 --> 30:53.600
past accuracy of those people, you have their three boxes and you have the image itself

30:53.600 --> 30:57.720
and you can give all of that to a machine learning algorithm.

30:57.720 --> 31:06.440
And so a fun way that one of our scientists set up here was to make this its own layer.

31:06.440 --> 31:11.560
So in a typical image, you have RGB, red, green and blue layers, because that's how the

31:11.560 --> 31:13.520
image is encoded.

31:13.520 --> 31:20.120
And then we treat the human, the various human identifications of boxes as additional layers.

31:20.120 --> 31:27.360
And so this was I think a really neat solution to think about new channels of information.

31:27.360 --> 31:33.120
Some human generated, some computer generated, and then allow in the machine learning algorithm

31:33.120 --> 31:38.800
to find the right combination of information to produce the most accurate result.

31:38.800 --> 31:45.680
Does it work at all to not think of these boxes as as bounding boxes per se, but more

31:45.680 --> 31:47.120
like probability densities?

31:47.120 --> 31:49.920
That's exactly what we do.

31:49.920 --> 31:54.360
That's a good suggestion.

31:54.360 --> 31:59.840
Yeah, we treat them as probability densities where those probabilities are taken from

31:59.840 --> 32:01.680
their their past accuracy.

32:01.680 --> 32:07.800
So with the figure eight platform, we have a lot of quality control measures such as

32:07.800 --> 32:14.040
making sure that people pass quizzes before they can take a task, plus embed in the known

32:14.040 --> 32:19.280
answers into tasks so that we can track someone's accuracy over time and remove them from

32:19.280 --> 32:21.480
a task if they're not accurate.

32:21.480 --> 32:27.640
And what this means is that we have fairly accurate probabilities given every single

32:27.640 --> 32:33.240
person's past work, so someone might be 70 percent accurate, someone might be 95.

32:33.240 --> 32:38.320
And so then each of those probably distributions can be represented.

32:38.320 --> 32:45.000
And then the machine learning can figure out exactly what the right densities or thresholds

32:45.000 --> 32:49.800
are to combine with the image data to produce that final result.

32:49.800 --> 32:50.800
Interesting, interesting.

32:50.800 --> 32:54.960
Anything else come to mind in terms of interesting challenges in this area?

32:54.960 --> 32:58.720
Well, like I said, I think we're just scratching the surface.

32:58.720 --> 33:05.080
And one of the things we lean on really heavily is transfer learning.

33:05.080 --> 33:10.720
So when we're helping someone do predictive bounding boxes or create their final model,

33:10.720 --> 33:15.800
we were able to do this by extending a model that's built on millions of previous images

33:15.800 --> 33:18.800
that that figure it has access to.

33:18.800 --> 33:23.560
And that gets a very high degree of accuracy, even when someone has relatively little training

33:23.560 --> 33:25.240
data to begin with.

33:25.240 --> 33:29.400
I think what's really interesting at the moment is that transfer learning has been incredibly

33:29.400 --> 33:33.880
effective with images, but not so much with language.

33:33.880 --> 33:38.200
So you can take a model learnt on everyday objects.

33:38.200 --> 33:43.360
And then if you start applying that with transfer learning to medical imaging, you get a really

33:43.360 --> 33:48.240
large head start in terms of accuracy from small amounts of training data.

33:48.240 --> 33:53.960
And if you take things which seem almost identical, so you take sentiment analysis on Twitter

33:53.960 --> 33:59.200
content in English, and then you try to apply that to sentiment analysis on your reviews

33:59.200 --> 34:03.160
in English, then that transfer learning is giving you a couple of percent increase

34:03.160 --> 34:09.200
in accuracy only, certainly not enough to make a big difference from a business standpoint.

34:09.200 --> 34:12.600
And so what do you think that is?

34:12.600 --> 34:18.920
Well, I think linguistically, it's just because language is so complex and exciting, the

34:18.920 --> 34:23.600
ways in which we will talk about food for your review, which is really different to the

34:23.600 --> 34:28.240
way we will talk about whatever it is people complaining about on Twitter.

34:28.240 --> 34:35.520
And those stylistics are enough that it's not really the same signal at all.

34:35.520 --> 34:43.600
Whereas with whether it's medical imaging or everyday objects all about satellite imagery,

34:43.600 --> 34:49.760
a 2D object with just three layers of colours has more similarities.

34:49.760 --> 34:55.000
There are 3D objects represented in two dimensions, there are colours, there are clear boundaries

34:55.000 --> 34:57.280
between objects.

34:57.280 --> 35:04.240
And so as a linguist, I find it fascinating, as a machine learning practitioner, I find

35:04.240 --> 35:05.240
it frustrating.

35:05.240 --> 35:09.600
I know a lot of smart people are working on this problem.

35:09.600 --> 35:16.800
I think some of the early results in what's been called zero-shot machine learning, machine

35:16.800 --> 35:21.720
translation, good early examples of the supplemental language.

35:21.720 --> 35:29.520
So I'm hopeful that we can get to a point where we have these models of different language

35:29.520 --> 35:35.600
tasks, which can make adapted new tasks much, much more efficient.

35:35.600 --> 35:42.200
Yeah, this keeps bringing me back to the, I guess the earlier comment or a related comment

35:42.200 --> 35:46.880
to the earlier one I made that it's, I think it's easy to look at some of the results we

35:46.880 --> 35:56.240
see around, you know, machine translation and deep neural net, language modeling.

35:56.240 --> 36:03.120
And I forget the person who made the quote, but there's a famous quote about, you know,

36:03.120 --> 36:10.080
for every linguist I fire, every linguist I get rid of, my accuracy of my models increases,

36:10.080 --> 36:15.000
talking about, you know, the advances we've made in statistical language modeling.

36:15.000 --> 36:20.240
It's interesting, in this conversation here, you, you know, reinforce the importance of

36:20.240 --> 36:27.320
the underlying, you know, linguistics and the language modeling and even within English,

36:27.320 --> 36:33.320
you know, to the extent that even within English, you know, examples from, you know, one

36:33.320 --> 36:37.520
type of communication, Twitter and another type of communication, Yelp reviews, you

36:37.520 --> 36:41.440
know, produce such different results that you can't really transfer easily between the

36:41.440 --> 36:42.440
two.

36:42.440 --> 36:49.280
Yeah, and I think we're at Westside and increasing and the importance of linguistics.

36:49.280 --> 36:52.320
I remember that adage, I think it was every time a linguist quits.

36:52.320 --> 36:58.840
I'm not sure if it was them being fired, the original quote, or maybe it was.

36:58.840 --> 37:05.840
And that's been an amazing change in terms of we really don't as much need someone with

37:05.840 --> 37:09.960
that linguistic knowledge to manually say what the features are, like this is a word

37:09.960 --> 37:13.120
boundary, you know, this is a proper noun, etc.

37:13.120 --> 37:18.360
The deep learning models can take care of a lot of that for us.

37:18.360 --> 37:22.080
And that's certainly also been a research focus for a while.

37:22.080 --> 37:26.120
So in my own research, I was trying to abstract away from specifically linguistic knowledge

37:26.120 --> 37:28.280
and resources so we could scale.

37:28.280 --> 37:33.960
But I'm thinking about some use cases here at the moment where while we don't need the

37:33.960 --> 37:39.240
linguists to extract the features, we get deep learning to that for us.

37:39.240 --> 37:43.800
Linguistic intuitions about how to set up a task can really, really help.

37:43.800 --> 37:51.120
So for one current use case, we're working with a large online retailer that also has

37:51.120 --> 37:53.320
a in-home device.

37:53.320 --> 37:58.000
And they have this problem where on their online store, there are titles, or often like

37:58.000 --> 38:02.520
40 or 50 words long, because the people putting products up there assume that a 50 word

38:02.520 --> 38:05.280
title is going to have better search engine optimization.

38:05.280 --> 38:09.400
However, that's a terrible experience if you're speaking to a device in your home and

38:09.400 --> 38:13.880
you have to listen to all 40 words and then that title to do audio shopping.

38:13.880 --> 38:16.360
And so they need to need to shorten those titles.

38:16.360 --> 38:22.680
And so making this purely a summarization task with sequence sequence models and deep

38:22.680 --> 38:26.440
learning really isn't producing very good results.

38:26.440 --> 38:30.680
The shortened titles and very natural that it look very good at all.

38:30.680 --> 38:33.040
But a bunch is a little bit of linguistic knowledge.

38:33.040 --> 38:36.560
We can see which are the important entities within the title.

38:36.560 --> 38:42.080
We have the name of the brand, the size, the color, the function.

38:42.080 --> 38:47.000
And treat this as a task where we identify those entities and then we can pile that short

38:47.000 --> 38:48.800
title from those entities.

38:48.800 --> 38:53.520
And so we were going from something about 50% of human level accuracy to now something

38:53.520 --> 39:00.000
at 90% of human level accuracy, just because we had a smart linguist analyze the problem

39:00.000 --> 39:06.240
and not have to hard code any features, but they just knew how to cast this problem as

39:06.240 --> 39:10.800
a sequence sequence problem for identifying entities rather than a sequence sequence problem

39:10.800 --> 39:13.560
for summarizing text.

39:13.560 --> 39:22.680
So I think this is one example of where domain expertise is coming back into machine learning.

39:22.680 --> 39:27.600
So a quick note, because I'm sure at least someone out there listening is going to be

39:27.600 --> 39:30.560
wondering who about this quote.

39:30.560 --> 39:36.680
The quote is from Frederick Jalenic, it's every time I fire a linguist, the performance

39:36.680 --> 39:40.720
of the speech recognizer goes up.

39:40.720 --> 39:47.440
So you are much more gracious than Frederick Jalenic in your treatment of the linguists.

39:47.440 --> 39:55.040
But I think what's interesting here is the kind of going back to this broader question

39:55.040 --> 40:04.840
of humans and AI, humans or AI, and human and the loop, there are multiple layers where

40:04.840 --> 40:19.680
AI and humans interface, there's the user, and the AI is getting, in many cases, training

40:19.680 --> 40:26.080
data from the user, the user has to use the AI in some cases, the user is configuring

40:26.080 --> 40:32.880
things that have AI in them and those have peculiarities, and so there's kind of work

40:32.880 --> 40:39.680
that needs to happen there about that user experience element.

40:39.680 --> 40:45.080
There's the folks that are creating training data, and you've talked about some of the

40:45.080 --> 40:56.000
work that you're doing in applying machine learning to that interface between the organization

40:56.000 --> 41:01.720
or entity that's collecting training data and humans that are helping to produce that

41:01.720 --> 41:05.040
training data, helping to label.

41:05.040 --> 41:11.400
And then we've talked about just now, and certainly plenty of times on this podcast, the

41:11.400 --> 41:19.400
role of domain expertise in, you know, broadly speaking data science teams that are building

41:19.400 --> 41:23.520
out machine learning.

41:23.520 --> 41:27.840
So those are kind of three places that humans are kind of in this loop.

41:27.840 --> 41:32.720
Are there others that don't fall into those three?

41:32.720 --> 41:36.920
So this, I'm numerating those three, so that would be the exit.

41:36.920 --> 41:42.680
The end uses the experts and pretzels work is doing labeling of those of three.

41:42.680 --> 41:43.680
Yeah, yeah.

41:43.680 --> 41:48.640
I'm just wondering if you guys have a model for thinking about, or if you have a model

41:48.640 --> 41:55.520
for thinking about kind of the roles, the varying roles that humans play in working with

41:55.520 --> 42:00.480
AI, and does that model, you know, tell you anything interesting?

42:00.480 --> 42:06.800
Yeah, I think we're seeing more and more tiered model of humans creating training data.

42:06.800 --> 42:12.680
So historically, when Figuert was called Crowdflower, it was because initially most of the work

42:12.680 --> 42:15.840
down the platform was CrowdSource.

42:15.840 --> 42:20.640
And Crowdflower still runs at the largest marketplace for CrowdSource workers for training

42:20.640 --> 42:21.640
data.

42:21.640 --> 42:25.440
So we have hundreds of thousands of people and more than 150 countries working on the

42:25.440 --> 42:26.440
platform.

42:26.440 --> 42:29.720
However, that's becoming a smaller and smaller part.

42:29.720 --> 42:36.120
So about a third of people using the Figuert software today are using the running

42:36.120 --> 42:37.120
tunnel experts.

42:37.120 --> 42:42.480
So they have domain expertise, whether that's in medical or financial domain, or simply

42:42.480 --> 42:45.160
sensitive data that I don't want to farm out.

42:45.160 --> 42:48.840
And while they're recognizing the importance of creating training data, they don't see

42:48.840 --> 42:54.480
this as a problem that they want to outsource, at least not for the human component, certainly

42:54.480 --> 42:56.960
they'll listen to our software still.

42:56.960 --> 43:02.920
And then we also have a very large number of, but maybe another third of workforce who

43:02.920 --> 43:06.320
are what we call an NDA crowd.

43:06.320 --> 43:09.440
So these are people who work in a center.

43:09.440 --> 43:15.000
They're often guaranteed an hourly salary, so they have job security.

43:15.000 --> 43:16.000
And they're everywhere.

43:16.000 --> 43:22.640
So that could be in New Orleans, or the Philippines, or in India, we just started to work with

43:22.640 --> 43:30.200
the UN org, hoping to provide employment for refugees in Europe as well.

43:30.200 --> 43:35.000
And the advantage of having groups of people in a room means that one, you know their identity,

43:35.000 --> 43:38.960
they can sign an NDA and see more sensitive data, and also they can be trained up a lot

43:38.960 --> 43:39.960
more.

43:39.960 --> 43:46.520
So they have the ability to understand more complicated data concepts.

43:46.520 --> 43:48.560
And so I find this to be really, really interesting.

43:48.560 --> 43:56.880
So for example, there is a center employing only women in areas of India where people normally

43:56.880 --> 44:00.560
don't get to take part in the information economy.

44:00.560 --> 44:05.640
And they're doing a lot of the work for us for self-driving car companies, which means

44:05.640 --> 44:13.040
that people whose other job opportunities would really only be in agriculture or in roadwork

44:13.040 --> 44:18.800
have learned what every single street sign means across North America, Japan, Europe,

44:18.800 --> 44:22.480
and can very quickly annotate all of those.

44:22.480 --> 44:27.720
So I find it to be fascinating because I don't know how to do these tasks, but they're

44:27.720 --> 44:34.360
able to take on this work, become domain experts, and then contribute to the training data

44:34.360 --> 44:35.360
worldwide.

44:35.360 --> 44:37.440
I think this is often very overlooked.

44:37.440 --> 44:43.360
So I read recently that someone made an estimate that there were 10,000 AI professionals

44:43.360 --> 44:44.960
worldwide.

44:44.960 --> 44:50.200
And so last year we had 60,000 people from Venezuela were alone creating training data

44:50.200 --> 44:54.320
on our platform and became very, really, really proficient at it.

44:54.320 --> 45:00.560
And so I think elevating people who are creating training data, whether that's a crowdsourced

45:00.560 --> 45:06.600
worker or an expert analyst within a company, is going to become something that we'll see

45:06.600 --> 45:11.120
more in the future as people recognize the human input component.

45:11.120 --> 45:20.240
And do you have a perspective on the kind of jobs and broader economic implications of

45:20.240 --> 45:21.240
that?

45:21.240 --> 45:25.480
Yeah, I think ultimately it'll find its way to the end users.

45:25.480 --> 45:31.120
And a lot of the software will be making sure that they can get that implicit feedback

45:31.120 --> 45:33.600
for the training data from the end user.

45:33.600 --> 45:36.600
And so we've seen this already in search engines.

45:36.600 --> 45:41.680
We do power a lot of search engines for various companies of crowdflower, but there are some

45:41.680 --> 45:45.680
like very large commercial search engines that really don't need a lot of extra training

45:45.680 --> 45:49.400
data because they get explicitly when you type something in a Google, whichever link

45:49.400 --> 45:54.960
you click on gives them that feedback as to how they should optimize their search engine

45:54.960 --> 45:59.000
for future similar search terms.

45:59.000 --> 46:03.880
And so that's the piece that's more missing at the moment.

46:03.880 --> 46:08.760
And this is where I see especially for areas like the medical domain.

46:08.760 --> 46:16.400
So there's huge debates at the moment about whether AI are going to replace physicians.

46:16.400 --> 46:21.400
And I can understand people worried about their job, but whenever I hear these arguments,

46:21.400 --> 46:26.240
I'm like, well, before I moved here to the US, the village I lived in in Sierra Leone

46:26.240 --> 46:30.320
had one doctor for every 100,000 people.

46:30.320 --> 46:35.040
And a little more than a decade later, it's still as one doctor for every 100,000 people.

46:35.040 --> 46:37.360
And that's going to be true in 10 years time.

46:37.360 --> 46:39.360
That's not really going to change.

46:39.360 --> 46:43.000
So it's economics of that nation I'm going to change that quickly.

46:43.000 --> 46:48.120
So I would love to be in a world where physicians were a seeded in idle because AI had solved

46:48.120 --> 46:49.120
healthcare.

46:49.120 --> 46:55.040
But I really don't think that's going to happen.

46:55.040 --> 47:01.960
What will happen is that that one physician will be able to scale what they are capable

47:01.960 --> 47:05.800
of working on as they are assisted by AI.

47:05.800 --> 47:10.720
And because they are going to encounter diseases or combinations of infections, which are

47:10.720 --> 47:16.760
very specific to their environment, we want to make sure that we're capturing the data

47:16.760 --> 47:22.720
in a safe but meaningful way at that point of care.

47:22.720 --> 47:27.160
So that AI that they're using can become optimized to the local population that they're

47:27.160 --> 47:28.160
serving.

47:28.160 --> 47:29.160
Awesome.

47:29.160 --> 47:31.320
I think we are about out of time.

47:31.320 --> 47:35.200
Is there anything that you'd like to add to close us out?

47:35.200 --> 47:36.200
Yeah.

47:36.200 --> 47:43.160
So I would love to invite anyone who is in the Bay Area to our train AI conference, which

47:43.160 --> 47:44.840
is in about one month.

47:44.840 --> 47:47.000
We'll be willing to it.

47:47.000 --> 47:49.840
And we have a fun keynote speaker there.

47:49.840 --> 47:58.520
So Gary Casparov, probably the most famous person to fight AI in lose, we'll be talking

47:58.520 --> 48:00.400
about his experience.

48:00.400 --> 48:04.520
And I love how positive he's become.

48:04.520 --> 48:10.600
So he is now one of the biggest advocates for chess that combines AI in humans, showing

48:10.600 --> 48:16.640
that the best chess players are combinations of humans and machines, which will consistently

48:16.640 --> 48:20.240
be both the best machines and the best humans even today.

48:20.240 --> 48:27.800
So we're looking forward to hearing about his experience and then having a large number

48:27.800 --> 48:34.880
of industry practices of machine learning, also sharing their experiences in combining

48:34.880 --> 48:36.680
human and machine intelligence.

48:36.680 --> 48:37.680
Awesome.

48:37.680 --> 48:38.680
And I will be there as well.

48:38.680 --> 48:44.680
And any listeners that are interested in attending can use the code TWIMAL to receive

48:44.680 --> 48:46.920
30% off of registration.

48:46.920 --> 48:47.920
All right.

48:47.920 --> 48:50.520
Well, Rob, it was great chatting with you.

48:50.520 --> 48:52.640
Thanks so much for taking the time.

48:52.640 --> 48:53.640
Same was my pleasure.

48:53.640 --> 48:57.640
Thanks for speaking to me today.

48:57.640 --> 48:58.640
All right, everyone.

48:58.640 --> 49:00.640
That's our show for today.

49:00.640 --> 49:05.760
For more information on Rob or any of the topics covered in this episode, you'll find

49:05.760 --> 49:11.520
the show notes at twimalai.com slash talk slash 125.

49:11.520 --> 49:16.080
If you're new to the podcast and like what you hear or you're a veteran listener and haven't

49:16.080 --> 49:21.440
already done so, please head on over to your podcast app of choice and leave us your most

49:21.440 --> 49:23.720
gracious rating and review.

49:23.720 --> 49:26.920
It helps new listeners find us, which helps us grow.

49:26.920 --> 49:29.000
Thanks in advance.

49:29.000 --> 49:32.040
Thanks again to Rob and to figure eight for sponsoring this show.

49:32.040 --> 49:37.960
And of course, make sure you head on over to figure-8 dot com slash train dash AI to learn

49:37.960 --> 49:43.560
more about the train AI conference and be sure to use code twimalai for 30% off of your

49:43.560 --> 49:45.400
registration.

49:45.400 --> 50:11.160
Thanks for listening and catch you next time.

