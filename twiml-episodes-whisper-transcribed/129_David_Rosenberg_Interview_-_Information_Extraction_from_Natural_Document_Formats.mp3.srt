1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:34,440
I'm your host Sam Charrington, I want to send a quick thanks to everyone who commented

4
00:00:34,440 --> 00:00:37,880
on and shared last week's show with Jeff Dean.

5
00:00:37,880 --> 00:00:42,120
We were super excited to share that show with you and the feedback and love you sent

6
00:00:42,120 --> 00:00:44,400
our way was amazing.

7
00:00:44,400 --> 00:00:48,760
Weeks like last are how we expand the Twimble community and get into the ears of people

8
00:00:48,760 --> 00:00:50,720
who don't know about us yet.

9
00:00:50,720 --> 00:00:57,640
All your shares, likes, tweets and retweets matter a great deal to us, so thanks.

10
00:00:57,640 --> 00:01:03,960
Before I introduce today's show, the details for April's Twimble Online Meetup are set.

11
00:01:03,960 --> 00:01:10,680
Join us on April 18th at 5pm Pacific time as Chris Butler dives headfirst into the topic

12
00:01:10,680 --> 00:01:16,000
of Trust in AI, covering a myriad of papers in the process.

13
00:01:16,000 --> 00:01:25,440
To register or for more details, head on over to twimbleai.com slash meetup.

14
00:01:25,440 --> 00:01:31,120
In this episode, I'm joined by David Rosenberg, data scientist in the office of the CTO at

15
00:01:31,120 --> 00:01:36,880
Financial Publisher Bloomberg to discuss his work on extracting data from tables and charts

16
00:01:36,880 --> 00:01:40,040
in natural document formats.

17
00:01:40,040 --> 00:01:44,440
Bloomberg deals with tons of financial and company data and PDFs and other unstructured

18
00:01:44,440 --> 00:01:47,560
document formats on a daily basis.

19
00:01:47,560 --> 00:01:52,000
To make meaning from this information more efficiently, David and his team have implemented

20
00:01:52,000 --> 00:01:55,760
a deep learning pipeline for extracting data from the documents.

21
00:01:55,760 --> 00:02:01,640
In our conversation, we dig into the information extraction process, including how it was built,

22
00:02:01,640 --> 00:02:06,960
how they source their training data, why they use Latech as an intermediate representation,

23
00:02:06,960 --> 00:02:11,320
and how and why they optimize for pixel-perfect accuracy.

24
00:02:11,320 --> 00:02:14,800
There's a lot of interesting info in this show, and I think you're going to really enjoy

25
00:02:14,800 --> 00:02:16,800
it.

26
00:02:16,800 --> 00:02:28,240
Alright everyone, I am on the line with David Rosenberg.

27
00:02:28,240 --> 00:02:34,320
David is a data scientist in the CTO's office at Bloomberg, the Financial Publisher.

28
00:02:34,320 --> 00:02:38,880
He's also an adjunct associate professor in the Center for Data Science at NYU.

29
00:02:38,880 --> 00:02:41,800
David, welcome to this week in Machine Learning and AI.

30
00:02:41,800 --> 00:02:43,800
Thanks so much, happy to be here.

31
00:02:43,800 --> 00:02:44,800
Awesome.

32
00:02:44,800 --> 00:02:48,960
It's our tradition to have our guests start by introducing themselves to the audience.

33
00:02:48,960 --> 00:02:52,800
So tell us how did you get involved in data science and machine learning?

34
00:02:52,800 --> 00:02:53,800
Yeah, sure.

35
00:02:53,800 --> 00:03:00,120
I've been interested in AI since I was a kid reading science fiction books as an elementary

36
00:03:00,120 --> 00:03:06,200
school about robots and artificial intelligence really grabbed my interest, and I guess it

37
00:03:06,200 --> 00:03:12,680
was in eighth grade, there's a summer program, and we got to build these Fisher Technic

38
00:03:12,680 --> 00:03:19,040
Kit projects that's kind of like motorized and computer controllable Lego Kit, but it

39
00:03:19,040 --> 00:03:22,040
was made by this company Fisher Technic, and I loved it.

40
00:03:22,040 --> 00:03:28,280
I thought it was a most amazing thing to be able to control a robot-like device with

41
00:03:28,280 --> 00:03:34,760
computer programming, and then a few years later, I guess in high school then, I started

42
00:03:34,760 --> 00:03:39,840
hearing about neural networks, which was my first exposure to machine learning.

43
00:03:39,840 --> 00:03:45,880
And yeah, for a project, I bought a textbook and I implemented a neural network to do some

44
00:03:45,880 --> 00:03:51,720
classification on some medical data, and yeah, frankly at the time, I didn't really

45
00:03:51,720 --> 00:03:57,000
understand very well how the neural network was working at the detailed mathematical level,

46
00:03:57,000 --> 00:04:03,400
but I had a taste of the ML framework even as like early 90s.

47
00:04:03,400 --> 00:04:08,280
That's pretty amazing that you were exposed to neural nets in high school.

48
00:04:08,280 --> 00:04:09,840
Where did you go to high school?

49
00:04:09,840 --> 00:04:13,240
I went to Montgomery Blair High School in Silver Spring, Maryland.

50
00:04:13,240 --> 00:04:17,040
It was a math science computer science magnet program.

51
00:04:17,040 --> 00:04:22,680
I don't remember how I first heard about neural networks, but somehow it came to my attention

52
00:04:22,680 --> 00:04:29,200
and found a way to special order these books that the local Barnes and Noble, and I coded

53
00:04:29,200 --> 00:04:30,720
it up in Pascal.

54
00:04:30,720 --> 00:04:31,720
Nice.

55
00:04:31,720 --> 00:04:36,040
How did you end up at Bloomberg, and what's your focus there?

56
00:04:36,040 --> 00:04:37,040
Right.

57
00:04:37,040 --> 00:04:39,080
So, yeah, two hops to Bloomberg.

58
00:04:39,080 --> 00:04:46,340
So after grad school, I moved to New York and I joined a startup company that was Tony

59
00:04:46,340 --> 00:04:51,160
Jabara, who's a machine learning professor, who's a machine learning professor from Columbia.

60
00:04:51,160 --> 00:04:53,360
Now he's at Netflix.

61
00:04:53,360 --> 00:04:58,560
I joined his startup company, we're doing a lot of spatial temporal data, machine learning

62
00:04:58,560 --> 00:05:04,680
based on spatial temporal data, and then eventually got into mobile advertising.

63
00:05:04,680 --> 00:05:12,280
So doing things like building bidders for ad exchanges, and those kind of fun problems

64
00:05:12,280 --> 00:05:15,960
that a lot of ML gets applied to these days.

65
00:05:15,960 --> 00:05:22,440
We got acquired by YP, which is yellow pages, and I stayed there for about a year or

66
00:05:22,440 --> 00:05:29,760
so, and then I looked for my next step and I ended up at Bloomberg, where at Bloomberg

67
00:05:29,760 --> 00:05:35,320
I'm in the office of the CTO, and just a small group, I think about 25 people total within

68
00:05:35,320 --> 00:05:41,880
that group, there's a five person data science group that I'm a member of, and kind of our

69
00:05:41,880 --> 00:05:49,080
task is to work on strategic projects or plan strategic projects on kind of a two to four

70
00:05:49,080 --> 00:05:50,560
year time horizon.

71
00:05:50,560 --> 00:05:56,320
Things that are a little bit too long term for any individual engineering group to really

72
00:05:56,320 --> 00:06:03,200
plan for, so we kind of make strategic initiatives and kind of point the data science part of

73
00:06:03,200 --> 00:06:06,000
the company in different different directions.

74
00:06:06,000 --> 00:06:10,840
So that's kind of the big picture, another way, another way we think about it is if some

75
00:06:10,840 --> 00:06:16,720
other company were to gain a large advantage over Bloomberg because of some new technology

76
00:06:16,720 --> 00:06:20,440
in data science that we did not pursue, that would be our fault.

77
00:06:20,440 --> 00:06:26,960
We're responsible for making sure we're not missing out on important new tech developments.

78
00:06:26,960 --> 00:06:27,960
Right.

79
00:06:27,960 --> 00:06:34,520
Can you give us some examples of the kinds of things that you're looking at, or have looked

80
00:06:34,520 --> 00:06:38,720
at the past that kind of fall into this two to four year time frame?

81
00:06:38,720 --> 00:06:40,040
Sure, I can.

82
00:06:40,040 --> 00:06:49,600
So one thing, maybe not quite so such a long term play, but when I joined maybe three

83
00:06:49,600 --> 00:06:56,760
years ago, there was a machine learning was at this interesting time where neural networks

84
00:06:56,760 --> 00:07:04,000
were starting to do very well on many tasks, but just kind of specific tasks, like certainly

85
00:07:04,000 --> 00:07:13,760
vision and some NLP tasks, but it was kind of to get into neural networks, it's a pretty

86
00:07:13,760 --> 00:07:16,320
big investment in terms of hardware.

87
00:07:16,320 --> 00:07:19,760
At Bloomberg, we don't have the ability to use the Amazon Cloud or something.

88
00:07:19,760 --> 00:07:22,000
We need to use internal machines.

89
00:07:22,000 --> 00:07:28,520
So the CTO office kind of led the movement to try out neural networks, which involves

90
00:07:28,520 --> 00:07:35,400
investing in cluster GPU machines and seeding projects with various engineering teams

91
00:07:35,400 --> 00:07:41,920
to see if neural networks was going to benefit the types of problems that we work on.

92
00:07:41,920 --> 00:07:48,160
And indeed, we have found within a couple of years that it's very important to some areas

93
00:07:48,160 --> 00:07:49,800
of the work that we do.

94
00:07:49,800 --> 00:07:54,400
So I could say that strategic, not so much because of the time horizon, but because of

95
00:07:54,400 --> 00:07:59,400
the investment required that was kind of too large for any individual engineering group

96
00:07:59,400 --> 00:08:00,400
to take that risk.

97
00:08:00,400 --> 00:08:09,080
I guess I'm curious about the evolution of the use of machine learning at a company like

98
00:08:09,080 --> 00:08:10,720
Bloomberg.

99
00:08:10,720 --> 00:08:12,720
And you said, how long have you been there now?

100
00:08:12,720 --> 00:08:14,760
I've been coming up on three years.

101
00:08:14,760 --> 00:08:16,440
Coming up on three years.

102
00:08:16,440 --> 00:08:20,840
So maybe you'll have a sense of this.

103
00:08:20,840 --> 00:08:29,720
I talk to people all the time about how enterprises, large businesses kind of evolve these types

104
00:08:29,720 --> 00:08:33,360
of technologies.

105
00:08:33,360 --> 00:08:39,880
It's interesting in that there are some businesses where there are parts of the business that

106
00:08:39,880 --> 00:08:43,000
have used machine learning for a really long time.

107
00:08:43,000 --> 00:08:48,840
Like it's been baked into, you know, just core ways that they deliver their products.

108
00:08:48,840 --> 00:08:53,400
But yet and still even at those businesses, there's been like a shift over the past five

109
00:08:53,400 --> 00:08:57,840
years in the way they've thought about machine learning.

110
00:08:57,840 --> 00:08:58,840
I'm just curious.

111
00:08:58,840 --> 00:09:04,120
Like in your words, like, does any of that resonate and how have you seen that evolve at

112
00:09:04,120 --> 00:09:05,120
Bloomberg?

113
00:09:05,120 --> 00:09:06,120
Yeah.

114
00:09:06,120 --> 00:09:14,120
So, I think Bloomberg was fairly early in bringing machine learning into the product,

115
00:09:14,120 --> 00:09:16,200
which I could tell you a little bit about.

116
00:09:16,200 --> 00:09:21,600
So I think machine learning at Bloomberg was well underway, I mean, you know, there's

117
00:09:21,600 --> 00:09:26,800
close to a hundred people doing machine learning at Bloomberg before I even arrived.

118
00:09:26,800 --> 00:09:31,160
So I can't really speak to how that developed.

119
00:09:31,160 --> 00:09:38,240
But I can say that even now we're continually trying to find areas where machine learning

120
00:09:38,240 --> 00:09:44,800
can help via by automation or just kind of maybe more broadly the machine learning, just

121
00:09:44,800 --> 00:09:52,640
a good data science statistical approach to assessing new, even if it's a rules based

122
00:09:52,640 --> 00:10:00,120
method to use kind of proper methodology and assessing performance and these sorts of

123
00:10:00,120 --> 00:10:01,120
things.

124
00:10:01,120 --> 00:10:08,080
In fact, to that end, to try to see where we can leverage ML more or data science more

125
00:10:08,080 --> 00:10:13,920
at Bloomberg, another strategic initiative that is almost a year old now coming from the

126
00:10:13,920 --> 00:10:18,880
CTO department is what we're calling ML EDU, so machine learning education.

127
00:10:18,880 --> 00:10:25,440
But the purview is broader than ML, it's kind of just data science more broadly.

128
00:10:25,440 --> 00:10:37,040
And we're trying to educate people at all different levels, basically from the most

129
00:10:37,040 --> 00:10:42,680
basic understanding of the main concepts of machine learning things like the notion

130
00:10:42,680 --> 00:10:49,520
of splitting your data into training and test and notions of overfitting these fundamental

131
00:10:49,520 --> 00:10:56,520
ideas of machine learning that we have a course called ML1, which is two half days and

132
00:10:56,520 --> 00:11:00,560
it's a few hours lecture and a few hours lab where people go through that.

133
00:11:00,560 --> 00:11:05,120
And that kind of gives people just a sense of what is this ML about.

134
00:11:05,120 --> 00:11:11,800
And then we have at the other extreme we have a kind of fairly in-depth course called

135
00:11:11,800 --> 00:11:16,360
ML101, which is kind of like a master's level machine learning class.

136
00:11:16,360 --> 00:11:23,960
That's kind of fairly mathematical, but with practical end, which is learning all the

137
00:11:23,960 --> 00:11:28,840
connections between things like gradient boosting and random forest and L1L2 regularization,

138
00:11:28,840 --> 00:11:31,920
kind of a standard master's level machine learning class.

139
00:11:31,920 --> 00:11:33,840
And we're trying to fill in everything in between.

140
00:11:33,840 --> 00:11:42,560
So how to manipulate data, explore data, visualize it, how to do basic statistics, things like

141
00:11:42,560 --> 00:11:49,200
AB testing, hypothesis testing, confidence intervals, and then machine learning, predictive

142
00:11:49,200 --> 00:11:50,200
theory.

143
00:11:50,200 --> 00:11:51,200
Awesome.

144
00:11:51,200 --> 00:11:55,800
I am shortly going to be jumping on a plane to head out to the Bay Area for the GTC

145
00:11:55,800 --> 00:11:56,800
conference.

146
00:11:56,800 --> 00:11:57,800
Yeah.

147
00:11:57,800 --> 00:12:03,760
And you will too, probably not before me since I'm getting on a plane in a few hours.

148
00:12:03,760 --> 00:12:10,440
But you're going to be presenting there on what is presumably one of these projects within

149
00:12:10,440 --> 00:12:15,280
the CTO's office, data science team that you've been working on.

150
00:12:15,280 --> 00:12:17,200
Can you tell us about that?

151
00:12:17,200 --> 00:12:18,200
Sure.

152
00:12:18,200 --> 00:12:19,200
Sure.

153
00:12:19,200 --> 00:12:24,160
So the title is information extraction for natural document formats.

154
00:12:24,160 --> 00:12:28,880
So natural document format, to my knowledge is not really a common terminology, but we

155
00:12:28,880 --> 00:12:30,120
encountered a lot of Bloomberg.

156
00:12:30,120 --> 00:12:37,720
And what we mean by that is a document that was designed for easy human consumption and

157
00:12:37,720 --> 00:12:42,800
comprehension, things like a word document, a PDF document.

158
00:12:42,800 --> 00:12:47,160
And in particular, what we have in mind for the projects I'll be speaking about is where

159
00:12:47,160 --> 00:12:53,160
some kind of, there's some kind of underlying data that is represented or that are represented

160
00:12:53,160 --> 00:12:58,720
in this natural document format in a way that's just fine for a person to comprehend, but

161
00:12:58,720 --> 00:13:06,520
is not easy at all to extract that data back out into say a database or an Excel spreadsheet

162
00:13:06,520 --> 00:13:08,000
or something like that.

163
00:13:08,000 --> 00:13:11,720
And this is a problem that we have a lot of at Bloomberg.

164
00:13:11,720 --> 00:13:12,720
A Bloomberg.

165
00:13:12,720 --> 00:13:17,120
So an example of this might be like a chart or graph or something like that.

166
00:13:17,120 --> 00:13:18,120
Is that the?

167
00:13:18,120 --> 00:13:19,120
Absolutely.

168
00:13:19,120 --> 00:13:20,120
Yeah.

169
00:13:20,120 --> 00:13:28,520
So a scatter plot, a pie chart, a bar chart, or a table, a table of numbers, a table of

170
00:13:28,520 --> 00:13:35,080
all things, you think should be very easy to extract the data out into an spreadsheet

171
00:13:35,080 --> 00:13:40,360
or a database or something, but when a table is just represented in a PDF document in the

172
00:13:40,360 --> 00:13:45,880
middle of a, say, company filing, Bloomberg collects all these documents from other companies,

173
00:13:45,880 --> 00:13:49,080
things like company filings and these sorts of things.

174
00:13:49,080 --> 00:13:55,320
And we, these documents that they deliver in a PDF format typically has important data

175
00:13:55,320 --> 00:14:01,280
in it that we need to extract that it's easy for our Bloomberg's customers to use to

176
00:14:01,280 --> 00:14:02,520
get to.

177
00:14:02,520 --> 00:14:08,920
And so traditionally, I think almost since the founding of the company 30 years ago, there's

178
00:14:08,920 --> 00:14:14,880
been a whole organization within the company called Global Data where it's people's jobs

179
00:14:14,880 --> 00:14:20,880
to figure out the most efficient and most correct way to extract this information from

180
00:14:20,880 --> 00:14:21,880
the documents.

181
00:14:21,880 --> 00:14:28,320
And there's, I can't say exactly how much, but certainly at least hundreds of people

182
00:14:28,320 --> 00:14:32,920
working on these problems, not necessarily, and it's been going on for 30 years.

183
00:14:32,920 --> 00:14:37,080
So it's started off mostly by hand.

184
00:14:37,080 --> 00:14:43,000
And a big effort over the years has been to see how to automate this as much as possible

185
00:14:43,000 --> 00:14:45,680
or make it more efficient for the people doing it.

186
00:14:45,680 --> 00:14:47,760
That's kind of the business driver.

187
00:14:47,760 --> 00:14:54,320
In this particular scenario, I kind of thought this was a solve problem like for 10 years

188
00:14:54,320 --> 00:15:04,680
now, I thought that financial filings, I forget where, I thought there was the development

189
00:15:04,680 --> 00:15:11,760
of some standardized XML formats that were used for S1s and all these financial filings

190
00:15:11,760 --> 00:15:12,760
now.

191
00:15:12,760 --> 00:15:17,760
It sounds like that it's, I know that maybe the largest companies kind of submit their

192
00:15:17,760 --> 00:15:22,920
things via these XML formats, but there's still a ton of traditional documents flying

193
00:15:22,920 --> 00:15:24,640
around with this information.

194
00:15:24,640 --> 00:15:25,640
They're sure.

195
00:15:25,640 --> 00:15:30,720
And maybe it's a letter to shareholders that is not necessarily regulated.

196
00:15:30,720 --> 00:15:33,760
There's no requirements on a format to use.

197
00:15:33,760 --> 00:15:36,520
And we kind of want to get as much data as we can.

198
00:15:36,520 --> 00:15:41,600
And even if the US were to go in a certain direction, there's still all the other countries

199
00:15:41,600 --> 00:15:44,840
that may or may not have these requirements.

200
00:15:44,840 --> 00:15:51,440
And so, yes, in some sense, perhaps someday everyone will kind of publish all their,

201
00:15:51,440 --> 00:15:56,760
any data that show up in any inconvenient document will be paired with a, you know, some

202
00:15:56,760 --> 00:16:00,360
kind of standard XML format, but we're surely not there yet.

203
00:16:00,360 --> 00:16:01,360
Interesting.

204
00:16:01,360 --> 00:16:04,360
So, tell me about the approach you're taking with us.

205
00:16:04,360 --> 00:16:05,360
Sure.

206
00:16:05,360 --> 00:16:09,960
So, there's kind of three different tasks that I'll be talking about.

207
00:16:09,960 --> 00:16:14,400
One of them is as far as extracting data from tables that show up in documents.

208
00:16:14,400 --> 00:16:20,800
And the first task there is to just find the tables in the PDF documents.

209
00:16:20,800 --> 00:16:27,720
So for that, we're using fairly off the shelf image detection methods.

210
00:16:27,720 --> 00:16:34,320
The same thing as you would use to find a CAD or a kite or whatever it is in an image.

211
00:16:34,320 --> 00:16:38,600
One advantage that we have is because we've been solving this problem by hand for so

212
00:16:38,600 --> 00:16:42,520
many years, we have a tremendous amount of labeled training data.

213
00:16:42,520 --> 00:16:46,760
And so now we're able to leverage that to build models.

214
00:16:46,760 --> 00:16:54,240
And one interesting aspect we have is we need, we basically can't afford to automate unless

215
00:16:54,240 --> 00:16:58,520
the performance will be at least as good as the humans.

216
00:16:58,520 --> 00:17:03,320
And so before we're willing to cut a human out of the loop completely.

217
00:17:03,320 --> 00:17:08,400
And so in fact, we've done that for this relatively straightforward problem of at least

218
00:17:08,400 --> 00:17:13,200
for some kind of sub-problems of finding charts and documents.

219
00:17:13,200 --> 00:17:18,840
We've been able to exceed human precision and recall, which was great.

220
00:17:18,840 --> 00:17:26,040
And then the downstream tasks of actually extracting the numbers from the table use some

221
00:17:26,040 --> 00:17:28,360
other techniques for.

222
00:17:28,360 --> 00:17:32,760
And so that's the second thing that I'm going to talk about in the presentation, which

223
00:17:32,760 --> 00:17:35,120
is a little bit futuristic.

224
00:17:35,120 --> 00:17:39,960
It's not something that we kind of, it's purely research right now.

225
00:17:39,960 --> 00:17:44,080
That's not something we're planning to productize anytime soon because it's kind of a long

226
00:17:44,080 --> 00:17:45,280
path.

227
00:17:45,280 --> 00:17:50,480
But we were inspired by this image captioning work that started a few years ago where you

228
00:17:50,480 --> 00:17:56,760
could show a picture of a man crossing the street and what it would produce using an image

229
00:17:56,760 --> 00:18:02,120
to sequence model the sentence man crossed the street or something like that.

230
00:18:02,120 --> 00:18:07,840
And the idea was like boy, if we could feed in a page of a document and have it output

231
00:18:07,840 --> 00:18:15,960
directly in one step kind of a well-structured XML or JSON or standardized formatting of

232
00:18:15,960 --> 00:18:21,200
all the content in that kind of picture of the page or the document wouldn't that be great

233
00:18:21,200 --> 00:18:23,920
then you could because that's so much easier.

234
00:18:23,920 --> 00:18:28,880
That's so there's so much you can do with that downstream as far as automated processing.

235
00:18:28,880 --> 00:18:33,360
It's hard to begin if you just have kind of a raw PDF, the format, if I could show

236
00:18:33,360 --> 00:18:40,400
you the format of the internal PDF or even a parsed PDF is not very easy to extract the

237
00:18:40,400 --> 00:18:42,880
structure from.

238
00:18:42,880 --> 00:18:46,600
So for that problem, so how are we going to apply image caption to this sort of thing?

239
00:18:46,600 --> 00:18:55,400
So I partnered with a student from Harvard, Yun Tian Dang who had this really cool work

240
00:18:55,400 --> 00:19:02,680
a year or two ago with Sasha Rush and some others was to convert a picture of an equation

241
00:19:02,680 --> 00:19:08,520
of mathematical equation that was generated by latex which is kind of mark up for making

242
00:19:08,520 --> 00:19:12,720
equations and scientific documents.

243
00:19:12,720 --> 00:19:18,760
And to go from the image and reproduce latex code that you would need to generate that

244
00:19:18,760 --> 00:19:19,760
equation.

245
00:19:19,760 --> 00:19:20,760
Interesting.

246
00:19:20,760 --> 00:19:25,920
You can see as kind of a simple version of going from the image of something to a structured

247
00:19:25,920 --> 00:19:32,280
representation of kind of the underlying information in the picture that you could then do further

248
00:19:32,280 --> 00:19:34,080
information extraction on.

249
00:19:34,080 --> 00:19:38,960
So we wanted to adapt that idea to this problem of information extraction from tables.

250
00:19:38,960 --> 00:19:44,720
So given the image of a table, that was, and we're restricting here to kind of somewhat

251
00:19:44,720 --> 00:19:49,520
of a toy problem where we assume the table is generated from latex in the first place

252
00:19:49,520 --> 00:19:51,560
from a latex document.

253
00:19:51,560 --> 00:19:58,760
And so the problem is can we regenerate the latex code that would reproduce that table exactly,

254
00:19:58,760 --> 00:20:01,040
kind of pixel level, exact.

255
00:20:01,040 --> 00:20:03,360
And so that's another thing I'll be talking about.

256
00:20:03,360 --> 00:20:05,920
We had a fairly impressive results for that.

257
00:20:05,920 --> 00:20:10,240
The kind of the exact match rate isn't so high, and it's 40%.

258
00:20:10,240 --> 00:20:14,240
But the errors are even when it makes errors that are pretty minor.

259
00:20:14,240 --> 00:20:19,160
So this seems like an interesting line of work that we're saying.

260
00:20:19,160 --> 00:20:23,800
And the last thing was extracting data from scatter plots.

261
00:20:23,800 --> 00:20:29,560
So in a document, they'll offer me scatter plots or plots containing information.

262
00:20:29,560 --> 00:20:34,600
And we found ourselves once or twice with the ruler trying to figure out exactly what points

263
00:20:34,600 --> 00:20:38,880
are represented in this chart, lining up the point with the axis.

264
00:20:38,880 --> 00:20:39,880
Right.

265
00:20:39,880 --> 00:20:40,880
Right.

266
00:20:40,880 --> 00:20:46,520
It seems like, boy, this should be automatable with all the computer vision technologies

267
00:20:46,520 --> 00:20:48,040
we have now.

268
00:20:48,040 --> 00:20:54,440
And this was an interesting thing where we actually thought that this was close enough to something

269
00:20:54,440 --> 00:20:59,360
we could make a product out of that we kind of went straight for what's the most direct

270
00:20:59,360 --> 00:21:05,760
way to solve this problem without, you know, it's very tempting to try to make kind of the

271
00:21:05,760 --> 00:21:11,800
end-to-end solution that are, you know, so striking these days with the neural networks.

272
00:21:11,800 --> 00:21:15,360
Like for instance, the image of the table to the late echo that produces that would be,

273
00:21:15,360 --> 00:21:18,160
I consider that an end-to-end solution.

274
00:21:18,160 --> 00:21:23,400
But so we were tempted to make the input, the chart and the output just be the list of

275
00:21:23,400 --> 00:21:26,200
points in one fell swoop.

276
00:21:26,200 --> 00:21:29,760
But it seems to be a little bit too hard for right now for us.

277
00:21:29,760 --> 00:21:33,000
So we broke that down into a pipeline of steps.

278
00:21:33,000 --> 00:21:39,040
Each one of which was just using off-the-shelf techniques, start with kind of image recognition

279
00:21:39,040 --> 00:21:43,800
to find the components of the charts.

280
00:21:43,800 --> 00:21:49,920
Then we used some various heuristics to put them together and at the end, I could do a fairly

281
00:21:49,920 --> 00:21:54,880
good job of extracting the data from scatterplots and currently we're working on pie charts

282
00:21:54,880 --> 00:21:58,360
and next I guess we bar charts and line charts.

283
00:21:58,360 --> 00:22:03,320
And I mean the goal is to solve the problem in this particular case rather than to come

284
00:22:03,320 --> 00:22:07,080
up with a very kind of one shot end-to-end solution.

285
00:22:07,080 --> 00:22:08,080
Right, right.

286
00:22:08,080 --> 00:22:15,880
So the first of the problems you described was just really localizing these graphical

287
00:22:15,880 --> 00:22:16,880
the tables.

288
00:22:16,880 --> 00:22:18,920
The tables in particular or any kind?

289
00:22:18,920 --> 00:22:19,920
Tables and charts.

290
00:22:19,920 --> 00:22:20,920
Okay.

291
00:22:20,920 --> 00:22:23,360
But we were focusing particularly on the tables initially.

292
00:22:23,360 --> 00:22:25,360
Okay.

293
00:22:25,360 --> 00:22:32,480
And if you're just looking at tables and charts like I'm curious, how much of the PDF internals

294
00:22:32,480 --> 00:22:37,520
do you actually use or do you just like take a picture of the page essentially and do

295
00:22:37,520 --> 00:22:40,400
your image recognition on the page itself?

296
00:22:40,400 --> 00:22:41,560
Yeah, good question.

297
00:22:41,560 --> 00:22:47,440
So the punchline is that it can do just fine using just the picture.

298
00:22:47,440 --> 00:22:53,800
So if you treat each PDF page as a picture just render it and use that as input, that

299
00:22:53,800 --> 00:22:54,800
works just fine.

300
00:22:54,800 --> 00:22:58,760
Initially, we were concerned that it would be too hard.

301
00:22:58,760 --> 00:23:02,680
So we tried to use a part of the PDF to simplify the image.

302
00:23:02,680 --> 00:23:07,240
So for instance, we figured it doesn't really know you to know exactly what characters

303
00:23:07,240 --> 00:23:08,240
are there.

304
00:23:08,240 --> 00:23:13,240
Maybe just needs to know the character type, like letter versus number, this sort of thing.

305
00:23:13,240 --> 00:23:14,240
Okay.

306
00:23:14,240 --> 00:23:20,080
You know, render a simpler version of the page that would be easier for the object detection

307
00:23:20,080 --> 00:23:22,320
system to learn from.

308
00:23:22,320 --> 00:23:25,880
But it turns out it works just fine with the rendering of the raw.

309
00:23:25,880 --> 00:23:29,640
I mean, sometimes one works a little better, sometimes the other works a little better,

310
00:23:29,640 --> 00:23:33,480
but it can go directly from the rendered image.

311
00:23:33,480 --> 00:23:41,800
So the result of this first step is just, you know, is it like a bounding box and a label

312
00:23:41,800 --> 00:23:44,880
that says table or chart or?

313
00:23:44,880 --> 00:23:45,880
It is a bounding box.

314
00:23:45,880 --> 00:23:50,960
And it sounds, when I first heard about it, I felt like this sounds so easy.

315
00:23:50,960 --> 00:23:51,960
Why?

316
00:23:51,960 --> 00:23:55,880
I'm sure everyone's thinking that.

317
00:23:55,880 --> 00:24:02,080
And it mostly is, but the issue is that, you know, if you don't get the bounding box

318
00:24:02,080 --> 00:24:06,520
exactly right, if you leave off a column or leave off some of the header, or you don't

319
00:24:06,520 --> 00:24:11,520
properly separate the headers from the rest of the table, which is another part of finding

320
00:24:11,520 --> 00:24:16,240
the table in the first place, then the entire extraction is messed up.

321
00:24:16,240 --> 00:24:20,440
And we don't, and kind of 95% accuracy isn't really good enough.

322
00:24:20,440 --> 00:24:24,080
So it's always about the, again, if I had pictures, I could show you some.

323
00:24:24,080 --> 00:24:29,240
So at the, if you go to the presentation, we could show you some really weird looking

324
00:24:29,240 --> 00:24:33,240
tables that heuristics just will fail on.

325
00:24:33,240 --> 00:24:36,400
This is actually really, really easy for me to visualize.

326
00:24:36,400 --> 00:24:43,240
And the reason why is because I often use my cell phone camera to take pictures of receipts

327
00:24:43,240 --> 00:24:45,640
or pages or things like that.

328
00:24:45,640 --> 00:24:49,720
And the particular app that I use, you know, whether it's there or several that I use,

329
00:24:49,720 --> 00:24:56,280
ever notice one cam scanner as another, but these apps will try to, you know, do exactly

330
00:24:56,280 --> 00:25:00,280
what you're describing, like draw a bounding box around the document and then like use

331
00:25:00,280 --> 00:25:06,160
that to like, you know, rewarp it or straighten it and crop it from the background.

332
00:25:06,160 --> 00:25:11,520
But it is uncanny the mistakes that these things will make and how, you know, I don't think

333
00:25:11,520 --> 00:25:18,400
the accuracy is anywhere near 95% on, you know, what, you know, even if I've got the

334
00:25:18,400 --> 00:25:23,760
paper on a black notebook or something like that, like it's still seems to be a challenging

335
00:25:23,760 --> 00:25:24,760
problem.

336
00:25:24,760 --> 00:25:30,160
And, you know, it's perhaps complicated by the fact that it's running on a mobile device,

337
00:25:30,160 --> 00:25:32,000
I don't know.

338
00:25:32,000 --> 00:25:38,760
But I can certainly imagine if you now, kind of, you know, you don't even have the benefit

339
00:25:38,760 --> 00:25:43,320
of the back, the contrasting background, you've got all different kinds of, you know, shapes

340
00:25:43,320 --> 00:25:48,720
and sizes of tables and, you know, adjacency of one table to the next.

341
00:25:48,720 --> 00:25:52,920
And, you know, I can, I can, you know, I said, is it, you know, just this issue of creating

342
00:25:52,920 --> 00:25:58,280
the back, the bounding box, but as you're describing this, I can imagine all of the complexities

343
00:25:58,280 --> 00:26:00,120
associated with getting this right.

344
00:26:00,120 --> 00:26:06,680
Right. And, and you nailed one of the challenges, which is when tables are adjacent, the problem

345
00:26:06,680 --> 00:26:10,760
of multiple columns, you know, there's often two column or three column documents.

346
00:26:10,760 --> 00:26:15,880
Yeah, I, I think you appreciate the, it's harder than it sounds, it's harder than it

347
00:26:15,880 --> 00:26:16,880
sounds.

348
00:26:16,880 --> 00:26:23,000
Is this a system that you've, you've tried to, or gotten to the point of operationalizing

349
00:26:23,000 --> 00:26:26,280
it, or is this, this is deployed, this is deployment.

350
00:26:26,280 --> 00:26:33,960
So this is in, this is kind of in the pipeline, helping people, either it's assisting people

351
00:26:33,960 --> 00:26:39,800
to annotate documents, so someone will load the document, the document will be kind of

352
00:26:39,800 --> 00:26:46,440
pre annotated with a guess by this system of finding the tables, and then a human can

353
00:26:46,440 --> 00:26:49,600
approve or edit those annotations.

354
00:26:49,600 --> 00:26:54,600
And then for some classes of documents, it's just straight pass through with no human

355
00:26:54,600 --> 00:26:56,600
oversight needed with decided.

356
00:26:56,600 --> 00:27:00,520
And that was, and that was going to be my exact question like, do you, you know, are

357
00:27:00,520 --> 00:27:08,920
you utilizing a model where you identify like a, or you kind of surface when, when the system

358
00:27:08,920 --> 00:27:13,560
isn't sure to the user and allow the, you know, that human in the loop to kind of make

359
00:27:13,560 --> 00:27:18,560
the final decision when there's some uncertainty or, you know, does it have to be kind of all

360
00:27:18,560 --> 00:27:19,560
or nothing?

361
00:27:19,560 --> 00:27:24,080
It sounds like, it sounds like you are kind of doing that, you know, taking that middle

362
00:27:24,080 --> 00:27:27,400
ground where you're surfacing the, you know, where there's some ambiguity.

363
00:27:27,400 --> 00:27:28,400
Right.

364
00:27:28,400 --> 00:27:29,400
So, yes.

365
00:27:29,400 --> 00:27:36,640
So I think what one thing that you seem to be speaking about is where the system will perhaps

366
00:27:36,640 --> 00:27:41,720
based on, you know, what it sees, and it will give a measured response.

367
00:27:41,720 --> 00:27:45,520
Like, you know, I think this is the bounding box, but my confidence is low or, or they may

368
00:27:45,520 --> 00:27:48,080
give a numeric score to the confidence or something.

369
00:27:48,080 --> 00:27:51,800
And then the ones that are low confidence will be highlighted to a user.

370
00:27:51,800 --> 00:27:58,240
But we feel see for with for now is finding classes of documents that overall have a very

371
00:27:58,240 --> 00:28:06,440
high performance kind of above human level accuracy or precision recall measures.

372
00:28:06,440 --> 00:28:12,160
And as a group, those will be kind of passed through because the issue with confidence

373
00:28:12,160 --> 00:28:16,720
is that you have to trust the confidence measure, you have to trust the confidence score.

374
00:28:16,720 --> 00:28:19,880
And so that would have to be kind of assessed on its own.

375
00:28:19,880 --> 00:28:20,880
Okay.

376
00:28:20,880 --> 00:28:25,320
So, how are these classes of documents described?

377
00:28:25,320 --> 00:28:31,440
Like is it, you know, all of the, you know, S1s for a major fortune, you know, 500 companies

378
00:28:31,440 --> 00:28:37,000
all kind of look the same or all of AT&T's, S1s, we've got good performance on or that

379
00:28:37,000 --> 00:28:38,000
kind of thing.

380
00:28:38,000 --> 00:28:39,000
Right.

381
00:28:39,000 --> 00:28:40,000
Yeah.

382
00:28:40,000 --> 00:28:44,160
It's like a class of documents, like, filings of a certain type, for example, that have

383
00:28:44,160 --> 00:28:47,280
such a certain regularity to them.

384
00:28:47,280 --> 00:28:53,040
And the performance is very high that will kind of shun those to automatic pass through,

385
00:28:53,040 --> 00:28:55,880
which is to say doesn't need a human oversight.

386
00:28:55,880 --> 00:28:56,880
Okay.

387
00:28:56,880 --> 00:29:02,720
And it sounds like by implication, then when, you know, when the system's nailed a document

388
00:29:02,720 --> 00:29:09,040
class, yeah, it's confident, well, you know, aside from confidence, like it, it performs

389
00:29:09,040 --> 00:29:15,160
extremely well, like, you know, above human levels of performance on every document in

390
00:29:15,160 --> 00:29:18,920
that class, there's not a lot of variability within the class.

391
00:29:18,920 --> 00:29:19,920
Yeah.

392
00:29:19,920 --> 00:29:20,920
That's the idea, right?

393
00:29:20,920 --> 00:29:25,960
You'd like a more fine-grained certainty measure that one could leverage.

394
00:29:25,960 --> 00:29:26,960
Yeah.

395
00:29:26,960 --> 00:29:31,880
I mean, I don't know that it's like, I guess I would expect that within, even within

396
00:29:31,880 --> 00:29:37,280
a document class, there are still ambiguous situations.

397
00:29:37,280 --> 00:29:45,080
And I would expect you to want to somehow kind of surface that ambiguity.

398
00:29:45,080 --> 00:29:47,160
But you don't want to do that.

399
00:29:47,160 --> 00:29:51,720
You want it to be kind of all or nothing, and I'm really trying to get into the thinking

400
00:29:51,720 --> 00:29:52,720
there.

401
00:29:52,720 --> 00:29:54,000
Well, I, you know, it's interesting.

402
00:29:54,000 --> 00:30:01,120
I think part of it is the way our annotation system works, but the annotation system works

403
00:30:01,120 --> 00:30:02,840
at the document level.

404
00:30:02,840 --> 00:30:11,400
So a doc, maybe 10 to 50 pages, and in some sense, we either have a person annotated document

405
00:30:11,400 --> 00:30:12,400
or we don't.

406
00:30:12,400 --> 00:30:17,840
At this point, don't have a kind of page-by-page decision on whether it will be annotated.

407
00:30:17,840 --> 00:30:18,840
Okay.

408
00:30:18,840 --> 00:30:20,560
So I think that's that part of it.

409
00:30:20,560 --> 00:30:21,560
That's a bit of it.

410
00:30:21,560 --> 00:30:22,960
Perhaps an idiosyncrasy of our setup.

411
00:30:22,960 --> 00:30:23,960
Right.

412
00:30:23,960 --> 00:30:24,960
Right.

413
00:30:24,960 --> 00:30:28,520
So if you had, if you could just throw ambiguous pages on a stack and, you know, someone

414
00:30:28,520 --> 00:30:33,000
goes through those page-by-page, then that might have changed the way you approach that

415
00:30:33,000 --> 00:30:34,400
piece.

416
00:30:34,400 --> 00:30:35,400
I think that's right.

417
00:30:35,400 --> 00:30:36,400
Yeah.

418
00:30:36,400 --> 00:30:42,080
Although I think, I think being able to trust a confidence score is a interesting problem

419
00:30:42,080 --> 00:30:43,080
in and of itself.

420
00:30:43,080 --> 00:30:48,640
You know, it's, it's very, you know, most, most machine learning methods these days output

421
00:30:48,640 --> 00:30:53,400
something that you are tempted to interpret as a probability, but whether those, oh, for

422
00:30:53,400 --> 00:30:59,600
a probability of, for classification, for instance, probability of being a cat versus

423
00:30:59,600 --> 00:31:00,600
not a cat.

424
00:31:00,600 --> 00:31:01,600
Mm-hmm.

425
00:31:01,600 --> 00:31:02,600
That's sort of things.

426
00:31:02,600 --> 00:31:03,600
Right.

427
00:31:03,600 --> 00:31:07,040
But whether those probabilities are calibrated in the sense that it will actually be right

428
00:31:07,040 --> 00:31:12,280
that number of times, if, when you predict cat is, that has to be confirmed.

429
00:31:12,280 --> 00:31:17,600
That's just because a method gives a probability score doesn't mean that's actually the probability,

430
00:31:17,600 --> 00:31:18,600
I guess.

431
00:31:18,600 --> 00:31:19,600
Right.

432
00:31:19,600 --> 00:31:20,600
Right.

433
00:31:20,600 --> 00:31:26,720
There's an implicit weighting of kind of trusting that confidence versus like assuming

434
00:31:26,720 --> 00:31:35,160
that it's 100% and kind of pushing those documents through like how is, I don't have

435
00:31:35,160 --> 00:31:42,320
an intuitive feel for why that trust is any, any better than, you know, even in the case

436
00:31:42,320 --> 00:31:48,600
where you've got general high level of trust in a class, like, you might, you know, in

437
00:31:48,600 --> 00:31:54,360
that case, seems like there'd be information in a low confidence, an exceedingly low confidence

438
00:31:54,360 --> 00:31:55,360
level for a document.

439
00:31:55,360 --> 00:31:56,360
Right.

440
00:31:56,360 --> 00:31:57,360
So I think you have the impression.

441
00:31:57,360 --> 00:31:58,360
Which do we have in better?

442
00:31:58,360 --> 00:31:59,360
Yeah.

443
00:31:59,360 --> 00:32:01,120
So I guess, I guess that's all I'm saying.

444
00:32:01,120 --> 00:32:05,240
So we have a class of documents, which without any information about the individual page

445
00:32:05,240 --> 00:32:11,040
or the individual document, the overall performance will be, say, 98% precision and recall while

446
00:32:11,040 --> 00:32:13,320
human is 97 or 98.

447
00:32:13,320 --> 00:32:14,320
Okay.

448
00:32:14,320 --> 00:32:16,200
So match or exceed human performance.

449
00:32:16,200 --> 00:32:21,360
And then you're pointing out, maybe we could do even better by going page by page and

450
00:32:21,360 --> 00:32:27,640
highlighting the ones that are somewhat less certain and maybe sending those to a human

451
00:32:27,640 --> 00:32:29,920
and then we can do even better overall.

452
00:32:29,920 --> 00:32:30,920
Yeah.

453
00:32:30,920 --> 00:32:31,920
Right.

454
00:32:31,920 --> 00:32:32,920
Yeah.

455
00:32:32,920 --> 00:32:33,920
Right.

456
00:32:33,920 --> 00:32:34,920
Yeah.

457
00:32:34,920 --> 00:32:35,920
I appreciate you.

458
00:32:35,920 --> 00:32:36,920
I appreciate you putting it like that.

459
00:32:36,920 --> 00:32:40,640
It's certainly not my job to, there's often a way to do better.

460
00:32:40,640 --> 00:32:46,520
But then there are, you know, the trade offs that, you know, come with trying it with doing

461
00:32:46,520 --> 00:32:47,520
that.

462
00:32:47,520 --> 00:32:53,800
And if you've achieved a level of performance that you need for your use case, then, you

463
00:32:53,800 --> 00:32:54,800
know, great.

464
00:32:54,800 --> 00:32:55,800
Yeah.

465
00:32:55,800 --> 00:33:02,680
So for the past through the, it's not even 97, 90, it's like essentially a hundred.

466
00:33:02,680 --> 00:33:03,680
Oh, really?

467
00:33:03,680 --> 00:33:04,680
Yeah.

468
00:33:04,680 --> 00:33:05,680
Yeah.

469
00:33:05,680 --> 00:33:12,560
For the 96, 97, I think they're still good at humans.

470
00:33:12,560 --> 00:33:17,880
I could, I'm not 100% sure, I'd have to double check that.

471
00:33:17,880 --> 00:33:25,760
And so another kind of thought that I'm wondering if you are thinking about it and tracking

472
00:33:25,760 --> 00:33:36,680
is the whole kind of adversarial attack conversation and like, you use some scenario where, you

473
00:33:36,680 --> 00:33:46,400
know, a company kind of, you know, manipulates the presentation of their data to, you know,

474
00:33:46,400 --> 00:33:51,640
change the way your parser interprets their charts and tables and, you know, somehow

475
00:33:51,640 --> 00:33:54,480
affect trades of Bloomberg customers.

476
00:33:54,480 --> 00:33:57,320
Like, I'm assuming that's something that you folks are thinking about.

477
00:33:57,320 --> 00:33:59,560
I mean, that's really important.

478
00:33:59,560 --> 00:34:05,760
So there's a little bit of that we've already seen where there'll be a document that if

479
00:34:05,760 --> 00:34:09,920
you look at it to the eye, nothing unusual going on.

480
00:34:09,920 --> 00:34:17,240
But if you parse it with a PDF parser, which tries to extract the text and stuff for you,

481
00:34:17,240 --> 00:34:25,600
but what we found is some documents will put incorrect information or confusing information

482
00:34:25,600 --> 00:34:29,440
in a kind of invisible font color.

483
00:34:29,440 --> 00:34:34,160
And so when you parse it, it's very difficult to figure out what's going on if you use

484
00:34:34,160 --> 00:34:36,440
like a PDF parser.

485
00:34:36,440 --> 00:34:41,520
But we've been able to get around those because we just use the rendering of the page.

486
00:34:41,520 --> 00:34:50,840
And so if the human can't see it, I mean, it can, let me just say that the network can

487
00:34:50,840 --> 00:34:56,840
figure out what are kind of relevant colors and irrelevant colors and that sort of thing.

488
00:34:56,840 --> 00:35:06,200
But we're not protected against kind of not necessarily protected against adversarial

489
00:35:06,200 --> 00:35:12,200
images that could mess up a network, but a human wouldn't see.

490
00:35:12,200 --> 00:35:17,080
I mean, I don't know how that would work through after being printed out and stuff, I assume

491
00:35:17,080 --> 00:35:18,080
it would.

492
00:35:18,080 --> 00:35:21,720
But yeah, of course, we've seen, I assume you're talking about these pretty cool examples

493
00:35:21,720 --> 00:35:27,360
where there'll be a picture that's clearly a cat and the classifier will give it 99%

494
00:35:27,360 --> 00:35:29,520
confidence that it's a car or something like that.

495
00:35:29,520 --> 00:35:30,520
Exactly.

496
00:35:30,520 --> 00:35:31,520
Exactly.

497
00:35:31,520 --> 00:35:33,920
That's really interesting.

498
00:35:33,920 --> 00:35:39,440
We have noticed things like that happening, but it's definitely something we need to keep

499
00:35:39,440 --> 00:35:40,440
it I have for.

500
00:35:40,440 --> 00:35:41,440
Yeah.

501
00:35:41,440 --> 00:35:47,480
I like the way you describe the tricks that folks do with like kind of background colored

502
00:35:47,480 --> 00:35:52,640
text makes me think of, I just struck me that like in some ways you can think of like

503
00:35:52,640 --> 00:35:57,480
fine print and some of these things as like adversarial attacks against a human brain,

504
00:35:57,480 --> 00:35:58,480
right?

505
00:35:58,480 --> 00:36:03,720
It's like things we do to like, you know, present information so as to missly the

506
00:36:03,720 --> 00:36:04,720
reader.

507
00:36:04,720 --> 00:36:05,720
Right.

508
00:36:05,720 --> 00:36:06,720
Right.

509
00:36:06,720 --> 00:36:09,200
So the first part is identifying these tables and charts.

510
00:36:09,200 --> 00:36:16,160
The second part is then parsing the tables and you talked about, you know, some of the

511
00:36:16,160 --> 00:36:21,080
challenges associated with that as a high level over there.

512
00:36:21,080 --> 00:36:28,960
You know, where did the kind of the bulk of the work on that particular piece take place

513
00:36:28,960 --> 00:36:33,480
or were there any like major, you know, what were the major challenges that you had to overcome

514
00:36:33,480 --> 00:36:37,480
on that, the table interpretation part?

515
00:36:37,480 --> 00:36:44,120
The finding the tables part or the late tech, the late tech extraction, the reverse engineering

516
00:36:44,120 --> 00:36:45,960
the tables, I guess.

517
00:36:45,960 --> 00:36:46,960
Right.

518
00:36:46,960 --> 00:36:47,960
Right.

519
00:36:47,960 --> 00:36:48,960
Right.

520
00:36:48,960 --> 00:36:51,720
One issue is that the images are just bigger.

521
00:36:51,720 --> 00:36:59,960
There's just much more information in a table potentially than in an equation that which

522
00:36:59,960 --> 00:37:03,520
has a lot of information, but a table is just can be a whole lot of numbers.

523
00:37:03,520 --> 00:37:05,640
It could be quite large.

524
00:37:05,640 --> 00:37:13,160
And there we get into kind of memory issues with these convolutional neural networks.

525
00:37:13,160 --> 00:37:19,880
When you're training, for instance, if you have, you know, a large input image, you're

526
00:37:19,880 --> 00:37:26,880
restricted to how big a batch you can use at one time and this will slow down training.

527
00:37:26,880 --> 00:37:32,280
And so the first challenge is that these things, you know, we're taking two weeks to train,

528
00:37:32,280 --> 00:37:37,480
which is, you know, it's hard to iterate on a problem when it takes along the train.

529
00:37:37,480 --> 00:37:39,120
So we did some work at that.

530
00:37:39,120 --> 00:37:45,320
We happened to have to have received the new Nvidia GPUs at that time.

531
00:37:45,320 --> 00:37:52,080
So that had 16-bit kind of floating, 16-bit floating point capabilities which are kind

532
00:37:52,080 --> 00:37:56,000
of theoretically going to be twice as fast and you can kind of have too many weight-storted

533
00:37:56,000 --> 00:37:58,760
memory because you're only using half as many bits for them.

534
00:37:58,760 --> 00:38:04,960
So we spent a lot of time trying to adapt to this 16-bit technology so we could have,

535
00:38:04,960 --> 00:38:09,560
you know, the speed up and the kind of access to put more stuff in memory, but it turned

536
00:38:09,560 --> 00:38:13,040
out to be much harder than we thought it would be.

537
00:38:13,040 --> 00:38:18,360
There are a whole bunch of kind of technical issues when we represented our weights in

538
00:38:18,360 --> 00:38:22,160
our network with only 16 bits.

539
00:38:22,160 --> 00:38:23,720
And it turns out we weren't alone.

540
00:38:23,720 --> 00:38:30,880
It turns out this has kind of been, it's kind of a known issue at this point that you don't

541
00:38:30,880 --> 00:38:32,600
really want to store everything in 16 bits.

542
00:38:32,600 --> 00:38:36,400
You can do some calculations in 16 bits, but your weights eventually should be stored

543
00:38:36,400 --> 00:38:39,240
in 32 bits.

544
00:38:39,240 --> 00:38:43,560
So we spent a lot of time kind of working through that problem.

545
00:38:43,560 --> 00:38:51,560
And what we're working on now is, I mean, so what's the basic issue with this table to

546
00:38:51,560 --> 00:38:55,960
latex is that it looks fine, but it doesn't really work that well if you're going for an

547
00:38:55,960 --> 00:39:01,280
exact match and we're going for an exact match, you know, 40%, that's 40% correct.

548
00:39:01,280 --> 00:39:04,720
That's pretty low by any of those standards.

549
00:39:04,720 --> 00:39:10,040
The equations were kind of more up like 80% exactly correct.

550
00:39:10,040 --> 00:39:12,600
So I mean, and this is ongoing work.

551
00:39:12,600 --> 00:39:14,400
Is your measure of correctness?

552
00:39:14,400 --> 00:39:21,880
Is this like pixel, like, you know, pixel overlay or is it something else?

553
00:39:21,880 --> 00:39:24,920
So is it more information based, I guess?

554
00:39:24,920 --> 00:39:25,920
Right.

555
00:39:25,920 --> 00:39:26,920
Yeah.

556
00:39:26,920 --> 00:39:27,920
So it's not information based.

557
00:39:27,920 --> 00:39:34,680
During training time, we're just trying to maximize kind of the likelihood of the

558
00:39:34,680 --> 00:39:37,880
correct latex, but that's training time.

559
00:39:37,880 --> 00:39:43,880
But when it actually comes to evaluation, we're going for exact pixel-to-pixel match.

560
00:39:43,880 --> 00:39:44,880
So it's binary.

561
00:39:44,880 --> 00:39:46,560
You either got it exactly correct or not.

562
00:39:46,560 --> 00:39:52,120
So what that means is, the inputs the image of the table, the outputs a string of latex

563
00:39:52,120 --> 00:39:56,920
tokens, which feed that string into a latex compiler, it renders an image.

564
00:39:56,920 --> 00:40:00,920
And then we compare that image pixel by pixel to be original image.

565
00:40:00,920 --> 00:40:03,160
And if it's an exact match, it's correct.

566
00:40:03,160 --> 00:40:05,200
And otherwise, it's incorrect.

567
00:40:05,200 --> 00:40:06,960
And why do you care about that?

568
00:40:06,960 --> 00:40:09,800
Why do we care about the exact match?

569
00:40:09,800 --> 00:40:16,640
You know, why is your bar, I guess there are multiple ways to ask a question like, why

570
00:40:16,640 --> 00:40:19,440
do you care about kind of the latex representation?

571
00:40:19,440 --> 00:40:21,800
Why do you care about pixel-to-pixel match?

572
00:40:21,800 --> 00:40:27,240
You know, why is it just that you've extracted the, you know, the rows and columns of data,

573
00:40:27,240 --> 00:40:30,440
the headings, the text, the numbers, all that stuff?

574
00:40:30,440 --> 00:40:31,440
Okay.

575
00:40:31,440 --> 00:40:33,080
So there's a few things in there.

576
00:40:33,080 --> 00:40:34,080
Let's see.

577
00:40:34,080 --> 00:40:41,000
So latex, I don't care about latex per se, latex is kind of a stand-in for a structured

578
00:40:41,000 --> 00:40:45,000
representation from which it should be easy to do the things you said, extract the rows

579
00:40:45,000 --> 00:40:46,760
and columns and that sort of thing.

580
00:40:46,760 --> 00:40:55,200
So why latex, we happen to have access to a huge collection of real world latex documents

581
00:40:55,200 --> 00:40:57,120
that have tables in them.

582
00:40:57,120 --> 00:41:02,480
And so that's kind of our label trainings that we went to archive, we scraped out all

583
00:41:02,480 --> 00:41:06,600
these papers, we found almost a half million tables with the original latex.

584
00:41:06,600 --> 00:41:07,600
Oh, nice.

585
00:41:07,600 --> 00:41:08,600
Yeah.

586
00:41:08,600 --> 00:41:12,200
So I mean, we could have generated artificial tables, but it's really better to work with

587
00:41:12,200 --> 00:41:14,960
kind of real live natural data.

588
00:41:14,960 --> 00:41:19,480
So that's, that's part, that's basically how we ended up with latteque.

589
00:41:19,480 --> 00:41:22,240
Then the question, why do we care about exact match?

590
00:41:22,240 --> 00:41:29,740
And well, one reason is expedience, which is that it's easy to do and it's actually quite

591
00:41:29,740 --> 00:41:35,680
difficult to figure out how you would score something that's not an exact match.

592
00:41:35,680 --> 00:41:40,120
I mean, you could do it in the image space where you then you have this kind of, the image

593
00:41:40,120 --> 00:41:44,360
is not an exact match and then if you want to rate it by how off it is, you'd have to

594
00:41:44,360 --> 00:41:51,480
kind of do some alignment and find, it seems like a very complicated problem in itself.

595
00:41:51,480 --> 00:41:55,680
And then, and then you're asking, what about just measuring how it does a downstream task,

596
00:41:55,680 --> 00:42:01,800
which is just finding the data, like extracting the data from the latex and, you know, are

597
00:42:01,800 --> 00:42:03,920
the numbers correct or the headers correct?

598
00:42:03,920 --> 00:42:05,800
And that would be possible.

599
00:42:05,800 --> 00:42:08,800
That would, it's still very difficult to score.

600
00:42:08,800 --> 00:42:14,560
We actually have the same problem with when we're extracting data from scattered plots,

601
00:42:14,560 --> 00:42:22,960
you know, there's 60 points in the chart, the system finds 57 and the points, you know,

602
00:42:22,960 --> 00:42:30,720
have to root the amounts of error ranging from 100% to, like by celebrating back there.

603
00:42:30,720 --> 00:42:31,720
Yeah.

604
00:42:31,720 --> 00:42:32,720
Sorry about that.

605
00:42:32,720 --> 00:42:33,720
Yeah.

606
00:42:33,720 --> 00:42:39,080
Is it kind of a, awards thing going on just starting now next door to me.

607
00:42:39,080 --> 00:42:46,320
So it sounds like in both the table and the, the scatter plots, you're using the visual

608
00:42:46,320 --> 00:42:52,920
domain and visual domain accuracy is really, it's just a connection.

609
00:42:52,920 --> 00:42:59,440
Convenient intermediary for you to be able to test whether you've accomplished the goal,

610
00:42:59,440 --> 00:43:05,040
whether you're able to replicate the system and because, at least in the case of the tables.

611
00:43:05,040 --> 00:43:10,240
And I think you're doing the same thing with the, the scatter plots because the table that

612
00:43:10,240 --> 00:43:19,280
you're generating or predicting is generated via via a structured representation.

613
00:43:19,280 --> 00:43:22,880
It doesn't really matter what it is, but you happen to have training data that's

614
00:43:22,880 --> 00:43:27,160
in the tech because you're generating it via a structured representation.

615
00:43:27,160 --> 00:43:31,320
You know that, you know, downstream, you'll be able to pull the data out the way you

616
00:43:31,320 --> 00:43:32,320
need to.

617
00:43:32,320 --> 00:43:34,720
That's, that's right.

618
00:43:34,720 --> 00:43:41,160
Also, it's, it's convenience to do in the image domain, but also it's, it's hard to

619
00:43:41,160 --> 00:43:45,760
know exactly what downstream tasks we're going to want to do on the structured representation.

620
00:43:45,760 --> 00:43:51,920
And maybe there's important information in that boldface versus italics, which you might

621
00:43:51,920 --> 00:43:57,040
think isn't necessarily part of the core information of the table.

622
00:43:57,040 --> 00:44:03,560
So the harder tables to extract, a lot of that complexity comes from things like hierarchical

623
00:44:03,560 --> 00:44:10,320
column headers or row headers or cells that span multiple rows or columns.

624
00:44:10,320 --> 00:44:18,760
And this is actually difficult to represent in a, it's difficult to score the performance

625
00:44:18,760 --> 00:44:23,040
on those sorts of mistakes, like what if it didn't properly represent the cell spanning

626
00:44:23,040 --> 00:44:26,120
to column headers or these sorts of things.

627
00:44:26,120 --> 00:44:33,440
So I guess, yes, it comes down to simplicity, but also it just not being exactly clear

628
00:44:33,440 --> 00:44:38,720
how, what else we would do, how else we would score in a way that would be, you know, good

629
00:44:38,720 --> 00:44:41,480
for any possible downstream task we'd want to do.

630
00:44:41,480 --> 00:44:45,880
Yeah, now that makes it, that makes a ton of sense, that makes a ton of sense.

631
00:44:45,880 --> 00:44:52,440
Awesome. So you, in your presentation, you kind of go through these three sub projects.

632
00:44:52,440 --> 00:44:53,440
Yeah.

633
00:44:53,440 --> 00:45:01,240
Were there any closing or parting thoughts that would make a good wrap up for us here?

634
00:45:01,240 --> 00:45:08,560
Well, I guess one, one thing that people often wonder about is, what about all these people

635
00:45:08,560 --> 00:45:13,280
who are labeling documents and now are they going to be automated away?

636
00:45:13,280 --> 00:45:17,640
And we're really not worried about it, not because we don't care about people's jobs,

637
00:45:17,640 --> 00:45:18,640
we absolutely do.

638
00:45:18,640 --> 00:45:23,360
But because the people doing the labeling are actually often fairly highly trained and

639
00:45:23,360 --> 00:45:29,840
we'd, we'd love to have them working on harder and deeper problems that they'll have

640
00:45:29,840 --> 00:45:33,960
time for once the more, the problems that a computer can solve are solved.

641
00:45:33,960 --> 00:45:40,040
So, you know, questions about we can find the data and then we can flag things that are

642
00:45:40,040 --> 00:45:45,800
unexpected, then the human can go and tag the unexpected behavior with perhaps linking

643
00:45:45,800 --> 00:45:47,560
to a possible reason why.

644
00:45:47,560 --> 00:45:53,040
These sorts of things are more still human level tasks that's not clear are automatable

645
00:45:53,040 --> 00:45:59,480
in the near future and kind of automating the menial tasks will hopefully be humans

646
00:45:59,480 --> 00:46:05,160
free to do the tasks that we don't yet know how to automate and maybe are more like specific

647
00:46:05,160 --> 00:46:08,040
to needing human intelligence at least for now.

648
00:46:08,040 --> 00:46:10,600
And it sounds like in the example you gave more valuable.

649
00:46:10,600 --> 00:46:11,600
Right.

650
00:46:11,600 --> 00:46:12,600
Awesome.

651
00:46:12,600 --> 00:46:15,120
Well, David, you've been very generous with your time.

652
00:46:15,120 --> 00:46:17,240
Thank you so much for chatting with us.

653
00:46:17,240 --> 00:46:18,240
It's been my pleasure.

654
00:46:18,240 --> 00:46:19,240
Thanks so much.

655
00:46:19,240 --> 00:46:25,120
All right, everyone, that's our show for today.

656
00:46:25,120 --> 00:46:30,040
For more information on David or any of the topics covered in this episode, you'll find

657
00:46:30,040 --> 00:46:36,240
the show notes at twomolei.com slash talk slash one, two, six.

658
00:46:36,240 --> 00:46:38,760
Thanks once again for listening and catch you next time.

