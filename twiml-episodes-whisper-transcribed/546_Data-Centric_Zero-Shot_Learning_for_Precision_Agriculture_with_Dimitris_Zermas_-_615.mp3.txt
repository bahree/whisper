All right, everyone. Welcome to another episode of the Twimmel AI podcast. I am your host Sam Charrington and today
I'm joined by Demetrius Zermas. Demetrius is a principal scientist at Centera.
Before we get into today's conversation, please take a moment and head over to Apple Podcasts, Spotify, or your listening platform of choice,
and subscribe, review, and leave us a five-star rating if you enjoy the show. Demetrius, welcome to the podcast.
Hey Sam, thank you for having me. I'm really looking forward to this conversation. We'll be chatting a bit about
data center AI and in particular how it applies to your work in precision agriculture.
But before we get there, let's start like we usually do with a little bit of background.
How'd you get started in ML and AI? I'm originally from Greece and when it was growing up,
I really wanted to work with robotics, and then as I managed to get accepted for a PSD program in the United States,
I was really hoping to do robotics. But the lab I joined was doing both robotics and AI, and I was drawn to AI
more, so then that sort of changed my plans or how I was viewing myself or my future self.
And that essentially started a trajectory that led me to where I'm here today.
Awesome, tell us a little bit about Centera. Centera is a software and hardware company,
specializing in precision agriculture. We are building tools to assist agronomists and
assist enterprises that work in the business of precision agriculture or business of agriculture,
with making decisions for their crops during the growing season.
Awesome. And what kind of tools in particular, what do those tools look like? Starting from the hardware,
we are building cameras that can be mounted on small drones. We also built a drone that has
a fixed wing airplane that you can launch by hand. And then these are paired nicely with a suite
of software and analytics solutions. So we have a platform where you can upload your data and then
view the results after the analysis is done. We also create all the analysis on the images we collect,
and this can be counting how many plants have emerged. And that way you can, or the agronomists can
decide whether the seed planted was doing well or not, whether he need to re-plant or not, as well as
figuring out the general vigor and health of the crop they're growing throughout the year.
Why build all of these components? Like why build a separate drone and a separate camera
as opposed to the software part that's kind of directly impacting the agronomists?
There is a continuous hunger for improvement of productivity in the precision agriculture and
the agriculture industry in general. They want to be flying more acres or capturing data for more
acres in a smaller amount of time. We figured that by combining a fixed wing drone that can fly
for about an hour, we can cover agronomists and cover much more ground than whatever was available
in the market. We are of course supporting some well-known drone companies. I'm not going to
mention any names because as long as they capture images that are up to some specifications,
then of course the algorithm can use them. How long have you been in the company? What stage
was the company at with regard to using ML and AI when you joined?
I was informed that I recently concluded the fourth year of joining the drones in
there. Time flies for sure. When we started or when I started, the company that was barely any
analytics available. We had some simple plant counting algorithm that was sort of
struggling to expand and able to be used for different types of plants. That was something
that the company leadership wanted to fix. We wanted to invest majorly at the analysis of
the images we're capturing because that was a unique strength for the company. The ability to
be able to both capture the data and process them. That was the beginning. I think the first
employee of a data analytics group. Is plant counting still one of the major challenges that you're
working on? More broadly, what are some of the various ways that you do use machine learning there?
Plant counting is still something important and something that we're focusing on and I know
means it has been completely solved. There are always new challenges, you know corner cases
that people are asking us who can support this and that. Apart from plant counting, we are
doing other types of counting. We're counting tassels of corn at the end of the
towards the end of the growing season where counting value crops are some permanent crops like
trees, value crops like lettuce for example. The way I like to separate the different problems
we're addressing is we like to count things. We like to detect areas of images that show some
particular textures, some particular pattern. We're trying to classify images into different
classes that show some specific characteristics. We also want to be able to detect anomalies,
things that should not be there like weeds for example or a plant that is of the correct species
but is their own hybrid. For example, a corn seed that was left there from a previous year and
didn't germinate previous years just germinated by accident when it shouldn't. So these types of
problems, it's a broad spectrum of what we're seeing. Yeah, you mentioned that when you joined
and early on in the companies evolution of using ML and analytics, one of these first problems was
the counting problem and forget the exact words you used but it sounded like they were some
barely working algorithms at first. Let's dig into that evolution. What were you using at first
and what were some of the challenges that you were running into? That was the standard
tale of how we are moving our computer vision technology moves from the classical computer vision
to deep learning and the merits of deep learning and how it overtakes everything. The challenges as
everybody who's familiar with the old computer vision can tell you that you cannot create
an algorithm that can be completely autonomous in an environment that you cannot control. Lightning
the light conditions change. A cloud passes over the field when you're capturing an immense
different soil types and different regions of the country or different regions of the world.
Everything lays their own into trying to set some parameters, some thresholds in achieving your
result, your final result and that essentially forced us to start creating very complicated
algorithmic pipelines. At some point it was almost unsustainable to be able to update them or
verify that they're working tests and etc. Then the next four years ago deep learning was
the hype. We decided to start looking some ways of utilizing deep learning to do counting
to solve that problem and even from the very few initial experiments the results were
substantial. We were looking at seeing much better results than computer vision and
that was essentially the sign telling us that as much as you love classical computer vision
because that was what we were taught. It's time to change, time to update and embrace
machine learning, deep learning. That's essentially what we are doing since then.
Thinking about this move into a deep learning type of an approach, just given the company's business
which you described earlier, you have these drones, you have these camera, your drones can fly
longer than any other drones, should be easy. You've got lots and lots of images. Is that the case?
Yes and no. That's a trick question for the audience because that's what we're talking about.
Yes, yes. Having embracing the deep learning approach for sure, solve some of the problems of
having variability in the images we capture for sure. But then again, on the other hand,
one of the main problems of the successful deep learning product is that 80% of the solution is
having data, having good annotations, having a variety of annotations from different scenes.
Which essentially means that you have to take a step back before you send any images to be annotated
and make a decision on whether this image is going to add new information to your training,
or if it's going to saturate a sensory or overtrain on things that you already know,
that you already have captured in your data set. The problem of selecting which images are the ones
that need to be annotated and trained, arose, and that's another significant hard rule we need to
overcome. You mentioned that in one of the challenges with classical computer vision,
techniques was you had to create this really complicated algorithmic pipeline to deal with all
of the variability that you were seeing in your images and in the cornfields and deep learning
did help with that. But there was still an aspect of variability that was problematic for you.
Yes, and that had mostly to do with corner cases. After you go through the initial excitement
of having something that works much better, you start actually testing and looking at corner
cases and making sure that it works for you on every occasion. And what we found was that
there were, of course, areas where we could improve. We always need to detect smaller plants,
for example, but as well as being able to detect different and isolate different plants when they
are overlapping. I don't know if you have ever visited the cornfield after the first month,
month and a half, depending on the weather, it is very hard to even walk between the rows.
I can imagine trying to identify which plant is wheat and separate and between the leaves.
But at the same time, the ability to be able to do this separation is important as it can reveal
a lot of information to both people that are growing corn in a production setting as well as
the people that are growing for seed production. So the people that are growing the corn that will
be planted next year. So you've got all these factors that are introducing variability into your
data set. And you mentioned you've got these corner cases that you're trying to be able to account
for. You've got this real world problem that you're trying to solve and you can't just solve it
for the perfect case. What's the relationship between the variability and the corner cases,
I guess, in your situation? The first thing that comes to mind is the size of the database.
This is a weird problem in a sense that we have millions of images.
So in that sense, we're lucky. But at the same time, there's an imbalance in the data.
And the corner case is something that happens that does not happen frequently.
So although we have a sea of data, identifying images that have good examples of the corner
cases is stuff. So I think that's the challenge. How do you search through your data space,
identifying corner cases, identifying images that are outliers,
and then include them in a somewhat meaningful way in your main training data set.
Because there's always the fear of the danger of skewing your data one direction or the other.
And of course, it requires a lot of testing to figure out if you're doing the right thing.
But starting, but you need to start somewhere and just trying to solve the problem of,
I need somewhat a made way to tell me which images are unique or interesting.
I think the first step. So you have the millions of images. These are
kind of raw images, so to speak, off of the camera. And your first step in curating this
data set is, well, probably first you just took a bunch of images and kind of proved to yourself
that deep learning would work. But then the next step is, okay, how do we curate a data set that really
works for all the cases that you need to consider? And in order to do that, you couldn't manually go
through millions of images to identify. You essentially have to label all of your images to identify
the ones that were useful. And that is costly and expensive. And so you did what?
We tried to approach it in a couple of ways. One is the first one and more simpler in my mind is,
let's try and train a network and randomly pick images from different data sets.
And see what the performance is. So essentially, down sizing your
your these millions of images to a few thousands of images by randomly sampling.
So before we even annotate, presentation is costly. Let's do inference and see, do we get good
results or not? If we don't get good results, then the network is balanced. So we should probably
use these images, these challenging images in the data set.
So and just to make sure I understand that you've got these different data sets that represent
kind of in a discrete way some of the variability that you see in the wild. So what if we sample
kind of randomly from across these data sets that in aggregate, we're still representing
the variability that we see in the wild. And so let's train a network on that and see if that works.
Yes, but not necessarily before you even train, let's see how the current network performs
on these images across the spectrum. The sort of nice thing is that there is variability in this
problem, but there is not unlimited variability. I mean, at some point you have exhausted all of the
different soil types you would encounter. You have exhausted flying in the morning at the middle of
the day or in the evening or later in the day. So there are a few components that create,
if you combine them, create something unique, but they are finite. So it's through this sort of
brute force method you can get a good sense of what you're dealing with. After doing this to
the manual labor for a few images, then next year comes we're getting two times more images
than the previous one. And then you start asking yourself if you have actually captured all the
changes that you could actually see in the field. And if that statement holds, then you're right,
we're done, but if it doesn't, and how do I know if it doesn't? So then the next step was to do
something a little bit more sophisticated, let's say. And that's when I started reading about
zero-shot learning and clustering without a supervision. I thought that this is probably a good
area to try and implement. That would probably be an adequate solution or at least the most
sophisticated solution that would ease my anxiety of whether I captured enough data or not.
And so what does a zero-shot learning-based approach look like in your scenario?
In my case, essentially, we're talking about finding visual similarities between images.
And essentially, this happens by downsizing significantly the images we capture.
Yeah, I should have mentioned this before, but one of the unique properties of the problem is
that the images we capture are at least 3,000 by 4,000 pixels. So we're doing what I'm about
a very high definition. Images, some of them are also a wide field of view. We're going to
feed an image like that in a normal network. So downsizing significantly to something I can
be handled is step number one. And then after this downsizing, we're passing it through a network that
acts as sort of a not only code there. Essentially takes the image to the dimensional image and finds
a representation in a higher dimensional space. And by doing so, it allows the algorithm itself to
find which images are close by in that higher dimensional space and then clusters them together.
And then through this by looking at this embedding space, essentially, which is this higher dimensional
one, you can sort of find similarities between images. And what you will find may surprise you.
Because what is what are similar images for the algorithm? For us, maybe some uniformity in the
soil. The first time we tried this, the algorithm just grouped the images based on the direction
of the row. Not very useful. How do you adjust for that? How do you iterate towards an algorithm
that works? So this happens with augmentations. So what the algorithms do is that they do not have
explicit constraints between images that should look alike. It's completely unsupervised. So what
they do is that they take an image, they apply some augmentations and then they treat the augmented
image and the original image as similar. So the network is being trained through this process of
taking an image, augmenting it and then projecting it, projecting both of them in that embedding
space. And these two should be very close in the embedding space because they come from the
same image. So essentially, in order to overcome the issues of unwanted clustering or unwanted
similarity, essentially, you are augmenting so that the network learns that it doesn't matter
what direction the rows are with random rotations, for example. So the implementation you can
use is the random rotation. This means that the network learns now that the image where the rows
are perpendicular is very similar with the image where the rows are horizontal. So this misses
this characteristic of the image and looks for something else. And I'm imagining that
you alluded to this earlier, the only way you really figure out what is happening is you have to
look at the results and spend a lot of time and just kind of intuit what the network is trying to
do. By the way, this is one of the reasons why I relate algorithmic development in computer vision
because you can't see the result. So you know if you're doing something wrong. Yes, it requires
a lot of verification and reviewing. But then it is possible to get the images from the embedding
space down into 2D or you have the connection. Essentially, you know that this image is that one
in the embedding space. So you can see you can, you know, through a key means or a clustering,
you can find which are the closest neighbors. And you know, through that essentially move forward
with making informed decisions or whether what you're trying to do works or not.
Do you start with images that, you know, some smaller set of images that you know how they relate
and then look and see if they relate in the space or... Yes, definitely. I mean, you know,
it's like this unit testing sort of attitude towards the data. Yeah, and again, as I mentioned,
with having millions of images, it doesn't allow you to literally just start processing
gigabytes of data. And since most of the processing, if not all of the processing is done on the cloud,
you can imagine, you know, the hefty price will have to pay. So talk a little bit about the
result you saw with the zero shot approach. How did it work out for you? So we're still the
testing phase. So we're working with smaller data. Crop season started sometime in May. And
that means for us, stop whatever you do and make sure that the product works. So, yeah, so
through some testing, it seems to be working well. Some networks work better than others, of course.
But we have been able to identify what we are looking for, which is that we can decrease the number
of images that express some unique characteristics by about 40%. Which is great, because this means that,
you know, from, instead of annotating 100 images, now we can annotate 60. Since we're going through
a process of somewhat cumbersome and elaborate process of annotation, where 18 images seen by
two people at least, and then we need to run some
comparisons and figure out if there's an agreement scoring high enough or not, and then correct the
annotations. That's a huge time saver. And maybe should have raised this as a point more directly
earlier on, but the, you know, we, in the context of deep learning, we talk, you know, we throw
around this idea, collect more data, collect more data, collect more data, but really your ultimate
goal here, well, your ultimate goal is to produce a better product, but your intermediate goal
was not to collect more data. It was to, you know, identify less data or the right data to annotate,
so that you wouldn't get eaten alive by annotation costs. That is very true, yes. And I think that I, we
probably see that this is a direction most people are heading, even in recent research that's,
that's probably a narrative that people are trying to push. And I think it actually makes sense.
The fortunate thing about this particular problem, the counting, the plan counting is that we are
receiving the data, whether we want it or not, because people are flying, collect, collect data
for their own purposes, so they're there, so why not take advantage of it? But if you think of
how we, we will be approaching new products, then that's a game changer, because
you know, a new customer comes in and they want to count potatoes. The first thing people are asking
me is, how many, how many images do you want? And I think after asking me so many times already,
we have created some common understanding where they know they know not to ask me this question.
Because my answer is always, I don't want more images, I want a variety of images, so it's better if
you go to 10 different fields in different states and capture two images from it than giving me
1000 images from two neighboring fields, for example. And are those specific numbers to, you know, kind of
arbitrary numbers to prove your point, or is that kind of the order of magnitude that you actually
require? I would take the actual order, mind you, would be around 100. That's the typical, because
again, since they are quite large, the images are quite large, you may imagine to train the network,
you have to crop them down. So out of one image, you can generate 40, smaller ones, but we'll
actually go into training. So I think it's a substantial number, and it always depends on the
problem we're trying to solve. But I think it's an indicative number. Yeah, just to kind of
to play back, the, you know, it's a, when we think about, you know, deep learning, like that's an
astonishingly small number, what we're doing with that 100, you know, that's a 100 images across
some representative number of fields, and what you're creating with that is this embedding space
that you can then use to create automatically more, you know, a more balanced data set,
which will probably consist of a lot more images. Is that right?
The reason why this helps a lot with the creation of new products is that I can, I can quickly
identify how many more images, or in which locations or what type of images we would like to
collect more of. So, let me get these 100 images, and then through this zero-short learning,
we'll find some, we have already, we have identified a few different clusters that we expect,
you know, different light conditions, different sort of different sort of types, whether the
images are the edge of the field or not. So, these are things that we expect. So, essentially,
by doing this clustering, I know where I am short, what type of image I am short of.
So, this is sort of the first leap iteration. I get 100 images, identify what type of images I want
more, and then I send them back out to collect more of that type.
Oh, okay. So, it's not even just reducing labeling costs. Here, we're talking about,
you know, the cost of sending someone to a field and flying a plane or a drone, and, you know,
it's the whole end-to-end data collection costs, which I'm imagining is significantly more
even. Yes, it can be, especially people are busy during the growing season. So, it is, you know,
I have to be very respectful of their time when I'm asking you data. And in previous years, it was more
of a gut feeling. You know, we have seen so many images, we have seen what works or what and what
doesn't work. But now it's more specific, more targeted. I want this, you know, fly at this time,
try to get images of where, you know, the day is not cloudy. So, it gives you a lot of space
to plan. So, this last example you talk through is still a counting type of a problem. Do you see the
approach applying to a broader set of projects? Yes, for sure. The next place I would like to
spend more time is detect the weed detection. And that is also something that is significant for
the industry. And it's also a problem where the annotation is much more costly. You can imagine
what, when you're counting things, you are requesting a human annotator to click on the object you
want to count for weeds, especially when you have patches of weed. We're talking about drawing
polygons. And the polygons are a series of clicks. And that requires, you know, more concentration
from the annotator because there may be small weeds. We don't want to miss those.
Polygons are generally more time consuming than just clicking and then going to the next one.
So, this is, I think it will be a time saver for annotations there too.
And maybe one last question. More broadly, has what you've learned in, you know, this project and
this approach change how you think about deep learning problems and applying deep learning within
your space? Yeah. I mean, previously I thought that 80% of the solution is data. Now I think 90%
of the solution is data. This has, in use, some changes or demanded some changes in how we architect
the deep learning framework we're building. These are more technical changes, essentially.
So, we have a data pipeline that goes from fetching data from our main database to reviewing the
selection of images we're doing, to sending them to a couple of human annotators and then
compare their annotations and do some quality control. So, initially, the way we were doing the
fetch data from the main database was either random or I'm going to select a few images and then say
this image has weeds in it, this image has different type of soil, this image is cloudy, etc.
Now things are more automated, which means that we can process, we can make this type of decision
in season since it's automated. We can essentially assess the images we collect Monday to Friday,
we can make the assessment over the weekend and then on Monday we can start training a new
network if there are any new data we want to include. As opposed to, before that, since it was a
human intense process, we had to wait until the end of the growing season where everybody was
relaxed and free and then we could do this type of data discovery. So, yeah, there are some small
changes, essentially, with additional features that we couldn't do before. Awesome, awesome.
Well, it sounds like a very exciting project and journey and I'm super appreciative of you jumping
on and sharing a bit about what you've accomplished to me, Tris. Thank you very much, Sam. Thank you
for having me, for reaching out and I hope this, my experience has helped. I'll see if there goes.
Awesome. Thanks so much. Bye-bye.
