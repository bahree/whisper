All right, everyone. Welcome to another episode of the Twomo AI podcast. I am your host, Sam
Charrington. And today, I'm joined by Sebastian Rashka, an assistant professor of statistics
at the University of Wisconsin-Madison, as well as the lead AI educator at Grid AI. Sebastian,
I'm really looking forward to digging into our chat. We'll touch on your research, as
well as your work in ML education. Welcome to the podcast. Yeah, thank you, Sam, for the kind
invitation to be on your podcast. I'm super excited to chat about research, education, or whatever.
Yeah, you feel like chatting about today. Fantastic. Well, let's start by having you share a little
bit about your background and introducing yourself to our audience. How do you end up in machine learning?
Yeah, that is a good question. It goes back many years now, but when I was a PhD student,
I was studying computational biology. And yeah, my professor back then, she recommended me
taking this introduction to statistical pattern recognition class, which was a grad level class
in the computer science department, and really that got me hooked. And so that was mostly about
like Bayesian statistics and yeah, Bayesian methods for pattern recognition. But yeah, somehow it
clicked with me and I found it super fascinating that you can kind of like teach computers how to
recognize patterns in data. And from there on, I was just, yeah, super hooked and studying machine
learning. And yeah, then I ended up writing a book back then in 2015, Python machine learning,
joined the University of Wisconsin Medicine in the statistics department. And yeah, now at
Grid AI as a educator. So yeah, it has been quite a journey. But yeah, I'm still as much excited as
I was back then about machine learning. So there's so much cool stuff coming out too. So it's
an exciting field. Yeah, absolutely. And your work in particular around education has been
inspirational to a lot of people. I mentioned that you are a great follow on Twitter. We'll link to
your Twitter handle profile in the show notes. And when I think about your take, it kind of reminds me
of a little bit of the top down approach that like a Jeremy Howard advocates, but also with
that academic grounding of a bottom up approach. You sooner do a really good job of fusing those
together. Tell, tell us a little bit about, you know, what got you excited about the teaching aspect
of machine learning and your philosophy around that. Yeah, so yeah, it's kind of like related to what
you just mentioned, like fusing the academic approaches, let's say the mathematical details.
And then also the practical aspect. So personally, I must say I'm really I enjoy coding. I really like
programming. It's something I do for fun on the weekends and like also contributing to open
source software. But then I'm also sometimes curious about certain things how they work. So it's
like maybe coming from academia, you are like taught to investigate, to make sure you understand
everything you're using. And yeah, I'm trying to kind of bridge the gap between the two that it's
fun where you get to code things and these types of things. But at the same time, you also develop an
understanding of how these things work because they make you, let's say, more powerful in terms of,
you know, what to change and what to expect. It's kind of like a deeper level of understanding. And
I think it's also very satisfying to know what's going on when you change certain things or when
you code something up. And yeah, for teaching, that's a good point. I try also to combine the two.
It's, I mean, everyone has different preferences. But when I was taking classes, I enjoy
sometimes the mathematical details. But it's something I also, I need to learn on my own time.
It's for me very hard to sit in a, let's say, lecture and just see mathematical equations.
It's often too fast for me, even. So in that case, I try to balance it that I don't, let's say,
have slides full of equations that I kind of change it up with big picture concepts. And also,
yeah, code examples, because I think code examples are at least helping me a lot like in terms of
solidifying things I learned. And yeah, when I'm teaching at the university, I also noticed that
students like this a lot. So yeah, it is, it is a fun part. I think it's the reward. You learn
something. And then you apply it and see, well, this is actually so cool. I want to do more of it.
And then I think if you do it like this way, where you show cool examples and empower people to
develop cool applications, people will automatically be motivated to learn more details. But if you
start the other way around, if you teach people like the nitty gritty details, I think it's easy to
lose track and get bored. That happened to me like with mathematics when I was like in high school
taking math classes. I wasn't really excited about that because it was like a bunch of numbers.
I can move them around cool. But why is that useful? Why is that cool? And yeah, with coding,
you can immediately see what you can do with it if you develop like your machine learning applications.
And yet in my class, I make sure that there's a decent portion of that. So I also have these
class projects I like my students to work on, where at the, yeah, I would say middle of the semester,
the students submitted proposal, project proposal. It could be anything they are interested in.
It just has to be related to machine learning or deep learning. And then they get to work on it
for the rest of the semester, while of course taking the lectures. But I think also based on
hearing from students, that was really the fun part because at the end, they work in teams of
three. At the end, they have like the teamwork experience. They develop something. They have
something to show for us. So we also have presentations and class where the students get to talk
about their project in front of other students. And then in the end, they have, I mean, I make this
voluntary because I don't want to force anyone, but they can share the project that's there on GitHub
publicly. And a lot of students like that because then when they apply for jobs, they can actually show
where they apply that can show, okay, I've actually done something cool here with machine learning.
I know how it works. I mean, of course, you can't expect in a semester to build
like this huge AI system, but it is at least something cool. I mean, there were so many cool
projects in the last couple of years that I've seen. I was really impressed. And I think
it's fun for me to see all of that, but also fun for the students to, yeah, um,
practically work on that and develop their skills. So yeah. So that's my approach to teaching
basically. I make sure, well, I want to make sure that students also get this practical experience
because I think it's also very important and motivating. Do you think about it from a pedagogical
perspective or is this just kind of how it all naturally came together for you? I'm not that good
at, let's say, reading literature in education and figuring out what is the best approach to teaching.
For me, I mostly go with gut feeling. Honestly, how I do these things is really, I'm thinking about
what do I like? How do I like, let's say, consuming information? Is this too much math? Is this
too much code? Is is that the right balance? Would I be excited about this? And it's basically just
that like being myself motivated and excited and then just going with it. That's awesome. That's
awesome. You did a workshop or participated in a workshop teaching machine learning at ECML
last year and did a session deeper learning by doing integrating hands-on research projects into
a machine learning course. And it sounds like that in some ways, you're sharing all the things that
we just touched on your experiences teaching. Are there for folks that are putting maybe putting
together courses? Are there interesting things that you've learned about how to integrate projects
in? Are there things that don't or is it more about be sure to focus on and include practical
hands-on projects versus not? I think this is one approach of doing it, but it's maybe not the
perfect approach. But one, I would say, one downside of a project is that if you imagine students
taking the first machine learning class or deep learning class, they don't know what you can do
with machine learning. So the one challenge I found is, yeah, you ideally want to have more time
so that students can work on the project more. I mean, let's say stretching it all out over the
whole semester, but then the problem becomes that if people have not encountered machine learning
or have learned about machine learning, it's hard for them to propose a project centered around
a machine learning because at that point they may not know what's feasible or not. So in this
proposal that I make them submit at this middle of the semester, I also give them feedback. But yeah,
it is the middle of the semester where it's kind of like a little bit late. And then also one downside
is that they haven't seen all the methods yet that we get to cover in class because the class
still goes on. But despite that, I mean, these are little downsides. I think there are lots of
upsides where people really get to, yeah, get to use the methods that you learn about. And
here I find also it's helpful to have homework examples where students get like also
understand the details where in the beginning, it might be harder to really develop a machine learning
that's a pipeline from scratch because if you're new to it, there are so many things to think about.
So what I found works well is providing template code and then leaving out let's say core parts
of the code. Like, for example, here we have the framework of a model at another, let's say,
activation function or something like that, something little small. And the students will think about
these things like how to do that, but then also have these templates that they can reuse and
let's say their class projects as a framework. So I think this is helpful to provide students with
ample examples like frameworks, frameworks in terms of code that is self-contained, it works.
Of course, they will adopt that for their project, but at least something to help them so that
they don't have to do everything from scratch. Because I think this is one intimidating thing about
machine learning. There are so many tools and so many frameworks, especially for deep learning,
that it's a lot of code and it can sometimes be a little bit overwhelming. And then kind of like
managing that by showing a lot of examples and yet providing templates, I think, helps.
What do you find is most challenging for folks just getting started with machine learning?
For people who want to use machine learning, one challenge is how do I get my data into this
machine learning model? I mean, there are, of course, there's machine learning and let's say the
non-neuronetwork deep learning part, where these are also two different cans of worms, but
the second learning on the surface looks very simple, very simple to use. It's like a few lines
of code where you can fit your classifier, but I think the main challenge is really preparing your data.
Especially if you don't want to do something like iris floor classification. I think the
biggest challenge is students have so many cool ideas for their class projects, but then it's
always about how do we make sure this data is the right format for machine learning classifier.
For example, if we are using second learn, this is usually a tabular data set, so we make sure
we have class labels and then also the columns, the feature columns. And for deep learning, okay,
it's a little bit more, I would say raw where you can work with image data directly or text data,
but still thinking about how to organize your data that is one challenge, I think.
In chatting earlier, you emphasize, you really take a lot of care to make sure you walk through
kind of classical machine learning before diving into deep learning. Talk a little bit more about
that and your experience is there. Yeah, that is a good point. So in my book, it's a pretty long book,
so it could have been two books almost. So it is a thick book. Yeah, we'll keep you busy for a while,
but it is essentially, you can think of it as two books, a machine learning book where you get to
learn about the basics of machine learning, model evaluation, hyperparameter tuning, all the basics
in the context of psychic learn and tabular data sets. And then the second half, I think chapter
11 or 12 is the turning point where I explain how to implement a neural network from scratch using
NumPy and then from that, it starts with the deep learning parts. And yeah, so I feel like, okay,
this could have been two books, but nowadays, I think this deep learning is so powerful and so
let's say exciting that a lot of people sometimes forget that there is also non-deep learning
machine learning where I think there's still a place for that if you especially look on Kaggle,
a lot of competitions are still won by XGBoost, which is a grade in boosting classifier for tabular data.
And honestly, I would rather say it should be kind of like, I mean, machine learning is still
like the non-deep learning part a good baseline, but also depending really on your data set,
how much data do you have and what format your data is, you want to use one approach over the other.
For example, for smaller data sets or tabular data sets, machine learning might be, let's say,
the way to go, whereas for a large image data set, you may want to go with deep learning,
but still you could apply a machine learning classifier as a baseline, like logistic regression
or something like that. So in that case, with that book, having both machine learning and deep
learning in there, I think it is kind of like a reminder to people, hey, it's not always about
deep learning, also consider, let's say, sometimes machine learning make, making sure that people who
say have their first encounter with machine learning and deep learning, that they know the big picture
basically, that there is more than just new networks also. You mentioned earlier just the proliferation
of frameworks in ML and DL. Do you, how do you advise folks when they're thinking about projects,
you know, where to start, what frameworks and tools choose that kind of thing? Oh, yeah, there is
also a big question. I think, I mean, again, there is no right or wrong, I would say there are
just different tools for different tasks. Personally, I started with, actually, I implemented a lot of
things from scratch because this is with learning experience, but in the real world, I advise people
to use something that is well supported, well developed because it's not only about, let's say,
having it back free or error free, but also about efficiency. So, and there are also, if you use
something that is out there, there's also usually a wider ecosystem and a community that you can
ask for questions and help, which I think is also very important because nowadays, there are
millions of algorithms and it's hard to find sometimes which one is, let's say, the right one,
and sometimes just asking people, chatting about it is helpful. And yeah, for regular machine learning,
that is not deep learning, I would advise scikit-learn still. I think it's the, maybe most mature
library out there. People in my department may disagree because my department is small, let's say,
R based the language R, but I personally, I think going with Python, if you want to do machine learning
or deep learning is the way to go. So, one consideration is, yeah, which programming language,
I think nowadays, 95% also is done in Python. And then, scikit-learn for machine learning,
and deep learning becomes a little bit trickier because we have a lot of more frameworks out there.
So, back then, I remember my first book, I covered Ciano, which I think is still around the people
at PMC3. I think they adopted it and still maintain it. But I don't think people use it for
deep learning anymore. So, I think it was like 2000, might be 15, 16, where TensorFlow came around,
which is maybe the first big breakthrough library for deep learning, where it became really,
really popular. And then, yeah, there were other libraries like MXNet, Chainer, and so forth,
and then eventually PyTorch in 2017. And I think nowadays, when I look at the trends on
papers with code and just reading research papers and looking out there, I feel like I would say,
like 80% now is a PyTorch. And I would say with PyTorch, it's a two-edged sort. It's a little bit
more verbose, let's say, then carous. But at the same time, for me, it makes me more productive
in my research. I wouldn't say it's necessary better for everything, but I feel like personally,
it strikes a nice balance between giving you all the tools you need, but giving you also some
control over what you're doing in case you need to modify something. Because, yeah, in my research
projects, unless it's just an application, I sometimes want to develop my own custom layer,
like a custom output layer or custom loss function. And PyTorch is very fast for that. And it is
a little bit, I would say, more low level. So there are also other APIs on top of that,
and there are a lot of APIs on top of that. But in general, I would say for deep learning,
I would personally recommend a PyTorch. I don't know this.
Yeah, it's interesting that you mentioned our, I don't think I've covered our a lot on the podcast,
but we did have this really awesome panel that we did that was exploring what's the best
programming language for machine learning. And we had representatives from, like, I think,
eight, it was like closure and JavaScript and Swift and Scala and Julia. There's certainly a ton
of different, what you can do, you can do machine learning and a lot of different languages.
And starting with what you know is always a good place or not a bad place at least, but the
Python ecosystem is certainly very strong. If I don't, if you don't mind, I can tell you two
anecdotes. So personally, so the first thing is when I was a student back then, I also started
with R before I started Python. And I was doing most of my statistics stuff and plotting in R.
And then I ended up in the computational biology context. I ended up having to process some custom
data. And that's where I learned Python just for the data wrangling. I learned a little, a
lot of, I learned about Pearl, but Pearl was a little bit unwieldy for me. So I heard Python is
the hot new thing. So I learned Python. And I was writing these really weird scripts. I had
like a batch script that was calling Python for processing the data and then ingesting it into R
to make the plots. So for a long time, I just used R for making plots, but the rest wasn't Python
and then eventually I switched. But one thing you mentioned is about also deep learning and machine
learning in R. I was recently at a seminar at our university where there was a talk on, it was
in general about like a machine learning industry. And the person also presented, I don't want to say,
like names or anything, but it was kind of funny. It was like more like a fun thing. The person
mentioned that they were training model in TensorFlow. And they had presented the results in a
conference in an R related conference. And I was like, how does, wait, you trained this model
in TensorFlow, but you presented in the conference that is related to R. How did you do that? And then
the person said, basically, don't tell anyone, but I actually, I used just the API. I did it in
Python and just use the R API or something like that so that it can be submitted to the conference.
But it was another hood basically a TensorFlow and Python and stuff like that. Now I see why you
were naming names. It was kind of funny though. It's like, I mean, R is still, I mean, I think it
has its place for sure. I think it's very user friendly, especially for statistics. And as soon as
you need to do some, I don't know, just hypothesis testing and statistics, there is of course stats
models, but it is just so many extra steps. And I feel like R comes with a lot of batteries included
when it comes to statistical modeling. So I think it definitely has its place. And of course,
like you mentioned, Julia, I also have a few colleagues who work in Julia and my colleagues
who use Julia, they really love Julia. It's like, I think that's, it's a really nice language.
It's just for deep learning. I think it hasn't caught on yet. And I think it's maybe like a
chicken egg problem where you don't have the community in Julia for deep learning. And without
the community, you don't have, let's say, the libraries that are working on frameworks and
yeah, I think I mean, it's possible for sure. And another name I don't want to mention, but I was
on a committee, a PhD committee, and the student did some research on deep learning, like developing
some custom methods and was using Julia for that. And in the end, the student mentioned to me, I
wish I had used PyTorch because it made certain things more elegant if you wanted to do things
from scratch because you have this array type in Julia and so forth. But overall, just the leg of
the framework, I think they have a library. I forgot the name. It's not blocks. I forgot the name.
But it is not as mature, let's say. And then once you want to compare your methods to other
methods, you bump into problems because yeah, you can either compare across languages or you have
to re-implement everything. And I think that is also one important consideration you want to maybe
look at what other people are using, not because you want to copy them, but you want to maybe also
compare your methods, especially if you want to develop a new research method. It's good to have
something out there that is also useful to other people. So if let's say other people you are
using your framework, it's a higher benefit for the community if you contribute it in that
language. But then also if you want to make sure you make progress in research, it's easier to
compare. If you make a small change to the loss function, it is easier to compare that to the
reference in the same framework compared to let's say another framework because then you don't know,
is this because of numerical approximation? Is it due to something else's improvement? So yeah,
I think there's a lot of benefits going with what everyone else is using, although
I usually try to do something different just because it's exciting, but there are definitely
benefits, yeah. Maybe a little bit more about the book, have you, did you find a way to incorporate
this idea of projects into the book? That is a good question. Unfortunately, no, there are only like
more like toy projects. The problem is, I think it's really hard to do. I mean, there have been some
great, not necessarily machine learning books that I'm thinking of, but just computer programming
books that the ones that I like are the ones that I like the most are the ones that kind of take this
longitudinal project approach and it kind of flows from the beginning to the end and adds,
you know, each chapter will add on to the project, but I've got to imagine that that's really,
really difficult to do. Yeah, yeah. Now that you mentioned it, I remember, I was last year reading a
book, Introduction to PyTorch, I think, or Introduction to Deep Learning with PyTorch by E. Life
Stevens, Luca and Tiga, and Thomas Feren. And they had something I could describe. The first
portion was an introduction to PyTorch, and then the second part of the book was a very long
example explaining, I think it was an MRI example, like object detection and these types of things,
but it was like this huge project that they walked through. And I think this is very valuable because
there's not much stuff like that out there. But one thing you mentioned about involving people
in the project, the problem here is really how you scale that up, because in my class, I had
usually 70 students, and I was just at the limit of my capacity. When the students submitted their
proposals, I spent multiple weeks reviewing them. There were only two pages each, but if you have
70 students, groups of three, you have like 24 groups, approximately 23, 24 groups, and yeah,
reading 23, like short papers, and then thinking about them, giving feedback, that is a lot of time,
and then the same thing for the final project, which was in the format of the eight page paper,
a conference paper. Yeah, this keeps you busy, especially if you want to also
during the semester provide feedback. So with a book, I can see the challenge is,
yeah, you can describe a project, but it is hard to give feedback if people are,
it's if you give an open ended exercise or something like that. But I think maybe that's
that's what Kaggle competitions are almost for, where you have also this community around it,
where people work on a similar project, and then they can help each other with feedback and
so forth. But yeah, I think projects are very powerful, but there's still like the issue of how to
how to help people with that, like in terms of having the time and capacity for that.
You mentioned PyTorch Lightning earlier. Can you talk a little bit about that, and
you know, what it is, how you use it? Yeah, so PyTorch Lightning, I must say, I just started using
it recently earlier this year. It is essentially, I wouldn't call it a framework. It's more like a
platform. So it is in a way an API that organizes your code, but it is more than just a framework.
It's like, I would call it more like a platform because it helps you integrate other technologies as
well. So it kind of brings together multiple things because when we do like deep learning now,
what I usually tend to do in my research projects even, I try to write everything from scratch.
I was, I mean, using PyTorch, but then I had my training loop. I had like a function that iterates
over the data set to compute the test accuracy because you can't load the whole data into memory
because it's too large. And then also logging. So I had my own logger where I was writing to a
CSV file, for example, or sometimes using weights and biases or even just a tensor board.
And yeah, I was just putting everything together myself. And I think this works if you work alone,
but then also I noticed like three months later coming back to the project. I had like 20 helper files
that I was importing from. I wanted to change something. It was like a mess. So and also when I was
collaborating with students, if you have your custom code, it makes sense to you, but it doesn't
make sense to anyone else. So PyTorch Lightning, yeah, it's basically, it's not much in a way that
it's not much different, let's say, than PyTorch. It's more like on top of it, but it helps you
integrate different other tools without having to, let's say reinvent the wheel. So what you do
is essentially you can still have your regular PyTorch model. So you don't change anything about
that model. It has your regular forward method and so forth. And then you have a Lightning module.
And this is like a class that wraps around the PyTorch module. But when you do that, you
you have still full control. You define, okay, how does my forward step look like? So the forward
step for training or testing. And you define an optimizer. And then you have a trainer class.
And this is it. And what's nice about it is in a trainer class, you can specify what type of
logger you want, like weights and biases, tensor board, simple CSV logger. And what's really
powerful is you can specify how many GPUs you want. So I mean, you can do this in PyTorch, but it's
much more extra work. And I never really got it to work myself. So right now, for my research
projects, I was just using the same code I had was wrapping it around a Lightning module. And I
was just training it on multiple GPUs. So in that case, I mean, it's also fully open source. And
if you want, you can still access the original PyTorch model. It's really just a wrapper around
it that that gives you certain things for free, which is nice. I'm curious what your sense for
for PyTorch usage beyond. Is it still primarily research oriented? Do you have a sense or visibility
into whether it's seeing broader adoption in industry and commercial context? I still see a lot
of tensor flow-out in that context. Yeah, that is an excellent question. I honestly, because I'm
coming more like from an academia background, I must say I haven't really deployed anything
myself yet. But talking to colleagues, I think it really depends on the company you work on.
I mean, some people similar prefer one cloud provider over the other. It's one framework over
the other. But there is no, I think big limitation of using PyTorch anymore for, let's say, deployment.
So I'm not super familiar with how things work under the hood. Sometimes I look at the source code
and it's really scary for me, like seeing all the files and stuff. But so how I understand it now
is that you have Python where you run PyTorch in primarily. And the bottleneck of using Python
is just like 10%. If you would remove Python, just run the code without Python, it would be maybe
10% faster. That's not much of a difference. And they have two different ways you can go from that
to C code. One is, I forgot the name is actually one is essentially tracing your code where it's
really a static graph from that where you, if you have a followup, it gets unrolled is this
static one. Like, and then they have the other approach, which is, I think it's called Torch
script, where you go from this Python API to a, I think it's called lip torch, which is like
the C++ API. And that one can be just used anywhere. I mean, I think they have a lot of tools
in the recent versions, also for mobile deployment and stuff like that. So I think to be honest,
there is no really bottleneck, no big bottleneck anymore, like using it for serious applications.
And then also you have all the quantization things to make it faster.
Yeah, so I think this is all really like what they focused on last year to make it more
deployment friendly. One more thing just comes to mind is Onix, like the ONNX format, where
you can also export PyTouch models to ONNX. And I think you can then also use it in like the Apple
framework, I think metal and core ML. But this is something to be honest, beyond my comfort zone,
I'm more like let's say research education. I am not really someone who is deploying applications.
So yeah, let's, let's maybe switch gears and talk a little bit about your research.
You're most recently you've been focused on ordinal regression among other topics. Can you
share a little bit about that field and why you find it interesting and kind of what the research
frontier is there? Yeah, that is a good point. So odd another regression, it's maybe an abstract
term, but how we can think about it is how do we use methods when in a supervised learning context,
when the class tables have a natural order. So usually when we teach or use machine learning,
we have like these two different scenarios where one scenario is classification, let's say
Iris flower classification, we have Satosa, Versicolor and Reginica, but we can't really say one is,
let's say, Versicolor is bigger than Reginica, there's no order, it's just independent class
tables. And then the other type is regression, where we have for example, I don't know house prices
or something like that, where you have numeric or continuous target. And ordinal regression
sits somewhere in between where we have something that looks on the surface like classification
problem, but it has an order. And so the class tables have an order, for example,
on Amazon customer ratings, where we have one, two, three, four, five stars. And I mean, it could
also be kind of like a regression problem, but the difference is really we don't know
where we can't quantify the distance between things. And we can say, okay, one in two stars and
four and five stars, it is one star difference, but yeah, it is a little bit more tricky than that,
because it's hard to compare a one to a two star review to a four and a five star review. It's
it's hard to quantify this distance. And the same thing is true like for let's say other things
like disease, if you have a scale between no disease, medium or mild disease and severe disease,
it's hard to put a label on it how different these two distances are. And this is really where
you don't want, so ordinal regression is where you don't want to or can't quantify the
distance between categories, but at the same time, you have ordering. You can say
that, for example, no disease is less than moderate than less than severe. That's like an ordering.
Would you specifically use it? I'm thinking about it in contrast to like trying to
attack a regression problem where you're concerned about integer values would or no regression
be used when you've got a much smaller set of labels or can use it if your set of labels is
relatively unconstrained and you're just really trying to focus on integers. Yeah, that is a good
point. Actually, there is no limit to the number of classes. So in our first paper, we focused on
age classification where we had 70 different age labels like from one to 70 years. And also,
we thought, okay, age, I mean, this could be modeled with a regression model, but it's a little
bit trickier than that because if you think about a person who is, let's say, 10 years old and the
person who is 15 years old, there's a lot of change that takes place when a person becomes older
in that five year time frame compared to, let's say, a person who is 80 and 85, where in this
age frame, maybe the texture of the skin changes mostly, whereas for a younger person, it's maybe
more like the growth, like the bones change and so forth. So in that case, you can use it with any
type of labels, but yeah, you're really flexible with that. So, but what I feel like was
people, or let's say, when I look for tutorials or anything like that, there has not been much
attention, or people were not really providing, let's say, help or tutorials or methods for how to
do that with deep learning. There is the classical statistics literature where we have
ordinary regression models, but nothing really for, let's say, deep neural networks. So if you have
an image data set and you, let's say, want to assess the damage to a building, you can't really say,
so if you have like a collapsed roof versus like a scratch or something like that, it's a very
type, a different type of difference compared to, or it is hard, let's say, to quantify things
sometimes. You can try to put numbers on it, but really there are a lot of problems where there are
no numbers that you can put on it, but you still want to, let's say, try in a classifier to recognize
more severe damage compared to moderate damage or no damage, let's say, in terms of insurances or
buildings and so forth. And yeah, so we have been focused on developing new networks for that,
but then also the challenge is you don't want to, let's say, develop a completely new type of
neural network, because then it's really hard for people to use that and compare to other methods.
So the focus was essentially what are like small changes that we can make to modify an existing
classifier such that it becomes an ordinary regression model. I think this is really cool because
that allows people ready to take something they already trained and then just change a few lines
of code and see if it becomes better. If it doesn't become better, okay, maybe I spent five minutes
making that change, no big loss, but maybe it makes things better and then I think it's a huge
win when people can just improve their model without having to spend a lot of time developing
something completely new. Yeah, and so there are, I'm not sure if you're interested, there are a
couple of methods for that I could talk about. Sure, yes, okay. One method was from 2016.
It's not by our group, but it was published in CBPR. We call it just the order regression
network by new at L. Yeah, and so how they tackled that problem was by, it's something called
extended binary classification. So they take a class label, let's say you have five different classes
and you have the classable three. So what they would do is they would extend this integer number
into five or four zeros and ones. So you turn this multi-category classification problem
into multiple binary classification problems and then you are predicting, is my label greater than
one? Is my label greater than two? Is my label greater than three? So you have a lot of, or you have,
let's say, in this case, four different yes and no questions and then you can just,
and so if the classable is on three, you answer, classable is greater than one, yes, greater than two,
yes, greater than three, no, and then you can, based on that, sum up the ones, add in one to it and
end up with the label. And each problem is then modeled as a binary classification task,
so we can use something we are familiar with like the logistic loss function on the binary
cross entropy loss and then sum up these binary cross entropy losses. And so this worked really
well in that paper when they have that. Sounds a bit like an extension to one hard encoding for
categorical variables. Yeah, yeah, it is kind of like that, right? So except you have, you can have
multiple ones basically instead of just one one, right? Yeah, but it is kind of like an encoding,
right? Right, right. You turn this problem into a multiple binary classification task.
The one little problem with that was when you do that, you can have like rank inconsistencies.
So what happens, let's say in an age, a prediction problem, you can predict that the person is older
than 41, not older than 42, but older than 43, which is like conflict. How can a person be not older
than 42, but then older than 43? So yeah, in our work, we just, yeah, it was like a little bit
of math. We did there. And then we had like a small tweak to prevent this rank inconsistency.
And we found that this also, yeah, improves prediction performance by a lot. And it's a really
small change. And all together with this method, we call that a coral, C-O-R-A-L. And
a sense for consistent rank logits. So with that, you only have to do two small changes.
So you have to change the last layer. There's like a constraint. We have in the last layer a
weight sharing constraint. But we, I have like a PyTouch package, you can just import the layer
and just use that. And then the other one is the loss function. And this is really it. So there
are like two little changes to the code. Maybe the binary extension could be also considered as a
change to the class table. But it's really something that you can do in five minutes. And then you
have instead of a classifier, an auto regression model. And recently, we have another method called
corn, C-O-R-N, which is taking this to another level. It's a bit more flexible. It has
better performance than coral. It is a little bit more, you have to be more careful because
with more, let's say, power comes more responsibility. So it's easier to overfit.
But yeah, so these two methods, what I like about them is really they are very easy to implement.
And everyone can use them. If you're using a classifier, you can just change a few lines of code.
And yeah, you have an auto regression classifier. Maybe to close things out, we'll return a
little bit back to education and talk about your recent role at Grid AI and kind of what you
have planned there. Oh, yeah, that is a big question. A small short question at first glance,
but there is a lot of things behind it. So yeah, I have been recently joined a Grid AI,
which is focused on deep learning at scale. My role there is, though, lead AI educator,
where I'm developing educational materials. So I'm essentially just doing what I love doing. I'm
developing material to explain machine learning and deep learning to people. And in a sense,
what I felt like also is I like teaching at the university, but also, let's say, going the next step,
maybe having a more like online base or like a course that is accessible to everyone,
my plan is to develop a free course that people can take. There's no restriction, nothing,
it's a totally free course. And also, let's say, nicely produced with where I get to focus on,
let's say, making this really nice and also involving the community with feedback. So yeah,
that is what I'm currently working on. It will be, firstly, yeah, my first goal is to have
something out maybe later this year focused on PyTorch. Maybe also PyTorch lightning, so
something around that. So I'm currently working on that. And yeah, I'm really excited because
I think that's like my passion. I wrote a book recently, but I also, now that I have a book,
let's say, going back to the course development, developing courses. But I really like about that,
it's also thinking it through. It's like, it is something where you get creative and you think
about, okay, how should I cover what? And yeah, in the past, that was always like, I think you
have to do it in order to see what is like the pro and kind of introducing a topic in a certain order.
And this now offers me another attempt doing that, like seeing how I can structure a course and how
I can develop a course. And of course, yeah, tinkering with code. This will be also very
code-focused course. And hope I can also develop good exercises because I think it's also very
important. There's a lot of material out there. But three, learn things. It's important to apply
these things and also checking your understanding with having good exercises. So I'm currently,
yeah, working on developing all of that. And hopefully I will have something by the end of the year
that I can share with you and the community. And yeah, you can tell me what you think.
We'll be keeping an eye out for it. In the meantime, thanks so much for joining and sharing a
bit about what you've been up to. It's been great finally meeting you. Thank you. That was a
total fun episode here. And I think, yeah, I could go on forever, but yeah, it was nice
chatting with you. And I enjoyed it. And yeah, whenever you feel like it, I'm always open to
talk more.
