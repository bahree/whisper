Hello everyone and welcome to Twimble Talk.
The podcast where I interview interesting people doing interesting things and machine
learning and artificial intelligence.
I am very excited to share this interview with you.
For this show, my guest is Chavier Amatriye, Chavier is a former researcher who went on
to lead the machine learning recommendations team at Netflix and is now the vice president
of engineering at Quora, the Q&A site.
Chavier and I spend quite a bit of time digging into each of these experiences in the interview.
Here are just a few of the things you'll learn from our discussion.
Why Netflix invested $1 million in a Netflix prize?
It didn't use the winning solution.
What goes into engineering practical machine learning systems anyway?
The problem that Chavier has with the deep learning hype.
And what the heck is a multi-arm bandit and how can it help us?
Of course, I'll be linking to the resources we mentioned in the show notes, which you'll
be able to find at twimlai.com slash talk slash three.
It's twimlai.com slash TALK slash the number three.
A quick note before the interview, you've got just a few days left to enter into my drawing
to win a free ticket to the O'Reilly AI conference.
I'll talk about how to enter after the interview and in the show notes.
And now on to the show.
Hey, everyone, I'm here with Chavier Amatrian and Chavier, why don't we get started by
here at Quora now?
Why don't we have you talk a little bit about what you do there?
Sure.
So, I'm at Quora, I'm the BP of engineering, so I lead the whole engineering organization
right now.
My background, though, is more in machine learning.
Previously to Quora, I was at Netflix and I was leading the machine learning recommendation
steam at Netflix.
And even before that, I was doing research and I was in academia.
And my background, again, is on recommendations, machine learning, and so on, and I've published
papers on that space for some years.
So it's kind of interesting that somebody with this kind of background is now the BP of
engineering of a growing company like Quora, where I need to deal with a lot of different
concerns, not only machine learning, but it also tells you a little bit of story
of what is important for Quora as a company as a product.
And that also aligns with some of the trends that we're seeing in industry, right?
That more and more the machine learning AI people that used to be like close in a room
by a corner and they were like, the weirdos in the lab, now they're having a lot more
influence on decisions that are being made on how to design programs and how to run companies.
And in my case, that's probably like one of the reasons that I'm
in this position now leading the whole engineering organization because for us, machine learning
it's like a big part of our success and how we're growing.
All right, so there's a ton in there and we'd really like to get to know you a little
bit better.
So let's rewind a bit.
You mentioned that you spent some time in academia.
Yeah, how did you learn machine learning?
Where did you go to school and where were you working in academia?
Yeah, that's a good question.
So I'm actually kind of old for what you see right now and I have a long history behind
me.
And I'm saying that because when I did my PhD, which by the way, I did it back in Spain.
I'm originally from Barcelona, Spain.
So when I did my PhD, I was mostly interested in signal processing and particularly in signal
processing and systems design related to audio and music.
Actually, that's what my PhD was based on.
And at that point in time, it was that age when multimedia and signal processing was kind
of like the hot thing and machine learning was not too much.
So I did use some machine learning here and there for different aspects of my research
and particularly for some of the initial recommendation systems that I worked on that
were related to music, but it wasn't my core area.
So I was more into signal processing and systems doing my PhD.
So I would say that I got into machine learning more on the chops and after I left my, you
know, I did my PhD.
I went and did some more multimedia related research in the University of California, Santa
Barbara and UCSB.
So I was there.
I was working on virtual reality and immersive environments.
And that was also very cool.
It's kind of coming back again now, but I was really interested in that space combining
signal processing and multimedia and this kind of immersive and virtual reality environment.
But after that, I became more and more interested on the data side, right?
Like how do we use the data and how do we infer information from the data?
And particularly very interested in how do we understand users from the data, right?
So that's what kind of led me to forget a little bit more about the signals that were
a little bit like, you know, more there's, they're also data, but they're like cold data
that come from systems and focus more on the human generated data and try to build intelligent
systems that understand.
So I did, then I switched my research and went into working for a few years in recommendations
and using machine learning and different kind of approaches, not only machine learning,
but also human computer interaction approaches to build this intelligent sort of like assistance
that tell you what you like and what you don't like.
So that's what actually led me eventually into net present to leading the recommendations
team there.
Okay.
Now, you dangled a big shiny object in front of my eyes and that is signals processing.
That was an area that I studied in grad school as well.
And I'm curious, well, hey, I'm curious if you could explain wavelets to me because that
was one thing that was game be a hard time, but actually, no, we're not going to talk
about that.
I'm wondering if you see any parallels.
I'm wondering if there are any interesting things happening at the intersection of signals
processing and machine learning just out of curiosity.
Do you have you seen anything?
There's actually a ton of those intersections.
There's more of like the principles and how they intersect, but I would say probably
more interesting now there is the intersection at the application side of things, right?
So if you think about it, a lot of the systems that are now being built using machine learning
approaches, particularly deep learning to understand things like speech recognition or image
recognition, those were considered in the past like signal processing applications and
for example, although I didn't professionally focus too much in speech recognition, I did
study quite a lot of that and at that time we were using Hayden Mark of models and these
other techniques that for us in the signal processing world, it wasn't, you know, there
were just tools and means to an end so it wasn't like the most important part of the system
although it was really like the core of it.
But now that's moved towards some deep learning and RNNs and so on.
So there's always been an intersection right between machine learning and signal processing
and there's always a lot to say about how to interpret signals wherever they come from
and those signals again could be audio, could be speech, music, video, images and you need
to build a system that actually either understand those things or even able to generate them
in some way and there's always a, well not always but at some point it's clear that that's
evolved more into having a layer of intelligence in the middle that it's going to be learned
and that comes from a machine learning system that it's sort of like at the heart of any
of those systems.
Great.
Great.
So you made your way from academia and ended up at Netflix immediately prior to where
you are now at Quora and your focus there was on recommendation systems.
Yeah.
I started with a very specific focus on recommendation systems.
You could consider it as a continuation and natural continuation of the Netflix
prize, the famous $1 million Netflix prize which by the way that's what got me connected
to Netflix as I was dabbling with it and also a part of using that data set for some
of my research.
Okay.
So yeah.
So I started with what you could consider like the continuation of that Netflix prize
but already working for Netflix and we eventually grew the team to be more of a core machine
learning algorithms team that was building not only recommendations but algorithms for
search and for different things where they do images and it was it grew to sort of like
being a core machine learning slash algorithms team that was serving different purposes beyond
recommendations.
But recommendations is something that is very important for Netflix right.
So that was really like probably the core of the team at any given time.
Okay.
So in terms of the you mentioned the next the Netflix prize am I correct that the the
winning prize entry was never really implemented at Netflix.
I'm glad you asked this because I get this question all the time and I react to it.
By saying it is correct the final entry was not used.
That doesn't mean that it was useless right.
So there's I'm saying that because people immediately when I say that and we wrote it in
a blog post when I was in Netflix at some point and even though it was very clearly explained
people still took away like oh Netflix wasted a million dollars and they didn't use the
outcome.
That's not true actually Netflix got way more than one million dollar back in research
and in interesting stuff that is being used and was used in different parts of different
systems.
So so if there's a difference between was the final entry use and the answer is no it was
not used.
There were over 130 different machine learning models combined in an ensemble.
Most of the different models that were there were adding just a tiny increase in accuracy
and a lot of complexity and they were not worth it.
So the reality is that two of the models on their own gave like enough accuracy that the
other hundred and thirty some were not needed or they were not worth the R.I.
That's it doesn't mean that they were not useful to understand what they were adding
and how they were adding it.
So again the story is the final prize winning entry with a complex combination of all of
those methods in an ensemble was not used as it was but the learning were worth much
more than what was invested in the prize and part of the final winning entry the most
important method were actually used directly in production.
Okay.
I came across this recently in an interesting blog post by Josh Bloom over at Wise and he
talked about the economics of machine learning basically all of the various trade offs that
get you know that come up when real business is trying to figure out how to put machine
learning into production and that was one of the examples he used about how I forget
how many pages or something the final algorithm was but a hundred and thirty models that's
a huge that's a huge model yeah and I know Josh very well so we're friends and he knows
a lot about what we've talked about this in person and you know the thing is that story
is so juicy that you can spin it in many different ways I actually recently got this
pretty crazy but I did get in my Facebook feed an advertisement from a math works trying
to sell me mad lab that was using that story and saying something like Netflix did not
use their final winning entry we can help you with mad lab what was that have to do with
mad lab right so I don't even I don't get where they're going at all with that well I don't
know but you know that's the point is that yeah the the real story is yes you do need to
be concerned and I'm I always say the same I mean you know you need to be concerned about
system complexity and about making sure that whatever you do in research is actually deployable
and it's and it's good to or easy to build engineering around it but that's very different
from saying that the Netflix prize was a waste of time or money sure so can you maybe
spend some time walking out walking through some of the various factors right so you
mention engineering time and there's you know so there's obviously like an implementability
you know from a complexity perspective you know they're going to be data aspects there's
computational obviously you know when you think about you know practical machine learning
and the the issues that you know you're you're an engineering VP of engineering now not a VP
of machine learning research or something when you think about you know engineering these systems
at large scale what are the things that you need to think about oh there's like a long list
of things and you mentioned a few them system complexity is one which actually spans into
different some areas and different concerns that relate to the system to the complexity of the
system one of them which is soft and overlooked is simply cost right it's like if you can do something
in a single machine which I have this kind of infamous slide that I when I show people some
people don't like very much is I tell people that they can do probably almost everything they need
to do machine learning in a single machine and I have reasons to say that but the point is
that if you add a necessary system complexity first of all you're going to have a lot more cost
so you're going to have this now a huge number of machines of machine that you're going to have
to maintain in a cluster or pay Amazon for the AWS cost right so that's one and it's probably
obvious and it's probably not the most important the most important one is system complexity reduces
your speed of innovation and if you have a system that is really complex from the get go
innovating on it becomes like a huge pain right because then I'm trying to tweak something and it
turns out that that's something it's just one of the 10,000 knob that are in the system and it's
hard to know what it did it's hard to understand whether it improves things and if you keep your
system as simple as possible as long as possible your innovation is going to improve and your
innovation speed because you're going to be in a much better position to then change things
dramatically improve them understand what you're doing and what is improving and at some point
you need to add complexity there's no way around it it's like complexity might add enough
improvement either in accuracy or basically in whatever metric you care about that it's worth adding
but the problem is you don't want arbitrary complexity from the start because that
midterm and longterm is going to impact you're going to be end up in a local optimal sort of speak
and you're never going to reach that global one that you would be getting if you keep your
option simple as much as possible interesting to me the thing that it brought up was the notion of
technical debt that's typically applied to code right code debt is there's anyone have you come
across anyone that's thought this through in terms of algorithmic debt oh yeah there's this
interesting paper that was published actually originally was published in a works of the iCore
organizing nips and it's called a high interest credit card of machine learning debt and it's
a very good read it's by a couple of authors from google by the way so they know what they're
talking about in terms of machine learning debt so it's something that it's been discussed
again even in papers right so right so it's it's it's an something that any organization will
face at some point and it's something that it's really important and it's really important
at many levels not only at the level of the system itself but also and I would go further that
that's part of sort of like the the core of the machine learning algorithm algorithmic design right
it's like it's okam's razor principle of you know if you have a possibility of choosing between
two things always choose the simplest one and part of the reason is because you want to minimize
your debt as long as possible and only make things more complicated when they really need to be
and they're adding up enough so that goes back to the lesson learned from the Netflix prize it like
you know yeah sure you can have you can go for the more complex solution but is the delta
improvement that is adding worth the huge increasing complexity and many times the answer is
going to be no that's an interesting segue to one of the topics that I wanted to chat with you
about you recently tweeted about a natural language processing course and the hashtag you use
was no deep learning and across a number of of your public appearances you've maybe developed
our little reputation for mr hashtag no deep learning and of course I'm being I'm being
artificially you know controversial here yeah I understand that this is you know it's a
it's a tool in the toolbox but some of our earlier discussion about system complexity I think
is one of the issues that you have with deep learning maybe walk us through you know what your
position how you think of your position on deep learning and you know why you bring it up
interesting when I talk about deep learning I always start by having a few slides in my presentation
that explain how deep learning works right so I want to get that out of the way and say hey
I know the deep learning works and it's great for a few things actually particularly for
natural language processing I think that it's getting to a point where it's the default
tool for many things and it's great so the reason I was using the hashtag is just to warn people
that if they were looking for deep learning it wasn't available in that course so I think it is
it's very important for people to understand what is the right tool for the right task and
for example we use deep learning at Quora for several things right we have a lot of text and going
back to the NLP example there's many things now in text processing that RNNs are you know they're
actually the simplest solution there is because you can you can find some of this
ready available open source tool kit that have already been trained and you can even use the
model as it is you don't even need to have your own data set or then you can retrain it but
that basically becomes simple enough that that could be your default approach to an NLP task
that you have in hand but that's very different from saying that that's equally true for
all machine learning applications and you need to understand like what is the complexity you're
paying for defaulting to machine learning for everything you have and I've seen a couple of
examples recently where I think we're you know in a dangerous situation where a lot of people
especially like more junior researchers or engineers that they're you know they've come into
industry right at the cost of the deep learning bubble or wave or whatever we want to call it
and their their mind goes straight into deep learning as the default solution for anything
and I've seen cases where I've had engineers in some companies tell me hey I'm using this
TensorFlow architecture on a problem where I have 10,000 examples and 30 features and I want to
ask you a question and my answer like why are you doing this to yourself I mean if you have
10,000 examples and 30 features do you really think you need a deep learning model with a bunch
of layers and most of the time the answer is no and even if the classifier you're building
with that deep learning architecture is let's say in the best case one percent better than the
one you could be building with a simple logistic regression you're still going to be better off
going for the logistic regression because what going back to what I was saying before your ability to
innovate on that initial model is going to be much bigger than your ability to innovate on a very
complex deep neural net that you don't really understand what's going on inside so I guess my
the point that I'm trying to make when I talk about quote unquote no deep learning is that deep
learning should be another of the tools we have in our toolkit and there's a lot of other very
interesting machine learning tools and even research that is going on that it's we should
still pay attention to there's a problem also in the research world right now with deep learning
is that because it's so new and there's so many so much low-hang improved it feels like you know
that it's the easiest way to get a paper except it is to do an incremental improvement or not
so incrementable an improvement on some deep learning approach and that's why we're seeing all
the conferences now dominated with deep learning things right even when you go to a
computer conference like KDD or the ACM recommender systems conference that I'm going to be attending
in September you start seeing like a bunch of deep learning papers because it's new it's easy to
be innovating using deep learning but we run the risk of like saying oh yeah this is the one thing
that works for everything and we're going to try to find all the nails that apply to this hammer
and we'll think that they're all they all look the same and and I think that's there is a danger
in that so you've touched a little bit on some of the things you're doing at Quora maybe tell us
a little bit about you know tell us a bit about your experiences there and you know what are some
of the interesting problems that you face there yeah sure so I that's a great question one of the
things that I love about Quora and one of the reasons as I said before that we have a VP of
engineering with this kind of background in machine learning and algorithms is that
everywhere I look on our product and our the issues that we're dealing with I see problems that
are solvable and should be solved through machine learning right so I know if I sorry for interrupting
but it's likely that most of the people listening know what Quora is but maybe you can start with
just an explanation of the site and the mission sure that's yeah that's that's a very good point
and it's a very good point because also even people that know us and use this frequently they have
a misconception about what Quora is so Quora is on the surface is a question and answer site and
application but our mission goes beyond that so the mission of Quora is to grow and share the
world's knowledge and we think that the question answer paradigm is really well suited for actually
growing and sharing knowledge just to give a different example of the only other Quora and
quote company that has a similar mission which would be Wikipedia Wikipedia also believes in the spreading
or growing the knowledge but they believe in the encyclopedic format and that leads to a bunch
of different part decisions of course so we feel like question entering and a broader notion of
what knowledge is so Wikipedia is about factual knowledge we think that for example an expert opinion
is also knowledge and should be included in any knowledge base so all of that defines our decisions
and using question answer for now is working really well and we think it's the ideal vehicle
but we are not close to trying different things and actually we do have even different things as
of today in our product that enable that knowledge growing and knowledge sharing so
so another way to look at to understand Quora is the different sort of like networks that overlay
in the product so we do have obviously a knowledge network and even another one that is a topical
network so we have entities of knowledge that are connected to each other topics that are related
to each other and then on top of that we add the social aspect right so then we have people and
we have people that are connected to other people and we have people that are connected to topics
and to knowledge entities and this sort of like different overlays of different graphs at different
levels and the different connections between them is what makes the whole data problem very exciting
because we have a lot of applications that cross the different networks in different directions
and we have for example algorithms that are purely on the content space and they tell us how
good is the quality of a given piece of content we have other algorithms that tell us
how likely is a person to answer a question on a given topic we have different kinds of
machine learning algorithms that their purpose is sort of like trying to understand and predict
different aspects of this dynamic system and the relations between all these different entities
so again examples of things that we do we do a lot of recommendations
you have initially in your home page you'll see a feed of different stories that include questions
and answers that we're optimizing for you to be interested on and that's kind of similar to
the Facebook feed that has other implications and a different objective function so recommendations
like that recommendations that you get through email we optimize the notifications that you get
through the different devices also using machine learning that's all on the personalization side of
things then we have content approaches to infer the quality of a content to do things like ranking
answers according to how good they are we have things related to a lot of the text side of things
automatic topic labeling how to infer a topic out of a given text how to find similarities
in questions and answers how to find duplicates and then also we have the whole abuse side of things
which also uses machine learning we need to one of the things that courage known about for is
you know keeping high quality content and that's the quality piece but also keeping a very healthy
positive community and we do that with very aggressive sort of norms and also algorithms that detect
any form of spam harassment bad actors and so on so forth and each one of them is a different
machine learning algorithm so it's really exciting in that sense because we have covering sort of
like a huge space of applications and data types that go into this applications interesting
can you talk a little bit about the extent to which you use hybrid machine learning plus human
yeah obviously there's a big component of the site that you could argue as hybrid as users are
ranking different answers but are there ways that you're using hybrid approaches behind the scenes
yes we are so so one way to think about it is initially all everything all of this was manual
right then the first initial beta version of kora there were no algorithms in place and all
that needed to be manual so we do have a team of moderators and people that look at content
and there's always a point where algorithms are not going to be sufficient and you need somebody
to look at the nuances of like is this answer about this politician really violating our norms yes
or no and it's like really nuanced and we need to have a person look at it so the way we think about
it is there's if you think about any content moderation issue there's always going to be a high
portion of the stuff that you have on your site that is going to be good and it's going to be good
with no doubt so you can have algorithms that say hey above of this threshold I'm totally positive
this is good stuff we don't need to worry about it there's always going to be a huge not a huge
but some part of your content is going to be really bad and there's no doubt about it so there's
another threshold that tells you below this threshold I'm just going to remove this stuff because
it's basically crap and you don't want that's how you keep the quality of your content
in the site right now there's this gray area in between those two thresholds and that's the
tricky part right so you have to do two things one is there's you know you have to have people
then look at this gray area and decide yeah this is not really that bad it should where it should be
okay with it and at the same time you need to improve your algorithms to get those two thresholds
as close to each other as possible and that's very interesting right because it represents sort of
like a research challenge for us to improve our machine learning algorithms say hey we want the
gray area of the things are uncertain to over time become as small as possible and we're doing
that at the same time the gray area is still there and when when we have things in the gray area we
need to use some humans in the loop to understand what's going on uh-huh so if if Quora were to do
a Quora prize analogous to the Netflix prize what would it be about what are some of the biggest
challenges that you face well there's in each of those dimensions that I mentioned before there's
challenges that are still not resolved but I guess thinking of the Netflix prize and something
that would be kind of similar and I think it's very interesting and probably that's an obvious
direction we would go is that for something like knowledge there is also the problem
which similar to a Netflix prize of how do you get the right piece of content to the right person
and content is expressed in two ways right one is a content that you can consume so that's an answer
that you can read and you can enjoy and you can learn from it and the other one is a question
that you can answer so both of those things how to route them to the right person and how to
optimize algorithm for those two things are at the core of what we're doing and they're very
important for us so I think we could think of like uh again drawing the analogy of the Netflix prize
of like question and answer recommendation uh being like a very interesting topic uh that um for
us it's like a super interesting challenge uh it also connects like many different dimensions on
different overlays that I was talking about because it's not only about personalization but you
also have to care about content quality right and you have to care about those different aspects
and how they uh feed into what what the users are going to be doing and reacting to short term
but more importantly what they're going to be reacting to long term uh I've talked about that in the
path in some of my presentations like this sort of like tension between short term metrics and long
term metrics and that's something that a lot of companies have done the wrong thing and they've
gone downhill because of that and it's really important to understand uh for example in the context
of content how to avoid clickbait right and if you're optimizing for some things you're going to get
clicks sure but those clicks are going to turn into people not visiting your site ever again after
a couple weeks uh so all those things sort of like uh fit into this picture of sort of like
content recommendation or knowledge recommendation
how do you address the short term long term trade off now and maybe even in the context of uh a
clickbait type of application so so there's different things that go into it uh I would say that
that's uh that's one of the most interesting research areas that I don't think it's been really
solved even in uh research literature because there's it's very hard to get enough good quality
datasets to even do something about it if you're if you're a research in academia and in the industry
uh I mean as far as I know from the field that I talk there's obviously different things that we're
all doing but uh holistic approach to it is it's hard um the the one important thing is you do need
to make sure that you're running your AB test with the right sort of metrics right because at the end
of the day you can be optimizing whatever you want in the lab and say oh uh it's a ranking problem
I'm going to be optimizing NDCG but the reality of that metric that you're optimizing in the lab with your
algorithm might not really correlate perfectly to what you want to get in the product in that long
term metric so first you need to make sure that you whatever you tune in your in the lab you run
AB test long enough term with the right metric to understand like what is the met what what what
what are the effects that whatever you're doing have on the users and then you kind of work backwards
from that right once you have the right metric on your AB test you know oh if I do this my users end
up not coming back after two weeks what did I do then you back you you kind of work backwards
from that and try to understand like what are the metrics in the lab that you could have used to
sort of like predict that kind of behavior and the kind of effect right so building regression
models from sort of like your uh easy to compute uh metrics which they're all going to be related to
some kind of error or some kind of uh information retrieval precision recall whatever you will
into the real world of usage I think that's that's very important and then there's a there's a
ton of other things that you can do once you understand those dynamics in trying to
define your training set in a way that actually um defines the problem in the right way
uh and and sometimes I've talked about this also in the past people have this mistake of I need
to use all the data that I have and I need to use the raw data that I have and sometimes that's
not really the answer you might need to use some data and not others because some of the data that
you might be feeding into the into your model might be teaching the model the wrong thing or you
might need to weight your data in a way that some is more important than other because it needs to
longer term effects that you're interested on while other might lead to a click but nothing else
so there's there's a lot of sort of like uh different details going into the recipe uh but again
I don't think there is a very holistic approach to it or not that I'm aware of
okay uh one thing that that came to mind for me was and this is maybe going back to our discussion
around deep learning uh there is some research happening around RNNs and you know
when the the reinforcement or the score you know comes later and how the RNN can optimize for
um you know this delayed gratification so to speak and so you know maybe this is where
you know if this gets sophisticated enough this is where you get some benefit from
introducing the complexity of RNNs where an otherwise simple model might come into play
yeah uh that's definitely true uh so models or approaches that have any sense of sequencing or time
or evolution over time do have some uh that some benefits uh and and and you can use them
it's not only about RNNs another thing that comes to mind it's uh some reinforcement learning
approaches uh I mean the typical what one of the typical ways to deal with this uh to use
and some form of multi-arm banded uh approach uh to deal with the exploration exploitation
tradeoff it's it's more of like yeah you know I know that you're clicking on this but let me try to
explore more things let me try to come up over time uh have uh you know my model converge to something
that is a global optimal rather than getting stuck on that local one where I am right now so yes
you're right I mean and and some of the sequential RNNs with some form of uh memory and and
ability to sort of like uh remember different stages and sort of like end up converging
over time into a better optimal uh they're super interesting yeah before we before we get too far
can you explain simply uh multi-arm banded yeah uh so the idea uh it's pretty simple I mean multi-arm
banded comes from this notion of you have uh the the typical image that people use is the
slot machines in a casino uh you imagine that you're going to casino and you have 10 slot
machines in front of you and you don't know which arm you should pull that's where the multi-arm
banded come from and you start trying one and say oh this one is giving me some interesting
prices but should I try another one because maybe the one that I have next to me is actually
better than this one and how to deal with this dilemma of out of multiple arms that you could be
pulling there's some that you have more information about and you know uh with a degree of certainty
how well they're doing and there are others that you don't really know anything about them
should you risk yourself and going to the ones you don't know anything about them or should you
just stick to the one that kind of works but maybe it's not the optimal one so I think that's the
whole point of the multi-arm banded uh approaches is like they try to define a way in which you can have
an optimal policy to deciding whether you should continue pulling from the same arm or you should
go to a different one and there's a lot of literature on on this and and you can read about it and
I usually joke about it there's a lot of literature about multi-arm banded but there's only one
that actually works in practice but I don't know if I want to give that away I mean it's it's it's
pretty it's pretty uh well-known in in industry that uh Thompson sampling is the easiest and
sort of like more practical approach to multi-arm banded so I think that I'm not giving too much
away by saying that right so what uh what do you find the most exciting about machine learning
right now obviously there's a ton of things going on there's uh deep learning stuff there's
the work that's happening around bots there's applying deep learning to NLP like you know given
everything that's going on like what what's the most exciting and and do you get to apply that in
your work um and what's the most exciting thing that you're actually working on um so I think the
most exciting thing for me it's almost a non-technical thing it's more of a this thing coming from
society as a whole that it's accepted as a given that machine learning and AI is inevitably part
of making a better future right and I think you know there's still so people that were arguing about
dangers and and about robots taking over and so on but I think generally speaking
society is convinced and it's pretty uh much you know all bought in you know self-driving cars
a couple of years ago people thought uh we were crazy about self-driving cars and now they're
already being tested uh with um people writing in them so so I think this sort of like change in
society and in mindset and people realizing that oh machine learning is not really evil it can be
it's a tooling can be used in my benefit and it's something that I expect things to have
to have so not very long ago seeing something that was an algorithm or machine learning was like whoa
what's going on I'm losing control this is not something I like and now it's shifting to the opposite
like you expect applications you expect uh gadgets to have intelligent and to have machine learning
otherwise you're disappointed like oh my gosh I need to tell this phone everything I want the
phone should know what I want right so uh I think that's that's a very very interesting
shift and and it kind of connects a lot with some of the things we're doing at Kora right and Kora
we are very user focused and we want to we want to keep this warm feeling of you're in the community
you're sharing knowledge this is very important for you it's very important for the people
but you're going to be surrounded by all this different algorithms that make your life much better
and they protect you from bad people and they protect you from horrible content that you don't
want to read and they help you get your content to the right people that want to uh read about it
and they're going to be helped by it uh so this combination of so that the warmth of community
social aspects and knowledge but also surrounded by all this different algorithms in a seamless way
I think that's super exciting and it's something that uh you need to uh strike the right balance
but uh it's something that just a few years ago we wouldn't thought about because you know again
algorithms uh were the the the school evil thing that you'd kind of like wanted to stay away from
uh so I think that's that's a very interesting trend and uh something that I'm excited about
we're coming to the end of our time but I've got a couple more quick questions for you the first is
you go to a lot of conferences what are your favorite conferences in the space?
um I wouldn't say I go to a lot of conferences unfortunately uh especially now since my
time as a VP of engineering is pretty precious and I don't get that much time there's some conferences
that I have ties for a very long time and I keep going to them because I I'm very interested in
the content but also I'm interested in the community one of them is uh is a small conference actually
the it's the ACM recommender systems conference that's a conference that is purely focused on
personalization and recommendations and I helped start the whole thing I was uh the general chair
for that in 2010 uh back in Barcelona and I kept kind of keep in touch it's in one of the
interesting things about this community which uh I think it's a little bit similar to for example
KDD is that it's a very diverse kind of uh audience and you don't get the pure machine learning
nips audience everyone focused on the algorithm and uh you know squeezing uh one percent more or
less uh RMSC or MAE out of their algorithm there's a combination of algorithms but also application
and then user oriented research which uh I think connects to the vision that I was saying right
this connection between uh user orientation and algorithms uh it's very interesting so yeah uh
the ACM recommender systems conference which by the way is happening in Boston if anyone is
listening from Boston or wants to travel there uh this year is in the US and it's going to be
super interesting uh when is it coming up right yeah it's in September 15 so yeah in a few weeks
uh we're going to be there um and I'm just to give an example I'm giving a tutorial uh with
together with Deepak Aval from LinkedIn on uh all the latest research and um all the evolution of
recommendation systems in industry and we're going to be giving a holistic perspective of
me coming from Netflix and now Kora and him having been at Yahoo and now meeting machine learning
at uh LinkedIn uh so it's going to be sort of like uh an overview of all this kind of uh
machine learning techniques for recommendations uh so that's that's an example of a small
focus conference but also with a very broad audience which I kind of enjoy uh KDD which
just happened to be in San Francisco recently uh I like the community a lot and uh I think I
can find all of uh very interesting uh uh approaches and applications um I usually um yeah I'm very
application driven in my uh approach to machine learning so although I will I will read all the papers
or not not all sorry some papers from MIPS and ICML I I tend to uh go to more sort of like
application driven conferences and and then there's also a lot of uh small conferences that are
organized now uh there are kind of local and focused uh on the industry side of machine learning
ML conference one that comes to mind that I attend regularly because I find the audience to be
very uh interesting and very engaging and uh it's a lot of uh practitioners from industry
mix together with uh a bunch of researchers and that intersection I think it's uh it's really
interesting um great great and then uh one more question that you're in a particularly good
place to answer for us and that is who are the people to follow uh the machine learning folks to
follow on Quora? Oh that's a great question but we have a lot of them so we've been doing actually
uh uh very strong push for this product feature that we have which is sessions which is similar to
an AMA AMA and we brought in uh I would say like all the top machine learning researchers
to do some uh session in the past uh we've had people like uh I mean most of the deep learning folks
like Jan Lecun and uh Joshua Benjo and we've had Andrew Eng we've had Peter Norbeck
we've had um a lot of different researchers and I would say most of the authors of the famous
machine learning books like Kevin Murphy from Google and so on uh or we we we had Ian
Goodfellow the main author of the deep learning book also recently so there's like a good
yeah I would say 50 people that you would follow we've also had uh people that leave machine learning
in different companies like uh Amazon we have my friend Ralph Herbys from Amazon uh or Joaquin
from Facebook uh so there's like a huge machine learning community in Quora that is very active
and very uh strong so it's one of our strongest areas right now so I would recommend
people who are interested in in machine learning there's like a ton of knowledge there
and growing so uh yeah great great uh well Chaviet thank you so much for spending the time with us
I learned a ton and I'm sure the folks that listen uh will as well uh anything you'd like to leave
us with uh no I mean thanks for having me and uh it was great to share a little bit of that knowledge
in this different format which it's also it's a way of spreading knowledge and I look forward
to interacting with people uh especially on Quora I myself write a lot of different answers
on different topics including machine learning uh that's a good point before we go where can folks
find you how can folks engage with you uh I'm pretty public on Twitter as you mentioned you
you had seen a bunch of my tweets so I'm uh they can find me on Twitter on uh Shamat X-A-M-A-T
or on Quora I'm also very active uh so you can follow me on Quora and message me there
um I usually keep a very active public profile so uh it's not hard to find me and I have a pretty
weird name and last name so it's like it's hard to uh to go into the wrong direction if you
if you google my name yeah all right great thanks so much Chaviet yeah thank you Sam
all right everyone that's it for today's interview before we go a reminder that
this week in machine learning and AI and O'Reilly have partnered to offer one lucky listener
a free pass to the inaugural O'Reilly AI conference which will be held at the end of September
in New York City you can enter via twitter or the twimmaleye.com website by doing one of the
following three things the preferred way of entering is via twitter just follow at twimmaleye
t-w-i-m-l-a-i and retweet the contest tweet that i'll pin to the account and post in the show notes
do those two things and you'll be entered if you're not on twitter you can sign up for my newsletter
at twimmaleye.com slash newsletter and add a note please enter me in the additional comments field
finally if you're not on twitter and you aren't interested in the newsletter no problem
just go to the contact form on twimmaleye.com and send me a message with that form using AI
contest as the subject the drawing will be open to entries through September first and i'll
announce the winner on the September second show good luck and hope to see you in New York thanks
again for listening
