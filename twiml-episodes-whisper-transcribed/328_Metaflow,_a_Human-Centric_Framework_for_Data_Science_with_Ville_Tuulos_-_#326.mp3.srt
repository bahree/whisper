1
00:00:00,000 --> 00:00:13,400
Welcome to the Tumel AI Podcast.

2
00:00:13,400 --> 00:00:16,400
I'm your host Sam Charrington.

3
00:00:16,400 --> 00:00:24,480
Hey, what's up everyone?

4
00:00:24,480 --> 00:00:29,920
I recently attended the AWS re-invent conference in Las Vegas and I'm excited to share

5
00:00:29,920 --> 00:00:38,720
a few of my many interesting conversations from that event here on the podcast this week.

6
00:00:38,720 --> 00:00:44,160
Before we dive in, I'd like to thank our friends at Capital One for sponsoring our re-invent

7
00:00:44,160 --> 00:00:45,760
series.

8
00:00:45,760 --> 00:00:50,200
Capital One has been a huge friend and supporter of this podcast for some time now and I'm

9
00:00:50,200 --> 00:00:55,040
looking forward to sharing my interview with Dave Castillo, Capital One's managing VP

10
00:00:55,040 --> 00:00:58,640
of machine learning with you on Thursday.

11
00:00:58,640 --> 00:01:02,400
Dave and I discussed the unique approach being taken at the company's center for machine

12
00:01:02,400 --> 00:01:07,520
learning as well as some of the interesting AI use cases being developed at the bank and

13
00:01:07,520 --> 00:01:12,080
the platform they're building to support their ML and AI efforts.

14
00:01:12,080 --> 00:01:17,880
Once again, check back in on Thursday, December 19th for that conversation.

15
00:01:17,880 --> 00:01:22,880
To learn more about Capital One's machine learning and AI efforts and research, visit capital

16
00:01:22,880 --> 00:01:26,960
one dot com slash tech slash explore.

17
00:01:26,960 --> 00:01:28,560
And now on to the show.

18
00:01:28,560 --> 00:01:40,040
All right, everyone, I am here at AWS re-invent in Las Vegas and I am with Vila Toulos.

19
00:01:40,040 --> 00:01:44,400
Vila is a machine learning infrastructure manager at Netflix.

20
00:01:44,400 --> 00:01:46,080
Vila, welcome to the Twentha AI podcast.

21
00:01:46,080 --> 00:01:47,880
Oh, thanks for having me, Stan.

22
00:01:47,880 --> 00:01:52,440
Yeah, I'm really looking forward to jumping into this conversation.

23
00:01:52,440 --> 00:01:57,520
It turns out our timing could not have been better. Your team just announced a new open

24
00:01:57,520 --> 00:02:01,200
source project called Metaflow that we'll dig into.

25
00:02:01,200 --> 00:02:05,160
But before we do that, you mentioned before we started that you've been working on machine

26
00:02:05,160 --> 00:02:08,040
learning infrastructure since what did you say 2010?

27
00:02:08,040 --> 00:02:12,080
No, actually, like 2000, I'm sorry, 2000.

28
00:02:12,080 --> 00:02:17,280
Yeah, 2000, I mean, it's kind of, I guess I date myself, but yeah, no, I've been doing

29
00:02:17,280 --> 00:02:18,960
this for a long time.

30
00:02:18,960 --> 00:02:23,200
And I started, even the term data science didn't exist back in 2000.

31
00:02:23,200 --> 00:02:25,320
This was just during the dot com boom.

32
00:02:25,320 --> 00:02:29,560
I was at the start up that tried to commercialize neural networks, neural networks really

33
00:02:29,560 --> 00:02:31,600
weren't that popular back in the day.

34
00:02:31,600 --> 00:02:33,320
We were away ahead of our time.

35
00:02:33,320 --> 00:02:35,080
I mean, what was the startup called?

36
00:02:35,080 --> 00:02:36,320
Will anyone have heard of it?

37
00:02:36,320 --> 00:02:38,280
No, I mean, like, it's called grew soft.

38
00:02:38,280 --> 00:02:39,280
Okay.

39
00:02:39,280 --> 00:02:42,840
No one, like, and actually, it's probably better that no one has heard of it, but I mean,

40
00:02:42,840 --> 00:02:46,600
it was, it was a great lesson learned, like I learned a lot than ever since then.

41
00:02:46,600 --> 00:02:50,800
I've been working with data scientists, people who want to build machine learning, people

42
00:02:50,800 --> 00:02:54,440
who need help with the infrastructure, who want to kind of a scale, who want to make

43
00:02:54,440 --> 00:02:55,440
it better.

44
00:02:55,440 --> 00:02:59,040
So I mean, it's a super exciting topic, and now it is, of course, absolutely mind blowing

45
00:02:59,040 --> 00:03:04,040
that the whole topic has become so popular and it is on top of everybody's minds, it seems.

46
00:03:04,040 --> 00:03:06,680
So, but yeah, no, I'll just keep doing it.

47
00:03:06,680 --> 00:03:10,280
Yeah, well, it's certainly a far cry and popularity from 2000.

48
00:03:10,280 --> 00:03:11,280
That's right.

49
00:03:11,280 --> 00:03:12,280
Yeah.

50
00:03:12,280 --> 00:03:13,280
What was your background?

51
00:03:13,280 --> 00:03:16,320
What kind of, how did you end up doing ML infrastructure?

52
00:03:16,320 --> 00:03:17,320
Right.

53
00:03:17,320 --> 00:03:18,320
Right.

54
00:03:18,320 --> 00:03:22,240
So I have a master's in computer science, and I was, I was part of a research group.

55
00:03:22,240 --> 00:03:27,080
I'm originally from Finland, so I was working at the University of Helsinki, like we did,

56
00:03:27,080 --> 00:03:32,880
many things related to Bayesian statistics, information retrieval, things like that.

57
00:03:32,880 --> 00:03:38,840
And, and like, I was like always like gravitating towards thinking how we can make these things

58
00:03:38,840 --> 00:03:39,840
easier.

59
00:03:39,840 --> 00:03:43,760
I mean, there were people who are absolutely amazing on the theoretical side of things,

60
00:03:43,760 --> 00:03:48,240
and I realized that, well, many of the things that people were already doing back in the

61
00:03:48,240 --> 00:03:52,600
day, I mean, the fact is that machine learning is not the new field per se.

62
00:03:52,600 --> 00:03:55,760
It was only kind of blocked by the fact that it wasn't easy enough.

63
00:03:55,760 --> 00:03:57,480
It wasn't easy enough to apply these things.

64
00:03:57,480 --> 00:04:01,280
It wasn't easy enough to scale them out, and that was really kind of the bottleneck

65
00:04:01,280 --> 00:04:05,680
in the whole process of like kind of making these techniques and methods like more applicable

66
00:04:05,680 --> 00:04:07,960
to more real life use cases.

67
00:04:07,960 --> 00:04:12,440
And, and like, it seems that like now, I mean, 20 years later, I mean, things are much

68
00:04:12,440 --> 00:04:13,440
better.

69
00:04:13,440 --> 00:04:17,240
I mean, especially off the shelf, machine learning like we're absolutely amazing these days,

70
00:04:17,240 --> 00:04:19,200
but I mean, I still think that there's work to be done.

71
00:04:19,200 --> 00:04:25,000
I still, that's why we open source Metaflow, and that's why I keep doing what I'm doing.

72
00:04:25,000 --> 00:04:31,960
Let's dive into Metaflow, and maybe the place to start is paint us a picture of the context,

73
00:04:31,960 --> 00:04:37,560
you know, out of which Metaflow grew, and what the problem is that it tries to solve.

74
00:04:37,560 --> 00:04:39,560
This was just announced yesterday, so now-

75
00:04:39,560 --> 00:04:45,600
Like 20 hours ago, probably not many people will have, you know, heard of it by the time

76
00:04:45,600 --> 00:04:46,600
this all.

77
00:04:46,600 --> 00:04:50,600
Oh, well, people may have heard of it by the time this is actually published, but as of

78
00:04:50,600 --> 00:04:53,040
today, and very few have.

79
00:04:53,040 --> 00:04:55,200
So let me, let me start by giving some context.

80
00:04:55,200 --> 00:05:00,440
So as you and like many, many of the listeners may know Netflix has been doing recommendations

81
00:05:00,440 --> 00:05:01,440
for a long time.

82
00:05:01,440 --> 00:05:05,440
So when you plug into Netflix.com, you see all the TV shows and movies that are recommended

83
00:05:05,440 --> 00:05:06,440
to you.

84
00:05:06,440 --> 00:05:10,200
And then obviously that's done by a machine, it's an algorithm not by people who choose

85
00:05:10,200 --> 00:05:11,800
like what to show there.

86
00:05:11,800 --> 00:05:15,200
And this is something that like the company has been doing for a long time.

87
00:05:15,200 --> 00:05:18,520
And now a couple of years back, I think it was about three years back.

88
00:05:18,520 --> 00:05:21,840
Like we started having the realization that more and more of machine learning use cases

89
00:05:21,840 --> 00:05:24,120
were actually happening outside recommendations.

90
00:05:24,120 --> 00:05:29,560
So so that of course Netflix is now probably like one of the largest movie studios, TV studios

91
00:05:29,560 --> 00:05:30,560
in the world.

92
00:05:30,560 --> 00:05:35,800
And like we have appetite to just like apply data science, machine learning and all kinds

93
00:05:35,800 --> 00:05:37,960
of different areas.

94
00:05:37,960 --> 00:05:43,000
And and like the first question we ask ourselves is that can we apply, can we use the existing

95
00:05:43,000 --> 00:05:47,360
infrastructure that we have for recommendations for these other use cases as well.

96
00:05:47,360 --> 00:05:52,480
And we are talking about things like natural language processing or like operations research,

97
00:05:52,480 --> 00:05:54,920
optimizing production schedules, things like that.

98
00:05:54,920 --> 00:05:58,920
And the realization was that these things are actually quite different like from the production

99
00:05:58,920 --> 00:06:01,600
scale recommendations that we had.

100
00:06:01,600 --> 00:06:05,240
And we started thinking that actually we need new kind of infrastructure that helps data

101
00:06:05,240 --> 00:06:08,520
scientists that are working on these more internal use cases.

102
00:06:08,520 --> 00:06:12,840
And that was really the context and motivation like why we started building Metaflow.

103
00:06:12,840 --> 00:06:17,000
And then when we when we started working on this or when we started thinking even like

104
00:06:17,000 --> 00:06:21,720
what to do, the interesting thing is that there is like two years back when we studied 2017

105
00:06:21,720 --> 00:06:26,640
there wasn't much available in open source or even as commercial products out there.

106
00:06:26,640 --> 00:06:29,520
And we started asking ourselves the question that like what are the things we should be

107
00:06:29,520 --> 00:06:30,960
doing in the first place.

108
00:06:30,960 --> 00:06:36,840
And quite soon the realization was that technically many of these things were kind of possible.

109
00:06:36,840 --> 00:06:41,840
Netflix of course has all kind of infrastructure already available, but nothing was easy enough.

110
00:06:41,840 --> 00:06:45,600
And that's when we kind of a in a way I mean light bulb went off in our heads that like

111
00:06:45,600 --> 00:06:49,320
our job as the machine learning infrastructure team is to make things easier.

112
00:06:49,320 --> 00:06:53,360
It's really the big human centric and like increase the productivity of data science instead

113
00:06:53,360 --> 00:06:57,120
of saying that like look I mean we can build larger scale models than anyone else.

114
00:06:57,120 --> 00:07:00,760
You contextualize this is making the data science process easier when I talk to folks that

115
00:07:00,760 --> 00:07:02,960
are building ML infrastructure.

116
00:07:02,960 --> 00:07:06,600
It's not always clear who their primary audience is whether they think of it as data science

117
00:07:06,600 --> 00:07:08,760
or machine learning engineering.

118
00:07:08,760 --> 00:07:12,960
Is that a hard distinction for you or who do you who you're supporting with?

119
00:07:12,960 --> 00:07:15,520
Yeah, that's that's a great question.

120
00:07:15,520 --> 00:07:20,560
So now the people who we support are data scientists and like really data scientists who

121
00:07:20,560 --> 00:07:25,520
are absolutely capable of what the world's best experts in building statistical models,

122
00:07:25,520 --> 00:07:27,080
building machine learning models.

123
00:07:27,080 --> 00:07:29,360
But oftentimes they don't have a background in computer science.

124
00:07:29,360 --> 00:07:31,160
So they are not software engineers.

125
00:07:31,160 --> 00:07:36,240
So they are like very classical like a scientist with capital is in that sense.

126
00:07:36,240 --> 00:07:40,240
And our job as the infrastructure team is to is to provide them with enough tooling.

127
00:07:40,240 --> 00:07:44,560
So that they can be experts at the kind of really at the level of data science like built

128
00:07:44,560 --> 00:07:45,560
the models.

129
00:07:45,560 --> 00:07:49,040
And then they wouldn't have to worry too much about the software itself.

130
00:07:49,040 --> 00:07:53,200
Now the thing there is that like the Netflix is culture is quite special and like we want

131
00:07:53,200 --> 00:07:57,760
people to operate the end to end machine learning workflows independently.

132
00:07:57,760 --> 00:08:01,560
So it's not so that the data scientist builds the model and hands it over to machine

133
00:08:01,560 --> 00:08:03,560
learning engineer who then pushes the production.

134
00:08:03,560 --> 00:08:08,360
But we want this data scientist to own own the project like from the prototype to production

135
00:08:08,360 --> 00:08:12,920
like from like kind of all the way like kind of a from the raw data to kind of the business

136
00:08:12,920 --> 00:08:13,920
results.

137
00:08:13,920 --> 00:08:17,480
And of course I mean this is very hard like if you don't have the supporting infrastructure

138
00:08:17,480 --> 00:08:19,600
and that's where we come in.

139
00:08:19,600 --> 00:08:27,000
So maybe another bit on context to you know when I think about Netflix having followed

140
00:08:27,000 --> 00:08:34,560
the company for many years the company has been very active in open source particularly

141
00:08:34,560 --> 00:08:41,040
with regard to the way that it does cloud infrastructure generally chaos monkey and lots

142
00:08:41,040 --> 00:08:47,320
of projects have been great contributions to the community as well as interesting projects

143
00:08:47,320 --> 00:08:53,280
on the data science side paper mill is the one that comes to mind most immediately.

144
00:08:53,280 --> 00:08:57,960
We talk a little bit about if we haven't really defined metaflow and like what it's doing

145
00:08:57,960 --> 00:09:04,040
beyond it's a platform to support data science but you know talk about why it was important

146
00:09:04,040 --> 00:09:08,080
for your team to open source this as opposed to build it to support the internal use case.

147
00:09:08,080 --> 00:09:09,880
Yeah that's a great question.

148
00:09:09,880 --> 00:09:16,480
Now as I mentioned we started about 2017 we started with metaflow and as I mentioned

149
00:09:16,480 --> 00:09:20,400
like the motivation was really to help data scientists be really human centric human friendly

150
00:09:20,400 --> 00:09:25,040
we started building this Python library and now over the past couple of years this has

151
00:09:25,040 --> 00:09:30,160
become really popular like inside Netflix and we have given a few conference talks about

152
00:09:30,160 --> 00:09:35,320
this outside Netflix as well and every time we went out and like talked about metaflow

153
00:09:35,320 --> 00:09:39,200
we got like really great response I mean like people in many other companies felt that

154
00:09:39,200 --> 00:09:43,000
like something like this is absolutely needed of course the need is very common like how

155
00:09:43,000 --> 00:09:47,960
do we make data scientists more productive and now another interesting angle like you pointed

156
00:09:47,960 --> 00:09:53,200
out that Netflix has been doing open source for a long time also another thing about Netflix

157
00:09:53,200 --> 00:09:58,960
is that we have been a user of Amazon like Amazon Web Services AWS for a long time metaflow

158
00:09:58,960 --> 00:10:04,400
like from the get go was built to support the cloud and like was built to really work nicely

159
00:10:04,400 --> 00:10:09,040
with the cloud and the combination of having something that like really like makes data science

160
00:10:09,040 --> 00:10:14,560
easy for people who are not software engineers as well as leverage is the scalability of the

161
00:10:14,560 --> 00:10:20,320
cloud was really something quite unique and now when we when we really decided that we

162
00:10:20,320 --> 00:10:25,360
want to open source metaflow we actually started also working with AWS to make sure that

163
00:10:25,360 --> 00:10:30,560
people outside Netflix can have the same seamless integration to the cloud that we have been

164
00:10:30,560 --> 00:10:36,000
enjoying internally at Netflix so so now it's really the kind of the combination of the

165
00:10:36,000 --> 00:10:40,120
productivity and the cloud integration that I think that like makes metaflow a very interesting

166
00:10:40,120 --> 00:10:46,280
package today as open source let's talk about its functionality what are the core features

167
00:10:46,280 --> 00:10:51,880
that metaflow is trying to offer to the user base yeah it's almost a paradox in the sense

168
00:10:51,880 --> 00:10:56,760
that we say that we are a machine learning infrastructure and it's there's one thing that

169
00:10:56,760 --> 00:11:03,240
like we are kind of not too opinionated about and that's machine learning so so the also an

170
00:11:03,240 --> 00:11:07,240
important realization is that they are absolutely amazing off the shelf libraries these days like

171
00:11:07,240 --> 00:11:12,840
TensorFlow, PyTorch, Scikit-learn, HDBoost and we use all these libraries internally and we

172
00:11:12,840 --> 00:11:16,680
absolutely don't think that like we can provide anything better than what you can get from those

173
00:11:16,680 --> 00:11:20,760
libraries also we feel that it's very important that data scientists have the freedom to choose

174
00:11:20,760 --> 00:11:26,760
the libraries kind of the best tool for the job so that's that's one layer but as you know

175
00:11:26,760 --> 00:11:31,720
the models themselves are only a tiny part of into and machine learning pipelines and what metaflow

176
00:11:31,720 --> 00:11:36,280
does is that it kind of helps you with everything else around the models so all the way like from how

177
00:11:36,280 --> 00:11:41,400
you access the data like to how you execute the compute in the cloud in very easily so that like

178
00:11:41,400 --> 00:11:46,120
you don't have to like learn new paradigms you can subscribe idiomatic Python code you can

179
00:11:46,120 --> 00:11:50,120
just use the off-the-shelf libraries we take care of packaging everything with get care of like

180
00:11:50,120 --> 00:11:53,880
scaling it out to the cloud and especially what we do and this is like really one of the key

181
00:11:53,880 --> 00:11:58,520
features of metaflow is that we automatically snapshot absolutely everything you do including the

182
00:11:58,520 --> 00:12:04,280
code the dependencies and the data that like flows through the kind of the data flow and why this is

183
00:12:04,280 --> 00:12:10,040
important for a couple of reasons now it allows you to reproduce results afterwards and also it

184
00:12:10,040 --> 00:12:14,920
allows you to inspect any internal state of the model and this is really important that machine learning

185
00:12:14,920 --> 00:12:21,480
models as any software engineering artifact they never like work perfectly like kind of during

186
00:12:21,480 --> 00:12:26,440
the at the first deployment so it's always a iterative process and and we feel that it's really

187
00:12:26,440 --> 00:12:30,120
really important that like we provide first class support for debugging and troubleshooting and

188
00:12:30,120 --> 00:12:35,160
that's why having the snapshots in the cloud is so useful so this is kind of the package that

189
00:12:35,160 --> 00:12:39,720
metaflow provides like really from from in to end and then like then you can like do the modeling

190
00:12:39,720 --> 00:12:46,040
as you want to do it well let's maybe start at the data and walk through that in more detail

191
00:12:46,760 --> 00:12:51,880
what are all the features that you're providing kind of or maybe another way a better way to

192
00:12:51,880 --> 00:12:59,080
ask this is what is the user experience from the perspective of you know accessing data managing

193
00:12:59,080 --> 00:13:05,720
data creating transformation pipelines things like that yeah that's a that's a good question

194
00:13:05,720 --> 00:13:13,160
so now Netflix has a very very mature data warehouse that's based in amazon s3 so we have

195
00:13:13,160 --> 00:13:19,080
hundreds of data bytes of data in amazon s3 and and also we have a very secure query engines that

196
00:13:19,080 --> 00:13:24,200
we use like presto and spark and and of course like many many data scientists are quite comfortable

197
00:13:24,200 --> 00:13:28,920
using cql to access data so we we support that so you can you can use any libraries you want to kind

198
00:13:28,920 --> 00:13:32,440
of access on many many companies who might want to use metaflow i mean they probably have a spark

199
00:13:32,440 --> 00:13:37,880
or crystal and that's it that's totally valid way to access data now one very specific optimization

200
00:13:37,880 --> 00:13:42,200
that we provide is that we notice that oftentimes in this machine learning applications you kind of

201
00:13:42,200 --> 00:13:46,200
just want to one big data frame you want kind of everything so again and then like you want to

202
00:13:46,200 --> 00:13:51,400
decide how you do feature engineering inside your python code so we provide this extremely fast path

203
00:13:51,400 --> 00:13:56,360
which we call fast data that allows you to pull data directly from s3 to your machine learning

204
00:13:56,360 --> 00:14:01,800
workflows very very fast so we are talking about 10 gigabits per second and and this along this

205
00:14:01,800 --> 00:14:05,960
feature alone has been really really popular among amongst data scientists since previously they

206
00:14:05,960 --> 00:14:10,120
used to wait for 10 minutes 20 minutes to get the data and then they could actually study trading

207
00:14:10,120 --> 00:14:14,600
on the data and so forth and now you can get it in seconds so that really is a big it's a big

208
00:14:14,600 --> 00:14:19,800
like boosting productivity that we provide and then as I said we we are not too opinionated we are

209
00:14:19,800 --> 00:14:23,800
not like proposing a new paradigm for data processing this is not the yet another map reduce

210
00:14:23,800 --> 00:14:27,800
or anything of that storage so you can use all the tools that you like you can use pandas

211
00:14:27,800 --> 00:14:34,680
we also heavily leverage the arrow framework like for like managing in memory data frames

212
00:14:34,680 --> 00:14:38,840
and then like you can just like in your normal python code like do the processing you like so now

213
00:14:38,840 --> 00:14:42,920
of course the question that might be might be going on in your head is that well I mean how does

214
00:14:42,920 --> 00:14:48,600
it scale like how it works if you have massive amounts of data one realization that we we had is

215
00:14:48,600 --> 00:14:53,960
that also that Netflix not everything is absolutely like massive scale we have many many use cases

216
00:14:53,960 --> 00:14:58,200
where the data actually fits in memory when you are a little bit careful how you how you handled

217
00:14:58,200 --> 00:15:03,800
the handle the kind of the data representation and the example I always use that if you imagine

218
00:15:03,800 --> 00:15:07,800
that today Netflix is about hundred and fifty million accounts if you have a data frame with

219
00:15:07,800 --> 00:15:11,880
hundred and fifty million rows and then like a thousand columns maybe maybe we are talking about

220
00:15:11,880 --> 00:15:15,960
the hundred and fifty gigabytes of data so which is something that you can hold in memory in on a

221
00:15:15,960 --> 00:15:21,480
large machine so like then you can just treat it as a big pandas data frame or something of

222
00:15:21,480 --> 00:15:25,960
that sort and it just makes life very easy obviously I mean it doesn't work for the largest

223
00:15:25,960 --> 00:15:32,040
scale use cases but it definitely works for 80 percent of use cases so the fast data abstraction

224
00:15:32,040 --> 00:15:39,160
is primarily focused on getting information in from S3 quickly and making accessible to the rest

225
00:15:39,160 --> 00:15:46,440
of your Python code you kind of describe this as an optimization how how do you optimize that if

226
00:15:46,440 --> 00:15:52,120
it all lives on the cloud yeah much of it beneath your kind of control horizon absolutely and that's

227
00:15:52,120 --> 00:15:57,720
a that's a great question and now what one like unique perspective that we have here is that

228
00:15:57,720 --> 00:16:02,200
Netflix has been working with AWS for more than ten years so we have a lot of operational

229
00:16:02,200 --> 00:16:07,560
expertise and experience how how to deal with AWS and and the fact is that AWS is amazing it's

230
00:16:07,560 --> 00:16:12,120
very easy to use but there are also certain things that just make life easier if you know how to do

231
00:16:12,120 --> 00:16:16,840
right and like these best practices are something that we baked in into the meta flow so for instance

232
00:16:16,840 --> 00:16:21,400
for things like S3 access they're like ways how you handle multiple connections to S3 so that like

233
00:16:21,400 --> 00:16:25,960
you can maximize the throughput things like that absolutely things that we don't expect that like

234
00:16:25,960 --> 00:16:30,360
any data scientists and not even more software engineers know about but I mean things that

235
00:16:30,360 --> 00:16:36,760
that like we want to provide providers a service so it sounds like you're counting on folks doing

236
00:16:36,760 --> 00:16:42,920
ETL and and data pipelines and Spark and other things you're not offering some new infrastructure for

237
00:16:42,920 --> 00:16:52,040
that are you doing anything around like a feature store or some way for data scientists to collaborate

238
00:16:52,040 --> 00:17:00,680
on data pipelines yeah I love that question well now the short answer is surprisingly maybe no

239
00:17:00,680 --> 00:17:07,480
and and like we have been thinking about that a lot and one thing that we do feel very strongly

240
00:17:07,480 --> 00:17:11,480
about is overall the question of collaboration and like how do we enable people to collaborate

241
00:17:11,480 --> 00:17:16,600
and like we provide a lot of tooling to to help everyone to first organize their work so then

242
00:17:16,600 --> 00:17:20,040
and actually it happens pretty much automatically so you automatically everything you do I mean

243
00:17:20,040 --> 00:17:25,080
gets persisted in the cloud anybody else can see what you have done and and they can build on your

244
00:17:25,080 --> 00:17:32,280
results now at the same time collaboration is actually pretty hard and like in general and

245
00:17:32,280 --> 00:17:36,040
in particular in data science and and the reason for that is let me just give you a practical

246
00:17:36,040 --> 00:17:41,000
example that if you have a data scientist let's say who builds some amazing embeddings like

247
00:17:41,800 --> 00:17:45,640
that like these are the ways how we can characterize let's say some content or something

248
00:17:45,640 --> 00:17:49,800
and now like someone else could potentially benefit from these features well that that works

249
00:17:49,800 --> 00:17:54,040
all couldn't find maybe like kind of during the first iteration but now what happens if the

250
00:17:54,040 --> 00:17:58,600
original data scientist who built the embeddings decides to like change something upstream and now

251
00:17:58,600 --> 00:18:02,840
of course like you have this trickle effect to do everything downstream and it takes a lot of

252
00:18:02,840 --> 00:18:08,120
discipline to actually now manage the upstream so that like these defects don't have any any adverse

253
00:18:08,120 --> 00:18:13,480
effects in the in the models downstream and and and there's like a difficult trade off between

254
00:18:13,480 --> 00:18:18,520
the stability like kind of okay being really stable so my consumers can consume my my features

255
00:18:18,520 --> 00:18:23,160
versus then being able to iterate fast right and and like we are definitely we have been always

256
00:18:23,160 --> 00:18:28,280
leaning kind of on the side of allowing people to iterate fast ultimately that is that is really

257
00:18:28,280 --> 00:18:32,680
really like what matters like many of these things are very experimental and then like only in some

258
00:18:32,680 --> 00:18:36,760
like very rare cases we understand that this is something like in some specific domains that like

259
00:18:36,760 --> 00:18:41,000
now we should make it so that like more people can start like sharing a features or like maybe code

260
00:18:41,000 --> 00:18:45,080
that generates the features rather than the features themselves so we have a bit like a shy

261
00:18:45,080 --> 00:18:50,680
the way from like being a super press prescriptive like how one should like store the features

262
00:18:50,680 --> 00:18:54,360
also the realization in our cases that we are supporting hundreds of different use cases

263
00:18:54,360 --> 00:19:00,360
and what features mean for MLP is different what features mean for for for some like a statistical

264
00:19:00,360 --> 00:19:05,080
like experimentation design pipeline which is different than what it means for for operations

265
00:19:05,080 --> 00:19:09,560
research so it's very hard to be press prescriptive about that but I mean we are always keeping our

266
00:19:09,560 --> 00:19:14,200
eyes and ears open like kind of how we should go about doing it so you definitely raise an

267
00:19:14,200 --> 00:19:19,480
interesting point there a lot of the the work that I see happening in the platform space is trying

268
00:19:19,480 --> 00:19:24,760
to drive this idea of reusability with you know either things like a feature store and reusing

269
00:19:24,760 --> 00:19:30,920
features or reusable data pipelines or like an embedding store or things like that but

270
00:19:31,720 --> 00:19:36,360
you know those the kinds of things are best done when the the teams that publish those treat

271
00:19:36,360 --> 00:19:42,200
them as products right yeah contracts right and and you know often there are implicit assumptions

272
00:19:42,200 --> 00:19:46,840
that are made in the thing that are hard to communicate yeah and if someone takes it off the

273
00:19:46,840 --> 00:19:51,960
shelf and tries to use it they need to really know about those those kinds of things yeah

274
00:19:52,600 --> 00:19:59,320
and you mentioned the the issue of when the original user wants to evolve the thing like

275
00:19:59,320 --> 00:20:04,520
you know the complexity is multiplied by the number of us that have ended up using it yeah

276
00:20:04,520 --> 00:20:09,720
so it's interesting to hear that the solution that you've chosen is to just not address it all

277
00:20:09,720 --> 00:20:15,240
yeah or like lead lead users to kind of a maybe kind of a manage it by themselves also the kind

278
00:20:15,240 --> 00:20:19,160
of the question I would like always to ask when people and like you believe me I mean people

279
00:20:19,160 --> 00:20:23,320
ask about this all the time even like data scientists at Netflix that like well and we have something

280
00:20:23,320 --> 00:20:28,840
like that I think like one one reason like why people feel in many cases that it is really important

281
00:20:28,840 --> 00:20:33,080
is that like when when things are slow and when things are hard reusability of course become

282
00:20:33,080 --> 00:20:37,080
super important like if you feel that oh I have to spend like three hours doing this then I'd

283
00:20:37,080 --> 00:20:41,080
be amazing if I could just get get it off the shelf absolutely it makes sense on the other

284
00:20:41,080 --> 00:20:45,320
than like if doing something takes about 15 seconds I mean then the reusability isn't quite that

285
00:20:45,320 --> 00:20:49,560
important because if it's just easy enough I mean then like you can just do it by yourself and you

286
00:20:49,560 --> 00:20:53,640
get exactly what you need so there's this like an interesting kind of a question that like everybody

287
00:20:53,640 --> 00:20:58,040
should be asking that like is it that like we need the reusability only because like everything is

288
00:20:58,040 --> 00:21:02,200
so hard and maybe we should like fix the root cause which is that things are you hard in the first

289
00:21:02,200 --> 00:21:06,680
place or is there like some actual actual need for reusability like when it comes to features and

290
00:21:06,680 --> 00:21:11,320
pipelines and now the thing is that like I absolutely do believe that like we need reusable data

291
00:21:11,320 --> 00:21:15,960
pipelines and features for specific domains so if you have a use case like recommendations or in

292
00:21:15,960 --> 00:21:20,360
my previous live I've used to do real-time bidding stuff like that I mean totally make sense

293
00:21:20,360 --> 00:21:24,360
but then like the use cases that we are dealing with are often there's more experimental in nature

294
00:21:25,000 --> 00:21:29,480
and it's just a question like where you are like kind of a in the life cycle of your project and I

295
00:21:29,480 --> 00:21:34,440
think that the sharing like comes much at much later stages of the project and many many people

296
00:21:34,440 --> 00:21:41,640
imagine and an interesting middle ground that I've seen work pretty effectively is to you know

297
00:21:41,640 --> 00:21:46,440
when folks don't want to build a bunch of infrastructure to support this collaboration to

298
00:21:47,320 --> 00:21:54,280
identify the you know the core features like you know there's going to be user features there's

299
00:21:54,280 --> 00:22:01,320
going to be product features you know in the case of Netflix maybe you know there are you know

300
00:22:01,320 --> 00:22:08,120
specific features around the the films things like that that probably a lot of data scientists are

301
00:22:08,120 --> 00:22:12,680
going to want to use and so the infrastructure team kind of owns you know those not necessarily

302
00:22:12,680 --> 00:22:18,440
through some generic infrastructure for right you know feature reuse but there are kind of vetted

303
00:22:18,440 --> 00:22:24,920
you know data pipelines and features for specific entities that everyone's going to want right

304
00:22:24,920 --> 00:22:29,240
right and I think that there's a crucial difference between kind of facts and features so I mean

305
00:22:29,240 --> 00:22:34,440
like we have a highly created tables that are easily available and widely shared for facts for

306
00:22:34,440 --> 00:22:39,880
things like I mean like what kind of a movie is people watching so forth and then like people can

307
00:22:39,880 --> 00:22:44,120
derive different type of features easily like from those so there's the question that yes I mean

308
00:22:44,120 --> 00:22:48,440
like we want to share data we obviously want to share facts but and like we occasionally like want

309
00:22:48,440 --> 00:22:53,720
to even share code that produces the features but do we want to share the final features like as

310
00:22:53,720 --> 00:22:58,840
is I mean that is a trickier question right right right so the the perspective then to kind of

311
00:22:58,840 --> 00:23:06,520
dig into that is a lot of times we think of the the features as this monolithic thing and you know

312
00:23:06,520 --> 00:23:12,040
them being hard to create and the data scientists spend 80% of their time you know doing feature

313
00:23:12,040 --> 00:23:16,360
engineering and getting the data and we throw that number around it sounds like your perspective

314
00:23:16,360 --> 00:23:21,240
might be well a lot of the challenges in getting access to the facts right so if we make

315
00:23:21,240 --> 00:23:28,280
a getting access to the facts easier then the features from the facts is more incremental and as

316
00:23:28,280 --> 00:23:32,440
were your 15 second versus three hours right right and like when you think about it I mean there's

317
00:23:32,440 --> 00:23:36,600
the question that like ultimately like how do you how do you improve the quality of models I mean

318
00:23:36,600 --> 00:23:41,160
the fact is that oftentimes it is much about data much about feature engineering so in a way I

319
00:23:41,160 --> 00:23:44,760
mean that is like that should be in a way I mean oftentimes the center of your attention I mean

320
00:23:44,760 --> 00:23:50,040
there's nothing wrong about that so I don't know how it could work if all you can do is to check

321
00:23:50,040 --> 00:23:53,800
some checkboxes and say that okay these are the features I want to use we actually want that

322
00:23:53,800 --> 00:23:58,920
people apply their domain knowledge and understanding in data and producing the features we just

323
00:23:58,920 --> 00:24:07,480
want to make it very easy to do it okay so you've got this high performance access to data and then

324
00:24:07,480 --> 00:24:16,040
folks are building out their models in Python does Metaflow include integrate with paper mill

325
00:24:16,040 --> 00:24:21,160
is there a relationship between it too yeah so now we have Netflix employees actually a number of

326
00:24:21,160 --> 00:24:26,840
people who contribute to Jupiter project and we also recently opened source another notebook project

327
00:24:26,840 --> 00:24:33,960
called Polynote like very exciting and and like they are a node Poly Polynote okay Polynote yeah

328
00:24:33,960 --> 00:24:39,800
Polynote dot org and and we work closely with them and it's an interesting question like how

329
00:24:39,800 --> 00:24:45,160
how how we like we see the data like notebook should be used in in conjunction with Metaflow so

330
00:24:45,160 --> 00:24:52,200
actually as of today we we require that people write the Metaflow code outside of notebooks and

331
00:24:52,200 --> 00:24:56,440
this is a very conscious decision like for the reason that we still feel that like much of the

332
00:24:56,440 --> 00:25:02,120
tooling for producing software is is kind of a better like kind of a been in kind of a traditional

333
00:25:02,120 --> 00:25:08,120
ideas and and like you have the the version control for your code and all that stuff now that being

334
00:25:08,120 --> 00:25:14,440
said we support notebooks first class as a way to inspect the results I mean that's where notebooks

335
00:25:14,440 --> 00:25:18,280
absolutely shine that you can you can like what you built a library you can use it in a notebook

336
00:25:18,280 --> 00:25:23,480
exactly totally and this is really surprising because I think a lot of us hold up Netflix as the

337
00:25:23,480 --> 00:25:30,280
poster child of an organization that is trying to extend notebooks beyond experimentation even

338
00:25:30,280 --> 00:25:36,280
into production yeah and and actually like one one thing I mean like now like building on that

339
00:25:36,280 --> 00:25:42,120
thought that like building this visualization in inspecting results is so so easy in notebooks

340
00:25:42,120 --> 00:25:47,160
this kind of relates to the question of of UIs and interestingly Metaflow as of today doesn't come

341
00:25:47,160 --> 00:25:51,800
with any graphical UI per se and again I mean that's a very thoughtful decision based on the

342
00:25:51,800 --> 00:25:56,680
based on the realization that like many of the use cases we support it have very specific needs

343
00:25:56,680 --> 00:26:01,240
and it would be very hard to have like one size fits all UI then like factually yes we could

344
00:26:01,240 --> 00:26:05,960
provide some metrics showing that okay here's our model converges and we actually ask data scientists

345
00:26:05,960 --> 00:26:10,040
if this is something that they would not need or want and like they say that well actually that's

346
00:26:10,040 --> 00:26:13,640
really not the most important thing maybe it would be nice to have but I mean not the most

347
00:26:13,640 --> 00:26:17,240
important thing and often I'm sitting they want to see a something really related to their like

348
00:26:17,240 --> 00:26:21,400
the business question or the model itself and that's how they want to monitor the results

349
00:26:21,400 --> 00:26:25,880
and what we do today is that we allow people to define exactly the visualizations and the metrics

350
00:26:25,880 --> 00:26:30,440
they need in a notebook and they can data scientists stop more than capable and like actually like

351
00:26:30,440 --> 00:26:34,440
really eager to build these visualizations by themselves and now since you brought up the topic

352
00:26:34,440 --> 00:26:39,080
of paper mill what paper mill does is that it allows one to take a notebook and then kind of a

353
00:26:39,080 --> 00:26:43,640
render the notebook in a headless manner like kind of a been in a scheduling system so then

354
00:26:43,640 --> 00:26:47,640
interestingly what we get is that we can render these notebooks automatically whenever the model

355
00:26:47,640 --> 00:26:51,800
updates and like we can push it to some location so that you can just go in your browser to some

356
00:26:51,800 --> 00:26:56,600
location and you always have a place like where you where you have a custom visualization of the

357
00:26:56,600 --> 00:27:02,840
latest state of your model so now I mean in short how we use paper mill would kind of use tools

358
00:27:02,840 --> 00:27:08,440
like paper mill to basically use notebooks almost as a UI in addition to using notebooks as a scratch

359
00:27:08,440 --> 00:27:13,240
patch so so yes I mean like Netflix does a lot of work around notebooks and for notebooks but at

360
00:27:13,240 --> 00:27:17,000
the same time we are like really thoughtful that like what are the kind of good use cases for notebooks.

361
00:27:17,560 --> 00:27:25,640
Going back to the data scientist experience when it comes to experimentation, training,

362
00:27:25,640 --> 00:27:33,800
model development, what is Metaflow providing there? Yeah so one of the first things that we

363
00:27:33,800 --> 00:27:40,600
wanted to do well is the support for the local development experience so in my previous life I

364
00:27:40,600 --> 00:27:45,400
used many other Python frameworks for workflow management like Luigi and Airflow and they

365
00:27:45,400 --> 00:27:51,400
create tools especially in production but it turns out that it's not so easy to actually develop

366
00:27:51,400 --> 00:27:55,960
your workflows. The question is what you handed when you're trying to run another. Exactly so if

367
00:27:55,960 --> 00:28:00,520
you think that what's really the fastest way to iterate on something new is that like you have a

368
00:28:00,520 --> 00:28:04,600
Python script running on your laptop and you can just like keep running it there's no no latency

369
00:28:04,600 --> 00:28:09,000
nothing I mean you just hack the code you iterate and or you do it in a notebook so that's the

370
00:28:09,000 --> 00:28:13,240
perfect experience then we wanted to replicate that experience with Metaflow so that you can run

371
00:28:13,240 --> 00:28:18,600
Metaflow locally and like you can develop everything it's super fast and so forth. Now the next

372
00:28:18,600 --> 00:28:23,000
question is that okay once you have that local version working how do you then like even scale it

373
00:28:23,000 --> 00:28:26,440
out not even take it to production but I mean let's say you want to like try it with larger

374
00:28:26,440 --> 00:28:31,160
amounts of data and in some cases it might be that you just have to re-implement the whole thing

375
00:28:31,160 --> 00:28:35,240
let's say using Spark which is a fine way of doing it but at the same time like requires a bit

376
00:28:35,240 --> 00:28:39,800
of a change in paradigm also it doesn't always play nicely with the off-the-shelf libraries like

377
00:28:39,800 --> 00:28:44,280
TensorFlow, PyTorch and XT boost and so forth. So what Metaflow provides is that you can first

378
00:28:44,280 --> 00:28:48,520
prototype locally as you would do with any Python script and there's a very easy one line of code

379
00:28:48,520 --> 00:28:51,960
or like just one command line switch and you can start running it in the cloud with arbitrary

380
00:28:51,960 --> 00:28:56,600
amount of resources and then like what with the single command you can export the whole workflow

381
00:28:56,600 --> 00:29:01,320
to a production scheduler so that then it becomes totally production ready and like a part of the

382
00:29:01,320 --> 00:29:09,480
overall data ecosystem at your companies. So does the library have its own workflow type of

383
00:29:09,480 --> 00:29:15,480
implementation paradigm separate from you know something like Argo or Airflow or you know

384
00:29:15,480 --> 00:29:20,200
Luigi. Yeah yeah we do have a local for the local experience we do have a local workflow engine

385
00:29:20,200 --> 00:29:25,640
and now at the same time like we absolutely like the the workflow part is only a kind of a small

386
00:29:25,640 --> 00:29:29,480
part the crucial but small part of Metaflow so we don't want to become a generic workflow engine

387
00:29:29,480 --> 00:29:34,040
we think that all these off-the-shelf tools including also AWS that functions could be a great way

388
00:29:34,040 --> 00:29:38,920
to kind of run these workflows in production internally at Netflix we are using a tool called

389
00:29:38,920 --> 00:29:43,480
Mason like there are a few like presentations about it available publicly that provides all kind

390
00:29:43,480 --> 00:29:48,920
of a nice operational features like high availability, alerting, UIs and like you can of course like

391
00:29:48,920 --> 00:29:53,800
get something like that from from Airflow as well. So the idea is that you can define your workflow

392
00:29:53,800 --> 00:29:58,200
in Metaflow and then you can export the workflow without any changes to one of these production

393
00:29:58,200 --> 00:30:02,360
schedulers so you kind of get the both best of the both worlds you get the perfect local experience

394
00:30:02,360 --> 00:30:06,920
as well as the kind of the production grade like workflow scheduling then like when you want to do

395
00:30:06,920 --> 00:30:13,720
things at large scale on a daily basis. We're talking about local and then production grade

396
00:30:13,720 --> 00:30:21,160
is there also a non-local distributed training type of environment that users can

397
00:30:21,160 --> 00:30:27,320
push to to scale up their ability to train a model. So that's where we really heavily leverage

398
00:30:27,320 --> 00:30:32,440
the cloud. So the beautiful thing about about a system like AWS and the same thing of course

399
00:30:32,440 --> 00:30:37,720
applies to any other cloud provider is that you can imagine that you have virtually unlimited

400
00:30:37,720 --> 00:30:44,360
amount of compute capacity and like storage capacity and we really heavily rely on that so you

401
00:30:44,360 --> 00:30:48,200
can define your workflow and like you can define the task in your workflow and like you can add

402
00:30:48,840 --> 00:30:53,960
like in our case at the batch decorator in which case we just like a take your Python functions and

403
00:30:53,960 --> 00:31:00,200
execute them in the cloud using AWS batch in the case of Metaflow today and we take care of like

404
00:31:00,200 --> 00:31:04,440
take packaging your code and like sending it to the cloud and getting the data and persisting the

405
00:31:04,440 --> 00:31:09,160
data all that stuff. So the code look exactly like what you would do locally in Python but at the

406
00:31:09,160 --> 00:31:14,200
same time what's really amazing is that you can specify the resources you want you can say that oh

407
00:31:14,200 --> 00:31:19,560
I want I want 200 gigabytes of RAM or I want eight GPUs and so forth. So the abstraction that we

408
00:31:19,560 --> 00:31:23,800
would like to have is that imagine that you had a laptop that like with the press of a button you

409
00:31:23,800 --> 00:31:27,320
can just like change the configuration on your laptop so you can say that like well I mean what if

410
00:31:27,320 --> 00:31:31,720
my laptop had like 200 gigabytes of RAM or what if my laptop had eight GPUs I mean that would be

411
00:31:31,720 --> 00:31:35,720
just amazing I mean that would be the kind of the ultimate way to do like kind of this development

412
00:31:35,720 --> 00:31:41,480
because you get the low latency as well as like almost unlimited resources. So that's kind of the

413
00:31:41,480 --> 00:31:45,560
vertical scalability part when you just want to get the bigger box there's of course the question

414
00:31:45,560 --> 00:31:50,520
that well I mean what if I want more boxes and and oftentimes what happens in our work flows is

415
00:31:50,520 --> 00:31:55,320
that we are not only training a single model but we are training multiple models and it might be

416
00:31:55,320 --> 00:31:59,160
that let's say we train a different model for every country or it could be that we just want to do

417
00:31:59,160 --> 00:32:05,480
a hyperparameter search. So we we define a agreed off of of 200 different parameterizations of

418
00:32:05,480 --> 00:32:09,720
the model and then we just fan out everything to the cloud and and like the cloud then like the

419
00:32:09,720 --> 00:32:13,400
xcare of like building all the models in parallel and then like metaflow takes care of fending in

420
00:32:13,400 --> 00:32:17,720
the results and you choose the model that you want to use. I know like a model parallelism. Exactly

421
00:32:17,720 --> 00:32:23,240
opposed to data or exactly and then of course like for the cases when you absolutely need like

422
00:32:23,240 --> 00:32:28,200
distributed models and and this happens although again it's more of a like a 20% use case rather than

423
00:32:28,200 --> 00:32:36,760
an 80% use case in our case. Is that roughly correlating to traditional models versus deep learning

424
00:32:37,320 --> 00:32:42,680
use question not not necessarily I mean it's it's amazing like even like how far you can get with

425
00:32:42,680 --> 00:32:48,520
one big box with with the number of GPUs even with with with the deep models but yes I mean like

426
00:32:48,520 --> 00:32:52,520
of course like in extreme cases let's say in computer vision you absolutely do need distributed

427
00:32:52,520 --> 00:32:57,480
learning like for for DNNs and and then like you can you can we also provide integrations of things

428
00:32:57,480 --> 00:33:02,280
like Amazon Sage maker that have distributed TensorFlow built in so that's an easy way. The

429
00:33:02,280 --> 00:33:05,880
fact is that distributed learning and like setting up the infrastructure for that is pretty hard

430
00:33:05,880 --> 00:33:10,840
and managing it pretty hard so what we do is that first I mean like we we try to remind people

431
00:33:10,840 --> 00:33:14,280
that if you don't need it if you can do it without it so I mean that that's always a good first

432
00:33:14,280 --> 00:33:18,280
depending if you need it I mean there are like infrastructure that can take care of it.

433
00:33:18,280 --> 00:33:26,840
You mentioned Sage maker I was surprised to hear that at the same time that AWS is announcing

434
00:33:27,480 --> 00:33:35,960
a ton of new ML ops ML in for our capabilities to Sage maker, experiment management,

435
00:33:35,960 --> 00:33:47,800
piece IDEs, studio debugger they're also you know actively promoting what you're doing with with Metaflow.

436
00:33:47,800 --> 00:33:52,040
You know why do you think that they're excited about it? We think about the data scientists

437
00:33:52,040 --> 00:33:57,960
productivity in very much the same way Amazon has realized that that the kind of the big bottleneck

438
00:33:57,960 --> 00:34:03,240
like for for for companies for being able to benefit more from data science is really the data

439
00:34:03,240 --> 00:34:07,000
scientists productivity like more than anything else and they are heavily investing on improving

440
00:34:07,000 --> 00:34:11,160
that situation like you mentioned the IDEs and the debuggers like all of those things are like a

441
00:34:11,160 --> 00:34:16,600
huge steps towards increasing productivity and now there is in the single formula how to increase

442
00:34:16,600 --> 00:34:21,000
productivity and like what we have done internally at Netflix over the past couple of years it has

443
00:34:21,000 --> 00:34:26,520
proven to work it is widely used inside Netflix and Amazon was really excited to see that there's

444
00:34:26,520 --> 00:34:31,160
a pattern that really works nicely with AWS it leverages the best parts of Sage maker and batch

445
00:34:31,160 --> 00:34:36,040
and S3 and so forth and and like we can just make it available to everybody so I think like you

446
00:34:36,040 --> 00:34:41,640
have very much aligned like when it comes to that. So what are the integration points with Sage maker?

447
00:34:41,640 --> 00:34:46,760
Yeah so like we are working on this integration that would allow you to take any Metaflow artifact

448
00:34:46,760 --> 00:34:50,920
so we like something that like we we haven't touched before is that is the question that like how

449
00:34:50,920 --> 00:34:56,360
we manage data inside this workflows so we automatically persist everything in S3 and and one

450
00:34:56,360 --> 00:35:00,760
thing about the Sage maker is that it's really amazing like with all the built in training algorithms

451
00:35:00,760 --> 00:35:04,280
that come with it but I mean still there's some some kind of a bookkeeping that you have to do to

452
00:35:04,280 --> 00:35:09,960
kind of persist the input data in S3 and like take the outputs and and and so forth so when you use

453
00:35:09,960 --> 00:35:15,160
Sage maker with Metaflow all that stuff is is taking care of for you so like we we handle the the

454
00:35:15,160 --> 00:35:19,480
S3 management for you and then you can just basically with one line say that okay then here's my data

455
00:35:19,480 --> 00:35:23,240
I want to train a model and then the model comes out and then you can use it in your Metaflow workflow

456
00:35:23,240 --> 00:35:27,880
as before and what's really exciting is that also in the workflow you can mix and match different

457
00:35:27,880 --> 00:35:31,800
parts also like an important fact is that this machine learning workflows are never only about

458
00:35:31,800 --> 00:35:35,880
machine learning oftentimes there's the data part and you may have your training part and then

459
00:35:35,880 --> 00:35:40,120
maybe there's some post processing like before you push the results somewhere like maybe that you

460
00:35:40,120 --> 00:35:44,120
write them to a table or maybe you deploy them as a microservice so you take a couple of steps

461
00:35:44,120 --> 00:35:49,160
after that so now Metaflow helps you to manage the whole pipeline and like somewhere in the pipeline

462
00:35:49,160 --> 00:35:53,400
and you can totally leverage Sage maker and like maybe you deploy to Sage maker in the end but then

463
00:35:53,400 --> 00:35:57,800
like Metaflow is kind of the substrate that that combines everything together is but I'm imagining

464
00:35:57,800 --> 00:36:04,760
that there are also a number of areas of overlap for example it sounds like while you're not providing

465
00:36:05,960 --> 00:36:12,520
visualization type of an experience for managing experiments you are managing the experimental data

466
00:36:13,400 --> 00:36:20,760
do you go to any specific length to try to make this you know smooth for for users you know what

467
00:36:20,760 --> 00:36:26,520
you should use where and when given that the company so heavily invested in the AWS tooling and

468
00:36:26,520 --> 00:36:32,760
ecosystem and and users will be you know it sounds like you've got some fair usage of Sage maker

469
00:36:32,760 --> 00:36:38,520
internally right so well I mean now not one thing is that over over the past many years Netflix has

470
00:36:38,520 --> 00:36:43,000
been building a lot of infrastructure like even before Sage maker existed and like for instance

471
00:36:43,000 --> 00:36:47,960
for notebooks we have our own like internally infrastructure how people can provision notebooks so

472
00:36:47,960 --> 00:36:52,280
they can get their managed notebook instances and so forth and now given that that's something that

473
00:36:52,280 --> 00:36:56,760
Netflix built internally it works for us we are using that at the same time we recognize that

474
00:36:56,760 --> 00:37:01,320
that's not available outside Netflix it's really deeply embedded in our environment and that's

475
00:37:01,320 --> 00:37:05,320
on the other hand something that Sage maker provides so we feel that it totally makes sense to use

476
00:37:05,320 --> 00:37:10,200
Sage maker notebooks if you don't have a managed notebook environment of your own and and now I mean

477
00:37:10,200 --> 00:37:14,200
we are like evaluating all the new offerings like what you mentioned about the experiment tracking

478
00:37:14,200 --> 00:37:19,000
UI that we have we have some like approaches how we have solved similar problems in the past now

479
00:37:19,000 --> 00:37:22,680
I mean it just made the release and like now we are evaluating the like like where things will go

480
00:37:22,680 --> 00:37:29,400
in the long terms yeah I'm drawing a lot from the cloud side of things but my impression has

481
00:37:29,400 --> 00:37:33,400
been that you know Netflix has always been hey if we don't have to do it we don't want to do it

482
00:37:33,400 --> 00:37:41,080
we'll let AWS do it yeah and so I imagine as Sage maker evolves you'll be continually evaluating

483
00:37:41,080 --> 00:37:45,240
you know what pieces of it you'll continue to support versus yeah I think you're spot on and I

484
00:37:45,240 --> 00:37:51,880
think it's an important like kind of a important design principle in Metaflow overall that Netflix

485
00:37:51,880 --> 00:37:55,880
is really not in the business for like building this software and we are not in the business for

486
00:37:55,880 --> 00:38:00,040
selling machine learning solutions I mean ultimately we want to entertain the world I mean that's

487
00:38:00,040 --> 00:38:05,320
what we do we really focus on that one one case and now so it happens that like an important

488
00:38:05,320 --> 00:38:10,360
component of our business goal is to be able to use data and data science and like these are

489
00:38:10,360 --> 00:38:15,000
the tools we need so we build the pragmatic tools that like answer like a very pragmatic business

490
00:38:15,000 --> 00:38:19,000
questions and I do feel that many other companies are in the same position that there are not in

491
00:38:19,000 --> 00:38:22,360
the business for building machine learning tools they are not in the business even like building

492
00:38:22,360 --> 00:38:26,840
machine learning per se it's just want to leverage it in their business to improve their whatever

493
00:38:26,840 --> 00:38:31,880
business outcome state they have in mind and I think that's why I mean did the pragmatic approach

494
00:38:31,880 --> 00:38:35,640
that Metaflow has taken like we can leverage the cloud when it makes sense like we can just

495
00:38:35,640 --> 00:38:39,560
focus on making data scientists product even in like a very practical business use cases and

496
00:38:39,560 --> 00:38:43,480
probably it resonates with many other companies as well so one of the things that I'm curious about

497
00:38:43,480 --> 00:38:54,360
is the flow of projects and use cases onto into and out of off of the infrastructure that

498
00:38:54,360 --> 00:39:00,520
you you've built with Metaflow and more broadly ML infrastructure and Netflix you started off by

499
00:39:00,520 --> 00:39:06,680
saying that recommendations you know wasn't even in scope right it's a mature use of machine

500
00:39:06,680 --> 00:39:11,720
learning you know they've been doing it for a very long time so it's not something that you

501
00:39:11,720 --> 00:39:18,200
are building for what you're primarily building for are these smaller teams newer use cases

502
00:39:18,920 --> 00:39:24,680
and correct me at any time but smaller teams newer use cases that you know haven't built up

503
00:39:24,680 --> 00:39:31,640
the infrastructure support internally I imagine that some of those at some point grow in complexity

504
00:39:31,640 --> 00:39:37,480
and sophistication and maybe need more than what the infrastructure can offer and you know may

505
00:39:37,480 --> 00:39:44,120
start to look at building their their own things or I'm generally curious about the way that

506
00:39:44,120 --> 00:39:50,840
dynamic is managed at Netflix and and how both the projects use of the infrastructure and the

507
00:39:50,840 --> 00:39:56,840
infrastructure evolves yeah well let me illustrate this like by by kind of a giving kind of a two

508
00:39:56,840 --> 00:40:01,720
metaphors I mean one is that production is really a spectrum it's not the dot that hears the

509
00:40:01,720 --> 00:40:06,360
production but it's a spectrum and so indeed we do have use cases that are absolutely business

510
00:40:06,360 --> 00:40:10,920
critical absolutely core to the business and like absolutely must not fail but still it might be

511
00:40:10,920 --> 00:40:16,600
that the scale is not huge so it's a like smaller scale maybe in terms of the data size but it's

512
00:40:16,600 --> 00:40:20,600
not smaller scales in terms of importance so it's really like a spectrum or maybe even like two

513
00:40:20,600 --> 00:40:24,440
dimensional plane like where you have different production use cases that's one thing

514
00:40:24,440 --> 00:40:30,600
metaflow there like covers a certain like part of that plane so and then the other important

515
00:40:30,600 --> 00:40:36,280
thing about this data science project is it's a funnel so we have tons of ideas that's like all

516
00:40:36,280 --> 00:40:40,920
companies doing data science employing data scientists know that all kinds of idea ideas what you could

517
00:40:40,920 --> 00:40:45,480
be doing what we would like to have optimally is the situation where people can really cheaply

518
00:40:45,480 --> 00:40:51,640
like a test different ideas experiment and then the fact is that like by design like many of

519
00:40:51,640 --> 00:40:56,200
these things actually like don't don't like so like enough promise that like we want to continue

520
00:40:56,200 --> 00:40:59,320
the investment and that's totally fine I mean that's how it's supposed to work and that's why

521
00:40:59,320 --> 00:41:03,640
it's a funnel and then like then when you go deeper down in the funnel I mean things do

522
00:41:03,640 --> 00:41:08,120
graduate and like then things might get bigger and so forth and again I mean now going back to the

523
00:41:08,120 --> 00:41:12,280
other idea of the spectrum I mean it's totally fine that like in some cases you can like totally

524
00:41:12,280 --> 00:41:17,000
manage the project operate the project in inside metaflow and that's what we aim to do in 80%

525
00:41:17,000 --> 00:41:21,720
of use cases now in some other cases like cases like if you are like super lucky you go through the

526
00:41:21,720 --> 00:41:26,440
funnel like your project becomes super super important also it turns out that it becomes super

527
00:41:26,440 --> 00:41:30,840
super large scale I think in those cases it's totally fine that then we say that now we want to

528
00:41:30,840 --> 00:41:35,000
build like specific infrastructure for this use case I mean there's nothing wrong with that and

529
00:41:35,000 --> 00:41:39,880
I realistically if you think about any frameworks that's how it always works so you start with some

530
00:41:39,880 --> 00:41:44,040
of the shell framework you enthusiastically use it then the company becomes big enough and then

531
00:41:44,040 --> 00:41:47,480
you realize that instead of using this like off the shell frameworks we have to build a custom

532
00:41:47,480 --> 00:41:51,560
solution I mean that's how it works and that's the reality the key thing there is that this happens

533
00:41:51,560 --> 00:41:56,920
in a very small fraction of all use cases and it's actually counterproductive to design a system

534
00:41:56,920 --> 00:42:01,480
that would theoretically like support any use cases one of those like a special snowflakes and

535
00:42:01,480 --> 00:42:06,280
and that's why we are really optimizing for the let's say the 95% of use cases while acknowledging

536
00:42:06,280 --> 00:42:12,200
the fact that maybe then the 5% graduate to a different system in the end. So you mentioned production

537
00:42:12,200 --> 00:42:18,120
as a spectrum and we haven't talked a whole lot about production what is Metaflow supporting

538
00:42:18,840 --> 00:42:25,240
from an inference perspective yeah like another important principle and by the way we list all

539
00:42:25,240 --> 00:42:29,960
the kind of the design principles of Metaflow on the on our in our documentation that really the

540
00:42:29,960 --> 00:42:35,640
kind of the guiding things for our work is the realization that like in real business environments

541
00:42:35,640 --> 00:42:40,600
these data science projects come in all shapes and sizes so there is in like one unified grand theory

542
00:42:40,600 --> 00:42:44,680
that this is how we always do inference or this is how we always deploy they are like so many

543
00:42:44,680 --> 00:42:49,240
different ways so sometimes you want to push results to a table where it's like the results get

544
00:42:49,240 --> 00:42:53,160
shown by a upload dashboard like sometimes the results are just used by another data scientist

545
00:42:53,160 --> 00:42:58,760
in a notebook and sometimes they may be power another system like as a microservice and now

546
00:42:58,760 --> 00:43:02,200
often times when when people talk about the inference and deployment they only think about the

547
00:43:02,200 --> 00:43:07,320
microservice use case that's one use case and we do have internal support for that but that's

548
00:43:07,320 --> 00:43:11,240
like only one of the use cases one of the kind of the output modalities that we support

549
00:43:11,960 --> 00:43:18,280
and internally like what we do with Metaflow is that we have this kind of almost as a function

550
00:43:18,280 --> 00:43:24,520
as a service platform that can consume the results of Metaflow pipelines and then deploy this as

551
00:43:24,520 --> 00:43:31,400
as basically like restful APIs or endpoints that then cost them internal AP like web applications

552
00:43:31,400 --> 00:43:35,240
can use or other microservices can use so this is of course like a very typical thing what you

553
00:43:35,240 --> 00:43:39,720
can also get with with statesmaker hosting service or the many many other platforms that provide

554
00:43:39,720 --> 00:43:44,200
similar functionality that really the important thing in our case is that there is a really seamless

555
00:43:44,200 --> 00:43:49,320
integration to Metaflow itself one one thing there is that we only do immutable deployments so

556
00:43:50,040 --> 00:43:55,800
all the artifacts produced by Metaflow pipelines are strongly versions strongly snapshot as immutable

557
00:43:55,800 --> 00:44:00,600
data blobs in s3 and then when we do a deployment we take one of these immutable data blobs

558
00:44:00,600 --> 00:44:05,480
which might be a model it might be a data set and then we push it as an as an immutable deployment

559
00:44:05,480 --> 00:44:12,120
to as a microservice and and what this current is as this then when you have an internally UI

560
00:44:12,120 --> 00:44:16,840
that like uses the machine learning models we have the perfect lineage that we know exactly that

561
00:44:16,840 --> 00:44:22,040
this model was produced by this workflow that was produced by this data set and like the

562
00:44:22,040 --> 00:44:25,480
important thing here is that the data scientists didn't have to do anything to make this possible

563
00:44:25,480 --> 00:44:29,320
because the fact is that this kind of bookkeeping is a bit boring it says but at the same time it's

564
00:44:29,320 --> 00:44:33,400
super super important so we just wanted to make that the experience happened out of the box

565
00:44:33,400 --> 00:44:37,800
so the data scientist doesn't need to be thinking about you know Git and using those kind of

566
00:44:37,800 --> 00:44:42,440
that's actually an interesting point that you mentioned Git since we like an early on like there

567
00:44:42,440 --> 00:44:47,320
was the question that that like while I'm a worsening like maybe we should use Git and

568
00:44:47,320 --> 00:44:51,560
should we use Git for a model should we use Git for data should we use Git for code obviously I

569
00:44:51,560 --> 00:44:55,720
mean Git is a good match for a code at the same time there's an interesting impedance mismatch between

570
00:44:55,720 --> 00:45:00,200
Git and then it's like a data science workflows that are you supposed to make a commit every time

571
00:45:00,200 --> 00:45:04,680
you run your notebook that's kind of not how Git is supposed to be used I mean the Git history

572
00:45:04,680 --> 00:45:10,600
looks kind of ugly if you do that it's kind of useless anyway so what we what we do is that we

573
00:45:10,600 --> 00:45:15,560
actually have a built-in content at your storage kind of a Git like where we automatically store

574
00:45:15,560 --> 00:45:19,400
like every time you run something we snapshot your code we snapshot your dependencies which is

575
00:45:19,400 --> 00:45:23,960
really important and which not even mean in the context of a notebook though right well I mean

576
00:45:23,960 --> 00:45:29,080
in the case you know like exactly or like in the case of metaflow you just take your workflow

577
00:45:29,080 --> 00:45:33,640
you run it into and unlike we persist all of those things automatically so you don't even have to

578
00:45:33,640 --> 00:45:39,960
use Git and and we kind of there was the idea that well I mean can we just like have some kind

579
00:45:39,960 --> 00:45:44,680
of a requirement or abstraction that like everybody uses and it's just felt that like it's just

580
00:45:44,680 --> 00:45:48,280
didn't feel quite right then we decided that well I mean let's build something that like does the

581
00:45:48,280 --> 00:45:53,480
job while not imposing any additional cognitive overhead that hears it yet another thing that you

582
00:45:53,480 --> 00:45:57,560
have to consider because I know that like if I were a data scientist by myself I wouldn't like

583
00:45:57,560 --> 00:46:01,240
to worry too much I mean my mind is elsewhere when I'm building the model I mean I don't want to

584
00:46:01,240 --> 00:46:06,760
worry about like commits and pool requests and whatnot so what is the you mentioned all the artifacts

585
00:46:06,760 --> 00:46:15,880
are stored in s3 for models and everything else but what is the artifact for a model is it

586
00:46:16,840 --> 00:46:22,600
pickle files jar files that kind of thing is it containers how are you what's kind of the currency

587
00:46:22,600 --> 00:46:28,120
of a model as opposed to the system right right so by default and this is like absolutely like one

588
00:46:28,120 --> 00:46:33,720
of the key features of metaflow is that in addition of like helping you to build your workflow as a

589
00:46:33,720 --> 00:46:39,960
as a DAG we also manage the internal state of the DAG so we automatically when you do something

590
00:46:39,960 --> 00:46:44,520
like you have a self dot model equals something we automatically persist at artifact so there's no

591
00:46:44,520 --> 00:46:50,840
need to write lines like store model load model like store data load data and and that reason for

592
00:46:50,840 --> 00:46:54,760
that again I mean goes back to the cognitive overhead that like every time you use a framework

593
00:46:54,760 --> 00:46:58,360
that forces you to decide like do I want to persist something you kind of have to think that well

594
00:46:58,360 --> 00:47:02,760
do I want to persist this I mean is this important enough and oftentimes people are just like really

595
00:47:02,760 --> 00:47:07,640
conservative thinking that like no I probably not important enough and then what happens is the two

596
00:47:07,640 --> 00:47:12,440
weeks after you deploy the product like it has been running two weeks in production then it fails

597
00:47:12,440 --> 00:47:16,120
then like you need troubleshoot like what was going on and then you don't have the piece of data

598
00:47:16,120 --> 00:47:19,800
that you would need to understand what was the internal state of the workflow so you could actually

599
00:47:19,800 --> 00:47:25,880
understand why it failed and that's why we so enthusiastically persist everything and since you ask

600
00:47:25,880 --> 00:47:31,240
about the format now again I mean we don't believe that there is necessarily like a single universal

601
00:47:31,240 --> 00:47:35,800
model serialization format so since we allow people to use all kind of frameworks what we do

602
00:47:35,800 --> 00:47:40,280
use that for normal basic Python objects we use pickle and like if people works I mean that's

603
00:47:40,280 --> 00:47:45,640
all good and fine we also as I mentioned we use like a content address storage we don't store copies

604
00:47:45,640 --> 00:47:50,440
we also compress everything and then like for models like let's say you have a cross model I mean

605
00:47:50,440 --> 00:47:55,320
if the modeling library has the serialization format of its own I mean we encourage people to use

606
00:47:55,320 --> 00:48:00,680
that so we don't try to abstract the way too much since the realization again is that like our

607
00:48:00,680 --> 00:48:06,600
users use such a heterogeneous set of different libraries that it would be always kind of like a

608
00:48:06,600 --> 00:48:11,640
cat and mouse came to kind of a try to implement the latest like a support for some serialization that

609
00:48:11,640 --> 00:48:16,440
like someone decided to use and and like it turns out that like given the additional support

610
00:48:16,440 --> 00:48:21,320
that people get from metaflow I mean kind of once you have the model adding the one line theory

611
00:48:21,320 --> 00:48:25,400
that says that okay now I need to save my cross model I mean it's not too much works you mentioned

612
00:48:25,400 --> 00:48:34,040
that model deployment for inference is at least the microservice based approaches functions

613
00:48:35,080 --> 00:48:40,440
is that specifically Lambda or do you have your own kind of function runner abstraction thing

614
00:48:40,440 --> 00:48:45,240
that you've built as part of metaflow so yeah good good question so this goes back to the

615
00:48:45,240 --> 00:48:51,560
previous question you had about like how we work with stage maker so Netflix has a very mature

616
00:48:51,560 --> 00:48:56,440
container management system called titles it's actually open source and as a part of that like we

617
00:48:56,440 --> 00:49:01,080
have been developing also kind of function as a service platform and like we are using that

618
00:49:01,080 --> 00:49:06,120
internally at the same time the functionally this is very close to Lambda and like there's actually

619
00:49:06,120 --> 00:49:10,440
an open kit happy issue now for a metaflow to to see like how much appetite there would be outside

620
00:49:10,440 --> 00:49:15,080
Netflix to have something like this available and like if there was appetite we could totally do

621
00:49:15,080 --> 00:49:19,160
something similar on top of Lambda at the same time this goes back to the question that while there

622
00:49:19,160 --> 00:49:23,960
are many other like tools doing doing similar things already available like stage maker deployments

623
00:49:23,960 --> 00:49:28,360
I mean maybe if people would be happy to use that I mean that would be an avenue like for providing

624
00:49:28,360 --> 00:49:34,680
hosting for metaflow so as the idea that the metaflow that's open source is a subset of the

625
00:49:34,680 --> 00:49:41,320
metaflow that is used internally with one of the big differences being hooks into these other

626
00:49:41,320 --> 00:49:49,080
Netflix projects and then when you the thing that an open source user would use is kind of scaled

627
00:49:49,080 --> 00:49:53,240
back so that it doesn't have the dependency on these other internally used projects and then

628
00:49:53,800 --> 00:50:01,640
if they you know if there's enough interest you might build hooks into the publicly available

629
00:50:01,640 --> 00:50:10,280
AWS analogues of those things or does metaflow you know include does it ship with hooks into the

630
00:50:10,280 --> 00:50:15,480
other Netflix open source ecosystem projects like how do you manage yeah all of that well I mean

631
00:50:15,480 --> 00:50:20,840
separately it seems like you know potentially a big distraction if you're your fundamental

632
00:50:20,840 --> 00:50:26,440
goal is to support your data scientists and you have these other people wanting to you know

633
00:50:26,440 --> 00:50:31,720
deploy the lambda like why do you care exactly I mean that's that's like honestly the reason why

634
00:50:31,720 --> 00:50:36,360
two two years for us to actually open source get off low we like wanting to be very conscious

635
00:50:36,360 --> 00:50:40,680
about that question that like internally like one of the one of the reasons why metaflow has been

636
00:50:40,680 --> 00:50:45,640
so so successful is that like really fanatic user support that we provide not only metaflow

637
00:50:45,640 --> 00:50:50,120
comes with really great documentation including the open source version but we also support our

638
00:50:50,120 --> 00:50:54,920
people on slacking on chat like really actively and like we wanted to provide similar kind of

639
00:50:54,920 --> 00:50:59,080
experience for everybody now at the realistically speaking again I mean like we we have very finite

640
00:50:59,080 --> 00:51:05,160
resources so so we wanted to be really thoughtful like how we how we kind of manage the workload

641
00:51:05,160 --> 00:51:10,680
now when you ask about like all these other like systems and like how we think about that well the

642
00:51:10,680 --> 00:51:16,680
fact is that like we release metaflow just 20 hours ago and that and we we like wanted to be very

643
00:51:16,680 --> 00:51:21,240
open about like what exists today in open source and what doesn't so you can go to the documentation

644
00:51:21,240 --> 00:51:26,120
and check the roadmap so we have about five six internal components that are not yet available

645
00:51:26,120 --> 00:51:31,080
open source including interesting stuff like a slackbot and like we have this internal like a

646
00:51:31,080 --> 00:51:35,400
data frame implementation stuff like that and we want to open it like ask people that like is

647
00:51:35,400 --> 00:51:39,240
something that like really would be interesting and useful to you and then we go with that in the

648
00:51:39,240 --> 00:51:43,400
long term the plan is definitely not to have to separate code basis we are actually like in in the

649
00:51:43,400 --> 00:51:47,240
in the first quarter of next year like migrating our internal systems to use the open source

650
00:51:47,240 --> 00:51:51,080
version as well which is like not that far the only difference is that like we we needed to get

651
00:51:51,080 --> 00:51:55,400
rid of these like internal like systems that like practically are not available like outside Netflix

652
00:51:56,040 --> 00:52:03,160
one thing I'll throw out there we recently started doing what we're calling demo casts which are

653
00:52:03,160 --> 00:52:09,400
kind of like an interview like this but with a kind of concrete you know background being a demo

654
00:52:10,280 --> 00:52:15,720
and if folks are interested and you're interested in open to it you know maybe it would be

655
00:52:15,720 --> 00:52:23,240
interesting kind of walk through this and and see see it and absolutely and maybe maybe like this

656
00:52:23,240 --> 00:52:27,000
is a good opportunity for me to pitch like one like really interesting feature that we have

657
00:52:27,640 --> 00:52:33,800
so when we open source metaflow we also realized that our cloud integrations integrations

658
00:52:33,800 --> 00:52:38,520
to AWS is one of kind of the killer features of metaflow now at the same time we knew that like for

659
00:52:38,520 --> 00:52:43,000
many individual data scientists it would be pretty hard to set up all the requirement required

660
00:52:43,000 --> 00:52:49,480
systems in AWS maybe they don't even have access to the companies AWS console so what we provide is

661
00:52:49,480 --> 00:52:54,680
this thing called the metaflow sandbox that allows anybody to just like a sign up for kind of a

662
00:52:54,680 --> 00:53:00,920
test evaluation environment and and we and actually this this like works like kind of it's paid by

663
00:53:00,920 --> 00:53:07,000
by by by Netflix and you get your own private AWS environment where you can test like all these

664
00:53:07,000 --> 00:53:12,600
cloud integrations like without having to set up absolutely anything in AWS and the idea with

665
00:53:12,600 --> 00:53:16,360
this is that like people especially individual data scientists can get the feel that what would

666
00:53:16,360 --> 00:53:20,680
it what would it feel like if I had access to this like infinitely scalable laptop and I can

667
00:53:20,680 --> 00:53:25,320
just like a fan out my compute to batch and like store everything in S3 and then like if they feel

668
00:53:25,320 --> 00:53:28,520
that like well I mean this is really something that would increase their productivity then it's

669
00:53:28,520 --> 00:53:32,360
it's kind of a easier to take the little bit of effort that it takes to kind of set up your own

670
00:53:32,360 --> 00:53:37,160
AWS account to kind of make this possible so like if if people are interested you can go to the

671
00:53:37,160 --> 00:53:42,200
documentation and look at the section about about metaflow sandboxes so it's fully functional you

672
00:53:42,200 --> 00:53:46,920
can sign up today and like kind of get your own own private sandbox for for a while to use and

673
00:53:46,920 --> 00:53:51,240
like that's it that's just a kind of a takeaway to the question about the demo so yes absolutely

674
00:53:51,240 --> 00:53:55,240
I mean like I would be more than happy to do a demo with you if people are interested awesome

675
00:53:55,240 --> 00:54:00,920
so if you're interested in that reach out however you like to reach out to us and let us know and

676
00:54:01,880 --> 00:54:07,640
be happy to do it if there's interest quick question on the the sandbox is there a limitation

677
00:54:07,640 --> 00:54:13,080
there is this like a you know Google collab where everyone gets six hours 12 hours I forget the

678
00:54:13,080 --> 00:54:19,080
limit of free GPU instances or is it only the management plane but not actually instances for

679
00:54:19,080 --> 00:54:25,560
training like yeah no it's it's actual instances like for training you get up to a cluster of eight

680
00:54:25,560 --> 00:54:32,600
boxes with htpu 64 CPU cores like a 32 gigabyte machines each so it's like a decent size I mean

681
00:54:32,600 --> 00:54:37,320
you can do a lot with those machines you can like persist any data you can use it with your own data

682
00:54:37,320 --> 00:54:41,320
this is really important since we have seen so many tutorials and examples in data science where

683
00:54:41,320 --> 00:54:45,000
you have something like the house pricing and everybody knows how it works but like really what

684
00:54:45,000 --> 00:54:48,280
resonates with you is your own data and like you understand of course the important thing is

685
00:54:48,280 --> 00:54:51,880
that like you shouldn't use anything that's actually privacy sensitive but I mean you can get the

686
00:54:51,880 --> 00:54:56,680
feel like with with some data that like you really care about and you can do data science as you do

687
00:54:56,680 --> 00:55:02,760
you can even use any of the shelf libraries you can we come with built-in like integration with

688
00:55:02,760 --> 00:55:07,800
your conduct so you can do by any conduct package you see one inch of flow the xg boost you name

689
00:55:07,800 --> 00:55:12,120
it and and you can execute these things in the cloud and then see how it works and the only

690
00:55:12,120 --> 00:55:16,280
limitation there is that well let me first there's no internet connection we handled the kind of

691
00:55:16,280 --> 00:55:20,200
the dependency installation for you but I mean the idea is not that you use this to kind of call

692
00:55:20,200 --> 00:55:24,440
all kinds of outside services you don't need that for data science and then the second limitation

693
00:55:24,440 --> 00:55:28,760
is that like well instead of like a collab couple of hours you get three days to buy default if you

694
00:55:28,760 --> 00:55:32,680
need more time I mean just reach out to us and we give you more time got it awesome awesome well

695
00:55:32,680 --> 00:55:37,800
Vila sounds like an awesome project that I'm looking forward to digging into and I'm definitely

696
00:55:37,800 --> 00:55:42,840
rooting for folks to reach out and you know express some interest so that we can get back together

697
00:55:42,840 --> 00:55:46,040
and kind of walk through it yeah thanks Tom thanks so much thanks

698
00:55:49,480 --> 00:55:55,560
all right everyone that's our show for today to follow along with our reinvent series visit

699
00:55:55,560 --> 00:56:03,800
twimmelai.com slash reinvent 2019 thanks once again to capital one for their sponsorship of this

700
00:56:03,800 --> 00:56:10,840
series be sure to check out capital one.com slash tech slash explore to learn more about their

701
00:56:10,840 --> 00:56:25,800
ML and AI research thanks so much for listening and catch you next time

