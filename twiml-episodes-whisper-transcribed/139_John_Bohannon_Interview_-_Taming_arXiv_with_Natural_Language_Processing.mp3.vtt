WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.520
I'm your host Sam Charrington.

00:31.520 --> 00:36.400
I'd like to start out by thanking everyone who joined me last week at the Twimble AI Summit

00:36.400 --> 00:37.960
in Las Vegas.

00:37.960 --> 00:39.960
It was a great event.

00:39.960 --> 00:44.920
For a summary of the event and my key takeaways from each of the event sessions, sign up for

00:44.920 --> 00:49.840
my newsletter at twimbleai.com slash newsletter.

00:49.840 --> 00:54.160
I wrote about it right after returning from the event last week and when you sign up,

00:54.160 --> 00:58.720
you'll automatically get an email telling you how to get access to back issues.

00:58.720 --> 01:04.480
Again, that's twimbleai.com slash newsletter.

01:04.480 --> 01:06.440
Event season continues this week.

01:06.440 --> 01:11.120
Tomorrow I'm key noting at the Prepare AI event here in St. Louis and then making my

01:11.120 --> 01:15.840
way out to San Francisco for Figure H's Train AI Conference.

01:15.840 --> 01:21.320
The Train AI agenda looks awesome and I'll be on site all day podcasting so if you're

01:21.320 --> 01:25.400
in the Bay area, you should definitely plan to stop by.

01:25.400 --> 01:31.680
Of course, if you do, use the discount code Twimbleai for 30% off of registration.

01:31.680 --> 01:35.040
Be sure to give me a shout if you're planning to be around.

01:35.040 --> 01:41.720
In this episode, I'm joined by John Bohannon, Director of Science at AI Startup Primer.

01:41.720 --> 01:46.000
As you all may know, a few weeks ago, we released my interview with Google Legend, Jeff

01:46.000 --> 01:51.160
Dean, which by the way, you should definitely check out if you haven't already.

01:51.160 --> 01:56.040
Anyway, in that interview, Jeff mentions the recent explosion of machine learning papers

01:56.040 --> 02:00.760
on archive, which I responded to jokingly by asking whether Google had already developed

02:00.760 --> 02:04.680
the AI system to help them summarize and track all of them.

02:04.680 --> 02:08.720
While Jeff didn't have anything specific to offer, a listener reached out and let me

02:08.720 --> 02:12.920
know that John was in fact already working on this problem.

02:12.920 --> 02:18.120
In our conversation, John and I discuss his work on Primer Science, a tool that harvests

02:18.120 --> 02:24.000
content uploaded to archive, sorts it into natural topics using unsupervised learning,

02:24.000 --> 02:28.600
then gives relevant summaries of the activity happening in different innovation areas.

02:28.600 --> 02:32.520
We spend a good amount of time on the inner workings of Primer Science, including their

02:32.520 --> 02:36.920
data pipeline and some of the tools they use, how they determine ground truth for training

02:36.920 --> 02:41.720
their models, and the use of heuristics to supplement NLP in their processing.

02:41.720 --> 02:43.920
Alright, let's do it.

02:43.920 --> 02:52.200
Alright, everyone, I am on the line with John Bohannon.

02:52.200 --> 02:56.360
John is Director of Science at a startup called Primer.

02:56.360 --> 02:59.200
John, welcome to this week in machine learning and AI.

02:59.200 --> 03:00.200
Hey!

03:00.200 --> 03:01.840
So this conversation is an interesting one.

03:01.840 --> 03:08.440
They grew out of a listener response to a comment made in my recent interview with Jeff Dean.

03:08.440 --> 03:13.680
Jeff commented on the explosion of machine learning papers on archive, and I jokingly

03:13.680 --> 03:18.320
asked if Google had already developed the deep learning based summarization techniques

03:18.320 --> 03:20.080
to help us all keep up.

03:20.080 --> 03:24.080
And it turns out that one of your colleagues, John, reached out to let me know that you

03:24.080 --> 03:27.120
have been working on this and have built it.

03:27.120 --> 03:30.560
And I think just before we got started, you showed it to me and it's pretty cool.

03:30.560 --> 03:37.080
So here we are, but before we get into the details of that project, you've got an interesting

03:37.080 --> 03:40.840
background in molecular biology and data journalism.

03:40.840 --> 03:45.320
How did you find your way to AI?

03:45.320 --> 03:53.280
It's a long journey, but I think it started in computer camp when I was nine years old.

03:53.280 --> 03:56.040
So that's the kind of summer camp I went to.

03:56.040 --> 04:04.520
But yeah, as my studies progressed, I actually drifted away into biology in a PhD in molecular

04:04.520 --> 04:05.680
biology.

04:05.680 --> 04:12.160
And then before doing my next postdoc, I wanted to take a break and do something different.

04:12.160 --> 04:18.760
So I tried being a journalist, a science journalist, and fell in love with it and basically jumped

04:18.760 --> 04:24.040
off the academic track and became eventually a computational journalist, basically using

04:24.040 --> 04:31.120
data and code to find and tell stories that are impossible to tell otherwise.

04:31.120 --> 04:37.280
And a friend of mine named Sean Gorley, who did his PhD with me in England at the same

04:37.280 --> 04:38.280
time.

04:38.280 --> 04:40.920
I actually lived in the same house.

04:40.920 --> 04:44.640
Our fate eventually became intertwined again.

04:44.640 --> 04:51.280
I moved to the Bay area to do a visiting scholar stint at Berkeley and he's in San Francisco.

04:51.280 --> 04:54.920
He says, hey, John, I've got this startup called Primer.

04:54.920 --> 04:58.000
And you really should come by and check out what we're doing.

04:58.000 --> 05:04.120
I think you're going to find that the stuff we're working on really, really matches with

05:04.120 --> 05:06.040
the stuff you work on.

05:06.040 --> 05:11.040
And so eventually I had some time and I was like, okay, I'll pop over there for a week.

05:11.040 --> 05:18.960
And sure enough, within one day, it was clear that they were solving problems that I just

05:18.960 --> 05:25.000
find so hard and I wanted so badly to solve myself that, basically, if you can't be

05:25.000 --> 05:26.400
to join them.

05:26.400 --> 05:27.400
Nice.

05:27.400 --> 05:28.400
Nice.

05:28.400 --> 05:36.520
So maybe for context, you can tell us a little bit about what the company does and the

05:36.520 --> 05:40.040
kinds of problems that they're working on or you're working on.

05:40.040 --> 05:41.040
Yeah.

05:41.040 --> 05:48.200
So Primer at its core is an AI company that's trying to make machines that read and write.

05:48.200 --> 05:51.520
That's the fundamental problem that underlies all this.

05:51.520 --> 05:58.800
In terms of a business model, we, for example, automate a lot of the work that a junior analyst

05:58.800 --> 06:03.520
would do in, say, a bank or the intelligence community.

06:03.520 --> 06:06.280
Also, frankly, what a journalist does.

06:06.280 --> 06:11.560
I feel like I'm reverse engineering myself every day because a lot of what you have to

06:11.560 --> 06:12.560
do.

06:12.560 --> 06:19.560
It's also somewhat automating a lot of what you do, Sam, like all of our jobs, what we

06:19.560 --> 06:24.360
have in common is that we have to read a ton of stuff, often very technical stuff, and

06:24.360 --> 06:25.760
makes sense of it.

06:25.760 --> 06:27.520
And then tell stories.

06:27.520 --> 06:30.720
Like that is the fundamental unit of information.

06:30.720 --> 06:33.800
That's our data structure, a story.

06:33.800 --> 06:38.000
And that is really hard for computers to do.

06:38.000 --> 06:40.600
It's really hard for people to do.

06:40.600 --> 06:41.600
Exactly.

06:41.600 --> 06:45.080
Yeah, it's one of those things that's both, that's hard for everyone.

06:45.080 --> 06:53.400
So I think you're relatively new to this podcast, but those that have been around for a while

06:53.400 --> 06:59.440
from the beginning know that it started out as more of a news-oriented format as opposed

06:59.440 --> 07:01.920
to an interview format.

07:01.920 --> 07:08.160
And basically, my mission was to kind of summarize the most interesting AI and ML tidbits from

07:08.160 --> 07:09.880
the previous week's news.

07:09.880 --> 07:15.520
But that is super, super hard, especially with so much news happening all the time.

07:15.520 --> 07:25.640
It would take a ton of time to curate all of that information and digest it and turn it

07:25.640 --> 07:28.360
into stories as you're saying.

07:28.360 --> 07:29.360
Exactly.

07:29.360 --> 07:33.360
And so like you face several problems and what we're trying to do at Primer is break it down

07:33.360 --> 07:36.720
into reasonable problems that you can actually attack.

07:36.720 --> 07:40.880
So one is, for example, what's relevant?

07:40.880 --> 07:43.000
What are you telling a story about?

07:43.000 --> 07:47.240
It's not enough to just say, I want to tell a story about last week's AI research.

07:47.240 --> 07:50.720
It's like, okay, well, what documents are relevant?

07:50.720 --> 07:54.320
Even if you could get the papers, then it's like, well, where do you get all the conversations

07:54.320 --> 07:55.640
about those papers?

07:55.640 --> 07:58.040
How do you figure out what those papers were about?

07:58.040 --> 08:01.720
If there were a thousand papers published over the past several months and you wanted to

08:01.720 --> 08:06.400
tell a story of a thousand papers, I don't know how a human would do that.

08:06.400 --> 08:08.800
Well, actually, I can tell you, humans simply don't do that.

08:08.800 --> 08:11.600
What we do is we take shortcuts.

08:11.600 --> 08:12.960
We sort of fly blind.

08:12.960 --> 08:19.320
We grab the zeitgeist and that's kind of a random process.

08:19.320 --> 08:24.840
It's like, well, I overheard some conversations and this seems to be a hot topic.

08:24.840 --> 08:27.400
I'm going to decide and so I'm going to amplify it.

08:27.400 --> 08:33.560
And what you end up with are coherent stories, but they're not necessarily what actually

08:33.560 --> 08:35.840
was the most important thing that happened.

08:35.840 --> 08:40.920
It's just some strange sampling of the space of all things that happened and that's the

08:40.920 --> 08:41.920
best you can do.

08:41.920 --> 08:47.160
But what if you had a machine that could actually read everything and show you in some sense

08:47.160 --> 08:48.760
everything that happened?

08:48.760 --> 08:49.760
That's the goal.

08:49.760 --> 08:56.360
So you showed me a kind of a portal into research papers is the idea to provide that as

08:56.360 --> 09:01.760
a service or more of the platform that allows someone to create that thing.

09:01.760 --> 09:08.080
So we're in a pretty privileged position, we're privileged in the sense that we've already

09:08.080 --> 09:09.920
got some really big customers.

09:09.920 --> 09:19.120
So the federal government, Walmart, Singapore's sovereign trust, several others coming online

09:19.120 --> 09:24.520
soon, those are the relationships that actually pay the bills.

09:24.520 --> 09:29.400
And so we do things like if you have a portfolio manager who's trying to keep track of a ton

09:29.400 --> 09:37.000
of companies, that portfolio manager needs to stay on top of all the relevant developments

09:37.000 --> 09:40.720
in the space roughly defined by all those companies.

09:40.720 --> 09:48.560
All the news about them, maybe SEC filings, if you want to assess changes in risk profile,

09:48.560 --> 09:50.960
it's sort of an overwhelming task.

09:50.960 --> 09:57.720
And so primer basically superpowers those analysts by automating all the things that are really

09:57.720 --> 10:03.480
hard and tedious and time consuming, and it basically reduces the cost of curiosity.

10:03.480 --> 10:08.920
It allows those analysts to not spend half their day reading a million things just to find

10:08.920 --> 10:17.760
out what was worth reading, instead they can see summaries of 100 papers at once, get

10:17.760 --> 10:22.880
a sense of whether it's worth diving deeper or look at another batch of 100 papers.

10:22.880 --> 10:32.320
It also gives alerts with predefined conditions so that you don't lose a second if something

10:32.320 --> 10:37.440
that you know in retrospect is going to be a situation worth knowing about, you'll get

10:37.440 --> 10:38.760
a heads up.

10:38.760 --> 10:45.200
So meanwhile though, you can use the same machinery that does reading and writing and summarization

10:45.200 --> 10:49.360
to do things like the thing I sent you, like read all of archive.

10:49.360 --> 10:54.560
So we do have a business model for this system going forward.

10:54.560 --> 11:00.920
We're going to be developing it into products for, for example, the pharmaceutical industry.

11:00.920 --> 11:07.040
But for the time being, we just have this beautiful laboratory where we get to really push the

11:07.040 --> 11:09.960
edge of natural language processing.

11:09.960 --> 11:14.840
Tell us more about this archive project that you've built.

11:14.840 --> 11:20.480
Yeah, archive is a really good illustration of this problem that we all face of too much

11:20.480 --> 11:21.800
information.

11:21.800 --> 11:28.520
If you ever go to the archive website, you basically see a fire hose of research coming in.

11:28.520 --> 11:37.120
Archive is amazing because it is literally the place where research gets debuted.

11:37.120 --> 11:44.800
It's the first place you'll see a paper coming out from Google or Microsoft or MIT on

11:44.800 --> 11:51.080
the topics that are basically going to define the machine learning progress over the next

11:51.080 --> 11:52.600
10 years.

11:52.600 --> 11:59.440
In retrospect, you can look back and you can see the timeline of this amazing scientific

11:59.440 --> 12:01.960
revolution unfolding.

12:01.960 --> 12:04.440
But it's not at all human readable.

12:04.440 --> 12:11.040
Even if you are an expert, even if you have a PhD in machine learning, you just can't

12:11.040 --> 12:13.040
make sense of all of archive.

12:13.040 --> 12:18.520
You might be able to make sense of the papers in your own subdomain, but even there, it's

12:18.520 --> 12:19.520
tough.

12:19.520 --> 12:20.520
You've got to find them.

12:20.520 --> 12:23.400
Archive isn't designed for humans in a way.

12:23.400 --> 12:29.760
I mean, it is, but it's just not user-friendly.

12:29.760 --> 12:34.160
Primer science is a stab at making sense of that.

12:34.160 --> 12:40.920
Basically, it's a really hard problem that's well-scoped.

12:40.920 --> 12:49.240
What it does is it harvests all these papers and it does unsupervised learning on the content

12:49.240 --> 12:54.200
of the papers to try and figure out what are the topics that this naturally falls into.

12:54.200 --> 12:59.120
So within machine learning, for example, I'm just looking now at some of the latest.

12:59.120 --> 13:04.800
The system has discovered that there are not only image reconstruction papers, there's

13:04.800 --> 13:10.400
like 58 papers actually in this bag that are on that theme, but it has discovered that

13:10.400 --> 13:15.880
there's a whole bunch of research on traffic and temporal analysis.

13:15.880 --> 13:18.080
There's something on mathematical optimization.

13:18.080 --> 13:23.720
There's a whole bunch of papers about semantic segmentation.

13:23.720 --> 13:28.640
All of this is happening without an ontology or a knowledge base.

13:28.640 --> 13:35.600
You're going to have to have such a system if you want it to work on any corpus of papers.

13:35.600 --> 13:41.840
You could imagine building some super ontology that captures everything there is to know

13:41.840 --> 13:47.040
about science, but then it's going to be out of date next month.

13:47.040 --> 13:51.320
I wouldn't want to build that thing because maintaining it would be a nightmare.

13:51.320 --> 13:55.320
Instead, you need a system that does more or less what humans do on a smaller scale.

13:55.320 --> 13:59.600
What we do is we look at things and we just sort of eyeball it and say, oh, these are

13:59.600 --> 14:03.000
kind of about this and these are about that.

14:03.000 --> 14:07.200
You get a natural segmentation of the space.

14:07.200 --> 14:13.080
Within each of these topics, it does a time series analysis and it tries to figure out if

14:13.080 --> 14:19.960
I take all the news and the social media signal, all the tweets about this research as it

14:19.960 --> 14:28.880
was published and afterwards, all the commentary, all the real time online critique, sort of the

14:28.880 --> 14:35.680
peer review that's happening in real time out in the open, can I detect events?

14:35.680 --> 14:39.360
An event can be more than just the publication of a paper.

14:39.360 --> 14:47.600
It could be that, for example, a self-driving car crashes somewhere and suddenly the world

14:47.600 --> 14:55.960
is looking intensely at an issue related to what we do and don't know about these systems.

14:55.960 --> 14:59.000
Some of this research may get pulled into that.

14:59.000 --> 15:04.960
If you want to detect that real-world event, you need a system that can actually divide

15:04.960 --> 15:09.840
all those documents, all those tweets, all those things that are relevant to the same thing

15:09.840 --> 15:13.000
and figure out how to segment them in time.

15:13.000 --> 15:16.720
It does that too and it tries to figure out, essentially, what were the big events in

15:16.720 --> 15:17.720
this space?

15:17.720 --> 15:24.800
How was human attention in the world divided in relation to this corpus of papers?

15:24.800 --> 15:31.040
Then does some other cute tricks to make it useful to you as you dive into all of this

15:31.040 --> 15:32.520
information.

15:32.520 --> 15:36.600
It pulls out all the people and tries to tell you what it knows about them.

15:36.600 --> 15:41.000
Just based on the corpus, mind you, we're also developing a version of this that is building

15:41.000 --> 15:46.040
a knowledge base and actually learning about people as it reads the news and as papers are

15:46.040 --> 15:47.040
published.

15:47.040 --> 15:55.400
What I sent you this morning is just, essentially, out of the box, I don't know anything about

15:55.400 --> 16:00.280
the world, but I know this group of thousands of papers you sent me and this is what I can

16:00.280 --> 16:01.680
tell you about them.

16:01.680 --> 16:03.800
These are all the people.

16:03.800 --> 16:05.600
These are all the topics.

16:05.600 --> 16:10.360
These are the events that seem to all of this information seems to be pointing at out

16:10.360 --> 16:13.320
in the real world.

16:13.320 --> 16:19.920
One is, if you're finding the jargon really hard to understand, I've generated a dictionary

16:19.920 --> 16:25.160
for you that is kind of a magical dictionary where if you click on a technical term, it

16:25.160 --> 16:30.800
actually shows you who coined that term, how is it defined?

16:30.800 --> 16:34.960
Give me some context about how to use this kind of like a Oxford English dictionary on

16:34.960 --> 16:35.960
steroids.

16:35.960 --> 16:36.960
Nice.

16:36.960 --> 16:37.960
Nice.

16:37.960 --> 16:42.240
I'm finding this interview more challenging than most because as you're speaking, I've

16:42.240 --> 16:47.920
got the tool in the background and I keep seeing papers that look really interesting.

16:47.920 --> 16:51.560
It's working.

16:51.560 --> 16:54.320
Super, super distracting.

16:54.320 --> 17:00.400
Maybe can you tell us a little bit about the technology that's making it all happen?

17:00.400 --> 17:02.840
What does the stack look like?

17:02.840 --> 17:04.560
What does the pipeline look like?

17:04.560 --> 17:09.400
How are you approaching the unsupervised learning piece?

17:09.400 --> 17:15.040
It all begins with a gigantic elastic search index.

17:15.040 --> 17:21.800
I think if you talk to a lot of the people that you've interviewed even already about what's

17:21.800 --> 17:28.440
at the bottom of this whole stack, there's often some massive index of documents.

17:28.440 --> 17:35.640
We're ingesting the news and blogs and tweets and scientific papers every day and that's

17:35.640 --> 17:41.760
the starting point of this whole system and it has this growing corpus.

17:41.760 --> 17:48.600
If you query as we've done today on artificial intelligence, for example, the first thing

17:48.600 --> 17:56.360
it has to do is retrieve all the information that is relevant and then kicks off this pipeline

17:56.360 --> 18:03.680
where basically the first thing it does is it tries with unsupervised learning plus

18:03.680 --> 18:10.560
several other steps to divide all the information up into natural topics.

18:10.560 --> 18:18.200
Within each topic, it then tries to detect the events in the real world that any of these

18:18.200 --> 18:21.400
documents might be referring to.

18:21.400 --> 18:27.640
If you've got 100 documents that might be news documents and scientific papers and

18:27.640 --> 18:33.120
social media signal about all the above, you do a time series analysis on it and you try

18:33.120 --> 18:37.920
and figure out, are there real world events?

18:37.920 --> 18:39.280
It's trying to make an inference here.

18:39.280 --> 18:46.120
Are there real world events that all of this information is pointing at and describing?

18:46.120 --> 18:52.080
It looks at events basically from the perspective of news articles, is that right?

18:52.080 --> 19:00.840
The system you're looking at does, yeah, but you can imagine any document that has a meaningful

19:00.840 --> 19:07.680
publication timestamp and includes a description or commentary about something that happened

19:07.680 --> 19:09.040
in the real world.

19:09.040 --> 19:12.920
It could in principle be mapped to something called an event.

19:12.920 --> 19:19.520
The concept of an event is bigger than what a human intuitively would call event.

19:19.520 --> 19:25.840
It might actually be, for example, an explosion of discussion around an issue.

19:25.840 --> 19:31.760
For example, the Me Too movement is not just an event, it's made up of many events and

19:31.760 --> 19:36.200
some of these events might not even be something that could have been observed in one place

19:36.200 --> 19:41.960
at one time, but there is a natural segmentation of all the things happening in the world into

19:41.960 --> 19:44.560
something that we call events.

19:44.560 --> 19:47.960
So that's the theory behind this.

19:47.960 --> 19:58.240
Then if you click over to overview, sorry to distract you again, then it tries to tell

19:58.240 --> 19:59.240
you a story.

19:59.240 --> 20:01.880
So we've got many versions of this.

20:01.880 --> 20:08.920
What you're looking at is basically one of the earliest versions of this, but basically

20:08.920 --> 20:15.960
if you asked a machine to go and read thousands of things and you give it a budget of one

20:15.960 --> 20:21.920
page to tell you what it learned, this is starting to get at what you'd expect to come

20:21.920 --> 20:23.440
back.

20:23.440 --> 20:25.120
This is what you get.

20:25.120 --> 20:34.040
It's basically, and it's kind of like a technical report on these are things that I learned.

20:34.040 --> 20:35.040
These are the big events.

20:35.040 --> 20:36.040
These are the big papers.

20:36.040 --> 20:37.040
This is what's getting us attention.

20:37.040 --> 20:44.760
Oh, and then by the way, my topic analysis has revealed that there are some changes of

20:44.760 --> 20:52.440
the foot in artificial intelligence, and these are the things that seem to be trending upwards

20:52.440 --> 20:53.520
and are really interesting.

20:53.520 --> 20:59.200
And oh, by the way, I discovered there's this weird paper that seems to fall in this topic,

20:59.200 --> 21:03.520
but it's deeply connected to this other topic, and that's statistically strange.

21:03.520 --> 21:05.640
I need to tell you about it.

21:05.640 --> 21:11.560
And by the way, here's some people who seem to be getting a ton of attention, and here's

21:11.560 --> 21:17.240
another person who has collaborated with them on a high profile paper, and they've never

21:17.240 --> 21:18.640
worked together before.

21:18.640 --> 21:19.640
That's interesting.

21:19.640 --> 21:25.720
So you can see what's going on here is the system has a model of what humans find interesting.

21:25.720 --> 21:28.840
And of course, we humans at Primer built that in.

21:28.840 --> 21:32.000
There's a story logic that I don't realize this.

21:32.000 --> 21:34.120
You don't want a system to tell you everything it learned.

21:34.120 --> 21:36.640
It's just going to be another fire hose.

21:36.640 --> 21:39.000
You've made no progress.

21:39.000 --> 21:42.120
A one-to-one map of the world is not a useful map.

21:42.120 --> 21:47.280
So you need something that will compress the information and try and tell you a story.

21:47.280 --> 21:48.960
So that's what the system does.

21:48.960 --> 21:54.640
I think I interrupted you as you were about to start talking about the pipeline that you're

21:54.640 --> 21:58.040
sending some of this stuff through.

21:58.040 --> 22:04.360
And just going back to the beginning with archives, are you ingesting all of the archive

22:04.360 --> 22:07.920
papers or crawling that site?

22:07.920 --> 22:08.920
Yeah.

22:08.920 --> 22:16.400
So Paul Ginsberg, who founded and still runs archive, is a friend of mine from a good

22:16.400 --> 22:18.600
while back.

22:18.600 --> 22:21.040
And he uses Primer Science as well.

22:21.040 --> 22:25.200
I think actually he's the very first one I made a user account for.

22:25.200 --> 22:26.200
Oh wow.

22:26.200 --> 22:27.200
Yeah.

22:27.200 --> 22:34.080
And so he's really helped out over the past year, making sure that we have direct access.

22:34.080 --> 22:37.760
So we don't have to scrape the site.

22:37.760 --> 22:45.920
We basically just pull down the entire day's new papers on one go.

22:45.920 --> 22:52.440
And we do the same with news, except it arrives more or less in real time.

22:52.440 --> 22:59.880
So we have a real-time stream, more or less, of the news with maybe a 10 minute delay.

22:59.880 --> 23:06.440
And we've got a real-time stream of all the tweets that are relevant to the space.

23:06.440 --> 23:11.000
Yeah, those via commercial APIs of some sort.

23:11.000 --> 23:13.080
We get them directly from Twitter.

23:13.080 --> 23:14.080
Okay.

23:14.080 --> 23:16.360
So yeah, we have a day to deal with them.

23:16.360 --> 23:17.360
Okay.

23:17.360 --> 23:18.360
And the news?

23:18.360 --> 23:21.720
The news we actually have several sources of.

23:21.720 --> 23:24.040
One of the most convenient is Lexus Nexus.

23:24.040 --> 23:26.000
They have a service called Morover.

23:26.000 --> 23:29.840
You can actually purchase a fire hose of news.

23:29.840 --> 23:31.480
They do a really good job, actually.

23:31.480 --> 23:32.480
Oh wow.

23:32.480 --> 23:33.480
Okay.

23:33.480 --> 23:39.920
So you pull all that into your Elasticsearch index and maybe talk a little bit about some

23:39.920 --> 23:44.200
of the underlying NLP bits that are enabling all this.

23:44.200 --> 23:45.200
Yeah.

23:45.200 --> 23:50.080
So when you kick off a query, what's happening is you're making a lot of reading happening.

23:50.080 --> 23:57.240
So for example, if you take a look at the topics that have been generated, text and word

23:57.240 --> 24:03.440
embeddings, quantum, and all of those topic labels that is generated, it actually

24:03.440 --> 24:09.080
discovered and chose those from the content of the articles themselves.

24:09.080 --> 24:18.640
So the first step in any NLP task on documents is to tokenize the entire document.

24:18.640 --> 24:21.400
So are you familiar with tokenizing?

24:21.400 --> 24:22.400
Mm-hmm.

24:22.400 --> 24:23.400
Yeah.

24:23.400 --> 24:28.760
So you basically discover all the words and punctuation and you run an analysis that

24:28.760 --> 24:30.040
gets you the parts of speech.

24:30.040 --> 24:35.200
It's kind of like what you did in grade school when you made the sentence diagrams to try

24:35.200 --> 24:40.800
and make sense of all the different parts of what someone says.

24:40.800 --> 24:44.000
And then a whole bunch of things happen in parallel.

24:44.000 --> 24:51.360
Basically, there's some things that are useful if you give it a bag of words, so you can

24:51.360 --> 24:55.440
take an entire scientific paper or even a thousand scientific paper person.

24:55.440 --> 24:58.080
They turn into bags of words.

24:58.080 --> 25:06.200
And with that kind of analysis, you could, for example, discover the groups of words,

25:06.200 --> 25:13.440
the Ngrams, that basically best describe this space and you can generate a label.

25:13.440 --> 25:20.520
So if you go into any of those topics, it has decided to give that topic a name based

25:20.520 --> 25:25.000
on the language within the documents themselves within the topic.

25:25.000 --> 25:29.920
So I'm still amazed that it works, frankly.

25:29.920 --> 25:33.880
NLP is kind of magical.

25:33.880 --> 25:37.520
When something makes sense to a human, when there's a machine that didn't really understand

25:37.520 --> 25:42.200
it in the same way you did, it's kind of magical.

25:42.200 --> 25:50.560
Are you using kind of off-the-shelf NLP toolkits, NLTK-5000 stuff, or are you rolling your

25:50.560 --> 25:51.560
arms off?

25:51.560 --> 25:54.040
No, we started off that way.

25:54.040 --> 25:59.560
So we've been using this tool Spacey from the very beginning.

25:59.560 --> 26:03.120
It's free, it's open source, and it's really powerful.

26:03.120 --> 26:10.320
And it's really, what shocks me is that there are just two people at the heart of this project,

26:10.320 --> 26:14.720
a fellow named Hannibal and a gal named Enis, who live in Berlin.

26:14.720 --> 26:18.240
Not far from where I lived for a few years, and I've gotten to know them a little bit

26:18.240 --> 26:20.000
just recently.

26:20.000 --> 26:24.640
And it does the nuts and bolts NLP that you need.

26:24.640 --> 26:29.440
So it will tokenize, but it'll also discover named entities.

26:29.440 --> 26:34.440
It'll help you find the people and organizations, and so forth.

26:34.440 --> 26:35.600
But you need to train it.

26:35.600 --> 26:41.040
That's something that we have discovered is just probably like everyone else.

26:41.040 --> 26:45.240
It'll get you started, but then you need to solve your own problems.

26:45.240 --> 26:46.920
It's only a starting point.

26:46.920 --> 26:55.160
So for example, with the people and all the information that we can extract about them

26:55.160 --> 27:01.280
and tell you a story based on the people in this space, Spacey is one of the things

27:01.280 --> 27:07.040
that we use early in the pipeline, but then there's a ton of custom code that we had to

27:07.040 --> 27:15.160
build to basically get the kind of information that Spacey can't get to clean up the stuff

27:15.160 --> 27:22.160
that Spacey gets wrong to link it with all the other information we're extracting by

27:22.160 --> 27:23.960
other means.

27:23.960 --> 27:29.840
And it's a mixture of machine learning and good old fashioned regular expressions.

27:29.840 --> 27:36.000
What I find so fun about being at an AI startup is the goal here is not to generate research

27:36.000 --> 27:37.000
papers.

27:37.000 --> 27:41.640
The goal is to just solve problems really well by whatever means you can.

27:41.640 --> 27:43.960
So which I think is like the right motivation to have.

27:43.960 --> 27:44.960
Right.

27:44.960 --> 27:49.000
You're just motivated to publish cutting-edge papers.

27:49.000 --> 27:52.880
You don't care if it works.

27:52.880 --> 27:58.800
I went to this conference called NIPS, which is essentially where all this cutting-edge

27:58.800 --> 28:00.600
research is being debuted.

28:00.600 --> 28:05.240
And something that really struck me is half the stuff that people are bragging about

28:05.240 --> 28:08.160
doesn't even really practically work.

28:08.160 --> 28:11.560
Our works within such a narrowly constrained way.

28:11.560 --> 28:12.560
Exactly.

28:12.560 --> 28:14.560
With a point problem that'll work.

28:14.560 --> 28:16.680
It's computationally intractable or whatever.

28:16.680 --> 28:18.000
And that's fine.

28:18.000 --> 28:23.400
It's like that's the whole point is to debut tomorrow's technology, but it's frustrating

28:23.400 --> 28:27.480
when you're trying to build something.

28:27.480 --> 28:33.160
You get excited about some new idea and you chase it down, only to discover, oh, this

28:33.160 --> 28:34.680
actually never could have worked.

28:34.680 --> 28:35.680
Yeah.

28:35.680 --> 28:36.680
Yeah.

28:36.680 --> 28:37.680
I've had that experience.

28:37.680 --> 28:38.680
I've had that experience.

28:38.680 --> 28:42.480
I found a paper using primer science, of course.

28:42.480 --> 28:45.800
This is a pretty weird situation to have AI eating itself.

28:45.800 --> 28:50.160
We basically have an AI system that reads AI papers, which we then used to try and improve

28:50.160 --> 28:54.240
the AI that reads papers.

28:54.240 --> 29:00.480
But we came across a really exciting paper and fully replicated it and it just doesn't

29:00.480 --> 29:01.480
work.

29:01.480 --> 29:02.840
And that's okay.

29:02.840 --> 29:04.240
That's how it goes in this space.

29:04.240 --> 29:08.760
When you're right at the edge of knowledge, it's not all going to work.

29:08.760 --> 29:15.200
So we have this principle, a primer, of always trying to find the practical solution as

29:15.200 --> 29:16.720
quickly as possible.

29:16.720 --> 29:21.920
Don't get seduced by ideas that are sexy to talk about, but it's not actually solving

29:21.920 --> 29:22.920
your problem.

29:22.920 --> 29:23.920
Yeah.

29:23.920 --> 29:25.880
I should throw in a plug for my newsletter.

29:25.880 --> 29:33.360
I've recently written on this topic of reproducibility and both science and AI drawing off

29:33.360 --> 29:40.320
of a recent interview I did with Claire Galnick on this same topic.

29:40.320 --> 29:45.680
But I really appreciate you owning up to that broader pipeline.

29:45.680 --> 29:54.600
One of the questions I get a lot when talking with folks about their products or projects

29:54.600 --> 30:02.040
is people want to know like, okay, granted you've applied some great cutting edge machine

30:02.040 --> 30:06.640
learning AI stuff, but what else is there required to make it work?

30:06.640 --> 30:13.880
What are the, how much heuristics are kind of in and around these tools to actually make

30:13.880 --> 30:14.880
it work?

30:14.880 --> 30:22.240
So to hear you note that, yeah, you know, good old regular expressions are used liberally

30:22.240 --> 30:25.680
to make sure that this all works.

30:25.680 --> 30:29.040
I think it's important for, it's important to realize that.

30:29.040 --> 30:31.320
Oh, yeah, absolutely.

30:31.320 --> 30:38.760
I guarantee you, you go into some of the biggest, most cutting edge groups at giant tech

30:38.760 --> 30:39.760
companies.

30:39.760 --> 30:43.760
You think that they're doing some kind of pristine AI that you just press a button and

30:43.760 --> 30:46.000
it understands things.

30:46.000 --> 30:49.760
I guarantee you look under the hood and there's just a ton of regular expressions.

30:49.760 --> 30:54.600
Now, that's not to say that machine learning isn't the way forward.

30:54.600 --> 31:01.000
Like it totally is, but to make these things work on actual problems, it's still labor

31:01.000 --> 31:02.320
of love.

31:02.320 --> 31:03.920
So you're doing a lot with Spacey.

31:03.920 --> 31:12.320
Are you also, which I'm assuming is more traditional NLP technology approach?

31:12.320 --> 31:21.480
Are you also doing things with like word-to-vec and deep learning based approaches?

31:21.480 --> 31:23.040
Yeah.

31:23.040 --> 31:29.440
In particular, as we've expanded into other languages beyond English, Spacey is just

31:29.440 --> 31:36.600
not going to cut it when you want to make something that understands Russian and Chinese.

31:36.600 --> 31:45.440
So we've actually had to pretty much make a bunch of tools from scratch, but it relies

31:45.440 --> 31:54.680
on word vectors and word embeddings and where things get complicated is actually where

31:54.680 --> 31:58.760
you try and pull this all together.

31:58.760 --> 32:10.320
If you use deep learning to extract, for example, some pattern in a corpus of 10,000 documents,

32:10.320 --> 32:15.200
the harder thing, once you've extracted it, is knowing whether you're right and whether

32:15.200 --> 32:17.400
it's worth saying.

32:17.400 --> 32:25.760
I can find a bunch of patterns in text pretty easily, but the harder thing is assessing

32:25.760 --> 32:31.320
how confident am I that I've found something that I haven't just misextracted.

32:31.320 --> 32:32.880
It's not just a serious pattern.

32:32.880 --> 32:37.800
And then even harder than that, is it worth telling you, like, how do I square this with

32:37.800 --> 32:41.000
my model of what humans are interested in?

32:41.000 --> 32:42.000
Right.

32:42.000 --> 32:46.880
Where we're headed with this is basically a model of stories, which ultimately is a model

32:46.880 --> 32:48.280
of humans.

32:48.280 --> 32:49.280
Humans are storytellers.

32:49.280 --> 32:51.600
We've evolved to do this thing.

32:51.600 --> 32:53.080
We just take it for granted.

32:53.080 --> 32:58.320
What we're doing right now, this conversation, is incredibly high tech.

32:58.320 --> 33:02.400
You and I, in real time, are like gliding through a narrative that this is.

33:02.400 --> 33:04.400
Many years of technology evolution.

33:04.400 --> 33:05.400
It's amazing.

33:05.400 --> 33:06.840
Yeah, it's amazing.

33:06.840 --> 33:12.880
So I think this is actually the next frontier of AI, decoding what story is.

33:12.880 --> 33:13.880
Yeah.

33:13.880 --> 33:15.640
So what does that mean practically?

33:15.640 --> 33:18.560
How are you approaching that?

33:18.560 --> 33:27.200
Yeah, so here's a bite-sized example, if you make something that reads scientific papers

33:27.200 --> 33:34.880
and tries to tell you what you need to know about AI research last week, for example.

33:34.880 --> 33:39.080
It's not enough to just give you a dashboard of, here's the most shared paper.

33:39.080 --> 33:42.160
Here's the paper that got the most news.

33:42.160 --> 33:45.360
Here's the paper that currently has the most citations.

33:45.360 --> 33:49.040
That's not doing much heavy lifting for you.

33:49.040 --> 33:54.760
If you were to hire a thousand human analysts to just work for you, like imagine you had

33:54.760 --> 33:59.520
that luxury, what would you ask them to do?

33:59.520 --> 34:06.360
That's kind of the better guiding question and what sort of story would they tell you?

34:06.360 --> 34:07.360
What would the format be?

34:07.360 --> 34:10.800
I guarantee the humans wouldn't come back and give you a dashboard.

34:10.800 --> 34:19.640
They would say, okay, the big deal last week is that a self-driving car crashed and it's

34:19.640 --> 34:26.160
kicked off a huge discussion about quality control and where system errors are going to

34:26.160 --> 34:32.080
creep in and how you can make machine learning systems understandable from an engineering

34:32.080 --> 34:33.080
point of view.

34:33.080 --> 34:36.120
How are we going to deal with this emerging problem?

34:36.120 --> 34:40.760
The people who are weighing in on this are the following researchers in deep learning,

34:40.760 --> 34:45.720
but here's some other people who are very knowledgeable, but they're in a adjacent domain.

34:45.720 --> 34:49.720
We think this is really worth knowing, but meanwhile, by the way, we discovered a paper

34:49.720 --> 34:56.000
published by a couple of researchers that you've rarely heard of, but it's getting a lot

34:56.000 --> 35:01.840
of traction and it seems to be on a topic that is emerging and you're probably going to

35:01.840 --> 35:05.240
care about this.

35:05.240 --> 35:10.520
It's basically, it has to do with voice recognition and we know that that's an interesting topic,

35:10.520 --> 35:15.920
but the more interesting thing is that this researcher is really well known in a totally

35:15.920 --> 35:20.240
different field and is just like diving into this and that's unusual.

35:20.240 --> 35:21.240
So check it out.

35:21.240 --> 35:22.240
Here's the paper.

35:22.240 --> 35:25.600
I'm just going to go out on a limb here and say, you really should read this paper.

35:25.600 --> 35:36.480
By the way, here's basically a new concept that is creeping into the space and we haven't

35:36.480 --> 35:37.640
seen it before.

35:37.640 --> 35:43.120
This might be a fluke, but I think this is actually something that's worth knowing about.

35:43.120 --> 35:45.760
Here are five papers that you should read.

35:45.760 --> 35:48.760
I'm working within your budget here.

35:48.760 --> 35:50.080
That's what all the humans would do.

35:50.080 --> 35:56.360
It's basically the one-to-two-page presidential intelligence briefing.

35:56.360 --> 35:57.960
Ideally, that's what it would look like.

35:57.960 --> 36:04.200
A ton of research has gone into boiling things down to a very tight story and that's all

36:04.200 --> 36:06.640
you need to know.

36:06.640 --> 36:15.000
The idea then is that you've got some kind of generative model for creating these, basically

36:15.000 --> 36:18.840
you're briefing over and it has two steps.

36:18.840 --> 36:21.000
Like at least two steps.

36:21.000 --> 36:26.880
One is, what information can I find that's truly relevant, the raw ingredients of a story?

36:26.880 --> 36:30.720
And then the next step is, well, how can I synthesize this into an actual story?

36:30.720 --> 36:34.560
I have to do text generation, document planning.

36:34.560 --> 36:40.120
You give me a budget, a page, a paragraph, maybe you just want a bullet point and I'll

36:40.120 --> 36:41.120
work with it.

36:41.120 --> 36:46.320
I'll be able to express this as a story given that constraint.

36:46.320 --> 36:54.840
And so kind of going back to our earlier exchange about good old fashion heuristics, how to

36:54.840 --> 36:55.840
what degree?

36:55.840 --> 37:03.680
I haven't looked at compared one of these briefing pages versus another, but how much is

37:03.680 --> 37:10.480
generation and how much is more templates and things like that?

37:10.480 --> 37:20.000
Yeah, so the philosophy we followed is always start fast and doable, put another way.

37:20.000 --> 37:25.360
You always want to start with a model that you can fully understand yourself and implement

37:25.360 --> 37:29.200
quickly so that you have some baseline.

37:29.200 --> 37:30.200
Sure.

37:30.200 --> 37:37.520
Yeah, we've always started with, first can you do it yourself as a human, maybe even

37:37.520 --> 37:40.040
no computer involved.

37:40.040 --> 37:46.760
If you were to read 10 papers and try and say something intelligent about them, for example,

37:46.760 --> 37:54.160
tell me, tell me, for example, what, if you were to classify events, and I gave you a

37:54.160 --> 38:00.840
pile of papers and I said, how would you classify these events, kind of tags would you attach

38:00.840 --> 38:01.840
to them?

38:01.840 --> 38:08.520
Or if you were looking for a particular kind of event, could you divide papers into yes

38:08.520 --> 38:11.040
and no?

38:11.040 --> 38:14.680
Always start with yourself, you the engineer, can you yourself do it?

38:14.680 --> 38:18.040
Because if you can't, you're probably going to have a hard time teaching a computer

38:18.040 --> 38:19.040
do it.

38:19.040 --> 38:24.920
Then if you get some other humans, probably the person just two chairs away from you, if

38:24.920 --> 38:29.680
you can get someone else to do the same task independently and get the same ideally or

38:29.680 --> 38:32.800
a similar answer, okay, now you're in good shape.

38:32.800 --> 38:39.440
Only then do you start building a computational system to try and do this automatically.

38:39.440 --> 38:44.000
Your first stab at that should be something great forward, a set of regular expressions,

38:44.000 --> 38:46.000
heuristics.

38:46.000 --> 38:53.160
Can you actually find this yourself using rules that you yourself devise?

38:53.160 --> 38:58.800
Then the only way really to get beyond that, to really tackle increasing complexity, is

38:58.800 --> 39:01.280
to have something that will learn on its own.

39:01.280 --> 39:06.000
You'll never do that with regular expressions, you have to use machine learning to have

39:06.000 --> 39:11.120
a system find patterns itself in a changing world.

39:11.120 --> 39:17.160
So I think you're saying then that there's, you know, you're somewhere on the spectrum

39:17.160 --> 39:20.360
of templates and machine learning.

39:20.360 --> 39:21.760
Oh yeah, always.

39:21.760 --> 39:28.400
In fact, I think the best things out there are always somewhere in the middle.

39:28.400 --> 39:29.400
Right.

39:29.400 --> 39:30.400
I think by definition.

39:30.400 --> 39:34.480
Yeah, and essentially it becomes a race.

39:34.480 --> 39:42.880
Can we build something that can learn faster and output better, smarter content than the

39:42.880 --> 39:44.440
system we have?

39:44.440 --> 39:51.880
We had a little race actually recently to try and build an event classifier and a brilliant

39:51.880 --> 39:58.640
engineer named Leonard Appleton took a stab at just using regular expressions, no machine

39:58.640 --> 39:59.640
learning.

39:59.640 --> 40:05.360
And another brilliant engineer named Yash took on the task of solving the same problem

40:05.360 --> 40:11.000
using a really complicated machine learning graphical model.

40:11.000 --> 40:15.520
And sometimes John Henry wins the race.

40:15.520 --> 40:22.440
Frankly, Yash could not build a system, at least last I checked, that could do better

40:22.440 --> 40:29.360
than Leonard's massive, complicated, regular expression, heuristic engine.

40:29.360 --> 40:33.440
But you know, eventually, eventually machine learning will win.

40:33.440 --> 40:34.920
Like we all know that.

40:34.920 --> 40:35.920
Right.

40:35.920 --> 40:36.920
Right.

40:36.920 --> 40:39.960
But that's the beauty of a practical approach.

40:39.960 --> 40:45.200
When you're really driven by practical principles, you're willing to say, well, we've got

40:45.200 --> 40:49.120
a better solution that's actually simpler and easier to understand.

40:49.120 --> 40:51.160
Let's use that for now.

40:51.160 --> 40:52.480
Keep trying.

40:52.480 --> 40:57.400
But it's never long before a machine learning based system does better.

40:57.400 --> 41:00.080
It's just an incredibly powerful tool.

41:00.080 --> 41:06.840
When you're using machine learning for tasks like summarization where you referenced earlier,

41:06.840 --> 41:11.560
you know, first you do it, then you get someone else to do it and you compare them.

41:11.560 --> 41:17.000
You know, your summary of a given paper or a given paragraph is likely to be very different

41:17.000 --> 41:18.000
from mine.

41:18.000 --> 41:23.720
Like what do you, how do you find ground truth so that you can train learning models?

41:23.720 --> 41:29.280
Yeah, that you've really put your finger on the hardest problem.

41:29.280 --> 41:34.160
Stories by their nature can be told infinite ways.

41:34.160 --> 41:39.800
And there are some automated techniques that have been around for a decade.

41:39.800 --> 41:41.200
They have French color names.

41:41.200 --> 41:44.720
I don't know how that came about, but there's something called russian, something called

41:44.720 --> 41:46.080
blue.

41:46.080 --> 41:52.760
And what they do is they treat the output as bag of word problems.

41:52.760 --> 41:55.640
And they try and find out how much information overlap.

41:55.640 --> 42:00.200
There is between a human summary and a computer summary.

42:00.200 --> 42:04.440
As you can imagine, that's great if you're trying to measure whether you got it terribly

42:04.440 --> 42:05.440
wrong.

42:05.440 --> 42:06.440
Right.

42:06.440 --> 42:10.680
If we make two summaries and they have not going to do with each other, then they're probably

42:10.680 --> 42:13.000
they're probably not talking about the same thing.

42:13.000 --> 42:14.000
That may be.

42:14.000 --> 42:15.000
That's right.

42:15.000 --> 42:21.200
I mean, summarizing fiction, right, you could be we could be summarizing on two totally

42:21.200 --> 42:23.160
different levels and both be right.

42:23.160 --> 42:24.160
That's true.

42:24.160 --> 42:25.160
That's absolutely true.

42:25.160 --> 42:29.400
I mean, the same, I think the same holds true for news.

42:29.400 --> 42:35.160
I mean, you know, I, I'll let you continue, but that seems like a very, very rudimentary

42:35.160 --> 42:36.160
metric.

42:36.160 --> 42:41.360
Well, I mean, you'd be surprised then to learn that the latest, greatest papers in this

42:41.360 --> 42:45.840
field are still using those metrics because they're easy.

42:45.840 --> 42:49.760
You know, you can, it's, it's a one click measurement, right?

42:49.760 --> 42:56.320
But it, it, it really doesn't help when you want to assess a subtle output of a story

42:56.320 --> 42:59.400
that could be sliced and diced sort of infinite ways.

42:59.400 --> 43:01.120
Unfortunately, it becomes a capture.

43:01.120 --> 43:06.560
You need some human to read it and go, oh, yeah, that makes sense or that's crazy, right?

43:06.560 --> 43:13.480
But there are, there are some techniques you can use, so one is you can actually crowd

43:13.480 --> 43:21.760
source assessment of narrative, you can, you can give human annotators and scorers a

43:21.760 --> 43:23.360
system, a rigorous system.

43:23.360 --> 43:25.880
So like, you can measure the coherence.

43:25.880 --> 43:33.640
You can measure the, the sophistication, the, whether or not you've, you've really summarized

43:33.640 --> 43:36.040
the space well in various ways.

43:36.040 --> 43:39.960
Those, those sounds like they would require a fairly sophisticated crowdsource.

43:39.960 --> 43:40.960
Yeah.

43:40.960 --> 43:46.400
Yeah, so that's right, like the, the more technical and sophisticated this task becomes,

43:46.400 --> 43:49.000
the less you can rely on mechanical Turk.

43:49.000 --> 43:52.520
Uh, in fact, eventually you've got your own engineers doing this.

43:52.520 --> 43:55.800
So it's, it's definitely not scalable.

43:55.800 --> 44:02.800
Um, but, uh, there are, uh, there are some, some tricks that you can use.

44:02.800 --> 44:09.840
So for example, um, if I generate a bunch of summaries, uh, on a topic that I've already

44:09.840 --> 44:14.880
summarized, for example, if I have a Wikipedia article about it, I can at least find out

44:14.880 --> 44:20.120
if the most important entities in the narrative have been represented.

44:20.120 --> 44:25.720
And I can also, uh, turn the system around and do extraction on the summary.

44:25.720 --> 44:31.720
You can even, I will suggest to make a generative adversarial network that generates stories

44:31.720 --> 44:33.640
and critiques them.

44:33.640 --> 44:35.160
You can see where this is going.

44:35.160 --> 44:41.520
Uh, eventually you can, you can have a system that, uh, tries to check off all the boxes

44:41.520 --> 44:45.800
of what counts as a good story, like you've, you've talked about the most important entities

44:45.800 --> 44:50.440
and you've expressed their relationships, uh, you've come in under budget in terms of,

44:50.440 --> 44:56.920
uh, space on the age, um, but ultimately you're going to need a human to assess whether

44:56.920 --> 45:04.440
it's a well-written story until we can crack the code of text style transfer, um, where

45:04.440 --> 45:08.920
you can actually say, tell me the story and the style of a New York Times reporter or

45:08.920 --> 45:14.800
tell me the story in the, in the style of, uh, um, you know, a, uh, terse military briefing

45:14.800 --> 45:15.800
time.

45:15.800 --> 45:18.640
Send on my text in, uh, Hemingway style.

45:18.640 --> 45:19.640
Exactly.

45:19.640 --> 45:26.120
Until we can actually have, uh, networks that can both detect and reproduce, uh, narrative

45:26.120 --> 45:27.120
style.

45:27.120 --> 45:31.440
Um, I think we're, we're, for the time being stuck in a world where it's really hard

45:31.440 --> 45:34.560
to assess how well our systems are doing.

45:34.560 --> 45:40.240
Um, ultimately you want to hook this up to your, your users and, and either passively

45:40.240 --> 45:43.000
or actively harvest their feedback.

45:43.000 --> 45:47.040
So, um, the simplest version of this, of course, is A-B testing.

45:47.040 --> 45:52.720
If you write many versions of a summary, um, and you expose a large number of humans

45:52.720 --> 45:57.800
to A versus B, you can just find out, uh, what they think of it by, for example, whether

45:57.800 --> 45:59.840
they click through and read it.

45:59.840 --> 46:01.840
You can, you can also make it active.

46:01.840 --> 46:05.080
You can let users say, yeah, that was good or that was bad.

46:05.080 --> 46:11.520
We're going back to my, uh, Hemingway text summaries, uh, Google inbox presenting you

46:11.520 --> 46:16.880
three choices for how to summarize the response, the appropriate response to an email.

46:16.880 --> 46:18.360
Yep.

46:18.360 --> 46:19.680
And we've played with that as well.

46:19.680 --> 46:26.720
We, we generate alternative summaries, uh, to events, for example, um, it's, it's, it's

46:26.720 --> 46:32.160
a really powerful way of real time effortless quality checking.

46:32.160 --> 46:35.880
You don't, you don't want to have to sort of pause your whole engineering operation in

46:35.880 --> 46:38.680
order all the time, just to assess how well you're doing.

46:38.680 --> 46:40.920
You really want it to be sort of continual.

46:40.920 --> 46:45.880
You want to always be reading the output of your own, uh, computational systems.

46:45.880 --> 46:46.880
We call it dog fooding.

46:46.880 --> 46:47.880
Mm-hmm.

46:47.880 --> 46:49.840
If you, you got to be real time dog fooding.

46:49.840 --> 46:55.440
And so the nice thing about primary science is this thing that I'm building is we, uh,

46:55.440 --> 47:00.640
we use it to discover the research that is going to help us make it better.

47:00.640 --> 47:01.640
Right.

47:01.640 --> 47:06.160
And so if you keep on using the thing, you are your own quality assessor.

47:06.160 --> 47:07.160
That really helps.

47:07.160 --> 47:08.160
Right.

47:08.160 --> 47:09.160
Right.

47:09.160 --> 47:10.160
Right.

47:10.160 --> 47:11.160
But hard to scale.

47:11.160 --> 47:14.680
I, I wish I could clone myself in some way to, uh, assess sort of, uh, at a thousand

47:14.680 --> 47:15.680
X.

47:15.680 --> 47:22.760
Now one thing that I didn't see in what you've built it, it seems like it is, it does

47:22.760 --> 47:30.560
a really good job at kind of this meta characterization of archive and what's happening

47:30.560 --> 47:32.720
in, in different categories.

47:32.720 --> 47:37.400
But I didn't see it attempting to summarize individual papers, which is the thing that

47:37.400 --> 47:39.960
Jeff Dean and I were originally talking about.

47:39.960 --> 47:42.160
Is it trying to do that somewhere?

47:42.160 --> 47:43.520
Not in what you're looking at.

47:43.520 --> 47:47.040
We are, we are actually working on that, that summarization problem.

47:47.040 --> 47:48.040
Okay.

47:48.040 --> 47:49.040
Um, yeah.

47:49.040 --> 47:54.040
We've taken two strategies, uh, and they're kind of running, uh, in parallel.

47:54.040 --> 48:00.760
One is extractive summarization, where you, you, you, you're, the system is allowed to

48:00.760 --> 48:06.320
pull words and even whole sentences directly from the text and then kind of pull them together

48:06.320 --> 48:07.400
into a summary.

48:07.400 --> 48:12.200
That works extremely well when you have a large number of docs, like if you, if you have

48:12.200 --> 48:17.360
a hundred documents all on all about the same thing, uh, extractive summarizations really

48:17.360 --> 48:18.560
powerful.

48:18.560 --> 48:23.920
And really efficient, uh, and then the alternative is abstractive summarization, where the system

48:23.920 --> 48:28.640
is going to write its own words, often character by character, uh, out of thin air and it has

48:28.640 --> 48:29.640
a language model.

48:29.640 --> 48:35.360
So it reads all these things and it, it basically makes a prediction about, uh, what it should

48:35.360 --> 48:41.000
say next as it generates a summary, um, a, a really nice, uh, bit of progress in this

48:41.000 --> 48:45.800
field that we've been using is abstractive summarization with pointers.

48:45.800 --> 48:51.560
So the idea here is you also have a sense of your confidence about whether the word or

48:51.560 --> 48:58.080
phrase that you're putting, uh, into the summary at any given time is going to be a good choice.

48:58.080 --> 49:02.520
And if you're not so confident, you point back to the text and you grab the thing itself.

49:02.520 --> 49:09.760
So for example, if you had a sentence that said, um, uh, a, um, one of the most exciting

49:09.760 --> 49:15.640
areas of, uh, artificial intelligence these days is, um, generate, generative adversarial

49:15.640 --> 49:16.640
networks.

49:16.640 --> 49:20.640
Now, if, if, if generative adversarial networks, that phrase is something that you have

49:20.640 --> 49:25.960
an encountered or your model basically says, I'm, I'm not sure if that, if I can actually

49:25.960 --> 49:29.680
paraphrase that, then what you want to do is what a good human writer would do.

49:29.680 --> 49:31.960
You just go back and you grab that thing.

49:31.960 --> 49:40.720
So you can, you can summarize while also having some of the advantages of extractive.

49:40.720 --> 49:47.680
So summarizing basically around the, the entities that you aren't too sure about.

49:47.680 --> 49:48.680
Exactly.

49:48.680 --> 49:52.200
It basically becomes a sliding scale between abstractive and extractive.

49:52.200 --> 49:56.040
The more confident it gets, the more abstractive it gets, the more flexible it gets, which

49:56.040 --> 50:01.920
will allow you to summarize a single scientific paper, for example, uh, in a couple of sentences.

50:01.920 --> 50:07.520
Um, and if you're not so sure, then it slides over to extractive and it will just pull

50:07.520 --> 50:13.480
out the sentences that it deem and the phrases that it deems are the most central and informative.

50:13.480 --> 50:14.480
Interesting.

50:14.480 --> 50:16.400
It's a hard problem though.

50:16.400 --> 50:17.400
It's a really hard problem.

50:17.400 --> 50:21.680
Another thing, uh, that makes it hard when it comes to scientific papers is they already

50:21.680 --> 50:23.600
have their own summaries.

50:23.600 --> 50:28.800
They're called abstracts and you, and you'd, and you'd think that, oh, great, this, it,

50:28.800 --> 50:34.920
job done, but, uh, apps, as you know, abstracts themselves can be so riddled with jargon and

50:34.920 --> 50:38.920
references to arcane things that it's hardly a summary at all.

50:38.920 --> 50:42.760
It's really only a summary for the authors of the paper, right?

50:42.760 --> 50:43.760
Right.

50:43.760 --> 50:46.960
So you really need a summary of the summary, right?

50:46.960 --> 50:48.440
And that's what we're working on.

50:48.440 --> 50:52.040
We're finding that you really do need to power this with an ontology and a knowledge base

50:52.040 --> 50:53.040
though.

50:53.040 --> 50:54.440
A library on that.

50:54.440 --> 50:55.440
Okay.

50:55.440 --> 51:00.640
So let's take, for example, a problem that I'm just starting to work on.

51:00.640 --> 51:07.440
How do you, how do you summarize and make sense of, uh, pharmaceutical research papers?

51:07.440 --> 51:15.160
So, uh, there is an ontology that is available to everyone, uh, that basically the NIH, um,

51:15.160 --> 51:17.680
paid for called MASH.

51:17.680 --> 51:25.640
And, um, it's, it's, it's kind of like, uh, every, every jargon term in, in, uh, biochemistry

51:25.640 --> 51:31.560
and molecular biology, gene names and gene types, uh, all of that is captured in this very

51:31.560 --> 51:40.160
rich ontology that was hand-built by, no doubt, by, uh, un thanked graduate students.

51:40.160 --> 51:45.280
And something that's really nice about MASH is that it's actually a subset of wiki data.

51:45.280 --> 51:51.600
And wiki data is the database, uh, that stands behind wikipedia.

51:51.600 --> 51:56.840
Um, now I, I say that, uh, in an idealistic way because actually, in real, that's the way

51:56.840 --> 51:57.840
it was dreamed up.

51:57.840 --> 52:01.120
Oh, wiki data is going to basically be the database that powers wikipedia.

52:01.120 --> 52:03.960
But in fact, um, it's not there yet.

52:03.960 --> 52:11.440
Humans, humans, um, vastly prefer to, uh, update wikipedia with content and wiki data basically

52:11.440 --> 52:12.440
place catch up.

52:12.440 --> 52:19.600
Nonetheless, it is a huge powerful, uh, open source knowledge base, uh, and the MASH ontology

52:19.600 --> 52:21.640
is a subset of it.

52:21.640 --> 52:28.480
And so, um, if you want to summarize a scientific paper, just a single scientific paper, the

52:28.480 --> 52:31.400
first thing you need to do is, is make sense of it.

52:31.400 --> 52:35.960
You need to map all of those words, which to the computer or just, it could be random

52:35.960 --> 52:39.200
numbers for all they cares has no idea what it means.

52:39.200 --> 52:44.200
We need to map them to concepts and that's what systems like MASH were designed to help

52:44.200 --> 52:45.440
us do.

52:45.440 --> 52:52.000
So the idea of being instead of what you're doing in science, primer, uh, and doing this

52:52.000 --> 52:57.080
in a totally unsupervised manner, here you're using the additional information you're getting

52:57.080 --> 53:05.560
from the, uh, pre-existing ontology to help the machine make sense of the various documents

53:05.560 --> 53:06.920
and to paraphrase it.

53:06.920 --> 53:14.920
So like a good summary is something that doesn't just like say less, uh, it also says, just

53:14.920 --> 53:19.160
as much but in a, in a compressed way, right, right, you know, if I just tell you the beginning

53:19.160 --> 53:24.160
of a story, I haven't really compressed that story for you, um, I need to like give you

53:24.160 --> 53:29.040
the sense of the beginning, middle and end and compress that all down into three sentences.

53:29.040 --> 53:34.920
And, um, you're not going to be able to do that just using a, uh, the standard NLP techniques

53:34.920 --> 53:37.520
on a scientific paper, you're just not going to be able to do it.

53:37.520 --> 53:38.360
No way.

53:38.360 --> 53:39.360
Right.

53:39.360 --> 53:44.960
You have to, uh, map that out to an ontology and say, oh, you know, this long sentence describing

53:44.960 --> 53:50.480
this, uh, genetic pathway, I can boil that down to a single sentence that says, um, the

53:50.480 --> 53:54.760
genetic pathway X, you know, interesting.

53:54.760 --> 53:58.640
But yeah, you, you need a lot of tacit knowledge to be able to do that.

53:58.640 --> 54:01.200
So that's what we're working on.

54:01.200 --> 54:02.200
Awesome.

54:02.200 --> 54:03.400
Well, John, this has been super interesting.

54:03.400 --> 54:05.880
I really appreciate you taking the time.

54:05.880 --> 54:06.880
Thank you.

54:06.880 --> 54:09.440
Anything else you'd like to share with the audience?

54:09.440 --> 54:14.080
Oh, just, uh, that, uh, I'd like to make a prediction.

54:14.080 --> 54:15.080
Go ahead.

54:15.080 --> 54:25.680
Well, I predict that the kind of stuff we're working on is going to accelerate artificial

54:25.680 --> 54:27.760
intelligence research more than anything else.

54:27.760 --> 54:34.680
I think building AI that can read the latest research on AI and help the engineers who

54:34.680 --> 54:42.280
build it, build it faster is going to, uh, vastly accelerate the whole process.

54:42.280 --> 54:43.280
Awesome.

54:43.280 --> 54:51.520
Well, we will put your prediction on the blockchain and, uh, just to make sure we get all the

54:51.520 --> 54:52.520
jargon in.

54:52.520 --> 54:53.520
Uh, exactly.

54:53.520 --> 54:54.520
Then we'll do an ICU.

54:54.520 --> 54:59.520
Awesome, thanks so much, John.

54:59.520 --> 55:00.520
Thanks, Sam.

55:00.520 --> 55:08.600
All right, everyone, that's our show for today.

55:08.600 --> 55:13.560
For more information on John or any of the topics covered in this episode, head on over

55:13.560 --> 55:19.360
to twimmaleye.com slash talk slash one, three, six.

55:19.360 --> 55:26.360
Thanks so much for listening and catch you next time.

