WEBVTT

00:00.000 --> 00:15.280
All right, everyone, I'm here with Brian Granger. Brian is a senior principle technologist

00:15.280 --> 00:19.520
with Amazon Web Services. Brian, welcome to the Twoma AI podcast.

00:19.520 --> 00:26.140
Hi, Sam. Thanks so much for having me. Looking forward to jumping into our discussion.

00:26.140 --> 00:32.180
You are a co-founder of Project Jupiter, and that is, of course, the topic that we will

00:32.180 --> 00:37.340
be digging into in this conversation. But to get us started, I'd love to have you share

00:37.340 --> 00:42.900
a bit about your background and how you came to work in machine learning, and we'll

00:42.900 --> 00:46.260
make our way to the founding of Jupiter as well.

00:46.260 --> 00:51.860
Yeah, definitely can walk through that. So, as you mentioned, I'm a senior principle

00:51.860 --> 00:59.180
technologist at AWS, and I've been here at AWS for three years, coming up in February.

00:59.180 --> 01:06.300
Before that, for the sort of decade and a half prior, I was a physics professor, most recently

01:06.300 --> 01:13.460
at Cal Poly San Luis Obispo, and then before that, it set a clear university. Even though

01:13.460 --> 01:19.940
as a physics professor, most of the time at university, I built open source tools for

01:19.940 --> 01:26.980
data science, machine learning, and scientific computing. And so I have a background in theoretical

01:26.980 --> 01:33.020
physics, but that's evolved over time through software engineering, building tools, and

01:33.020 --> 01:37.660
more recently, I spent a lot of time on UX design and research.

01:37.660 --> 01:42.500
Nice. Nice. And so, how did Jupiter come to be?

01:42.500 --> 01:51.220
Yeah, so it's a fun story. So if you rewind back to the early 2000s, Linux was really taking

01:51.220 --> 01:58.100
off. Python had been around for a few years, but it became visible in the scientific computing

01:58.100 --> 02:05.660
community. And a classmate of mine at CU Boulder in grad school, Fernando Perez, had started

02:05.660 --> 02:13.020
to use Python in his research. And he's really the one that introduced me to Python, both

02:13.020 --> 02:22.780
he and I during our physics education used Mathematica a lot. And we, even though we were doing

02:22.780 --> 02:29.340
computational physics in other languages, we weren't necessarily using Mathematica, we had

02:29.340 --> 02:35.180
always missed the notebook interface that Mathematica had. And in 2001, Fernando released

02:35.180 --> 02:41.940
IPython, which is an improved and enhanced command line REPL for Python, that had some

02:41.940 --> 02:47.540
of the ideas from Mathematica in it, although it didn't have the full notebook interface.

02:47.540 --> 02:51.940
And so in those early years, I started to play with Python a bit, Fernando was working

02:51.940 --> 02:58.500
on IPython. And then in 2004, he visited me in the Bay Area. I was a young professor at

02:58.500 --> 03:05.140
Santa Clara University. And while he was there, we spent a lot of time talking about computing

03:05.140 --> 03:11.980
what we were doing in our research, how we were using these tools. And it was really then

03:11.980 --> 03:19.780
where the vision of creating a web-based notebook for Python came into focus. And there was

03:19.780 --> 03:23.980
a couple different factors in that one. It was something that we wanted to use in our

03:23.980 --> 03:31.860
own research. We have found over the years that this interactive computing in a notebook

03:31.860 --> 03:36.740
-based interface, where you also have a document, was extremely useful. And we just wanted

03:36.740 --> 03:44.820
it to exist. The other dimension was that by 2004, rich web applications were starting

03:44.820 --> 03:51.300
to appear. And so it started to make a lot of sense to us at that time, that if we were

03:51.300 --> 03:57.220
going to build something like this, it should be entirely web-based. Now, that was 2004.

03:57.220 --> 04:03.940
It took us until 2011 to release the first version of the IPython notebook. And some of

04:03.940 --> 04:10.340
it was us learning about this space. We were theoretical, computational physicists,

04:10.340 --> 04:16.180
not web developers. We wrote a lot of code as physicists, but of a very different nature

04:16.180 --> 04:23.860
than this, obviously. And the other is that modern web technologies, even in 2011, were

04:23.860 --> 04:33.300
relatively primitive. And from 2004 to 2011, we were really waiting for modern web technology

04:33.300 --> 04:40.500
to catch up to what we needed. And even in 2011, state-of-the-art at the time was JQuery

04:40.500 --> 04:46.260
and Bootstrap. Web Sockets had just been turned on and all the browsers. And we were using

04:46.260 --> 04:53.620
all the latest stuff in 2011, which now seems rather primitive compared to what we have today.

04:53.620 --> 05:00.580
When we think about Jupiter or talk about Jupiter today, it's often in the context of ideas

05:00.580 --> 05:07.300
like literate programming. Were you thinking about it from the perspective of literate programming

05:07.300 --> 05:13.780
and some of the theoretical foundations of why a tool like this makes sense? Or is it

05:15.540 --> 05:22.900
kind of strictly scratching your own itch and trying to bring to Python this interface that you

05:22.900 --> 05:27.940
loved in Mathematica? The connection to traditional literate programming

05:28.740 --> 05:39.460
came much, much later. And I think we, and so the phrase that we use, there's sort of two phrases

05:39.460 --> 05:47.620
that we use. One would be literate computing rather than programming. And the other is distinction.

05:47.620 --> 05:54.260
So in the traditional literate programming paradigm, there's nothing interactive about it.

05:55.220 --> 06:01.060
You're not actually, as a human, interacting with the live code as you would in a repel.

06:01.060 --> 06:05.620
You just write a source code file and then you use the literate programming tool to compile that

06:05.620 --> 06:11.780
to the actual source code file that can run. There's nothing interactive about it. And in scientific

06:11.780 --> 06:18.580
computing and data science and machine learning, that interactive experience of writing and running

06:18.580 --> 06:25.300
a bit of code, seeing what the output is and having a stateful process that holds the state

06:25.300 --> 06:30.660
of the program in memory that you can then write more code against. And so that's where we've

06:30.660 --> 06:38.260
always thought of it as literate computing or interactive computing. Another phrase that we talk

06:38.260 --> 06:44.580
about a lot is the idea of a computational narrative. And again, the focus there is on a narrative

06:44.580 --> 06:50.180
that's contained in a document, but it's not about mirror programming as in typing code. It's

06:50.180 --> 06:55.060
about actual computing. It's about writing code and running it, seeing the result of that and

06:55.060 --> 07:00.820
using that to think about data in the case of machine learning. So I think you got us through

07:00.820 --> 07:09.860
2011, 2012, all these new web tools kind of catching up to what you needed around that time. We also

07:09.860 --> 07:16.340
saw an explosion in machine learning, deep learning interests. How did that shift? What was happening

07:16.340 --> 07:23.620
with the Jupyter project? Yeah. So in the early years, when we thought about what would success

07:23.620 --> 07:31.300
look like for us in building this web-based notebook for Python, I think our market, if you want

07:31.300 --> 07:38.740
to phrase it that way, would have been academic researchers who are doing scientific computing.

07:39.620 --> 07:43.620
That's the universe we were in at the time. Those were all the people we were talking to.

07:45.140 --> 07:49.780
And every time, all through the early 2000s, whenever we talked to people in the industry,

07:49.780 --> 07:58.500
they looked at interactive computing with a bit of a sort of, well, that's nice, but we never

07:58.500 --> 08:05.860
need to do that. I think Fernando even had a conversation with Guido Van Rossum, who was the

08:05.860 --> 08:13.620
creator of Python. And when Fernando described how we use Python interactively, Guido said,

08:13.620 --> 08:18.580
wow, I always thought of the Python REPL as being a bit of a toy that no one would actually use for

08:18.580 --> 08:25.700
real work. It's amazing to see how in the scientific computing context, you live in these interactive

08:25.700 --> 08:34.020
shells. And so we had always thought that the commercial adoption of these tools would be very

08:34.020 --> 08:44.020
slow at best. Now, it sort of came in from the side that around the same time, commercial entities

08:44.020 --> 08:49.940
discovered the power of data through data science and machine learning in a way that they hadn't

08:49.940 --> 08:55.780
before. And so they ended up needing these same tools for interactive computing, and they quickly

08:55.780 --> 09:04.420
discovered Jupiter as one of the tools that they could use for this. But it took, I remember in the

09:04.420 --> 09:13.620
early, so starting in 2011, going up to maybe 2015, was an amazing time for us in that it felt like

09:13.620 --> 09:20.020
every month a new major organization discovered interactive computing and Jupiter and Python.

09:20.660 --> 09:29.700
And by the time we got to 2015, 2016, it was a lot of people, a lot of companies were using these

09:29.700 --> 09:35.940
tools as well. But it happened. It was a transition and growth that we had not seen coming and

09:35.940 --> 09:40.180
definitely hadn't planned on. And it created a lot of challenges for Jupiter as a project.

09:40.180 --> 09:50.420
Was it obvious that you should embrace these new use cases and new user communities,

09:50.420 --> 09:58.100
or was there a bit of tension between kind of staying the course and building the thing that

09:58.100 --> 10:05.300
your scientific computing users needed versus things that machine learning users might need.

10:05.300 --> 10:13.140
It's in the extent that those are divergent in any way. Yeah, so I don't want to imply that

10:13.140 --> 10:21.940
there's never been tension there. I think that the I don't want to speak for all Jupiter contributors,

10:21.940 --> 10:31.380
but I can try to summarize some of the sentiments in the community. We even today, so today, Jupiter

10:31.380 --> 10:37.620
is used by many large corporations and many contributors to Jupiter today work at those large

10:37.620 --> 10:46.180
corporations. Back in 2011, it was close to 100% academics working on project Jupiter. And

10:46.980 --> 10:54.340
even today, I think the core Jupiter team deeply values the role of Jupiter in research and education.

10:54.340 --> 10:59.780
We recognize it's important in the commercial space. We definitely want to address those usage

10:59.780 --> 11:07.380
cases, but I think broadly speaking, the Jupiter community holds the research and educational

11:07.380 --> 11:14.820
usages with special importance. And so there has been some tension there. Now, the other question

11:14.820 --> 11:22.100
you brought up is the potential for divergence between the needs of the academic users and commercial

11:22.100 --> 11:30.900
users. I think to first order, the experience we've had is that there's no substantial difference

11:30.900 --> 11:36.180
in the needs of those communities. It's even to the point where it's a little humorous in the

11:36.180 --> 11:44.020
sense that even still to this day, we regularly talk to organizations that will tell us how they're

11:44.020 --> 11:49.140
using Jupiter and start out by saying, you know, the way we're using Jupiter is really weird and

11:49.140 --> 11:54.820
special and probably unlike anything you've ever heard. And then they'll tell us a story that we've

11:54.820 --> 11:59.780
heard hundreds of times about. They're doing all the same things everyone on the planet's doing

11:59.780 --> 12:07.220
with Jupiter. That's not to say that they're not differences. For example, in the academic context,

12:08.180 --> 12:12.900
the requirements of teaching are really unique. And so when you're teaching a large class and

12:12.900 --> 12:18.660
university with notebooks, being able to manage homework, assign homework that involves notebooks,

12:18.660 --> 12:23.700
grade the homework involving notebooks. And so we've built special capabilities for things like

12:23.700 --> 12:29.540
that. But at the core, I would say most of the functionality is common across to all Jupiter users.

12:30.260 --> 12:38.820
Got it. Got it. And so you're now at AWS and you continue to work on Jupiter. How did that come

12:38.820 --> 12:49.780
to be? Yeah. So as I mentioned, by the somewhere in maybe 2015, 2016 commercial and enterprise

12:49.780 --> 12:59.300
usages of Jupiter had really taken off. And what that meant is that the Jupiter developers were talking

12:59.300 --> 13:05.300
to a lot of users that were no longer individual users, but were people maintaining and operating

13:05.300 --> 13:10.260
large scale Jupiter deployments in their enterprise. And the pain points and struggles that they were

13:10.260 --> 13:17.540
having sometimes were related to Jupiter and would be either bugs or feature requests or enhancements

13:17.540 --> 13:22.900
that we could make on the Jupiter side. In other cases, their challenges that they were running into

13:23.620 --> 13:30.820
really were not a Jupiter problem or challenge. It was more of a deploying and maintaining

13:30.820 --> 13:37.060
cloud infrastructure type of problems. A great example of that would be entities that have

13:38.100 --> 13:43.780
some manner of private or sensitive data and need to deploy Jupiter to meet a certain compliance

13:43.780 --> 13:52.740
regime such as HIPAA. And that's not really a problem that Jupiter's an open source project is

13:52.740 --> 13:57.940
going to solve in an end to end way. Jupiter may offer building blocks that can be used to assemble

13:57.940 --> 14:05.060
such a system. And so that was one of the, for me personally, starting to talk to these

14:05.060 --> 14:10.580
enterprise users and realize, okay, there's a huge need here. We're probably not going to be

14:10.580 --> 14:15.140
that the Jupiter open source community is not going to fully solve these needs. I'd love to start

14:15.140 --> 14:20.340
to work in an organization that's really good at all those enterprise cloud computing challenges.

14:20.340 --> 14:28.420
That was one dimension. The other dimension was us thinking about the long-term sustainability.

14:30.180 --> 14:36.980
The as a result of the adoption and the enterprise commercial space, the user base of Jupiter

14:36.980 --> 14:45.460
grew far, far faster than the size of the development team of Jupiter. I think that the Jupiter

14:45.460 --> 14:51.940
user base has been growing exponentially with a doubling period of, I don't remember, it's about

14:51.940 --> 15:02.900
a year since I think 2015. The Jupiter contributor population has not grown exponentially. We've grown

15:02.900 --> 15:10.180
a lot. And so we've really faced a resourcing issue where we just as an open source project have

15:10.180 --> 15:17.060
not been able to keep up. I love by the way that you said it was growing exponentially and

15:17.780 --> 15:26.260
actually meant exponentially. I can show you the plot where I'm getting this from

15:27.060 --> 15:37.060
is we have a chart that we periodically gather and that is the number of public notebooks on GitHub.

15:37.060 --> 15:41.860
There's a number of different ways we measure how big the Jupiter user base is.

15:42.980 --> 15:48.260
But you can see we have a chart in this repository in a notebook that shows

15:49.300 --> 15:53.940
the growth of notebooks, public notebooks on GitHub, and it's been growing exponentially since I

15:53.940 --> 16:02.660
think somewhere around 2015. So yeah, and so part of this was the Jupiter governance model has

16:02.660 --> 16:08.820
always been multi-stakeholder. We've designed it and some of this came out of our own needs.

16:09.300 --> 16:14.740
Fernando was at Berkeley. I was at Cal Poly. So almost by definition, there's multiple stakeholders

16:14.740 --> 16:20.580
in organizations involved. As additional academic contributors came on board and then eventually

16:21.140 --> 16:26.180
contributors from companies came on board, we embraced that multi-stakeholder nature.

16:26.180 --> 16:33.460
And I think from this perspective, my moving to Amazon was an opportunity to bring a new stakeholder

16:33.460 --> 16:38.980
into the mix of improving and making Jupiter sustainable and growing open source project.

16:40.660 --> 16:48.340
And the governance model is it's Jupiter's part of the numfocus foundation. Is that correct?

16:48.340 --> 16:55.540
Yeah, numfocus is a 501c3 nonprofit that's the umbrella organization for a number of open source

16:55.540 --> 17:04.260
projects in this space that would include NumPy, SciPy, Pandis, SimPy, Jupiter, and dozens of others.

17:04.260 --> 17:09.780
I know I'm forgetting. There's more than I can possibly name. So Jupiter's one of those

17:11.700 --> 17:17.780
Jupiter in numfocus, each of those open source projects has its own governance model. It's not like

17:17.780 --> 17:22.580
the Apache foundation where there's a single governance model that everyone adopts under the

17:22.580 --> 17:31.380
foundation. And we actually in the Jupiter side have been refactoring and designing a new

17:31.380 --> 17:36.980
governance model over the last two years to address the scope and scale of Jupiter.

17:36.980 --> 17:44.740
And we've been rolling that out incrementally over the last year and still doing work to

17:44.740 --> 17:52.020
finish that up. But the core idea is that it is multi-stakeholder and we're trying to build checks

17:52.020 --> 17:59.460
and balances to include cooperation in a vibrant community among all these stakeholders.

18:00.100 --> 18:10.660
So you've talked about the kind of what's in it for Jupiter in finding kind of an enterprise

18:10.660 --> 18:20.820
cloud home, if you will. What's in it for AWS and how and why does AWS invest in Jupiter?

18:20.820 --> 18:27.620
Yeah, this is this is a great question. So the story of Jupiter and AWS actually began before I

18:27.620 --> 18:37.620
joined. And as AWS was diving into machine learning and data science, the question came up of what

18:37.620 --> 18:44.260
do we do? Our customers are asking us about notebook platforms. What are we going to offer for

18:44.260 --> 18:51.460
that? And a decision was made before I joined to embrace Jupiter. And it really came from feedback

18:51.460 --> 19:01.540
from customers. The leadership team and the org that I'm in the AI ML org at AWS. But we spent a

19:01.540 --> 19:06.180
lot of time talking to customers, understanding what they're doing, what their pain points are,

19:06.180 --> 19:12.020
what existing open source technologies they're using. And like I said, even before I joined,

19:12.020 --> 19:18.180
we heard the resounding chorus that people were using Jupiter and they needed help deploying Jupiter

19:18.180 --> 19:24.740
in a secure cost effective way. And that they wanted actual Jupiter. They didn't want a notebook

19:24.740 --> 19:30.420
like solution. They wanted real Jupiter. This is also something that made it possible for me to

19:30.420 --> 19:36.580
join AWS and very attractive to join AWS. I didn't need to start at the sort of very beginning and

19:36.580 --> 19:43.300
argue and make a case at AWS for why Jupiter? Why should we ship Jupiter versus build our own notebook?

19:43.300 --> 19:50.900
That was already done and settled. And so since I joined AWS, it's more been a question of how do we

19:50.900 --> 19:58.980
at AWS make sure that Jupiter continues to be the best notebook platform in a vibrant and growing

19:58.980 --> 20:06.180
open source community? And at AWS, there, you know, across different projects, there are different

20:06.180 --> 20:19.700
approaches to engaging with open source communities. It sounds like the way that AWS is engaging

20:19.700 --> 20:28.900
with Jupiter in terms of, or rather, the way that AWS is incorporating Jupiter into its projects is

20:28.900 --> 20:36.340
to try to stick close to kind of the core Jupiter as opposed to forking it off into something else.

20:37.380 --> 20:45.300
Absolutely. Yep. Now, one of the things that, and this gets back to a technical and architectural

20:45.300 --> 20:53.460
principle that Jupiter has used since its founding. And that is Jupiter at the end of the day builds

20:53.460 --> 21:00.260
Lego building Lego pieces for notebook platforms or for interactive computing platforms. And the

21:00.260 --> 21:05.300
idea is that enterprises and organizations can take those building blocks and assemble them in

21:05.300 --> 21:10.500
different ways. And at AWS, that's exactly what we're doing. We're taking the open source building

21:10.500 --> 21:17.060
blocks and assembling them in a particular way to serve the needs of our customers. And so we may

21:17.060 --> 21:24.500
build, and we do, in fact, build additional things on top of it using the various extensibility APIs

21:24.500 --> 21:33.060
that Jupiter has. So for example, our machine learning IDE at AWS is SageMaker Studio. It's based

21:33.060 --> 21:39.140
on Jupiter Lab. But then on top of that, in the SageMaker team, we've written a bunch of Jupiter

21:39.140 --> 21:44.740
Lab extensions that add machine learning specific capabilities to make it an end-to-end solution for

21:44.740 --> 21:52.740
machine learning. And those extensions that we're building wouldn't make sense to be in Jupiter

21:52.740 --> 22:01.220
from an open source perspective. They are, a lot of them are specific to AWS. Jupiter as an open

22:01.220 --> 22:08.660
source project works really hard to have a essentially vendor neutral perspective. So if you look

22:08.660 --> 22:14.180
across Jupiter's different code bases, you're not going to find a lot of code that's specifically

22:14.180 --> 22:23.140
tuned to a particular cloud platform or deployment context. And so at Amazon, we're extending Jupiter,

22:23.140 --> 22:29.860
we're building additional domain specific capabilities on top of that. But anytime we're looking at

22:30.580 --> 22:35.460
either bugs or enhancements to the core of Jupiter itself, our approach is to work with the

22:35.460 --> 22:42.100
Jupiter open source community and contribute back to those changes. And so we have a dedicated

22:42.100 --> 22:48.100
team of engineers. It's a small team, but they're 100% focused on upstream contributions to

22:48.100 --> 22:53.700
Jupiter. With the goal of making sure that Jupiter continues to be the best notebook platform out

22:53.700 --> 23:00.340
there. And that is, and it's again, not just about the software, but it's also about the community,

23:00.340 --> 23:07.780
the open source community. And so we're participating in that open source community in a way that we

23:07.780 --> 23:16.260
hope makes sustainable and growing inclusive and diverse. Zooming out a bit, I'm curious how you

23:16.260 --> 23:26.260
think about the broader ML tooling space. And you know, Jupiter is just one piece of what data

23:26.260 --> 23:34.660
scientists or machine learning engineer might interact with to get an idea for a model from

23:34.660 --> 23:40.740
that idea into production. How do you think about that broader space?

23:42.020 --> 23:51.140
Yeah. And so for this, I'll start with the landscape of products we have at AWS for machine

23:51.140 --> 23:59.540
learning under the SageMaker umbrella. And what we're seeing from customers is that there's

23:59.540 --> 24:06.740
a bunch of different tools and capabilities they need to go all the way from the beginning of

24:06.740 --> 24:13.140
the machine learning workflow where they're preparing data, importing data all the way to

24:13.140 --> 24:17.620
building models and then deploying them and then using them to make predictions, whether it's

24:17.620 --> 24:25.300
in a product through an API or make predictions that are more consumed by humans and something

24:25.300 --> 24:34.580
like a dashboard. And we've been building the tools at AWS and SageMaker for the different parts

24:34.580 --> 24:40.820
of that machine learning workflow in close collaboration with customers. As you know, one of the AWS

24:40.820 --> 24:47.620
leadership principles is customer obsession, which means that we spend a lot of time talking to

24:47.620 --> 24:53.220
customers and understanding what they're doing, what their needs are. And so all the different

24:53.220 --> 24:58.900
things we're building in SageMaker are a response to what our customers need. Now with that said,

24:59.940 --> 25:06.180
I think that the challenge that's emerging more broadly is one of complexity, that if you look

25:06.180 --> 25:13.460
at all the tools, a large organization would have to string together to cover and span the complete

25:13.460 --> 25:18.980
end-to-end machine learning workflow to have those tools address the different personas that

25:18.980 --> 25:24.900
are participating in machine learning, whether it's data engineers, data scientists, ML scientists,

25:24.900 --> 25:33.140
ML ops engineers, etc. There's just incredible complexity. And the complexity is along a number of

25:33.140 --> 25:39.860
different dimensions. There's fundamental complexity in the data. People are working with,

25:39.860 --> 25:44.820
there's complexity in the algorithms they're working with, there's workflow complexity,

25:44.820 --> 25:51.540
and then there's the reality that this nice picture that we have about the machine learning workflow

25:51.540 --> 25:57.380
that starts from importing data to exploratory data analysis, to data preparation, to model training,

25:57.380 --> 26:04.420
to model evaluation, deployment, it's never linear in practice, right? Someone starts working with

26:04.420 --> 26:10.740
a data set and the initial questions are going to be asking are very basic, such as what's even

26:10.740 --> 26:16.180
in this data? What might we predict? What business questions might we predict with this data?

26:16.900 --> 26:22.900
And they may get to the end of that initial pass and discover we're not even close to being ready

26:22.900 --> 26:27.700
to building a model that we can deploy and make predictions against. We have to go back to the

26:27.700 --> 26:33.460
beginning, clean up the data, gather more data, join it with other data that we don't have available,

26:34.100 --> 26:37.940
and then they're come back and do that again. And maybe this time they get a little further

26:37.940 --> 26:43.460
and start to feel like, okay, we may be able to predict this. Let's dive in and see how far we

26:43.460 --> 26:49.380
can push it in terms of the quality of the model we can build. And then after that, they may have

26:49.380 --> 26:56.980
to look at questions around bias and explainability and understand, okay, we have a model that's performing

26:56.980 --> 27:03.220
well, but can we use it responsibly and ethically? And they may have to do another cycle through all of

27:03.220 --> 27:10.500
this. And this iterative nature, and then the complexity of the overall workflow, I think is

27:10.500 --> 27:17.780
something that we at AWS and everyone across this entire industry is just starting to grapple with.

27:18.660 --> 27:23.540
I'm hoping that 10 years from now, we look back on this stage and say, wow, we've made incredible

27:23.540 --> 27:31.220
progress. Really on the side of UX design and human computer interaction that our systems will

27:31.220 --> 27:36.900
evolve to the point where they still have these capabilities, but allow human workers who are using

27:36.900 --> 27:42.020
the tools to have a much simpler experience. And I think that's the main challenge we have right now.

27:42.980 --> 27:49.700
Digging into the user experience and HCI aspects of this, I know that's something that you

27:50.340 --> 27:56.260
are very passionate about and spend a lot of time researching. What,

27:56.260 --> 28:04.500
you know, what, you know, have we learned or what have you learned and have applied into

28:05.540 --> 28:12.500
Jupiter or, you know, what's kind of changed the way you think about Jupiter or, you know, what

28:12.500 --> 28:20.980
from those spaces do you think will kind of impact the way that you, you know, build these tools

28:20.980 --> 28:27.540
and guide these tools in the future? Yeah, there's a number of different dimensions here.

28:30.020 --> 28:38.500
All maybe pick two, two of them to talk about briefly. One is that in organizations that are doing

28:38.500 --> 28:46.100
machine learning and building machine learning tools, you're pretty much guaranteed that by definition,

28:46.100 --> 28:53.380
they're engineering heavy. You, if you look at these organizations, you're not going to find a lot

28:53.380 --> 28:59.700
of UX designers that just naturally work into the process. So that's the first challenge is that

28:59.700 --> 29:04.500
is sort of the way to engineering required to build these systems and use these systems is massive.

29:05.220 --> 29:14.020
And even in, even in organizations like SageMaker in the AWS AIML org, we have been very deliberate

29:14.020 --> 29:19.780
to build out UX design teams. And yet, if you look across our organization, we're still very

29:19.780 --> 29:26.740
engineering heavy because the problem requires it to be so. And so just the weight and momentum of

29:26.740 --> 29:34.580
engineering presents, presents a lot of challenges to prioritizing the human experience of these tools.

29:34.580 --> 29:42.500
And so a lot of what I'm working on right now at AWS is building mechanisms to help us include

29:42.500 --> 29:51.620
the consideration of the human experience in this. And it's a lot of fun to be diving into that,

29:51.620 --> 29:58.100
but certainly very challenging. And I think that the key is that at least at AWS,

29:58.900 --> 30:06.420
it's rather new to build tools where the human experience is so primary and important.

30:06.420 --> 30:13.700
And it's a growth area for us and something that we're spending a lot of time and energy and

30:13.700 --> 30:24.100
investment on to improve in this space. The other dimension of this is I think that there's very

30:24.100 --> 30:36.180
few situations where we as humans have tried to design tools that are this technically complex.

30:36.180 --> 30:41.780
And what I mean, I'll use an analogy here. I'm a car nerd in addition to being a

30:43.380 --> 30:51.620
data nerd. And if you think about how people approach car design, if you're designing a hatchback

30:51.620 --> 30:59.300
for mass-produced market, you can have UX designers come in and look at the human needs.

30:59.300 --> 31:04.260
And those UX designers will not need to know much about the technical implementation of that car.

31:04.260 --> 31:09.540
They're not going to need to know about that. They can work with engineers who can handle all that

31:09.540 --> 31:15.300
and it will work wonderfully. If on the other hand, your job is to design a formula and racing car,

31:16.420 --> 31:20.180
anyone involved in that product, I mean, if you want to think of it as a product,

31:21.220 --> 31:25.940
has to have an incredibly high level of technical knowledge. For example,

31:25.940 --> 31:33.220
let's say you're the UX designer who's designing the steering wheel for an F1 racing car,

31:34.260 --> 31:39.620
you need to understand what are all the technical capabilities that the driver needs to have

31:39.620 --> 31:48.980
at their fingertips. What are the principles on the human side, the human factors that would enable

31:48.980 --> 31:55.860
a driver to manage dozens of buttons driving 200 miles an hour. How on earth do they do

31:55.860 --> 32:01.300
that? They're going to have to glance down in a split second to find that button to change the

32:01.300 --> 32:07.780
brake bias or to change how the engine is tuned. And the designer going through that has to become

32:08.420 --> 32:12.740
an expert in the technical details of that platform. They're going to need to know about

32:12.740 --> 32:18.580
tire wear, brake bias. When do the drivers need to use these things? And this is, I think,

32:18.580 --> 32:24.980
another fundamental challenge is that the designers who are helping to design these tools

32:24.980 --> 32:31.780
need over time to get that technical expertise to understand these technical users and what they're

32:31.780 --> 32:40.580
doing with the code and the data and the tools we're building. In kind of talking about the first of

32:40.580 --> 32:50.660
those, the first of those directions for incorporating user experience into product,

32:50.660 --> 32:59.140
the recent Canvas announcement came to mind. Can you talk a little bit about the way that

33:00.100 --> 33:08.100
user experience design went into that product? Yeah, absolutely. So at reinvent this year,

33:08.100 --> 33:14.340
we launched Amazon SageMaker Canvas, which is a tool that enables business analysts to train

33:14.340 --> 33:19.700
machine learning models. So these are users that spent a lot of time working with tabular

33:19.700 --> 33:26.420
data sets. And they're focused on answering significant business questions with tabular data sets.

33:26.420 --> 33:32.900
Maybe Excel spreadsheets. They may have data in relational databases and running SQL queries

33:32.900 --> 33:42.020
against them. And what we're hearing from customers is that these business analysts often would work

33:42.020 --> 33:50.660
with data scientists or machine learning practitioners who can build models. But there's never enough data

33:50.660 --> 33:58.260
scientists and machine learning practitioners to support the business analysts. And so the vision

33:58.260 --> 34:05.460
of Canvas is basically let one of these analysts import a tabular data set. And then pick a target

34:05.460 --> 34:13.460
column. We suggest what type of prediction is relevant, whether that's classification or regression.

34:13.460 --> 34:18.340
And then we train a model and enable the business analyst to quickly make predictions. And it's a

34:18.340 --> 34:25.300
no-code interface. And what's exciting about it is that use the same underlying platform

34:26.100 --> 34:31.780
of SageMaker. So the models that are trained in Canvas use SageMaker Autopilot, which is our

34:31.780 --> 34:40.020
AutoML service. And so the analysts when they train a model can then hand it off to the data scientists

34:40.020 --> 34:45.540
who can then do additional work on that model as needed. For example, if there's multiple model

34:45.540 --> 34:50.420
candidates that autopilot is suggested, the data scientists can come in and help the analysts at

34:50.420 --> 34:56.020
that point figure out what for this business use case, what is the best possible model at that time.

34:56.020 --> 35:02.740
And what we're seeing is that Canvas enables these analyst users to focus on the business

35:02.740 --> 35:07.220
questions that they want to answer. And then understanding what types of things they can

35:07.220 --> 35:16.340
predict using machine learning. And the, yes, even the name of the product kind of elicits this

35:16.340 --> 35:27.940
visual approach to building machine learning. Do you see that as extending beyond what Canvas is

35:27.940 --> 35:37.860
today, which is frankly a very simple approach to solving relatively simple problems?

35:37.860 --> 35:46.820
The question that I would come back to is, is for these analysts, what are they doing on a daily

35:46.820 --> 35:52.740
basis that where machine learning could help them? And how do we make them successful in doing that?

35:53.620 --> 36:03.300
And today, Canvas does have some data preparation capabilities, but it's not as sophisticated,

36:03.300 --> 36:09.620
for example, as the, what data scientists would do in a notebook or what they would do in a tool

36:09.620 --> 36:19.540
like SageMaker Data Wrangler, which is a low-code data preparation tool we have in SageMaker Studio.

36:20.580 --> 36:27.220
And so I think we have a question in Canvas right now around, or I guess it's more of a hypothesis,

36:27.220 --> 36:34.180
that the analyst personas don't need to do heavy-duty data preparation, but now that we've

36:34.180 --> 36:38.180
launched a product, we're going to get to figure out how much data preparation do they need?

36:38.820 --> 36:44.420
Do they want to do it themselves? Do they want to be assisted in doing data preparation by data

36:44.420 --> 36:50.660
scientists? At this point, our hypothesis is that they don't, they don't need to do a heavy-duty

36:50.660 --> 36:57.620
data preparation. And a lot of this, you know, this is not just sort of a wild gas, but we spent a

36:57.620 --> 37:04.820
lot of time talking to customers who have analysts who would be using a tool like this, and that's

37:04.820 --> 37:10.660
our sense right now. And so, you know, I think part of what you're asking is how might, where might

37:11.540 --> 37:19.380
Canvas evolve to over time? I think that's one question we have. Another question is the role of

37:19.380 --> 37:27.220
collaboration between the business analysts and data scientists. We have collaboration capabilities

37:27.220 --> 37:33.860
built into Canvas and SageMaker Studio to enable this to happen. I think our hypothesis is that

37:33.860 --> 37:40.100
these users do need to work together. Time will tell, tell us more about the nature of that

37:40.100 --> 37:47.140
collaboration and what additional things customers need. Yeah, I'd love to maybe spend a bit talking

37:47.140 --> 37:56.420
a little bit more about collaboration and the way you see collaboration kind of taking place

37:56.420 --> 38:04.420
in the context of the machine learning workflow in general, and notebooks in particular. I think

38:04.420 --> 38:14.100
when we, it's easy to look at notebooks and what they, you know, taking you from this IDE and

38:14.100 --> 38:20.980
a terminal or terminal that's kind of, you know, landlocked to your computer to a web page that,

38:20.980 --> 38:26.660
you know, could be anywhere and offers the idea of, or the possibility of collaboration.

38:28.580 --> 38:36.100
It strikes me that while that is a natural idea for notebooks, it's under-implemented maybe.

38:36.100 --> 38:41.700
I don't see it being used in that way as often as, you know, I might expect. It's like the promise

38:41.700 --> 38:46.100
of a Google Doc, but, you know, everyone just uses it as a regular word processor.

38:47.380 --> 38:55.140
And I'm wondering, you know, what you observe about collaboration and the ML process in general,

38:55.140 --> 38:59.940
and the way you see that applying to, you know, tools and notebooks in particular.

39:00.580 --> 39:04.580
When we released the, the Python notebook in 2011,

39:04.580 --> 39:10.900
and users started to work with it and began to open issues on GitHub to give us feedback.

39:10.900 --> 39:17.220
And within a very short period of time, I think it was a month or two, one of the earliest feature

39:17.220 --> 39:22.340
requests we had was for real-time collaborations similar to what you would have in something like

39:23.300 --> 39:30.500
Google Docs. And it has continued to be probably the most significant feature requests we have

39:30.500 --> 39:37.060
from the Jupyter community. And so we heard from the Jupyter user base very early on that they

39:37.060 --> 39:41.940
wanted real-time collaboration, that they looked at these notebook documents in a similar way to how

39:41.940 --> 39:48.580
they look at documents that they work within a word processor and wanted to collaborate with that,

39:48.580 --> 39:54.980
that mode of interaction. And so we've, on the Jupyter side, we spent many years working on this,

39:54.980 --> 40:01.780
we've had a number of sort of false starts. It's compounded by the fact that building a,

40:01.780 --> 40:08.260
the needed infrastructure and architecture for real-time collaboration from a, from an algorithm

40:08.260 --> 40:14.740
perspective is quite complex. Thankfully, the underlying algorithms have improved over the years.

40:15.540 --> 40:23.140
And so it, just this year in Jupyter Lab 3, we've launched the first support for real-time

40:23.140 --> 40:28.980
collaboration. And we're using a, another open source library that's been fantastic for this,

40:28.980 --> 40:38.100
called YGS. It offers a very high-performance CRDT implementation in JavaScript. And so that's

40:38.100 --> 40:45.300
really what is enabled us to build real-time collaboration in Jupyter Lab 3. And so if you,

40:45.300 --> 40:51.140
any user of Jupyter Lab downloads the latest version of Jupyter Lab 3, there's a special flag

40:51.140 --> 40:56.340
you can issue at the command line that enables the collaboration feature. With that said,

40:56.340 --> 41:01.060
we're just getting started in terms of the full experience of this. There's a lot of additional

41:01.060 --> 41:08.020
user experience, dimensions that we need to add, other technical dimensions, but it continues to be

41:08.020 --> 41:14.500
a major focus of the Jupyter community. And something that users want and have wanted since the

41:14.500 --> 41:21.060
very beginning. Now, the broader picture of collaboration that you mentioned in machine learning,

41:21.060 --> 41:27.940
I think what, what we see both at AWS and in Jupyter is that there are many different personas

41:27.940 --> 41:33.700
that participate in the overall machine learning workflow. And the key points of collaboration

41:33.700 --> 41:39.380
are between those different personas. So, for example, one, a data engineer who's been

41:39.380 --> 41:45.620
preparing and getting the data ready, hands off a data set to a data scientist for them to work on

41:45.620 --> 41:53.380
it. And I think that that mode of collaboration between personas is really one of the main challenges

41:53.380 --> 42:00.740
we see both in Project Jupyter and in in SageMaker products on the AWS side. And it's very different

42:00.740 --> 42:06.260
from environments where collaboration happens primarily among the same persona.

42:06.260 --> 42:13.940
And it adds that it's not to say that that that pattern of collaboration never happens in data

42:13.940 --> 42:19.380
science and machine learning, but I think that the more the more challenging one is the cross

42:19.380 --> 42:26.740
persona collaboration. Yeah, I could see arguments for that making things

42:26.740 --> 42:37.700
easier in that you have these well-defined interfaces between, you know, not that they're inherently

42:37.700 --> 42:43.380
well-defined, but there's an opportunity to define an interface between the personas, whereas

42:44.500 --> 42:49.620
if you have people in the same, with the same role in the process working on the same thing,

42:49.620 --> 42:57.300
it's easier for them to kind of walk on one another's work, so to speak. But it also defining

42:57.300 --> 43:04.660
those interfaces can be challenging. Absolutely. And that's, it really is, and there's both the

43:05.540 --> 43:12.740
interface from the perspective of a programmatic API, and then also from the perspective of a

43:12.740 --> 43:20.420
like a graphical application. And the other, you know, we quickly get into the challenges of

43:20.420 --> 43:28.580
distributed and shared data structures, and that is some personas tend to work with entities

43:28.580 --> 43:36.580
that are immutable, others with entities that are immutable, and figure out how to

43:36.580 --> 43:43.700
get those personas to collaborate, when the underlying entities that they're dealing with

43:43.700 --> 43:49.860
are fundamentally different. So for example, software engineers are completely familiar with

43:49.860 --> 43:56.660
collaborating using Git and a version control system. But when you look at other stakeholders

43:56.660 --> 44:00.580
that want to interact with maybe the notebooks the data scientists are working with,

44:00.580 --> 44:06.580
they're not going to be using Git, right? They probably want a graphical interface that allows

44:06.580 --> 44:12.660
them to comment on a notebook in the same way that you comment on a word processing document,

44:13.220 --> 44:17.540
right? They're not going to be on GitHub. They're not submitting pull requests and using the

44:17.540 --> 44:22.420
Git command line or anything like that. And yet it's still the same entity underneath. It's still

44:22.420 --> 44:29.060
a notebook at the end of the day. And so figuring out how even what the entities and data structures

44:29.060 --> 44:32.980
are underneath the cross-role collaboration, I think is a really major challenge.

44:33.540 --> 44:40.820
Nariah that I wanted to talk with through with you is the role of the notebook overall.

44:40.820 --> 44:46.980
It's maybe circling back to the very beginning of the conversation. But this is I think a

44:46.980 --> 44:53.940
conversation that's happening fairly broadly in our community. And that is, you know,

44:53.940 --> 44:59.060
often comes up as, you know, our notebooks, the right tool for machine learning or, you know,

44:59.060 --> 45:06.900
notebooks versus IDE's. And, you know, when you think about Canvas in the mix, you know,

45:06.900 --> 45:13.700
maybe the question is, you know, no code versus notebooks versus IDE's. How do you react to

45:14.500 --> 45:22.340
those types of questions? Yeah, this is a great one. So first, I'll tackle the question of

45:22.340 --> 45:29.300
when should you use a notebook versus IDE or is the notebook a substitute for the IDE?

45:30.180 --> 45:38.740
And really here, I think that the question to ask is, what is the fundamental activity or task

45:38.740 --> 45:44.340
you're performing? And in the case of an IDE, typically that task is that you're building something.

45:44.340 --> 45:50.260
You're building software, you're building a service, an API, a software product. And so the

45:50.260 --> 45:57.780
fundamental verb of an IDE, I would say is build. Now, maybe the secondary verbs that would be test,

45:57.780 --> 46:04.980
deploy, debug, et cetera, that go along with that. Whereas if you look at a notebook and what

46:04.980 --> 46:11.700
the notebook was built for and how people use it, I would say that build is probably not even

46:11.700 --> 46:19.460
secondary. And so what is the sort of fundamental activity? I think it's really that the notebook

46:19.460 --> 46:26.340
is a tool for thinking with code and data. That when a user's working with a notebook at the end

46:26.340 --> 46:33.620
of the day, they're trying to work in parallel with the computer to understand what is in the data

46:33.620 --> 46:39.060
and what they might predict. And what the meaning of that prediction is, is their causation there,

46:39.060 --> 46:44.740
is their bias. How can they use this to explain the result? Do they trust the prediction that the

46:44.740 --> 46:52.020
model is making? Can they use it? Essically, these are all human questions. And so the notebook

46:52.020 --> 46:58.180
really is a tool for thinking. And when you have this perspective, there's not really any confusion

46:58.180 --> 47:04.260
between an IDE and a notebook. There are two different tools that are used for two very

47:04.260 --> 47:12.980
different tasks. In the same way that an SUV and a two-seater sports car are two very different

47:12.980 --> 47:19.460
vehicles use for a different set of purposes. And if you try to take an SUV and drive it and get

47:19.460 --> 47:24.260
the sports car experience out of it, it's going to be pretty disappointing and vice versa.

47:25.460 --> 47:31.140
And so when I want to hear people sort of complaining that Jupiter's not a very good IDE,

47:32.020 --> 47:38.020
my sort of the filter I read that with is more along the lines of someone saying that an SUV is not

47:38.020 --> 47:45.780
a very good sports car, namely, yeah, it's not. It wasn't designed to be, Jupiter was not designed

47:45.780 --> 47:52.180
to be an IDE in the same sense that it's used for building and deploying and debugging software

47:52.180 --> 48:01.140
products. With that said, there is a gray zone where users start to work in a notebook interactively

48:01.140 --> 48:06.020
thinking about code and data. And at some point, a project gets to the point where it's mature enough

48:06.020 --> 48:14.900
that people start to build things. That transition is still really painful. And it's painful whether

48:14.900 --> 48:22.260
you try to keep working in Jupiter or you go from working in Jupiter with notebooks over traditional IDE.

48:22.820 --> 48:28.980
And I think that's a major area of innovation that there's a lot of potential for the Jupiter

48:28.980 --> 48:34.260
open source community and others to dive into and figure out what does this transition look like

48:34.260 --> 48:40.420
from thinking with code and data to building software products. And how do you make that transition

48:40.420 --> 48:49.620
and work in that sort of in between zone? Yeah, I was thinking there are a number of efforts,

48:49.620 --> 48:55.620
you know, taking different approaches to try to productionize the notebook.

48:55.620 --> 49:04.900
And I'm sure you've seen these as well. And up until the very end of your comment, I would have

49:04.900 --> 49:09.620
thought you were thinking that those are all misguided. But it sounds like rather,

49:10.980 --> 49:14.980
there's just attempts to figure out this confusing thing that we don't really know what it needs to

49:14.980 --> 49:22.020
look like just yet. Yeah, there's a number of efforts in the Jupiter open source community and

49:22.020 --> 49:28.340
other open source projects around taking notebooks and using them in a more production oriented way.

49:29.460 --> 49:38.020
So one idea that's a it's a Jupiter sub project called voila, it allows users to tag cells in a

49:38.020 --> 49:43.620
notebook and then turn those cells into an interactive dashboard that looks like a web application,

49:43.620 --> 49:48.820
does not look like a notebook and deploy that to users. So that would be more of a human oriented

49:48.820 --> 49:55.860
deployment of a notebook to a group of users who never want to look at the code and and the

49:55.860 --> 50:01.140
notebook, but who want to interact with the outputs of that notebook. Maybe another example,

50:01.140 --> 50:06.820
as you brought up was idea of scheduling notebooks. And that is that that at some level,

50:06.820 --> 50:12.260
you can write a notebook like you can write a Python function, a notebook could be parametrized

50:12.260 --> 50:16.580
by a set of arguments. And then you might want to run that notebook for a different set of

50:16.580 --> 50:23.860
arguments on some schedule. And both of those usage cases are things that we're seeing. And I think

50:24.820 --> 50:32.740
different Jupiter users and AWS customers are doing things like that. I think the more

50:33.620 --> 50:37.860
challenging cases in this space are where you want to

50:39.540 --> 50:44.740
build a machine learning model initially in a notebook, but eventually transition to

50:44.740 --> 50:51.540
building a model as part of a broader pipeline that leads to the deployment of a model with an end

50:51.540 --> 50:57.620
point, that transition between a notebook and the more traditional building that you do in an IDE

50:58.180 --> 51:04.420
is still quite painful. And I don't know that these notebook-driven dashboards or notebook

51:04.420 --> 51:10.660
scheduling are really the right answer to tackle those. Before we wrap up, I wanted to cover another

51:10.660 --> 51:18.660
of the announcements that was made at ReInvent. And that is the new Amazon SageMaker Studio Lab

51:19.300 --> 51:25.380
product that you and your team worked on. Tell us a little bit about Studio Lab and how it came about.

51:25.380 --> 51:31.220
Yeah. So as you mentioned, Amazon SageMaker Studio Lab was launched at ReInvent this year.

51:32.020 --> 51:38.100
And the origin of this really comes back to the following question. And that is

51:38.100 --> 51:43.700
what's the minimum set of things that someone needs to get started with machine learning?

51:44.420 --> 51:48.740
And I'm using the phrase getting started with machine learning very broadly here. This could be

51:49.860 --> 51:54.980
students who are learning about machine learning and data science in a university class.

51:54.980 --> 52:00.100
They could be learning on their own in a self-paced way. Or it even extends to

52:00.980 --> 52:07.220
people who already have a good amount of machine learning expertise and are more enthusiast. And not

52:07.220 --> 52:13.060
doing machine learning though in enterprise context where they have a support staff that maintains

52:13.060 --> 52:18.500
cloud-based infrastructure for them. And really, if you look at how people learn machine learning

52:18.500 --> 52:24.340
these days, there's a small set of things they need. One, they need notebooks. They need some

52:24.340 --> 52:31.140
way of using Jupyter notebooks. Two, they need open source packages for machine learning.

52:31.140 --> 52:38.900
They need tools such as NumPy, Pandas, TensorFlow, Scikit-learn, PyTorch, etc.

52:39.620 --> 52:45.220
And then they need some place to run the code. They need compute of some sort and storage that

52:45.220 --> 52:52.980
goes along with it. And those basic ingredients are really what is how we approach SageMaker Studio Lab.

52:52.980 --> 52:59.460
So it really is an abbreviated version of SageMaker Studio that provides a notebook-based

52:59.460 --> 53:06.900
development environment for users where they can use a Jupyter Lab-based environment.

53:07.460 --> 53:15.220
And we offer free compute and free storage along with this. And so the real significance here

53:15.220 --> 53:22.260
is that users don't need to have an AWS account for this. They can sign up with an email,

53:22.820 --> 53:28.820
no credit card required. There's a simple account approval step that takes a few hours.

53:28.820 --> 53:34.180
Once you have an account, you get 15 gigs of persistent storage for your project.

53:34.820 --> 53:42.260
And then you can attach that storage to either a CPU or a GPU runtime and do data science

53:42.260 --> 53:48.340
in machine learning and work with it in that context. And it's all free. And because there's

53:48.340 --> 53:54.100
persistent storage behind this, even though we obviously behind the scenes, we shut down the

53:54.100 --> 53:59.380
instance when you're not working, when you come back, all your files will still be there. And so

53:59.380 --> 54:05.460
this is a real file system that's persistent and allocated to your project. You can check out

54:06.660 --> 54:12.180
Git repositories locally. You can install Python packages persistently and save your data sets

54:12.180 --> 54:18.660
and notebooks, notebooks alongside of all those things. And is it from the perspective of

54:18.660 --> 54:32.020
building the products for the intended scale? Is it a, how did you think about this as a product?

54:32.020 --> 54:41.700
Is it a ground up effort starting from components like EC2 and all the other components that AWS

54:41.700 --> 54:49.220
has in Jupyter or, you know, is it a starting from SageMaker and kind of trim back? How should we

54:49.220 --> 54:54.420
think about the way this came together? Yeah, that's a great question. So when we built Amazon

54:54.420 --> 55:01.140
SageMaker Studio, that was launched at Reinvent two years ago, we built a platform that enabled us

55:01.140 --> 55:07.300
to build these types of applications where you have an interactive user interface connected to

55:07.300 --> 55:14.820
compute underneath with a persistent file system. And so that platform was already there with

55:14.820 --> 55:21.700
SageMaker Studio. And we've reused that platform for SageMaker Studio Lab. Now there's some key

55:21.700 --> 55:27.540
differences between the two and some common points. I'll start with the common points. So part of

55:27.540 --> 55:35.140
the reason we built this platform for SageMaker Studio was that when we talked to customers,

55:35.140 --> 55:40.900
they had security needs that could not be satisfied in a traditional Kubernetes environment.

55:41.540 --> 55:48.900
And so the platform that we're using for SageMaker Studio and for Studio Lab is we're not using

55:48.900 --> 55:55.380
Kubernetes. It's based on instances. Our customers have told us that they need instance level

55:55.380 --> 56:01.780
isolation from a security perspective. And so a lot of the work we've put in on the SageMaker

56:01.780 --> 56:10.020
Studio side with encryption at rest, encryption at transit, VPC support, instance level isolation.

56:10.980 --> 56:16.820
We've been able to take that and apply it in the SageMaker Studio Lab case. And so one of the

56:16.820 --> 56:23.300
sort of hidden features of SageMaker Studio Lab, even though it's not focused on large enterprise

56:23.300 --> 56:29.220
usage cases, it still has all the enterprise security instance level isolation that we have on

56:29.220 --> 56:36.820
the SageMaker side of things. So we we're able to reuse that. A lot of the the magic of this

56:36.820 --> 56:44.580
platform is because it's instance space, there's a potential for to take a long time to start

56:44.580 --> 56:52.420
instances. We've done a lot of work and innovated pretty incredible stuff that enables the

56:52.420 --> 56:57.460
instance start times in SageMaker Studio Lab to be fast enough that it's not really going to get

56:57.460 --> 57:02.820
in the way of most people. Obviously, it can't be hundreds of milliseconds or something like that,

57:02.820 --> 57:08.020
but it's fast enough. I find when I'm using SageMaker Studio Lab that the the runtime

57:08.980 --> 57:13.300
an instance start time is fast enough that I don't really think about it. And so we have been

57:13.300 --> 57:20.820
able to reuse that platform for SageMaker Studio Lab. And the other point where the enterprise

57:20.820 --> 57:26.500
security is important is that we wanted SageMaker Studio Lab to be a place where we could tell users

57:26.500 --> 57:33.620
it's fine if you want to install your AWS credentials to another AWS account that you have a paid

57:33.620 --> 57:40.980
AWS account and make calls out from the AWS SDK or command line from SageMaker Studio Lab.

57:41.540 --> 57:46.820
And if we didn't have that enterprise security in place, we could not tell users great install

57:46.820 --> 57:54.660
your AWS credentials on the on Studio Lab. Does that mean that there's a key store feature or that

57:54.660 --> 58:02.020
you consider the instance level security to be robust enough that I can just put my

58:03.140 --> 58:10.660
AWS keys in a cell in the Jupyter Notebook. So please don't put your credentials in a cell in

58:10.660 --> 58:22.020
the Jupyter Notebook. That is definitely an anti-pattern. And we regularly see customers who do that

58:22.020 --> 58:27.620
and then later forget about it and version control the notebook in the end of yeah the credentials

58:27.620 --> 58:39.780
end up on GitHub. So that's why I was asking. It's a great question. So the model is that your project

58:39.780 --> 58:48.260
gets 15 gigs of persistent storage and that storage is encrypted. And so you can install your AWS

58:48.260 --> 58:55.380
credentials just like you normally would on your laptop. And because the entire drive is encrypted

58:56.260 --> 59:01.860
and we handle it with all the necessary security precautions, you can install your credentials

59:01.860 --> 59:08.180
that way. But yes, putting them directly in a notebook obviously is not a recommended.

59:08.180 --> 59:13.140
In theory, not because it's any less encrypted, but because you're more likely to put it

59:13.140 --> 59:18.740
someplace where it shouldn't be. Yes, if you never move a notebook out of SageMaker Studio Lab,

59:18.740 --> 59:23.300
that notebook will be saved on that same encrypted volume and it will be fine. The risk is more

59:23.300 --> 59:29.140
that that users would later do something with the notebook that expose those credentials outside

59:29.140 --> 59:37.540
their original context. Maybe just one more kind of to wrap things up. Where do you see all this going?

59:37.540 --> 59:43.140
What are you most excited about in terms of the future of ML development and

59:44.900 --> 59:49.700
human computer interfaces for machine learning? I'll answer this personally.

59:51.460 --> 01:00:01.140
And for me, I thrive on ambiguity and challenge. I want to be working on things where the answer

01:00:01.140 --> 01:00:08.340
is not known, or it's not obvious, or there's significant challenges involved in coming to an answer.

01:00:10.340 --> 01:00:16.580
I, when I look at this space, the amount of challenge in ambiguity that we have left is vast.

01:00:17.380 --> 01:00:21.860
And so I find a lot of just a lot of enjoyment in working in a space where there's so many

01:00:21.860 --> 01:00:27.460
unanswered questions. And some of it, this does come from my background in physics and

01:00:27.460 --> 01:00:35.780
I love physics. And at the end of the day, I'm probably still a physicist. One of the challenges

01:00:35.780 --> 01:00:44.500
in physics, though, is that as the field has grown and more and more is known in the physics space,

01:00:44.500 --> 01:00:50.500
there are fewer and fewer unanswered questions that are available to be answered that are really

01:00:50.500 --> 01:00:56.900
deep and interesting. Now, there are some obviously, but you really have to hunt in physics, honestly,

01:00:56.900 --> 01:01:02.660
is my, my sense as a physicist is that you have to work really hard to find good problems to solve,

01:01:03.300 --> 01:01:08.820
whereas in this space, there's an abundance of problems. And they're all really challenging

01:01:08.820 --> 01:01:13.780
and really interesting. And there's a lot of people who will benefit by solving those problems.

01:01:13.780 --> 01:01:19.060
So that, that's what I'm excited about in terms of looking forward in this space.

01:01:19.540 --> 01:01:25.940
Awesome. Awesome. Brian, thanks so much for joining us and sharing a bit about what you've

01:01:25.940 --> 01:01:33.380
been working on and some of the new stage maker and studio announcements coming out of reinvent.

01:01:34.100 --> 01:01:38.180
Thank you so much, Sam. It's really great to be here and talk to you about all these things.

01:01:38.180 --> 01:01:44.660
And I appreciate your time and questions about the early history of Jupiter, which is really a fun

01:01:44.660 --> 01:01:56.100
story to tell.

