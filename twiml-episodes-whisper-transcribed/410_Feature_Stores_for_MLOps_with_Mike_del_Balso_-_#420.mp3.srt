1
00:00:00,000 --> 00:00:12,320
All right, everyone. I am here with Mike DelBalso. Mike is the co-founder and CEO of Techton.

2
00:00:13,040 --> 00:00:17,920
Mike, welcome to the Twomo AI podcast or I should say welcome back to the Twomo AI podcast.

3
00:00:17,920 --> 00:00:22,160
Yeah, thank you. Happy to be back after a couple of years now.

4
00:00:22,160 --> 00:00:28,800
A couple of years. So we recorded our first interview in March of 2018. So

5
00:00:28,800 --> 00:00:37,440
it's like two and a half years. It was episode number 115 and we just published four

6
00:00:37,440 --> 00:00:45,680
17. So 300 episodes ago. Wow. I'm not even considering 2020 years which make it seem way

7
00:00:45,680 --> 00:00:50,960
longer. Yeah, that's like three decades ago. That's nuts. Well, I'm happy to be back and

8
00:00:50,960 --> 00:01:01,280
congrats on having what 415, 417. Wow, that's a that's quite an accomplishment.

9
00:01:02,240 --> 00:01:06,160
Yeah, happy to be back. Thanks for having me. Absolutely, absolutely. And you've been busy

10
00:01:06,160 --> 00:01:14,000
yourself. When we first spoke, you were at Uber and we were talking about Michelangelo, the platform

11
00:01:14,000 --> 00:01:23,280
that you built there to help scale and operationalize machine learning and you left Uber to help

12
00:01:23,280 --> 00:01:31,040
other folks do that. When did you how long has it been? Yeah, so beginning of 2019 right at the

13
00:01:31,040 --> 00:01:37,920
end of 2018, that's when myself and some of the other folks that helped build the Michelangelo

14
00:01:37,920 --> 00:01:48,000
system, we kind of split off to help other folks solve similar problems. And yeah, so companies

15
00:01:48,000 --> 00:01:54,960
called Techton, we build an enterprise feature store for machine learning and happy to tell folks

16
00:01:54,960 --> 00:02:01,360
about that today. But yeah, that started. So we've been doing that almost two years into that.

17
00:02:01,360 --> 00:02:14,080
Wow, wow. I'm curious about one thing I'm curious about is, you know, Michelangelo kind of

18
00:02:14,080 --> 00:02:24,560
encompassed a ton of features not to overload that term. And you could have done a lot of things

19
00:02:24,560 --> 00:02:33,040
in space, but you chose to focus on the kind of feature store part of it. Maybe share a little bit

20
00:02:33,040 --> 00:02:40,880
of that to help contextualize the way you think about the overall problem of operationalizing machine

21
00:02:40,880 --> 00:02:48,880
learning. Yeah, for sure. Well, so I've been doing this a long time now. And before building this

22
00:02:48,880 --> 00:02:59,120
stuff at Uber, I actually was at Google and I worked on the machine learning systems that power

23
00:02:59,120 --> 00:03:06,720
that adds auction at Google. And they had been doing this for many years and they had really great

24
00:03:06,720 --> 00:03:13,120
systems to power these core processes that run Google's business, right, determining what you

25
00:03:13,120 --> 00:03:19,520
had to show. And it's very financially important and super highly productionized. And you know,

26
00:03:19,520 --> 00:03:27,440
at Uber, we were starting from, you know, not zero, but we just had a handful of models and

27
00:03:27,440 --> 00:03:32,960
production. It was kind of early days for machine learning at that time. And we went through this

28
00:03:32,960 --> 00:03:40,080
journey at Uber over a period of like two and a half, three years where we brought in the right

29
00:03:40,080 --> 00:03:48,800
tooling and we really unlocked the ability for the data science and the analytics teams to really

30
00:03:48,800 --> 00:03:53,200
build machine learning systems and deploy them in production. And so during that time, I was,

31
00:03:53,200 --> 00:03:57,520
you know, thinking about, hey, what is, you know, how does this look when it's done right? And

32
00:03:57,520 --> 00:04:02,080
I was thinking a lot about my time at Google and with these really amazing large models updated

33
00:04:02,080 --> 00:04:08,640
all the time, you know, really, we didn't use the term ML ops at that time. But things were highly

34
00:04:08,640 --> 00:04:16,480
productionized and had a very DevOps and modern ML ops feel. And so, you know, we had to build the

35
00:04:16,480 --> 00:04:24,800
whole stack at Uber. We started that 20 in 2015. And there was not a lot of good ML infrastructure

36
00:04:24,800 --> 00:04:33,920
and all tools at that time. And going through that journey, I had the chance to really kind of

37
00:04:33,920 --> 00:04:39,760
understand the value of every single component to the ML stack as we added it, right? We added

38
00:04:40,320 --> 00:04:45,360
model serving layer and, you know, how many use cases did that unlock and how much, how much

39
00:04:45,360 --> 00:04:51,600
did it make it easier for teams that were trying to put ML in production? And we built a model

40
00:04:51,600 --> 00:04:56,000
training system and then we connected them. We built all the different components. And

41
00:04:56,000 --> 00:05:05,040
what we found was that the, so we always hear, you know, team struggle with data and data scientists

42
00:05:05,040 --> 00:05:10,640
spend 85% of their time cleaning data. You know, I'm sure every single, you know, podcast guests

43
00:05:10,640 --> 00:05:18,400
has said that at one point. So we also found though that after kind of solving spending 85% of their

44
00:05:18,400 --> 00:05:23,360
time on that, there's another kind of like hidden 85% of the time it takes to get something into

45
00:05:23,360 --> 00:05:30,640
production as well. And so, and I get that that adds up to more than 100%, but it's also like kind

46
00:05:30,640 --> 00:05:37,040
of the point. And the core of that was these data challenges that were preventing people from

47
00:05:37,040 --> 00:05:43,200
getting to production. And as we built out, what at the time was just kind of like data infrastructure

48
00:05:43,200 --> 00:05:47,760
that we were building into the machine learning system and we were building in these kind of core

49
00:05:47,760 --> 00:05:54,400
data workflows into the machine learning platform at Uber. We found out that that unlocked a lot

50
00:05:54,400 --> 00:06:02,240
of value. And so what, what does that mean? More specifically, it allowed teams to get

51
00:06:03,120 --> 00:06:08,000
into production, to go to production really quickly because before they would have to, they would

52
00:06:08,000 --> 00:06:16,080
be really like coming up with some cool model prototype and then have a bunch of data engineering

53
00:06:16,080 --> 00:06:20,880
that they would have to do to get that model in production. And a lot of the kind of future

54
00:06:20,880 --> 00:06:26,960
store capabilities, we didn't even call it future store right away, are things that unlocked that

55
00:06:26,960 --> 00:06:32,400
path to production really quickly for data scientists who are just trying to build their models.

56
00:06:33,120 --> 00:06:40,000
And the second element there was making just in terms of in terms of machine learning as a

57
00:06:40,000 --> 00:06:50,480
like an organization thing, the future store really allowed for different teams to be able to reuse

58
00:06:50,480 --> 00:06:55,600
each other's work. And so it really kind of like led to the scaling of machine learning across

59
00:06:55,600 --> 00:07:04,720
the organization really quickly because you know, we would have teams that have a variety of

60
00:07:05,680 --> 00:07:08,880
models that they want to build, but they're all kind of similar. They're all kind of using

61
00:07:08,880 --> 00:07:15,600
similar and related data. And so they probably have very high overlap in the number of,

62
00:07:15,600 --> 00:07:20,400
in which features they want to use across those models. And so this provided a way for teams to

63
00:07:20,400 --> 00:07:27,040
share and reuse and kind of have this canonical catalog of these features that allowed for like

64
00:07:27,040 --> 00:07:30,960
kind of like a Cambrian explosion of machine learning at the company. And it wasn't even really

65
00:07:30,960 --> 00:07:35,760
something that we realized at the time, but kind of looking back on it and doing reflections and

66
00:07:35,760 --> 00:07:41,120
reviews, you're like, oh, that was really the component that was the most useful and unlocking

67
00:07:41,120 --> 00:07:44,960
machine learning at the company. And so we spend a lot of time formalizing like what is a

68
00:07:44,960 --> 00:07:52,000
feature store? And what are the bounds of it? And how, you know, how does it use? And that's why

69
00:07:52,000 --> 00:07:58,000
we really focused on the area. Does that make sense? Yeah, no, it does. It does. Yeah, it makes me think

70
00:07:58,000 --> 00:08:03,520
of a question that I've asked a number of folks. We may have even talked about this a couple of

71
00:08:03,520 --> 00:08:12,160
years ago, but when, you know, talking to folks about a feature store, there's, you know,

72
00:08:12,160 --> 00:08:18,880
there's often a set of folks that are super excited about it and get this idea of feature

73
00:08:18,880 --> 00:08:24,720
reusability and wanting to make it, you know, easy for, you know, the next data scientist that

74
00:08:24,720 --> 00:08:30,560
has to deal with customers or products or some of these core ideas that, you know, that a given

75
00:08:30,560 --> 00:08:36,640
business deals with over and over again, you know, wanting to make it easy for them to use pre-built

76
00:08:36,640 --> 00:08:41,600
features. You know, there's a core set of folks that get excited about that. There are other

77
00:08:41,600 --> 00:08:51,120
folks that are somewhat hesitant and, you know, worry about the burden it puts on a data scientist

78
00:08:51,120 --> 00:08:56,160
to, you know, they're essentially then if they publish a feature into a feature store kind of

79
00:08:56,160 --> 00:09:01,520
owning a product, that feature that they have to then maintain and, you know, they may be confronted

80
00:09:01,520 --> 00:09:06,800
with requirements from other data scientists that are not really in line with what they're trying

81
00:09:06,800 --> 00:09:13,040
to do. There's a little bit of, you know, tension between, you know, just making it really easy

82
00:09:13,040 --> 00:09:19,360
for folks to solve their own problem, you know, and then you put in this kind of reuse infrastructure

83
00:09:19,360 --> 00:09:28,800
that promises to make the overall ecosystem faster, but it does require, you know, potentially

84
00:09:28,800 --> 00:09:34,560
sacrifices on the part of individual data scientists. And I'm curious, is that something, you know,

85
00:09:34,560 --> 00:09:40,880
that you run into is that, you know, how was that evolved kind of over the past couple of years

86
00:09:40,880 --> 00:09:46,640
in terms of in practice and the way you see folks use these kind of tools? Yeah, I mean, this is,

87
00:09:46,640 --> 00:09:53,200
I guess that's a core collaboration problem, right? And why do teams want to do this in the first

88
00:09:53,200 --> 00:09:59,040
place? Well, the reason is because these efficiencies that you mentioned, you know, without this,

89
00:09:59,040 --> 00:10:05,120
we, you know, talk to companies every day, see the first hand, there will be two data scientists

90
00:10:05,120 --> 00:10:10,560
who sit right next to each other and they're building the same 10 features or the same 100 features

91
00:10:10,560 --> 00:10:16,400
and either they don't know that the other person is building the same features or they know about it

92
00:10:16,400 --> 00:10:20,560
and then they don't have a way to reuse it. They don't have, they don't have that kind of path

93
00:10:20,560 --> 00:10:25,280
to build that into their model. And then there's that kind of third element of like,

94
00:10:25,280 --> 00:10:31,680
hey, I actually do have a way to reuse this, but you know, I don't know if I'm going to be able

95
00:10:31,680 --> 00:10:36,000
to trust that this person is going to maintain this data pipeline, this feature at the quality,

96
00:10:36,000 --> 00:10:39,760
the level of quality that I care about, is this person going to be on call for this pipeline?

97
00:10:39,760 --> 00:10:46,080
Is, does this person think of it as seriously as I do? You know, I could probably work something

98
00:10:46,080 --> 00:10:49,520
out with them, but you know, it's probably just easier for me to build my own thing even though

99
00:10:49,520 --> 00:10:55,680
it's going to be a hassle. I want to, I want to save this future larger hassle. And so these are

100
00:10:55,680 --> 00:11:00,960
kind of problems, collaboration problems that can be solved by a central platform, right? So

101
00:11:00,960 --> 00:11:12,160
within a feature store, of course, the feature store tracks the kind of data, the feature values

102
00:11:12,160 --> 00:11:17,200
and the functions or the pipelines that generate these features. But there's also like a variety

103
00:11:17,200 --> 00:11:22,400
of metadata, which is like a pretty important component of the feature store metadata that are

104
00:11:22,400 --> 00:11:29,120
tracked for these features to allow different organizations to kind of apply policies for reuse,

105
00:11:29,120 --> 00:11:35,920
right? Who's the owner of this feature? And what level of kind of productionization or SLA,

106
00:11:35,920 --> 00:11:40,480
are they promising for this feature? Are they promising? Is this used in like a tier one system

107
00:11:40,480 --> 00:11:44,880
or a tier two system? And different organizations have different ways that they think about this

108
00:11:44,880 --> 00:11:50,960
kind of stuff. Is it an experimental feature, a production feature, or a completely dev feature?

109
00:11:50,960 --> 00:11:58,400
And so having this kind of metadata and this transparency of this metadata is the first step

110
00:11:58,400 --> 00:12:05,680
to allowing these teams to collaborate. But one kind of pattern that we're beginning to see

111
00:12:05,680 --> 00:12:13,680
in many organizations also is there is this notion of these kind of like analytical data pipelines

112
00:12:13,680 --> 00:12:22,560
and then these operational data pipelines. Think of analytical as being data that doesn't actually

113
00:12:22,560 --> 00:12:26,960
get used in my product or in production in some way, but it's just something I've built for

114
00:12:26,960 --> 00:12:34,640
exploration or reporting or just like a one-off analysis, hey, I want to estimate what the

115
00:12:34,640 --> 00:12:41,600
sales forecast is going to be at the end of the year or something like that. And then the operational

116
00:12:41,600 --> 00:12:46,160
pipelines are things that run every day or potentially real time, they're using the product,

117
00:12:46,160 --> 00:12:52,000
they're productionized, they have SLAs, you want to be on call for them. And so

118
00:12:52,000 --> 00:13:02,400
another kind of pattern we're starting to see in organizations is that beyond, they recognize

119
00:13:02,400 --> 00:13:06,640
that individual data scientists need to be able to get stuff in production on their own.

120
00:13:07,360 --> 00:13:14,880
But as what they have built becomes useful to beyond just their single use case,

121
00:13:15,360 --> 00:13:19,840
there tends to be these kind of central, most a lot of companies have these ML platform teams

122
00:13:19,840 --> 00:13:25,760
and the ML platform teams often dedicate some resources to like managing the core feature pipelines

123
00:13:25,760 --> 00:13:34,000
for the company. So rather than just having data scientists now have to worry about owning this

124
00:13:34,000 --> 00:13:38,880
feature that other people will consume and then they'll have all these extra expectations of them,

125
00:13:39,680 --> 00:13:47,600
a central kind of like feature team as a sub team of the ML platform team is a common pattern

126
00:13:47,600 --> 00:13:52,000
we're beginning to see. And they'll kind of take over the most use and the highest value features

127
00:13:52,000 --> 00:13:57,360
to guarantee their correctness, et cetera. And that's actually the pattern we use in the Michael

128
00:13:57,360 --> 00:14:04,320
Angelo team as well. Now you're talking about a level of rigor and sophistication that's

129
00:14:04,320 --> 00:14:12,080
you know fairly common in the kind of large Silicon Valley companies, but for traditional enterprises

130
00:14:12,080 --> 00:14:18,240
is certainly starting to see more and more platform teams forming,

131
00:14:19,040 --> 00:14:24,000
but it's not nearly as common in my experience. I'm curious if that's your experience as well.

132
00:14:24,000 --> 00:14:30,640
And if you can kind of maybe compare and contrast what you're seeing in traditional enterprises,

133
00:14:31,840 --> 00:14:38,720
both with regard to feature stores, but more broadly kind of their journey to operationalizing

134
00:14:38,720 --> 00:14:46,320
machine learning. Yeah, I mean, it really depends on the company, but there's a lot of companies

135
00:14:46,320 --> 00:14:51,280
who are being told, hey, we need to we need to figure out ML. We need to kind of that's

136
00:14:51,280 --> 00:14:56,720
core to our strategy. And they're spinning up an ML platform team and ML infrastructure team,

137
00:14:56,720 --> 00:15:04,560
or it could be kind of like an advanced analytics infrastructure group. And it's hard, you know,

138
00:15:04,560 --> 00:15:10,800
often it's hard to find people who the people who like know know this stuff well, or it's hard

139
00:15:10,800 --> 00:15:15,600
to like learn this stuff in the first place. And a big challenge that a lot of these companies

140
00:15:15,600 --> 00:15:22,080
have is that they're still not kind of at like data maturity. So then building like ML maturity

141
00:15:22,080 --> 00:15:29,840
on top of that is a tricky spot to be probably the biggest kind of elements. And technically,

142
00:15:29,840 --> 00:15:34,320
that's the challenge is you have to be in a pretty good spot with your data infrastructure.

143
00:15:34,320 --> 00:15:40,240
First and a lot of these companies, you know, they're trying to hop on the AI, the machine learning

144
00:15:40,240 --> 00:15:47,280
wave while they're still mid migration to cloud, or they have a ton of data silos, or they're

145
00:15:47,280 --> 00:15:52,000
they have they're trying to figure out how to adopt streaming data at the same time, but they want

146
00:15:52,000 --> 00:15:56,720
to build machine learning using streaming data. So kind of like that core infrastructure and the

147
00:15:56,720 --> 00:16:05,600
core data is something that I would say is like one of the top priorities to focus on and really

148
00:16:05,600 --> 00:16:11,120
work on as you're building out the ML platform team. But then also kind of on top of that,

149
00:16:11,120 --> 00:16:17,200
you want to build ML ops processes. And it's a super fragmented space right now. And I think it'll

150
00:16:17,200 --> 00:16:21,840
stay like that for a while. The ML ops, all the different tools that can fit in the ML ops pipelines.

151
00:16:21,840 --> 00:16:26,880
But that's stuff you can figure it out and get started with. There's a lot of good options out

152
00:16:26,880 --> 00:16:31,920
there and you know, just goes start using cube flow. A lot of teams can just pull that in and get

153
00:16:31,920 --> 00:16:37,680
going. But a specific challenge that teams face there is kind of the boundary between that

154
00:16:37,680 --> 00:16:45,120
infrastructure data and and the kind of ML ops tooling. And we see a lot of kind of,

155
00:16:45,120 --> 00:16:51,760
for example, example, like see a lot of auto ML systems that do really nice demos where

156
00:16:52,400 --> 00:16:57,920
you know, they'll say, okay, let me just drag in this training data dot CSV into my auto ML

157
00:16:57,920 --> 00:17:01,920
system. And then, you know, I have this amazing model now and it's productionized. But it's like,

158
00:17:01,920 --> 00:17:05,840
where did that training data dot CSV come from? That's actually the whole hard part here.

159
00:17:05,840 --> 00:17:11,280
And then how do I use that in production? And so, you know, practically like I want to

160
00:17:11,280 --> 00:17:16,560
calculate a feature on a stream. I want to share share something with my colleague. A lot of

161
00:17:16,560 --> 00:17:21,760
these elements are challenging. And and I think like getting started with the infrastructure.

162
00:17:21,760 --> 00:17:26,560
And then some of the just like core ML ops frameworks like cube flow is a great option. It's just

163
00:17:26,560 --> 00:17:37,840
a great way to get started. You know, kind of digging into the feature store and and you know,

164
00:17:37,840 --> 00:17:46,160
kind of what it really means technically. Yeah, I'm curious your sense for, you know,

165
00:17:46,160 --> 00:17:55,280
what are the kind of core components or or capabilities. I think at the highest level,

166
00:17:55,280 --> 00:18:00,080
like you can kind of group it into online and offline. And you know, those have different

167
00:18:00,880 --> 00:18:06,000
requirements. But I've, you know, refer, I think we actually talked about this at one point.

168
00:18:06,000 --> 00:18:12,320
Like, you know, there's, you know, different, you know, feature stores will do like automatic

169
00:18:12,320 --> 00:18:17,440
backfilling and, you know, have all different kinds of abilities. I'm curious what you,

170
00:18:18,720 --> 00:18:22,400
you know, and maybe the way to lay it out is in terms of, you know, what do you need when

171
00:18:22,400 --> 00:18:27,840
you're just getting started? And, you know, gives you kind of the, you know, 60% of the bang for

172
00:18:27,840 --> 00:18:38,320
your buck or your 80% and what are the capabilities that more mature teams tend to look for or need to

173
00:18:38,320 --> 00:18:47,520
build? Yeah, it's, it's very interesting because the space of needs is really large. So different

174
00:18:47,520 --> 00:18:54,800
teams need totally different things. And, and it really comes down to kind of what are their data

175
00:18:54,800 --> 00:19:01,280
needs for their models and the ML things that they're trying to build. So if you're a company where

176
00:19:01,280 --> 00:19:11,200
you have, you, if you're a company that is only doing kind of batch analyses, there's no real time

177
00:19:11,200 --> 00:19:15,680
component to your, to your company. There's no interaction, live interactions with the customer.

178
00:19:16,480 --> 00:19:23,600
The concept of a batch, batch feature stores, probably sufficient. And that's, it's not so much

179
00:19:23,600 --> 00:19:30,400
different from what you would get from a standard data warehouse and some kind of typical data

180
00:19:30,400 --> 00:19:36,800
pipeline and tools where things start to get more complicated is when you have, you really have

181
00:19:36,800 --> 00:19:44,000
this operational environment, this production environment on top of the analytic environment

182
00:19:44,000 --> 00:19:49,600
or as alongside it. And then you have to manage your machine learning development process

183
00:19:49,600 --> 00:19:55,360
in such a way that it interacts with that it plays well with the operational or the production

184
00:19:55,360 --> 00:20:02,640
environment. And so a feature store kind of, what is it? It's a data system built for supporting

185
00:20:04,480 --> 00:20:10,480
ML ops workflows. And so it operates the data pipelines that generate feature values,

186
00:20:11,040 --> 00:20:18,000
it persists and manages the feature data itself. And then it serves this feature data consistently

187
00:20:18,000 --> 00:20:26,800
across production, you know, online and development offline workflows. And so we think of it kind

188
00:20:26,800 --> 00:20:34,880
of as like a central hub for feature data and the metadata that is used across ML models,

189
00:20:34,880 --> 00:20:40,480
lifecycle and especially for sharing and crossing organization. So some specific things, you know,

190
00:20:40,480 --> 00:20:50,160
you mentioned, you mentioned that kind of backfilling. So, you know, feature stores are unique in

191
00:20:50,160 --> 00:20:58,720
that they map across the development environment and the production environment. And so when they

192
00:20:58,720 --> 00:21:04,880
have some special capabilities to allow when you add a new feature to automatically backfilling

193
00:21:04,880 --> 00:21:09,920
and calculate historical values of a feature. So when you're training a model on all

194
00:21:09,920 --> 00:21:15,920
logins on the past six months or all purchases in the last year or something like that,

195
00:21:16,480 --> 00:21:21,360
you don't have to wait another year for a feature to be calculated, right? You don't have to

196
00:21:21,360 --> 00:21:26,720
log that feature for a year. You can generate, you can continually register new features and have

197
00:21:27,440 --> 00:21:34,400
all of that training data be instantly available. And so that's a pretty big component

198
00:21:34,400 --> 00:21:38,960
of feature stores. But we break down the capabilities of a feature stores roughly into five

199
00:21:38,960 --> 00:21:44,560
components, right? A transformation layer, which takes your raw data and generates feature

200
00:21:44,560 --> 00:21:50,720
dollars, a storage layer. So that's kind of like feature store, the storage layer, which

201
00:21:51,680 --> 00:21:58,160
organizes those feature values and persists them for use, for retrieval online and offline.

202
00:21:59,200 --> 00:22:05,040
And then a serving layer that serves them online. So for real time serving less than

203
00:22:05,040 --> 00:22:15,760
so like low latency serving, monitored, etc. And to and to also power training data set feature

204
00:22:15,760 --> 00:22:21,920
retrieval to build a model to generate a training data set. So kind of a unified retrieval interface

205
00:22:21,920 --> 00:22:27,760
across the serving, across online and offline. So those are kind of the three main components that

206
00:22:27,760 --> 00:22:34,080
touch the data. And then a central registry that defines all of these features and contains

207
00:22:34,080 --> 00:22:38,160
that data and metadata, which is kind of like an immutable record of what was what was I using

208
00:22:38,160 --> 00:22:43,600
in production? What was available analytically at this time or that time? And a monitoring layer to

209
00:22:44,880 --> 00:22:50,160
ensure the correctness of features and the operational, you know, track the operational metrics of all

210
00:22:50,160 --> 00:22:58,640
of the data pipelines that are powering my model in production. Now a lot of the elements that you

211
00:22:58,640 --> 00:23:05,680
talked about have kind of traditional analogs within the enterprise data ecosystem. Data catalogs

212
00:23:05,680 --> 00:23:12,800
have gotten more popular. You know, certainly there's data warehouses, you know, snowflake,

213
00:23:12,800 --> 00:23:17,520
IPO, make sure that we all know about data warehouses, although that's been part of the enterprise

214
00:23:17,520 --> 00:23:24,720
data landscape for a very long time. But there's, you know, all of these kind of independent

215
00:23:24,720 --> 00:23:35,920
tools that have played a role in helping enterprises do similar kinds of things. Is it, is it, you know,

216
00:23:35,920 --> 00:23:41,680
easy to kind of put a finger on the difference between, you know, those standalone components

217
00:23:41,680 --> 00:23:48,000
and a feature store or are you maybe even seeing organizations, you know, take their existing databases

218
00:23:48,000 --> 00:23:55,200
and data warehouses and data catalogs and kind of build a feature store out of those things. Yeah,

219
00:23:55,200 --> 00:24:01,120
so those components make up, those components are reused by a feature store. So feature store

220
00:24:01,120 --> 00:24:08,880
really coordinates across, like across a common orchestration data transformation orchestration

221
00:24:08,880 --> 00:24:16,240
system or a warehouse for storage or a data lake for storage. And we don't reuse anything,

222
00:24:16,240 --> 00:24:21,920
we've run our own kind of serving layer. But the goal, it's kind of important to recognize that

223
00:24:22,480 --> 00:24:29,200
the goal of the feature store is to provide really, really good access to data in the ways that

224
00:24:29,200 --> 00:24:34,480
ML ops workflows need that data. It's not to replace existing data infrastructure. So it's actually

225
00:24:34,480 --> 00:24:41,120
quite important for the feature store to plug in and integrate quite nicely with what data

226
00:24:41,120 --> 00:24:47,440
infrastructure, a team company already has today that they're happy with. And, you know,

227
00:24:47,440 --> 00:24:53,280
this kind of goes back to actually like a lesson that I learned, I learned building out

228
00:24:53,280 --> 00:24:58,240
Michelangelo, you know, we would go to, we'd, we'd built Michelangelo, we would go talk to

229
00:24:58,240 --> 00:25:03,280
different teams internally, hey, you guys are building this kind of model. Can Michelangelo help

230
00:25:03,280 --> 00:25:09,680
your team out? And it was never the case that a team would say, hey, I want to migrate this

231
00:25:09,680 --> 00:25:14,800
existing thing that's working for me onto this other system that you're coming and telling me about.

232
00:25:14,800 --> 00:25:21,360
It was always, hey, we have some pain points and maybe we can build V2 of what we're building

233
00:25:21,360 --> 00:25:26,720
on your new system because that system solves all of these additional pain points and makes use

234
00:25:26,720 --> 00:25:32,800
of what is already working. And so this concept of being gradually adoptable and reusing as much

235
00:25:32,800 --> 00:25:39,520
of the company's existing data infrastructure such that there's as little duplication as possible,

236
00:25:39,520 --> 00:25:44,960
was quite important for a feature store. I think the biggest distinction though is the concept of

237
00:25:44,960 --> 00:25:50,160
now we're talking about operational environment as well. And so that's the big shift that a

238
00:25:50,160 --> 00:25:55,280
feature store also has to take into account. It's, it's, there's this concept of a catalog of

239
00:25:55,280 --> 00:26:01,760
operationally available, vetted, productionized signals features for use in models.

240
00:26:03,440 --> 00:26:10,640
And on the note of kind of this evolution, what does it typically look like to

241
00:26:12,400 --> 00:26:19,840
deploy one of these? So that conversation that you had with team at Uber, I imagine you're having

242
00:26:19,840 --> 00:26:25,520
various versions of that conversation with teams today. And what are you telling them? It looks

243
00:26:25,520 --> 00:26:33,760
like to eventually kind of make their way to, you know, dynamic, always available feature store

244
00:26:33,760 --> 00:26:43,920
in Irvana. Yeah, there's, so a tech con we have a couple of deployment models. And one of, so

245
00:26:43,920 --> 00:26:53,280
they range from a fully hosted cloud service to a, a managed cloud service that lives actually

246
00:26:53,280 --> 00:27:02,640
in your cloud account. So tech con is completely cloud based. And the, the distinction between

247
00:27:02,640 --> 00:27:09,760
those deployment models that I just mentioned is that in one, it's a little bit more similar to

248
00:27:09,760 --> 00:27:16,080
a snowflake model where tech con manages the whole tech con cluster, the whole feature store,

249
00:27:16,080 --> 00:27:21,840
we manage all the SLAs for it. You pass your data into it, it's storing the features and it

250
00:27:21,840 --> 00:27:27,520
will serve features to you. And so your data comes into tech con's account and we, and we manage the

251
00:27:27,520 --> 00:27:32,480
whole thing end to end. You don't need to have any engineers do anything internally to kind of

252
00:27:32,480 --> 00:27:41,200
maintain or support the tech on deployment. There's a separate deployment model, which is preferred

253
00:27:41,200 --> 00:27:47,760
by some organizations, which actually has tech on run in there, Amazon account, but still have

254
00:27:47,760 --> 00:27:54,720
our team manage that software. And this is becoming a more and more common deployment model for

255
00:27:54,720 --> 00:28:01,840
enterprise data infrastructure assets. It's, it's really, you know, have, have a company from the,

256
00:28:01,840 --> 00:28:09,440
from the outside, have their control plan talk into connect to a data plan that lives within the

257
00:28:09,440 --> 00:28:17,760
customers, AWS account or whatever it is. And within that, that there's a VPC where all that

258
00:28:17,760 --> 00:28:25,440
software runs and talks to the data sources internal to the customers account processes that data

259
00:28:25,440 --> 00:28:30,000
and serves that data all within the customers account. So their data never leaves their own account.

260
00:28:30,000 --> 00:28:34,960
And so you can imagine there's some larger enterprises that prefer deployment models like that.

261
00:28:37,600 --> 00:28:43,600
And maybe let's talk a little bit about what you're seeing in terms of the, you know, for folks that

262
00:28:43,600 --> 00:28:53,040
decide to go this route, what does the ecosystem look like? You've got some open source out there,

263
00:28:53,040 --> 00:29:02,000
particularly in the Kubernetes community in Feast. There are kind of rumblings that, you know,

264
00:29:02,000 --> 00:29:08,000
some of the cloud providers will incorporate feature store capabilities into their offerings.

265
00:29:08,000 --> 00:29:16,960
You know, what else are you seeing out there and what, you know, your, your offering is

266
00:29:17,680 --> 00:29:24,480
cloud-based. Does that, you know, does that disadvantage you when the cloud vendors decide that

267
00:29:24,480 --> 00:29:29,520
they want to offer this as a, you know, feature store as a feature? I mean, it's going to be a

268
00:29:29,520 --> 00:29:35,680
battle, but, you know, it's definitely not worried that they're going to build a better product or

269
00:29:35,680 --> 00:29:42,400
better feature store than we will. The, you know, the space right now, there's a handful of

270
00:29:43,200 --> 00:29:50,800
systems called feature stores, the most notable beyond. So we kind of coined the term feature store

271
00:29:50,800 --> 00:29:56,080
a couple of years ago when we published a blog post at Uber about Michelangelo and we talked a

272
00:29:56,080 --> 00:30:02,640
lot about this notion of a feature store. There's a couple of different projects that have come out

273
00:30:02,640 --> 00:30:08,400
and a number of kind of talks at conferences where different companies have, have talked about,

274
00:30:08,400 --> 00:30:12,560
hey, this is how we implemented a feature store internally. One of the most notable is,

275
00:30:14,240 --> 00:30:23,120
is Gojack on G, on GCP, they open sourced pretty lightweight, but very powerful feature store

276
00:30:23,120 --> 00:30:26,800
that is quite good and people should check it out. It's really easy to get started with that.

277
00:30:26,800 --> 00:30:34,320
That is based on Google right now. I'm sure it's going to be in other clouds quite soon as well.

278
00:30:34,320 --> 00:30:41,840
And then TechCon offering is more of like an enterprise-based offering. So, you know,

279
00:30:41,840 --> 00:30:50,960
with SLAs, hosting, you know, being on call all of the enterprise capabilities. And I think we're

280
00:30:50,960 --> 00:30:57,280
going to see the cloud providers and the big data companies come in this space quite strong.

281
00:30:57,280 --> 00:31:02,720
I believe that 2021 is going to be the year of the feature store. I can't tell you how many

282
00:31:02,720 --> 00:31:08,480
companies come to us asking for a feature store without, you know, having a great understanding,

283
00:31:08,480 --> 00:31:14,080
like originally about what a feature store is, what problems directly it solves for them,

284
00:31:14,080 --> 00:31:20,240
because they have a variety of problems and they know just, hey, I have so many data problems.

285
00:31:20,240 --> 00:31:23,920
How can the feature store help me out? And we have a lot of those discussions and just to help

286
00:31:23,920 --> 00:31:34,720
them get started in this space. Yeah, it's been an interesting evolution of the MLOB space

287
00:31:35,600 --> 00:31:42,480
in general. You know, just in doing this interview and kind of reflecting on the fact that this

288
00:31:42,480 --> 00:31:51,040
was two and a half years ago that we were talking about feature stores. The first wave of products

289
00:31:51,040 --> 00:31:54,880
in the space, and it's more nuanced in this, but a lot of them were kind of these workflow

290
00:31:54,880 --> 00:31:59,600
end to end. We're going to try to slurp up your entire process and automate it.

291
00:32:02,160 --> 00:32:10,560
And yet, when in my conversations with folks that were, you know, building and running these

292
00:32:10,560 --> 00:32:17,600
systems, you know, at Facebook and Google and Airbnb and others, one of the most important

293
00:32:17,600 --> 00:32:21,920
elements of what they're doing was this, you know, this feature store. Airbnb has Zipline,

294
00:32:21,920 --> 00:32:27,360
which is, you know, their kind of central repository. And I forget what it was called in Facebook,

295
00:32:27,360 --> 00:32:35,520
but they had theirs and Google had theirs. And yet, it's taken quite a while before, you know,

296
00:32:35,520 --> 00:32:43,680
you have started to see kind of commercial offerings in the space. Your company's relatively

297
00:32:43,680 --> 00:32:51,920
new in terms of go-to-market. And yet, it seems like I read 2021 is going to be this year where,

298
00:32:51,920 --> 00:32:56,400
you know, we're starting to see a lot more activity. And I'm curious to your take on why that is.

299
00:32:57,360 --> 00:33:00,400
Yeah, I think it's interesting because you think of machine marketing.

300
00:33:00,400 --> 00:33:05,200
It's going to be great for you. Like, you have this market that you know that you know is important

301
00:33:05,200 --> 00:33:10,640
and no one seems to be in it for a really long time, or I should say few seem to be in it because

302
00:33:10,640 --> 00:33:18,160
there are, you know, some folks, but a lot of what I've seen thus far has been folks taking, you

303
00:33:18,160 --> 00:33:22,560
know, older technologies or technologies that weren't necessarily purpose-built and trying to

304
00:33:22,560 --> 00:33:30,480
apply them to solving this problem as opposed to taking a purpose-built feature store approach.

305
00:33:30,480 --> 00:33:36,800
Yeah, I think part of the trickiness here in one factor is just when you think of machine learning,

306
00:33:36,800 --> 00:33:42,800
you think of models, and you think of, you know, when people get started, what's the sexiest thing

307
00:33:42,800 --> 00:33:47,280
to work on? I want to get started on these cool models. And, you know, some people just jump straight

308
00:33:47,280 --> 00:33:52,720
to deep learning, which you know, I'm sure you've had a ton of people on the podcast say the way

309
00:33:52,720 --> 00:33:57,120
to do it is actually start as simple as possible with the simplest algorithm and then you get more

310
00:33:57,120 --> 00:34:04,880
complicated after that, right? And so what we see is the teams, there's just kind of like this

311
00:34:04,880 --> 00:34:14,400
anti-pattern in industry where teams kind of get started with kind of focusing on stuff that's

312
00:34:14,400 --> 00:34:22,000
slightly more advanced in what their needs actually are. And they kind of over-invest in some of the

313
00:34:22,000 --> 00:34:30,000
model stuff at first, which ends up being actually operationally easier to manage than the

314
00:34:30,000 --> 00:34:38,800
data pipelines that power these models. And so the teams that come to us, or they kind of say,

315
00:34:38,800 --> 00:34:42,080
hey, we actually thought we could repurpose a lot of our existing data infrastructure,

316
00:34:42,080 --> 00:34:46,560
just like plug it in directly to the models. But what actually happened was that's now where we're

317
00:34:46,560 --> 00:34:51,680
having a ton of pain, a ton of friction. And that's the core thing that's grinding the innovation

318
00:34:51,680 --> 00:34:58,560
from our data science teams to a halt. So, you know, we see a feature store to help us out there,

319
00:34:58,560 --> 00:35:01,840
but we already have this investment in this model stuff and we probably should have

320
00:35:02,960 --> 00:35:09,920
done it the other order or kind of done those in parallel. And so it's not a super obvious,

321
00:35:09,920 --> 00:35:15,760
there's all these kind of roadblocks and challenges you face that are not super obvious up front.

322
00:35:16,720 --> 00:35:20,240
But when you hit them, it kind of just grinds things to a halt.

323
00:35:26,560 --> 00:35:29,120
I had a follow-on question to that.

324
00:35:29,120 --> 00:35:41,760
You know, one of the things that we have that I think we see that is like actually quite challenging

325
00:35:41,760 --> 00:35:48,640
for people to kind of makes, it really makes it obvious what some of the data challenges are when

326
00:35:48,640 --> 00:35:55,200
putting machine learning into production is that there's kind of just a variety of elements,

327
00:35:55,200 --> 00:36:00,400
you know, the development and production environments are not the same. So you kind of have to map

328
00:36:00,400 --> 00:36:06,080
between those. And then we see teams that have kind of constraints from what can be done in

329
00:36:06,080 --> 00:36:10,960
production that affect what the data scientists are even allowed to experiment with. And that

330
00:36:10,960 --> 00:36:15,520
really kind of just like constraints, you know, what they're able to do. Deploying these systems

331
00:36:15,520 --> 00:36:22,320
is really complex as well. And even just like monitoring and validation of these systems,

332
00:36:22,320 --> 00:36:26,480
not a solve problem. So when things break in machine learning, it tends to be kind of the data

333
00:36:26,480 --> 00:36:32,480
pipelines that break and investing in. And so these problems are super hard to debug also.

334
00:36:32,480 --> 00:36:37,760
So it kind of investing in that layer ends up going paying off in a big way when you're really

335
00:36:37,760 --> 00:36:44,240
trying to depend a core business process on these systems. And the question that I was looking for

336
00:36:44,240 --> 00:36:54,560
earlier was right along those lines, do you you mentioned platform teams earlier as folks that

337
00:36:54,560 --> 00:37:05,840
are kind of owning these production feature pipelines. Is that the primary person that is that

338
00:37:05,840 --> 00:37:10,880
you see kind of leading the the feature store charge or does it does it ever come from data

339
00:37:10,880 --> 00:37:18,640
engineering and the data infrastructure side of the house or good question. So the so there's

340
00:37:18,640 --> 00:37:23,360
a couple of things like why do people adopt feature stores in the first place. And so it kind of

341
00:37:23,360 --> 00:37:29,040
comes. There's kind of two paths. There's teams who are just trying to get this one model,

342
00:37:29,040 --> 00:37:34,080
you know, they have this important use case where this fraud system and we need to be able to

343
00:37:34,080 --> 00:37:39,120
calculate features in real time and use our historical features. And it's just like a crazy

344
00:37:39,120 --> 00:37:43,440
engineering problem for us and we just want a system that can handle that for us. So that's that

345
00:37:43,440 --> 00:37:50,400
kind of component. Another path for people who are adopting feature stores is when they are

346
00:37:50,400 --> 00:37:55,200
trying to build out their ML infrastructure properly and they're doing their research and they

347
00:37:55,200 --> 00:38:00,640
identify, you know, I was going to conversation with a big bank the other day and they're showing

348
00:38:00,640 --> 00:38:05,760
their stack and right in the center they're kind of ideal stack and there's kind of data infrastructure

349
00:38:05,760 --> 00:38:10,080
feature store feature catalog right in the center and then some of the modeling elements

350
00:38:10,080 --> 00:38:14,160
and the application elements on top. So they're just trying to take a very thoughtful approach to

351
00:38:14,160 --> 00:38:19,840
building the right infrastructure and the right tooling. What we want to enable the goal is to

352
00:38:19,840 --> 00:38:27,680
enable data scientists or analysts who ever are building these features to be able to to go

353
00:38:27,680 --> 00:38:32,640
end to end and get their models all the way in production without requiring without throwing

354
00:38:32,640 --> 00:38:37,840
things over the wall to the engineering teams for every single change that they have. You shouldn't

355
00:38:37,840 --> 00:38:43,920
need production or data engineers really have to know or be involved in any way when a data scientist

356
00:38:43,920 --> 00:38:49,600
is making a change to their model and production. When that happens, we've seen a real kind of shift

357
00:38:49,600 --> 00:38:57,760
in almost like the almost like the roles it kind of makes data scientists much more owners of their

358
00:38:57,760 --> 00:39:02,800
work in production rather than rather than being in a position where yeah I handed it off to that

359
00:39:02,800 --> 00:39:08,160
team and they're handling it. I don't know why it's not working right now and so that has been

360
00:39:08,160 --> 00:39:13,840
like a really big cultural shift in teams that have adopted this kind of adopted this technology

361
00:39:13,840 --> 00:39:19,840
that allows data scientists to kind of get stuff into production on their own. So we like to kind

362
00:39:19,840 --> 00:39:24,320
of have the people who build the systems be the owners of those systems and then there's just

363
00:39:24,320 --> 00:39:30,000
instances where you you have so many people who depend on these systems that you might want to

364
00:39:30,000 --> 00:39:35,120
centralize some components of that ownership. Is it now like us to the transformation has been

365
00:39:35,120 --> 00:39:40,480
happening over the past 10 years or so with traditional software engineering and DevOps and

366
00:39:40,480 --> 00:39:47,600
having these pizza box teams that you know exactly like cycle of their services. Exactly and

367
00:39:47,600 --> 00:39:55,200
yeah and people you know sometimes company will ask okay what's the the right operational ml stack

368
00:39:55,680 --> 00:40:00,880
and you know I don't think the space of needs is so so large I don't think there is one and

369
00:40:01,920 --> 00:40:06,880
to me it's kind of like what's the right software stack period in question mark right and it's

370
00:40:06,880 --> 00:40:13,760
just like you know it depends and the answer is always it depends and so you know I kind of like

371
00:40:13,760 --> 00:40:20,560
give guidance to companies or when you're trying to figure out what the right approach is talk to

372
00:40:20,560 --> 00:40:24,800
someone who's done it before and they can kind of walk you through a lot of the challenges that

373
00:40:24,800 --> 00:40:31,040
you're likely to encounter there's a lot of a lot of bottlenecks that you will hit when you have

374
00:40:31,680 --> 00:40:36,240
you know data scientists and engineers starting to collaborate for the first time or when you're

375
00:40:36,240 --> 00:40:40,560
trying to buy some software that you've never had to buy before you don't have an owner for the

376
00:40:40,560 --> 00:40:47,840
software there's just like a number of elements that come to cause a lot of challenges without

377
00:40:47,840 --> 00:40:52,080
being kind of thoughtful about things ahead of time and on the data side we think obviously we

378
00:40:52,080 --> 00:40:58,800
think feature stores are like the right way to kind of unlock a lot of the core ability to put

379
00:40:58,800 --> 00:41:05,200
models in production features in production and so that's kind of the key reason why we got started

380
00:41:05,200 --> 00:41:12,400
with the feature store yeah yeah I mean there's an interesting paradox in there where you know earlier

381
00:41:12,400 --> 00:41:19,520
you were alluding to folks that were choosing more complex technology than they needed for the

382
00:41:19,520 --> 00:41:23,520
thing that they were doing the thought in my head as you were saying that was yeah I need to deploy

383
00:41:24,400 --> 00:41:31,920
you know you know single you know team internal web app I need Kubernetes right and you know at

384
00:41:31,920 --> 00:41:38,720
the same time your advice is talk to folks who have kind of gone down the road and

385
00:41:40,160 --> 00:41:49,760
consider things that you're likely to run into as you're making your plans and and you know

386
00:41:49,760 --> 00:41:55,920
that in many cases is what you know leads folks to kind of overbuild right there kind of thinking

387
00:41:55,920 --> 00:42:01,360
far into the future at least that's an optimistic you know view rather than kind of playing with

388
00:42:01,360 --> 00:42:06,080
cool what actually mean like talk to someone who knows what they're doing who can tell you hey don't

389
00:42:06,080 --> 00:42:10,480
overbuild someone who can someone who can say you probably shouldn't be investing in that because

390
00:42:10,480 --> 00:42:15,840
you don't even have you don't even have your data in the right place or I know where I'm where

391
00:42:15,840 --> 00:42:22,400
I'm the question and I'm trying to get to is like you know how does someone know if they should

392
00:42:22,400 --> 00:42:29,040
even be thinking about a feature store at all or if it's you know a step or or or five ahead of

393
00:42:29,040 --> 00:42:34,880
them and it sounds like the first question is you know do you have your data house in order you know

394
00:42:34,880 --> 00:42:42,160
if you don't worry about that first right yeah I think the core kind of like the two biggest

395
00:42:42,160 --> 00:42:49,680
things are are you building models that need to interact in real time so are do you have some online

396
00:42:49,680 --> 00:42:54,320
component to your machine learning application to your operational machine learning application

397
00:42:54,320 --> 00:42:59,680
that's when you that's just like a key like a pretty good indicator that okay I'm going to have

398
00:42:59,680 --> 00:43:03,760
I'm gonna have this production environment I'm gonna have to have a real time real time serving

399
00:43:03,760 --> 00:43:09,920
on this machine learning application very likely includes kind of an online data storage

400
00:43:09,920 --> 00:43:13,520
element for my features which I'm gonna have to manage and it's a data scientist probably haven't

401
00:43:13,520 --> 00:43:22,400
done that before so that's kind of one pretty important kind of path and then second is do we have

402
00:43:22,400 --> 00:43:29,440
do we have more than a handful of models and more than a handful of features powering those right

403
00:43:29,440 --> 00:43:36,080
uh especially if they're being shared across those models it it goes from I've seen teams kind of

404
00:43:36,080 --> 00:43:42,560
like manage their collaboration with you know a Google spreadsheet and they have a list of

405
00:43:42,560 --> 00:43:48,720
features that is okay this pipeline is here and this feature does this and just ask this person

406
00:43:48,720 --> 00:43:54,000
if you want to use it or if you want the code for it and uh and so I've talked to them and said

407
00:43:54,000 --> 00:43:59,280
hey this is working pretty well for us now and uh that's great when that works for you and then a

408
00:43:59,280 --> 00:44:04,400
month later they call me up and then they were like okay so now we're at uh you know a couple hundred

409
00:44:04,400 --> 00:44:08,640
rows of this thing and things are kind of going crazy and we need a better way to manage this so

410
00:44:08,640 --> 00:44:12,960
it's almost like when you get that scale and you need some kind of like you need to start thinking

411
00:44:12,960 --> 00:44:19,120
about collaboration between your team and you want to have some efficiencies of scale as well.

412
00:44:25,440 --> 00:44:31,120
Features you know one of the uh you you brought up uh kind of deep learning earlier in the

413
00:44:31,120 --> 00:44:37,600
conversation is kind of a side comment um you know deep learning is kind of notable for not being

414
00:44:37,600 --> 00:44:46,240
as dependent on features and feature engineering as traditional ML models um is a feature store still

415
00:44:46,240 --> 00:44:54,560
relevant in that world or no not as well. Yeah good question um so we see uh teams use feature

416
00:44:54,560 --> 00:45:02,560
stores in two ways for when they're doing deep learning. One is uh to to host pre-computed parts

417
00:45:02,560 --> 00:45:08,640
of uh their model you can think of it as like use a feature store to do my embeddings properly

418
00:45:08,640 --> 00:45:14,480
and uh and pre-computed my embeddings and then look them up in production so that's a really big

419
00:45:14,480 --> 00:45:18,800
element of a feature store is kind of like making that stuff operationally possible and really easy

420
00:45:20,560 --> 00:45:24,640
and then a second component is making sure the data is available so you know you may have a

421
00:45:24,640 --> 00:45:33,440
uh deep learning model that let's say it's a uh recommendation model and it does uh it needs

422
00:45:33,440 --> 00:45:40,480
some input from for example your current search query right that's one one input to the model

423
00:45:40,480 --> 00:45:46,960
and then some also some information about the user itself or users themselves and maybe some

424
00:45:46,960 --> 00:45:52,720
information about the current page or the current product that they're looking at that model needs

425
00:45:52,720 --> 00:45:59,120
to have access to all that information that historical information about the user item etc and

426
00:45:59,120 --> 00:46:04,400
it's really the feature store's responsibility to get that right information at the right time

427
00:46:04,400 --> 00:46:09,520
and deliver that information the those data uh to that model and they're effectively features

428
00:46:09,520 --> 00:46:14,320
at that point that we're passing into the model though they're typically less processed features

429
00:46:14,320 --> 00:46:19,360
than uh you might have in a non deep learning uh kind of model does that make sense you got

430
00:46:19,360 --> 00:46:23,760
you get what I'm saying where you know you bring that data up and make that available to the

431
00:46:23,760 --> 00:46:30,320
model and that's really um uh that's really kind of the role of the feature store for deep learning

432
00:46:30,320 --> 00:46:36,640
models typically yeah well what it made me think of is um you know presentations that I've seen

433
00:46:36,640 --> 00:46:41,840
from folks at like Google for example where they talk about one of the main issues that they see

434
00:46:41,840 --> 00:46:49,840
in production is um you know for any kind of model deep learning or otherwise is the feature data

435
00:46:49,840 --> 00:46:57,040
just changing in semantic or being semantics or being missing or um you know before you

436
00:46:57,680 --> 00:47:02,720
you know had you know something as nulls and then you change it to empties or whatever it's just

437
00:47:02,720 --> 00:47:10,160
random things that that happen in a pipeline that no one sees and it's um it sounds like what you're

438
00:47:10,160 --> 00:47:18,080
saying is that people use the feature store to kind of manage uh that uh that infrastructure that

439
00:47:18,080 --> 00:47:24,560
that process and and specifically the the data part yeah having a common way to reference like

440
00:47:24,560 --> 00:47:29,280
a common way to literally specify what data does this model need what data does it need in

441
00:47:29,280 --> 00:47:35,680
production yeah I'm making a prediction for this user and this item how do I know which data to

442
00:47:35,680 --> 00:47:40,320
pass into the model for that purpose for this this data for this user and this data for this item for

443
00:47:40,320 --> 00:47:47,200
example um but then all of that data that does you know we do use for that model you know we think

444
00:47:47,200 --> 00:47:51,920
of it as kind of making it like operationally ready for for machine learning consumption for your

445
00:47:51,920 --> 00:47:58,400
actual ML application where there's a bunch of things you want to do uh in terms of like validating

446
00:47:58,400 --> 00:48:03,760
that data monitoring it for drift when we talk about monitoring it for drift it's like monitoring

447
00:48:03,760 --> 00:48:07,680
it compared to you know how the data looks today compared to how it looked last week and make

448
00:48:07,680 --> 00:48:13,120
sure the data doesn't look completely different but also does this data look similar to the data

449
00:48:13,120 --> 00:48:18,000
that the model was trained on in the first place and you know is there are there any indications that

450
00:48:18,000 --> 00:48:24,320
this model is um starting starting to get a completely different data than it expects in which case

451
00:48:24,320 --> 00:48:29,360
we don't really have any guarantees about its behavior and it's you can't really expect non

452
00:48:29,360 --> 00:48:38,240
erratic behavior from a model in in that situation mm-hmm awesome awesome uh well great stuff here

453
00:48:38,240 --> 00:48:44,720
any uh kind of parting thoughts or you know for folks that want to dig in deeper to this where they

454
00:48:44,720 --> 00:48:51,680
should look or um words of wisdom being uh a couple of years into this journey well or more than

455
00:48:51,680 --> 00:48:56,640
a couple years into this journey yeah i would say i would say start simple and um yeah for

456
00:48:56,640 --> 00:49:02,560
your interest in learning more about feature stores um or getting started with them uh come to

457
00:49:02,560 --> 00:49:08,480
tecton.ai and uh and just leave us you know get in touch and uh and we can chat and see how we can

458
00:49:08,480 --> 00:49:15,680
help awesome well mike uh wonderful to catch up with you and yeah i want to see all the cool things

459
00:49:15,680 --> 00:49:33,600
you guys are up to yeah thanks a lot it's been fun awesome thank you

