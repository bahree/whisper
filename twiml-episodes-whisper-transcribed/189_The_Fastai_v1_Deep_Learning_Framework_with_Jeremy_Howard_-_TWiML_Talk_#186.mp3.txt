Hello and welcome to another episode of Twomble Talk, the podcast where I interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington.
For today's show, we'll be taking a break from our strategy data conference series coverage
and presenting a special conversation recorded yesterday with Jeremy Howard, founder and researcher
at fast.ai, accompanying many of our listeners are quite familiar with due to their popular
deep learning course.
The podcast is being released today in conjunction with the company's announcement of version
1 of their fast AI library at the inaugural PyTorch DevCon in San Francisco.
Jeremy and I cover a ton of ground in this conversation.
Of course, we dive into the new version of the library and explore why it's important
and what's changed.
We also explore the unique way in which it was developed and what it means for the future
of the fast.ai courses.
What's more, Jeremy shares a ton of great insights and lessons learned in this conversation,
not to mention a bunch of really interesting sounding papers.
I know you'll enjoy this one.
Alright, let's do it.
Alright everyone, I am on the line with Jeremy Howard.
Jeremy is founder and researcher with fast AI.
Jeremy, welcome to this week in machine learning and AI.
Thank you very much.
It is great to finally get you on the show.
As you know, the tool more community in particular, our meet up has really been enjoying the
deep learning for coders course.
We brought a group of folks through that course earlier this summer and spun up a second
group to work on that course.
And then you've recently announced the machine learning course and we've got a group starting
soon that will be working on that course together.
So we are big fans of fast AI.
The interview I did with Rachel, that was Twomble Talk 138 back in May, remains one of
the most popular ones shows to date.
So I am super excited.
So I'm the pleasure of all mine and let me just say thank you so much for everything
that you're doing for the machine learning and AI community and thanks so much for spending
time looking at our little course.
I'm really grateful.
It is a great course and we'll jump into all the reasons why I am sure.
But before we do that, I want to talk a little bit about your background.
So you've been former president and chief scientist at Kaggle.
You founded several startups in this space, your published researcher as well as on the
faculty at U.S.F. and you're unabashedly Ph.D.
Less.
That's true.
Unlike Rachel, who is facetly Ph.D. or something.
So I want to start out by talking about, I want to give you a chance to more fully walk
folks through your background, but also maybe end up at the Ph.D. I think has come to,
this is a space where the Ph.D. carries a lot of weight and I'm curious your thoughts
on kind of navigating the space and doing all that you've done without one and what it
says to other folks that want to participate in the space.
Yeah, I mean, I understand where the question is coming from Sam because it's definitely
always been intimidating and terrifying for me doing what I'm doing without an academic
background.
And I can't begin to tell you how deeply surprised I was when I discovered I was actually pretty
good at machine learning because I had, no, literally I had no idea, like you have to
realize I, I mean, sort of answer your question.
I started my career when I was 18 at a, at a strategy corporate strategy company called
McKinsey and Company, I got a degree in a Bachelor of Arts in Philosophy, but I didn't
turn up to any lectures because I was working full time, so I just turned up to exams.
So I really, even though in theory I have a degree, I haven't really studied anything
much in a formal way.
So I'm kind of very unfamiliar with the university system and the academic system overall.
And so I spent, you know, eight years in corporate strategy and then 10 years running a couple
of companies, which were somewhat related to machine learning, but one of them was an
email provider called FastMail, which is still pretty popular.
And you know, the machine learning I did there was like, you know, try to improve the spam
detector mainly.
And then the other one was an insurance pricing company called Optimal Sisions, which
was more about operations research and optimization and simulation than it was about predictive
modeling.
So at the end of all that, when I entered my first Kaggle competition, because I wanted
to like finally learn to do machine learning properly, and I won it, I was just like, that
can't be right, because I knew that it was an econometrics competition and there was
a lot of PhDs and professors and econometrics in the competition and I just thought, that's
really weird that some kind of self-taught hack, you know, business guy could possibly
beat these guys at predicting time series.
I just thought that was, yeah, deeply weird and surprising and very pleasing.
I mean, it was the start of a new career for me because when you find out you're good
at something, you kind of, you know, at least in my case, I went all in on trying to be as
good as I could be.
I didn't realize that your career at Kaggle began with competing in a competition.
Yeah.
So at that point, it was just Anthony Goldblum and he had, you know, hired a contractor
to kind of hack together a site based on his idea of creating a competition platform.
And yeah, I came across it because I went to the R meetup in Melbourne thinking that would
be a good way to learn to do machine learning properly and somebody there told me, oh, there's
a good way to learn machine learning would be to try one of these Kaggle competitions.
And so, yeah, so I did much to my surprise, you know, I won my first one and I think I also
won my second one and I got to the top of the leaderboard and so by the time the next
meetup came along, Anthony was actually at the meetup and somebody introduced me and
by that stage, he knew who I was because I was the highest ranked Kaggleer and I ended
up becoming the first investor in the company.
And then I rewrote the whole platform from scratch as a volunteer because it turned out
it wasn't really going to be scalable enough to do what was needed to be done.
And yeah, I ended up becoming an equal partner in the company.
So that was, yeah, that was a cool way to get involved.
Yeah, that's that's pretty amazing.
And people often kind of poo poo Kaggle competitions and they do with comments like, oh, it's
not really the real world, all the hard stuff is done for you.
I imagine you have a slightly different to the Kaggle competition.
So these are people who, these are people who have heard third hand and it's, yeah, what's
your take on that?
A lot of the exercises and the deep learning for coders course are, hey, just go find
a data set on Kaggle and do some stuff with it.
So you obviously believe pretty strongly in that as a way to learn.
Yeah, I do.
You know, that's a great question, actually, because you know, like with many of these
troubling myths, there's just enough of an element of truth in it to make it sound
believable, you know, which is like, obviously, there is a lot to building a data product
or solving a data-oriented problem that is not about creating a more predictive, predictive
model.
So yes, that's true.
But then, you know, taking that premise that the, therefore, competing in Kaggle competitions
as a waste of time is a totally ridiculous leap.
It's actually, if you want to do a good job of your data product, having a predictive
model that's good at predicting things is actually a pretty good, pretty important part
of that.
Furthermore, Bryman, who developed the Random Forest amongst other things, had this
fantastic two cultures of statistics paper in which he talked about how incredibly
powerful a good predictive model is is providing a platform for data interpretation for understanding
your data.
And that's one of the things that I spend a lot of time on on the new machine learning
course.
So if you're going to kick us on a Kaggle competition, you need to understand the data
really, really well.
And so if you're good at understanding data really, really well and building models that
are very predictive, and you also have to be really good at software engineering,
in a very practical way, because every idea you come up with, you have to be able to
code it in a way that actually works correctly and that's tested.
And then you need to make sure it's maintainable because you've got to patch lots and things
on top of each other over the three months of the competition.
So realistically, if you can get a good result on a Kaggle competition, you have exercised
many of the pieces necessary for machine learning in the real world.
The other pieces like productionising that model, that's a whole different skill, which
you can practice elsewhere, or skills like figuring out what problem to solve and what
constraints there are to solve that problem.
I mean, that's kind of more of a management consulting corporate strategy kind of issue,
which again, there are resources for that.
But yeah, for the part that is really about machine learning, Kaggle competitions are
a great exercise.
You made an interesting comment in there that winning a Kaggle competition and building
models in general is very much about really understanding the data.
And in the deep learning for coders, part one course, you kind of, my personal experience,
we kind of sail through the first three lessons that were focused on building object detectors
and things like that.
And then we got to this really interesting set of lessons around building, using machine
learning for more tabular data.
And the promise of that is that actually kind of the opposite of what you said, that
previously, in order to really work with traditional enterprise data, a data scientist really
had to be a domain expert and understand those domains and the data sources very deeply.
The impression a lot of us took from what we learned in applying deep learning to tabular
data is that we didn't have to be as deeply ingrained in that particular field because the
network would learn a lot of the patterns for us.
How do you reconcile those two perspectives?
Well, the first thing to note is there's a difference between getting a pretty good model
and winning a Kaggle competition.
So winning a Kaggle competition, you actually have to do everything better than everybody
else because if you don't, somebody else will do that thing better than you and will
beat you.
So you know, Kaggle, it's definitely true that Kaggle solutions, like the top 10 Kaggle
solutions are going to be very over engineered for practical purposes.
But what they show you is kind of the full menu of things which can improve your model
and you can kind of pull each one out one at a time to figure out how important each
piece is.
So doing some amount of feature engineering is almost always helpful and doing a lot is
going to be necessary to actually winning a competition.
Having said that, it's definitely true that deep learning allows us to do less feature
engineering and still get as good results as we might of with a GBM or a random forest
or something.
And there's been some interesting papers and talks from folks like Instacart and Pinterest
who have switched from GBM based methods in their companies.
So Pinterest switched from GBM to deep learning, for example, for their home page, you know,
kind of main home page recommendation feed.
And they've talked about how doing that made their engineering process less complex because
they didn't need to do as much feature engineering as they did before, the architecture kind
of did more for them.
So you generally, you know, with deep learning, you don't have to bucketize your continuous
variables, which some kinds of model require.
You don't have to create interactions, which some kinds of model require.
You don't have to do special tricks to allow it to extrapolate further, which you certainly
need for any tree based method.
So yeah, I think both of those things are true at the same time.
Yeah, certainly the course in our group created a number of fans of the whole technique of
entity embeddings.
Oh, yeah.
Yeah.
Yeah.
Very underappreciated.
I mean, the idea that you can use a mixture of categorical and continuous variables kind
of without thinking about it is great.
And you can use them for time series, you can use them for tabular, you can use them
for collaborative filtering, you can use them for text.
I mean, they pop up everywhere.
And actually, I'll be interested to see your feedback when you try it.
But the new Fast AI version one library makes that ridiculously easy.
Like now you can basically create a model with a mixture of categorical and continuous variables
in, you know, and train it in three or four lines of code, because we're really trying
to, yeah, make that that idea of entity embeddings be as natural to use as possible.
Well, I appreciate you helping us get to talking about the new library, which you're going
to be announcing tomorrow today for those who listen to the podcast the day it's released
because we're going to try and get this out tomorrow.
Let's talk about the library.
So Fast AI as a company is focused on research, it's focused on software, it's focused
on courses.
We talked a little bit about all of that with Rachel.
This is really about the software.
Yeah.
And this is the long term vision of what Fast.ai is doing.
And I'm a bit sloppy about this myself, but our company is Fast.ai and the software is
just Fast.ai.
So Fast.ai, you know, it's all about getting to a point where people can use deep lining
to help them do whatever it is they're doing really easily.
And to allow anybody to do that, we actually have to get to a point where you don't have
to use code at all because only something like 0.1% of the global population knows how
to code.
So kind of the Fast.ai library is step one along that path to kind of require less and less
code to be able to do more and more things, more and more reliably, more and more quickly.
Since you grounded us out on terminology, another area that's somewhat confusing is that
you're announcing what you call the V1 version one of the Fast.ai library, but it supersedes
a previous version of the library that was also written in PyTorch, which itself supersedes
a previous version of the library that was written in TensorFlow.
So when we talk about the V1 library, we're talking about the new thing.
Yeah.
So just to go back through that, so the previous thing was version 0.7.
And that never got a version one tag because I wrote it knowing that it was not going
to be that particularly close to the final form of what we wanted.
It was kind of something that I hacked together that was good enough for the needs of the
initial PyTorch-based courses, because as you won't know, PyTorch is really not suitable
on its own as a first library for deep learning because you have to write your own training
loop and you have to do a lot of things yourself, and it's an amazingly great library,
but it's kind of missing that carous style layer on top.
So we kind of built the amount we needed to get people going, but it was certainly not
a really carefully integrated, fully thought through library.
So here we are, 18 months later, we've rewritten the entire thing from scratch in a way which
is explicitly designed to provide a long-term foundation for all the software we built
for now on.
And then before that was something that was, yeah, a sad on top of carous and TensorFlow,
and I don't think we ever even called that a library or gave it a name.
It was only a kind of bunch of little utilities that's sad on top of carous, to smooth over
some of the slightly rough edges.
So yeah, that's been kind of the progression.
And so it's really the first time where we're saying, okay, you know what, this software
is actually now, we think pretty damn good, we're pretty damn proud of it, we think people
should start using it for, you know, basically anybody who's trying to train neural nets, we
think this is the best software out there for doing that.
And specifically for kind of production use as opposed to education or rapid prototyping?
Yeah, and I know there are certainly Fortune 500 companies using FastAI 0.7, but you know,
they're nearly entirely Fortune 500 companies where they have a lot of their technical
staff who have done the courses and got introduced to it that way and are kind of happy to dig
into the source code as necessary to make it work the way they wanted to.
So yeah, now this is, you know, we think this is totally ready for everybody to use.
It's also like a good time for it because it's aligned with the PyTorch version 1 release.
I mean, we're a little bit ahead of them, so we're actually using the PyTorch version
1 pre-release now and when the final release comes out, we'll be obviously supporting that.
But PyTorch version 1 has done a lot of work on the productionization story with the
integration of Cafe 2 and, you know, the kind of full support of Owen and X and stuff
like that.
So because any FastAI model is also a PyTorch model, you can use all of that new functionality
to serve your FastAI models directly.
You made an interesting post about the methodology behind developing the new library that was
actually somewhat controversial on the twimmel slack.
If I remember the gist of it, it was that the library was built, just kind of built from
the ground up relative to 0.7 and specifically built kind of using or around the Jupyter
notebooks that will eventually become part of the course or maybe the part 2 version
of the course.
Yeah, talk a little bit about that process.
Yeah, okay, so this is actually pretty fascinating.
I'm glad you boarded up because it's not something I've had a chance to write about yet.
So this will be the first kind of proper description of this.
Here's what happened.
The first thing is I just love working in Jupyter notebooks.
I am, you know, I've been coding for gosh, you know, well over 30 years.
I just, in many different languages, but I just write better code faster when I'm in
a notebook.
And so I like that, but it's, you know, writing stuff in a notebook is not something that's
really been well suited to creating, you know, reusable modules in the past.
So kind of that was issue number one.
Issue number two is that we've got this kind of unique thing we do when there's an in-person
course on where I make a big room available every day during the course.
And I tell everybody all the students, I'm going to be working in this room.
If anybody else wants to work with me, you are most welcome to do so.
And so during the course, we have a whole bunch of fast AI students, you know, hanging out
working together.
And generally I've got my work being projected onto a big screen so people can kind of watch.
And one of the most common things I hear from the students is, gosh, I learned so much
watching you test and refactor and build, which I can't, I don't get out of the course,
you know, like in the course, everything kind of just appears all done.
And I think one of the things people surprised me is how much I screw things up, you know,
I'm just constantly making mistakes and fixing them.
And, you know, everything is a lot harder than people perhaps realize based on what they
see in the course.
So the question I often get is like, how can we learn to kind of develop software, you
know, machine learning software, the way you're developing it?
So what I did was I decided the next version of the software version, one of fast AI,
which we're releasing today, I am going to build in notebooks where each stage, I'm
going to like, I'm going to leave all the cells in there.
So you can see every stage of that progression.
So you can see what I built first and then how I refactored it and then what I checked
it against and so forth.
So as a result, there's this series of, I don't know, something like 14 or 15 notebooks,
which if you go through the whole thing, you end up writing the entire fast AI library
yourself.
Wow.
And so that 14 notebooks, and that'll eventually be the part two course, which the current
part two course is kind of taking you into the internals of the old library.
So this is a new approach to doing that for the new library.
Yeah.
And in the process, you're going to have to learn about a lot of recent research results
because as you're aware, the, you know, even the 0.7 and particularly 1.0 integrates
a lot of recent research results to kind of make them directly available.
So as you go through part two, you're going to be like learning about, you know, what
paper is this particular line of code based on and why has it done that way and so forth.
So yeah, you're, you're both learned a lot about modern kind of cutting edge deep learning
research, but also about the process of building machine learning software.
And so what we did is like really simple, but it worked really well is from time to time
as I was kind of building a notebook and I could create a function that I kind of think,
okay, that's probably going to be useful to use again.
So I just put a little comment at the top and my comment was always a hash export.
And anytime I had a little thing running in the background that anytime it saw a cell that
said hash export, it would chuck it into a Python module.
And so I could then build the next notebook on top of the previous notebook by simply importing
the previous notebooks, auto generated module.
And so then at the end of all that, we then went through a manual process of kind of
figuring out like, okay, well, what have we ended up with here and we kind of structured
things into a carefully decoupled set of independent modules, which ended up being
fast AI and wrote all the documentation and so on and so forth.
But you know, it really, you can really see the final result is close to identical to
what you'll see in those notebooks.
One of the issues that was raised, and I think I raised questions along this line, well,
I'm sure I raised questions along this line as well and our slack is, you know, that sounds
like a very kind of organic way of coming up with the library that may not lend itself
well to kind of the door ability and, you know, well architected APIs that you would want
if you're going to be using this for a general purpose.
Like how do you?
That's a great question.
So that's how I used to think too.
And about 20 years ago, I got maybe a bit less, I got super interested in test driven development.
And for those that aren't familiar with it, the kind of basic idea of test driven development
is you kind of write a bunch of tests, you make each one pass one at a time.
Every time you find you've got some duplicate code, you refactor it into a class or a function
and you try to figure out what it is that class or functions doing based on that duplicate
code and give it a name.
And you keep on repeating this again and again and again.
And I kind of just played around with it because a few people I respected thought it was
great.
I thought it was really weird.
And one of my key issues was what you just said, which is, well, what point do you actually
design a durable thought for API?
Much to my surprise, I discovered that this process of testing and refactoring naturally
ended up just through having to refactor out these abstractions and then abstractions
on top of those and then abstractions on top of those and carefully naming things.
Yeah, like I ended up with better APIs than I'd ever written when I'd carefully designed
them.
And you know, I should mention I've spent a lot of time designing APIs.
I wrote a number of MVC modules.
I was the Pell 6 chair for all the data functionality in Pell 6.
So I like explicitly was writing RFCs for that API, you know, I've written a lot of
APIs in my time and I've discovered that this organic approach, I end up with better APIs.
I end up with, I end up with no stuff in them which actually doesn't need to be there.
So unnecessary complexity is entirely avoided because you only build what you need.
So I end up with less kind of unnecessary and over complex abstractions.
So I kind of end up with something that's concise and neat and I don't know, like when
you try it out, see what you think.
I'm really, really proud of this API, like I found that we have almost identical four
lines of code to build a NLP model versus a computer vision model versus a tabular model
versus a collaborative filtering model.
You know, it's, it's been a, I found it a real pleasure to work in frankly.
Definitely looking, looking forward to that.
Yes, since you mentioned your work with Pearl, I will admit that in working with the 0.7
version of the API, at some point I grumbled in our slide channel that, you know, some
of the, you know, the attribute and function names were seemed unnecessarily terraced.
And, you know, Jeremy must have been a Pearl developer in a former life.
And someone said, oh, yeah, he was actually a Pearl committer.
Yeah.
And I mean, I think it's fair to say also that some of them were unnecessarily terraced.
So we've actually changed from a rule of thumb of symbol parts should try to be three
letters or less to kind of symbol parts should try to be five letters or less.
And that's actually made a big difference to be able to say train rather than TRN and
valid rather than VAL.
Um, it's actually worse than that though, I'm not just a, a keen Pearl programmer, I'm also
a keen kind of J and APL programmer where everything is one symbol.
So we should expect like, uh, deltas and upside down deltas and Greek letters, creeping
it.
Not quite, right?
Because, um, I mean, I could talk about this for hours, but I'm, I'm just fascinated
in notation and my kind of hero here is Kenneth Iverson, the cheering award winner who wrote
the classic cheering award lecture notation as a tool for thought.
And in it, he describes how good notation helps you, you know, do good work, do good
research, come up with new ideas, implement things more quickly and easily.
And good notation as he defines it is very, very different to what kind of pairpate Python
looks like.
Good notation is something where you, you know, you're kind of I, um, can quickly look
at one part of the screen and capture the gist of gist of what's going on.
So it's about using vertical space really carefully.
It's about kind of having common idioms be easily recognizable.
And so I would say to get to that point where you've got notation as a tool for thought,
you kind of have to slightly give up on Python's goal of being immensely friendly, even to
the most new programmers and say, okay, now I actually want people to invest a little
bit of time learning this, but the promise will be that if you do so, you will be immensely
more productive as a result.
So you know, we definitely don't go anywhere near to the APL and J level of that kind of
premise.
I don't know less it is, it is the premise.
I don't know of J, but APL was a language that I studied for a few weeks and my first
like computer languages survey classes at school, and I remember that those weird keyboards
very well.
So J is kind of an ASCII version of that largely written by Kenneth Iverson's son, actually,
because Kenneth Iverson wrote the original APL, but you've got to realize like APL goes
back to, I mean, it was originally written as a mathematical notation, not as a programming
language.
So, you know, it came out, that came out in the late 50s, the implementations came out
in the early 60s, still today many big and successful companies choose to use APL for their
most important stuff, particularly, you know, big hedge funds.
So the fact that this is a notation that has survived many, many decades longer than any
other widely in use language today, I think it tells you a lot about how extraordinarily
it was designed.
And it's something everybody should study it at some point, because it's, you know,
you just learned so much from seeing this totally independent language evolution path.
I did not realize it was still in wide use.
Oh, yeah, absolutely.
So you know, maybe to digress a little bit from the library, you know, you've already
mentioned a few papers, and one of the hallmarks of the library is, you know, that you have
identified these, in some cases, relatively obscure papers that have outsized results in
terms of training efficiency.
I love doing that.
And clearly, clearly you do.
The question, and maybe why it's a digression is, you know, how do you keep up with all of
the stuff that's happening in the space and, you know, to the extent that you're able
to drop in these obscure references in both code and conversation?
Hmm.
Twitter, basically, you know, the Twitter machine learning community is really terrific.
And you can quickly get, you know, become a part of it.
If you go to my Twitter page, so I am Jeremy P Howard, if you go to my profile, you can
click on my likes, and you can immediately see, you know, what, who am I liking things
from?
And you'll see that there's just a long list of people posting about, basically, mainly
about deep learning.
So you can start following the people you find interesting.
And it's just a really rich, highly technical community.
And so the other thing I do is I explicitly look out for the stuff that other people are
missing.
Or rather than kind of trying to say, oh, here's a really popular paper everybody's talking
about.
Instead, I kind of look out for like, oh, here's a extremely good model somebody's built,
but nobody's talking about this paper, because that's where I get to do something that other
people aren't doing.
So I get to kind of contribute more.
And so I particularly interested in looking at, you know, I always read the winning blog posts
from Kaggle competitions, I look at the, if you go to any machine learning or deep learning
workshop website, you'll generally find posted papers from the people that won that competition.
They are at a astonishing source of tricks, but those things never generally get published
anywhere else.
So and they're never kind of, they don't appear in search results.
You have to go and find them.
But in like these workshops where people say, here's how I won, you know, this academic
competition's object detection path.
They'll generally say, you know, these are all the other papers we looked at.
These are the things we tried.
These are the things we worked.
These are the things that didn't work.
So that's, that's a really great trick.
Oh, that's an interesting hack to, to focus your efforts on papers where there's a competition
involved somewhere.
Yeah, focus on stuff that works.
And you know, even that's much more controversial than it should be, because this is kind of
a view in the academic community that researchers don't really need to worry about, you know,
the latest and greatest tweaks, you know, and techniques.
But the truth is, you know, people building deep learning models are doing it because
they're trying to make something that's more accurate than somebody else's model or trains
faster than somebody else's model, you know, we're not just doing it because of the mathematical
purity of it or something.
So, you know, furthermore, if you're claiming that your model, you know, your architecture,
your training method, your optimizer is better than some other thing, you know, you have
to compare it to that other thing.
And if you don't know how to actually train a good modern model, then your experiments
are pretty much meaningless anyway.
So, you know, I think it's really important for practitioners to be familiar with, you
know, in practice, how are people actually training these most accurate and fastest
models?
At the recent deep learning in Daba event in South Africa, Jeff Dean made a comment
about how, you know, one of his secrets to success, if you will, is as opposed to going
deep on fewer papers, going shallower on, you know, many more papers, he thinks is
a preferred approach, you know, do you ascribe to something similar or do you have other
kind of, you know, hacks for learning and keeping up?
Yeah.
I think that's basically right.
I mean, like when you think about it, if you don't use that approach, then, you know,
you know, think of like your knowledge is a weighted average of the kind of the inputs
you're putting into it, right?
And so, anything that you don't read or look at gets away to zero.
So you can't like, you know, it's kind of easy to pretend like, oh, I didn't look at
it so it doesn't count, but no, you know, you're supposed to put 98% there and 2% there
and 0% on these other thousand things.
So yeah, I think it's definitely worth going broad, but I'd also say like, I look out
for the themes, you know, and so for me, one of the most important theme at the moment
is transfer learning beats everything all the time.
And almost nobody's really doing, you know, not totally nobody, but almost nobody's
actually doing research about transfer learning.
Most papers don't actually apply their techniques to transfer learning.
So you know, here for me, here's a theme, right?
So every time I see anything that I think, oh, that, you know, what if you added transfer
learning to that or, you know, what if I use that transfer learning technique in this
different field that doesn't currently use transfer learning?
So like our ULM fit model, which is the state of the art for text classification, pretty
much everywhere it's been looked at now in multiple languages.
That was just me saying, how come people never use transfer learning properly in NLP?
You know, I should try it.
And yeah, it's kind of like following that, that, that theme.
And I won't go deeper on that because I do have a conversation with Sebastian scheduled
to dig into that sometime soon.
Oh, good.
Maybe back to the, the library and the course, I've heard some, I don't know if they're
rumors.
You know, there's something that you wrote gave folks the impression that the new part
one course is kind of turning away from this top down approach and taking more of a bottom
up approach.
Is that true?
And before you answer that, I will say that, you know, so we did these weekly study
group sessions, kind of like virtual sessions where we all got online and talked about, you
know, what we were learning in the course.
And we spent a ton of time almost every week talking about top down and just getting
used to it.
It's very different from the way folks learn, but very effective at kind of getting you
pulled in quickly.
Yeah.
I mean, it depends a lot on your background, right?
I mean, you know, in a lot of kind of more MBA style stuff, it's often, it is often a
lot more top down, a lot of kind of executive education is a lot more top down.
You know, but most people who are kind of coding have come from more of a, yeah, maybe
come from more of a computer science, academic background, which is very bottom up.
So no, we're not stepping away from the top down approach at all because it's, you know,
all of the educational research I've studied, which is a lot, shows that most, by far the
majority of people learn better with the top down approach, even though it requires to
some extent unlearning how to learn based on the bottom up approach that we kind of get
used to from school and university, I will say the machine learning course, the introduction
to machine learning course is it's still pretty top down like lesson one, you know, the
first cell is here's a random forest, we've trained it and here's the result.
And then we kind of gradually dig into like how do we interpret that result and how to
be actually build that tree and by kind of lesson seven, we write our own random forest
from scratch in pure Python, but I don't know, yeah, I think because the people I was originally
doing that course for were master's students, I possibly was a little more, I don't know,
go a little bit deeper a little bit earlier so that they didn't get too uncomfortable
with the kind of change of style.
I'm looking for the details here since you mentioned that machine learning course, of course
has been kind of, you know, it's been around in a pre-release state, I guess for quite
some time, but since it's been formally released, we've got a study group that some folks
in the community are organizing that will be starting very soon.
In fact, lesson one is going to be on Sunday, October 7th at three o'clock GMT and they're
going to continue that for, you know, 12 weeks on Sundays at that time.
Well, let me encourage people to get into that even if, even for folks who haven't done
the deep learning course yet, like you can do the two in either order, they both are designed
to work well together, but it's definitely true that people who study with a group on
average have more effective learning outcomes and more importantly tend to stick with it
for longer than people who study independently.
So yeah, I think that sounds like a fantastic initiative and I hope people listening join
in.
Well, we had a great group that did the deep learning part one course together this summer
and in fact, most of the, you know, this course and we've got another session of the deep
learning course that's going now, I'll elaborate on that in a second, but these are all kind
of being run by folks that came together to do this deep learning course together.
So it's been awesome for us on that deep learning course.
So we had a group that started three, three weeks ago, I think they've had three sessions,
a second group on the deep learning for coders part one course.
We made some tweaks to how we did it.
The first time we did it, we did, we were planning for a weekly pace.
We held that through about the fourth lesson and then we went to buy weekly because it
gets a lot harder.
Yeah.
Yeah.
This time they started doing a bi-weekly pace all the way through, but one of the things
that through a little bit of a wrench in our plan, a good wrench, is that you announced
that for the new course, which is going to be starting towards the end of October, although
we noted that the notebooks haven't been written yet, yeah, I should probably do that.
For this new course, previously the options for taking this course were you could take
it in person and you offered a bunch of different types of scholarships or apply to take
it remotely during the live course time or wait a few months and catch it via video.
But you just announced with some pretty interesting kind of background commentary that you've
decided to make the remote course available to anyone who wants to sign up for it.
Yeah.
As long as, you know, the only thing I ask is that you follow a long live, which means
if you're in a annoying time zone for our evening US time classes that you get up and
do it anyway.
I want people involved to be contributing to the real-time chat during the course.
But other than that request, yeah, it's open to anybody who has at least a year of coding
experience and definitely looking forward to seeing how this little experiment works out.
I think it's going to be really cool.
Yeah, that was one of the questions that folks had was whether the folks that are in kind
of off-time zones, whether the videos would be made available any sooner so that they
could, you know, participate via forums and groups like ours, but watch the videos at
a slightly more convenient time.
I mean, it's, I mean, I can't technically stop anybody from doing that, I guess, because
I mean, it's on YouTube live and the videos appear on YouTube live, but I would certainly
much prefer people to actually be there during the class because that's where we're having
the discussion.
You can ask me questions, you know, while the lesson's going on, you know, I think that's
what makes it a really rich and interesting experience.
We started this course, a second session of the part one course through this really
a great wrench in our plan.
And so what we've decided to do is we'll kind of continue for the part one course, the
first couple of lessons, but as soon as that, the new course starts, which I think you
said was the 22nd of October, if that date holds, we will be kind of switching gears and
working on the new course, the new library, et cetera, and everyone's really excited
about that.
And people do need to sign up to participate in fast AI live, so I'm sure you can provide
the link there that they can do that with.
All right, so we'll include that in the show notes and then the sign up for the meetup
and for our study groups, that'll be at twimmalei.com slash meetup.
So maybe kind of jumping back to the library, one of the things that you are kind of
including in your announcement about the new library is some benchmarking that you did
relative to the Kieres library.
Can you talk a little bit about that and what you showed?
Yeah, so I mean, I'd love for people to help do more benchmarking, I only had time to
quickly throw something together.
And I will say it's been a while since I really used Kieres, so I tried to find documentation
on best practices, but there actually is, I couldn't find anything post 2016 in terms
of official, here's how to do transfer learning in Kieres, so it's possible that my Kieres
approach is not as optimal as it could be, but basically, yeah, I tried to use the classic
Kaggle Dog's versus Cats data set to transfer and learn a ResNet 34 and just to attract how
many lines of code it took, and I tried to optimize my Kieres lines of code as best as
I could, how long it took to train and what accuracy I could get.
And yeah, I was very pleased to find that the first AI library code was something like
a fifth as many lines and I was quite a bit faster and quite a bit more accurate, which
is, yeah, it's really all about the little, you know, all the stuff we curate both in terms
of papers that we incorporate into the defaults and also some unpublished research, which
we hope to publish later this year around ways to do this kind of training better.
One of the things that I did notice about the new library is the code to do fine-tuning
got very compact to the 0.7, can you maybe, you know, talk a little bit about that and
more broadly, like the big, the differences that folks, you know, should expect to see
when they start working with the new library.
So, you know, Perl, since we've talked about Perl has Larry Wall who wrote it has this
motto, which is, make the easy things easy and make the hard things possible.
And so, to me, it's not just about making the easy things easy, but make the important
things easy and there's nothing more important than transfer learning.
So yeah, we tried very, very hard to make it, you know, basically transfer learning is
kind of the thing you get automatically and for free.
So if you create a model by default, you'll get some pre-trained weights and by default,
you'll get something that is set up for discriminative fine-tuning and set up for, you know, layer
freezing and, you know, all the stuff you need that you'll know from the course if you've
done it.
Yeah, but then, you know, the nice thing is that all of the power of PyTorch, we very
intentionally make as close to the surface as possible.
So for example, you know, we integrate very closely with PyTorch and we use a lot of
PyTorch APIs directly.
So for example, a fast AI data set is a PyTorch data set.
The fast AI data loader is a wrapper for the PyTorch data loader and in our docs, which
actually we should talk about our docs a bit because it's one of the things I'm most
proud of, but in our docs, everywhere that we are using a PyTorch object, you'll see
that there is actually a hyperlink directly to the PyTorch documentation for that class
or function.
So, you know, the two libraries are really nicely integrated.
Oh, that's awesome.
I'd love to hear you talk a little bit about the docs with the 0.7 library for the most
part, the code was the docs.
Yeah, there was no docs.
And in fact, someone from our, from the tumble community, Kai contributed some docs and
was told, well, you know, hold off on this because we're going to do better.
So what have you done with the version 1 library?
Well, you won't be shocked to hear this, but the entire set of documentation is written
as Jupyter notebooks.
Oh, nice.
And so that means that every page in the documentation, you can actually run it in your own Jupyter
notebook and see the experiments.
So that all of the documentation is designed to be a very, you know, every, every module
starts with an overview of like, hey, here's some code you can run right now to, you know,
build this kind of model or to do this kind of data orientation.
We wrote our entire, a kind of computer vision library from scratch in PyTorch, full
new set of transformations, every transformation, therefore, is documented as, you know, a line
of code in the, in the docs that actually, you know, prints out examples of that data
orientation shows you the pictures.
So then what we've written is we've written a whole new documentation framework, which
takes those docs and turns them into a, into a website.
And that website, for example, it does things like any, any, any place you've used back
to text to kind of, you know, say, hey, this is, this is code.
This is a symbol, it will automatically try and find anything in that code that represents
a PyTorch or, first AI class or function or object automatically generate a hyperlink
to that.
So you can basically write, you know, standard mark down cells, you can standard code
cells, inputs, outputs, pictures, everything will then automatically generate this fully
hyperlinked table of contents, searchable documentation with, you know, embedded pictures
and all that kind of thing.
And then, yeah, you can go and try it out yourself by actually loading up that, that notebook
locally and trying it out.
So I think it's, as far as I know, it's the first time anything like this has been done
and I think it's going to be super helpful for this kind of thing we say to people, which
is how you should be experimenting, you should be running code, you should be trying things
out.
So the documentation, you know, is stuff that you can try out as experiments.
That sounds, that sounds tremendous.
The, I'm not aware of any, I've never seen code distributed as Jupyter notebooks.
That does sound very cool.
Someone mentioned that you tweeted something about some extensions to Jupyter that you
were creating, is that what that's referring to?
Yeah, they're not actually extensions, it's a, it's a, it's a framework of, it's a bit
like a, if you've ever used things, it's kind of syncs on steroids, you know, about
for notebooks.
So basically something where you feed in Jupyter notebooks and it spits out a nice document
documentation website for you.
Hmm.
And one of the things that comes up occasionally is, yeah, folks that want to develop in Jupyter
notebooks and then productize, productionalize that code are, are you using techniques in, in
this process that could be, also used to take a Jupyter notebook and, you know, maybe
identify parts that are annotated as being, you know, that kind of the export thing that
you're referring to.
And then put those into a production module.
Yeah, absolutely.
So, you know, as we go through part two, which I guess will be kind of first and second
quarters of 2019, that's kind of what we'll be doing is we'll be seeing how to, how to
go through that process.
You know, for me, I like automating things, the right amount, which is like not too much
and not too little.
So for me, this kind of exporting cells is a great way to kind of gradually build up much
of the API that you want, but then the piece where it's like, okay, let's create a really
nicely designed decoupled set of modules with clear dependency paths and all that kind
of stuff.
That's something I did, actually Sylvan and I did together, you know, manually and carefully.
So I'm not really into kind of necessarily directly turning that Jupyter notebook into
a module, but we certainly got some, yeah, use some simple tools to help us semi automate
that process.
Okay.
What are some other highlights that folks that are familiar with the.7 library should
expect to see or should be on a lookout for with version one?
Yeah.
So this new data augmentation slash computer vision library is something which you should
definitely check out because it's, it's actually something which the, the PyTorch team helped
make sure that PyTorch was explicitly performance accelerated for exactly the things we needed
for it.
So it's very fast and it actually ends up with much higher quality outputs than any existing
data augmentation library because normally if you do like a rotate and then a zoom, for
example, it basically interpolates on top of interpolation and you end up with these kind
of fuzzier and fuzzier images where else we use an approach which actually keeps all of
the sharpness of the image throughout the process.
We also have some, this allows us to actually incorporate as default some kinds of transformation
which pretty much nobody else is using, particularly perspective warping, which is a really important
transformation in practice but it really requires this special kind of library to make it work
effectively.
So I'd say definitely check out the computer vision transformation library we've built.
I'd also say have a look at the really good support for NLP transfer learning.
Quite a few of the community on the fuzzier forums have been trained out the ULM fit techniques
of basically transfer learning for NLP in non-English languages.
In the last week or two, I've heard from two Polish students that they just won the
Polish main Polish academic competition.
Somebody else has just got the state of the art of a German and then a few months ago,
somebody got the state of the art of a tie.
Like in the German example, the chap on the forum basically said, hey, I tried it.
I trained it for 20 minutes.
The first thing that popped out was the immediate state of the art of a German.
So for NLP, you can basically do stuff with this library that you will get better results
than anybody's published before, kind of trivially.
And we actually include, if you look in the examples directory of the repo, just click
on the text example that'll actually show you how to do it end to end.
And certainly, very much easier support for tabular data sets that's there is definitely
worth checking out.
It's not that it's doing anything that you couldn't do with 0.7, but it's now super, super
easy.
Yeah.
And I think also, just check out the documentation framework because we do plan to extract
that out into a separate independent project at some time soon-ish and I'd love to see
more people trying to build Jupyter-based documentation systems because I think it's
really helpful to your users to be able to say, hey, all of the documentation is code
that you can run yourself right now and try it out.
So the current library is very much focused on supervised learning and as we've discussed
transfer learning.
Do you see the library moving into models like reinforcement learning or unsupervised
learning?
Reinforcement learning, no, at least not in the short to medium term.
I'm still unconvinced that we really know what we're doing as a community when it comes
to reinforcement learning.
The good results we're seeing are largely because of hacks that basically involve throwing
ridiculous amounts of hardware at a problem.
So I still want to spend some time doing some deep research into reinforcement learning
to try and find ways to make it work better on smaller amounts of resources and on kind
of more practical problems, you know, not many people need to win Dota or go.
Unsupervised learning definitely kind of, I don't really believe that there's such a thing
as unsupervised learning, but I do believe very much in what Jan LaCouden calls self-supervised
learning, which is coming up with a supervised learning model which doesn't require explicit
labels.
And so for example, ULM fit is entirely based on something called a language model.
A language model is just a model which predicts the next word in a piece of text.
So you don't need any labels, you just need some text and you can build a model that
tries to predict the next word after every sequence.
So that's a self-supervised model because it uses the input data itself to generate labels.
So I'm very keen to continue to provide richer and richer and more and more varied self-supervised
learning support because that allows you to do transfer learning even in situations where
you may not have explicit labels.
The idea of self-supervised learning as you described it is related to another recurring
theme that comes up from time to time on the podcast and that is incorporating model-based
approaches into deep learning models, like physics-based approaches or other depending on
the domain.
Is that something that you are interested in, you're seeing and do you see it?
How do you see it working with the library?
Oh yeah, so very much so.
It's something I really enthusiastic about.
I mean, a great example of a model-based approach is the convolutional neural network.
So if you start out with the observation that your data is auto-currelated along some
dimensions, so for example, in an image, one pixel tends to be similar to the pixel above
it and to the left of it and to the right of it and below it.
So you've got two-dimensional autocorrelation and so a convolution is an operation explicitly
architected to allow it to be easier to identify those kind of autocorrelated patterns.
So like I see, it is a great example of a model-based or model inspired architecture.
Then there's more recently, there's been a lot of, maybe not a lot, quite a few good
examples of places where domain experts have come up with tweaks to an architecture which
allow it to, you know, more easily represent the kinds of things that are most common
in that domain.
So for example, there was a couple of papers, one of which was by Saunderdeeleman talking
about group convolutions, which is basically saying, hey, if you're doing something like
pathology images or satellite images, which are rotation invariant, here is an architecture
that is explicitly designed so that rotation invariance is built into the variant architecture.
I've seen similar things in models for physics, where the kind of basic invariances or constraints
of what would be required in those physics modules are, models are built into the architecture.
So with fast AI, we've tried to make that kind of thing pretty easy to add because there's
this idea of a custom head, you can very easily create a custom head for your architecture
which might contain some of those ideas, or you can create a custom module, a custom
NN module, you know, a PyTorch model, and pass that directly to a fast AI learner, and
we've kind of provided lots of hooks for you to make it easy to add all the additional
fast AI features into your model.
So yeah, I think we've, you know, tried to support what we can there and maybe people who
are interested in specific domains that already have some kind of model inspired architectures,
hopefully we'll be able to start contributing some of their approaches.
Maybe to start to wrap things up, I hear you're writing a book on machine learning, what's
that going to cover?
Okay, so we've got two books coming up.
Why does a book with Professor Terence Pa about machine learning?
The first few chapters are available in an early draft form online, and it's basically
inspired by the course.
So Terence Pa, if your listeners may recognize the name, he's a pretty famous computer scientist
who built the antler parser generator, which I guess is kind of the most widely used parser
generator around, and he spent decades becoming, say, the world's leading expert, or certainly
one of them in parser generators, and he's now turning his attention to machine learning,
and he's a colleague here at the University of San Francisco.
He actually sat in on my machine learning course when I taught it, and said, oh, I like
that so much.
I think we should write a book based on it.
So yeah, so we're doing that, and everything Terence does, he does exceptionally deeply and
exceptionally well.
So if you check out some of the early material, you will see there's a lot of beautiful
visualizations and really nice descriptions.
The second book is with Sylvia Guga, Sylvia, some of your listeners may recognize as being
an exceptional student from an earlier course who repeatedly wrote brilliant material that
I featured in the course, and since then he's gone on to do some really cool research
around transfer learning, and AWS were kind enough to actually sponsor him as the first
FastAI scholar in residence, so he's been working full-time with us for most of this year,
and he's going to help me write a book about the FastAI Deep Learning Library, and learning
Deep Learning using the Fast.AI top-down approach.
So that one's going to be coming out published by O'Reilly sometime in 2019.
Awesome.
Related to your own evolution in the space and what you've seen from Sylvia, I'm sure
you've been asked for folks that are interested in this field, don't want to get a PhD but
want to contribute to research.
Do you have kind of a path that you point folks down?
Yeah.
I mean, Sylvia would be a great example of that.
His background is pure math, so minimal computer science.
He's actually visiting us in San Francisco this week, so I've just been chatting to him
about this, and he was telling me, yeah, he's been doing Deep Learning for less than a
year, and he thinks his story of kind of going from a pure math, minimal computer science
background to contributing to the FastAI library and doing well-regarded research is kind
of a good example of how people, yeah, it doesn't have to take a long time.
You don't have to have some kind of formal background.
I think all it needs is tenacity.
I think it requires strong coding shops, and so Sylvia has been working very hard to
become a better coder, because then you can run lots of experiments every time you come
up with an idea, you can try it out.
And then just start writing.
Start writing simple little blog posts, like just pick something that you've seen come
out where somebody maybe, give me a simple example, ULMFIC came out showing good results
on English classification.
So if you're a big French, why not try it on French classification, and that's a simple
piece of research, and you can write a blog post, or you can write a PDF, or put it on
archive, showing your results on French.
And then maybe you could say, oh, well, now that I've done French classification, let's
also try sequence to sequence, or let's try sequence labeling, you know, just little
extensions, and you'll be pretty surprised that you kind of keep publishing little extensions
to something that you like pretty quickly, you'll find that you've somehow become more
of an expert on that particular area than anybody else, and people start coming to you
for advice, and you can start suddenly realizing, oh, you know, when Jeremy and Sebastian did
that paper, they never tried this other technique.
So maybe they'd be like, oh, they didn't try using a transformer model, maybe I should
try a transformer model instead of an LSTM, let's try that.
And so, you know, just keep digging, keep trying things, I'd say try to be as practical and
useful as possible, don't get too lost in the math.
And then, yeah, if you start coming up with some things that start showing good results,
you can reach out to other people who have been doing work in that field and say, you
know, here's my results, here's my code, what do you think?
And if they think it's good, you know, maybe you can start doing some collaborative research
with other people, which is exactly how Sebastian and I ended up doing some work together,
and now it is Leslie Smith and I, you know, talking about collaborating, you know, yeah,
it's all about doing useful work in a field and getting to know some of the other folks
that are doing that kind of work too.
Leslie, we know from the work on cyclical learning rates that was featured in the library,
right?
Yeah, and the learning rate finder, and more recently, the one cycle schedule that's going
to be kind of the main featured training method in fast AI version one, and perhaps most importantly,
the super convergence phenomenon that we're finding we can train things five to ten times
faster than we were before he discovered that.
Well, that sounds like another conversation, maybe one that I'll need to have with him.
Yeah.
But for now, Jeremy, thank you so much.
Once again, for taking the time to chat with me, it was really great having you on the
show.
That's my pleasure, and I hope folks, you know, if people interested in the fast AI library,
if you just go to docs.fast.ai, you'll find all the information to get started there
and come to our forums and tell us how you go.
Fantastic.
Thanks so much.
Thanks, Sam.
Bye-bye.
All right, everyone, that's our show for today.
For more information on Jeremy or any of the topics covered in this show, visit twimmelai.com
slash talk slash 186.
You'll find there a link to the fast AI library and the new fast.ai courses as well.
To join our community of machine learning enthusiasts, including our study groups for the fast.ai courses,
visit twimmelai.com slash meetup.
If you're a fan of the podcast and you haven't already done so or you're a new listener
and you like what you hear, head to your Apple or Google podcast app and leave us a five-star
rating and review.
The reviews help inspire us to create more and better content and they help new listeners
find the show.
As always, thanks so much for listening and catch you next time.
