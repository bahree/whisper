Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
Alright everyone, I am on the line with Danny Stoll, Danny is a research assistant at the
University of Freiburg in Germany.
Danny, welcome to this week in machine learning and AI.
Thank you for having me.
So Danny, I interview a lot of folks that are practicing machine learning professionally,
as well as PhD students, but you are actually an undergraduate student working as a research
assistant and you've been doing deep learning since high school.
How did you get introduced to deep learning?
So I guess it all started with a general interest in math for the math sake.
So I learned a lot about analysis and linear algebra, stochastic, things like that.
And at some point I got introduced to machine learning and deep learning via some blocks
or things like that.
And that really caught my attention.
So I started with a famous curse offered by Andrew and G, a basic machine learning curse.
And when I worked on that curse, which is an online curse, I really got hooked and I
never looked back from that on and though deeper and deeper, mostly using online lectures
because at the time it was still a high school student.
Is that what you're studying at the University of Freiburg as well?
So the program I'm in at my university is a general computer science program.
So we learn all the basics of that for sure, but there are a lot of mandatory curses
which cover the basics. But in the later stages of this program, you have a lot of freedom.
You can choose different curses.
You can hear reinforcement learning, machine learning, deep learning.
You can have different seminars.
You can even listen to very advanced seminars.
But what I did when I started this program, I joined the reading groups with the topics
related to machine learning and I joined the seminars just sitting in there and I really
enjoyed that.
And so the group here in, as a research assistant, automated machine learning, what's the
focus of that group?
So as the name says, the focus is on automatic machine learning because for once it's not
everyone has experience in machine learning, it's pretty hard to do.
But a lot of people would like to use machine learning or even AI for their products, for
their research, people that might not even have a background in computer science.
So one goal of automating machine learning is to really democratize machine learning
to make it available to everyone and you do that by automating it to really remove the
necessary expertise to run machine learning.
And so we are going to talk a little bit about a paper you co-authored called learning
to design RNA.
Tell us a little bit about the origins of that paper and the problem that it sets out
to address.
So I guess I should start with automating why we care about RNA and what it means to design
RNA.
Many people or most people know RNA from their high school education and it's rural during
the synthesis of proteins.
But RNA can actually regulate biologic processes directly to match like proteins and there's
a lot of focus on proteins because they can regulate these processes.
But RNA can actually do the same thing and it has been connected to all kinds of different
diseases like Parkinson's, Alzheimer's, epilepsy.
And in a very recent study also autism, which was a 2019 study.
So we're even still learning about where RNA is involved and it's only growing in size.
So what actually matters about RNA in terms of which function it has in the body is its
structure, its spatial structure, the weight holds, not the basic structure which is just
a sequence of four nucleotides.
But you don't really know which kind of sequence the desired way.
So once you can have designed a spatial structure that you would hope has a certain function
in the body, you still need to design an RNA sequence which has this structure which holds
in the desired way.
So you can actually have the desired function in the body and that's what RNA design tries
to address.
So given a high order structure design an RNA molecule, a sequence which has a structure
which has the function that you want to have.
So it's the function determines the structure that you need and the folding or the structure
then determines the folding that's required to kind of create that structure.
Yes, it's the structure determines the function it has and the basic sequence determines the
structure, the higher folding.
But we want to inverse that process, we want to go from function to structure to low level
structure to the basic molecule itself.
Great and so you kind of set out to tackle this problem.
What led you to the particular approach that you ended up using here?
So as we talked about in the start of this interview our group focuses mostly on automating
machine learning and deep learning and one recent field there around recent approach
what people are doing is called neural architecture search where you try to find the best
architecture, you try to search of architectures of neural networks which perform best.
And early times of neural architecture search people use reinforcement learning and basically
decided for each building block or for each stage in the network what you want to use.
And we saw some similarities with RNA design because there you also can choose which nucleotide
at which point in the sequence you want to place and that led us to try this out and we
got a proof of concept and it seems to work nicely.
So from there on we went with it.
Was there an existing body of research that you or kind of implementations that you were
trying to automate through this neural architecture search or did you have to come up with, yeah
I don't know if this question even makes sense but did you have to develop the algorithm
to do the underlying kind of folding? Yeah that's actually a great question.
So there has been a lot of research into RNA design because it's such an important problem
and the research goes back almost 30 years and you ask about the folding itself.
Folding has actually been solved for RNA and that's nice because if you compare to proteins
there we are very far from solving folding. People are mostly working on folding, not designing
and so we had this folding algorithm available to us. It's called the Zaka algorithm,
there are other algorithms and our approach basically works with all of them but we concentrated
on this one algorithm because mostly everyone else was trying that as well.
As for the state of RNA engineering before our publication it was there were not many
machine learning approaches but there were probably none that I know of. There was one other
machine learning approach published in parallel to us but before that there was no really
machine learning approach. What people usually did is they did a basic search, a local search for
example to progressively improve the sequence that you have, that you want to then fold and see
how well it folds and then try something else at some side of the sequence but that doesn't work
very well we found because it doesn't scale well with sequence size. What we did instead is
we formulated it as a reinforcement learning problem and that is in a generative way so
we would put out the complete sequence that we want to fold at once and then we learned to do that
very quickly and our approach scales really well with sequence length. The other machine learning
approach which was published basically implements a heuristic for a local search so that's actually
very different from what we have done. What's the relationship between your use of reinforcement
learning and neural architecture search here? In the other days people were using reinforcement
learning to do neural architecture search so reinforcement learning is the type of learning where
you get a state or rather you have an agent and an environment and the environment provides a state
and the agent can based on the state choose which action the agent wants to take and what people
did with neural architecture search is they said okay our actions basically choose building blocks
for different layers of the network say for example what do you want to choose a
relu or what do you want to choose a different activation do you want a basic convolution or do you
want a separable convolution things like that and we thought well that's the same for RNA design
that's let's choose which nucleotides we place at different points in the sequence and so are
you using neural architecture search or rather was this approach inspired by neural architecture search?
So it's both so okay we already talked about how approach how basic approach was inspired by it
but then we only had this basic idea and it's a very novel setting for machine learning algorithms
and we didn't know what would work well which kind of architectures would we have to use
what we have to use recurrent neural networks do we have to use convolutional neural networks
do we need some embedding which we learn or what a basic embedding work and we said to ourselves
okay we could try these things by hand but we are actually experts on doing this automatically
and optimize it and then we went ahead and formulated our approach in a general way such that we
could search the best architecture for it but we didn't stop there we also we also didn't know
which kinds of hyper parameters we would need which how our training would need to work
and finding the right hyper parameters is a very tedious and time consuming
process as probably our machine learning practitioners know and our group usually tries to
develop algorithms that automate this so we used our state-of-the-art algorithms or
used algorithms and searched for the hyper parameters and the architectures jointly
to to really optimize for that and we didn't even stop there we we thought okay but now we have
to choose our environment how do we need to choose our environment what what kind of reward do we
need how would our states need to look like how how do we need to choose our actions or what do
our actions really correspond to all these kinds of choices of the environment and we also included
these choices in our search so we searched for the best agent and the best environment jointly
that's what we really did and also the training hyper parameters we we really automated our L here
I mean it sounds like you kind of you know through the the kitchen sink at this problem you got
a little bit of you know it sounded like multi-task learning in there reinforcement learning
neural architecture search you know when you throwing so many you know different cutting-edge
techniques at a problem like this you know I'm wondering what the you know are there some drawbacks
or costs associated with doing that do you end up with you know something that you wouldn't want
to implement because it's too complex or because there's no way for you to really understand what
is doing you know or did you find that the you know the result met all the criteria that you you had
for it and maybe you know that's a good place to start is what are the criteria that you you know
would put in place for a solution to this problem so one basic criterion that that I tried to
follow in my work always is do it simple you said we threw all these sophisticated things at it but
in actuality our solution and or even our automation is extremely simple it sounds very complicated
and but it but it's not it's the final result it's just a few layers it's it's it's very basic we
didn't do any sophisticated techniques in there like we didn't even have learning rates get yields
or we we basically only experiment with basic convolutional networks basic fully connected
networks different very simple embeddings such that we could search over them efficiently and
also our automation is very simple we had we formulated a 14-dimensional search space of integer
parameters like how many convolutional layers do you want how many recurrent layers do you want
but also continues parameters like what should the learning rate be or how should we shape the
reward and we used a standard approach or our approach for hyper parameter optimization which is
used in quite a lot of papers and through that at the search space and look what kind came out
I guess a drawback when you do it like that is that you have computation overhead in terms of
how you the big because you have to search over these hyper parameters you do that on
many machines simultaneously but I think that's the better way than doing it manually and
have it cost developer time because a lot of bottleneck in machine learning and deep learning is not
on the computational side but on the developer time and that's also a great problem that can be
solved with this automated type of parameter search and architecture search removing the need for
a machine learning developers and researchers to really fiddle around the type of parameters because
it is a very tedious and time consuming process and just formulate a search space run a hyper parameter
optimization on top of it and see what works best and so were there any unique challenges or
approaches that went into formulating that search base is it you know as simple as the things
you outlined previously the number of layers and the types of layers that kind of thing or were there
interesting interdependencies or you know did you have to kind of craft objective functions in
an interesting way what was the kind of scope of that part of the problem so so there were some
some things like the state space and the first few layers which had to which are conditional on each
other we have some conditional parameters there but one other thing that that we had to come up with
and it actually had a lot of impact on the final performance is the way we do the reward so what
we do is we once we have designed a sequence we fold it and then we compare the folding the higher
order structure with the one that we want to obtain and then we take the distance of these two
but if you think about it if you're folding if your structure is 90% correct then that's not
really good because you really need the structure to be exact and then we had to reshape the reward
to put a lot more emphasis on if you only get 0.9% if you only get 90% right then your reward should
almost be zero but if you get 0.98 correct then then the reward then there should be some reward
because they're very close but we did not know how much we had to shape this reward in this
regard so we formulated the reward in a way such that we had one parameter which could influence
this kind of shape and then that's one part of a 14-dimensional search space with the reward
function that needs to be shaped like that I imagine at one of the challenges that you run into
is that you're not able to give your agent enough information as to how well it's doing unless it
stumbles on to the perfect solution or something very close did you run into that challenge and
how did you address it so that's a major challenge and when you when you start off with a single
sequence and you run an algorithm on that you might get very close and then you get some reward
yes but if it's a very complicated molecule then then it's very unlikely that you you will hit
something successful and that's a major drawback of algorithms before ours but what we did is
we incorporated this meta-learning on multitask learning across many molecules so we could
actually transfer knowledge from for example a simple molecule where we can get good solutions
quickly to more complicated ones so we can first learn the basics of the RNA folding dynamics
or the inverse of that and then transfer this to some more complicated molecules so that's also
where where where a very great advantage of our approach lies in because we can actually perform
very well very fast on very long sequences which others cannot and if you take this component
out of our approach which learns across these molecules then we do not perform as well but
we would still have the state of the art so is the this transfer learning aspect is this across
different training runs meaning you train up a model and then you apply it to a separate problem
or you training across different problems or different molecules so it's kind of both
because what we do is we do a kind of multitask learning very run on sequences on RNA molecules
in sequence and in parallel and update parameters according to all of these RNA design tasks
and then we use the resulting parameters to initialize our approach on a novel RNA design problem
that's what we do but what we also do is we explicitly optimize the hyperparameters environment
and the architecture to do this transfer well so we also optimize for being able to transfer well
and how do you do that the objective that our hyperparameter and architecture search and environment
search optimizes is given a training set of RNA design tasks and you can train on that how well
do you on a few novel ones and we optimize this objective with our meta search and so when you
kind of taking a step back and thinking about this from the the the perspective of the problem
the RNA design problem what's your ultimate performance metric there and how do you how do you
assess it is it are you comparing to other non-machine learning based approaches or something else
we are comparing to the to non-machine learning based approaches that people proposed before us
but we're also comparing it to the one machine learning based approach that I also mentioned
and the kind of metric people used in the past for RNA design and which we also adapted
is at each time point or in a for a given time how many RNA sequences or how many RNA design problems
rather can you solve and solving means getting the structure completely right and what people
usually do is they say okay there there we have a benchmark there we get 10 minutes per sequence
or you have a benchmark where you get one day per sequence and then compare only the final
performance but we looked at the complete trajectory of how long at each time point how many sequences
have we solved and what we can see especially with our meta learning our multitask learning
approach is that we solve a lot of sequences very very rapidly so for one of the benchmarks
we we take some time for our parameters to load and everything but after that it takes one second
and we basically beat most of the other approaches which take like five minutes to really
solve softness many sequences so for one of the benchmarks we achieve state of the other results
a thousand times faster than the previous state of the art and for another one we do it 60 times
faster in this case of the thousand times faster you said loading your parameters is that
so that's you're comparing a traditional approach that's non machine learning based with just
the kind of inference against your model yeah we run the inference of our model on
or the complete time it takes for our algorithm to receive the sequence to load the parameters
and everything and to start predicting something so that's part of our evaluation and if some
other algorithms also need some initializations then we measure that as well yes but
but it's basically running the algorithms and looking at how quickly they solve a molecule or
if they solve it at all I guess I'm I'm curious when you're talking about a thousand times faster is
is it you know we really at that point trying to compare apples and oranges or they really
comparable in the sense of a lot of your work is done in training and then you produce this model that
is you know once you've got the model the time it takes to get the inference is going to be much
less whereas if you have an algorithm that's doing the computation at the time of you know trying
to figure out the the answer it strikes me as not being particularly comparable am I thinking
about that correctly or yeah you can think about it that way but that's actually a nice thing about
our approach that once you have trained it which doesn't take a lot of time in our case it took
an hour or three hours and once you have that you can you can apply to novel RNA design problems
which you haven't seen before and it just works that's that's definitely something that you should
aim for like if you if you can pre-train your model or your algorithm beforehand and make
and make use of information that you have for other problems and apply to new problems then
that's a that's a very nice thing right and we also have one instantiation of our algorithm
which does not do that does not transfer knowledge but just runs at the problem
correctly and that also achieves state of the art performance I mean in one sense that it's saying
you know a machine learning approach is where you produce a model and you can run inferencing
as this model is better than an analytical approach where you're kind of doing the computations
from scratch every time but you're you're saying that because the algorithm because your model
generalizes it's kind of a valid comparison yes that's what I'm saying and there's also the other
machine learning approach that I talked about also uses reinforcement learning but it only
implements a heuristic via the reinforcement learning for a local search for these more traditional
methods and um transfers knowledge for that as well but I'm not sure how well it actually does
that yes but and it's and it still cannot just generate a sequence from scratch directly which
which works yeah so from my point of view being able to transfer knowledge from from a set of
training tasks to to novel tasks and make the performance better is a great thing but I might be
biased since a lot of my work also focuses on meta learning where they try to do the same thing
you try to learn to learn or you try to learn to effectively solve novel tasks if you
someone's listening and they you know they hear this and they want to try it or their particular
things that they need to be aware of or think about that are specifically related to maybe any
interactions that all these things have with one another or they pretty straightforward to apply
in conjunction with one another so because what we did is this is very simple we didn't run into
really a lot of problems with using all these things in conjunction but if you want to combine
very sophisticated meta learning algorithms with something like neural architecture search
that's that that's a hard thing to do and that's an open research question how do you effectively
meta learn to do architecture search or how do you do architecture search for meta learning
that's that's what people are researching but in our case it was a very simple thing about a very
simple formulation which ended up working great and that's also a strength of our approach that's
very simple it's it's using hyper parameter search and architecture search and all these things
but the way you formulate it it basically reduces to hyper parameter search for all of these
things so we formulate a neural architecture search as a hyper parameter search and the same
with the environment and that way you can very effectively search over all these choices at
the same time and we talked before how we explicitly set the objective of our optimization
for to the to how well at the configuration transfers so that's the thing you can do as well
you can explicitly optimize for how well your meta learning optimizes or how you multitask
learning transfers in the paper you talk about some ablation studies that she did can you talk a
little bit about this yeah sure so in general I think it's very important to the ablation studies
for your systems for your algorithms because if you do not you do not know what actually
is the thing that performs well and if you do not do an ablation study then you end up doing
things that don't help and it just makes your approach more complicated and more complicated for
other people to use so I think in general it's very important to do an ablation study and what we did
is we we ablated or we disabled the meta learning the transfer learning across molecules learning
across molecules and what we observed is that while we still achieve very good results when
we compare to other methods we do solve things much more slowly and also solve some molecules
not at all one other thing that we disabled and saw how important it was was building a model
itself like do we actually need to build a model or is it trying to just randomly predict something
and as you would expect that that does not work very well yeah we also had an additional step
in the reward or in the folding where once we are very close to a solution like only
for sites or very small number of mistakes were made then we do some more search for it like
not go through the our reinforcement learning agent again but just try some things just change
some things and see how it affects the folding and if we can solve it and in early stages of our
approach it was very important so we kept it in there but once we optimized for the transfer
learning and everything we observed that it's important Scott less and less and only on very hard
problems and very hard on a design problems it does make a difference so we ended up using that
because it does help in these very hard cases but we could have disabled it for for easier benchmarks
as well and that's something we learned from our ablation study that's that's very important I
think to really learn what difference do your do your components make of your algorithm but what
happens if you disable them are they really critical do they help at all and people do not do that
enough I think did you develop any intuition for why that particular component only had the
impact with the more complex molecules that's a good question I don't have a good answer I guess
that that's not something we have looked too much into because only at the very late stages
we found out that it's not actually important anymore so our intuition before that was like
our model predicts a complete structure and it has to get everything right but our model is also
very stochastic so it basically learns a distribution over molecules and you can make some mistakes
there and we added this local adaptation step to really make up for this generative approach where
you and allow the model to make some small mistakes that's how we thought about it but
once you got a very good model and really learned how to transfer learn here we
we then observed that that it did not make that many mistakes anymore and it it was more certain as
well in which areas of the molecule space it wants to predict so it basically did this kind of
search itself that's that's that's how I would interpret it I guess but for hard cases then for for
very long molecules a very big molecules it cannot cannot do that very good still so there
you still want to allow the model to do some mistakes and have it explore around good regions I guess
one of the themes that comes up and pretty frequently in my interviews is this pendulum swinging
between traditional model based approaches to the world where you're you know we're solving
problems like this based on chemical or biological principles to more of a statistics based
approach and how in a lot of research the pendulum is kind of centering again where we're trying to
marry you know these model based approaches with the statistical based approaches is that
something that you could see an opportunity for here so your question is whether the more
traditional approaches for RNA design can be marriage with something like our approach in the
future to even get better performance essentially yes so so so I see potential in in using our
agent to produce a good initial guess for how the molecule should look like and then use more
traditional methods to then work with this initialization because a lot of the drawbacks way
of these traditional methods which are mostly search based are that it takes a lot of time to get
close to a good solution so if you can already get very close to a solution right from the start
like using our agent then then the drawbacks of the traditional approaches might not exist anymore
and I see a lot of opportunities there thanks so much for taking the time to chat with me it was
great chatting with you on about this stuff yeah it was my pleasure all right everyone that's our
show for today for more information on today's show visit twomolai.com slash shows make sure you
head over to twomolcon.com to learn more about the Twomolcon AI Platforms conference as always thanks
so much for listening and catch you next time
