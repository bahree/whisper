WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.880
people doing interesting things in machine learning and artificial intelligence.

00:20.880 --> 00:23.480
I'm your host Sam Charrington.

00:23.480 --> 00:28.040
A quick thanks to everyone who participated in last week's Twimble Online Meetup.

00:28.040 --> 00:29.960
It was another great one.

00:29.960 --> 00:35.480
If you missed it, the recording will be posted to the Meetup page at twimbleai.com slash

00:35.480 --> 00:36.480
meetup.

00:36.480 --> 00:37.880
Definitely check it out.

00:37.880 --> 00:43.680
I never cease to be amazed by the generosity and creativity of the Twimble community.

00:43.680 --> 00:48.480
And I'd like to send a special shout out to listener Sharon Glander for her exceptional

00:48.480 --> 00:50.200
sketch notes.

00:50.200 --> 00:55.120
Sharon has been creating beautiful hand sketch notes of her favorite Twimble episodes

00:55.120 --> 00:57.160
and sharing them with the community.

00:57.160 --> 01:00.400
Sharon, we truly love and appreciate what you're doing with those.

01:00.400 --> 01:02.920
So please keep up the great work.

01:02.920 --> 01:06.040
We'll link to her sketch notes in the show notes for this episode.

01:06.040 --> 01:11.440
And you should definitely follow her on Twitter at sharingglander for more.

01:11.440 --> 01:15.840
This is your last chance to register for the rework, deep learning and AI assistant

01:15.840 --> 01:22.200
summits in San Francisco, which are this Thursday and Friday, January 25th and 26th.

01:22.200 --> 01:26.600
These events feature leading researchers and technologists like the ones you heard in

01:26.600 --> 01:29.680
our Deep Learning Summit series last week.

01:29.680 --> 01:34.600
The San Francisco event is headlined by Ian Goodfellow of Google Brain, Daphne Kohler

01:34.600 --> 01:37.320
of Calico Labs and more.

01:37.320 --> 01:42.880
Definitely check it out and use the code Twimbleai for 20% off of registration.

01:42.880 --> 01:47.400
In this episode of the show, I host the largest group of guests I've ever had on a single

01:47.400 --> 01:48.560
podcast.

01:48.560 --> 01:55.760
I speak with Arthur Gretton, Wittowat Jekritam, Zoltan Zabo, and Kenji Fukumizu, who, alongside

01:55.760 --> 02:02.240
with Wenkai Shu, authored the 2017 Nipps Best Paper Award winner, a linear time kernel

02:02.240 --> 02:04.320
goodness of fit test.

02:04.320 --> 02:09.840
In our discussion, we cover what exactly a goodness of fit test is and how it can be used

02:09.840 --> 02:15.320
to determine how well a statistical model applies to a given real world scenario.

02:15.320 --> 02:19.960
The group and I then discuss this particular test, the applications of this work, as well

02:19.960 --> 02:24.640
as how this work fits in with other research the group has recently published.

02:24.640 --> 02:25.640
Enjoy.

02:25.640 --> 02:37.400
Alright everyone, I am in Long Beach, California at Nipps and I've got the stink pleasure

02:37.400 --> 02:42.960
of being seated with a group who is authored one of the Best Paper Award winners.

02:42.960 --> 02:48.080
Here at Nipps, it is by far the largest group that I've ever interviewed at one time on

02:48.080 --> 02:49.080
a podcast.

02:49.080 --> 02:56.560
So I'm going to allow them to introduce themselves and please name, role, title, affiliation,

02:56.560 --> 03:02.080
and maybe while you're at it, a little bit about your research and areas of interest.

03:02.080 --> 03:03.080
Thank you.

03:03.080 --> 03:04.080
So I'm Arthur Gretton.

03:04.080 --> 03:10.240
I'm a professor at the Gatsby Computational Neuroscience Unit at University College London.

03:10.240 --> 03:17.120
So my research interests, I generally know how to represent and compare probabilities.

03:17.120 --> 03:22.440
So on one hand, if you've got two groups of objects, you're trying to tell whether they're

03:22.440 --> 03:26.480
similar or different, that's one of the problems that we might address.

03:26.480 --> 03:27.480
Another is in reasoning.

03:27.480 --> 03:32.040
So if you're observing something that might have an effect on something else, you want

03:32.040 --> 03:37.120
to know how strong that effect is and how confident you are in whether that effect exists.

03:37.120 --> 03:38.120
Great.

03:38.120 --> 03:39.120
Thanks, Arthur.

03:39.120 --> 03:40.120
Hello.

03:40.120 --> 03:41.120
My name is Witowat Gretton.

03:41.120 --> 03:44.400
I'm from the Gatsby Unit University College London.

03:44.400 --> 03:48.320
I'm a PhD student studying computer science.

03:48.320 --> 03:54.200
So my interests are statistical tests, hypothesis testing, and a bit on Bayesian inference.

03:54.200 --> 03:55.200
Okay, great.

03:55.200 --> 03:56.200
Kenji.

03:56.200 --> 03:57.200
Hello.

03:57.200 --> 03:58.200
I'm Kenji Fukumizu.

03:58.200 --> 04:02.720
I'm a professor at the Institute of Statistical Mathematics in Tokyo.

04:02.720 --> 04:07.120
And I'm basically interested in statistics and the machine learning.

04:07.120 --> 04:13.120
And my interest is also ranging from the mathematical aspect of machine learning to the application

04:13.120 --> 04:14.600
of machine learning.

04:14.600 --> 04:15.600
Okay.

04:15.600 --> 04:16.600
Great.

04:16.600 --> 04:17.600
And Zaltan?

04:17.600 --> 04:18.600
Hello.

04:18.600 --> 04:22.520
I'm Zaltan Sable from C-MAP, Center of Applied Mathics, Equality Technique France.

04:22.520 --> 04:28.360
I'm a research associate professor, genuinely interested in information theory, connoe algorithms,

04:28.360 --> 04:34.880
how to define similarities between many different objects, graphs, time series, dynamical systems,

04:34.880 --> 04:40.640
vectors, and how to apply it in different information, theoretical context, including hypothesis

04:40.640 --> 04:41.640
testing.

04:41.640 --> 04:42.640
Okay.

04:42.640 --> 04:46.960
I want to tell us about the paper that you guys submitted.

04:46.960 --> 04:48.480
So I'm happy to do that.

04:48.480 --> 04:52.360
So the paper is a goodness of fit test.

04:52.360 --> 04:57.040
What this means is that we have some model of the world, and we want to tell whether that

04:57.040 --> 05:01.280
model reflects the world well or not, and if not, why not.

05:01.280 --> 05:06.440
So an example that we used in the talk was that if you have a model of where crime occurs

05:06.440 --> 05:11.000
in Chicago, you might want to know whether that model accurately predicts where the crime

05:11.000 --> 05:16.480
will occur, and if there is some shortcoming to the model, you might want to know where

05:16.480 --> 05:17.800
that is.

05:17.800 --> 05:22.240
As an example, we used a rather crude crime model, which was mistakenly predicting crimes

05:22.240 --> 05:26.120
in the lake next to the city where clearly there weren't any crimes.

05:26.120 --> 05:32.000
So this would automatically flag those, so there's no piracy at the moment in Chicago.

05:32.000 --> 05:34.920
So this is a specific instance.

05:34.920 --> 05:38.600
The difficulty we encounter with this is that if the model that you have of the world

05:38.600 --> 05:43.680
is very complicated, then it can be very difficult to compare this with data.

05:43.680 --> 05:49.200
So in our crime example, imagine trying to figure out whether it's likely that somebody's

05:49.200 --> 05:53.840
going to commit a crime or this is going to depend on their social network, on the state

05:53.840 --> 05:58.040
of the economy, on the political atmosphere, and so on.

05:58.040 --> 06:02.680
All of these things are very complicated and interact, so you can state what the interactions

06:02.680 --> 06:08.160
are, but then to figure out how these all combined to create a probability is impossible.

06:08.160 --> 06:10.520
It's just not mathematically feasible.

06:10.520 --> 06:15.440
Nonetheless, we might want to know when our test has difficulties and the way that we've

06:15.440 --> 06:21.640
formulated it, our test is able to decide on the, or to locate the mismatch between data

06:21.640 --> 06:27.840
and model without having to figure out these probabilities and do this impossible computation.

06:27.840 --> 06:29.800
And what was the title of the paper?

06:29.800 --> 06:36.040
So the title is a linear term, kernel goodness of fit test, linear time kernel goodness

06:36.040 --> 06:37.640
of fit test.

06:37.640 --> 06:45.000
How is this other standard set of goodness of fit test that folks would use otherwise?

06:45.000 --> 06:48.440
So in certain simple cases, there are goodness of fit test.

06:48.440 --> 06:53.520
So if you have a very simple model that you're comparing with like a simple Gaussian, then

06:53.520 --> 06:55.280
there are other goodness of fit tests.

06:55.280 --> 06:59.480
In the case of the Gaussian, we don't have this complexity that I mentioned where you

06:59.480 --> 07:05.120
have many interacting effects that make computing probabilities in close form impossible.

07:05.120 --> 07:11.800
So what we have tried to address is the case when these models are very complex.

07:11.800 --> 07:16.400
And what, out of curiosity, what brought you all together from disparate parts of the

07:16.400 --> 07:17.400
world?

07:17.400 --> 07:20.480
Yes, we are like frequent collaborators.

07:20.480 --> 07:22.920
So Zoltan used to be at Caspi unit.

07:22.920 --> 07:24.600
We worked together before.

07:24.600 --> 07:30.320
I and other also frequently visit Kenji at Institute of Statistical Mathematics, so kind

07:30.320 --> 07:33.080
of frequent collaborators.

07:33.080 --> 07:38.520
And so with the, you know, when I think about a best paper, you know, there are lots of

07:38.520 --> 07:44.640
reasons why a paper might win best paper, you know, brought applicability, elegance of

07:44.640 --> 07:50.560
the solution and others, you know, why do you think this paper was selected as one of

07:50.560 --> 07:52.000
the best papers for Nips?

07:52.000 --> 07:57.520
I think it's a combination of broad applicability and the analysis that comes with it.

07:57.520 --> 08:05.360
So one, I guess, key thread in modern machine learning is like the formulating generative

08:05.360 --> 08:07.640
models for complicated data.

08:07.640 --> 08:13.000
So one of the key research directions of DeepMind, for example, is reinforcement learning.

08:13.000 --> 08:18.240
They want an agent that is in a world and that is able to learn from that world.

08:18.240 --> 08:23.880
What this requires in practice to train it is a simulation of the world, which is very realistic.

08:23.880 --> 08:28.720
So one important, I guess, component of that is to know when your simulation of the world

08:28.720 --> 08:29.720
is not accurate.

08:29.720 --> 08:31.160
What is it missing?

08:31.160 --> 08:36.240
I think for this reason, a paper which is able to, like, troubleshoot these models of

08:36.240 --> 08:42.800
the world that people might use in practice is a very much interest across the community.

08:42.800 --> 08:49.760
I think sort of coupled with this sort of very applied, I guess, benefit is that we have

08:49.760 --> 08:51.160
some nice theory results.

08:51.160 --> 08:54.480
So one of the phrases in the title was linear time.

08:54.480 --> 08:59.440
So the time that it takes is no more than the time that it takes to sort of look at each

08:59.440 --> 09:00.440
item.

09:00.440 --> 09:02.760
Quadratic time means you sort of have to look at all pairs of items.

09:02.760 --> 09:04.520
So that becomes very expensive.

09:04.520 --> 09:10.240
So what another result that we showed in the paper is of the various ways that one could

09:10.240 --> 09:15.400
derive a linear time goodness of fit test with the properties that we've talked about,

09:15.400 --> 09:18.240
the way that we've proposed is provably better.

09:18.240 --> 09:23.400
So it's going to give you a test which has the number of true positives, I should say,

09:23.400 --> 09:28.040
is going to improve faster for this test and for the other alternatives.

09:28.040 --> 09:29.040
Yeah.

09:29.040 --> 09:34.840
When you say linear time, is it linear in the number of examples or the number of distributions

09:34.840 --> 09:38.040
that you're trying to fit to or linear in the number of examples?

09:38.040 --> 09:39.040
Okay.

09:39.040 --> 09:43.160
We have a single model, you know, our grand map of Chicago, and then we're looking, it's

09:43.160 --> 09:44.640
linear in the number of crimes.

09:44.640 --> 09:45.640
Okay.

09:45.640 --> 09:46.640
Okay.

09:46.640 --> 09:49.480
So what's the process for applying it?

09:49.480 --> 09:54.400
So this goodness, then this new goodness of fit test takes in two inputs.

09:54.400 --> 09:55.400
Okay.

09:55.400 --> 09:56.400
The first one is a model.

09:56.400 --> 09:57.400
Okay.

09:57.400 --> 10:00.720
For example, in the crime, Chicago crime example, the model, let's say we want to model

10:00.720 --> 10:05.960
spatial density of robbery events in Chicago, say, just going to be the model, then just

10:05.960 --> 10:07.360
some density function.

10:07.360 --> 10:09.680
The second input would be a collection of points.

10:09.680 --> 10:14.080
In this case, it's going to be observed robbery events where each point is just like

10:14.080 --> 10:17.840
the larger your language coordinate of one event, for example.

10:17.840 --> 10:23.960
And the way that this works is that the test constructs some function, it's essentially

10:23.960 --> 10:31.240
a scoring function that tells where the mismatch is between the model and the data.

10:31.240 --> 10:36.600
And once we have this scoring function, we can then use it to find sort of a region where

10:36.600 --> 10:38.640
the mismatch is the largest.

10:38.640 --> 10:42.640
And then we can pinpoint, okay, that is where there's a mismatch.

10:42.640 --> 10:45.800
And then this is how we criticize the model.

10:45.800 --> 10:50.400
So in the end, we would get a region indicating, okay, this is where the model doesn't fit quite

10:50.400 --> 10:51.920
well to the data.

10:51.920 --> 10:57.080
And then as a modeler, they can just improve the model based on the hints, on the evidence

10:57.080 --> 10:58.480
given by the test.

10:58.480 --> 11:00.520
So when you say region, region of what?

11:00.520 --> 11:03.880
We're not talking about a region of the map of Chicago, we're talking about a region

11:03.880 --> 11:04.880
of the map.

11:04.880 --> 11:07.480
Yeah, a physical region, actually.

11:07.480 --> 11:13.320
And does that correspond to, you know, if we're not talking about a map example, but it

11:13.320 --> 11:19.280
sounds like this applies more broadly, what's the generalization of a region?

11:19.280 --> 11:20.280
Right.

11:20.280 --> 11:25.600
So the technical term would be, it's going to be the domain where your data live in.

11:25.600 --> 11:28.720
So whatever that domain is, so I don't know.

11:28.720 --> 11:35.880
So typically, I guess if you have data, I'd represent it at a table, then you have many

11:35.880 --> 11:36.880
columns.

11:36.880 --> 11:41.200
I guess columns correspond to the number of features or the number of attributes.

11:41.200 --> 11:46.600
Then let's say your data live in Rd, where D is the number of columns, then that is going

11:46.600 --> 11:50.080
to be like the equivalent of the region that I mentioned.

11:50.080 --> 11:54.080
So it's going to identify regions in your feature space.

11:54.080 --> 11:55.080
In the feature space, yeah.

11:55.080 --> 11:56.080
Okay.

11:56.080 --> 11:57.080
Right.

11:57.080 --> 11:58.080
Okay.

11:58.080 --> 12:03.880
Let me give you maybe two other examples, because this paper is, in fact, part of a larger,

12:03.880 --> 12:07.880
let's say, a package of hypothesis tests in your time hypothesis tests.

12:07.880 --> 12:13.760
And we use this technology in, for example, computer vision or natural language processing.

12:13.760 --> 12:19.000
In the first case, you have, let's say, images of, let's say, happy or sad people.

12:19.000 --> 12:20.000
Okay.

12:20.000 --> 12:24.480
And then the question is whether you can detect the difference between the two emotions,

12:24.480 --> 12:29.960
or if there's difference, which, let's say, masses are responsible for this difference.

12:29.960 --> 12:30.960
Okay.

12:30.960 --> 12:37.640
So that's the domain, in this case, let's say, muscle activities or parts of the face.

12:37.640 --> 12:42.960
In the other application, natural language processing, we had, let's say, documents from

12:42.960 --> 12:48.800
two different topics, categories, like neuroscience, Bayesian inference.

12:48.800 --> 12:55.160
And then the question was, again, whether these two possibly different topics can be discriminated.

12:55.160 --> 12:58.840
And if this is the case, what are the keywords you should look at?

12:58.840 --> 13:03.040
In this case, that's the domain, what are the most distinguishing keywords?

13:03.040 --> 13:04.040
Mm-hmm.

13:04.040 --> 13:11.240
So in the case of the first example, you, in applying this result, you would identify, for

13:11.240 --> 13:14.000
example, regions of the face, that, what?

13:14.000 --> 13:17.160
That distinguish between the emotions or...

13:17.160 --> 13:18.320
Yeah, so that's right.

13:18.320 --> 13:23.920
So for instance, if you had sort of emotions that required you to frown or to, yeah, to

13:23.920 --> 13:27.760
put the sides of your mouth downwards, like you're unhappy, which causes the sort of lines

13:27.760 --> 13:32.320
on each side to stand out, these would be the regions, the spatial regions in the face,

13:32.320 --> 13:37.920
which distinguish the sort of contented emotions from the angry or upset emotions.

13:37.920 --> 13:42.080
So yeah, so the domain is sort of all of the possible regions in the face, just the spatial

13:42.080 --> 13:43.080
domain.

13:43.080 --> 13:47.200
And then the salient regions that matter in distinguishing them are the locations around

13:47.200 --> 13:50.720
the eyebrows and to each side of the nose and mouth.

13:50.720 --> 13:57.560
And so this, one of the areas that it sounds like this plays into is the domain of explainability

13:57.560 --> 13:59.160
of AI models.

13:59.160 --> 14:03.640
Is that one of the primary motivators as well for this research?

14:03.640 --> 14:08.880
I think so, yes, because, yeah, it's basically a way of showing the shortcoming of your model,

14:08.880 --> 14:11.880
like what it is that your model fails to explain about your data.

14:11.880 --> 14:17.680
So I think, yeah, explainability is really one of the, regions, I think that the paper

14:17.680 --> 14:20.200
was given the award, yeah.

14:20.200 --> 14:24.720
And we are using the more and the more complex model, the recent three, and so it's very

14:24.720 --> 14:33.000
important to, well, say that we are, that model correctly reflects our data, that's our

14:33.000 --> 14:34.000
motivation.

14:34.000 --> 14:38.760
And so what are the requirements of the model that would allow us to apply this?

14:38.760 --> 14:43.760
Is it applicable to like box set of models or do we need to know something about, you

14:43.760 --> 14:48.600
know, either the models or the distributions of our data or other things in order to apply

14:48.600 --> 14:50.640
this technique?

14:50.640 --> 14:53.120
So it does need to be a probabilistic model.

14:53.120 --> 14:59.520
So by contrast, one might think of these adversarial networks where there you might not have actually

14:59.520 --> 15:05.520
a model of the probabilities of the images that it's generating, if it's generating images.

15:05.520 --> 15:10.960
So what we do require is that we're able to, you know, write the model as something that,

15:10.960 --> 15:15.360
you know, if you were able to, like, to normalize it to take the sum over all possible states

15:15.360 --> 15:17.880
would be a valid probability.

15:17.880 --> 15:24.360
Some ways of generating data from randomness, just take the data and apply a bunch of transforms

15:24.360 --> 15:29.160
to it, but it's not clear how or if you could turn that into a probability of the outputs

15:29.160 --> 15:31.680
given the random noise that you fed in.

15:31.680 --> 15:36.440
We are only able to deal at this stage with the case where you have this, you know, thing

15:36.440 --> 15:40.200
that you could write as a probabilistic model, were you able to normalize it?

15:40.200 --> 15:41.200
Okay.

15:41.200 --> 15:47.160
And maybe taking a step back, what was the fundamental realization or innovation that

15:47.160 --> 15:49.560
kind of led you down the path that led to this paper?

15:49.560 --> 15:55.920
It sounds like it's all time you mentioned this paper is one in a series of works, but

15:55.920 --> 15:58.240
what inspired this particular result?

15:58.240 --> 16:00.720
Zoltan mentioned it was one of a sequence of works.

16:00.720 --> 16:03.680
So the first work was just in comparing sets of objects.

16:03.680 --> 16:08.080
So in Zoltan's example, sets of faces with positive and negative emotions.

16:08.080 --> 16:10.720
So notice that model never appeared in that description.

16:10.720 --> 16:15.720
It's just, I have set A set B and I want to know why and where these two sets are different.

16:15.720 --> 16:20.160
The second test in the series was a test of whether two things are dependent.

16:20.160 --> 16:26.040
So as an example, if you show to a human some movie, then their brain will be active in

16:26.040 --> 16:28.680
a way that depends on the movie that they're watching.

16:28.680 --> 16:33.000
And so this dependence, you see, can we take a step back and as you talk through each of

16:33.000 --> 16:37.960
these papers in this sequence, kind of what the key results were as well?

16:37.960 --> 16:38.960
Sure.

16:38.960 --> 16:45.000
So for the first paper, we were able to show again, a linear time test of where these two

16:45.000 --> 16:47.720
sets of objects were different.

16:47.720 --> 16:50.760
So again, it only costs me a time to compute.

16:50.760 --> 16:54.320
So that means the linear and the number of objects that we're comparing.

16:54.320 --> 16:59.240
And we were also given a diagnosis of where it was that the two sets were different.

16:59.240 --> 17:04.280
And so my first kind of flash intuition on this would be to try to do some kind of difference

17:04.280 --> 17:09.440
or something like that and maybe convolve the images together or something is, are you

17:09.440 --> 17:15.640
thinking about it in the same domain or more like from a pure probabilistic perspective

17:15.640 --> 17:16.640
or?

17:16.640 --> 17:20.480
So we need to think in terms of sets of objects rather than objects.

17:20.480 --> 17:27.000
So for example, if one looks at a pair of faces, you can take their difference and you

17:27.000 --> 17:28.960
can see where that difference occurs.

17:28.960 --> 17:33.560
If you have two sets, it can be that the mean is the same, but one set has a higher variance

17:33.560 --> 17:34.560
than the other.

17:34.560 --> 17:38.640
And so we care about any difference that might occur between two sets of objects.

17:38.640 --> 17:42.920
So the second paper was about dependence testing.

17:42.920 --> 17:47.240
And in this case, again, we have a linear time test.

17:47.240 --> 17:51.360
We also care about dependence that might be quite complicated.

17:51.360 --> 17:57.880
So the dependence that you might learn in statistics 101, you notice that when one thing increases,

17:57.880 --> 18:01.920
like, you know, I press down my accelerator, my cargo's fastest, linear dependence.

18:01.920 --> 18:06.280
What we might care about is dependence that is much more complicated than that.

18:06.280 --> 18:11.440
For example, like if you are adjusting a parameter on a robot arm, it might, on average, hit the

18:11.440 --> 18:12.440
same target.

18:12.440 --> 18:17.600
But it might be that if you under-damped the robot arm, it's half the time above the target,

18:17.600 --> 18:18.600
half the time below.

18:18.600 --> 18:21.360
So the variance is going up depending on this parameter, even though if you just looked

18:21.360 --> 18:23.640
at the means, you would get the same mean.

18:23.640 --> 18:28.600
So this, you know, this is a very trivial example, but illustrating this sort of complexity

18:28.600 --> 18:29.880
of dependence.

18:29.880 --> 18:34.840
So that's, you know, first of all, testing pairs of samples, second testing dependence.

18:34.840 --> 18:39.160
And then this led us to say, well, what if we don't have, you know, two sets of samples,

18:39.160 --> 18:42.040
but a sample in a model, what's the best way to approach that?

18:42.040 --> 18:43.560
And that led to our third paper.

18:43.560 --> 18:44.560
Okay.

18:44.560 --> 18:45.560
Great.

18:45.560 --> 18:46.560
Great.

18:46.560 --> 18:48.240
And does the sequence continue?

18:48.240 --> 18:50.880
What's next for the group of you?

18:50.880 --> 18:59.360
So one possible future work is that continuing from the third work, which is, so now that we

18:59.360 --> 19:02.000
have a model and we have one data set, right?

19:02.000 --> 19:06.600
But in practice, in reality, most of the time your model is probably wrong.

19:06.600 --> 19:09.600
And you know, a priori that it is, it is probably wrong.

19:09.600 --> 19:14.720
But now a more relevant question is given two models that are wrong, two competing models

19:14.720 --> 19:18.120
that are wrong, which one fits better?

19:18.120 --> 19:23.560
That is, this is now a model comparison instead of, so in the current version is model

19:23.560 --> 19:24.560
acquitticism.

19:24.560 --> 19:28.120
There's only one model when we try to criticize where it goes wrong.

19:28.120 --> 19:33.120
But now we can also extend to two models that we know are wrong, but we want to ask,

19:33.120 --> 19:34.440
okay, which one fits better?

19:34.440 --> 19:37.320
I think this is one possible direction.

19:37.320 --> 19:41.960
And then maybe which fits better where, as opposed to hiring, exactly, exactly, exactly.

19:41.960 --> 19:42.960
Exactly.

19:42.960 --> 19:44.640
That's what we are going to continue.

19:44.640 --> 19:45.640
Exactly.

19:45.640 --> 19:46.640
Nice.

19:46.640 --> 19:52.080
For the rest of you, any kind of parting words as we wrap up, there's another possibility

19:52.080 --> 19:53.280
of extension.

19:53.280 --> 19:58.760
So here, all these linear time tests, the underlying assumption is that the probabilistic model lies

19:58.760 --> 20:05.160
on essentially on vectors, like data machine, Euclidean vectors, which is possibly the simplest

20:05.160 --> 20:07.280
concept to understand.

20:07.280 --> 20:13.240
But one might argue maybe there are some dependencies between the coordinates somehow, so like if

20:13.240 --> 20:18.880
you, for example, think of graphs or like images, not all the pixels can vary completely

20:18.880 --> 20:20.400
in the pendants.

20:20.400 --> 20:27.600
So often there's some underlying load-dimensional structure in the background, hidden under

20:27.600 --> 20:28.600
the hood.

20:28.600 --> 20:32.600
So that's another possible direction to extend this framework.

20:32.600 --> 20:33.600
Awesome.

20:33.600 --> 20:35.840
Any other thoughts?

20:35.840 --> 20:37.600
How's Neb's been for everyone?

20:37.600 --> 20:38.600
Great.

20:38.600 --> 20:47.480
I'm very impressed by Neb's giving a word to this work because this is the age of artificial

20:47.480 --> 20:52.240
intelligence, and many people are looking at their application with deep learning, but

20:52.240 --> 21:01.280
our research is very basic ones, but we are using any method, we are using many complex

21:01.280 --> 21:08.320
models, and the model criticism is very important and basic research, and I'm very happy that

21:08.320 --> 21:12.760
Neb's gives respect to such type of basic work.

21:12.760 --> 21:17.360
And there was a call here at Neb's somewhat controversial call for kind of more basic

21:17.360 --> 21:20.960
work and more rigor in the way we look at machine learning.

21:20.960 --> 21:23.960
Any thoughts or comments on that?

21:23.960 --> 21:28.800
It sounds like you would all agree with that general idea.

21:28.800 --> 21:35.560
So there was an inspiring call to arms, which has caused a lot of discussion, and in a way,

21:35.560 --> 21:40.800
I think it's also a call to arms that is already being acted on in the sense that this

21:40.800 --> 21:46.080
year there has been a lot more thought about fundamentals of algorithms that are being

21:46.080 --> 21:49.040
used very successfully in the past two years.

21:49.040 --> 21:53.400
One example that was raised in this call to arms is understanding when you're optimizing

21:53.400 --> 21:59.000
a model with a huge number of parameters, as deep learning methods are, what the pathologies

21:59.000 --> 22:04.960
of these optimization methods are, when correlations cause you to converge very slowly or converge

22:04.960 --> 22:11.000
poorly, many of the, I guess, presentations by the optimization community, the SNPs were

22:11.000 --> 22:12.960
actually addressing that.

22:12.960 --> 22:17.960
So I think there was a standing ovation, as you know, when this call to arms was made.

22:17.960 --> 22:22.840
And I think that's because, like, the spirit of this Vali Rahimi's words was very much

22:22.840 --> 22:27.560
in the air that people were saying, OK, let's, we've got this amazing success on applications.

22:27.560 --> 22:34.120
Now let's understand what's still holding us back, and then that will help us to progress

22:34.120 --> 22:35.120
even further.

22:35.120 --> 22:36.120
Hmm.

22:36.120 --> 22:37.120
Great.

22:37.120 --> 22:42.120
Well, Arthur with Wat, Kenji, Zoltan, thanks so much for taking a few minutes to chat

22:42.120 --> 22:45.920
with us about your paper, and congratulations on the award.

22:45.920 --> 22:46.920
Thank you very much.

22:46.920 --> 22:48.920
Thanks, Zoltan.

22:48.920 --> 22:55.160
Alright, everyone, that's our show for today.

22:55.160 --> 23:00.240
Thanks so much for listening, and for your continued feedback and support.

23:00.240 --> 23:05.240
For more information on Arthur with Wat, Zoltan, Kenji, or any of the topics covered in this

23:05.240 --> 23:11.160
episode, head on over to twomlai.com slash talk slash 100.

23:11.160 --> 23:16.400
Of course, we'd be delighted to hear from you, either via a comment on the show notes page,

23:16.400 --> 23:22.960
or via Twitter, directly to me at At Sam Charrington, or to the show at At Twomlai.

23:22.960 --> 23:32.960
Thanks once again for listening, and catch you next time.

