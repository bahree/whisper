WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:28.720
I'm your host Sam Charrington.

00:28.720 --> 00:33.040
I want to send a quick thanks to our friends at Cloud Era for their sponsorship of this

00:33.040 --> 00:39.760
series of podcasts from the Stratidata conference, which they present along with O'Reilly media.

00:39.760 --> 00:41.960
Cloud Era is long been a supporter of the podcast.

00:41.960 --> 00:47.760
In fact, they sponsored the very first episode of Twimble Talk back in 2016.

00:47.760 --> 00:51.920
Since that time, Cloud Era has continued to invest in and build out its platform, which

00:51.920 --> 00:57.680
already securely hosts huge volumes of enterprise data, to provide enterprise customers with

00:57.680 --> 01:01.920
a modern environment for machine learning and analytics that works both in the cloud

01:01.920 --> 01:04.240
as well as in the data center.

01:04.240 --> 01:09.680
In addition, Cloud Era Fast Forward Labs provides research and expert guidance that helps enterprises

01:09.680 --> 01:14.080
understand the realities of building with AI technologies without needing the higher

01:14.080 --> 01:16.440
and in-house research team.

01:16.440 --> 01:19.840
To learn more about what the company is up to and how they can help, visit Cloud Era's

01:19.840 --> 01:32.080
machine learning resource center at cloudera.com slash ml.

01:32.080 --> 01:33.080
All right, everyone.

01:33.080 --> 01:35.080
I am on the line with Eric Colson.

01:35.080 --> 01:39.560
Eric is the chief algorithms officer at StitchFix.

01:39.560 --> 01:44.560
And Eric and I are here today to talk a little bit about some of the work the company's

01:44.560 --> 01:51.080
done around algorithms and organizing for success in data science.

01:51.080 --> 01:54.200
And I suspect some other stuff will come up as well.

01:54.200 --> 01:57.400
Eric, welcome to this week in machine learning and AI.

01:57.400 --> 02:01.560
It's fun to be here with you and thanks for having me on board.

02:01.560 --> 02:02.560
Absolutely.

02:02.560 --> 02:03.560
Absolutely.

02:03.560 --> 02:06.200
Why don't we start by learning a little bit about your background.

02:06.200 --> 02:11.320
You spent what, five or six years at Netflix before joining StitchFix.

02:11.320 --> 02:17.080
How did you kind of get started in data science and machine learning and kind of work your

02:17.080 --> 02:18.760
way to Netflix and StitchFix?

02:18.760 --> 02:19.760
I don't know.

02:19.760 --> 02:20.760
Okay.

02:20.760 --> 02:21.760
You want to go way back.

02:21.760 --> 02:23.920
Well, let's see.

02:23.920 --> 02:29.000
To be honest, data science is kind of what I wanted to do from the very beginning, even

02:29.000 --> 02:34.960
back 20 years ago, undergrad days, I'm not the closer to 25 now, that we didn't have

02:34.960 --> 02:36.760
the word data science back then.

02:36.760 --> 02:44.120
But when I majored in my undergrad was economics, and particularly micro economics was a passion

02:44.120 --> 02:45.120
of mine.

02:45.120 --> 02:47.960
I thought this is something that I wanted to do for companies, right?

02:47.960 --> 02:52.440
Go in there and it seems like such a, what I call a noble way to compete, to be used

02:52.440 --> 02:58.720
data and statistics and things to operate a business better more efficiently.

02:58.720 --> 03:02.680
And that's a win-win because it would be better for the consumers better for the company

03:02.680 --> 03:05.120
hence a noble way to compete.

03:05.120 --> 03:06.680
And I thought that'd be great.

03:06.680 --> 03:11.040
And so I learned as much as I could in my micro economics, I maybe took a few courses

03:11.040 --> 03:13.080
in statistics, but that was about it.

03:13.080 --> 03:21.160
I graduated and I got into the industry, into companies, I got a gig consulting, helping

03:21.160 --> 03:22.320
companies do this.

03:22.320 --> 03:27.200
And it turns out that micro economic stuff was pretty much all theory.

03:27.200 --> 03:30.920
Nobody was doing this stuff yet.

03:30.920 --> 03:35.360
You talk about being born at the right time, however, you know, right when I got out

03:35.360 --> 03:39.080
of undergrad was right when things were starting to turn.

03:39.080 --> 03:43.960
The stuff was still highly theoretical, but data was becoming available and the cost

03:43.960 --> 03:47.760
of the process it was becoming affordable.

03:47.760 --> 03:50.960
And so now you could actually start to do these things.

03:50.960 --> 03:56.120
Again, these were represented as graphs in economics textbooks.

03:56.120 --> 03:57.720
Nobody actually really did them.

03:57.720 --> 04:02.480
They were just kind of conceptual, but for the first time ever it was becoming possible.

04:02.480 --> 04:06.920
So it was kind of fun to be, you know, entering the workforce at exactly that moment where

04:06.920 --> 04:10.520
I got to do something that the time was very novel.

04:10.520 --> 04:16.720
But I learned sort of the hard way that economics did not properly prepare me for this.

04:16.720 --> 04:21.080
The required skills were sort of distributed into several fields.

04:21.080 --> 04:27.600
I mentioned statistics, there's also computer science and then more of a business domain

04:27.600 --> 04:29.640
expertise type of thing.

04:29.640 --> 04:32.920
And I found out that economics alone was just completely impractical.

04:32.920 --> 04:37.960
You needed, you know, the statistics to actually quantify the exact curves and the shapes

04:37.960 --> 04:41.920
of those curves and where points intersect, so we find the top of a curve that type of

04:41.920 --> 04:42.920
thing.

04:42.920 --> 04:47.720
And then to do anything, you need a computer science to process that data to allow those statistics

04:47.720 --> 04:50.000
to compute, et cetera.

04:50.000 --> 04:54.720
And then of course you needed domain expertise in the business, which I got through my consulting

04:54.720 --> 04:55.720
path.

04:55.720 --> 05:02.520
But my whole career has been that quest to kind of combine those three things all in the

05:02.520 --> 05:07.080
quest to do these micro economic type of models to put them into production and make them

05:07.080 --> 05:08.080
a reality.

05:08.080 --> 05:09.080
So that's my background.

05:09.080 --> 05:15.320
It goes back, you know, 25 years ago consulting and then, you know, going back to school to

05:15.320 --> 05:20.960
get better computer science skills and better statistic skills, et cetera.

05:20.960 --> 05:28.600
And sort of meandered across business domains to consulting later into the world of big

05:28.600 --> 05:32.880
data when I time at Yahoo or learning how to process petabytes of data.

05:32.880 --> 05:38.720
And then later when I got to Netflix actually putting things into production through algorithms

05:38.720 --> 05:44.440
actually having, you know, systems that would take automated action on things to actually

05:44.440 --> 05:48.360
do things in response to these micro economic trends and so forth.

05:48.360 --> 05:53.240
And so that was kind of my amalgam of stuff that I had to come together with.

05:53.240 --> 05:57.240
And then my latest thing is figuring out how to organize for this.

05:57.240 --> 06:01.440
So it's been a long road with a lot of things coming together nicely and again completely

06:01.440 --> 06:02.440
unplanned by my part.

06:02.440 --> 06:06.360
This was all just a silly quest to do these micro economic things.

06:06.360 --> 06:11.560
But along the path I got meds into different directions to acquire different skills and

06:11.560 --> 06:16.920
the experiences that kind of have all now culminated into where I am today.

06:16.920 --> 06:24.320
But you talk about micro economics and algorithms, at least the kinds of algorithms that we tend

06:24.320 --> 06:31.920
to see at companies like Yahoo and Netflix and StitchFix as almost one in the same.

06:31.920 --> 06:36.600
But I never hear that characterization as you know what we're trying to do is put micro

06:36.600 --> 06:39.080
economics into practice.

06:39.080 --> 06:45.160
You suppose there's any kind of unique perspective that your passion for micro economics and

06:45.160 --> 06:50.600
background in that field that you bring to data science?

06:50.600 --> 06:52.600
Yeah, because you're corrected.

06:52.600 --> 06:57.520
I believe the things like recommendation systems really were born out of schools of computer

06:57.520 --> 06:59.720
science as opposed to economics.

06:59.720 --> 07:05.160
But if you think about what they're doing is they're making an organization more efficient

07:05.160 --> 07:10.440
right, which is really micro economics is the classic micro economics which are the things

07:10.440 --> 07:13.600
that are in my textbooks where things like pricing efficiency.

07:13.600 --> 07:19.560
Figure out your base price elasticity and setting prices appropriately or more from the

07:19.560 --> 07:24.160
school of operations research how to run your operations more efficiently.

07:24.160 --> 07:31.320
And they all use the same concepts from math and statistics to and leverage data to materialize

07:31.320 --> 07:37.440
those concepts and then you take action them through automated means or algorithms.

07:37.440 --> 07:43.080
So all those things kind of I put under this kind of superheading of micro economics.

07:43.080 --> 07:47.880
And if those textbooks were written now, I think they could include things like recommendation

07:47.880 --> 07:50.280
systems because they are doing a similar thing.

07:50.280 --> 07:55.640
They're leveraging a company's internal asset data in order to be more efficient figuring

07:55.640 --> 07:58.520
out what to show different customers and say.

07:58.520 --> 08:01.360
You've been at Citrix for how long now?

08:01.360 --> 08:03.920
Coming up on seven years now.

08:03.920 --> 08:09.160
Yeah, it's a little I you know I first started actually as an advisor to the company and

08:09.160 --> 08:11.640
that was a little over seven years ago.

08:11.640 --> 08:13.600
I was at Netflix prior to this.

08:13.600 --> 08:19.680
So it was the VP of data science and engineering at Netflix for six or six and a half years.

08:19.680 --> 08:24.680
No interest in actually leaving Netflix, but I got a call and you get calls a lot, but

08:24.680 --> 08:26.800
Netflix, you're pretty busy.

08:26.800 --> 08:30.440
You work a lot of hours is hard and the company is a fast pace.

08:30.440 --> 08:35.480
And so you don't really participate in a lot of things outside of Netflix, so things

08:35.480 --> 08:36.480
like advising.

08:36.480 --> 08:41.000
So I would pretty quickly turn these things down and wouldn't even listen to most of them.

08:41.000 --> 08:45.320
But I do remember receiving a particular call from a venture capitalist was in the parking

08:45.320 --> 08:47.840
of Netflix trying to leave to go home.

08:47.840 --> 08:53.680
And I took the call and he told me about Citrix and its founder Katrina Lake, who's trying

08:53.680 --> 08:57.760
to do this interesting thing with clothing.

08:57.760 --> 08:59.480
And instantly it struck a chord.

08:59.480 --> 09:04.200
It was sort of a fortuitous timing that very day, some of the meetings I walked out of

09:04.200 --> 09:09.440
earlier that day, we were stumbling on some problems, things like more opportunities

09:09.440 --> 09:13.480
I should call them, you know, we talked about our recommendations as the meta Netflix.

09:13.480 --> 09:18.240
And you know, at the time most of the recommendations were there on the website as well as in the

09:18.240 --> 09:19.240
mobile app.

09:19.240 --> 09:23.920
But what we would do is we'd cast a wide net with the recommendations, because we're

09:23.920 --> 09:27.160
not that confident in what somebody wants to watch a meta predict for a moment.

09:27.160 --> 09:31.200
So on the website, you might be met with a hundred recommendations that want a hundred

09:31.200 --> 09:34.720
box shots of different movies and might be interested in.

09:34.720 --> 09:35.720
We used to joke.

09:35.720 --> 09:39.120
There's a product manager still at Netflix today that would joke, you know, if we are

09:39.120 --> 09:43.400
more confident in our recommendations, we wouldn't show so many a hundred.

09:43.400 --> 09:49.240
We would show maybe like five or even one if we're super confident in our recommendations,

09:49.240 --> 09:52.840
we could just play the very thing the person wants to see.

09:52.840 --> 09:56.480
And you can imagine that you open up the app and the very thing you wanted to see just

09:56.480 --> 09:57.480
starts playing.

09:57.480 --> 09:58.840
Now that would be bold.

09:58.840 --> 10:04.080
All right, so this was a conversation we had just had and I get the call about Citrix,

10:04.080 --> 10:06.840
which is doing this very thing, but with clothing, right?

10:06.840 --> 10:10.880
They're going to be so bold is not to actually just recommend the clothes to you, but they're

10:10.880 --> 10:13.800
rather going to ship them to your door side unseen.

10:13.800 --> 10:17.520
So I found that was interesting and, you know, hearing about their business model was

10:17.520 --> 10:20.200
very interesting.

10:20.200 --> 10:24.880
And you know, again, they caught me at the right timing that, you know, this sounds like

10:24.880 --> 10:28.080
something that I'd like to participate in, not as an employee.

10:28.080 --> 10:29.080
That sounds crazy.

10:29.080 --> 10:34.720
I'm not going to leave Netflix for this, you know, risky startup, but I'll be an advisor.

10:34.720 --> 10:37.680
And so I, well, even that didn't happen immediately.

10:37.680 --> 10:43.320
I had the first research Katrina, the founder, our CEO, which is very impressive on paper,

10:43.320 --> 10:46.000
but she hadn't run a company before.

10:46.000 --> 10:47.680
This was her first startup.

10:47.680 --> 10:52.480
And so, you know, I was actually even reluctant to even take the meeting with her because

10:52.480 --> 10:54.320
of time, I just never had time.

10:54.320 --> 10:59.600
But we finally ended up meeting up in San Francisco and we hit it off and once I met her

10:59.600 --> 11:06.720
in person, I realized there's a lot more thought put into this than I had first believed.

11:06.720 --> 11:09.120
And, you know, I was very inspired by her.

11:09.120 --> 11:11.160
And anyways, we made it happen.

11:11.160 --> 11:12.920
I became an advisor to the company.

11:12.920 --> 11:15.520
I still wasn't going to joke.

11:15.520 --> 11:19.640
And I last said, merely four or five months as a big advisor, one of the conditions of

11:19.640 --> 11:22.320
my advising is I needed access to the data.

11:22.320 --> 11:27.240
I wanted to be able to see what's going on in there and how, you know, the quality of

11:27.240 --> 11:31.360
the data, how predictive it can be, and what it could be useful with.

11:31.360 --> 11:36.120
And she complied and was able to access the data and I looked at things.

11:36.120 --> 11:38.640
And I never seen data like this before.

11:38.640 --> 11:42.880
It was like straight out of the textbook, those old, like those microeconomic textbooks,

11:42.880 --> 11:48.080
things that were supposed to be theory, where it's clear as day, the curves looked like

11:48.080 --> 11:53.120
the curves they're supposed to be had gouches, you had, you know, power laws, you had all

11:53.120 --> 11:56.920
the things right there staring at the face, you didn't even have to do much to reveal

11:56.920 --> 12:00.840
that we just kind of query the data in there, it was presented to you and a lot of this

12:00.840 --> 12:01.840
is fun.

12:01.840 --> 12:06.120
There's a lot of predictive power once you have that data that's so well behaved and I

12:06.120 --> 12:11.120
loved explaining the novel and so I get hooked on this data pretty quickly over my four

12:11.120 --> 12:12.120
months of the advisor.

12:12.120 --> 12:15.160
I'm supposed to be spending like an hour a month with the company.

12:15.160 --> 12:16.160
That's my contract.

12:16.160 --> 12:20.840
I was spending more like 25 hours a month, just tinkering and again, I'm a busy guy.

12:20.840 --> 12:25.560
I had things going on at Netflix, but I found the time to tinker with this stuff and I

12:25.560 --> 12:26.560
got hooked.

12:26.560 --> 12:30.640
The other thing that happened over this four or five months as an advisor is I had my

12:30.640 --> 12:32.040
wife try the service.

12:32.040 --> 12:37.960
It was women only at the time, so I had my wife try it and a few of the ladies in my neighborhood

12:37.960 --> 12:38.960
try.

12:38.960 --> 12:43.120
Of course, they try it the first time because I asked them to, but I watched them and I

12:43.120 --> 12:49.080
watched how the anticipation when they're waiting to receive their fix, their shipment

12:49.080 --> 12:53.480
and I watched the joy as they open these things and I watched how they talked about how

12:53.480 --> 12:58.880
it made them feel and then I watched most importantly how it changed their behaviors.

12:58.880 --> 13:00.960
All of a sudden they stop going to stores.

13:00.960 --> 13:05.800
This becomes their primary means of shopping and this is something Katrina tried to tell

13:05.800 --> 13:09.640
me from the very beginning to say, we're going to change the way people shop and I thought

13:09.640 --> 13:14.440
that was just a founder aspiration and I go, that's great, you should believe that because

13:14.440 --> 13:15.440
you're the founder.

13:15.440 --> 13:19.520
I don't want to believe it because I'm just an advisor, but I found that she was not

13:19.520 --> 13:24.760
just one smoke, she meant it and it took me five months and staring at data to be convinced

13:24.760 --> 13:30.480
of it and seeing some anecdotal examples of my wife and neighborhood ladies to really

13:30.480 --> 13:31.480
find it compelling.

13:31.480 --> 13:36.680
I said, wow, she's onto something and that's when I approached Katrina, who's August of 2012

13:36.680 --> 13:42.000
is, hey, Katrina, if you'll have me in as an employee, I'd love to do this.

13:42.000 --> 13:45.800
We figured out how to make that work and it's been a fun ride ever since.

13:45.800 --> 13:47.680
Oh, what a great story.

13:47.680 --> 13:55.040
So since then, you've done quite a bit with algorithms and data science at StitchFix.

13:55.040 --> 14:00.560
Can you kind of give us an overview of the different ways that data science plays out

14:00.560 --> 14:02.040
within StitchFix?

14:02.040 --> 14:07.320
Yeah, so StitchFix, the fun thing is, is we found these applications of data science

14:07.320 --> 14:08.920
throughout the company.

14:08.920 --> 14:13.720
So what had originally started is the most ostensible thing we could do is a recommendation

14:13.720 --> 14:14.720
system, right?

14:14.720 --> 14:18.600
We're going to be picking out clothes for people and we're going to be paying, you know,

14:18.600 --> 14:20.720
this is the start contrast to Netflix.

14:20.720 --> 14:24.520
Netflix, we recommend things just digitally, bits and bytes, we recommend things through

14:24.520 --> 14:30.640
a web page or a map, but with StitchFix, we're actually going to send it to you, right?

14:30.640 --> 14:35.440
So we need to pay the shipping to get it to your house and that is expensive, right?

14:35.440 --> 14:39.440
So we got the shipping in both directions we're paying for, plus that cost of the physical

14:39.440 --> 14:43.400
inventory being unavailable to other clients for a period of time, right?

14:43.400 --> 14:47.840
So this is getting expensive, plus we have a much bigger investment on the part of our

14:47.840 --> 14:49.480
client, right?

14:49.480 --> 14:53.400
So our client is expecting a very relevant box of clothes.

14:53.400 --> 14:56.520
She's going to be very upset if we get this wrong.

14:56.520 --> 15:00.360
Contrast to Netflix, people, you know, there's going to be recommendations that happen, but

15:00.360 --> 15:01.560
it's sort of a shoulder shrug.

15:01.560 --> 15:06.120
You move on, you know, as a consumer or a client at Netflix, you know, that's weird.

15:06.120 --> 15:07.120
Why are you recommending that?

15:07.120 --> 15:08.120
And you move on.

15:08.120 --> 15:12.080
And on Netflix, I didn't really cost them much on that, at least on the margin for an

15:12.080 --> 15:15.160
incremental bad recommendation, not a big deal.

15:15.160 --> 15:20.880
Of course, an aggregate, it could be pretty bad, but on the margin, not a big deal.

15:20.880 --> 15:26.520
So Citrix has this interesting nuance that, oh, we're actually, we have bigger penalties

15:26.520 --> 15:27.520
for getting it wrong.

15:27.520 --> 15:29.520
And it turns out this is a good thing.

15:29.520 --> 15:32.560
This makes you pay attention as an algorithm developer.

15:32.560 --> 15:38.120
You want a penalty so that you really have to, you have the screen incentive to get it

15:38.120 --> 15:39.120
right.

15:39.120 --> 15:42.560
You don't want the penalties to be too high because then you won't take any risk.

15:42.560 --> 15:44.880
And that's why you get them like financial loans, right?

15:44.880 --> 15:50.280
They don't want a single default that ever happened because while the defaults will

15:50.280 --> 15:55.960
probably evoke great learnings, it's still very costly, it could be $50,000.

15:55.960 --> 16:00.600
So Citrix is right in a sweet spot with our recommendations, the penalties are severe.

16:00.600 --> 16:03.600
You don't want to have many of them, but not so severe they're not going to take any

16:03.600 --> 16:04.600
risk.

16:04.600 --> 16:05.800
You want to learn, they'll do those things.

16:05.800 --> 16:08.760
So okay, this is interesting now.

16:08.760 --> 16:13.200
And so we started, you know, again, this was the most obvious thing we can do is start

16:13.200 --> 16:16.120
to build a recommendation engine.

16:16.120 --> 16:17.120
And we've done that.

16:17.120 --> 16:19.440
We did that from the very beginning and it was great.

16:19.440 --> 16:23.600
We started out with very simple methods and started getting more and more leverage.

16:23.600 --> 16:25.920
Of course, we have a new ones with our humans in the loop.

16:25.920 --> 16:31.200
We also have stylists because there's things that machines can't do, things like empathizing

16:31.200 --> 16:33.280
and relating to other humans, right?

16:33.280 --> 16:38.160
So we still need that, but we need machines to do all the things that are more quantitative

16:38.160 --> 16:39.440
and paracol.

16:39.440 --> 16:42.760
And so there's this whole challenge of combining those two different process.

16:42.760 --> 16:45.920
There's machine hardware with human hardware.

16:45.920 --> 16:49.320
And so we've figured out how to do that over the years.

16:49.320 --> 16:54.480
But that was just our initial foot in the water on algorithms.

16:54.480 --> 16:59.240
We quickly learned that there's a whole bunch of other things we can do.

16:59.240 --> 17:04.400
And things like inventory management algorithms, things like demand forecasting algorithms,

17:04.400 --> 17:06.200
things like escalation algorithms.

17:06.200 --> 17:10.000
Or even, we even have algorithms that are designing the closed now.

17:10.000 --> 17:15.400
So the algorithms proliferated and we can talk about how that happens in a pit.

17:15.400 --> 17:20.640
But we now have several dozen algorithmic capabilities that are running various parts

17:20.640 --> 17:22.040
of the company.

17:22.040 --> 17:24.200
And not much of it was planned for.

17:24.200 --> 17:27.320
They all sort of emerged kind of naturally.

17:27.320 --> 17:30.280
And so I can't take credit for planning this all out.

17:30.280 --> 17:35.680
This was having the right people around and the right motivations for them to figure

17:35.680 --> 17:38.680
this stuff out, not eating without being asked to.

17:38.680 --> 17:42.000
So a lot of these things that you'll see on that algorithms tour, if you go check that

17:42.000 --> 17:48.360
out, they just emerged on their own, not driven by top down processes.

17:48.360 --> 17:51.480
And that's the conversation that we'll get into in a bit.

17:51.480 --> 17:57.520
But I want the main thing to convey now is that it's not just the recommendation system.

17:57.520 --> 18:01.600
We have over a hundred algorithm developers at StitchFix and we only have about seven

18:01.600 --> 18:03.520
that are working on the recommendation system.

18:03.520 --> 18:07.360
And the other 93 are doing other types of algorithms that are equally important.

18:07.360 --> 18:09.440
They're just a little bit more behind the scenes.

18:09.440 --> 18:15.560
They're not ostensible to the outside world as much as our recommendation system is.

18:15.560 --> 18:17.440
And you mentioned the algorithms tour.

18:17.440 --> 18:23.920
That's a post that you put up on the StitchFix blog a couple of years back.

18:23.920 --> 18:27.840
And we will link to that in the show notes so folks can check it out.

18:27.840 --> 18:30.080
It's definitely pretty interesting.

18:30.080 --> 18:37.280
But when you think about these hundreds of algorithms, how do you think about them from

18:37.280 --> 18:40.840
a portfolio and value perspective?

18:40.840 --> 18:49.640
Is the recommendation system kind of the big value driver and then you've got a bunch

18:49.640 --> 18:59.360
of low hanging fruit smaller systems or are there other kind of big value drivers in there?

18:59.360 --> 19:03.840
How do you think about that algorithmic landscape, if you will?

19:03.840 --> 19:04.840
Well, you can see.

19:04.840 --> 19:11.960
So there are ones that are equally valuable to even a recommendation system.

19:11.960 --> 19:15.240
And there are smaller ones, bigger ones, etc.

19:15.240 --> 19:16.400
So they're kind of all of them out.

19:16.400 --> 19:20.200
Now they are nicely, most of the time, nicely quantifiable.

19:20.200 --> 19:24.360
You can do things like A, B, Testum to find out what would happen in the absence of their

19:24.360 --> 19:29.440
presence and you can find out what they're worth to the company.

19:29.440 --> 19:34.600
That's how most of them emerge as we can say things like, we develop this new algorithm.

19:34.600 --> 19:38.120
And if we use it, it will generate X.

19:38.120 --> 19:39.920
So it becomes what we call no-brainer.

19:39.920 --> 19:45.520
There's no cost or the cost has already been born and we know the value.

19:45.520 --> 19:46.720
That's what you call no-brainer.

19:46.720 --> 19:53.280
Of course, we're going to push that to production and get the benefits.

19:53.280 --> 19:57.360
To give you a little more context of some of the value it's driving, so you have things

19:57.360 --> 20:01.320
like inventory algorithms that manage the inventory or buying algorithms.

20:01.320 --> 20:02.720
So we do hold inventory.

20:02.720 --> 20:07.520
So what happens is we buy things at wholesale, sell them at retail, right?

20:07.520 --> 20:11.680
Same business model that's existed for hundreds of years, but we do it more efficiently.

20:11.680 --> 20:16.920
So when we buy things at wholesale, we need to decide what to go buy.

20:16.920 --> 20:20.600
And we crudely break it into two classes of purchases.

20:20.600 --> 20:25.280
We'll be called rebuys, things that we've had some experience before, such as dresses

20:25.280 --> 20:29.440
and jeans and things that we've actually tried out in the past, and we've got data on

20:29.440 --> 20:30.440
it now.

20:30.440 --> 20:33.360
So those things can be managed algorithmically.

20:33.360 --> 20:37.440
And so we have an algorithm that says what to go buy.

20:37.440 --> 20:40.960
And that is tremendously valuable.

20:40.960 --> 20:44.440
I hadn't had an appreciation of this before working in retail.

20:44.440 --> 20:47.960
I've heard from others that hadn't worked in retail about what a challenge it says,

20:47.960 --> 20:51.560
but I didn't have the appreciation until I got to live and breathe it.

20:51.560 --> 20:53.360
Buying is tricky.

20:53.360 --> 20:58.000
Buying your merchandise is one of the most critical things you can do for a company, right?

20:58.000 --> 20:59.560
This is your big capital outlay.

20:59.560 --> 21:03.680
You're going to buy this inventory and then you're going to sell it.

21:03.680 --> 21:06.680
And if it doesn't sell, you're stocked with a lot of inventory.

21:06.680 --> 21:10.040
And if you buy the wrong sizes of stuff, it could be way off, right?

21:10.040 --> 21:16.400
So most companies, most retailers buy this kind of standard distribution of sizes, you

21:16.400 --> 21:19.480
know, you have things like extra small, small, medium, large, and extra large.

21:19.480 --> 21:24.040
And you get like a bell shaped curve over that, you know, the quantity you're going to

21:24.040 --> 21:25.040
buy.

21:25.040 --> 21:29.480
But it turns out that that's not necessarily what's going to get sold.

21:29.480 --> 21:33.840
And so rather than buy in a traditional bell shaped curve, we'll buy in the distributions

21:33.840 --> 21:36.040
that are clients exhibit.

21:36.040 --> 21:41.640
So in some cases, we may choose to get no extra large at all in some particular bios

21:41.640 --> 21:45.040
because we've learned that it doesn't fit well.

21:45.040 --> 21:51.240
Or we'll buy twice as many smalls as mediums because we know that our clients will demonstrate

21:51.240 --> 21:52.400
that behavior.

21:52.400 --> 21:57.640
And so this is really a lot more efficient when you can buy the right things that you know

21:57.640 --> 22:00.480
we're going to sell in the right amount of time.

22:00.480 --> 22:05.520
And so again, we use a myriad of algorithms and some of them were borrowed from the area

22:05.520 --> 22:11.880
of Operation Research to figure out how frequently to buy things, what quantities to buy in,

22:11.880 --> 22:16.440
and what overall distributions of what we call an assortment to buy.

22:16.440 --> 22:22.200
And this makes a humongous difference in providing value to our clients and to our economic

22:22.200 --> 22:23.680
sense, the checks.

22:23.680 --> 22:30.280
Now as you describe these hundreds of algorithms or 800 algorithms constantly at work at Stitch

22:30.280 --> 22:37.320
Fix, I'm thinking of, it calls to mind for me, you know, these hundreds of individual

22:37.320 --> 22:44.120
applications and is there a common operating system that all of these applications run

22:44.120 --> 22:45.120
on?

22:45.120 --> 22:53.360
Can you speak a little bit to the way you support the different algorithmic efforts from

22:53.360 --> 22:55.360
a technology perspective?

22:55.360 --> 22:56.360
Right.

22:56.360 --> 23:03.320
So that is a critical point of success for any algorithms team is to have a great algorithms

23:03.320 --> 23:05.040
platform team.

23:05.040 --> 23:08.920
And so we have that, they're also part of the department, right, so they're not a separate

23:08.920 --> 23:15.480
team, they're within us and they call them data platform or algorithms platform.

23:15.480 --> 23:20.560
And these folks are a little bit more computer science oriented.

23:20.560 --> 23:24.080
They're great generalizers, they'll build things that run that algorithm or that algorithm

23:24.080 --> 23:25.080
or that one, right.

23:25.080 --> 23:26.360
So they know how to generalize things.

23:26.360 --> 23:31.960
They also build the infrastructure that runs all the algorithms as well as other tooling

23:31.960 --> 23:39.280
like, you know, job schedules and job sequencers, things that will handle data distribution.

23:39.280 --> 23:43.160
What they're doing is encapsulating all the things that are more computer sciencey in

23:43.160 --> 23:47.880
nature so that the data scientists don't need to worry about them as much, right.

23:47.880 --> 23:53.760
They can go focus most of their time on science and statistics and math and they don't

23:53.760 --> 24:00.400
need to know the innards of containerization, for example, or parallel processing.

24:00.400 --> 24:05.320
So that can be encapsulated for them so they can get back to working on science.

24:05.320 --> 24:08.080
And so that has been a wonderful compliment.

24:08.080 --> 24:11.080
And again, having them as part of the same team is key.

24:11.080 --> 24:14.600
That way they can adopt the same priorities and values.

24:14.600 --> 24:20.520
And we come up with a much better solution, sort of a mantra we use at Cishfix, an algorithms

24:20.520 --> 24:22.480
team is no handoffs.

24:22.480 --> 24:27.640
So we don't want to hand off things between teams and so we want to build and design the

24:27.640 --> 24:29.360
rules for autonomy.

24:29.360 --> 24:35.360
And so when you think about our algorithms platform, a lot of people mistakenly think, oh,

24:35.360 --> 24:36.360
you know, I get it.

24:36.360 --> 24:38.600
They're the data engineers that build the pipelines for the data scientists.

24:38.600 --> 24:39.600
Like, no, that's not true.

24:39.600 --> 24:41.840
They build the data platform.

24:41.840 --> 24:45.840
The data scientists have to build their own data pipelines, but they can run them on

24:45.840 --> 24:46.840
the platform.

24:46.840 --> 24:48.760
So it is a platform of a mature sense.

24:48.760 --> 24:50.080
And it's all homegrown.

24:50.080 --> 24:57.280
We're, of course, in the cloud and AWS and we've, you know, we've found as much as

24:57.280 --> 25:01.520
we can promote this community spark and all the usual players are in there.

25:01.520 --> 25:05.200
And then we've augmented with our own stuff as we've needed to.

25:05.200 --> 25:11.600
And so that was maybe a side door segue and they're talking about organizations and the

25:11.600 --> 25:19.840
way you organize data science, a part of that being have a team that supports them from

25:19.840 --> 25:22.080
a platform perspective.

25:22.080 --> 25:27.240
What are some of the other things that you've learned from an organizational perspective

25:27.240 --> 25:32.520
that have contributed to the success of the data science team there?

25:32.520 --> 25:37.160
Yeah, there's a few things that we've learned over the years.

25:37.160 --> 25:40.000
Roughly, I'll put them into three big buckets.

25:40.000 --> 25:44.720
They are have your own department, reporting to the CEO.

25:44.720 --> 25:51.880
Second, when it comes down to individual roles of the data scientist, we tend to leverage

25:51.880 --> 25:55.920
what we call data science generalist or full stack data scientist.

25:55.920 --> 26:03.320
And then finally is more of a statement about how process we prefer a more bottoms of

26:03.320 --> 26:05.520
approach versus central planning.

26:05.520 --> 26:07.480
So we can go into each of those.

26:07.480 --> 26:12.600
Let's start with our own department, reporting to the CEO.

26:12.600 --> 26:16.920
Now this isn't something I would say I would endorse for every company, but when data

26:16.920 --> 26:22.560
science is part of your competitive differentiation, then you want to take it seriously and give

26:22.560 --> 26:27.040
it its own department, reporting to the CEO, whatever your differentiation is, you want

26:27.040 --> 26:30.040
to make it its own department, reporting to the CEO.

26:30.040 --> 26:35.200
Because in that way, you get to develop your own tooling and workflows, ways of working

26:35.200 --> 26:36.200
right.

26:36.200 --> 26:38.880
Data science is not like any other field, right?

26:38.880 --> 26:39.880
It's not like engineering.

26:39.880 --> 26:41.600
It's not like marketing or product.

26:41.600 --> 26:43.920
It has its own way of working.

26:43.920 --> 26:49.280
The biggest distinction is that most of its capabilities when you design a data product

26:49.280 --> 26:52.520
or an algorithmic product, it usually can't be designed.

26:52.520 --> 26:56.160
Up front, it needs to be learned as you go.

26:56.160 --> 27:01.320
And this warrants a very different work style, and it's one that just doesn't fit into

27:01.320 --> 27:06.120
a lot of engineering workflows or marketing or others.

27:06.120 --> 27:10.200
And so if it's tucked, if you have your data science team tucked under a different department

27:10.200 --> 27:16.000
like that, it'll be forced to inherit the work style of the parent organization.

27:16.000 --> 27:18.760
And so that won't work for data science.

27:18.760 --> 27:22.600
I think it needs to have its own ethos and ways of working.

27:22.600 --> 27:24.840
And so you've got to make it its own.

27:24.840 --> 27:33.200
Now, to be clear, when you say these projects need to be learned, we're not talking strictly

27:33.200 --> 27:34.200
about machine learning.

27:34.200 --> 27:37.040
We're talking about learning in the broader sense.

27:37.040 --> 27:38.040
Is that right?

27:38.040 --> 27:39.040
That's correct.

27:39.040 --> 27:43.320
I mean, even inherent to machine learning, there is uncertainty, right?

27:43.320 --> 27:44.840
You don't know if this thing's going to work or not.

27:44.840 --> 27:48.720
You may think, well, gosh, it'd be great if we can develop an algorithm to do whatever

27:48.720 --> 27:53.400
and you may find that at least what the data you have, there's no predicted power.

27:53.400 --> 27:56.400
So it's not going to help, right?

27:56.400 --> 27:57.960
So that does happen.

27:57.960 --> 28:02.080
But even when you have success, you found predictive capabilities within your data and

28:02.080 --> 28:05.240
you start to build your algorithm.

28:05.240 --> 28:10.000
Oftentimes, each individual parameter or even the type of model or even the hyper parameters

28:10.000 --> 28:12.320
that all need to be learned, right?

28:12.320 --> 28:14.200
You can't design them up front.

28:14.200 --> 28:19.840
You get any to try things in the data and see what it tells you and then iterate and

28:19.840 --> 28:20.840
go back.

28:20.840 --> 28:26.000
Often, there's a lot of feature engineering that is done through trial and error.

28:26.000 --> 28:32.600
Like you make your best attempt in your first pass and then you learn something by looking

28:32.600 --> 28:37.400
at the results of trying that feature in a model and you're saying, wow, it must be

28:37.400 --> 28:39.920
something different than I had originally thought.

28:39.920 --> 28:43.360
I'm going to try it this way now and you keep going and iterating.

28:43.360 --> 28:46.280
And then you usually find a bunch that doesn't know the things that you didn't anticipate

28:46.280 --> 28:48.760
trying at all in the process, right?

28:48.760 --> 28:54.040
So it's a heavy iterative process to develop an algorithm.

28:54.040 --> 28:57.280
It's not something that you spec out and hand off to somebody else.

28:57.280 --> 28:58.280
It's a, here you go.

28:58.280 --> 28:59.280
Here's your algorithm.

28:59.280 --> 29:00.280
I'll just go implement it.

29:00.280 --> 29:03.920
Now, you have to kind of learn it as you go.

29:03.920 --> 29:08.560
And so this is something that when you have a property like that where it can't be designed

29:08.560 --> 29:13.320
up front, then you're going to want to organize very differently and that's where

29:13.320 --> 29:17.720
we get into that full stack data scientist.

29:17.720 --> 29:24.840
The full stack data science thing is a, you know, it's sort of a, it's a generous role

29:24.840 --> 29:30.440
as opposed to way a lot of other companies are doing things specializing their data science

29:30.440 --> 29:31.440
teams.

29:31.440 --> 29:37.560
We got like data engineering or ML engineering or inference engineer or research scientist

29:37.560 --> 29:45.200
and each plays a smaller part and a big collection of capability where all those things need

29:45.200 --> 29:47.720
to come together as a single capability.

29:47.720 --> 29:51.960
But you got the different pieces farmed out to different specialists and it, we do that

29:51.960 --> 29:53.800
because it makes a lot of sense to us.

29:53.800 --> 30:00.160
We learned from Adam Smith and we were taught that, oh, you know, we get these process efficiencies

30:00.160 --> 30:03.560
due to the division of labor and it sounds really good.

30:03.560 --> 30:07.280
But how many works when you know exactly what it is you're building, right?

30:07.280 --> 30:11.680
And you have specs that are crystal clear down to the millimeter of precision, then you

30:11.680 --> 30:13.640
can divide and conquer like that.

30:13.640 --> 30:18.120
But when you need to learn as you go, you have to rely on iteration and the challenge

30:18.120 --> 30:21.680
with specialists is they have a high coordination cost.

30:21.680 --> 30:25.600
It's a lot more expensive to coordinate in multiple people than it is just one.

30:25.600 --> 30:30.360
Even worse, even more nefarious than those coordination costs are a wait times.

30:30.360 --> 30:32.480
This is the time in between work.

30:32.480 --> 30:37.920
So let's suppose you have a data engineer that builds a new data pipeline and, you know,

30:37.920 --> 30:43.400
maybe a research scientist is now going to construct a model from that data.

30:43.400 --> 30:47.920
And the research scientist says, well, she discovers that, oh, she needs a few more features

30:47.920 --> 30:49.920
that are not manifest in the data.

30:49.920 --> 30:53.720
So she goes back to the data engineers and you add these things in.

30:53.720 --> 30:57.200
Data engineer says, yes, I can, but I'm busy on a different project right now.

30:57.200 --> 30:59.360
I'll get back to you next week.

30:59.360 --> 31:05.920
And so a week goes by and it may have only been a few hours of work to add the new features,

31:05.920 --> 31:07.320
but a week goes by.

31:07.320 --> 31:11.960
So that's a week of wait time for what is just a few hours of work.

31:11.960 --> 31:13.640
And that is expensive.

31:13.640 --> 31:18.720
And that's the cost of specialization is you're coordinating these disparate resources that

31:18.720 --> 31:24.040
all work on other projects because they're specialists and you end up with long gaps in

31:24.040 --> 31:25.560
between the work.

31:25.560 --> 31:31.040
And it's very costly, especially when you benefit so much from learning and iteration.

31:31.040 --> 31:35.280
So that's the reason we don't do the data science specialist roles instead.

31:35.280 --> 31:41.280
We do the full stack data scientists that can take the initiative from conception, you

31:41.280 --> 31:46.120
know, coming up with the idea and framing the problem to doing the modeling, to doing

31:46.120 --> 31:50.440
the data engineering, to even putting it in production.

31:50.440 --> 31:55.080
One person to or one are very few people to go through all those steps.

31:55.080 --> 32:00.520
We find is a lot more effective than dealing with other coordination costs than wait times.

32:00.520 --> 32:11.200
One of the perhaps most prominent trends in organizing data science efforts, and you spoke

32:11.200 --> 32:16.320
to this, but is that aspect of specialization?

32:16.320 --> 32:22.440
I feel like, you know, when we first started talking about this, whatever, 10 years ago,

32:22.440 --> 32:27.360
someone was looking for kind of this unicorn data scientist, and maybe you can talk about

32:27.360 --> 32:32.000
if that's the same or different than a full stack data scientist, but everyone was looking

32:32.000 --> 32:38.160
for this unicorn that knew the business, knew the stats, knew how to code.

32:38.160 --> 32:44.480
And in a lot of ways, I think part of the progress that we've made is splitting out these skill

32:44.480 --> 32:54.560
sets and allowing for some of that specialization so that, you know, we don't have to find these

32:54.560 --> 33:01.840
kind of Swiss Army knife ninja, whatever's that can do everything.

33:01.840 --> 33:07.360
And as the most recent element of that, you know, we've seen the, you know, for the past

33:07.360 --> 33:15.080
two years, this role of machine learning engineer has really kind of taken off.

33:15.080 --> 33:19.360
And that is someone that kind of knows the machine learning stuff, you know, well not

33:19.360 --> 33:26.240
as much as maybe a research scientist or someone, or not as deeply as a research scientist

33:26.240 --> 33:31.160
or someone that has, you know, the statistical background, but knows how to build systems

33:31.160 --> 33:37.640
with it and can also code, you know, in a production ready way.

33:37.640 --> 33:44.280
And you know, that seems to have driven a lot of the scale at some of the companies that

33:44.280 --> 33:48.160
are really heavily invested in machine learning and data science.

33:48.160 --> 33:53.840
And I'm wondering are there things that you, in particular that you kind of attribute

33:53.840 --> 33:55.360
your different way of seeing things?

33:55.360 --> 34:00.480
Is it an issue of scale or your team smaller than, you know, the teams at some of the companies

34:00.480 --> 34:06.960
that are taking a more specialized approach or, you know, is it just a fundamentally different

34:06.960 --> 34:10.960
way of looking at kind of the efficiencies of an organization?

34:10.960 --> 34:11.960
Yeah.

34:11.960 --> 34:15.200
Well, first of all, yes, your unicorn analogy is correct.

34:15.200 --> 34:17.400
Those are the type of people we look for.

34:17.400 --> 34:21.320
They can, you know, frame the problems, have enough business context and speak business

34:21.320 --> 34:29.600
enough to be credible, but also do the math and the statistics to build and select models

34:29.600 --> 34:33.080
and train models, but also put them into production, right?

34:33.080 --> 34:37.320
We don't like handoffs between those rules, because it slows us down.

34:37.320 --> 34:42.000
So we do hire unicorns, now we've been adding that unicorns do exist.

34:42.000 --> 34:44.040
It's just that they're a little horn.

34:44.040 --> 34:50.640
It's not always visible in early stages development, you can train people, right?

34:50.640 --> 34:56.880
So we can hire folks, very smart folks, that are willing to learn these things.

34:56.880 --> 34:59.520
And it's sort of a trait that we look for.

34:59.520 --> 35:04.760
It's a tough one to really identify in interviews, but you can pull out of them in clever ways,

35:04.760 --> 35:09.560
asking them about a time where they've had to go way outside of their, you know, purview

35:09.560 --> 35:10.560
to get something done.

35:10.560 --> 35:11.560
And we look for that.

35:11.560 --> 35:17.760
We've hired a lot of physicists, for example, that have gone way outside of their purview

35:17.760 --> 35:18.760
to get something done.

35:18.760 --> 35:24.280
You know, they might have to go their job is to, you know, get satellite imagery.

35:24.280 --> 35:30.440
And because they didn't have any, you know, support to process the data, they took it upon

35:30.440 --> 35:36.640
themselves to build structures and packages to make the processing more efficient.

35:36.640 --> 35:42.840
Or because, you know, they needed to more machines than their organization was providing

35:42.840 --> 35:43.840
them with.

35:43.840 --> 35:46.840
They took it upon themselves to go get into the cloud and provision their own machines,

35:46.840 --> 35:47.840
right?

35:47.840 --> 35:51.080
So these are examples of folks that will do whatever it takes to get that thing up and

35:51.080 --> 35:52.080
running.

35:52.080 --> 35:56.400
And that's what we look for, and that's what we provide them with all the tools that

35:56.400 --> 36:01.120
they need to be effective at doing an end-to-end solution.

36:01.120 --> 36:03.400
Now we're not crazy here.

36:03.400 --> 36:07.320
We do know that there are boundary conditions to this, and we're well aware of them.

36:07.320 --> 36:10.000
We do benefit from a few things at StitchFix.

36:10.000 --> 36:13.000
Number one, our data is not particularly among us.

36:13.000 --> 36:16.280
We deal with terabytes of data, not pediments.

36:16.280 --> 36:23.080
And this makes it much more feasible to have these unicorn types do, you know, code well

36:23.080 --> 36:30.200
enough to, you know, do their own data pipelines, as well as implement them in a production

36:30.200 --> 36:31.920
framework, et cetera.

36:31.920 --> 36:36.640
Now if there is a point where the data gets so big that you really need to get highly

36:36.640 --> 36:41.400
specialized, you know, you can no longer do this stuff in Python, you have to resort to

36:41.400 --> 36:48.520
C++ or heavily typed languages where the processing could be a lot more efficient.

36:48.520 --> 36:49.880
We're not in that place.

36:49.880 --> 36:55.120
We deal with terabytes, not pedabytes, and so we can get away with this for that reason.

36:55.120 --> 36:58.680
That's the data volume effect.

36:58.680 --> 37:02.920
The other thing we benefit is availability requirements.

37:02.920 --> 37:04.240
So we do have the gamut.

37:04.240 --> 37:08.560
We do have some algorithms that are extremely highly available, or need to be extremely

37:08.560 --> 37:12.880
highly available, very high SLAs.

37:12.880 --> 37:20.120
Others are low availability, meaning they're, like I described earlier, a buying algorithm

37:20.120 --> 37:28.200
on our middle, go and purchase, or, you know, give out a buy sheet of what to go buy.

37:28.200 --> 37:33.440
And that algorithm does not need to be nearly as highly available, because it's only used

37:33.440 --> 37:36.360
internally by about 30 merchants, right?

37:36.360 --> 37:42.160
So it spits out their buy sheets for them, and that one, you know, it could break, and

37:42.160 --> 37:46.840
our algorithm developer can send out a note to the 30 people and says, hey, I'm on it,

37:46.840 --> 37:49.840
it'll be back up and running in an hour, and that's fine.

37:49.840 --> 37:55.200
So that, in that scenario, it's a much lower availability requirement, and it allows us

37:55.200 --> 38:01.520
to be, to make judgment calls on, you know, the level of support we need, it needs to provide.

38:01.520 --> 38:05.080
So those are two examples of boundary conditions.

38:05.080 --> 38:10.120
Okay, our data is not that big, that you need specialization, nor is it, in some cases,

38:10.120 --> 38:14.120
need to be so highly available that it can never fail, right?

38:14.120 --> 38:20.080
You have different engineering requirements based on those parameters.

38:20.080 --> 38:21.880
And so it allows us to do things different.

38:21.880 --> 38:27.800
We also, oftentimes, don't have the same consequences as other companies were, I mentioned

38:27.800 --> 38:33.120
our styling, our rhythm is pretty sensitive to failures, we don't want to get that one

38:33.120 --> 38:34.120
wrong.

38:34.120 --> 38:36.360
But failures are not so bad.

38:36.360 --> 38:42.400
You know, in fact, I would say, we would do things differently if we were in manufacturing

38:42.400 --> 38:43.720
or medical.

38:43.720 --> 38:49.240
In those two domains, you want to be far more buttoned up, you don't want to do the

38:49.240 --> 38:52.160
amount of risk taking that we do with our algorithms.

38:52.160 --> 38:56.440
In those areas, you need to be ironclad because the cost of getting something wrong, it

38:56.440 --> 38:58.840
could be devastating to the company.

38:58.840 --> 39:04.480
So we're aware of these boundary conditions, and I think that's a key message to get

39:04.480 --> 39:08.920
out there is you want to do what's appropriate for your environment.

39:08.920 --> 39:14.120
And for us, we found that, given those different requirements, we don't need to be as highly

39:14.120 --> 39:18.400
available in some cases, and we don't have as big a data in some cases, and we don't

39:18.400 --> 39:21.880
have the big consequences in other cases.

39:21.880 --> 39:28.480
And so that means we can get by with doing things and a more generalist model, which allows

39:28.480 --> 39:31.760
us to innovate much faster.

39:31.760 --> 39:35.560
The good side of generalist roles is you can innovate much faster, you can try things

39:35.560 --> 39:40.240
much quicker, you can tail quicker, and also lead to successes quicker.

39:40.240 --> 39:42.400
And it also leads to very fulfilling roles.

39:42.400 --> 39:46.560
There's nothing more satisfying than owning something from end to end.

39:46.560 --> 39:51.720
It gives you the three properties of job satisfaction that Dan Ping talks about in his book

39:51.720 --> 39:52.720
drive.

39:52.720 --> 39:56.280
You get autonomy because you are no longer depending on something else for success.

39:56.280 --> 40:01.680
You get mastery because you know this thing from end to end and you get purpose or impact.

40:01.680 --> 40:05.880
You get to impact the company in a very measurable way.

40:05.880 --> 40:11.800
And all those three things combine to make it one sweet role in data science and statistics.

40:11.800 --> 40:19.960
And you mentioned you've got this platform's team that is part of the algorithms organization.

40:19.960 --> 40:25.880
Is that team staff with the same type of generalist could they swap out and take the

40:25.880 --> 40:36.480
place of one of the algorithms folks that's working on a modeling problem in vice versa?

40:36.480 --> 40:43.720
Less so why there is that is a more clear distinction and skill set.

40:43.720 --> 40:50.760
I would say that our algorithms platform team it tends to be much better computer scientist

40:50.760 --> 40:56.760
than our data science side of the house which tend to be in you know some of the sciences

40:56.760 --> 41:02.280
either statistics or math or even neuroscience or some of the physics domains.

41:02.280 --> 41:05.280
But they usually don't come from a computer science background.

41:05.280 --> 41:08.440
And that's why they're very complimentary as well you know one team is building all the

41:08.440 --> 41:12.880
tooling to enable data scientists to not have to worry about the internet.

41:12.880 --> 41:14.440
And so there is a bit of a distinction there.

41:14.440 --> 41:20.720
Now happily we've had some migration between the groups and to our surprise it's more

41:20.720 --> 41:27.240
or so from the data science side to the data platform or our own platform side.

41:27.240 --> 41:30.160
We thought that there would be the other way.

41:30.160 --> 41:35.160
It seems like everybody wants to be a data scientist these days and less an out a platform

41:35.160 --> 41:36.160
developer.

41:36.160 --> 41:40.160
But happily we found the office that we've had more migration the other way.

41:40.160 --> 41:44.640
Now not everyone can transition back and forth I think there has to be you know a little

41:44.640 --> 41:49.440
bit of skills that people either have picked up or have been classically trained you know

41:49.440 --> 41:54.240
computer science is one of those things where I think it matters that you get some real

41:54.240 --> 42:01.080
training real academic training not just hack your way into things it can really matter

42:01.080 --> 42:03.680
and the way you design and write code.

42:03.680 --> 42:10.360
But happily it's we've had some malleability across those two pieces of the team.

42:10.360 --> 42:18.160
But I guess the key distinction is that typically the data scientist that's working on a problem

42:18.160 --> 42:22.280
isn't waiting for platform features or capabilities there.

42:22.280 --> 42:27.600
The platform team is outside of that innovation loop for getting projects done.

42:27.600 --> 42:28.600
That's right.

42:28.600 --> 42:34.200
There's no handoffs between the teams right you're not going to data scientists isn't going

42:34.200 --> 42:39.720
to go to a data platform engineer and say here's what I need from you right that data

42:39.720 --> 42:44.200
rather than the short term hopefully there's some long term communication there.

42:44.200 --> 42:48.560
Long term what happens actually is it's the data platform that figured out what needs

42:48.560 --> 42:49.560
to be built.

42:49.560 --> 42:52.160
They build all the things that aren't asked for.

42:52.160 --> 42:57.040
So nobody asked for you know a containerization package they just realized you know that's

42:57.040 --> 43:00.440
probably hard for the data scientists to do that we should do that for them.

43:00.440 --> 43:05.600
Well nobody asked for you know a distributed processing engine you know the data platform

43:05.600 --> 43:09.320
folks just observed the yeah the running of some issues let's take care of that for

43:09.320 --> 43:10.320
them right.

43:10.320 --> 43:16.480
They do all these wonderful things by just being good listeners good observers and build

43:16.480 --> 43:19.720
what's not asked for but it's desperately going to be needed.

43:19.720 --> 43:25.440
And so that's how things get done is we just keep people very closely working together.

43:25.440 --> 43:31.360
They do have some different seal sets and they watch for where they can add value.

43:31.360 --> 43:37.680
And so you talked about three kind of characteristics that the way you organize and we've touched

43:37.680 --> 43:44.480
on two of them the third is around kind of supporting emergent behaviors in the organization

43:44.480 --> 43:45.480
what does that mean.

43:45.480 --> 43:52.600
Yeah so you know I mentioned we have several dozen algorithmic capabilities and I can only

43:52.600 --> 43:58.600
think of one of them that was actually asked for all the others were emergent meaning

43:58.600 --> 44:01.720
they came from data science tinkering.

44:01.720 --> 44:06.120
So what that means is we have data scientists and we hire them to do something they have

44:06.120 --> 44:09.840
some stated priorities and they'll be working on that stuff.

44:09.840 --> 44:14.280
And along the way they'll come across some data that was curious or interesting to them

44:14.280 --> 44:16.560
you know not what they're supposed to be doing but they stumble and say I wonder why

44:16.560 --> 44:18.920
that turned out to be as big as it was.

44:18.920 --> 44:23.680
And they might follow that path and go explore it and then so doing they might trip across

44:23.680 --> 44:29.840
some unexplained phenomenon and it leads to the development of a new capability you know

44:29.840 --> 44:33.560
just at nobody asked them to do it just curiosity ensued.

44:33.560 --> 44:38.800
And the next thing you know they've discovered you know the next capability that we're going

44:38.800 --> 44:40.440
to be leveraging.

44:40.440 --> 44:49.960
In example being we have somebody named Dara he was working on these purchasing algorithms

44:49.960 --> 44:54.240
and as a side project he sort of tinkered and he said I wonder if I could use an algorithm

44:54.240 --> 44:56.440
to design clothing.

44:56.440 --> 45:01.640
And so then he started tinkering and figured out that this looks pretty good that if he

45:01.640 --> 45:07.400
used this form of genetic algorithm he can recombine old styles together in new ways

45:07.400 --> 45:11.120
that nobody's ever seen before to create something new.

45:11.120 --> 45:16.440
And you know we're all kind of skeptical of it but the nice thing with data is it comes

45:16.440 --> 45:17.440
with evidence.

45:17.440 --> 45:22.080
These aren't just opinionated ideas they come with evidence right.

45:22.080 --> 45:25.920
So by the time he's coming to talk to us about it he's already proven it out to you

45:25.920 --> 45:31.560
know for the most part you know we have measures and statistics like AUC and RMSC

45:31.560 --> 45:35.560
that kind of tell us we're on the right path this has predictive value and then the next

45:35.560 --> 45:41.240
that might be to try it out in real life you know try it out on the AV test on real clients

45:41.240 --> 45:46.400
and that'll you know either validate or reject your earlier evidence and then from that

45:46.400 --> 45:50.680
point it becomes really easy back to that part where I call it a no-brainer it's already

45:50.680 --> 45:55.120
been built so there's no cost to build it and you have evidence of the impact it'll have

45:55.120 --> 45:58.920
once you launch it live and so usually it just kind of goes right into production from

45:58.920 --> 45:59.920
that.

45:59.920 --> 46:04.160
What I described there was an example of a success of course there's failures we have

46:04.160 --> 46:09.720
lots of failures in fact they they outnumber the successes by some magnitude I don't know

46:09.720 --> 46:13.760
if it's three to one or five one we've never really kept track but the thing is they're

46:13.760 --> 46:18.640
very low cost they fail and he probably not even think to tell anybody about it because

46:18.640 --> 46:22.600
you just tried some curiosity thing anytime I didn't go anywhere you shut it down you move

46:22.600 --> 46:29.040
on and that's the beauty I've learned of these data products is they're extremely low

46:29.040 --> 46:34.240
cost to explore and yet they come with this evidence that show when you're on the right

46:34.240 --> 46:38.680
path and then you can easily even build and productionize them for barely you know cheap

46:38.680 --> 46:44.240
they don't take a lot of upfront cost it's just somebody's tinkering and then you can

46:44.240 --> 46:50.480
try them out you know an AV test that really get the true measure and then you know push

46:50.480 --> 46:57.200
it live to the rest of the company if it really holds up and so low cost exploration

46:57.200 --> 47:03.520
with evidence and then the last little bit that I think is an important thing is these asymmetric

47:03.520 --> 47:08.560
outcomes right to cost the failures small the costs are the benefits of success are big

47:08.560 --> 47:15.840
and so you can have that sort of losing ratio you might have you know three to one failures

47:15.840 --> 47:22.520
to success rate and the one success will pay for all the failures and it's a way to really

47:22.520 --> 47:28.680
kind of endorse innovation and foster rich in your organization is to you know those three

47:28.680 --> 47:34.840
properties of low cost exploration evidence of their efficacy and asymmetric outcomes.

47:34.840 --> 47:41.400
And so to maybe wrap things up you know much of the way you've talked about these organizational

47:41.400 --> 47:49.800
principles is unconventional in the well I don't yeah it's even unconventional the right word

47:49.800 --> 47:55.800
here in the sense of all the stuff is new and I don't know that there's necessarily a convention

47:55.800 --> 48:04.440
but it's it certainly goes against the direction that things are headed you know if someone

48:04.440 --> 48:14.200
out there has heard what you are describing and is in or runs an organization that is not organized

48:14.200 --> 48:21.240
like this at all but is kind of interested in these ideas any advice for them. Yeah you really

48:21.240 --> 48:30.360
got to be thoughtful about your environment you know no way of working is necessarily better than

48:30.360 --> 48:37.160
any other it has to be a good fit for your environment and so you know even what we've done here

48:37.160 --> 48:41.720
it's districts if we didn't do this from the beginning I'm not sure it would have been

48:41.720 --> 48:47.960
the company would have been as amenable to it right we were you know here from the very beginning

48:47.960 --> 48:53.000
we established some of these ways of working and then we had a lot of successes to build on and I

48:53.000 --> 48:59.560
think that's what allowed us to pave the way to learn and foster the parts that worked and get rid

48:59.560 --> 49:06.120
of the parts that didn't work so well so we have to be very reflective on that like you have to

49:06.120 --> 49:12.520
figure out well why is there friction when we try to do this and why is there you know resistance

49:12.520 --> 49:16.600
when we try to do this other way and figure out what it is is going on you know it's kind of like

49:16.600 --> 49:22.920
the study of incentives within an organization figure out what works so you need to do the right

49:22.920 --> 49:27.880
thing for your environment is one thing and then be aware of those boundary conditions right that

49:27.880 --> 49:34.200
I mentioned you know we can are able to do this for you know various reasons of our data is not

49:34.200 --> 49:39.800
big we don't have in most cases the availability requirements etc so you have to really be thoughtful

49:39.800 --> 49:46.760
about this and figure out you know we've spent significant time on this debating and a

49:46.760 --> 49:53.720
entire day off sites just to talk about org structure and process and the main credit I will give

49:53.720 --> 50:00.040
us is we didn't do the default thing we didn't just say well let's do it we did our last companies

50:00.040 --> 50:05.800
in fact I explicitly came to stitch fix partially for that reason I mentioned all that all my

50:05.800 --> 50:11.000
rational for joining but there was one other nice thing and that was that I'd made a lot of

50:11.000 --> 50:16.680
mistakes in my press career at Netflix and Yahoo or you know they weren't really mistakes until

50:16.680 --> 50:22.200
hindsight gave me the clarity I needed I looked back and said gosh if I could start over I would

50:22.200 --> 50:27.240
do things differently at all these companies and sometimes it's hard to start over at your existing

50:27.240 --> 50:33.960
place because you just have a lot of legacy code you need to support and so forth but I remember

50:33.960 --> 50:39.320
that when I went to stitch fix I said wow I have a clean slate right now I'm going to leverage

50:39.320 --> 50:44.760
everything I learned in my career and do this very intentionally from the beginning and set up

50:44.760 --> 50:49.320
all the stuff that I thought would always be a good idea that I learned only learned you know

50:49.320 --> 50:55.000
three years of experience and so that thoughtfulness I think is what brought on a lot of this and

50:55.000 --> 51:01.080
again not I couldn't claim to have foreseen everything that we've done it was just a matter of

51:01.080 --> 51:06.120
keeping our eyes open and keep you know a good group of people that I was fortunate enough to

51:06.120 --> 51:12.680
hire and have them to debate things with and you know collaborate with on setting up the right

51:12.680 --> 51:18.040
structures and incentives to do this you know way there was a hundred percent appropriate for our

51:18.040 --> 51:23.640
environment and I think that paid off pretty well so don't ever underestimate the amount of

51:23.640 --> 51:29.000
thought and work it takes it takes to put something like this together and don't accept the defaults

51:29.000 --> 51:34.120
don't just do it like you did at your last company do it intentionally correct for your environment

51:34.120 --> 51:39.640
well Eric thanks so much for taking the time to chat with me about what you've been up to

51:41.400 --> 51:46.040
I think there are really some interesting learnings in here for folks that are on their own

51:46.040 --> 51:53.080
processes of or their own paths of organizing for data science sounds good well thanks for having

51:53.080 --> 52:01.880
me on it's been fun all right everyone that's our show for today if you like what you've heard

52:01.880 --> 52:07.640
here please do us a favor and tell your friends about the show and if you haven't already

52:07.640 --> 52:12.680
hit the subscribe button yourself make sure to do so so you won't miss any of the great episodes

52:12.680 --> 52:18.040
we've got in store for you for more information on any of the shows in our strata data series

52:18.040 --> 52:25.400
visit twomolei.com slash strata sf19 thanks once again to cloud error for sponsoring this series

52:25.400 --> 52:32.120
be sure to check them out at cloud error.com slash ml as always thanks so much for listening

52:32.120 --> 52:49.400
and catch you next time

