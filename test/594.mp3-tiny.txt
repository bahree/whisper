Alright everyone, welcome to another episode of the Twimmel AI podcast.
I am your host Sam Charmington, and today I'm joined by Vasey Filament, Vasey is Vice President
and General Manager of Machine Learning and AI at Amazon.
Before we get going, be sure to take a moment to hit that subscribe button wherever you're
listening to today's show.
Vasey, welcome to the podcast.
Thanks for having me Sam.
I'm super excited for this discussion for those who, well, you don't know yet, but you're
about to know.
This is a very special interview because it is the first in-person interview I've
done since NURPS in Vancouver in 2019.
I happen to be in New York for some meetings with AWS as was Vasey, and here we are.
We're going to spend some time today talking about the recently announced Amazon Code
Whisperer, Coding Companion, and as a bonus, Vasey will be doing a demo for me that
you'll be able to catch on YouTube towards the end of our interview.
Vasey, let's get started with some background.
Tell us a little bit about your role at AWS.
Yeah, so I'm Vice President at AWS and I'm responsible for our AI services.
My background is machine learning, back in the 90s, I did a PhD in Computer Science from
the University of Maryland, and I chose to do it in machine learning.
It wasn't a common thing to do at that time.
A lot of my friends were asking me what, what the heck is machine learning?
Why are you doing machine learning?
You should be doing databases or you should be doing operating systems.
But I have to say that I'm the one with the last laugh.
I'm kind of glad that I did it at that time and serving me really well right now.
In your role at AWS, what aspects of ML and AI are you responsible for?
Yeah, I'm responsible for a lot of the services that we have at the top layer of the stack.
Are you familiar with the three layers of the stack, the way we think about machine learning?
Absolutely.
Yeah, so we can recap that infrastructure at the bottom, develop or data sciences,
focus tools and middle, and cognitive services for lack of a better order.
AI services at the top.
Right.
And I'm responsible for the top layer there, AI services layer.
It's not just cognitive.
There's a set of cognitive language services at the top layer.
There's also a bunch of industrial services.
So there's a whole variety of services at the top layer of the stack.
The difference though with the middle layer is that the top layer is more managed experience
and people using those services don't have to be experts in machine learning.
All they need to know is, here's my application and here's how it's going to make
it smarter.
And I need this capability that I could just plug into my application to make it smarter.
And then they can just go and use it just like they do today.
They access a web service for compute or the access of web service for storage.
They can now access an AI service in the same exact way.
They can insert it into their own applications and make their applications faster.
So let's dig in a little bit into the distinction between cognitive and industry.
So the non-cognitive services would be things like, I know AWS has, for example,
medical transcription, would you consider that non-cognitive or you think you're not because
of the scenario.
Okay, okay.
Let me describe that to you.
Okay.
When we started out, the first few services we launched, I would call them like
foundational to any machine learning business or a unit.
And they're foundational in the sense that they capture a lot of the cognitive things
that humans are able to do.
So to give you an example, we started with Lex, Lex is sort of the guts of Alexa.
Essentially, it's the two ways removed from Alexa and what's inside it's Lex.
Not many people know that, but now they do actually.
It all makes sense.
Right.
Right.
And Lex is our conversational AI platform and what people can do with it is they could
build their own Alexa, if they wanted to, or they could build a chatbot and insert it into
their website.
And so that Lex is something that would understand both text input as well as speech input.
So they build the bot just once and then they can insert it into a call center conversation
so that it can take the call and maybe take care of the customer that's calling.
So that's Lex, which is a conversational part, that's definitely a cognitive service.
We call it a language service.
I think Gardner calls it a language service too.
So we also have Poly, Poly is our text to speech service.
Alexa's voice is actually a Poly voice.
But customers now have the capability to have their own voices.
They can pick from one of the many languages that we support and the different kinds of
voices we may have for each of the languages.
And then they could just use it for various applications in a common one.
The use it for is they just put this thing on a web page and so when people are driving
their cars, they can just listen to what's on the web page and Poly is going to narrate it
for you.
So that's another cognitive service.
Then we've got Translate, Amazon Translate, which is a document translation.
You can go from one language to another and we've gotten to very high quality these days
in terms of translation.
So you can do a lot of cool things with that.
Then we've got Transcribe, which is about is a speech to text.
We talked about text to speech before with Poly, but this one is a speech to text.
And so this is useful for you to understand what's being said in a conversation.
So that is another cognitive service.
And then we've got yet another one called Comprehend, which is a natural language processing
service.
And it's got all kinds of things you could do with it, like sentiment.
I'm going to piece of unstructured text, it'll tell you what the sentiment is.
Is it a negative sentiment?
Is it a positive sentiment?
So customers often they use it for reviews, like the capture reviews.
And then they run it through Comprehend.
And they understand like our people excited about what what whatever it is that the review
was for or they unhappy about it.
And we've got things like targeted sentiment.
So you know, in the same sentence, you could say that the food was great, but the service
was lousy.
And so that's multiple sentiments within the same sentence.
That's the kind of stuff you could do with Comprehend.
You could also do things with Comprehend where you can extract entities of interest from
unstructured text.
Like let's say you see there's an article on one company acquiring another company.
You could now just look at that news article and you can extract things like which was
the company that was acquired, who was the CEO of that company.
There was a transaction value, all of those kinds of things can be extracted.
So that's kind of what Comprehend does.
It helps you understand unstructured text.
So these are sort of the language or the cognitive services that we have.
And that's what we started with at the beginning.
These are the basic foundational blocks you would need to build anything else.
And then more recently, we've added domain specific services, like let me take one industrial
service for example, monotron is an example of it.
And this is an AWS service that's, it includes a piece of hardware that comes with it.
The hardware is essentially a temperature and vibration sensor.
And it's meant for shop floor technicians that want to monitor their equipment on the
factory floor and they want to do predictive maintenance.
So they buy this piece of hardware from us and they attach it to some portion of the
machine that they want to monitor.
And what we do is we learn the behavior of that part of the machine in terms of vibration
and temperature, which is what the sensors are in that unit.
And so over time, we'll be able to tell the person, the user, the customer, if there's
a deviation in behavior.
And because vibration is something that it predicts, it's something that it tell you
before things are going to fail, it has that predictive nature.
So we're able to actually detect issues way before they actually happen.
So for example, our fulfillment centers, we have conveyor belts in our fulfillment centers to
move the products around.
And so it's very important for those belts to keep running.
And there's a lot of rotating parts there.
And we use these, we use monotron there to monitor the health, the whole conveyance system.
And we've been able to catch failures like two weeks before they actually happened.
So this essentially allows customers to plan the maintenance rather than, you know, react.
It's going to be chaos if it just happens and they are not prepared for it.
So that's a very clear, it's not cognitive, it's something that is specific to the domain.
And it's a large enough segment there and lots of customers have moving parts.
And they have equipment that they can afford to fail.
And so that's a place where things like monotron is being used.
And to combat your question on the medical transcription thing, that's just an extension
of the transcription that we have.
It just applies to the medical domain.
So I would say that that is a cognitive service because it has to do with, you know, speech
and it has to do with understanding speech.
So those are the kinds of things we have.
We have also other kinds of services up there at the top layer of the stack.
We've got things like contact lens for Amazon connect.
And what contact lens does is it's a higher level abstraction.
It uses transcribe underneath the scenes, it uses comprehend underneath the scenes.
But it was built for the call center.
And if you're a call center customer, what you're interested in is you just want to know
why are customers calling me, right?
You want to know that you want to know how every call is going, is it going, and by the way,
you want to know this real time as it's happening, but you may also want to do it post
call, which is called post call analytics.
You want to know how your agents are doing, how are they responding, are they actually
helping the customer, are they saying the right things at the right time, right?
So you could do all of those things, and that's what contact lens does.
It actually implements the actual, it takes the business problem, and just implements it,
using a combination of these foundational services that I talked about.
So we've also got some of those at the top layer of the stack.
And then I've got one more thing, and it's called Amazon Kendra, and that's about search.
It's about enterprise search, where if you're an enterprise, you've got a lot of documents
within your enterprise, and these documents are typically siloed.
They're not, they're not like the documents on the web, where everything's linked to each
other, and you can figure out what people are clicking on and keep track of which documents
are more interesting.
Instead here, they're all siloed, they're sitting in different systems, like they're sitting
in SharePoint, maybe, or they're sitting in your wiki pages, or they're sitting in
inside Salesforce, and so it's always a much harder problem for employees to find things
that they actually want to find within an enterprise.
If you've ever tried the search systems that are an enterprises, they are pretty horrible.
And the one that we used to have inside Amazon wasn't very good either, before Kendra.
So, and this is a space that I know fairly well, having worked at a startup that tried
to solve this problem 20 something years ago, okay, okay, all right.
But it's like you're giving the pitch that we used to give back that, because one of these
problems that just hasn't been solved, and probably won't ever be solved in the enterprise.
Because it's such a difficult problem.
It's a difficult problem, but I think the technology is there where we were able to solve
it in a very good way, and I'll tell you the kinds of things you can do with Kendra.
So Kendra is, again, another higher level of abstraction, where it just focuses on the business
problem, which is search, right.
You need to be able to help people find what they're looking for, and documents are
sitting in different places, so you can't use all the usual techniques.
So what Kendra does, number one, is it allows you to suck in all of the data from all
of these systems, there's connectors, manage connectors, all you have to do is to provide
credentials, and it's going to suck in all of the data, and also keep the access rights
along with it, so that you're not going to show up, they're not going to show up in search
results for people that are not authorized to see certain kinds of documents.
So it keeps not only sucks the data from these different systems, but it also keeps
all the permissions intact so that it knows what to show and what not to show.
The second thing Kendra does is it understands all of the documents like a human would after
reading it.
So now, anyone can ask a question, and I'm not talking about keyword search, I'm talking
about semantic search here.
So I could actually say, where is the IT help desk at this Amazon building, right?
I can just ask that question, and the answer is not going to be like a 100 links where
I need to click on every single document, and then hope I find this information in there.
This Kendra is actually going to tell me it's the fourth floor, right, right up there.
And of course it's going to have all the links as well, the documents below, like you're
used to in a traditional search, but you don't have to go digging for the answer.
If it's confident, it'll show you the answer right up there.
And also in terms of relevance and the documents being the right documents, given we can't
use a lot of signals that are available in the web.
We use a lot of clever techniques there.
This is, it's pre-trained on various domains, so it's going to perform really well out
of the box.
So there's a lot of our customers that love the ease of setting this up.
We've also made it very easy to set up.
You can ingest all of your documents with these connectors, and immediately you've got
a search application that you can just go in and try it out.
And then of course you can embed that into your own websites and things like that.
That's what can, and underneath the scenes, if you're interested in kind of underneath
the scenes, there's a whole bunch of NLP models.
That's what makes it happen.
You said it was a hard problem, and that's rightfully so.
And we were using Verity, and I think we started looking at autonomy.
These are all text search engines, and the problem that you described, if I use our
getting back tons of links that match, but relevance was the difficult problem.
And we were nowhere near at that time, summarization, and some of the things that you described.
Absolutely.
And underneath the scenes, there's a whole bunch of models.
There's a document ranking model, there's an FAQ model, there's a question-answering model,
and all of these models sort of work together, and all of the complexities is not, I mean,
the user doesn't have to deal with all of their complexity and putting all of this together.
We make sure that these things work seamlessly together.
And of course, Kendra has like learning, like continuous learning, it gets better.
As more people use it, there's explicit feedback, there's a thumbs up, thumbs down on the
search results.
If somebody does click it, we'll keep track of it, it gets better for the enterprise.
Or implicitly, we can track, okay, they are clicking on this document in from the results.
So maybe it wasn't the first one, it was the third one, and so those kinds of things
make sure that it gets better over time, which is another thing, it's continuous learning.
So that's another thing that's made it possible for customers to find information that they
actually want to find it, make their employees more productive.
So that's sort of the top, the top layer of the stack is essentially a whole bunch of AI services.
There's some foundational ones, like I said, and then there's some other specific domains
like healthcare and industrial manufacturing domains.
And then there's a lot of applications, sort of things, things that solve business problems
directly.
Mm-hmm.
So you've described this pretty broad set of services, you want to dump jump into talking
about code whisperer, code whisperer is not the first AWS service that's dealing
with code, right?
There was code guru and then possibly others, it talk a little bit about what AWS
has been doing with code and kind of how code whisperer came about.
Mm-hmm.
So we've always known that AI ML is going to, it's going to help a whole variety of different
areas.
It's going to find its way into many different areas and it's going to make things easier
in those areas.
I remember, I think, Werner Vogels, who's our CTO, he wrote a blog article on how,
yeah, ML has the potential to completely change the way developers do their everyday, go
about their everyday, everyday work that they do.
So the journey actually started in 2019.
And if you look at, I think I should start with what is a developer's workflow look like?
That's a great place to start and then I can sort of tell you how we went about tackling
all of those different pieces.
So what a developer first does, of course, he writes code.
That's the first sort of stuff he writes code.
And then the next thing that they do is get the code reviewed by peers and some people
may even use some automated systems to kind of scan the code and help find things.
So there's that piece, you get it reviewed.
And once you've reviewed the code, you deploy it, you deploy the whole thing and then
you monitor it as the application is serving the customers that is meant to serve.
And at that time, you're monitoring your applications for cost and performance and then
you'll maybe find opportunities to make those better.
So those are sort of like key pieces of a workflow, developers workflow.
We started in 2019, we launched our very first service that is related to developers and
writing code.
And the one we decided to launch at that time, it was code guru in 2019.
And what code guru does is it helps you find bugs in your code and it helps you find lines
a code that are very expensive, expensive in terms of the amount of compute it would need.
So that's the kind of stuff that code guru helped.
And so you could think of code guru then as taking care of the quality of the code, the
reviewing part.
It helps in that part of the workflow.
And then is it considered an ML service or an AI service?
Yeah, it is considered an AI service.
So in the AI service groups at the top layer of the stack, we also have a developer focused
set of services.
Code guru was the first one, which we launched in 2019.
The second one we launched was a year later and that's DevOps group.
And this is to tackle the monitoring the application once you've deployed it and you
monitoring it and you're up, then you're trying to find places to optimize it.
And so that's what DevOps guru does and we launched that in 2020.
And we finally, we've now tackled the writing core part, which is what code whisperer is
all about.
And let me set up the problem a little bit more.
I mean, writing code is majority of what a developer would do and I'm still, I'm always
been a very passionate developer and I still write code.
Not as much as I like to, but I still write a lot of code.
And so the best way to set up this problem is to talk through my own experience here.
So what I tend to do with the limited amount of time that I can get these days, I may
pick a pet project that I'm either that I want to automate.
And I'm doing it mainly to learn because I know that there's new frameworks all the time.
And so when I hear about something, I want to do so many new frameworks.
That's right.
That's right.
So I just want to learn.
I want to be in touch with the technology because then I can interact better with
my people because that's what they do all day long.
So what I tried to do, this was maybe a year and a half ago.
I was hearing a lot about React as a framework for front end development.
And the last time I've done any front end programming was back in the 2011-2012 timeframe
when there was this Microsoft had this Windows presentation foundation.
There was this concept of ZAML which would separate design from actual implementation,
the design of how the user interface would look like from the actual implementation of
what would happen when you actually trigger those buttons and those drop downs.
So that was the last time I'd done any kind of front end programming.
But then I heard, I heard so much about React, everybody talk about it.
So I said, okay, I need to learn this too.
I need to see what it is and so I picked a project that I wanted to just implement.
I thought it was going to just be a weekend project.
And so I learned about React.
I knew Java, but JavaScript, I've not done a lot of JavaScript or TypeScript,
but it was closing off and so the first issue was of course programming language
and the syntax and how things are, they're all different.
There's so many programming languages these days and new ones coming up all the time.
And each one has its own area where it shines and other areas where it's not so great.
So that's the first place.
There's the difference if you're it's a different language that's used there.
But then the framework itself, the concepts behind React and how do you use it for doing fun?
And that was another thing.
But it wasn't enough for me to just learn about React.
The moment I once I finished learning about React,
I needed to learn about React router, which is the thing that would route incoming calls.
But that wasn't enough.
I needed to learn about React Redux.
And even that wasn't enough because I liked to test my code.
I like to, I shouldn't even say test.
I'd like to specify the behavior of the code first and then actually go and implement the code.
So I needed to have some testing frameworks.
So just I needed to learn about just.
And that was also not enough because there's another testing framework for React called enzyme,
which is very popular.
So by the, all these different frameworks and by the time I just spent a whole bunch of weekends learning a lot of these things.
And I still haven't written anything meaningful.
I've not made any progress on what I wanted to build, right?
And so that's a big problem that there's just so many different things that developer needs to know.
And now if you take this to the cloud world, with AWS, we've have 250 plus services I think today.
One AWS.
That's about 10,000 plus APIs.
Yeah.
Right?
And by the time we finish this conversation, they'll be a few more.
All right.
So what is a, how is, what is a developer, how does he do this, right?
And typically what people do is they go to stack overflow.
Yeah.
Okay.
You're saying, right?
And then you're going to look for snippets of code that you can copy paste, right?
So that's the, that's the life of a developer and it's, it's, it's gotten harder.
And so that's kind of where code whisperer comes in and what code whisperer is is, it's an
ML powered coding companion, a pair programming companion, if you will, that just helps
developers be more productive.
And it doesn't matter where you are in your journey as a developer, what, what code whisperer
helps you accomplish, it helps you magnify your impact no matter where you are in the
journey.
So, right?
And so I think that's the core, that's the core reason why we built it.
I've got to ask my, my suspicion is that, you know, most folks listening to this podcast,
if not all, have heard of co-pilot, which is kind of collaboration between open AI
and GitHub, which preceded code whisperer by, sometimes six months maybe, did they scoop
you?
Or?
No, I mean, it's, you actually helped me set this up really nicely by with your previous
question, right?
Like, so you, I talked to you about the journey we were on, developer tools, we started
in 2019 with code group, right?
So for me, this is a continuation of that whole journey, so you can, you can argue who
came first with that story in place, right?
But let me tell you about things that we're doing differently with code whisperer.
We did a few things very differently with code whisperer.
The first thing we did differently, if you look at things, the other tools that are out
there that do things that are similar, you'll often, often, you'll see, you'll see headlines
like a lot of the code about 40% of the code that's generated has security problems,
security issues, security and licensing are the things that come up, right?
So I'm going to tackle security first, but then I'll come to licensing, so you're hitting
the, you're hitting all the sweet spots right now.
So yeah, so it's on security.
So what we do is as part of code whisperer, which by the way, it's part of the AWS toolkit,
and the toolkit is a plug-in to all the major IDs, so it's, we've got plugs into which
was studio code, it also plugs into all the jet-brains IDs, so it's, I think, PyCharm
for Python and IntelliJ for Java and the WebStorm.
And primarily to do completion for APIs and that kind of thing.
Yes, and it's, or initially, if not, yeah, we're not talking about completion, like the
way IntelliSense used to be, we're talking about like 20 lines of code and 25 lines of code,
so when you get to the demo at the end, you'll see, see, that was speaking more generally
about the IDE toolkit, that preceded code whisperer, correct?
Or is that?
Oh, the AWS toolkit has been there for a long time, right, and that's how that was primarily
created to make those IDs aware of the AWS API.
Exactly, exactly, right, completion and things like that.
Exactly, okay, now it is like completion at another level.
That's right, you will show us, absolutely, absolutely, yeah, that's true.
So, and what people just need to do is just download the AWS toolkit, and they have
it as part of these IDs, we also integrated code whisperer into our Lambda console,
so Lambda is our serverless service, so it's where you just type in code, and there's
no servers to manage, you code just runs and gives you the results, right?
And so there's a lot of code that's being written on the Lambda console, so it's plugged
in there, it's also built on the Cloud9, yeah, yes it is, okay, it comes with integration
into Cloud9 as well, that's our web-based ID, so we were on a topic and I digress
and went into this one, yeah, the differentiators, right?
So this, the first one is the security thing, like for us at AWS, security is like job
zero, I'm sure you've heard a lot about how seriously we take security, and we think
we need to help, because security is a very specialized skill, most companies have, you
know, a separate group of experts that are just there for, you know, for this topic in general,
and so we have what's called a security scan, that's built into code whisperer, so you
can, you could write code, and then you could, you could accept a lot of the code whisperer
suggestions, and you can also edit it further, but at the very end, we've got the security
scan thing that you can hit, and it's going to tell you if there are any security issues
in the code that, that it's scanned, so that's the first thing that we've done differently,
we want to make sure that the code we generated, the code that ends up coming out at the
other end, we want to help in, in as many ways as we can to make sure that it has the,
it doesn't have any security issues, and presumably that security scan is also an ML model
that's trained in recognizing the potential security issues, absolutely absolutely, yeah, yeah.
Code Guru had this capability when we launched it in 2019, and so we're, we're using
a lot of that here as well, okay, so that's the first area where it's different, and
the second area where it's different is in terms of the code generates, I'm sure you've
heard of AI systems, like with games like chess and go, these AI, they come up with new
moves that they've never seen before, new strategies they've never seen before, and to
a large extent, that's what happens when code whisperer is generating code, it's generating
code it's not seen before, but there may be instances where the code that it generates
is close enough to something that it's seen before, and Code whisperer of course is trained
on billions of lines more than billions of lines of code, from public repositories, you
know, from Amazon repository, it's code repositories, from documentation and forums, public
forums, and that's, it's trained on a lot of stuff, so it may have seen something similar
before, and then what code whisperer will do is it provides what we call a reference tracker
where it lists the license under which that other similar piece of code was provided, so
this way developers know that the code that is there could potentially have that license,
they can decide whether they want to include that piece of code, but they want to accept
that suggestion, or they don't want to, it depends on what the, what the company rules
are, it depends on things like that, so that's the second thing that we're doing differently,
and the third thing that we're doing differently is like, we talked about the number
of AWS services, right, and so first class support for AWS APIs, we know what the most
common patterns are in terms of application developers and how they use the cloud, and
now you can, without having to learn about the 10,000 plus APIs, without having to worry
about any of that, your intent, you just express your intent as you'll see later, you
express your intent, either in the form of a good name for the function or in the form
of a comment, and we're just going to give you the best pieces of code that would make
the most sense and that point.
So those are sound differences, we're also pretty, we do some aggressive filtering on potential
harmful stuff, and so we're also, we've taken a lot of effort to minimize any issues
there as well.
So these are all the differences for code whisperer at this point in time.
We talked about the sources of code that code whisperer was trained on, you spoke about
them broadly, is GitHub included in that set of repositories?
Anything that's public and has the right license, that's what we use.
Are there specific licenses or types of licenses that you filtered on?
Definitely the pieces of code that are public and are available for consumption, those are part
of the training companies, as well as all of the Amazon code internally that we've had
from over many years, that's part of it as well, and anything that's public and documentation
that's public, those are all pieces of code that goes into the training.
I'm imagining that if you're scouring the web, crawling the web looking for code, even
the identifying code, identifying the licenses associated with that code presents interesting
machine learning problems.
Absolutely, absolutely, there's a lot of classification problems right there, a whole class
of classification problems, just on figuring out which are the ones that you want to use
in which are the ones you don't want to use, and of course, we've used every technique
that we've already have.
I've talked about many of our AI services at the top layer of the stack, Comprehend, for
example, has a document classification API, essentially what you do there is that you decide
what you want to call your category and you give it examples of a certain document that
belong to the category, some number of documents that belong to the category, define
a category two, another set of documents that belong to that category, and then you could
define a third category called other where you give it a whole bunch of documents that
have no particular category, and then Comprehend will train a custom model for you, and
you're not an ML, you don't have to be an ML expert for it, it's just an all-accessible
through the APIs, and then you have now an endpoint where you can send it new documents,
and it's going to tell you, is it class one or class two or class three, and so we have
a lot of these techniques already in place, and we've used that a lot for these kinds
of things, okay, presumably this is based on a large language model, like other implementations
of code generation, in the textual context of LLMs, one of the big conversations is
around bias, and kind of responsible use of those, do those same kinds of issues surface
when we're talking about code, and if so how?
Yeah, so if you look at a lot of the transform models, they've got, you know, they're built
on top of each other, so there's various checkpoints, typically you would have a large language
model that's trained on just text, and then that would be a checkpoint, and then you would
take that, and then now train it on code, right?
So if there's issues with that core-based model, they're probably going to linger on, and
so we've got, if you go to Amazon.science, it's one of the websites, and you'll see
that we published just in the last year alone, we published about 400 papers on responsible
AI, that deals with all of these topics, which we take very seriously, things like bias
and fairness, we have, in my team, we've got the person that wrote the book on algorithmic
bias, he's a professor at UPEN, his name is Michael Karns, he'll meet him later today.
And so we've got all of those experts helping us avoid the pitfalls as much as possible.
Now this is, of course, an emerging, it's a thing that's still progressing, it's not like
we know exactly what we need to do here, but we've got the best minds looking at these
topics and helping us figure out how best to deal with those situations.
I didn't mention some very aggressive filtering that we're doing to prevent those kinds
of situations, those kinds of things were implemented with the guidance of folks like Michael.
I'm imagining the kind of classic profanity in comments is one example, but are there
other, I was kind of trying to get some examples of the way bias types of issues might
surface in a code specific context, are there examples that come in the mind of that?
Yeah, generally if you're, let's say you're writing a function that takes in a gender
and makes a decision based on the gender, there could be areas where bias can creep in.
And so you've got to explicitly look for situations like that and make sure you don't
generate codes along those paths, that's one, another one is of course keys, right?
So we're talking about APIs in the cloud, a common thing that I see happen a lot is just
keys, where your secret keys and developers tend to sometimes just put it into the source
file, including the ones checked into GitHub, right?
There's a lot of your keys are in there, right?
And now if you're learning from all of that and let's say you do want to generate, you
do want to generate that line, it could, like you could leak potential key, right?
And so we've taken a lot of care to prevent those kinds of situations and I'll probably
be able to show you that as well when we actually get to the demo in the end.
Awesome, awesome.
Well, this may be a great segue to the demo before we do any additional thoughts you want
to share before we jump into the demo.
No, I just think that I told you that I was like, I'm a very passionate developer and
a developer and it's still am.
I really think that this is just the beginning of where we're going to be able to do.
And this is going to make developers' lives a lot more easier.
And I think they can focus most developers that I know.
They want to focus on the higher value problem.
They are less interested in the boilerplate, things that a framework may dictate.
And that's the bad part of writing code.
The real cool part is the business logic.
That's the cool part that you want to actually write.
And so I think this is going to be, this is going to be in a space to watch going forward.
There's going to be a lot of innovation coming on this topic and I just, I'm very excited
for what's to come in this area.
Just to probe into that a lot of bit, do you have a gut feel for where you think the innovation
will come first or what the path looks like?
We've got some ideas on where the path looks like.
And I'm sure you know that like 90% of what we do, it is driven by our customers.
It's what they're asking us for.
And about 10% of the time we think on their behalf and we do something based on that.
The obvious next steps will just be support for the more popular languages.
I think we're currently support TypeScript, JavaScript, Java Python is what we support.
So obviously there's going to be an element of supporting some of the key languages.
That's definitely going to be one that's going to be there.
But I think it's just going to get better and better in terms of in terms of the actual
code that's generated.
Today developers can accept, you know, they can accept, there's going to be options.
So when code whisperer generates code, it gives you X number of options.
You can actually scroll through it and see which one sort of fit your style and what
do you want to include.
Those suggestions will get better over time and I think it just make people's lives
lot easier.
And best practices, you know, we can capture best practices.
I mentioned already.
We kind of know the patterns of how AWS APIs are accessed for application development.
And if you use, there's best practices in terms of how you put them together, how you
do error checking and things like that.
And so those things can come more and more out of the box.
And this will make it easier for even, you know, developers that are earlier in their
journey to generate pieces of code that are pretty robust.
So that's pretty much what I can share at this point in time.
Awesome.
Awesome.
Well, let's jump into the demo.
No, okay.
All right.
What are we looking at here, Vasi?
All right.
You're looking at Jedvrain's pie charm.
And I think this one, because Python is not a language that I like, but that's exactly
why you know, code whisperer is very useful.
So let me, let me just alienate it.
I know.
I know.
I know.
I know.
I know.
I know.
I know.
I just don't like.
I hate to be able to redeem yourself by saying you loved Julie.
Okay.
All right.
Anyway.
So I'm going to be doing a series of demos in each one sort of takes it up
a notch a little bit.
That's what I'm going to try and do here.
So the first one, it's kind of going to be a utility kind of thing that I think most
developers want to do.
They end up doing at some point, right?
So code whisperer is enabled and the AWS toolkit has been installed.
You guys can see it on the left side of the screen.
So I'm going to just start by saying a function to convert a JSON file to.
And you see code whisperer just popped up.
In my comment, all right.
So I'm just going to accept that.
And I want to specify a few more things, right?
I want to say things like the keys of the JSON file are the column names.
Again you see that code whisperer popped up.
I'm going to accept that as well.
And then I don't care what the value is much.
And now let's see what code whisperer does.
It just generates the function name.
I'm just going to accept it.
And there is a set of code, a bunch of code that it just popped up.
And then you can see this little thing at the bottom.
And those are the choices.
It says 104.
And so I could probably go through the various options it's given me.
Try and pick the one that I like the most.
And I'm probably going to pick this one.
You can see what it's doing here.
It's writing the header with the keys, just like we said.
And then it's writing all the rows.
So I'm just going to pick that.
And so I guess that's kind of done.
I don't want to print anything.
And then if we just go in here to an empty area and then see what else it's going to.
You can see that what it did here is now it's saying a function to convert a CSV file
to a JSON file.
So it's the opposite of what we just did, which is a common thing that most developers
do.
Like they write a transformation from one side to the other.
And it's very likely want the transformation on the other side as well.
So we can continue doing that and we'll see what happens here.
I don't want that thing.
So there's the function name and CSV to JSON.
I accept it and then I keep going.
And again, I've got a bunch of options here.
You can see it uses a Dict reader on the CSV data and then it's
dumping it into the JSON file.
I could just accept that and I'd be done with it.
So that's sort of the first little demo that I wanted to start with.
So that you get used to the interface.
You kind of see what happens.
Yeah.
What I'll do next is I'll go to a more obscure API.
And I say obscure because most developers that use AWS, they've used the S3.
The typical examples are upload a file to S3 or they're doing some EC2 stuff.
And so transcribe is one of my services, the speech to tech service.
Unless you are an AI developer or unless you're a developer that wants AI in your app,
you probably won't know about it and it's, and so this is a situation exactly like that.
So what I'll start with and because we're going to be demonstrating use of an AWS API here,
I'll start with variables for AWS credentials, right?
And you can see there's the access key.
And you also see that it's not giving me the key itself and even though it may have
seen some keys in the training data, there's a secret key, probably a region.
And I guess I don't care anymore.
Then the next thing I'll do is write a function to transcribe after type write, transcribe
German, you popped up audio file, but I want to say a German audio file to text.
You can see it popped out as well, right?
So it's giving me the name of the function, I accepted it and this is going to be some
elaborate, it's going to be more elaborate so we just wait for it.
You can see a lot of stuff happening here.
The bottom client is created with the transcribe thing that's typically how you can see
that the access keys and the secret keys and the region from above that variables are being
used to generate that variable.
And then you can see the cool thing here, it understands the locale, it's D, D, and so you don't
have to look up the documentation, there's a transcribe start, transcription job, right?
And then here it returns the job, right?
And so there's probably more options, there's probably more options down there, but I'm
just going to ask you, speaking of options, if you knew a little bit about transcribe
and previously defined a variable with the channel type, which is one of those parameters
that transcribe will take.
Would it have inserted that in the right place?
Yes, absolutely.
The way code whisperer works is it gets context in the call, and the context for it
is depends on where the cursor is.
It's code, code around that cursor, and it could even be code in other files in the project.
And so it uses that to figure out what's the best way to do it, and some of the options
being included, some of the options may not include it, right?
So that's kind of how it works.
So let me accept this, and maybe what I, rather than returning the transcribe job, maybe
what I could do is just delete this thing here and see what it would generate, maybe it
would generate the same thing, but okay, wait for the transcription to complete, okay,
while true, and let's see what happens, yeah, okay.
So it's actually parsing that thing, going into it in multiple levels to figure out the
status, sleeping for a while, and so on, and so forth.
So you could keep going with this, and it's discoverability of these APIs, it's now
a lot easier, you don't have to go to Stack Overflow and look for the snippets right there
on the ID.
All right, so that's the second demo that I wanted to show, and I wanted to show how it
would work on an AWS API, that's not very common for people to know about.
Then the last thing that I probably would do, and this is where we, let's actually create
something that we actually run and see if it works, right, and so, and what I'm going
to try and do is write a function to plot the sign of sign of X, and let's say two star
cosine of X, come on, with red and blue dashes for the range minus point of pi, that's a
lot of stuff.
And we always have to pray to the demo guys, so to speak, but you would think that given the
nature of what's happening, you'd be fairly robust to typos, is that what you find it?
In general, when I'm writing code, I'm writing it for the next person that's going to be
looking at it more than anything else.
There's this whole philosophy, and I could talk about it for hours, a good code basis
is one where, let's say you have a new developer in the team, that person can add a new
feature in the shortest amount of time, and I think that's possible only if your code
basis is self-explanatory, it's decoupled, isolated things, responsibilities are isolated.
So yeah, even if I, you could say, okay, why can we correct the typos?
Maybe that would be a future thing that we do, it should be possible to do, I don't
see a reason why that won't work, but in general, the context is a lot of stuff, and
so if let's say there's a spelling or, in fact, what I'm going to do right now, let me
actually take this, let me actually mess around with it, I don't want that argument.
So it generated that, I'm actually going to change that, and now let's see what it does.
It just generated all that stuff, and you could see it's using minus pi to pi, it's got
the red dashes on red dash on sign and the blue on the, let me just accept it, and
then if I go here, yeah, so it's calling that function.
So now if I just run this thing, let's see what happens if it's even correct, and there
it is, all right, so you see, you see the program actually running.
So that's kind of the, the last thing that I wanted to show that you can do things that
are pretty elaborate, and in the end though, the developer is responsible for the code,
and I think the person needs to know what to accept, you know, with the options,
how does he want to take this further? So that's why we call it a, it's more of a companion,
then it's not the thing leading the way, it's the thing that's helping you not have to go,
look, look things up in multiple places.
Yeah. Um, so that's your type, oh not. Right. Right. Right. But I think that's definitely
something that we should be able to handle. Um, so you've just given me a good idea for our
roadmap. Cool. Um, that's all I had to show.
Oh, Vasi, uh, great conversation and great demo. Thanks so much for taking the time to share
with us a bit about code whisperer and more broadly the AS services portfolio and the way
you think about all these things. It was a pleasure. Thanks for having me, Sam. My pleasure. Thank you.
All right. Bye bye.
