 All right, everyone, welcome to another episode of the TwiML AI podcast. I am your host, Sam Charrington. And today I'm joined by Vasi Filaman. Vasi is vice president and general manager of machine learning and AI at Amazon. Before we get going, be sure to take a moment to hit that subscribe button wherever you're listening to today's show. Vasi, welcome to the podcast. Thanks for having me, Sam. I'm super excited for this discussion. For those who, well, you don't know yet, but you're about to know, this is a very special interview because it is the first in-person interview I've done since NeurIPS in Vancouver in 2019. I happen to be in New York for some meetings with AWS, as was Vasi. And here we are, and we're going to spend some time today talking about the recently announced Amazon Code Whisperer coding companion. And as a bonus, Vasi will be doing a demo for me that you'll be able to catch on YouTube towards the end of our interview. Vasi, let's get started with some background. Tell us a little bit about your role at AWS. Yeah, so I'm vice president at AWS, and I'm responsible for our AI services. My background is machine learning. Back in the 90s, I did a PhD in computer science from the University of Maryland. And I chose to do it in machine learning. It wasn't a common thing to do at that time. A lot of my friends were asking me, what the heck is machine learning? Like, why are you doing machine learning? You should be doing databases, or you should be doing operating systems. But I have to say that I'm the one with the last laugh. I'm kind of glad that I did it at that time. It's serving me really well right now. And your role at AWS, what aspects of ML and AI are you responsible for? Yeah, I'm responsible for a lot of the services that we have at the top layer of the stack. Are you familiar, Sam, with the three layers of the stack, the way we think about machine learning? Absolutely. Yeah, so... But we can recap. That's infrastructure at the bottom, developer or data scientist, focus tools in the middle, and cognitive services, for lack of a better word, or AI services at the top. Right, right. And I'm responsible for the top layer there, the AI services layer. It's not just cognitive. There's a set of cognitive language services at the top layer. There's also a bunch of industrial services. So there's a whole variety of services at the top layer of the stack. The difference, though, with the middle layer is that the top layer is more a managed experience, and people using those services don't have to be experts in machine learning. All they need to know is, here's my application, and here's how I'm going to make it smarter, and I need this capability that I could just plug into my application to make it smarter. And then they can just go and use it just like they do today. They access a web service for compute, or they access a web service for storage. They can now access an AI service in the same exact way, and they can insert it into their own applications and make their applications faster. So let's dig in a little bit into the distinction between cognitive and industry. So the non-cognitive services would be things like, I know AWS has, for example, medical transcription. Would you consider that non-cognitive, or are you thinking like the call center AI? Okay, okay. Let me describe that to you in more detail. When we started out, the first few services we launched, I would call them foundational to any machine learning business or unit. And they're foundational in the sense that they capture a lot of the cognitive things that humans are able to do. So to give you an example, we started with Lex. Lex is sort of the guts of Alexa. Essentially it's the two A's removed from Alexa, and what's inside is Lex. Not many people know that, but now they do, I'm sure. It all makes sense now. Right, right. So Lex is our conversational AI platform, and what people can do with it is they could build their own Alexas if they wanted to, or they could build a chat bot and insert it into their website. And so Lex is something that would understand both text input as well as speech input. So they build a bot just once, and then they can insert it into a call center conversation so that it can take the call and maybe take care of the customer that's calling. So that's Lex, which is our conversational part. That's definitely a cognitive service. We call it a language service. I think Gartner calls it a language service too. So we also have Polly. Polly is our text to speech service. Alexa's voice is actually a Polly voice. But customers now have the capability to have their own voices. They can pick from one of the many languages that we support and the different kinds of voices we may have for each of the languages, and then they could just use it for various applications. And a common one they use it for is they just put this thing on a webpage. And so when people are driving their cars, they can just listen to what's on the webpage and Polly is going to narrate it for you. So that's another cognitive service. Then we've got Amazon Translate, which is a document translation. You can go from one language to another. And we've gotten to very high quality these days in terms of translation. So you could do a lot of cool things with that. Then we've got Transcribe, which is a speech to text. We talked about text to speech before with Polly, but this one is speech to text. And so this is useful for you to understand what's being said in a conversation. So that is another cognitive service. And then we've got yet another one called Comprehend, which is a natural language processing service. And it's got all kinds of things you could do with it, like sentiment. Given a piece of unstructured text, it'll tell you what the sentiment is. Is it a negative sentiment? Is it a positive sentiment? So customers often, they use it for reviews, like they capture reviews and then they run it through Comprehend. And they understand like, are people excited about whatever it is that the review was for or are they unhappy about it? And we've got things like targeted sentiment. So in the same sentence, you could say that the food was great, but the service was lousy. And so that's multiple sentiments within the same sentence. That's the kind of stuff you could do with Comprehend. You could also do things with Comprehend where you can extract entities of interest from unstructured text. Like let's say you see there's an article on one company acquiring another company. You could now just look at that news article and you can extract things like which was the company that was acquired, who was the CEO of that company? What was the transaction value? All of those kinds of things can be extracted. So that's kind of what Comprehend does. It helps you understand unstructured text, right? So these are sort of the language or the cognitive services that we have. And that's what we started with at the beginning. These are the basic foundational blocks you would need to build anything else. And then more recently, we've added domain specific services. Like let me take one industrial service, for example, Monitron is an example of it. And this is an AWS service that includes a piece of hardware that comes with it. The hardware is essentially a temperature and vibration sensor. And it's meant for shop floor technicians that want to monitor their equipment on the factory floor. And they want to do predictive maintenance. So they buy this piece of hardware from us and they attach it to some portion of the machine that they want to monitor. And what we do is we learn the behavior of that part of the machine in terms of vibration and temperature, which is what the sensors are in that unit. And so over time, we'll be able to tell the person, the user, the customer, if there's a deviation in behavior. And because vibration is something that it predicts, it'll tell you before things are going to fail. It has that predictive nature. So we're able to actually detect issues way before they actually happen. So for example, our fulfillment centers, we have conveyor belts in our fulfillment centers to move the products around. And so it's very important for those belts to keep running. And there's a lot of rotating parts there. And we use Monotron there to monitor the health of the whole conveyance system. And we've been able to catch failures like two weeks before they actually happened. So this essentially allows customers to plan the maintenance rather than react. It's going to be chaos if it just happens and they are not prepared for it. So that's a very clear. It's not cognitive. It's something that is specific to the domain. And it's a large enough segment there. And lots of customers have moving parts. And they have equipment that they can't afford to fail. And so that's a place where things like Monotron is being used. And to come back to your question on the medical transcription thing, that's just an extension of the transcription that we have. It just applies to the medical domain. So I would say that that is a cognitive service because it has to do with speech and it has to do with understanding speech. So those are the kinds of things we have. We have also other kinds of services up there at the top layer of the stack. We've got things like Contact Lens for Amazon Connect. And what Contact Lens does is it's a higher level abstraction. It uses transcribe underneath the scenes. It uses comprehend underneath the scenes. But it was built for the call center. And if you're a call center customer, what you're interested in is you just want to know why are customers calling me? You want to know that. You want to know how every call is going. Is it going? And by the way, you want to know this real time as it's happening. But you may also want to do it post call, which is called post call analytics. You want to know how your agents are doing. How are they responding? Are they actually helping the customer? Are they saying the right things at the right time? So you could do all of those things and that's what Contact Lens does. It actually implements the actual, it takes the business problem and just implements it using a combination of these foundational services that I talked about. So we've also got some of those at the top layer of the stack. And then I've got one more thing and it's called Amazon Kendra and that's about search. It's about enterprise search where you've got, if you're an enterprise, you've got a lot of documents within your enterprise and these documents are typically siloed. They're not like the documents on the web where everything's linked to each other and you know, you can figure out what people are clicking on and keep track of which documents are more interesting. Instead here, they're all siloed. They're sitting in different systems, like they're sitting in SharePoint maybe, or they're sitting on your Wiki pages or they're sitting inside Salesforce. And so it's a much harder problem for employees to find things that they actually want to find within an enterprise. If you've ever tried the search systems that are at enterprises, they are pretty horrible. And the one that we used to have inside Amazon wasn't very good either before Kendra. This is a space that I know fairly well, having worked at a startup that tried to solve this problem 20 something years ago. But it's like you're giving the pitch that we used to give back then. It's one of these problems that just, you know, hasn't been solved and probably won't ever be solved in the enterprise because it's such a difficult problem. Absolutely. It's a difficult problem, but I think the technology is there where we were able to solve it in a very good way. And I'll tell you the kinds of things you can do with Kendra. So Kendra is again, another higher level abstraction where it just focuses on the business problem, which is search, right? You need to be able to help people find what they're looking for and documents are sitting in different places so you can't use all the usual techniques. So what Kendra does, number one is it allows you to suck in all of the data from all of these systems. There's connectors, managed connectors. All you have to do is to provide credentials and it's going to suck in all of the data and also keep the access rights along with it so that you're not going to show up. They're not going to show up in search results for people that are not authorized to see certain kinds of documents. So it keeps, it not only sucks the data from these different systems, but it also keeps all the permissions intact so that it knows what to show and what not to show. The second thing Kendra does is it understands all of the documents like a human would after reading it. So now anyone can ask a question and I'm not talking about keyword search. I'm talking about semantic search here. So I could actually say, where is the IT help desk at this Amazon building, right? I can just ask that question and the answer is not going to be like a hundred links where I need to click on every single document and then hope I find this information in there. Kendra is actually going to tell me it's the fourth floor, right up there. And of course it's going to have all the links as well, the documents below, like you're used to in a traditional search, but you don't have to go digging for the answer. If it's confident, it'll show you the answer right up there. And also in terms of relevance and the documents being the right documents, given we can't use a lot of signals that are available on the web, we use a lot of clever techniques there. It's pre-trained on various domains, so it's going to perform really well out of the box. So there's a lot of our customers that love the ease of setting this up. We've also made it very easy to set up. You can ingest all of your documents with these connectors and immediately you've got a search application that you can just go in and try it out. And then of course you can embed that into your own websites and things like that. And underneath the scenes, if you're interested in Kendra, underneath the scenes, there's a whole bunch of NLP models. That's what makes it happen. You said it was a hard problem and that's rightfully so. Yeah, we were using Verity and I think we started looking at Autonomy. These are all text search engines and the problem that you described of a user getting back tons of links that match, but relevance was the difficult problem. And we were nowhere near at that time summarization and some of the things that you described. Absolutely. And underneath the scenes, there's a whole bunch of models. There's a document ranking model, there's an FAQ model, there's a question answering model. And all of these models sort of work together and all of the complexities, the user doesn't have to deal with all of that complexity and putting all of this together. We make sure that these things work seamlessly together. And of course Kendra has continuous learning, it gets better as more people use it. There's explicit feedback, there's a thumbs up, thumbs down on the search results. If somebody does click it, we'll keep track of it. It gets better for the enterprise or implicitly we can track, okay, they are clicking on this document from the results. So maybe it wasn't the first one, it was the third one. And so those kinds of things make sure that it gets better over time, which is another thing. It's continuous learning. So that's another thing that's made it possible for customers to find information that they actually want to find it, making their employees more productive. So that's sort of the top layer of the stack is essentially a whole bunch of AI services. There's some foundational ones, like I said, and then there's some that are specific to domains like healthcare and industrial manufacturing domains. And then there's a lot of applications sort of things, things that solve business problems directly. Mm-hmm. Mm-hmm. So you've described this pretty broad set of services. Yeah. We want to jump into talking about Code Whisperer. Code Whisperer is not the first AWS service that's dealing with code, right? There was CodeGuru and possibly others. Yes. Talk a little bit about what AWS has been doing with code and kind of how Code Whisperer came about. Mm-hmm. Mm-hmm. Yeah. So we've always known that AI ML is going to help a whole variety of different areas. It's going to find its way into many different areas, and it's going to make things easier in those areas. I remember I think Werner Vogels, who's our CTO, he wrote a blog article on how AI ML has the potential to completely change the way developers go about their everyday work that they do. So the journey actually started in 2019, and I think I should start with what does a developer's workflow look like? That's a great place to start, and then I can sort of tell you how we went about tackling all of those different pieces. So what a developer first does, of course, is he writes code. That's the first sort of step. He writes code, and then the next thing that they do is get the code reviewed by peers, and some people may even use some automated systems to kind of scan the code and help find things. So there's that piece. You get it reviewed, and once you've reviewed the code, you deploy it. You deploy the whole thing, and then you monitor it as the application is serving the customers that it's meant to serve. And at that time, you're monitoring your applications for cost and performance, and then you'll maybe find opportunities to make those better. So those are sort of key pieces of a developer's workflow. We started in 2019. We launched our very first service that is related to developers and writing code, and the one we decided to launch at that time, it was CodeGuru in 2019. And what CodeGuru does is it helps you find bugs in your code, and it helps you find lines of code that are very expensive, expensive in terms of the amount of compute it would need. So that's the kind of stuff that CodeGuru helped. And so you could think of CodeGuru then as taking care of the quality of the code, the reviewing part, it helps in that part of the workflow. And then... And is it considered an ML service or an AI service? Yeah, it is considered an AI service. So we do have... So in the AI service groups at the top layer of the stack, we also have a developer-focused set of services. CodeGuru was the first one, which we launched in 2019. The second one we launched was a year later, and that's DevOpsGuru. And this is to tackle the monitoring the application once you've deployed it and you're monitoring it and then you're trying to find places to optimize it, right? And so that's what DevOpsGuru does, and we launched that in 2020. And finally, we've now tackled the writing code part, which is what CodeWhisperer is all about. And let me set up the problem a little bit more. I mean, writing code is the majority of what a developer would do. And I'm still... I've always been a very passionate developer and I still write code. Not as much as I like to, but I still write a lot of code. And so the best way to set up this problem is to talk through my own experience here. So what I tend to do with the limited amount of time that I can get these days, I may pick a pet project either that I want to automate, and I'm doing it mainly to learn because I know that there's new frameworks all the time. And so when I hear about something, I want to... So many new frameworks. That's right. That's right. That's right. So I just want to learn. I want to be in touch with the technology because then I can interact better with my people because that's what they do all day long. So what I tried to do, this was maybe a year and a half or a year and a half ago. I was hearing a lot about React as a framework for front end development. And the last time I've done any front end programming was back in the 2011, 2012 timeframe when there was this... Microsoft had this Windows Presentation Foundation. There was this concept of XAML, which would separate design from actual implementation. The design of how the user interface would look like from the actual implementation of what would happen when you actually trigger those buttons and those dropdowns. And so that was the last time I'd done any kind of front end programming. But then I heard so much about React. Everybody talk about it. So I said, okay, I need to learn this too. I need to see what it is. So I picked a project that I wanted to just implement. I thought it was going to just be a weekend project. And so I learned about React. I knew JavaScript, I've not done a lot of JavaScript or TypeScript, but it was close enough. And so the first issue was, of course, programming language and the syntax and how things are. They're all different. There are so many programming languages these days and new ones coming up all the time. And each one has its own area where it shines and other areas where it's not so great. So that's the first place there's a difference. It's a different language that's used there. But then the framework itself, the concepts behind React and how do you use it for doing front end, that was another thing. But it wasn't enough for me to just learn about React. Once I finished learning about React, I needed to learn about React Router, which is the thing that would route incoming calls. But that wasn't enough. I needed to learn about React Redux. And even that wasn't enough because I like to test my code. I like to I shouldn't even say test. I'd like to specify the behavior of the code first and then actually go and implement the code. So I needed to have some testing frameworks. So Jest, I needed to learn about Jest. And that was also not enough because there's another testing framework for React called Enzyme, which is very popular. So there were all these different frameworks. And by the time I'd just spent a whole bunch of weekends learning a lot of these things. And I still haven't written anything meaningful. I've not made any progress on what I wanted to build. And so that's a big problem that there's just so many different things a developer needs to know. And now if you take this to the cloud world, with AWS, we have 250 plus services I think today on AWS. That's about 10,000 plus APIs. And by the time we finish this conversation, there'll be a few more. All right. So what does a developer, how does he do this? And typically what people do is they go to Stack Overflow. Google and Stack Overflow. Yeah. Okay. You're saying the same thing. Right. And then you're going to look for snippets of code that you can copy paste. So that's the life of a developer. And it's gotten harder. And so that's kind of where Code Whisperer comes in. And what Code Whisperer is is it's an ML powered coding companion, pair programming companion, if you will, that just helps developers be more productive. And it doesn't matter where you are in your journey as a developer. What Code Whisperer helps you accomplish, it helps you magnify your impact no matter where you are in the journey. Sure. Right. So that's the core. That's the core reason why we built it. Yeah. I've got to ask, my suspicion is that most folks listening to this podcast, if not all, have heard of Copilot, which is a kind of collaboration between OpenAI and GitHub, which preceded Code Whisperer by sometimes six months, maybe. Did they scoop you or... No, I mean, you actually helped me set this up really nicely with your previous question, right? I talked to you about the journey we were on, developer tools. We started in 2019 with Code Guru, right? So for me, this is a continuation of that whole journey. So you can argue who came first with that story in place, right? But let me tell you about things that we're doing differently with Code Whisperer. We did a few things very differently with Code Whisperer. The first thing we did differently, if you look at the other tools that are out there that do things that are similar, often you'll see headlines like a lot of the code, about 40% of the code that's generated has security problems, security issues. Security and licensing are the things that come up quite a bit. Right. So I'm going to tackle security first, but then I'll come to licensing. So you're hitting all the sweet spots right now. So yeah, so it's on security. So what we do is as part of Code Whisperer, which by the way, it's part of the AWS toolkit and the toolkit is a plugin to all the major IDs. So it plugs into Visual Studio Code. It also plugs into all the JetBrains IDs. So it's, I think PyCharm for Python and IntelliJ for Java and WebStorm. And primarily to do completion for APIs and that kind of thing. Yes. And it's this- Or initially, if not- Yeah. We're not talking about completion like the way IntelliSense used to be. We're talking about 20 lines of code and 25 lines of code. So when we get to the demo at the end, you'll see- Yeah, I was speaking more generally about the IDE toolkit. That preceded Code Whisperer, correct? Or is that- Oh, the AWS toolkit has been there for a long time. Yeah. Right. And that was primarily created to make those IDs aware of the AWS API ecosystem. Exactly. Exactly. For completion and things like that. Exactly. Okay. Now- This is like completion at another level. That's right. Which you will show us. Absolutely. Absolutely. And what people just need to do is just download the AWS toolkit and they have it as part of these IDs. We also integrated Code Whisperer into our Lambda console. So Lambda is our serverless service. So it's where you just type in code and there's no servers to manage. Your code just runs and gives you the results, right? And so there's a lot of code that's being written on the Lambda console. So it's plugged in there. It's also- Is it built into Cloud9 yet? Yes, it is. Oh, okay. It's built into Cloud9 as well. That's our web-based ID. So we were on a topic and I digressed and went into this one. Yeah. The differentiators, right? So the first one is the security thing. For us at AWS, security is like job zero. I'm sure you've heard a lot about how seriously we take security. And we think we need to help because security is a very specialized skill. Most companies have a separate group of experts that are just there for this topic in general. And so we have what's called a security scan that's built into Code Whisperer. So you could write code and then you could accept a lot of the Code Whisperer suggestions and you could also edit it further. But at the very end, we've got the security scan thing that you can hit and it's going to tell you if there are any security issues in the code that it scanned. So that's the first thing that we've done differently. We want to make sure that the code we generated, the code that ends up coming out at the other end, we want to help in as many ways as we can to make sure that it doesn't have any security issues. And presumably that security scan is also an ML model that's trained to recognize potential security issues? Absolutely. Yeah. Yeah. CodeGuru had this capability when we launched it in 2019. And so we're using a lot of that here as well. So that's the first area where it's different. And the second area where it's different is in terms of the code it generates. I'm sure you've heard of like AI systems with games like chess and Go, they come up with new moves that they've never seen before or new strategies they've never seen before. And to a large extent, that's what happens when CodeWhisperer is generating code. It's generating code it's not seen before. But there may be instances where the code that it generates is close enough to something that it's seen before. And CodeWhisperer, of course, is trained on billions of lines, more than billions of lines of code from public repositories, from Amazon repositories, code repositories, from documentation and forums, public forums. And it's trained on a lot of stuff. So it may have seen something similar before. And then what CodeWhisperer will do is it provides what we call a reference tracker, where it lists the license under which that other similar piece of code was provided. So this way, developers know that the code that is there could potentially have that license so they can decide whether they want to include that piece of code or they want to accept that suggestion or they don't want to, it depends on what the company rules are and it depends on things like that. So that's the second thing that we're doing differently. And the third thing that we're doing differently is we talked about the number of AWS services. And so first class support for AWS APIs. We know what the most common patterns are in terms of application developers and how they use the cloud. And now without having to learn about the 10,000 plus APIs, without having to worry about any of that, your intent, you just express your intent, as you will see later, you express your intent either in the form of a good name for the function or in the form of a comment. And we're just going to give you the best pieces of code that would make the most sense in that point. So those are some of the differences. We do some aggressive filtering on potential harmful stuff. And so we've taken a lot of effort to minimize any issues there as well. So these are all the differences for Code Whisperer at this point in time. You talked about the sources of code that Code Whisperer was trained on. You spoke about them broadly. Is GitHub included in that set of repositories? Anything that's public and has the right license, that's what we use. Are there specific licenses or types of licenses that you filtered on? Definitely the pieces of code that are public and are available for consumption. Those are part of the training corpus as well as all of the Amazon code internally that we've had from over many years. That's part of it as well. And anything that's public, like documentation that's public, those are all pieces of code that goes into the training. I'm imagining that if you're scouring the web, crawling the web, looking for code, that even the identifying code, identifying the licenses associated with that code presents interesting machine learning problems. Absolutely. There's a lot of classification problems right there. A whole class of classification problems just on figuring out which are the ones that you want to use and which are the ones you don't want to use. Of course, we've used every technique that we already have. I've talked about many of our AI services at the top layer of the stack. Comprehend, for example, has a document classification API. Essentially what you do there is that you decide what you want to call your category and you give it examples of a certain document that belong to that category, some number of documents that belong to that category, define a category two, another set of documents that belong to that category, and then you could define a third category called other where you give it a whole bunch of documents that have no particular category. And then Comprehend will train a custom model for you and you don't have to be an ML expert for it. It's just all accessible through the APIs. And then you have now an endpoint where you can send it new documents and it's going to tell you, is it class one or class two or class three? So we have a lot of these techniques already in place and we've used that a lot for these kinds of things. Okay. Okay. Presumably this is based on a large language model like other implementations of code generation and the textual context of LLMs, one of the big conversations is around bias and kind of responsible use of those. Do those same kinds of issues surface when we're talking about code? And if so, how? Yeah. So if you look at a lot of the transformer models, they're built on top of each other. So there's various checkpoints. Presumably you would have a large language model that's trained on just text. And then that would be a checkpoint. And then you would take that and then now train it on code, right? So if there's issues with that core base model, they're probably going to linger on. And so if you go to amazon.science, it's one of the websites, and you'll see that we published just in the last year alone, we published about 400 papers on responsible AI that deals with all of these topics, which we take very seriously, things like bias and fairness. In my team, we've got the person that wrote the book on algorithmic bias. He's a professor at UPenn, his name is Michael Kearns, you'll meet him later today. And so we've got all of those experts helping us avoid the pitfalls as much as possible. Now, this is, of course, an emerging, it's a thing that's still progressing. It's not like we know exactly what we need to do here, but we've got the best minds looking at these topics and helping us figure out how best to deal with those situations. I didn't mention some very aggressive filtering that we're doing to prevent those kinds of things, those kinds of things were implemented with the guidance of folks like Michael. Imagining the kind of classic profanity and comments is one example, but are there other... I was kind of trying to get some examples of the way bias types of issues might surface in a code-specific context. Are there examples that come to mind of that? Yeah, generally, if you're, let's say you're writing a function that takes an agenda and makes a decision based on the gender, there could be areas where bias can creep in. And so you've got to explicitly look for situations like that and make sure you don't generate codes along those paths. That's one. Another one is, of course, keys, right? So we're talking about APIs in the cloud. A common thing that I see happen a lot is just keys, where your secret keys and developers tend to sometimes just put it into the source file, including the ones checked into GitHub. There's a lot of your keys are in there. Unfortunately, that does happen, yeah. Right. And now if you're learning from all of that, and let's say you do want to generate that line, you could leak a potential key. And so we've taken a lot of care to prevent those kinds of situations. And I'll probably be able to show you that as well when we actually get to the demo in the end. Awesome, awesome. Well this may be a great segue to the demo. Before we do that, any additional thoughts you want to share before we jump into the demo? No, I just think that I told you that I'm a very passionate developer, and I still am. I really think that this is just the beginning of what we're going to be able to do. And this is going to make developers' lives a lot more easier. I think they can focus, most developers that I know, they want to focus on the higher value problem. They are less interested in the boilerplate things that a framework may dictate. And that's the bad part of writing code. It's the real cool part is the business logic. That's the cool part that you want to actually write. And so I think this is going to be in a space to watch going forward. There's going to be a lot of innovation coming on this topic, and I'm very excited for what's to come in this area. Just to probe into that a little bit, do you have a gut feel for where you think the innovation will come first, or what the path looks like? We've got some ideas on where the path looks like. I'm sure you know that 90% of what we do, it is driven by our customers. It's what they're asking us for. And about 10% of the time, we think on their behalf and we do something based on that. The obvious next steps will just be support for the more popular languages. I think we currently support TypeScript, JavaScript, Java, Python is what we support. So obviously there's going to be an element of supporting some of the key languages. That's definitely going to be one that's going to be there. But I think it's just going to get better and better in terms of the actual code that's generated. Today, developers can accept, there's going to be options. So when Code Whisperer generates code, it gives you X number of options. You can actually scroll through it and see which ones sort of fit your style and what you want to include. Those suggestions will get better over time. And I think it'll just make people's lives a lot easier. And best practices, we can capture best practices. I mentioned already, we kind of know the patterns of how AWS APIs are accessed for application development. And there's best practices in terms of how you put them together, how you do error checking and things like that. And so those things can come more and more out of the box. This will make it easier for even developers that are earlier in their journey to generate pieces of code that are pretty robust. So that's pretty much what I can share at this point in time. Awesome. Awesome. Well, let's jump into the demo. Okay. All right. What are we looking at here, Vasi? All right. You're looking at JetBrains PyCharm. And I picked this one because Python is not a language that I like. But that's exactly why Code Whisperer is very useful. So let me- You just alienated a large portion of our audience. I know. I know. I know. I just don't like- You might be able to redeem yourself by saying you love Julia. Okay. All right. Anyway. So I'm going to be doing a series of demos and each one sort of takes it up a notch a little bit. That's what I'm going to try and do here. So the first one, it's kind of going to be a utility kind of thing that I think most developers want to do, what they end up doing at some point, right? So Code Whisperer is enabled and the AWS toolkit has been installed. You guys can see it on the left side of the screen. So I'm going to just start by saying a function to convert a JSON file to, and you see Code Whisperer just popped up. Even my comment, all right? So I'm just going to accept that. And I want to specify a few more things, right? I want to say things like the keys of the JSON file are the column names. Again, you see that Code Whisperer popped that up. I'm going to accept that as well. And then I don't care about the values much. And now let's see what Code Whisperer does. It just generates the function name. I'm just going to accept it. And there is a set of code, a bunch of code that had just popped up. And then you can see this little thing at the bottom. And those are the choices. It says one of four. And so I could probably go through the various options it's given me and try and pick the one that I like the most. And I'm probably going to pick this one. You can see what it's doing here. It's taking the keys. It's writing the header with the keys, just like we said. And then it's writing all the rows. So I'm just going to pick that. And so I guess that's kind of done. I don't want to print anything. And then if we just go in here to an empty area and then see what else it's going to, you can see that what it did here is now it's saying a function to convert a CSV file to a JSON file. So it's the opposite of what we just did, which is a common thing that most developers do. Like they write a transformation from one side to the other. And it's very likely you want the transformation from the other side as well. So we can continue doing that. And we'll see what happens here. I don't want that thing. And there's the function name, CSV to JSON. I accept it. And then I keep going. And again, I've got a bunch of options here. You can see it uses a dict reader on the CSV data. And then it's dumping it into the JSON file. I could just accept that and be done with it. So that's sort of the first little demo that I wanted to start with so that you get used to the interface. You kind of see what happens. What I'll do next is I'll go to a more obscure API. And I say obscure because most developers that use AWS, they've used S3. The typical examples are upload a file to S3 or they're doing some EC2 stuff. And so Transcribe is one of my services, the speech-to-text service. Unless you are an AI developer or unless you are a developer that wants AI in your app, you probably won't know about it. And so this is a situation exactly like that. So what I'll start with, because we're going to be demonstrating use of an AWS API here, I'll start with variables for AWS credentials. And you can see there's the access key. But you also see that it's not giving me the key itself. And even though it may have seen some keys in the training data, there's a secret key and probably a region. And I guess I don't care anymore. Then the next thing I'll do is write a function to transcribe. I have to type, right, transcribe a German. It popped up audio file, but I want to say a German audio file to text. You can see it popped that as well, right? So it's giving me the name of the function. I accepted it. And this is going to be more elaborate, so we just wait for it. You can see a lot of stuff happening here. The bottom client is created with the transcribe thing. That's typically how... You can see that the access keys and the secret keys and the region from above, the variables are being used to generate that variable. And then you can see the cool thing here, it understands the locale. It's DDE. And so you don't have to look up the documentation. There's a transcribe transcription job, right? And then here it returns the job, right? And so there's probably more options. There's probably more options down there. But I'm just going to... Now if you... Speaking of options, if you knew a little bit about transcribe and say previously defined a variable with a channel type, which is one of those parameters that transcribe will take, would it have inserted that in the right place? Yes, absolutely. So the way Code Whisperer works is it gets context in the call. And the context for it depends on where the cursor is. It's code around that cursor. And it could even be code in other files in the project. And so it uses that to figure out what's the best way to do it. And some of the options may include it, some of the options may not include it, right? So that's kind of how it works. So let me accept this. And maybe what I... And then returning the transcribe job, maybe what I could do is just delete this thing here and see what it would generate. Maybe it would generate the same thing. But okay, wait for the transcription to complete. Okay, while true. And let's see what happens. Yeah. Okay. So it's actually parsing the thing, going into it multiple levels to figure out the status, sleeping for a while, and so on and so forth. So you could keep going with this. And it's discoverability of these APIs, it's now a lot easier. You don't have to go to Stack Overflow and look for the snippet. The snippet's right there on the IDE. All right. So that's the second demo that I wanted to show. And I wanted to show how it would work on an AWS API. It's not very common for people to know about. Then the last thing that I probably would do, and this is where we... Let's actually create something that we actually run and see if it works, right? And so... And what I'm gonna try and do is write a function to plot the sine of X and let's say two star cosine of X, come on, with red and blue dashes for the range minus pi to pi, right? That's a lot of stuff. And granted that we always have to pray to the demo gods, so to speak, but you would think that given the nature of what's happening, it'd be fairly robust to typos. Is that what you find in general? In general, when I'm writing code, I'm writing it for the next person that's gonna be looking at it more than anything else. So there's this whole philosophy and I could talk about it for hours. A good code base is one where let's say you have a new developer in the team, that person can add a new feature in the shortest amount of time. And I think that's possible only if your code base is self-explanatory. It's decoupled, isolated, things, responsibilities are isolated. So yeah, even if I, you could say, okay, why can't we correct the typos? Maybe that would be a future thing that we do. It should be possible to do, I don't see a reason why that won't work. But in general, the context is a lot of stuff. And so if let's say there's a spelling error, in fact, you know what I'm gonna do right now? Let me actually take this, let me actually mess around with it. I don't want that argument, right? So it generated that, I'm actually gonna change that. And now let's see what it does. It just generated all that stuff, right? And you can see it's using minus pi to pi. It's got the red dash on sign and the blue on the, let me just accept it. And then if I go here, yeah, so it's calling that function. So now if I just run this thing, let's see what happens if it's even correct. There it is, all right. So you see the program actually running. So that's kind of the last thing that I wanted to show that it can do things that are pretty elaborate. And in the end though, the developer is responsible for the code and I think the person needs to know what to accept with the options. How does he wanna take this further? So that's why we call it a, it's more of a companion than, it's not the thing leading the way. It's the thing that's helping you not have to go look things up in multiple places. So that- It's your typo, not code whisperers. Right. But I think that's definitely something that we should be able to handle. So you've just given me a good idea for our roadmap. Cool. That's all I had to show. I see. Great conversation and great demo. Thanks so much for taking the time to share with us a bit about code whisperer and more broadly the AI services portfolio and the way you think about all those things. It was a pleasure. Thanks for having me, Seth. My pleasure. Thank you. All right. Take care.
